[2024-07-23 21:06:23,160][explain_satisfiability.py][line:85][INFO] ############ CASE TEXT isComme j'ai mal is written in
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:86][INFO] ############ CASE Prediction is  the
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:87][INFO] ############ Refined Forward Graph
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:88][INFO] ****** Layer 1
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 0
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 1
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 2
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 3
[2024-07-23 21:06:23,160][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 4
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 5
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 6
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 7
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 8
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 9
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 10
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 11
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 12
[2024-07-23 21:06:23,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 13
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 14
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 15
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 16
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 17
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 18
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 19
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 20
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 21
[2024-07-23 21:06:23,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 22
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 23
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 24
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 25
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 26
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 27
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 28
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 0
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,163][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 1
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 2
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 3
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 4
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 5
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 6
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,164][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 7
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 8
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 9
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 10
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 11
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 12
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 13
[2024-07-23 21:06:23,165][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 14
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 15
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 16
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 17
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 18
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 19
[2024-07-23 21:06:23,166][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 20
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 21
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 22
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 23
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 24
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 25
[2024-07-23 21:06:23,167][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 26
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 27
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 28
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 0
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 1
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,168][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 2
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 3
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 4
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 5
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,169][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 6
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 7
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 8
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 9
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 10
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,170][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 11
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 12
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 13
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 14
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 15
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,171][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 16
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 17
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 18
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 19
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 20
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 21
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 22
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,172][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 23
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 24
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 25
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 26
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 27
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 28
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 0
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:06:23,173][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 1
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 2
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 3
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 4
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 5
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 6
[2024-07-23 21:06:23,174][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 7
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 8
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 9
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 10
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 11
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,175][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 12
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 13
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 14
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 15
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 16
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 17
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,176][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 18
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 19
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 20
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 21
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 22
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 23
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,177][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 24
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 25
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 26
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 27
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 28
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,178][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 0
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit19', 'circuit23']
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit23', 'circuit25']
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 1
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 2
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 3
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 4
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,179][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 5
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 6
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 7
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 8
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 9
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,180][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 10
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 11
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 12
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 13
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 14
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,181][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 15
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 16
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 17
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 18
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 19
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,182][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 20
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 21
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 22
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 23
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 24
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,183][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 25
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 26
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 27
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 28
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,184][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 0
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit20', 'circuit23', 'circuit24']
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit19', 'circuit22']
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 1
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 2
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 3
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 4
[2024-07-23 21:06:23,185][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 5
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 6
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 7
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 8
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,186][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 9
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 10
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 11
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 12
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,187][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 13
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 14
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 15
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 16
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,188][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 17
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 18
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 19
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 20
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,189][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 21
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 22
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 23
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 24
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 25
[2024-07-23 21:06:23,190][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 26
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 27
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 28
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 0
[2024-07-23 21:06:23,191][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22']
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit25']
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 1
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 2
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 3
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,192][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 4
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 5
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 6
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 7
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,193][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 8
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 9
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 10
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 11
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,194][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 12
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 13
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 14
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,195][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 15
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 16
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 17
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 18
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,196][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 19
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 20
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 21
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 22
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,197][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 23
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 24
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 25
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 26
[2024-07-23 21:06:23,198][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 27
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 28
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 0
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit23']
[2024-07-23 21:06:23,199][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit21', 'circuit23']
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 1
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 2
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 3
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,200][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 4
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 5
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 6
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 7
[2024-07-23 21:06:23,201][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 8
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 9
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 10
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,202][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 11
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 12
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 13
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,203][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 14
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 15
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 16
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,204][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 17
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 18
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 19
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 20
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,205][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 21
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 22
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 23
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,206][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 24
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 25
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 26
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,207][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 27
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 28
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 0
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit23', 'circuit24']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit20', 'circuit22']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-23 21:06:23,208][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit13']
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 1
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 2
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 3
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,209][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 4
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 5
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 6
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,210][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 7
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 8
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 9
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,211][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 10
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 11
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 12
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,212][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 13
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 14
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 15
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,213][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 16
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 17
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 18
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,214][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 19
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 20
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 21
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,215][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 22
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 23
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 24
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,216][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 25
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 26
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 27
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,217][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 28
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 0
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit22']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit16']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit19']
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 1
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,218][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 2
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 3
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 4
[2024-07-23 21:06:23,219][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 5
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 6
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,220][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 7
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 8
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 9
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,221][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 10
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 11
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 12
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,222][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 13
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 14
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,223][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 15
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 16
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 17
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,224][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 18
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 19
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 20
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,225][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 21
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 22
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 23
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,226][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 24
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 25
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,227][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 26
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 27
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 28
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,228][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 0
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit19', 'circuit21', 'circuit22']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit22']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 1
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,229][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 2
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 3
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 4
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,230][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 5
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 6
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,231][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 7
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 8
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 9
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,232][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 10
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 11
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,233][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 12
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 13
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit17', 'circuit18']
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 14
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,234][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 15
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 16
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,235][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 17
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 18
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 19
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,236][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 20
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 21
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,237][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 22
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 23
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 24
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,238][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 25
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 26
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,239][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 27
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 28
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:23,240][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:06:24,804][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:24,805][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,806][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,807][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,808][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,808][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,809][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,811][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,811][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,812][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,813][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,814][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,814][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,815][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.8496, 0.1504], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,816][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [me] are: tensor([5.4004e-04, 9.9946e-01], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,818][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.8908, 0.1092], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,820][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.4251, 0.5749], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,822][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.8727, 0.1273], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,824][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.0273, 0.9727], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,826][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.9303, 0.0697], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,828][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.9810, 0.0190], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,829][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.8696, 0.1304], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,832][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.7996, 0.2004], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,834][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.6313, 0.3687], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,835][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.7853, 0.2147], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,837][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.5078, 0.3384, 0.1538], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,839][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ j] are: tensor([1.9371e-04, 1.3607e-03, 9.9845e-01], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,840][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.6210, 0.2917, 0.0873], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,841][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.0244, 0.0018, 0.9738], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,842][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.1908, 0.0071, 0.8021], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,843][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ j] are: tensor([1.2114e-02, 5.1254e-04, 9.8737e-01], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,843][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.7603, 0.1516, 0.0881], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,844][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.4619, 0.3026, 0.2355], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,845][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.4905, 0.1420, 0.3675], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,847][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.5936, 0.3099, 0.0965], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,849][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.5081, 0.1322, 0.3597], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,850][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.7117, 0.1490, 0.1393], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:24,852][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.4474, 0.2114, 0.2527, 0.0885], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,853][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token ['] are: tensor([2.4706e-04, 2.0116e-03, 1.8179e-03, 9.9592e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,855][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.3220, 0.0646, 0.0300, 0.5834], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,857][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.1003, 0.0558, 0.1892, 0.6547], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,859][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.2076, 0.0799, 0.2061, 0.5063], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,861][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.0670, 0.0029, 0.0015, 0.9286], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,862][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.5997, 0.0701, 0.2052, 0.1249], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,864][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.4166, 0.0984, 0.3691, 0.1159], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,866][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.0994, 0.0116, 0.2248, 0.6642], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,868][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.4409, 0.2039, 0.1582, 0.1970], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,870][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.4345, 0.1525, 0.1106, 0.3023], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,872][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.5431, 0.0946, 0.1591, 0.2032], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:24,874][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.7163, 0.1013, 0.0828, 0.0700, 0.0296], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,875][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ai] are: tensor([3.5300e-05, 3.1948e-03, 5.9324e-03, 9.9950e-04, 9.8984e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,877][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.4395, 0.1895, 0.1082, 0.0956, 0.1671], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,879][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.0232, 0.0068, 0.0689, 0.0115, 0.8896], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,881][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.0302, 0.0337, 0.1538, 0.0252, 0.7570], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,882][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ai] are: tensor([1.2031e-03, 3.8270e-04, 3.2858e-05, 2.6716e-05, 9.9835e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,884][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.4714, 0.1975, 0.0991, 0.0696, 0.1624], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,886][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.1873, 0.1238, 0.4811, 0.1853, 0.0225], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,888][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.4310, 0.1095, 0.2210, 0.1672, 0.0713], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,890][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.4293, 0.2012, 0.1356, 0.1865, 0.0474], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,891][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.3029, 0.1547, 0.1312, 0.1160, 0.2952], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,894][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.6249, 0.0597, 0.1210, 0.1478, 0.0466], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:24,895][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.3704, 0.1840, 0.0890, 0.0976, 0.0634, 0.1956], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,896][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([1.6735e-05, 2.7578e-04, 1.6085e-03, 7.4659e-05, 1.7438e-04, 9.9785e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,899][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.3933, 0.1937, 0.0797, 0.0975, 0.1214, 0.1145], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,900][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([2.3714e-02, 8.7576e-05, 2.4986e-03, 1.9026e-04, 4.5420e-04, 9.7306e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,902][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.0376, 0.0026, 0.0181, 0.0053, 0.0048, 0.9315], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,903][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([3.4485e-04, 1.7188e-05, 1.4608e-04, 4.4832e-07, 4.4171e-06, 9.9949e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,904][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.4224, 0.1068, 0.1284, 0.0727, 0.1112, 0.1586], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,904][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.1141, 0.0595, 0.3355, 0.1367, 0.2297, 0.1245], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,905][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.1912, 0.1084, 0.1860, 0.2286, 0.0838, 0.2019], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,906][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.3329, 0.1757, 0.1906, 0.1652, 0.1149, 0.0207], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,907][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.2656, 0.0836, 0.1416, 0.0950, 0.0446, 0.3695], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,909][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.3381, 0.0872, 0.1294, 0.1946, 0.0531, 0.1976], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:24,910][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.3714, 0.1431, 0.1618, 0.0646, 0.0661, 0.1345, 0.0585],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,912][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ is] are: tensor([7.5490e-04, 1.4493e-03, 6.0943e-04, 1.1845e-03, 3.6785e-04, 1.1727e-03,
        9.9446e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,913][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.2925, 0.1410, 0.0696, 0.1445, 0.0743, 0.0614, 0.2168],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,916][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.0109, 0.0011, 0.0077, 0.0090, 0.0059, 0.0355, 0.9299],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,917][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.1348, 0.0315, 0.0664, 0.0715, 0.0574, 0.1955, 0.4429],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,919][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.0093, 0.0030, 0.0059, 0.0029, 0.0025, 0.0018, 0.9746],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,921][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.3211, 0.1440, 0.0974, 0.0569, 0.1391, 0.1974, 0.0441],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,923][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.0839, 0.0439, 0.0663, 0.1462, 0.0937, 0.1342, 0.4318],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,925][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.0582, 0.0337, 0.0924, 0.1289, 0.0504, 0.0602, 0.5761],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,927][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.2548, 0.1456, 0.1214, 0.1585, 0.0754, 0.0755, 0.1689],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,929][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.2136, 0.1033, 0.1097, 0.1092, 0.0393, 0.0760, 0.3490],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,930][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.3837, 0.0472, 0.0990, 0.1563, 0.0440, 0.0915, 0.1783],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:24,933][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.3846, 0.1534, 0.0765, 0.1009, 0.0496, 0.1014, 0.0844, 0.0492],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,934][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ written] are: tensor([8.2790e-04, 2.4971e-03, 4.3484e-04, 3.0383e-04, 3.4647e-05, 1.8438e-04,
        9.3152e-04, 9.9479e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,935][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.3095, 0.1444, 0.0494, 0.0703, 0.1470, 0.0500, 0.1672, 0.0622],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,937][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ written] are: tensor([5.7251e-03, 3.3858e-04, 3.8207e-03, 5.3607e-05, 1.2082e-03, 1.6829e-02,
        2.5950e-03, 9.6943e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,939][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.1043, 0.0107, 0.0544, 0.0114, 0.0333, 0.2155, 0.0479, 0.5226],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,940][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ written] are: tensor([1.6785e-02, 5.8956e-04, 6.8580e-05, 5.7225e-05, 9.7077e-05, 5.0981e-05,
        5.6468e-06, 9.8235e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,942][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.3010, 0.0728, 0.1294, 0.0625, 0.0929, 0.1521, 0.0403, 0.1490],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,944][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.1543, 0.0158, 0.1534, 0.0592, 0.0865, 0.0765, 0.3299, 0.1243],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,946][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.1208, 0.0597, 0.1464, 0.1269, 0.0450, 0.1290, 0.3074, 0.0649],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,948][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.2491, 0.1283, 0.0995, 0.1289, 0.0800, 0.0988, 0.1642, 0.0512],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,950][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.1850, 0.1008, 0.0779, 0.0895, 0.0325, 0.0423, 0.1199, 0.3522],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,952][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.3776, 0.0356, 0.0915, 0.1543, 0.0487, 0.0971, 0.0773, 0.1178],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:24,954][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.2256, 0.1441, 0.1356, 0.0525, 0.0645, 0.1641, 0.0644, 0.1289, 0.0202],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,956][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ in] are: tensor([1.1325e-03, 3.1553e-04, 8.2039e-04, 2.1528e-04, 2.1890e-04, 9.0371e-04,
        7.6746e-04, 2.0346e-04, 9.9542e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,957][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.1935, 0.0994, 0.0407, 0.0820, 0.0533, 0.0444, 0.1331, 0.1148, 0.2387],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,959][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ in] are: tensor([1.7274e-03, 2.2602e-04, 4.2156e-03, 7.9364e-04, 1.2881e-03, 9.5384e-03,
        2.6034e-02, 1.2864e-02, 9.4331e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,961][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.0629, 0.0157, 0.0353, 0.0173, 0.0155, 0.0550, 0.1345, 0.4227, 0.2412],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,963][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.0381, 0.0192, 0.0325, 0.0238, 0.0099, 0.0196, 0.0626, 0.0022, 0.7920],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,964][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.2017, 0.0981, 0.1029, 0.0414, 0.1338, 0.2105, 0.0394, 0.1606, 0.0114],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,965][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.0368, 0.0136, 0.0244, 0.0385, 0.0253, 0.0486, 0.1647, 0.3317, 0.3164],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,965][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.0273, 0.0129, 0.0640, 0.0814, 0.0248, 0.0168, 0.4892, 0.0271, 0.2564],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,966][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.1978, 0.1112, 0.0932, 0.1060, 0.0527, 0.0744, 0.1203, 0.0871, 0.1573],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,967][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.1830, 0.0683, 0.0951, 0.0804, 0.0367, 0.0646, 0.1255, 0.0577, 0.2887],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,969][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.2756, 0.0379, 0.0692, 0.1024, 0.0386, 0.0650, 0.1093, 0.1061, 0.1960],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:24,981][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:24,982][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,983][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,983][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,984][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,985][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,986][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,986][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,988][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,989][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,990][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,990][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,991][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:24,992][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.8496, 0.1504], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,993][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([5.4004e-04, 9.9946e-01], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,994][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.8908, 0.1092], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,996][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.4251, 0.5749], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:24,998][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.8727, 0.1273], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,000][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.0273, 0.9727], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,002][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.9303, 0.0697], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,004][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.9810, 0.0190], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,006][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.8696, 0.1304], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,007][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.7996, 0.2004], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,009][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.6313, 0.3687], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,011][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.7853, 0.2147], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,013][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.5078, 0.3384, 0.1538], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,014][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([1.9371e-04, 1.3607e-03, 9.9845e-01], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,016][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.6210, 0.2917, 0.0873], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,018][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.0244, 0.0018, 0.9738], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,020][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.1908, 0.0071, 0.8021], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,021][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([1.2114e-02, 5.1254e-04, 9.8737e-01], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,023][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.7603, 0.1516, 0.0881], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,025][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.4619, 0.3026, 0.2355], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,027][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.4905, 0.1420, 0.3675], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,028][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.5936, 0.3099, 0.0965], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,030][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.5081, 0.1322, 0.3597], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,032][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.7117, 0.1490, 0.1393], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,034][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.4474, 0.2114, 0.2527, 0.0885], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,035][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([2.4706e-04, 2.0116e-03, 1.8179e-03, 9.9592e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,037][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.3220, 0.0646, 0.0300, 0.5834], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,039][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.1003, 0.0558, 0.1892, 0.6547], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,041][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.2076, 0.0799, 0.2061, 0.5063], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,042][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.0670, 0.0029, 0.0015, 0.9286], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,042][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.5997, 0.0701, 0.2052, 0.1249], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,043][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.4166, 0.0984, 0.3691, 0.1159], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,044][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.0994, 0.0116, 0.2248, 0.6642], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,045][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.4409, 0.2039, 0.1582, 0.1970], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,046][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.4345, 0.1525, 0.1106, 0.3023], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,048][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.5431, 0.0946, 0.1591, 0.2032], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,049][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.7163, 0.1013, 0.0828, 0.0700, 0.0296], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,051][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([3.5300e-05, 3.1948e-03, 5.9324e-03, 9.9950e-04, 9.8984e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,052][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.4395, 0.1895, 0.1082, 0.0956, 0.1671], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,054][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.0232, 0.0068, 0.0689, 0.0115, 0.8896], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,056][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.0302, 0.0337, 0.1538, 0.0252, 0.7570], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,057][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([1.2031e-03, 3.8270e-04, 3.2858e-05, 2.6716e-05, 9.9835e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,059][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.4714, 0.1975, 0.0991, 0.0696, 0.1624], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,061][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.1873, 0.1238, 0.4811, 0.1853, 0.0225], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,063][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.4310, 0.1095, 0.2210, 0.1672, 0.0713], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,065][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.4293, 0.2012, 0.1356, 0.1865, 0.0474], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,067][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.3029, 0.1547, 0.1312, 0.1160, 0.2952], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,068][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.6249, 0.0597, 0.1210, 0.1478, 0.0466], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,071][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.3704, 0.1840, 0.0890, 0.0976, 0.0634, 0.1956], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,072][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([1.6735e-05, 2.7578e-04, 1.6085e-03, 7.4659e-05, 1.7438e-04, 9.9785e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,074][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.3933, 0.1937, 0.0797, 0.0975, 0.1214, 0.1145], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,075][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([2.3714e-02, 8.7576e-05, 2.4986e-03, 1.9026e-04, 4.5420e-04, 9.7306e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,077][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.0376, 0.0026, 0.0181, 0.0053, 0.0048, 0.9315], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,078][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([3.4485e-04, 1.7188e-05, 1.4608e-04, 4.4832e-07, 4.4171e-06, 9.9949e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,080][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.4224, 0.1068, 0.1284, 0.0727, 0.1112, 0.1586], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,082][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.1141, 0.0595, 0.3355, 0.1367, 0.2297, 0.1245], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,084][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.1912, 0.1084, 0.1860, 0.2286, 0.0838, 0.2019], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,086][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.3329, 0.1757, 0.1906, 0.1652, 0.1149, 0.0207], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,088][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.2656, 0.0836, 0.1416, 0.0950, 0.0446, 0.3695], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,090][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.3381, 0.0872, 0.1294, 0.1946, 0.0531, 0.1976], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,091][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.3714, 0.1431, 0.1618, 0.0646, 0.0661, 0.1345, 0.0585],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,093][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([7.5490e-04, 1.4493e-03, 6.0943e-04, 1.1845e-03, 3.6785e-04, 1.1727e-03,
        9.9446e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,095][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.2925, 0.1410, 0.0696, 0.1445, 0.0743, 0.0614, 0.2168],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,096][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.0109, 0.0011, 0.0077, 0.0090, 0.0059, 0.0355, 0.9299],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,099][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.1348, 0.0315, 0.0664, 0.0715, 0.0574, 0.1955, 0.4429],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,100][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.0093, 0.0030, 0.0059, 0.0029, 0.0025, 0.0018, 0.9746],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,102][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.3211, 0.1440, 0.0974, 0.0569, 0.1391, 0.1974, 0.0441],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,103][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.0839, 0.0439, 0.0663, 0.1462, 0.0937, 0.1342, 0.4318],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,104][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0582, 0.0337, 0.0924, 0.1289, 0.0504, 0.0602, 0.5761],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,104][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.2548, 0.1456, 0.1214, 0.1585, 0.0754, 0.0755, 0.1689],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,105][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.2136, 0.1033, 0.1097, 0.1092, 0.0393, 0.0760, 0.3490],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,106][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.3837, 0.0472, 0.0990, 0.1563, 0.0440, 0.0915, 0.1783],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,108][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.3846, 0.1534, 0.0765, 0.1009, 0.0496, 0.1014, 0.0844, 0.0492],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,109][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([8.2790e-04, 2.4971e-03, 4.3484e-04, 3.0383e-04, 3.4647e-05, 1.8438e-04,
        9.3152e-04, 9.9479e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,111][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.3095, 0.1444, 0.0494, 0.0703, 0.1470, 0.0500, 0.1672, 0.0622],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,112][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([5.7251e-03, 3.3858e-04, 3.8207e-03, 5.3607e-05, 1.2082e-03, 1.6829e-02,
        2.5950e-03, 9.6943e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,113][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.1043, 0.0107, 0.0544, 0.0114, 0.0333, 0.2155, 0.0479, 0.5226],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,115][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([1.6785e-02, 5.8956e-04, 6.8580e-05, 5.7225e-05, 9.7077e-05, 5.0981e-05,
        5.6468e-06, 9.8235e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,117][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.3010, 0.0728, 0.1294, 0.0625, 0.0929, 0.1521, 0.0403, 0.1490],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,118][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.1543, 0.0158, 0.1534, 0.0592, 0.0865, 0.0765, 0.3299, 0.1243],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,120][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.1208, 0.0597, 0.1464, 0.1269, 0.0450, 0.1290, 0.3074, 0.0649],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,122][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.2491, 0.1283, 0.0995, 0.1289, 0.0800, 0.0988, 0.1642, 0.0512],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,124][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.1850, 0.1008, 0.0779, 0.0895, 0.0325, 0.0423, 0.1199, 0.3522],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,127][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.3776, 0.0356, 0.0915, 0.1543, 0.0487, 0.0971, 0.0773, 0.1178],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,128][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.2256, 0.1441, 0.1356, 0.0525, 0.0645, 0.1641, 0.0644, 0.1289, 0.0202],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,129][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([1.1325e-03, 3.1553e-04, 8.2039e-04, 2.1528e-04, 2.1890e-04, 9.0371e-04,
        7.6746e-04, 2.0346e-04, 9.9542e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,132][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.1935, 0.0994, 0.0407, 0.0820, 0.0533, 0.0444, 0.1331, 0.1148, 0.2387],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,133][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([1.7274e-03, 2.2602e-04, 4.2156e-03, 7.9364e-04, 1.2881e-03, 9.5384e-03,
        2.6034e-02, 1.2864e-02, 9.4331e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,135][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.0629, 0.0157, 0.0353, 0.0173, 0.0155, 0.0550, 0.1345, 0.4227, 0.2412],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,138][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.0381, 0.0192, 0.0325, 0.0238, 0.0099, 0.0196, 0.0626, 0.0022, 0.7920],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,139][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.2017, 0.0981, 0.1029, 0.0414, 0.1338, 0.2105, 0.0394, 0.1606, 0.0114],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,141][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.0368, 0.0136, 0.0244, 0.0385, 0.0253, 0.0486, 0.1647, 0.3317, 0.3164],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,143][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.0273, 0.0129, 0.0640, 0.0814, 0.0248, 0.0168, 0.4892, 0.0271, 0.2564],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,145][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.1978, 0.1112, 0.0932, 0.1060, 0.0527, 0.0744, 0.1203, 0.0871, 0.1573],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,147][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.1830, 0.0683, 0.0951, 0.0804, 0.0367, 0.0646, 0.1255, 0.0577, 0.2887],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,149][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.2756, 0.0379, 0.0692, 0.1024, 0.0386, 0.0650, 0.1093, 0.1061, 0.1960],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,153][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:25,155][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[  54],
        [ 482],
        [ 412],
        [ 167],
        [ 344],
        [1167],
        [  10],
        [ 114],
        [   2]], device='cuda:0')
[2024-07-23 21:06:25,156][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 7682],
        [16830],
        [13604],
        [18661],
        [32307],
        [20939],
        [16831],
        [17988],
        [ 3998]], device='cuda:0')
[2024-07-23 21:06:25,158][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[14796],
        [11541],
        [ 2865],
        [ 3256],
        [ 9913],
        [ 1359],
        [ 1586],
        [ 2338],
        [ 1479]], device='cuda:0')
[2024-07-23 21:06:25,159][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[26099],
        [ 2658],
        [ 6466],
        [ 8803],
        [  352],
        [24423],
        [ 5581],
        [ 1572],
        [   21]], device='cuda:0')
[2024-07-23 21:06:25,161][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[ 5979],
        [ 7296],
        [ 9418],
        [ 9972],
        [13583],
        [10934],
        [10748],
        [11520],
        [ 7264]], device='cuda:0')
[2024-07-23 21:06:25,162][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[21578],
        [18593],
        [10717],
        [ 9330],
        [13258],
        [ 4691],
        [  537],
        [  857],
        [ 8701]], device='cuda:0')
[2024-07-23 21:06:25,164][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 163],
        [ 108],
        [  78],
        [ 105],
        [  30],
        [7817],
        [  22],
        [ 335],
        [ 108]], device='cuda:0')
[2024-07-23 21:06:25,165][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[2313],
        [ 685],
        [ 673],
        [ 863],
        [ 449],
        [1461],
        [  93],
        [2251],
        [  19]], device='cuda:0')
[2024-07-23 21:06:25,166][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[ 8017],
        [ 7976],
        [ 7368],
        [ 4909],
        [10611],
        [ 6038],
        [ 6743],
        [ 6399],
        [ 7170]], device='cuda:0')
[2024-07-23 21:06:25,167][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[1719],
        [1702],
        [2304],
        [4715],
        [6670],
        [6491],
        [ 897],
        [1029],
        [1213]], device='cuda:0')
[2024-07-23 21:06:25,168][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[4771],
        [4047],
        [1679],
        [  25],
        [ 467],
        [ 485],
        [   2],
        [   6],
        [   1]], device='cuda:0')
[2024-07-23 21:06:25,170][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[  11],
        [  28],
        [  33],
        [ 126],
        [ 104],
        [  38],
        [ 372],
        [ 200],
        [1950]], device='cuda:0')
[2024-07-23 21:06:25,172][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[ 5081],
        [ 5088],
        [ 9232],
        [ 2143],
        [ 2554],
        [12994],
        [  335],
        [  818],
        [   36]], device='cuda:0')
[2024-07-23 21:06:25,173][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[154],
        [148],
        [126],
        [ 79],
        [103],
        [106],
        [ 66],
        [110],
        [ 27]], device='cuda:0')
[2024-07-23 21:06:25,174][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 7274],
        [11627],
        [13641],
        [ 9957],
        [ 2451],
        [16304],
        [ 1202],
        [ 8841],
        [   21]], device='cuda:0')
[2024-07-23 21:06:25,176][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[1051],
        [1952],
        [9159],
        [8090],
        [2419],
        [3623],
        [6168],
        [5732],
        [7008]], device='cuda:0')
[2024-07-23 21:06:25,178][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[  1],
        [507],
        [356],
        [ 86],
        [271],
        [ 94],
        [244],
        [208],
        [393]], device='cuda:0')
[2024-07-23 21:06:25,179][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[1328],
        [2445],
        [4039],
        [ 795],
        [2658],
        [2439],
        [1233],
        [1629],
        [ 600]], device='cuda:0')
[2024-07-23 21:06:25,181][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[  92],
        [  36],
        [  51],
        [ 302],
        [  16],
        [ 122],
        [1863],
        [ 242],
        [ 395]], device='cuda:0')
[2024-07-23 21:06:25,182][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[  84],
        [  87],
        [ 188],
        [ 298],
        [1031],
        [  41],
        [ 394],
        [ 196],
        [ 196]], device='cuda:0')
[2024-07-23 21:06:25,184][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[ 812],
        [1785],
        [3334],
        [1828],
        [5069],
        [1866],
        [1831],
        [4290],
        [4357]], device='cuda:0')
[2024-07-23 21:06:25,185][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[ 461],
        [ 502],
        [ 525],
        [ 500],
        [ 883],
        [ 771],
        [1012],
        [ 611],
        [ 817]], device='cuda:0')
[2024-07-23 21:06:25,187][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[14063],
        [14180],
        [12318],
        [10594],
        [ 9592],
        [11912],
        [ 7258],
        [ 9799],
        [ 5827]], device='cuda:0')
[2024-07-23 21:06:25,189][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[2289],
        [2510],
        [4568],
        [ 658],
        [2384],
        [4568],
        [ 543],
        [1053],
        [ 149]], device='cuda:0')
[2024-07-23 21:06:25,190][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[ 6495],
        [ 5950],
        [ 7004],
        [11048],
        [10880],
        [12225],
        [15248],
        [14827],
        [13052]], device='cuda:0')
[2024-07-23 21:06:25,192][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[ 8790],
        [ 9458],
        [ 6791],
        [ 5611],
        [11479],
        [ 5900],
        [ 5947],
        [ 8826],
        [11036]], device='cuda:0')
[2024-07-23 21:06:25,193][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[  45],
        [  52],
        [ 103],
        [  57],
        [  62],
        [ 820],
        [ 713],
        [ 810],
        [2009]], device='cuda:0')
[2024-07-23 21:06:25,195][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[2668],
        [1729],
        [ 962],
        [1162],
        [ 971],
        [1510],
        [1259],
        [1172],
        [1154]], device='cuda:0')
[2024-07-23 21:06:25,197][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[  646],
        [  295],
        [  450],
        [  441],
        [ 2858],
        [  759],
        [ 4859],
        [ 1090],
        [37635]], device='cuda:0')
[2024-07-23 21:06:25,198][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:25,220][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:25,221][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,222][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,222][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,223][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,224][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,224][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,225][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,225][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,226][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,227][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,227][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,229][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,230][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.5003, 0.4997], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,232][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.5002, 0.4998], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,234][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.4998, 0.5002], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,236][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.5001, 0.4999], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,237][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,240][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,241][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,243][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.4997, 0.5003], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,244][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.5003, 0.4997], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,244][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,245][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,246][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,246][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.3337, 0.3333, 0.3330], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,248][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.3337, 0.3334, 0.3329], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,250][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.3333, 0.3335, 0.3332], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,252][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.3335, 0.3334, 0.3331], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,253][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.3334, 0.3334, 0.3332], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,255][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.3334, 0.3334, 0.3332], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,257][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.3333, 0.3333, 0.3334], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,259][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.3331, 0.3335, 0.3334], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,260][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.3334, 0.3330, 0.3336], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,262][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.3333, 0.3332, 0.3335], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,264][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.3333, 0.3334, 0.3334], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,266][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.3333, 0.3334, 0.3333], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,268][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.2504, 0.2501, 0.2498, 0.2497], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,270][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.2504, 0.2501, 0.2498, 0.2497], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,272][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.2500, 0.2502, 0.2500, 0.2498], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,273][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.2502, 0.2500, 0.2499, 0.2500], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,275][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.2501, 0.2501, 0.2499, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,277][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.2501, 0.2501, 0.2500, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,279][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.2500, 0.2500, 0.2501, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,281][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.2499, 0.2501, 0.2501, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,283][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.2501, 0.2499, 0.2503, 0.2498], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,285][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.2499, 0.2498, 0.2501, 0.2502], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,286][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,288][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.2500, 0.2501, 0.2500, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,290][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.2003, 0.2001, 0.1999, 0.1998, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,292][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.2003, 0.2001, 0.1999, 0.1997, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,294][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.2000, 0.2001, 0.2000, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,296][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.2001, 0.2000, 0.1999, 0.2000, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,298][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.2001, 0.2001, 0.1999, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,300][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.2001, 0.2001, 0.2000, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,302][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.2000, 0.2000, 0.2001, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,304][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.1999, 0.2001, 0.2001, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,306][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.2001, 0.1999, 0.2003, 0.1998, 0.1999], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,308][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.1999, 0.1998, 0.2000, 0.2001, 0.2001], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,309][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,310][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.2000, 0.2001, 0.2000, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,311][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.1669, 0.1667, 0.1666, 0.1665, 0.1667, 0.1666], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,312][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.1669, 0.1668, 0.1666, 0.1665, 0.1667, 0.1666], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,312][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.1667, 0.1668, 0.1667, 0.1666, 0.1667, 0.1665], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,313][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.1668, 0.1667, 0.1666, 0.1666, 0.1667, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,315][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.1667, 0.1667, 0.1666, 0.1666, 0.1666, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,317][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.1667, 0.1667, 0.1666, 0.1666, 0.1666, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,319][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.1667, 0.1667, 0.1667, 0.1666, 0.1666, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,320][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.1665, 0.1667, 0.1667, 0.1666, 0.1667, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,322][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.1668, 0.1666, 0.1669, 0.1666, 0.1666, 0.1664], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,324][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.1665, 0.1664, 0.1666, 0.1667, 0.1667, 0.1672], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,325][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1666], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,328][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.1667, 0.1667, 0.1667, 0.1666, 0.1667, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,330][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.1431, 0.1429, 0.1428, 0.1427, 0.1429, 0.1428, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,331][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.1431, 0.1430, 0.1428, 0.1427, 0.1429, 0.1428, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,334][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.1429, 0.1430, 0.1429, 0.1428, 0.1429, 0.1428, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,335][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.1429, 0.1429, 0.1428, 0.1428, 0.1429, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,337][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.1429, 0.1429, 0.1428, 0.1428, 0.1428, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,339][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.1429, 0.1429, 0.1428, 0.1428, 0.1428, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,341][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.1429, 0.1429, 0.1429, 0.1428, 0.1428, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,343][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.1428, 0.1429, 0.1429, 0.1428, 0.1429, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,345][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.1429, 0.1428, 0.1430, 0.1427, 0.1428, 0.1426, 0.1431],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,347][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.1427, 0.1427, 0.1429, 0.1429, 0.1429, 0.1433, 0.1425],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,348][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.1428, 0.1429, 0.1429, 0.1428, 0.1429, 0.1428, 0.1429],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,350][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.1429, 0.1429, 0.1428, 0.1428, 0.1429, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,352][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.1252, 0.1250, 0.1249, 0.1248, 0.1250, 0.1250, 0.1249, 0.1252],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,354][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.1252, 0.1251, 0.1249, 0.1248, 0.1250, 0.1249, 0.1249, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,356][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1250],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,358][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ written] are: tensor([0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,359][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,362][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,363][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,365][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.1249, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,367][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.1251, 0.1249, 0.1251, 0.1249, 0.1249, 0.1248, 0.1252, 0.1252],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,369][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.1249, 0.1249, 0.1250, 0.1251, 0.1250, 0.1254, 0.1247, 0.1250],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,371][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,372][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,372][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.1113, 0.1111, 0.1110, 0.1110, 0.1111, 0.1111, 0.1110, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,373][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.1113, 0.1112, 0.1110, 0.1110, 0.1111, 0.1110, 0.1110, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,374][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.1111, 0.1112, 0.1111, 0.1111, 0.1111, 0.1110, 0.1111, 0.1112, 0.1111],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,375][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ in] are: tensor([0.1112, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,377][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.1111, 0.1112, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1112, 0.1111],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,379][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1110, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,381][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,383][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.1110, 0.1111, 0.1111, 0.1110, 0.1111, 0.1111, 0.1111, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,385][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.1111, 0.1110, 0.1112, 0.1110, 0.1110, 0.1109, 0.1113, 0.1113, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,386][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.1110, 0.1110, 0.1111, 0.1112, 0.1112, 0.1115, 0.1109, 0.1111, 0.1110],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,389][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,390][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.1111, 0.1111, 0.1111, 0.1110, 0.1111, 0.1111, 0.1111, 0.1112, 0.1111],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,413][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:25,414][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,414][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,415][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,416][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,416][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,417][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,418][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,418][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,419][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,421][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,421][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,422][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,423][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.5003, 0.4997], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,423][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.5002, 0.4998], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,424][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.4998, 0.5002], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,425][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.5001, 0.4999], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,426][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,426][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,427][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,428][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.4997, 0.5003], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,429][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.5003, 0.4997], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,431][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,433][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,435][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.5000, 0.5000], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,437][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.3337, 0.3333, 0.3330], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,439][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.3337, 0.3334, 0.3329], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,441][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.3333, 0.3335, 0.3332], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,442][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.3335, 0.3334, 0.3331], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,444][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.3334, 0.3334, 0.3332], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,446][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.3334, 0.3334, 0.3332], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,448][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.3333, 0.3333, 0.3334], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,450][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.3331, 0.3335, 0.3334], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,452][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.3334, 0.3330, 0.3336], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,454][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.3333, 0.3332, 0.3335], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,455][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.3333, 0.3334, 0.3334], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,455][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.3333, 0.3334, 0.3333], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,456][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.2504, 0.2501, 0.2498, 0.2497], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,457][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.2504, 0.2501, 0.2498, 0.2497], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,457][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.2500, 0.2502, 0.2500, 0.2498], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,458][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.2502, 0.2500, 0.2499, 0.2500], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,460][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.2501, 0.2501, 0.2499, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,462][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.2501, 0.2501, 0.2500, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,464][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.2500, 0.2500, 0.2501, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,465][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.2499, 0.2501, 0.2501, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,467][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.2501, 0.2499, 0.2503, 0.2498], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,469][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.2499, 0.2498, 0.2501, 0.2502], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,470][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.2500, 0.2500, 0.2500, 0.2500], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,473][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.2500, 0.2501, 0.2500, 0.2499], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,474][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.2003, 0.2001, 0.1999, 0.1998, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,476][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.2003, 0.2001, 0.1999, 0.1997, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,478][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.2000, 0.2001, 0.2000, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,480][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.2001, 0.2000, 0.1999, 0.2000, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,482][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.2001, 0.2001, 0.1999, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,484][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.2001, 0.2001, 0.2000, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,486][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.2000, 0.2000, 0.2001, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,487][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.1999, 0.2001, 0.2001, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,490][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.2001, 0.1999, 0.2003, 0.1998, 0.1999], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,492][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.1999, 0.1998, 0.2000, 0.2001, 0.2001], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,493][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.2000, 0.2000, 0.2000, 0.2000, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,495][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.2000, 0.2001, 0.2000, 0.1999, 0.2000], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,497][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.1669, 0.1667, 0.1666, 0.1665, 0.1667, 0.1666], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,499][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.1669, 0.1668, 0.1666, 0.1665, 0.1667, 0.1666], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,501][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.1667, 0.1668, 0.1667, 0.1666, 0.1667, 0.1665], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,503][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.1668, 0.1667, 0.1666, 0.1666, 0.1667, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,504][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.1667, 0.1667, 0.1666, 0.1666, 0.1666, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,507][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.1667, 0.1667, 0.1666, 0.1666, 0.1666, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,508][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.1667, 0.1667, 0.1667, 0.1666, 0.1666, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,510][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.1665, 0.1667, 0.1667, 0.1666, 0.1667, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,512][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.1668, 0.1666, 0.1669, 0.1666, 0.1666, 0.1664], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,514][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.1665, 0.1664, 0.1666, 0.1667, 0.1667, 0.1672], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,516][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1666], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,516][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.1667, 0.1667, 0.1667, 0.1666, 0.1667, 0.1667], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,517][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.1431, 0.1429, 0.1428, 0.1427, 0.1429, 0.1428, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,518][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.1431, 0.1430, 0.1428, 0.1427, 0.1429, 0.1428, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,519][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.1429, 0.1430, 0.1429, 0.1428, 0.1429, 0.1428, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,520][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.1429, 0.1429, 0.1428, 0.1428, 0.1429, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,522][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.1429, 0.1429, 0.1428, 0.1428, 0.1428, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,523][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1429, 0.1429, 0.1428, 0.1428, 0.1428, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,525][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.1429, 0.1429, 0.1429, 0.1428, 0.1428, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,526][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.1428, 0.1429, 0.1429, 0.1428, 0.1429, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,529][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.1429, 0.1428, 0.1430, 0.1427, 0.1428, 0.1426, 0.1431],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,530][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.1427, 0.1427, 0.1429, 0.1429, 0.1429, 0.1433, 0.1425],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,532][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.1428, 0.1429, 0.1429, 0.1428, 0.1429, 0.1428, 0.1429],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,534][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.1429, 0.1429, 0.1428, 0.1428, 0.1429, 0.1429, 0.1428],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,536][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.1252, 0.1250, 0.1249, 0.1248, 0.1250, 0.1250, 0.1249, 0.1252],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,538][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.1252, 0.1251, 0.1249, 0.1248, 0.1250, 0.1249, 0.1249, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,540][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.1250, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1250, 0.1250],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,542][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([0.1251, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,544][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,546][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1249, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,547][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,549][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.1249, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,551][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.1251, 0.1249, 0.1251, 0.1249, 0.1249, 0.1248, 0.1252, 0.1252],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,553][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.1249, 0.1249, 0.1250, 0.1251, 0.1250, 0.1254, 0.1247, 0.1250],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,555][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250, 0.1250],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,557][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1250, 0.1250, 0.1251],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,559][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.1113, 0.1111, 0.1110, 0.1110, 0.1111, 0.1111, 0.1110, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,560][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.1113, 0.1112, 0.1110, 0.1110, 0.1111, 0.1110, 0.1110, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,563][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.1111, 0.1112, 0.1111, 0.1111, 0.1111, 0.1110, 0.1111, 0.1112, 0.1111],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,564][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([0.1112, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,566][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.1111, 0.1112, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1112, 0.1111],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,568][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1110, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,570][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,572][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.1110, 0.1111, 0.1111, 0.1110, 0.1111, 0.1111, 0.1111, 0.1112, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,574][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.1111, 0.1110, 0.1112, 0.1110, 0.1110, 0.1109, 0.1113, 0.1113, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,576][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.1110, 0.1110, 0.1111, 0.1112, 0.1112, 0.1115, 0.1109, 0.1111, 0.1110],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,577][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1112],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,578][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.1111, 0.1111, 0.1111, 0.1110, 0.1111, 0.1111, 0.1111, 0.1112, 0.1111],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,581][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:25,583][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 3678],
        [ 6238],
        [10133],
        [ 5730],
        [ 1328],
        [13673],
        [  666],
        [ 5598],
        [   14]], device='cuda:0')
[2024-07-23 21:06:25,585][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 8665],
        [11085],
        [13599],
        [11330],
        [ 2662],
        [17057],
        [ 1622],
        [ 9382],
        [   34]], device='cuda:0')
[2024-07-23 21:06:25,586][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[731],
        [732],
        [730],
        [733],
        [733],
        [732],
        [731],
        [733],
        [734]], device='cuda:0')
[2024-07-23 21:06:25,588][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[732],
        [732],
        [731],
        [729],
        [730],
        [730],
        [731],
        [731],
        [729]], device='cuda:0')
[2024-07-23 21:06:25,589][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[303],
        [303],
        [303],
        [303],
        [303],
        [303],
        [303],
        [303],
        [303]], device='cuda:0')
[2024-07-23 21:06:25,591][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[23],
        [23],
        [23],
        [23],
        [23],
        [23],
        [23],
        [23],
        [23]], device='cuda:0')
[2024-07-23 21:06:25,592][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[11035],
        [11034],
        [11030],
        [11031],
        [11038],
        [11049],
        [11047],
        [11053],
        [11053]], device='cuda:0')
[2024-07-23 21:06:25,594][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[81],
        [81],
        [81],
        [81],
        [81],
        [80],
        [80],
        [79],
        [79]], device='cuda:0')
[2024-07-23 21:06:25,596][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[237],
        [237],
        [240],
        [236],
        [238],
        [236],
        [235],
        [237],
        [237]], device='cuda:0')
[2024-07-23 21:06:25,597][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[2652],
        [2649],
        [2659],
        [2656],
        [2653],
        [2654],
        [2652],
        [2651],
        [2649]], device='cuda:0')
[2024-07-23 21:06:25,599][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[22],
        [22],
        [22],
        [22],
        [22],
        [22],
        [22],
        [22],
        [22]], device='cuda:0')
[2024-07-23 21:06:25,600][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[3],
        [3],
        [3],
        [3],
        [3],
        [3],
        [3],
        [3],
        [3]], device='cuda:0')
[2024-07-23 21:06:25,602][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[3],
        [3],
        [3],
        [3],
        [3],
        [3],
        [3],
        [3],
        [3]], device='cuda:0')
[2024-07-23 21:06:25,604][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[598],
        [597],
        [597],
        [597],
        [596],
        [596],
        [596],
        [596],
        [596]], device='cuda:0')
[2024-07-23 21:06:25,605][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:25,607][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[3577],
        [3583],
        [3573],
        [3572],
        [3573],
        [3579],
        [3575],
        [3575],
        [3576]], device='cuda:0')
[2024-07-23 21:06:25,608][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[854],
        [853],
        [855],
        [855],
        [855],
        [855],
        [854],
        [854],
        [854]], device='cuda:0')
[2024-07-23 21:06:25,610][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:25,611][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[48],
        [48],
        [48],
        [48],
        [48],
        [48],
        [48],
        [48],
        [48]], device='cuda:0')
[2024-07-23 21:06:25,613][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[101],
        [102],
        [102],
        [102],
        [102],
        [102],
        [102],
        [102],
        [102]], device='cuda:0')
[2024-07-23 21:06:25,615][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[1350],
        [1350],
        [1347],
        [1349],
        [1348],
        [1345],
        [1344],
        [1344],
        [1344]], device='cuda:0')
[2024-07-23 21:06:25,616][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[8],
        [8],
        [8],
        [8],
        [8],
        [8],
        [8],
        [8],
        [8]], device='cuda:0')
[2024-07-23 21:06:25,618][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[5],
        [5],
        [5],
        [5],
        [5],
        [5],
        [5],
        [5],
        [5]], device='cuda:0')
[2024-07-23 21:06:25,619][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[51],
        [51],
        [51],
        [51],
        [51],
        [51],
        [51],
        [51],
        [51]], device='cuda:0')
[2024-07-23 21:06:25,621][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:25,622][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:25,624][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[63],
        [63],
        [63],
        [63],
        [63],
        [62],
        [62],
        [62],
        [62]], device='cuda:0')
[2024-07-23 21:06:25,625][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[1333],
        [1333],
        [1332],
        [1332],
        [1333],
        [1332],
        [1333],
        [1333],
        [1332]], device='cuda:0')
[2024-07-23 21:06:25,627][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[288],
        [286],
        [284],
        [284],
        [289],
        [290],
        [291],
        [291],
        [287]], device='cuda:0')
[2024-07-23 21:06:25,629][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[2],
        [2],
        [2],
        [2],
        [2],
        [2],
        [2],
        [2],
        [2]], device='cuda:0')
[2024-07-23 21:06:25,664][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:25,666][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,666][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,667][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,668][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,668][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,669][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,670][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,670][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,671][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,672][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,673][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,673][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,675][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.6719, 0.3281], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,677][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.9046, 0.0954], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,679][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.0200, 0.9800], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,681][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.1863, 0.8137], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,682][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.0183, 0.9817], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,684][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.0507, 0.9493], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,686][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.5237, 0.4763], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,688][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.3876, 0.6124], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,690][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.0880, 0.9120], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,692][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.0374, 0.9626], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,694][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.4304, 0.5696], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,696][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.0571, 0.9429], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,698][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.1425, 0.3398, 0.5177], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,700][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.2970, 0.3956, 0.3074], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,701][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ j] are: tensor([4.3240e-05, 7.0343e-01, 2.9652e-01], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,703][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.0046, 0.4065, 0.5888], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,705][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.0018, 0.4650, 0.5332], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,706][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.0032, 0.5454, 0.4513], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,708][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.1820, 0.2389, 0.5792], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,710][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.0208, 0.0339, 0.9452], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,712][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.0092, 0.4811, 0.5098], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,714][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.0009, 0.4688, 0.5303], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,716][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.1835, 0.3483, 0.4682], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,718][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.0320, 0.5888, 0.3792], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,719][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.0716, 0.1859, 0.3769, 0.3655], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,721][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.4013, 0.1344, 0.2443, 0.2200], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,723][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token ['] are: tensor([1.9715e-06, 1.4160e-02, 5.2186e-01, 4.6398e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,725][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.0021, 0.0466, 0.4047, 0.5466], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,726][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token ['] are: tensor([4.4496e-04, 2.2690e-01, 2.5313e-01, 5.1953e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,726][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.0008, 0.0449, 0.3123, 0.6420], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,727][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.0705, 0.1328, 0.4617, 0.3350], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,728][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.0040, 0.0034, 0.1133, 0.8794], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,728][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.0024, 0.1455, 0.2075, 0.6445], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,729][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token ['] are: tensor([1.2473e-04, 5.6422e-02, 1.9520e-01, 7.4825e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,730][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.0913, 0.1952, 0.3045, 0.4091], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,732][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.0288, 0.3980, 0.2529, 0.3203], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,734][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.0523, 0.0700, 0.2631, 0.5131, 0.1014], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,736][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.3517, 0.0989, 0.2535, 0.1395, 0.1564], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,737][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ai] are: tensor([5.0364e-07, 5.6658e-03, 6.6048e-02, 6.5044e-01, 2.7784e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,738][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ai] are: tensor([3.7696e-04, 1.6435e-02, 1.0274e-01, 6.1546e-01, 2.6498e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,739][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ai] are: tensor([1.3703e-04, 1.3826e-01, 1.5999e-01, 6.1968e-01, 8.1930e-02],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,741][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ai] are: tensor([1.5867e-04, 1.3045e-02, 4.3538e-02, 7.5332e-01, 1.8994e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,742][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.0542, 0.0815, 0.1981, 0.3587, 0.3076], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,744][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.0024, 0.0018, 0.0511, 0.4310, 0.5137], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,747][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.0009, 0.0314, 0.0346, 0.7427, 0.1904], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,748][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ai] are: tensor([5.2053e-05, 1.0979e-02, 4.6051e-02, 7.9737e-01, 1.4555e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,749][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.0540, 0.1218, 0.1649, 0.2468, 0.4124], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,752][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.0242, 0.3670, 0.1851, 0.2629, 0.1607], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,753][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.0259, 0.0452, 0.1192, 0.2245, 0.2195, 0.3658], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,755][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.1669, 0.1531, 0.1939, 0.1883, 0.1901, 0.1078], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,756][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([4.3570e-08, 1.9989e-05, 4.1310e-04, 2.8979e-02, 4.9703e-02, 9.2088e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,758][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([8.9589e-05, 2.7362e-03, 1.3126e-02, 1.7939e-01, 1.3365e-01, 6.7101e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,759][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([1.7646e-05, 1.3253e-03, 1.1773e-02, 3.8091e-02, 2.3299e-01, 7.1580e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,760][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([3.8309e-05, 1.5428e-03, 6.2725e-03, 9.0402e-02, 1.9346e-01, 7.0828e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,762][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.0370, 0.0381, 0.1090, 0.2835, 0.1870, 0.3455], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,764][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.0007, 0.0010, 0.0236, 0.1883, 0.2200, 0.5665], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,765][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([1.8563e-04, 6.0741e-03, 1.7214e-02, 2.1342e-01, 2.9092e-01, 4.7218e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,766][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([5.7094e-06, 1.8621e-03, 9.2633e-03, 1.4239e-01, 2.7401e-01, 5.7247e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,769][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.0388, 0.0633, 0.0975, 0.1803, 0.2212, 0.3989], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,770][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.0161, 0.1940, 0.1187, 0.1558, 0.0817, 0.4337], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,772][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.0137, 0.0175, 0.0580, 0.0535, 0.1127, 0.4342, 0.3104],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,775][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.1637, 0.1468, 0.1377, 0.1334, 0.1035, 0.1410, 0.1739],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,776][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ is] are: tensor([1.2415e-08, 1.7634e-06, 1.0938e-04, 1.8622e-03, 4.8928e-03, 6.7242e-01,
        3.2071e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,777][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ is] are: tensor([4.9895e-05, 1.2806e-03, 5.5846e-03, 3.7656e-02, 2.5210e-02, 5.4486e-01,
        3.8536e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,778][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ is] are: tensor([1.4790e-05, 3.4462e-04, 3.3997e-03, 8.3233e-03, 1.7424e-02, 8.0909e-01,
        1.6141e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,780][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ is] are: tensor([1.7886e-05, 4.0071e-04, 1.4871e-03, 1.7555e-02, 2.1709e-02, 4.1739e-01,
        5.4144e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,782][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.0260, 0.0364, 0.0698, 0.2151, 0.1172, 0.3329, 0.2025],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,783][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ is] are: tensor([4.0846e-04, 3.3327e-04, 1.0369e-02, 7.6142e-02, 8.9584e-02, 2.3997e-01,
        5.8319e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,784][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ is] are: tensor([1.6470e-04, 1.0837e-03, 6.0994e-03, 3.2909e-02, 2.6117e-02, 4.6887e-01,
        4.6476e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,785][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ is] are: tensor([1.8868e-06, 2.7066e-04, 1.4929e-03, 1.9425e-02, 1.8649e-02, 4.8049e-01,
        4.7967e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,788][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.0266, 0.0474, 0.0827, 0.1124, 0.1312, 0.2481, 0.3516],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,789][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.0143, 0.1458, 0.0936, 0.1104, 0.0622, 0.2911, 0.2826],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,790][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.0060, 0.0052, 0.0221, 0.0297, 0.0714, 0.3172, 0.1773, 0.3711],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,791][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.0777, 0.1505, 0.1442, 0.1065, 0.1467, 0.1374, 0.1529, 0.0841],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,792][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ written] are: tensor([7.7566e-10, 1.1910e-07, 7.3010e-06, 1.6759e-04, 2.7640e-04, 4.0703e-02,
        3.8616e-01, 5.7268e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,793][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ written] are: tensor([2.0762e-05, 4.1649e-04, 2.2254e-03, 1.5807e-02, 9.3140e-03, 1.2722e-01,
        1.9561e-01, 6.4939e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,793][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ written] are: tensor([8.8522e-06, 7.6172e-04, 8.3486e-04, 4.4190e-03, 7.5391e-03, 3.4524e-01,
        2.2699e-01, 4.1421e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,794][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ written] are: tensor([2.4149e-06, 7.5333e-05, 2.6012e-04, 3.7688e-03, 5.8422e-03, 7.5728e-02,
        4.2192e-01, 4.9240e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,796][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.0138, 0.0190, 0.0467, 0.0989, 0.0740, 0.1848, 0.2126, 0.3502],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,798][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ written] are: tensor([1.9239e-04, 1.9667e-04, 5.8524e-03, 4.0944e-02, 4.3677e-02, 1.2434e-01,
        3.1331e-01, 4.7149e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,799][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ written] are: tensor([9.4814e-06, 1.4201e-04, 6.4312e-04, 4.5968e-03, 1.9132e-03, 6.7253e-02,
        5.0334e-01, 4.2210e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,800][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ written] are: tensor([6.7012e-07, 1.3729e-04, 3.6557e-04, 7.5641e-03, 6.7815e-03, 2.1818e-01,
        2.7076e-01, 4.9621e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,801][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.0164, 0.0259, 0.0424, 0.0644, 0.0820, 0.1580, 0.2597, 0.3511],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,804][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.0117, 0.1059, 0.0647, 0.0766, 0.0422, 0.2369, 0.2524, 0.2097],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,805][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.0040, 0.0028, 0.0089, 0.0149, 0.0210, 0.0855, 0.0623, 0.2284, 0.5723],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,807][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.2036, 0.1020, 0.0788, 0.0866, 0.0744, 0.0969, 0.1432, 0.0904, 0.1242],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,809][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ in] are: tensor([1.3767e-09, 8.5871e-09, 2.5214e-07, 5.9997e-06, 8.9724e-06, 1.3701e-03,
        9.7919e-03, 3.7419e-01, 6.1463e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,810][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ in] are: tensor([1.2663e-05, 8.4303e-05, 2.3231e-04, 1.2855e-03, 2.1834e-03, 2.8472e-02,
        4.2329e-02, 4.9166e-01, 4.3374e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,811][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ in] are: tensor([3.3465e-06, 4.7511e-05, 2.7139e-04, 6.4124e-04, 5.6714e-04, 2.0242e-02,
        2.5791e-02, 6.5641e-01, 2.9602e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,812][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ in] are: tensor([2.4842e-06, 1.4048e-05, 4.7640e-05, 5.5463e-04, 9.9226e-04, 1.3245e-02,
        9.4299e-02, 1.2039e-01, 7.7046e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,815][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.0123, 0.0096, 0.0233, 0.0555, 0.0409, 0.0834, 0.0985, 0.1691, 0.5074],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,816][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ in] are: tensor([1.1856e-04, 6.7983e-05, 1.6812e-03, 1.2165e-02, 1.4280e-02, 3.4957e-02,
        9.5330e-02, 1.4299e-01, 6.9841e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,817][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ in] are: tensor([1.4431e-05, 2.2720e-05, 9.8096e-05, 1.4432e-03, 5.9307e-04, 5.9816e-03,
        6.8777e-02, 6.5236e-01, 2.7071e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,818][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ in] are: tensor([2.5504e-07, 9.0765e-06, 6.3733e-05, 7.4478e-04, 9.7427e-04, 2.1383e-02,
        5.5447e-02, 2.8004e-01, 6.4134e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,820][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.0119, 0.0217, 0.0284, 0.0432, 0.0527, 0.0909, 0.1442, 0.2071, 0.4000],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,822][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.0138, 0.0970, 0.0526, 0.0586, 0.0383, 0.1689, 0.1854, 0.1924, 0.1930],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:25,859][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:25,860][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,861][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,861][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,863][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,864][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,865][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,867][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,868][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,869][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,870][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,872][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,873][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:25,875][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.6719, 0.3281], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,877][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.9046, 0.0954], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,879][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.0200, 0.9800], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,881][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.1863, 0.8137], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,882][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.0183, 0.9817], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,884][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.0507, 0.9493], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,886][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.5237, 0.4763], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,888][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.3876, 0.6124], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,890][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.0880, 0.9120], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,892][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.0374, 0.9626], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,893][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.4304, 0.5696], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,895][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.0571, 0.9429], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:25,897][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.1425, 0.3398, 0.5177], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,899][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.2970, 0.3956, 0.3074], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,900][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([4.3240e-05, 7.0343e-01, 2.9652e-01], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,902][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.0046, 0.4065, 0.5888], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,904][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.0018, 0.4650, 0.5332], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,906][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.0032, 0.5454, 0.4513], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,908][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.1820, 0.2389, 0.5792], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,910][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.0208, 0.0339, 0.9452], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,911][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.0092, 0.4811, 0.5098], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,913][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.0009, 0.4688, 0.5303], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,915][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.1835, 0.3483, 0.4682], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,917][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.0320, 0.5888, 0.3792], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:25,919][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.0716, 0.1859, 0.3769, 0.3655], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,921][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.4013, 0.1344, 0.2443, 0.2200], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,922][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([1.9715e-06, 1.4160e-02, 5.2186e-01, 4.6398e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,924][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.0021, 0.0466, 0.4047, 0.5466], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,925][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([4.4496e-04, 2.2690e-01, 2.5313e-01, 5.1953e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,925][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.0008, 0.0449, 0.3123, 0.6420], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,926][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.0705, 0.1328, 0.4617, 0.3350], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,927][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.0040, 0.0034, 0.1133, 0.8794], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,928][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.0024, 0.1455, 0.2075, 0.6445], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,929][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([1.2473e-04, 5.6422e-02, 1.9520e-01, 7.4825e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,931][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.0913, 0.1952, 0.3045, 0.4091], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,933][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.0288, 0.3980, 0.2529, 0.3203], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:25,935][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.0523, 0.0700, 0.2631, 0.5131, 0.1014], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,937][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.3517, 0.0989, 0.2535, 0.1395, 0.1564], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,938][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([5.0364e-07, 5.6658e-03, 6.6048e-02, 6.5044e-01, 2.7784e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,939][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([3.7696e-04, 1.6435e-02, 1.0274e-01, 6.1546e-01, 2.6498e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,940][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([1.3703e-04, 1.3826e-01, 1.5999e-01, 6.1968e-01, 8.1930e-02],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,941][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([1.5867e-04, 1.3045e-02, 4.3538e-02, 7.5332e-01, 1.8994e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,943][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.0542, 0.0815, 0.1981, 0.3587, 0.3076], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,945][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.0024, 0.0018, 0.0511, 0.4310, 0.5137], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,947][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.0009, 0.0314, 0.0346, 0.7427, 0.1904], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,948][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([5.2053e-05, 1.0979e-02, 4.6051e-02, 7.9737e-01, 1.4555e-01],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,950][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.0540, 0.1218, 0.1649, 0.2468, 0.4124], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,952][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.0242, 0.3670, 0.1851, 0.2629, 0.1607], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:25,954][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.0259, 0.0452, 0.1192, 0.2245, 0.2195, 0.3658], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,956][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.1669, 0.1531, 0.1939, 0.1883, 0.1901, 0.1078], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,957][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([4.3570e-08, 1.9989e-05, 4.1310e-04, 2.8979e-02, 4.9703e-02, 9.2088e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,958][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([8.9589e-05, 2.7362e-03, 1.3126e-02, 1.7939e-01, 1.3365e-01, 6.7101e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,960][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([1.7646e-05, 1.3253e-03, 1.1773e-02, 3.8091e-02, 2.3299e-01, 7.1580e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,961][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([3.8309e-05, 1.5428e-03, 6.2725e-03, 9.0402e-02, 1.9346e-01, 7.0828e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,963][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.0370, 0.0381, 0.1090, 0.2835, 0.1870, 0.3455], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,965][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.0007, 0.0010, 0.0236, 0.1883, 0.2200, 0.5665], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,966][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([1.8563e-04, 6.0741e-03, 1.7214e-02, 2.1342e-01, 2.9092e-01, 4.7218e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,967][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([5.7094e-06, 1.8621e-03, 9.2633e-03, 1.4239e-01, 2.7401e-01, 5.7247e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,969][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.0388, 0.0633, 0.0975, 0.1803, 0.2212, 0.3989], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,970][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.0161, 0.1940, 0.1187, 0.1558, 0.0817, 0.4337], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:25,973][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.0137, 0.0175, 0.0580, 0.0535, 0.1127, 0.4342, 0.3104],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,974][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.1637, 0.1468, 0.1377, 0.1334, 0.1035, 0.1410, 0.1739],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,976][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([1.2415e-08, 1.7634e-06, 1.0938e-04, 1.8622e-03, 4.8928e-03, 6.7242e-01,
        3.2071e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,977][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([4.9895e-05, 1.2806e-03, 5.5846e-03, 3.7656e-02, 2.5210e-02, 5.4486e-01,
        3.8536e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,979][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([1.4790e-05, 3.4462e-04, 3.3997e-03, 8.3233e-03, 1.7424e-02, 8.0909e-01,
        1.6141e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,980][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([1.7886e-05, 4.0071e-04, 1.4871e-03, 1.7555e-02, 2.1709e-02, 4.1739e-01,
        5.4144e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,981][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.0260, 0.0364, 0.0698, 0.2151, 0.1172, 0.3329, 0.2025],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,983][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([4.0846e-04, 3.3327e-04, 1.0369e-02, 7.6142e-02, 8.9584e-02, 2.3997e-01,
        5.8319e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,984][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([1.6470e-04, 1.0837e-03, 6.0994e-03, 3.2909e-02, 2.6117e-02, 4.6887e-01,
        4.6476e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,985][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([1.8868e-06, 2.7066e-04, 1.4929e-03, 1.9425e-02, 1.8649e-02, 4.8049e-01,
        4.7967e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,987][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.0266, 0.0474, 0.0827, 0.1124, 0.1312, 0.2481, 0.3516],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,988][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.0143, 0.1458, 0.0936, 0.1104, 0.0622, 0.2911, 0.2826],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:25,989][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.0060, 0.0052, 0.0221, 0.0297, 0.0714, 0.3172, 0.1773, 0.3711],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,990][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.0777, 0.1505, 0.1442, 0.1065, 0.1467, 0.1374, 0.1529, 0.0841],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,991][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([7.7566e-10, 1.1910e-07, 7.3010e-06, 1.6759e-04, 2.7640e-04, 4.0703e-02,
        3.8616e-01, 5.7268e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,991][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([2.0762e-05, 4.1649e-04, 2.2254e-03, 1.5807e-02, 9.3140e-03, 1.2722e-01,
        1.9561e-01, 6.4939e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,992][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([8.8522e-06, 7.6172e-04, 8.3486e-04, 4.4190e-03, 7.5391e-03, 3.4524e-01,
        2.2699e-01, 4.1421e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,994][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([2.4149e-06, 7.5333e-05, 2.6012e-04, 3.7688e-03, 5.8422e-03, 7.5728e-02,
        4.2192e-01, 4.9240e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,996][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.0138, 0.0190, 0.0467, 0.0989, 0.0740, 0.1848, 0.2126, 0.3502],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,997][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([1.9239e-04, 1.9667e-04, 5.8524e-03, 4.0944e-02, 4.3677e-02, 1.2434e-01,
        3.1331e-01, 4.7149e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,998][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([9.4814e-06, 1.4201e-04, 6.4312e-04, 4.5968e-03, 1.9132e-03, 6.7253e-02,
        5.0334e-01, 4.2210e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:25,999][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([6.7012e-07, 1.3729e-04, 3.6557e-04, 7.5641e-03, 6.7815e-03, 2.1818e-01,
        2.7076e-01, 4.9621e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,002][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.0164, 0.0259, 0.0424, 0.0644, 0.0820, 0.1580, 0.2597, 0.3511],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,003][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.0117, 0.1059, 0.0647, 0.0766, 0.0422, 0.2369, 0.2524, 0.2097],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,005][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.0040, 0.0028, 0.0089, 0.0149, 0.0210, 0.0855, 0.0623, 0.2284, 0.5723],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,008][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.2036, 0.1020, 0.0788, 0.0866, 0.0744, 0.0969, 0.1432, 0.0904, 0.1242],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,009][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([1.3767e-09, 8.5871e-09, 2.5214e-07, 5.9997e-06, 8.9724e-06, 1.3701e-03,
        9.7919e-03, 3.7419e-01, 6.1463e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,010][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([1.2663e-05, 8.4303e-05, 2.3231e-04, 1.2855e-03, 2.1834e-03, 2.8472e-02,
        4.2329e-02, 4.9166e-01, 4.3374e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,011][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([3.3465e-06, 4.7511e-05, 2.7139e-04, 6.4124e-04, 5.6714e-04, 2.0242e-02,
        2.5791e-02, 6.5641e-01, 2.9602e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,012][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([2.4842e-06, 1.4048e-05, 4.7640e-05, 5.5463e-04, 9.9226e-04, 1.3245e-02,
        9.4299e-02, 1.2039e-01, 7.7046e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,014][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.0123, 0.0096, 0.0233, 0.0555, 0.0409, 0.0834, 0.0985, 0.1691, 0.5074],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,016][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([1.1856e-04, 6.7983e-05, 1.6812e-03, 1.2165e-02, 1.4280e-02, 3.4957e-02,
        9.5330e-02, 1.4299e-01, 6.9841e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,017][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([1.4431e-05, 2.2720e-05, 9.8096e-05, 1.4432e-03, 5.9307e-04, 5.9816e-03,
        6.8777e-02, 6.5236e-01, 2.7071e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,018][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([2.5504e-07, 9.0765e-06, 6.3733e-05, 7.4478e-04, 9.7427e-04, 2.1383e-02,
        5.5447e-02, 2.8004e-01, 6.4134e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,020][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.0119, 0.0217, 0.0284, 0.0432, 0.0527, 0.0909, 0.1442, 0.2071, 0.4000],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,022][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.0138, 0.0970, 0.0526, 0.0586, 0.0383, 0.1689, 0.1854, 0.1924, 0.1930],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,026][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:26,027][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[1929],
        [ 504],
        [2405],
        [  43],
        [  52],
        [4644],
        [  13],
        [ 148],
        [   1]], device='cuda:0')
[2024-07-23 21:06:26,029][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[10211],
        [13148],
        [15121],
        [11513],
        [ 2862],
        [17370],
        [ 1767],
        [10610],
        [   31]], device='cuda:0')
[2024-07-23 21:06:26,031][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[1578],
        [1712],
        [1509],
        [2162],
        [2563],
        [2564],
        [1797],
        [ 665],
        [1813]], device='cuda:0')
[2024-07-23 21:06:26,032][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[3020],
        [2878],
        [3550],
        [2960],
        [3071],
        [3428],
        [3191],
        [3067],
        [2835]], device='cuda:0')
[2024-07-23 21:06:26,034][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[2187],
        [7877],
        [9918],
        [6920],
        [1691],
        [2794],
        [2151],
        [1535],
        [ 903]], device='cuda:0')
[2024-07-23 21:06:26,036][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[24000],
        [16124],
        [ 4390],
        [ 7109],
        [16022],
        [ 9256],
        [13165],
        [13073],
        [10233]], device='cuda:0')
[2024-07-23 21:06:26,037][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[3723],
        [3478],
        [3725],
        [2544],
        [2793],
        [5973],
        [4792],
        [2900],
        [1828]], device='cuda:0')
[2024-07-23 21:06:26,039][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[ 302],
        [2262],
        [1863],
        [ 735],
        [1342],
        [ 829],
        [ 395],
        [1656],
        [ 963]], device='cuda:0')
[2024-07-23 21:06:26,040][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[ 185],
        [ 463],
        [3255],
        [1793],
        [2616],
        [2876],
        [4105],
        [4299],
        [6380]], device='cuda:0')
[2024-07-23 21:06:26,042][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[2041],
        [2724],
        [3791],
        [2272],
        [3455],
        [3797],
        [5399],
        [4862],
        [4987]], device='cuda:0')
[2024-07-23 21:06:26,044][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[2898],
        [ 451],
        [3910],
        [5931],
        [4114],
        [3460],
        [2472],
        [2138],
        [4663]], device='cuda:0')
[2024-07-23 21:06:26,045][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[195],
        [408],
        [207],
        [435],
        [398],
        [268],
        [530],
        [503],
        [660]], device='cuda:0')
[2024-07-23 21:06:26,047][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[589],
        [314],
        [ 78],
        [ 45],
        [ 42],
        [ 31],
        [ 36],
        [ 28],
        [ 25]], device='cuda:0')
[2024-07-23 21:06:26,048][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[1542],
        [3985],
        [3681],
        [3493],
        [3794],
        [4809],
        [4800],
        [5071],
        [4821]], device='cuda:0')
[2024-07-23 21:06:26,050][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[14],
        [ 2],
        [ 1],
        [ 4],
        [ 2],
        [ 1],
        [ 1],
        [ 1],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:26,051][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[17],
        [37],
        [17],
        [14],
        [15],
        [13],
        [12],
        [ 6],
        [ 8]], device='cuda:0')
[2024-07-23 21:06:26,053][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:26,054][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[ 11],
        [  2],
        [  3],
        [410],
        [  2],
        [  1],
        [  2],
        [  3],
        [ 10]], device='cuda:0')
[2024-07-23 21:06:26,055][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[329],
        [216],
        [295],
        [154],
        [124],
        [408],
        [131],
        [ 91],
        [270]], device='cuda:0')
[2024-07-23 21:06:26,056][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 9],
        [ 2],
        [19],
        [ 6],
        [ 3],
        [13],
        [11],
        [10],
        [ 2]], device='cuda:0')
[2024-07-23 21:06:26,057][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[  5],
        [101],
        [ 53],
        [  5],
        [  3],
        [ 75],
        [ 10],
        [  6],
        [  1]], device='cuda:0')
[2024-07-23 21:06:26,059][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[  9],
        [287],
        [ 52],
        [ 10],
        [  3],
        [  6],
        [  5],
        [ 44],
        [163]], device='cuda:0')
[2024-07-23 21:06:26,060][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[8],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [3]], device='cuda:0')
[2024-07-23 21:06:26,062][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[ 25],
        [ 25],
        [ 12],
        [ 36],
        [ 56],
        [224],
        [ 83],
        [  7],
        [ 10]], device='cuda:0')
[2024-07-23 21:06:26,063][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[2],
        [2],
        [2],
        [3],
        [3],
        [2],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:26,065][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[ 1],
        [ 1],
        [57],
        [ 1],
        [ 1],
        [ 4],
        [ 1],
        [ 1],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:26,066][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[1],
        [2],
        [2],
        [4],
        [3],
        [3],
        [3],
        [3],
        [4]], device='cuda:0')
[2024-07-23 21:06:26,068][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[2],
        [1],
        [1],
        [1],
        [2],
        [1],
        [2],
        [2],
        [5]], device='cuda:0')
[2024-07-23 21:06:26,069][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[ 1740],
        [11816],
        [ 1185],
        [ 3559],
        [  875],
        [ 7719],
        [ 4891],
        [10636],
        [  694]], device='cuda:0')
[2024-07-23 21:06:26,071][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[1702],
        [1702],
        [1702],
        [1702],
        [1702],
        [1702],
        [1702],
        [1702],
        [1702]], device='cuda:0')
[2024-07-23 21:06:26,114][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:26,117][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,119][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,119][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,120][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,121][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,121][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,122][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,124][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,125][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,127][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,128][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,129][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,130][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [me] are: tensor([8.2481e-07, 1.0000e+00], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,132][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.8726, 0.1274], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,134][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.9950, 0.0050], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,136][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,138][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.7562, 0.2438], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,139][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.7564, 0.2436], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,141][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.9620, 0.0380], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,143][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.9962, 0.0038], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,145][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.9702, 0.0298], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,146][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.9405, 0.0595], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,149][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.8003, 0.1997], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,150][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.9815, 0.0185], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,152][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ j] are: tensor([4.0327e-04, 4.7064e-05, 9.9955e-01], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,154][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.5629, 0.3909, 0.0462], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,156][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.2043, 0.7933, 0.0024], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,157][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.5045, 0.4932, 0.0023], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,159][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.5758, 0.2253, 0.1989], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,161][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.2758, 0.6494, 0.0747], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,163][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.5071, 0.4657, 0.0271], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,164][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.6223, 0.3756, 0.0021], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,167][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.6441, 0.3543, 0.0017], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,168][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.5509, 0.4417, 0.0075], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,170][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.5055, 0.3356, 0.1589], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,172][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.7476, 0.2050, 0.0474], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,173][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token ['] are: tensor([1.2340e-04, 8.9743e-05, 1.8878e-04, 9.9960e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,175][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.4163, 0.2247, 0.2535, 0.1055], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,177][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.7319, 0.2317, 0.0352, 0.0013], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,179][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.9629, 0.0217, 0.0139, 0.0014], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,180][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.0538, 0.1303, 0.4411, 0.3749], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,182][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.4833, 0.1903, 0.2155, 0.1109], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,183][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.8251, 0.0570, 0.0471, 0.0709], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,183][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.9125, 0.0342, 0.0463, 0.0070], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,184][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.8558, 0.0843, 0.0532, 0.0068], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,185][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.5979, 0.2803, 0.0925, 0.0294], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,186][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.3324, 0.0788, 0.0330, 0.5557], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,187][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.8132, 0.0518, 0.0183, 0.1167], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,188][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ai] are: tensor([1.6983e-07, 1.5020e-06, 2.3396e-06, 5.4126e-07, 1.0000e+00],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,190][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.4270, 0.0192, 0.0496, 0.4001, 0.1041], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,192][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.5904, 0.0302, 0.0094, 0.2814, 0.0887], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,194][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.9403, 0.0111, 0.0050, 0.0344, 0.0092], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,196][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.2568, 0.5151, 0.0482, 0.1726, 0.0073], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,197][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.3545, 0.2108, 0.1083, 0.1682, 0.1582], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,199][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.5014, 0.0370, 0.1114, 0.1425, 0.2077], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,201][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.8640, 0.0065, 0.0148, 0.0963, 0.0184], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,203][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.7366, 0.0807, 0.0153, 0.1353, 0.0322], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,205][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.7524, 0.1443, 0.0019, 0.0347, 0.0667], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,207][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.5747, 0.0470, 0.0296, 0.1293, 0.2195], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,209][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.6546, 0.0152, 0.0569, 0.2210, 0.0523], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,210][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([5.0394e-06, 2.1461e-05, 1.5951e-08, 3.5795e-05, 6.6267e-06, 9.9993e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,211][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.4937, 0.0469, 0.0435, 0.1292, 0.2612, 0.0256], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,214][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.2424, 0.0082, 0.0098, 0.2997, 0.4243, 0.0156], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,215][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.2573, 0.0098, 0.0051, 0.0056, 0.6811, 0.0410], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,217][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.3150, 0.2291, 0.0967, 0.0152, 0.3178, 0.0263], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,219][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.3337, 0.1826, 0.0753, 0.1280, 0.2315, 0.0489], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,221][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.2810, 0.0158, 0.0411, 0.0216, 0.5261, 0.1144], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,223][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.0685, 0.0028, 0.0012, 0.0182, 0.9047, 0.0046], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,225][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.4678, 0.0229, 0.0264, 0.0652, 0.4068, 0.0109], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,227][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.1339, 0.0266, 0.0081, 0.0020, 0.8153, 0.0141], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,228][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.3892, 0.0174, 0.0271, 0.1006, 0.0791, 0.3867], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,231][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.6074, 0.0358, 0.0273, 0.0292, 0.2629, 0.0373], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,232][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ is] are: tensor([1.4623e-03, 4.2848e-04, 1.0024e-04, 6.5876e-03, 3.4368e-03, 1.5268e-03,
        9.8646e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,234][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.1771, 0.0158, 0.0603, 0.3219, 0.3443, 0.0653, 0.0153],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,235][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ is] are: tensor([1.0804e-01, 1.9960e-02, 2.1729e-02, 1.1215e-01, 1.3759e-01, 6.0047e-01,
        6.7616e-05], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,237][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ is] are: tensor([1.2699e-01, 8.4392e-04, 7.9129e-04, 9.5973e-03, 2.0407e-01, 6.5744e-01,
        2.6138e-04], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,239][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.0897, 0.0751, 0.0133, 0.1127, 0.0586, 0.0137, 0.6368],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,240][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.2510, 0.2749, 0.0787, 0.1225, 0.1359, 0.0760, 0.0610],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,243][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.0530, 0.0043, 0.0248, 0.0125, 0.7201, 0.1839, 0.0014],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,244][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ is] are: tensor([6.5701e-02, 4.2487e-03, 1.0245e-02, 3.0875e-02, 3.7714e-01, 5.1173e-01,
        5.2631e-05], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,245][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ is] are: tensor([1.3321e-01, 3.5423e-02, 1.2434e-02, 1.0936e-01, 3.1038e-01, 3.9892e-01,
        2.8666e-04], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,247][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.0922, 0.0177, 0.0135, 0.0224, 0.5631, 0.2708, 0.0202],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,247][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.1451, 0.0135, 0.0266, 0.2128, 0.0797, 0.2623, 0.2601],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,248][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.1398, 0.0054, 0.0310, 0.1765, 0.1432, 0.4760, 0.0281],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,249][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ written] are: tensor([3.2065e-07, 3.0090e-07, 1.1053e-07, 2.7464e-08, 1.3373e-06, 8.4000e-11,
        3.3514e-06, 9.9999e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,250][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.3950, 0.0276, 0.0511, 0.0237, 0.1008, 0.0829, 0.2979, 0.0211],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,251][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.0951, 0.0051, 0.0026, 0.0395, 0.0496, 0.7615, 0.0319, 0.0148],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,253][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ written] are: tensor([2.4872e-01, 4.1101e-04, 1.2181e-03, 4.2626e-03, 2.2778e-01, 5.1651e-01,
        4.3614e-04, 6.5998e-04], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,255][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.0273, 0.4651, 0.0393, 0.0197, 0.1783, 0.0052, 0.2248, 0.0403],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,256][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.1161, 0.0928, 0.0454, 0.0762, 0.2493, 0.0307, 0.0749, 0.3146],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,258][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.2034, 0.0065, 0.0075, 0.0110, 0.1347, 0.6107, 0.0096, 0.0166],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,260][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.2098, 0.0048, 0.0228, 0.0827, 0.3904, 0.2778, 0.0054, 0.0063],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,261][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ written] are: tensor([1.1887e-01, 3.8659e-04, 1.0119e-02, 2.5328e-02, 2.6921e-02, 8.1235e-01,
        6.0141e-03, 1.0331e-05], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,263][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.2121, 0.0062, 0.0282, 0.0241, 0.0059, 0.0523, 0.6055, 0.0655],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,265][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.2315, 0.0263, 0.0143, 0.0307, 0.0595, 0.0568, 0.0459, 0.5350],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,267][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.1290, 0.0230, 0.0064, 0.0078, 0.0923, 0.6675, 0.0433, 0.0306],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,268][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ in] are: tensor([1.3084e-04, 1.9953e-06, 2.8338e-06, 5.8255e-04, 6.1055e-05, 1.4816e-05,
        4.2898e-05, 3.1718e-05, 9.9913e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,270][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.1164, 0.0233, 0.0227, 0.0524, 0.1872, 0.0306, 0.2407, 0.3162, 0.0105],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,271][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ in] are: tensor([2.2739e-02, 1.2086e-02, 3.9776e-03, 3.3343e-02, 2.1520e-01, 4.9187e-01,
        4.6346e-02, 1.7436e-01, 7.4123e-05], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,272][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ in] are: tensor([4.4279e-03, 7.2910e-04, 5.5599e-04, 1.5901e-03, 2.4824e-02, 2.1076e-02,
        8.6047e-04, 9.4591e-01, 3.0566e-05], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,274][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.0825, 0.0451, 0.0890, 0.0680, 0.0064, 0.0602, 0.6165, 0.0089, 0.0233],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,276][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.1391, 0.0502, 0.0467, 0.0910, 0.1465, 0.0710, 0.0976, 0.3402, 0.0178],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,278][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.1710, 0.0382, 0.0102, 0.0573, 0.3665, 0.2238, 0.0085, 0.1233, 0.0012],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,279][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ in] are: tensor([1.6783e-02, 1.2935e-03, 6.6829e-04, 6.3243e-03, 1.2223e-01, 2.8310e-01,
        4.5854e-04, 5.6882e-01, 3.2118e-04], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,280][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ in] are: tensor([1.4558e-01, 4.2224e-03, 9.5510e-04, 8.3048e-03, 5.0574e-02, 1.9480e-02,
        7.9840e-03, 7.6222e-01, 6.7839e-04], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,282][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ in] are: tensor([1.4269e-02, 9.8345e-04, 3.8328e-04, 1.1791e-03, 1.9738e-02, 1.7530e-02,
        3.2697e-02, 9.1303e-01, 1.9038e-04], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,284][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.0829, 0.0133, 0.0050, 0.0521, 0.0409, 0.0415, 0.0736, 0.0488, 0.6418],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,286][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.0583, 0.0014, 0.0117, 0.0243, 0.0364, 0.0828, 0.0169, 0.7672, 0.0009],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,329][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:26,330][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,332][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,333][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,334][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,335][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,335][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,336][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,337][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,337][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,338][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,339][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,339][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,340][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([8.2481e-07, 1.0000e+00], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,341][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.8726, 0.1274], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,341][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.9950, 0.0050], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,342][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,343][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.7562, 0.2438], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,345][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.7564, 0.2436], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,347][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.9620, 0.0380], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,348][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.9962, 0.0038], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,351][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.9702, 0.0298], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,352][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.9405, 0.0595], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,354][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.8003, 0.1997], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,356][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.9815, 0.0185], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,357][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([4.0327e-04, 4.7064e-05, 9.9955e-01], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,359][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.5629, 0.3909, 0.0462], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,361][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.2043, 0.7933, 0.0024], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,363][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.5045, 0.4932, 0.0023], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,365][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.5758, 0.2253, 0.1989], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,366][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.2758, 0.6494, 0.0747], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,368][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.5071, 0.4657, 0.0271], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,370][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.6223, 0.3756, 0.0021], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,372][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.6441, 0.3543, 0.0017], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,374][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.5509, 0.4417, 0.0075], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,376][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.5055, 0.3356, 0.1589], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,377][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.7476, 0.2050, 0.0474], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,379][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([1.2340e-04, 8.9743e-05, 1.8878e-04, 9.9960e-01], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,381][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.4163, 0.2247, 0.2535, 0.1055], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,382][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.7319, 0.2317, 0.0352, 0.0013], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,384][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.9629, 0.0217, 0.0139, 0.0014], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,385][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.0538, 0.1303, 0.4411, 0.3749], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,386][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.4833, 0.1903, 0.2155, 0.1109], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,386][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.8251, 0.0570, 0.0471, 0.0709], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,387][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.9125, 0.0342, 0.0463, 0.0070], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,388][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.8558, 0.0843, 0.0532, 0.0068], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,390][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.5979, 0.2803, 0.0925, 0.0294], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,392][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.3324, 0.0788, 0.0330, 0.5557], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,394][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.8132, 0.0518, 0.0183, 0.1167], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,395][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([1.6983e-07, 1.5020e-06, 2.3396e-06, 5.4126e-07, 1.0000e+00],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,397][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.4270, 0.0192, 0.0496, 0.4001, 0.1041], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,398][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.5904, 0.0302, 0.0094, 0.2814, 0.0887], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,400][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.9403, 0.0111, 0.0050, 0.0344, 0.0092], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,402][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.2568, 0.5151, 0.0482, 0.1726, 0.0073], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,404][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.3545, 0.2108, 0.1083, 0.1682, 0.1582], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,406][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.5014, 0.0370, 0.1114, 0.1425, 0.2077], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,408][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.8640, 0.0065, 0.0148, 0.0963, 0.0184], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,410][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.7366, 0.0807, 0.0153, 0.1353, 0.0322], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,412][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.7524, 0.1443, 0.0019, 0.0347, 0.0667], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,414][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.5747, 0.0470, 0.0296, 0.1293, 0.2195], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,416][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.6546, 0.0152, 0.0569, 0.2210, 0.0523], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,417][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([5.0394e-06, 2.1461e-05, 1.5951e-08, 3.5795e-05, 6.6267e-06, 9.9993e-01],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,419][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.4937, 0.0469, 0.0435, 0.1292, 0.2612, 0.0256], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,421][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.2424, 0.0082, 0.0098, 0.2997, 0.4243, 0.0156], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,423][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.2573, 0.0098, 0.0051, 0.0056, 0.6811, 0.0410], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,424][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.3150, 0.2291, 0.0967, 0.0152, 0.3178, 0.0263], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,427][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.3337, 0.1826, 0.0753, 0.1280, 0.2315, 0.0489], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,428][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.2810, 0.0158, 0.0411, 0.0216, 0.5261, 0.1144], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,430][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.0685, 0.0028, 0.0012, 0.0182, 0.9047, 0.0046], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,432][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.4678, 0.0229, 0.0264, 0.0652, 0.4068, 0.0109], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,434][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.1339, 0.0266, 0.0081, 0.0020, 0.8153, 0.0141], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,436][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.3892, 0.0174, 0.0271, 0.1006, 0.0791, 0.3867], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,438][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.6074, 0.0358, 0.0273, 0.0292, 0.2629, 0.0373], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,439][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([1.4623e-03, 4.2848e-04, 1.0024e-04, 6.5876e-03, 3.4368e-03, 1.5268e-03,
        9.8646e-01], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,441][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.1771, 0.0158, 0.0603, 0.3219, 0.3443, 0.0653, 0.0153],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,443][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([1.0804e-01, 1.9960e-02, 2.1729e-02, 1.1215e-01, 1.3759e-01, 6.0047e-01,
        6.7616e-05], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,444][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([1.2699e-01, 8.4392e-04, 7.9129e-04, 9.5973e-03, 2.0407e-01, 6.5744e-01,
        2.6138e-04], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,446][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0897, 0.0751, 0.0133, 0.1127, 0.0586, 0.0137, 0.6368],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,447][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.2510, 0.2749, 0.0787, 0.1225, 0.1359, 0.0760, 0.0610],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,448][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.0530, 0.0043, 0.0248, 0.0125, 0.7201, 0.1839, 0.0014],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,449][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([6.5701e-02, 4.2487e-03, 1.0245e-02, 3.0875e-02, 3.7714e-01, 5.1173e-01,
        5.2631e-05], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,450][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([1.3321e-01, 3.5423e-02, 1.2434e-02, 1.0936e-01, 3.1038e-01, 3.9892e-01,
        2.8666e-04], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,450][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.0922, 0.0177, 0.0135, 0.0224, 0.5631, 0.2708, 0.0202],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,451][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.1451, 0.0135, 0.0266, 0.2128, 0.0797, 0.2623, 0.2601],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,453][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.1398, 0.0054, 0.0310, 0.1765, 0.1432, 0.4760, 0.0281],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,455][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([3.2065e-07, 3.0090e-07, 1.1053e-07, 2.7464e-08, 1.3373e-06, 8.4000e-11,
        3.3514e-06, 9.9999e-01], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,456][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.3950, 0.0276, 0.0511, 0.0237, 0.1008, 0.0829, 0.2979, 0.0211],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,458][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.0951, 0.0051, 0.0026, 0.0395, 0.0496, 0.7615, 0.0319, 0.0148],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,459][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([2.4872e-01, 4.1101e-04, 1.2181e-03, 4.2626e-03, 2.2778e-01, 5.1651e-01,
        4.3614e-04, 6.5998e-04], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,461][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.0273, 0.4651, 0.0393, 0.0197, 0.1783, 0.0052, 0.2248, 0.0403],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,463][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.1161, 0.0928, 0.0454, 0.0762, 0.2493, 0.0307, 0.0749, 0.3146],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,465][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.2034, 0.0065, 0.0075, 0.0110, 0.1347, 0.6107, 0.0096, 0.0166],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,467][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.2098, 0.0048, 0.0228, 0.0827, 0.3904, 0.2778, 0.0054, 0.0063],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,468][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([1.1887e-01, 3.8659e-04, 1.0119e-02, 2.5328e-02, 2.6921e-02, 8.1235e-01,
        6.0141e-03, 1.0331e-05], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,470][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.2121, 0.0062, 0.0282, 0.0241, 0.0059, 0.0523, 0.6055, 0.0655],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,471][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.2315, 0.0263, 0.0143, 0.0307, 0.0595, 0.0568, 0.0459, 0.5350],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,474][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.1290, 0.0230, 0.0064, 0.0078, 0.0923, 0.6675, 0.0433, 0.0306],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,475][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([1.3084e-04, 1.9953e-06, 2.8338e-06, 5.8255e-04, 6.1055e-05, 1.4816e-05,
        4.2898e-05, 3.1718e-05, 9.9913e-01], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,476][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.1164, 0.0233, 0.0227, 0.0524, 0.1872, 0.0306, 0.2407, 0.3162, 0.0105],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,478][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([2.2739e-02, 1.2086e-02, 3.9776e-03, 3.3343e-02, 2.1520e-01, 4.9187e-01,
        4.6346e-02, 1.7436e-01, 7.4123e-05], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,480][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([4.4279e-03, 7.2910e-04, 5.5599e-04, 1.5901e-03, 2.4824e-02, 2.1076e-02,
        8.6047e-04, 9.4591e-01, 3.0566e-05], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,481][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.0825, 0.0451, 0.0890, 0.0680, 0.0064, 0.0602, 0.6165, 0.0089, 0.0233],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,483][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.1391, 0.0502, 0.0467, 0.0910, 0.1465, 0.0710, 0.0976, 0.3402, 0.0178],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,485][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.1710, 0.0382, 0.0102, 0.0573, 0.3665, 0.2238, 0.0085, 0.1233, 0.0012],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,487][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([1.6783e-02, 1.2935e-03, 6.6829e-04, 6.3243e-03, 1.2223e-01, 2.8310e-01,
        4.5854e-04, 5.6882e-01, 3.2118e-04], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,488][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([1.4558e-01, 4.2224e-03, 9.5510e-04, 8.3048e-03, 5.0574e-02, 1.9480e-02,
        7.9840e-03, 7.6222e-01, 6.7839e-04], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,489][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([1.4269e-02, 9.8345e-04, 3.8328e-04, 1.1791e-03, 1.9738e-02, 1.7530e-02,
        3.2697e-02, 9.1303e-01, 1.9038e-04], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,491][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.0829, 0.0133, 0.0050, 0.0521, 0.0409, 0.0415, 0.0736, 0.0488, 0.6418],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,493][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.0583, 0.0014, 0.0117, 0.0243, 0.0364, 0.0828, 0.0169, 0.7672, 0.0009],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,497][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:26,499][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[  1],
        [  5],
        [ 49],
        [  2],
        [  1],
        [133],
        [  2],
        [  1],
        [  1]], device='cuda:0')
[2024-07-23 21:06:26,500][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[  1],
        [  7],
        [ 60],
        [  3],
        [  2],
        [219],
        [  2],
        [  3],
        [  1]], device='cuda:0')
[2024-07-23 21:06:26,502][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[5142],
        [1244],
        [1258],
        [ 300],
        [8197],
        [1801],
        [ 675],
        [1619],
        [1975]], device='cuda:0')
[2024-07-23 21:06:26,504][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[2942],
        [2535],
        [1753],
        [1193],
        [2191],
        [2911],
        [2744],
        [2425],
        [3098]], device='cuda:0')
[2024-07-23 21:06:26,505][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[10650],
        [10682],
        [ 9839],
        [11266],
        [ 9135],
        [10759],
        [ 7756],
        [ 6494],
        [ 8846]], device='cuda:0')
[2024-07-23 21:06:26,506][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[1056],
        [1058],
        [1361],
        [1067],
        [1115],
        [4140],
        [9327],
        [7840],
        [2410]], device='cuda:0')
[2024-07-23 21:06:26,508][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[4332],
        [3474],
        [2101],
        [ 710],
        [1859],
        [1594],
        [ 444],
        [1086],
        [ 444]], device='cuda:0')
[2024-07-23 21:06:26,510][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[1368],
        [2114],
        [5293],
        [3505],
        [5701],
        [5508],
        [5605],
        [2026],
        [1555]], device='cuda:0')
[2024-07-23 21:06:26,511][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[1016],
        [1024],
        [1512],
        [ 909],
        [ 953],
        [1358],
        [1621],
        [1141],
        [1230]], device='cuda:0')
[2024-07-23 21:06:26,513][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[195],
        [194],
        [111],
        [187],
        [166],
        [ 60],
        [ 44],
        [ 31],
        [ 75]], device='cuda:0')
[2024-07-23 21:06:26,514][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[5148],
        [4993],
        [3183],
        [5202],
        [4748],
        [6155],
        [6557],
        [6719],
        [1162]], device='cuda:0')
[2024-07-23 21:06:26,515][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[ 1111],
        [ 1028],
        [  702],
        [  716],
        [ 1001],
        [ 4693],
        [ 3615],
        [13422],
        [ 6000]], device='cuda:0')
[2024-07-23 21:06:26,516][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[1603],
        [1606],
        [1410],
        [ 214],
        [ 553],
        [ 942],
        [ 765],
        [4730],
        [1732]], device='cuda:0')
[2024-07-23 21:06:26,517][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[4881],
        [4832],
        [4215],
        [4490],
        [3931],
        [3030],
        [3068],
        [3117],
        [3322]], device='cuda:0')
[2024-07-23 21:06:26,519][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[129],
        [220],
        [ 41],
        [ 15],
        [ 28],
        [ 40],
        [  9],
        [  4],
        [  1]], device='cuda:0')
[2024-07-23 21:06:26,520][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 221],
        [  43],
        [1254],
        [ 233],
        [  56],
        [   1],
        [ 153],
        [   1],
        [ 479]], device='cuda:0')
[2024-07-23 21:06:26,522][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[ 71],
        [118],
        [ 84],
        [124],
        [ 28],
        [ 36],
        [ 25],
        [ 86],
        [ 71]], device='cuda:0')
[2024-07-23 21:06:26,523][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[39],
        [39],
        [55],
        [34],
        [36],
        [20],
        [74],
        [49],
        [58]], device='cuda:0')
[2024-07-23 21:06:26,525][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[133],
        [131],
        [  7],
        [ 97],
        [114],
        [  3],
        [  3],
        [  5],
        [ 86]], device='cuda:0')
[2024-07-23 21:06:26,526][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 2],
        [ 2],
        [ 4],
        [ 2],
        [ 1],
        [ 7],
        [ 5],
        [ 3],
        [10]], device='cuda:0')
[2024-07-23 21:06:26,528][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[ 58],
        [165],
        [527],
        [540],
        [613],
        [660],
        [586],
        [462],
        [464]], device='cuda:0')
[2024-07-23 21:06:26,529][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[1147],
        [1103],
        [ 814],
        [ 732],
        [ 698],
        [ 987],
        [ 941],
        [ 100],
        [ 609]], device='cuda:0')
[2024-07-23 21:06:26,531][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 2],
        [ 2],
        [ 1],
        [ 2],
        [ 2],
        [ 1],
        [ 3],
        [ 1],
        [18]], device='cuda:0')
[2024-07-23 21:06:26,533][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[ 5],
        [ 5],
        [ 6],
        [ 5],
        [ 5],
        [ 1],
        [ 3],
        [ 2],
        [53]], device='cuda:0')
[2024-07-23 21:06:26,534][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[1],
        [2],
        [5],
        [2],
        [3],
        [6],
        [3],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:26,536][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[ 7],
        [ 3],
        [ 1],
        [ 9],
        [ 1],
        [ 1],
        [ 1],
        [ 1],
        [26]], device='cuda:0')
[2024-07-23 21:06:26,537][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[8],
        [8],
        [6],
        [6],
        [5],
        [8],
        [3],
        [3],
        [9]], device='cuda:0')
[2024-07-23 21:06:26,539][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[474],
        [338],
        [286],
        [321],
        [376],
        [248],
        [312],
        [774],
        [442]], device='cuda:0')
[2024-07-23 21:06:26,541][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[ 347],
        [ 167],
        [1879],
        [   3],
        [  13],
        [ 357],
        [  70],
        [ 129],
        [ 570]], device='cuda:0')
[2024-07-23 21:06:26,542][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[5],
        [5],
        [5],
        [5],
        [5],
        [5],
        [5],
        [5],
        [5]], device='cuda:0')
[2024-07-23 21:06:26,595][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:26,597][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,599][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,600][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,602][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,604][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,605][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,606][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,608][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,610][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,611][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,613][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,614][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,616][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.9617, 0.0383], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,618][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.7926, 0.2074], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,620][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.5688, 0.4312], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,622][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.7527, 0.2473], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,624][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.2058, 0.7942], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,626][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.9065, 0.0935], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,628][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.8408, 0.1592], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,630][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.7031, 0.2969], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,632][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.4413, 0.5587], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,634][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.8712, 0.1288], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,636][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.4042, 0.5958], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,637][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [me] are: tensor([9.9985e-01, 1.4547e-04], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,639][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.7331, 0.2521, 0.0148], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,641][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.4114, 0.5522, 0.0364], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,642][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.5049, 0.2726, 0.2225], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,643][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.3170, 0.5500, 0.1330], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,644][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.1411, 0.3348, 0.5240], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,644][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.5056, 0.3685, 0.1259], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,645][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.4465, 0.3999, 0.1536], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,646][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.2669, 0.3586, 0.3745], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,647][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.1463, 0.4624, 0.3912], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,649][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.6703, 0.2863, 0.0434], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,650][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.4557, 0.3357, 0.2086], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,652][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ j] are: tensor([3.7036e-01, 6.2964e-01, 1.7567e-07], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,653][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.7884, 0.0927, 0.0485, 0.0705], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,655][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.2949, 0.4999, 0.1284, 0.0767], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,657][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.3317, 0.2106, 0.2800, 0.1777], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,659][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.3347, 0.3294, 0.2136, 0.1223], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,661][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.0992, 0.1848, 0.1561, 0.5599], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,663][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.2938, 0.4492, 0.1891, 0.0679], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,665][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.3715, 0.2151, 0.2292, 0.1843], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,667][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.1771, 0.1035, 0.0835, 0.6359], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,669][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.1398, 0.3177, 0.1497, 0.3928], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,670][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.5872, 0.2330, 0.0721, 0.1078], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,672][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.4138, 0.2926, 0.1474, 0.1463], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,674][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token ['] are: tensor([1.5188e-01, 8.4737e-01, 7.2329e-04, 2.8994e-05], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,676][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.7620, 0.0355, 0.0284, 0.1192, 0.0549], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,677][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.4307, 0.2105, 0.0531, 0.1406, 0.1650], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,679][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.2596, 0.2029, 0.1773, 0.2056, 0.1547], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,681][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.2965, 0.0965, 0.0824, 0.2649, 0.2597], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,683][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.0469, 0.1428, 0.1316, 0.1725, 0.5063], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,685][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.4762, 0.0781, 0.0866, 0.1771, 0.1821], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,687][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.3366, 0.1651, 0.0889, 0.2114, 0.1979], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,688][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.1448, 0.0763, 0.0734, 0.3803, 0.3253], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,691][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.1001, 0.1681, 0.4145, 0.2192, 0.0981], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,693][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.6149, 0.1261, 0.0587, 0.1278, 0.0726], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,694][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.1604, 0.2694, 0.1815, 0.1196, 0.2690], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,696][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ai] are: tensor([8.8517e-01, 1.7867e-02, 7.0637e-05, 9.4125e-02, 2.7723e-03],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,698][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.4156, 0.0263, 0.0220, 0.1389, 0.3189, 0.0784], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,699][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.3353, 0.1533, 0.0313, 0.1050, 0.2980, 0.0770], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,701][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.1486, 0.0778, 0.2341, 0.0675, 0.3623, 0.1096], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,703][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.1518, 0.1427, 0.0277, 0.1970, 0.3241, 0.1567], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,705][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.0141, 0.0352, 0.0221, 0.1206, 0.2325, 0.5755], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,706][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.5494, 0.1069, 0.0331, 0.0700, 0.1722, 0.0684], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,707][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.2950, 0.1460, 0.0965, 0.1502, 0.2743, 0.0381], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,708][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.1039, 0.0631, 0.1362, 0.2668, 0.2177, 0.2124], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,708][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.0270, 0.1432, 0.2533, 0.0744, 0.4476, 0.0545], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,709][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.4046, 0.1407, 0.0918, 0.0968, 0.1317, 0.1344], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,711][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.4094, 0.3050, 0.0676, 0.0514, 0.0482, 0.1183], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,712][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([7.2542e-06, 2.6461e-03, 2.8970e-07, 7.7110e-04, 9.9658e-01, 1.5479e-09],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,714][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.1077, 0.0176, 0.0278, 0.0808, 0.1206, 0.6384, 0.0071],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,716][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.1906, 0.2681, 0.0121, 0.0641, 0.3250, 0.1346, 0.0055],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,717][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.1873, 0.0985, 0.2085, 0.0846, 0.2190, 0.1472, 0.0549],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,719][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.0769, 0.0724, 0.1015, 0.0945, 0.2874, 0.3519, 0.0154],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,721][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.0712, 0.1112, 0.1340, 0.2206, 0.2371, 0.0683, 0.1577],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,723][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.1933, 0.0600, 0.0795, 0.0895, 0.2249, 0.3408, 0.0120],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,725][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.1790, 0.1179, 0.0827, 0.1158, 0.2645, 0.2143, 0.0258],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,727][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.0619, 0.0530, 0.0659, 0.2164, 0.1637, 0.1177, 0.3214],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,728][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.0669, 0.1304, 0.3348, 0.0776, 0.1733, 0.1100, 0.1069],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,731][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.3586, 0.1386, 0.0732, 0.1549, 0.1391, 0.1000, 0.0356],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,733][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.2824, 0.0973, 0.0893, 0.0442, 0.1523, 0.1862, 0.1484],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,734][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ is] are: tensor([1.6130e-03, 3.6678e-03, 2.5731e-05, 3.2004e-03, 9.4108e-01, 5.0408e-02,
        8.0676e-07], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,736][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.2002, 0.0066, 0.0091, 0.0697, 0.0169, 0.5007, 0.0766, 0.1202],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,738][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.2751, 0.1134, 0.0384, 0.2087, 0.0817, 0.1612, 0.0803, 0.0412],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,740][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.1670, 0.0990, 0.2733, 0.0664, 0.1649, 0.0859, 0.1021, 0.0415],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,742][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ written] are: tensor([0.1382, 0.0857, 0.0590, 0.0992, 0.2940, 0.1929, 0.0228, 0.1082],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,744][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.0317, 0.0284, 0.0401, 0.0809, 0.0535, 0.0326, 0.0213, 0.7116],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,745][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.2489, 0.0454, 0.0237, 0.1576, 0.2311, 0.1120, 0.1206, 0.0606],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,748][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.1936, 0.0448, 0.0661, 0.0668, 0.2757, 0.2628, 0.0795, 0.0107],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,749][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.0537, 0.0358, 0.0279, 0.3123, 0.1382, 0.0281, 0.1741, 0.2299],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,751][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.0242, 0.0506, 0.0840, 0.0936, 0.1675, 0.2012, 0.1760, 0.2029],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,753][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.1342, 0.0956, 0.0446, 0.1195, 0.1728, 0.1535, 0.1634, 0.1165],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,755][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.0688, 0.1195, 0.1260, 0.0332, 0.2010, 0.1669, 0.0973, 0.1873],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,756][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ written] are: tensor([6.8253e-03, 4.8048e-04, 3.7354e-04, 2.4254e-01, 6.9376e-01, 2.3751e-02,
        3.1600e-02, 6.7081e-04], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,758][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ in] are: tensor([7.6402e-02, 7.5776e-03, 2.6702e-03, 1.0629e-02, 6.4179e-02, 1.3799e-01,
        2.2757e-02, 6.7730e-01, 4.9485e-04], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,760][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.1843, 0.1767, 0.0612, 0.0646, 0.1422, 0.1419, 0.0468, 0.1771, 0.0052],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,762][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.2034, 0.0727, 0.1156, 0.0605, 0.1902, 0.0802, 0.0453, 0.1113, 0.1209],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,763][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ in] are: tensor([0.0463, 0.0886, 0.0192, 0.0322, 0.1693, 0.1310, 0.0055, 0.5026, 0.0054],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,766][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.0522, 0.1272, 0.0246, 0.1508, 0.2698, 0.0593, 0.0805, 0.1402, 0.0955],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,768][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.2436, 0.0930, 0.0454, 0.0946, 0.2288, 0.1175, 0.0417, 0.1282, 0.0072],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,769][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.1879, 0.0704, 0.0481, 0.0873, 0.1992, 0.1845, 0.0417, 0.1626, 0.0183],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,770][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.0733, 0.0338, 0.0368, 0.0783, 0.1382, 0.0672, 0.0850, 0.2318, 0.2556],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,771][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.0773, 0.0648, 0.1247, 0.0652, 0.0849, 0.0693, 0.1023, 0.2885, 0.1231],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,772][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.1596, 0.0839, 0.0167, 0.0392, 0.0215, 0.0442, 0.0482, 0.5775, 0.0092],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,772][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.2233, 0.1936, 0.0483, 0.0469, 0.0563, 0.0835, 0.1332, 0.0857, 0.1292],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,773][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ in] are: tensor([1.5489e-06, 2.9589e-05, 7.8190e-09, 2.8480e-06, 2.3287e-03, 1.7626e-05,
        6.9902e-08, 9.9762e-01, 3.5555e-10], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,827][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:26,828][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,830][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,831][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,833][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,835][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,836][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,838][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,839][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,841][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,842][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,843][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,844][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:26,845][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.9617, 0.0383], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,846][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.7926, 0.2074], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,846][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.5688, 0.4312], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,847][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.7527, 0.2473], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,849][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.2058, 0.7942], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,850][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.9065, 0.0935], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,852][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.8408, 0.1592], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,854][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.7031, 0.2969], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,855][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.4413, 0.5587], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,857][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.8712, 0.1288], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,859][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.4042, 0.5958], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,860][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([9.9985e-01, 1.4547e-04], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:26,862][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.7331, 0.2521, 0.0148], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,864][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.4114, 0.5522, 0.0364], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,866][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.5049, 0.2726, 0.2225], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,867][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.3170, 0.5500, 0.1330], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,869][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.1411, 0.3348, 0.5240], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,871][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.5056, 0.3685, 0.1259], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,873][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.4465, 0.3999, 0.1536], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,875][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.2669, 0.3586, 0.3745], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,877][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.1463, 0.4624, 0.3912], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,878][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.6703, 0.2863, 0.0434], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,880][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.4557, 0.3357, 0.2086], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,882][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([3.7036e-01, 6.2964e-01, 1.7567e-07], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:26,883][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.7884, 0.0927, 0.0485, 0.0705], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,885][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.2949, 0.4999, 0.1284, 0.0767], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,887][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.3317, 0.2106, 0.2800, 0.1777], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,889][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.3347, 0.3294, 0.2136, 0.1223], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,890][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.0992, 0.1848, 0.1561, 0.5599], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,893][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.2938, 0.4492, 0.1891, 0.0679], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,895][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.3715, 0.2151, 0.2292, 0.1843], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,896][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.1771, 0.1035, 0.0835, 0.6359], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,898][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.1398, 0.3177, 0.1497, 0.3928], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,900][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.5872, 0.2330, 0.0721, 0.1078], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,902][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.4138, 0.2926, 0.1474, 0.1463], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,903][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([1.5188e-01, 8.4737e-01, 7.2329e-04, 2.8994e-05], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:26,905][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.7620, 0.0355, 0.0284, 0.1192, 0.0549], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,907][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.4307, 0.2105, 0.0531, 0.1406, 0.1650], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,908][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.2596, 0.2029, 0.1773, 0.2056, 0.1547], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,909][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.2965, 0.0965, 0.0824, 0.2649, 0.2597], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,910][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.0469, 0.1428, 0.1316, 0.1725, 0.5063], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,910][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.4762, 0.0781, 0.0866, 0.1771, 0.1821], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,911][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.3366, 0.1651, 0.0889, 0.2114, 0.1979], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,912][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.1448, 0.0763, 0.0734, 0.3803, 0.3253], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,914][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.1001, 0.1681, 0.4145, 0.2192, 0.0981], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,916][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.6149, 0.1261, 0.0587, 0.1278, 0.0726], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,918][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.1604, 0.2694, 0.1815, 0.1196, 0.2690], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,919][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([8.8517e-01, 1.7867e-02, 7.0637e-05, 9.4125e-02, 2.7723e-03],
       device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:26,920][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.4156, 0.0263, 0.0220, 0.1389, 0.3189, 0.0784], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,922][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.3353, 0.1533, 0.0313, 0.1050, 0.2980, 0.0770], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,923][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.1486, 0.0778, 0.2341, 0.0675, 0.3623, 0.1096], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,925][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.1518, 0.1427, 0.0277, 0.1970, 0.3241, 0.1567], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,927][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.0141, 0.0352, 0.0221, 0.1206, 0.2325, 0.5755], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,929][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.5494, 0.1069, 0.0331, 0.0700, 0.1722, 0.0684], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,931][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.2950, 0.1460, 0.0965, 0.1502, 0.2743, 0.0381], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,933][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.1039, 0.0631, 0.1362, 0.2668, 0.2177, 0.2124], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,935][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.0270, 0.1432, 0.2533, 0.0744, 0.4476, 0.0545], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,937][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.4046, 0.1407, 0.0918, 0.0968, 0.1317, 0.1344], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,939][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.4094, 0.3050, 0.0676, 0.0514, 0.0482, 0.1183], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,941][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([7.2542e-06, 2.6461e-03, 2.8970e-07, 7.7110e-04, 9.9658e-01, 1.5479e-09],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:26,942][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.1077, 0.0176, 0.0278, 0.0808, 0.1206, 0.6384, 0.0071],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,944][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.1906, 0.2681, 0.0121, 0.0641, 0.3250, 0.1346, 0.0055],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,946][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.1873, 0.0985, 0.2085, 0.0846, 0.2190, 0.1472, 0.0549],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,948][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.0769, 0.0724, 0.1015, 0.0945, 0.2874, 0.3519, 0.0154],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,949][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0712, 0.1112, 0.1340, 0.2206, 0.2371, 0.0683, 0.1577],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,952][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1933, 0.0600, 0.0795, 0.0895, 0.2249, 0.3408, 0.0120],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,954][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.1790, 0.1179, 0.0827, 0.1158, 0.2645, 0.2143, 0.0258],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,955][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.0619, 0.0530, 0.0659, 0.2164, 0.1637, 0.1177, 0.3214],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,958][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0669, 0.1304, 0.3348, 0.0776, 0.1733, 0.1100, 0.1069],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,959][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.3586, 0.1386, 0.0732, 0.1549, 0.1391, 0.1000, 0.0356],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,961][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.2824, 0.0973, 0.0893, 0.0442, 0.1523, 0.1862, 0.1484],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,962][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([1.6130e-03, 3.6678e-03, 2.5731e-05, 3.2004e-03, 9.4108e-01, 5.0408e-02,
        8.0676e-07], device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:26,964][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.2002, 0.0066, 0.0091, 0.0697, 0.0169, 0.5007, 0.0766, 0.1202],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,966][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.2751, 0.1134, 0.0384, 0.2087, 0.0817, 0.1612, 0.0803, 0.0412],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,968][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.1670, 0.0990, 0.2733, 0.0664, 0.1649, 0.0859, 0.1021, 0.0415],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,970][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([0.1382, 0.0857, 0.0590, 0.0992, 0.2940, 0.1929, 0.0228, 0.1082],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,972][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.0317, 0.0284, 0.0401, 0.0809, 0.0535, 0.0326, 0.0213, 0.7116],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,973][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.2489, 0.0454, 0.0237, 0.1576, 0.2311, 0.1120, 0.1206, 0.0606],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,974][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.1936, 0.0448, 0.0661, 0.0668, 0.2757, 0.2628, 0.0795, 0.0107],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,974][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.0537, 0.0358, 0.0279, 0.3123, 0.1382, 0.0281, 0.1741, 0.2299],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,975][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.0242, 0.0506, 0.0840, 0.0936, 0.1675, 0.2012, 0.1760, 0.2029],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,976][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.1342, 0.0956, 0.0446, 0.1195, 0.1728, 0.1535, 0.1634, 0.1165],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,977][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.0688, 0.1195, 0.1260, 0.0332, 0.2010, 0.1669, 0.0973, 0.1873],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,979][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([6.8253e-03, 4.8048e-04, 3.7354e-04, 2.4254e-01, 6.9376e-01, 2.3751e-02,
        3.1600e-02, 6.7081e-04], device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:26,980][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([7.6402e-02, 7.5776e-03, 2.6702e-03, 1.0629e-02, 6.4179e-02, 1.3799e-01,
        2.2757e-02, 6.7730e-01, 4.9485e-04], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,982][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.1843, 0.1767, 0.0612, 0.0646, 0.1422, 0.1419, 0.0468, 0.1771, 0.0052],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,983][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.2034, 0.0727, 0.1156, 0.0605, 0.1902, 0.0802, 0.0453, 0.1113, 0.1209],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,985][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([0.0463, 0.0886, 0.0192, 0.0322, 0.1693, 0.1310, 0.0055, 0.5026, 0.0054],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,987][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.0522, 0.1272, 0.0246, 0.1508, 0.2698, 0.0593, 0.0805, 0.1402, 0.0955],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,989][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.2436, 0.0930, 0.0454, 0.0946, 0.2288, 0.1175, 0.0417, 0.1282, 0.0072],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,991][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.1879, 0.0704, 0.0481, 0.0873, 0.1992, 0.1845, 0.0417, 0.1626, 0.0183],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,993][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.0733, 0.0338, 0.0368, 0.0783, 0.1382, 0.0672, 0.0850, 0.2318, 0.2556],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,995][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.0773, 0.0648, 0.1247, 0.0652, 0.0849, 0.0693, 0.1023, 0.2885, 0.1231],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,997][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.1596, 0.0839, 0.0167, 0.0392, 0.0215, 0.0442, 0.0482, 0.5775, 0.0092],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:26,999][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.2233, 0.1936, 0.0483, 0.0469, 0.0563, 0.0835, 0.1332, 0.0857, 0.1292],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,000][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([1.5489e-06, 2.9589e-05, 7.8190e-09, 2.8480e-06, 2.3287e-03, 1.7626e-05,
        6.9902e-08, 9.9762e-01, 3.5555e-10], device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,004][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:27,006][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 1],
        [ 5],
        [14],
        [ 2],
        [ 2],
        [20],
        [ 1],
        [ 1],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:27,007][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 1],
        [ 5],
        [18],
        [ 2],
        [ 2],
        [49],
        [ 1],
        [ 5],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:27,009][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[ 2300],
        [ 2357],
        [ 2717],
        [ 2053],
        [ 2234],
        [ 4960],
        [ 8321],
        [ 8288],
        [12574]], device='cuda:0')
[2024-07-23 21:06:27,011][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[1033],
        [ 609],
        [ 220],
        [ 268],
        [ 592],
        [ 842],
        [ 699],
        [ 719],
        [ 645]], device='cuda:0')
[2024-07-23 21:06:27,012][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[1236],
        [1782],
        [1666],
        [2118],
        [2289],
        [1925],
        [1979],
        [2235],
        [2381]], device='cuda:0')
[2024-07-23 21:06:27,013][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[2462],
        [2373],
        [2373],
        [2758],
        [2249],
        [2281],
        [2761],
        [2155],
        [2224]], device='cuda:0')
[2024-07-23 21:06:27,015][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 500],
        [ 518],
        [1222],
        [ 220],
        [1442],
        [1177],
        [ 422],
        [5766],
        [ 870]], device='cuda:0')
[2024-07-23 21:06:27,017][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[2506],
        [2413],
        [1714],
        [1750],
        [2281],
        [2117],
        [2829],
        [2646],
        [2074]], device='cuda:0')
[2024-07-23 21:06:27,018][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[1685],
        [1721],
        [2031],
        [2441],
        [2767],
        [2906],
        [2985],
        [2729],
        [2345]], device='cuda:0')
[2024-07-23 21:06:27,020][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[6],
        [4],
        [3],
        [5],
        [5],
        [4],
        [4],
        [4],
        [5]], device='cuda:0')
[2024-07-23 21:06:27,022][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[ 6454],
        [10789],
        [16020],
        [15608],
        [16111],
        [12487],
        [14126],
        [10225],
        [ 9778]], device='cuda:0')
[2024-07-23 21:06:27,023][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[1555],
        [1457],
        [1336],
        [1468],
        [1674],
        [1322],
        [1714],
        [2871],
        [4388]], device='cuda:0')
[2024-07-23 21:06:27,025][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[3496],
        [3061],
        [2605],
        [2913],
        [1712],
        [2607],
        [2040],
        [1636],
        [2828]], device='cuda:0')
[2024-07-23 21:06:27,026][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[ 531],
        [ 529],
        [ 837],
        [1186],
        [ 549],
        [1347],
        [1177],
        [1030],
        [3480]], device='cuda:0')
[2024-07-23 21:06:27,028][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 2],
        [14],
        [93],
        [11],
        [ 4],
        [ 9],
        [15],
        [ 1],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:27,030][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[51],
        [54],
        [52],
        [60],
        [50],
        [ 6],
        [ 6],
        [ 2],
        [30]], device='cuda:0')
[2024-07-23 21:06:27,031][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[ 2],
        [ 5],
        [19],
        [30],
        [14],
        [13],
        [13],
        [14],
        [20]], device='cuda:0')
[2024-07-23 21:06:27,033][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[14],
        [ 3],
        [ 4],
        [ 7],
        [10],
        [11],
        [12],
        [11],
        [14]], device='cuda:0')
[2024-07-23 21:06:27,034][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[3],
        [2],
        [1],
        [1],
        [2],
        [1],
        [2],
        [2],
        [2]], device='cuda:0')
[2024-07-23 21:06:27,036][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[360],
        [ 21],
        [  3],
        [ 36],
        [  5],
        [ 94],
        [  5],
        [ 25],
        [  7]], device='cuda:0')
[2024-07-23 21:06:27,038][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[18],
        [15],
        [26],
        [63],
        [53],
        [25],
        [40],
        [60],
        [59]], device='cuda:0')
[2024-07-23 21:06:27,039][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:27,040][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[9661],
        [7316],
        [4951],
        [3671],
        [3473],
        [3417],
        [3367],
        [4115],
        [4923]], device='cuda:0')
[2024-07-23 21:06:27,041][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[1],
        [2],
        [2],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:27,042][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[ 8],
        [16],
        [56],
        [54],
        [34],
        [99],
        [61],
        [13],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:27,044][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[20],
        [ 1],
        [ 1],
        [ 2],
        [ 4],
        [ 8],
        [18],
        [15],
        [21]], device='cuda:0')
[2024-07-23 21:06:27,045][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[4053],
        [4053],
        [ 860],
        [ 588],
        [4087],
        [ 279],
        [ 316],
        [ 668],
        [2457]], device='cuda:0')
[2024-07-23 21:06:27,046][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[13873],
        [16356],
        [19225],
        [19322],
        [19481],
        [22432],
        [22876],
        [25727],
        [19200]], device='cuda:0')
[2024-07-23 21:06:27,048][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[    3],
        [17502],
        [23255],
        [ 2754],
        [16087],
        [24146],
        [19972],
        [33096],
        [26068]], device='cuda:0')
[2024-07-23 21:06:27,049][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[2],
        [2],
        [2],
        [2],
        [2],
        [2],
        [2],
        [2],
        [2]], device='cuda:0')
[2024-07-23 21:06:27,112][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:27,114][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,115][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,117][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,119][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,119][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,120][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,121][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,121][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,122][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,123][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,123][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,124][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,125][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.4865, 0.5135], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,125][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.5495, 0.4505], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,126][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.5850, 0.4150], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,127][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.6473, 0.3527], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,129][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.7278, 0.2722], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,130][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.6973, 0.3027], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,132][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.8458, 0.1542], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,134][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.5998, 0.4002], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,136][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.7062, 0.2938], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,137][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.6745, 0.3255], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,139][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.5005, 0.4995], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,142][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.3638, 0.6362], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,143][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.4182, 0.2850, 0.2968], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,145][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.2986, 0.6406, 0.0608], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,147][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.5635, 0.3617, 0.0748], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,149][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.4807, 0.3366, 0.1828], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,151][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.4804, 0.2746, 0.2450], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,153][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.6074, 0.3623, 0.0303], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,155][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.6363, 0.2974, 0.0663], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,157][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.4709, 0.2541, 0.2750], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,159][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.5415, 0.3774, 0.0810], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,161][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.3813, 0.4049, 0.2138], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,163][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.4983, 0.2101, 0.2916], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,165][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.3267, 0.2937, 0.3796], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,167][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.3012, 0.2540, 0.3138, 0.1310], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,169][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.2520, 0.3911, 0.2658, 0.0911], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,171][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.3661, 0.2504, 0.2040, 0.1795], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,172][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.3975, 0.2704, 0.1871, 0.1449], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,174][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.3520, 0.2394, 0.2657, 0.1429], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,176][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.2402, 0.2633, 0.3455, 0.1510], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,178][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.5079, 0.2546, 0.1379, 0.0996], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,179][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.3079, 0.3362, 0.1468, 0.2091], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,180][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.3926, 0.2010, 0.2646, 0.1418], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,181][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.2606, 0.2675, 0.2910, 0.1808], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,182][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.3731, 0.2376, 0.2182, 0.1711], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,182][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.2671, 0.1778, 0.1530, 0.4022], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,183][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.2101, 0.1554, 0.2261, 0.2591, 0.1494], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,185][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.3388, 0.2571, 0.2019, 0.1585, 0.0438], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,187][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.3094, 0.2286, 0.1560, 0.1710, 0.1350], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,189][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.3044, 0.1828, 0.1993, 0.1657, 0.1479], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,191][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.3403, 0.1484, 0.1387, 0.1682, 0.2043], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,193][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.3737, 0.2189, 0.1832, 0.1556, 0.0686], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,194][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.3508, 0.1317, 0.0739, 0.2322, 0.2114], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,196][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.2933, 0.1991, 0.1057, 0.1844, 0.2175], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,198][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.3962, 0.1391, 0.1981, 0.1807, 0.0859], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,200][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.1940, 0.2317, 0.2566, 0.1861, 0.1316], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,201][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.2546, 0.1321, 0.1674, 0.1070, 0.3390], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,203][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.2158, 0.1913, 0.2093, 0.1895, 0.1941], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,205][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.1921, 0.1574, 0.1753, 0.2602, 0.0849, 0.1301], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,207][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.2140, 0.3052, 0.1089, 0.1171, 0.2443, 0.0106], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,209][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.2330, 0.1977, 0.1175, 0.1769, 0.1159, 0.1591], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,211][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.3068, 0.1379, 0.1282, 0.1353, 0.1674, 0.1243], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,213][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.2311, 0.1038, 0.1506, 0.1334, 0.1829, 0.1983], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,215][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.2887, 0.1608, 0.1118, 0.1252, 0.3008, 0.0127], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,217][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.1964, 0.1282, 0.0614, 0.1326, 0.4471, 0.0342], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,219][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.1159, 0.0902, 0.1231, 0.2026, 0.1967, 0.2715], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,221][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.2778, 0.1457, 0.1725, 0.1224, 0.2323, 0.0493], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,223][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.1320, 0.2128, 0.2381, 0.1229, 0.2617, 0.0325], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,224][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.1761, 0.0941, 0.1295, 0.0649, 0.2712, 0.2643], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,227][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.1387, 0.1031, 0.1514, 0.1281, 0.0981, 0.3806], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,228][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.1202, 0.1411, 0.2177, 0.1245, 0.0916, 0.2196, 0.0853],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,230][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.1012, 0.1362, 0.1915, 0.1216, 0.1623, 0.2096, 0.0775],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,232][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.1866, 0.1585, 0.0938, 0.1058, 0.1331, 0.2381, 0.0843],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,234][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.2232, 0.1488, 0.1071, 0.1239, 0.1746, 0.1323, 0.0900],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,236][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.1436, 0.0853, 0.1168, 0.0987, 0.1171, 0.3844, 0.0542],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,238][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.1346, 0.1028, 0.0964, 0.1706, 0.2682, 0.1609, 0.0664],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,240][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.2131, 0.0873, 0.1070, 0.1365, 0.2654, 0.1414, 0.0493],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,242][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.2079, 0.1452, 0.0657, 0.1244, 0.1748, 0.1813, 0.1008],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,244][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.1669, 0.0805, 0.1644, 0.1093, 0.1279, 0.3034, 0.0476],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,246][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.1663, 0.1764, 0.1422, 0.1208, 0.1645, 0.1000, 0.1298],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,247][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.2364, 0.0925, 0.1097, 0.0969, 0.2236, 0.1265, 0.1144],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,248][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.1182, 0.1343, 0.0887, 0.1864, 0.1441, 0.0999, 0.2286],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,249][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.0851, 0.0981, 0.1538, 0.1666, 0.0730, 0.2064, 0.1614, 0.0557],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,250][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.0364, 0.0544, 0.1147, 0.1175, 0.0702, 0.5218, 0.0730, 0.0120],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,251][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.1239, 0.0887, 0.1404, 0.0664, 0.1225, 0.2838, 0.0936, 0.0807],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,251][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ written] are: tensor([0.1877, 0.0954, 0.0904, 0.1179, 0.1197, 0.1197, 0.1190, 0.1502],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,253][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.1897, 0.0884, 0.1190, 0.0764, 0.1151, 0.2850, 0.0768, 0.0496],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,255][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.0341, 0.0494, 0.0842, 0.1416, 0.1259, 0.4829, 0.0656, 0.0164],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,257][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.1853, 0.0504, 0.0739, 0.1024, 0.1670, 0.1807, 0.1144, 0.1258],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,258][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.1583, 0.1263, 0.0842, 0.1313, 0.1023, 0.2218, 0.0777, 0.0980],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,260][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.0877, 0.0517, 0.0929, 0.1139, 0.1019, 0.4482, 0.0674, 0.0363],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,262][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.1483, 0.1535, 0.1421, 0.0913, 0.1744, 0.0788, 0.1386, 0.0729],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,264][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.0989, 0.0713, 0.0812, 0.1061, 0.1139, 0.0675, 0.0930, 0.3681],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,266][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.1065, 0.1211, 0.1054, 0.1434, 0.1288, 0.0841, 0.0961, 0.2146],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,268][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.0978, 0.1034, 0.1464, 0.1087, 0.0912, 0.0974, 0.1417, 0.1462, 0.0672],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,270][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.0641, 0.1535, 0.1856, 0.0862, 0.0962, 0.0587, 0.1557, 0.1700, 0.0302],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,271][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.1344, 0.1287, 0.0532, 0.1011, 0.1202, 0.1417, 0.0798, 0.1843, 0.0566],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,274][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ in] are: tensor([0.1795, 0.1063, 0.0825, 0.0825, 0.1051, 0.1110, 0.0943, 0.1900, 0.0488],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,275][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.1164, 0.0884, 0.1068, 0.0608, 0.1287, 0.2635, 0.0746, 0.1174, 0.0433],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,277][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.0861, 0.0993, 0.1228, 0.1150, 0.1511, 0.0755, 0.1172, 0.1955, 0.0375],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,279][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.1303, 0.1149, 0.0519, 0.0920, 0.2078, 0.0944, 0.0568, 0.2209, 0.0309],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,281][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.1099, 0.0787, 0.0659, 0.0945, 0.0937, 0.2256, 0.0826, 0.1486, 0.1006],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,283][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.1150, 0.0828, 0.1348, 0.0857, 0.1124, 0.2002, 0.1093, 0.1380, 0.0217],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,285][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.0999, 0.1115, 0.1192, 0.0902, 0.1300, 0.0790, 0.1074, 0.1689, 0.0939],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,287][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.1714, 0.0849, 0.0662, 0.0725, 0.1904, 0.0987, 0.0783, 0.1294, 0.1082],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,288][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.1199, 0.0812, 0.0729, 0.1097, 0.0924, 0.0894, 0.0902, 0.0995, 0.2448],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,352][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:27,354][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,355][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,356][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,358][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,358][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,359][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,360][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,360][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,361][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,362][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,362][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,363][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,364][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.4865, 0.5135], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,364][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.5495, 0.4505], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,365][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.5850, 0.4150], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,366][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.6473, 0.3527], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,366][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.7278, 0.2722], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,368][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.6973, 0.3027], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,370][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.8458, 0.1542], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,371][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.5998, 0.4002], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,373][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.7062, 0.2938], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,376][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.6745, 0.3255], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,377][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.5005, 0.4995], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,379][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.3638, 0.6362], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,381][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.4182, 0.2850, 0.2968], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,383][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.2986, 0.6406, 0.0608], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,385][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.5635, 0.3617, 0.0748], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,387][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.4807, 0.3366, 0.1828], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,389][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.4804, 0.2746, 0.2450], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,391][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.6074, 0.3623, 0.0303], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,393][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.6363, 0.2974, 0.0663], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,395][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.4709, 0.2541, 0.2750], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,396][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.5415, 0.3774, 0.0810], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,397][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.3813, 0.4049, 0.2138], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,397][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.4983, 0.2101, 0.2916], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,398][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.3267, 0.2937, 0.3796], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,399][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.3012, 0.2540, 0.3138, 0.1310], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,399][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.2520, 0.3911, 0.2658, 0.0911], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,401][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.3661, 0.2504, 0.2040, 0.1795], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,403][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.3975, 0.2704, 0.1871, 0.1449], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,405][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.3520, 0.2394, 0.2657, 0.1429], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,407][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.2402, 0.2633, 0.3455, 0.1510], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,409][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.5079, 0.2546, 0.1379, 0.0996], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,410][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.3079, 0.3362, 0.1468, 0.2091], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,412][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.3926, 0.2010, 0.2646, 0.1418], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,414][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.2606, 0.2675, 0.2910, 0.1808], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,416][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.3731, 0.2376, 0.2182, 0.1711], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,418][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.2671, 0.1778, 0.1530, 0.4022], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,420][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.2101, 0.1554, 0.2261, 0.2591, 0.1494], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,422][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.3388, 0.2571, 0.2019, 0.1585, 0.0438], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,424][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.3094, 0.2286, 0.1560, 0.1710, 0.1350], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,426][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.3044, 0.1828, 0.1993, 0.1657, 0.1479], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,428][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.3403, 0.1484, 0.1387, 0.1682, 0.2043], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,430][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.3737, 0.2189, 0.1832, 0.1556, 0.0686], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,432][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.3508, 0.1317, 0.0739, 0.2322, 0.2114], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,434][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.2933, 0.1991, 0.1057, 0.1844, 0.2175], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,436][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.3962, 0.1391, 0.1981, 0.1807, 0.0859], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,438][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.1940, 0.2317, 0.2566, 0.1861, 0.1316], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,440][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.2546, 0.1321, 0.1674, 0.1070, 0.3390], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,441][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.2158, 0.1913, 0.2093, 0.1895, 0.1941], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,443][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.1921, 0.1574, 0.1753, 0.2602, 0.0849, 0.1301], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,446][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.2140, 0.3052, 0.1089, 0.1171, 0.2443, 0.0106], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,447][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.2330, 0.1977, 0.1175, 0.1769, 0.1159, 0.1591], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,449][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.3068, 0.1379, 0.1282, 0.1353, 0.1674, 0.1243], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,451][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.2311, 0.1038, 0.1506, 0.1334, 0.1829, 0.1983], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,453][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.2887, 0.1608, 0.1118, 0.1252, 0.3008, 0.0127], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,455][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.1964, 0.1282, 0.0614, 0.1326, 0.4471, 0.0342], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,457][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.1159, 0.0902, 0.1231, 0.2026, 0.1967, 0.2715], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,459][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.2778, 0.1457, 0.1725, 0.1224, 0.2323, 0.0493], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,460][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.1320, 0.2128, 0.2381, 0.1229, 0.2617, 0.0325], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,461][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.1761, 0.0941, 0.1295, 0.0649, 0.2712, 0.2643], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,461][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.1387, 0.1031, 0.1514, 0.1281, 0.0981, 0.3806], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,462][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.1202, 0.1411, 0.2177, 0.1245, 0.0916, 0.2196, 0.0853],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,463][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.1012, 0.1362, 0.1915, 0.1216, 0.1623, 0.2096, 0.0775],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,464][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.1866, 0.1585, 0.0938, 0.1058, 0.1331, 0.2381, 0.0843],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,466][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.2232, 0.1488, 0.1071, 0.1239, 0.1746, 0.1323, 0.0900],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,468][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.1436, 0.0853, 0.1168, 0.0987, 0.1171, 0.3844, 0.0542],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,469][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1346, 0.1028, 0.0964, 0.1706, 0.2682, 0.1609, 0.0664],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,471][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.2131, 0.0873, 0.1070, 0.1365, 0.2654, 0.1414, 0.0493],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,473][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.2079, 0.1452, 0.0657, 0.1244, 0.1748, 0.1813, 0.1008],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,475][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.1669, 0.0805, 0.1644, 0.1093, 0.1279, 0.3034, 0.0476],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,477][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.1663, 0.1764, 0.1422, 0.1208, 0.1645, 0.1000, 0.1298],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,479][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.2364, 0.0925, 0.1097, 0.0969, 0.2236, 0.1265, 0.1144],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,480][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.1182, 0.1343, 0.0887, 0.1864, 0.1441, 0.0999, 0.2286],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,482][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.0851, 0.0981, 0.1538, 0.1666, 0.0730, 0.2064, 0.1614, 0.0557],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,484][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.0364, 0.0544, 0.1147, 0.1175, 0.0702, 0.5218, 0.0730, 0.0120],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,486][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.1239, 0.0887, 0.1404, 0.0664, 0.1225, 0.2838, 0.0936, 0.0807],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,488][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([0.1877, 0.0954, 0.0904, 0.1179, 0.1197, 0.1197, 0.1190, 0.1502],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,490][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.1897, 0.0884, 0.1190, 0.0764, 0.1151, 0.2850, 0.0768, 0.0496],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,492][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.0341, 0.0494, 0.0842, 0.1416, 0.1259, 0.4829, 0.0656, 0.0164],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,494][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.1853, 0.0504, 0.0739, 0.1024, 0.1670, 0.1807, 0.1144, 0.1258],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,496][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.1583, 0.1263, 0.0842, 0.1313, 0.1023, 0.2218, 0.0777, 0.0980],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,498][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.0877, 0.0517, 0.0929, 0.1139, 0.1019, 0.4482, 0.0674, 0.0363],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,499][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.1483, 0.1535, 0.1421, 0.0913, 0.1744, 0.0788, 0.1386, 0.0729],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,501][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.0989, 0.0713, 0.0812, 0.1061, 0.1139, 0.0675, 0.0930, 0.3681],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,503][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.1065, 0.1211, 0.1054, 0.1434, 0.1288, 0.0841, 0.0961, 0.2146],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,505][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.0978, 0.1034, 0.1464, 0.1087, 0.0912, 0.0974, 0.1417, 0.1462, 0.0672],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,507][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.0641, 0.1535, 0.1856, 0.0862, 0.0962, 0.0587, 0.1557, 0.1700, 0.0302],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,509][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.1344, 0.1287, 0.0532, 0.1011, 0.1202, 0.1417, 0.0798, 0.1843, 0.0566],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,511][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([0.1795, 0.1063, 0.0825, 0.0825, 0.1051, 0.1110, 0.0943, 0.1900, 0.0488],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,513][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.1164, 0.0884, 0.1068, 0.0608, 0.1287, 0.2635, 0.0746, 0.1174, 0.0433],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,515][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.0861, 0.0993, 0.1228, 0.1150, 0.1511, 0.0755, 0.1172, 0.1955, 0.0375],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,517][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.1303, 0.1149, 0.0519, 0.0920, 0.2078, 0.0944, 0.0568, 0.2209, 0.0309],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,519][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.1099, 0.0787, 0.0659, 0.0945, 0.0937, 0.2256, 0.0826, 0.1486, 0.1006],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,521][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.1150, 0.0828, 0.1348, 0.0857, 0.1124, 0.2002, 0.1093, 0.1380, 0.0217],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,522][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.0999, 0.1115, 0.1192, 0.0902, 0.1300, 0.0790, 0.1074, 0.1689, 0.0939],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,524][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.1714, 0.0849, 0.0662, 0.0725, 0.1904, 0.0987, 0.0783, 0.1294, 0.1082],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,524][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.1199, 0.0812, 0.0729, 0.1097, 0.0924, 0.0894, 0.0902, 0.0995, 0.2448],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,528][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:27,530][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[3],
        [7],
        [4],
        [2],
        [3],
        [5],
        [2],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:27,531][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 4],
        [13],
        [11],
        [ 4],
        [ 3],
        [10],
        [ 3],
        [ 1],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:27,533][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[8985],
        [3488],
        [3240],
        [2808],
        [2475],
        [3777],
        [3749],
        [3065],
        [2665]], device='cuda:0')
[2024-07-23 21:06:27,534][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[4822],
        [4925],
        [5020],
        [5385],
        [5164],
        [4249],
        [4896],
        [6178],
        [4405]], device='cuda:0')
[2024-07-23 21:06:27,536][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[453],
        [363],
        [338],
        [432],
        [475],
        [572],
        [544],
        [583],
        [609]], device='cuda:0')
[2024-07-23 21:06:27,537][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[4422],
        [2847],
        [2043],
        [2193],
        [2301],
        [2618],
        [2850],
        [3611],
        [3794]], device='cuda:0')
[2024-07-23 21:06:27,539][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[11426],
        [12802],
        [10990],
        [10051],
        [ 9266],
        [ 9045],
        [ 9145],
        [ 9277],
        [ 8371]], device='cuda:0')
[2024-07-23 21:06:27,540][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[11520],
        [11589],
        [11594],
        [13050],
        [13198],
        [12936],
        [11030],
        [ 6895],
        [10985]], device='cuda:0')
[2024-07-23 21:06:27,542][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[4169],
        [3310],
        [2064],
        [1501],
        [ 890],
        [ 365],
        [ 358],
        [ 412],
        [ 435]], device='cuda:0')
[2024-07-23 21:06:27,544][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[414],
        [105],
        [ 45],
        [ 36],
        [ 62],
        [ 65],
        [ 62],
        [ 78],
        [ 77]], device='cuda:0')
[2024-07-23 21:06:27,545][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[2512],
        [3360],
        [4000],
        [4914],
        [4310],
        [3375],
        [2686],
        [2213],
        [2774]], device='cuda:0')
[2024-07-23 21:06:27,547][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[153],
        [178],
        [280],
        [312],
        [347],
        [425],
        [401],
        [373],
        [334]], device='cuda:0')
[2024-07-23 21:06:27,548][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[6269],
        [4740],
        [3727],
        [3416],
        [3385],
        [3189],
        [2943],
        [3092],
        [3470]], device='cuda:0')
[2024-07-23 21:06:27,550][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[2257],
        [5614],
        [4572],
        [2525],
        [3989],
        [3037],
        [3185],
        [4726],
        [2655]], device='cuda:0')
[2024-07-23 21:06:27,552][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 17],
        [ 67],
        [225],
        [ 25],
        [ 55],
        [403],
        [ 26],
        [  3],
        [  1]], device='cuda:0')
[2024-07-23 21:06:27,553][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 9],
        [22],
        [ 5],
        [ 3],
        [ 5],
        [ 6],
        [21],
        [31],
        [28]], device='cuda:0')
[2024-07-23 21:06:27,555][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[ 14],
        [ 22],
        [ 31],
        [ 46],
        [ 42],
        [ 62],
        [156],
        [443],
        [ 79]], device='cuda:0')
[2024-07-23 21:06:27,556][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[ 962],
        [2120],
        [2418],
        [3586],
        [4012],
        [3953],
        [3500],
        [3166],
        [4700]], device='cuda:0')
[2024-07-23 21:06:27,558][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[119],
        [117],
        [ 29],
        [ 22],
        [ 13],
        [ 21],
        [ 21],
        [ 35],
        [ 42]], device='cuda:0')
[2024-07-23 21:06:27,559][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 98],
        [ 90],
        [180],
        [211],
        [145],
        [164],
        [162],
        [144],
        [136]], device='cuda:0')
[2024-07-23 21:06:27,561][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[15],
        [16],
        [15],
        [12],
        [16],
        [14],
        [16],
        [34],
        [22]], device='cuda:0')
[2024-07-23 21:06:27,563][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[1258],
        [1450],
        [1555],
        [1687],
        [3165],
        [4565],
        [2487],
        [1855],
        [3080]], device='cuda:0')
[2024-07-23 21:06:27,564][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[1],
        [1],
        [2],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:27,566][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[3],
        [3],
        [2],
        [4],
        [4],
        [3],
        [4],
        [4],
        [4]], device='cuda:0')
[2024-07-23 21:06:27,567][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[4736],
        [4708],
        [4289],
        [3732],
        [3390],
        [3161],
        [2981],
        [2665],
        [2340]], device='cuda:0')
[2024-07-23 21:06:27,569][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[ 8],
        [36],
        [29],
        [55],
        [23],
        [43],
        [27],
        [76],
        [42]], device='cuda:0')
[2024-07-23 21:06:27,571][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[410],
        [ 61],
        [130],
        [749],
        [281],
        [ 83],
        [505],
        [225],
        [323]], device='cuda:0')
[2024-07-23 21:06:27,572][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[5044],
        [3583],
        [4115],
        [3732],
        [4031],
        [4061],
        [3884],
        [4267],
        [4618]], device='cuda:0')
[2024-07-23 21:06:27,574][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[ 9868],
        [16712],
        [18239],
        [10935],
        [12841],
        [15723],
        [13616],
        [13923],
        [24177]], device='cuda:0')
[2024-07-23 21:06:27,575][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[46],
        [46],
        [46],
        [46],
        [46],
        [46],
        [46],
        [46],
        [46]], device='cuda:0')
[2024-07-23 21:06:27,652][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:27,654][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,654][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,655][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,656][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,656][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,657][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,658][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,658][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,659][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,660][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,660][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,661][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,662][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.6012, 0.3988], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,662][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.6517, 0.3483], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,663][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.4524, 0.5476], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,664][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.6078, 0.3922], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,666][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.4324, 0.5676], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,668][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.6708, 0.3292], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,670][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.4618, 0.5382], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,672][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.5681, 0.4319], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,673][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.6595, 0.3405], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,675][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.5780, 0.4220], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,676][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.5721, 0.4279], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,676][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.6137, 0.3863], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,677][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.4714, 0.3614, 0.1672], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,678][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.4696, 0.3751, 0.1553], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,678][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.3430, 0.3195, 0.3376], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,680][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.4692, 0.3123, 0.2185], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,682][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.3345, 0.3931, 0.2724], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,684][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.4530, 0.2728, 0.2743], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,685][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.2702, 0.2372, 0.4926], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,687][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.4571, 0.3517, 0.1912], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,689][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.5245, 0.3190, 0.1565], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,691][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.5521, 0.3949, 0.0531], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,693][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.4157, 0.2703, 0.3141], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,695][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.4378, 0.3585, 0.2037], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,696][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.3397, 0.2570, 0.1900, 0.2133], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,699][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.3854, 0.2852, 0.1764, 0.1530], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,700][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.2175, 0.2457, 0.2739, 0.2630], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,702][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.2899, 0.2230, 0.2406, 0.2464], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,704][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.2429, 0.2907, 0.2352, 0.2312], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,706][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.3351, 0.1941, 0.2549, 0.2159], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,708][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.2281, 0.2089, 0.3410, 0.2221], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,710][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.3515, 0.2756, 0.2063, 0.1666], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,712][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.3702, 0.2630, 0.1728, 0.1940], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,713][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.2875, 0.3570, 0.1776, 0.1780], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,715][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.2764, 0.1907, 0.2488, 0.2841], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,717][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.3212, 0.2867, 0.1995, 0.1926], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,719][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.2663, 0.2114, 0.1632, 0.1781, 0.1811], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,721][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.2967, 0.2043, 0.1177, 0.1666, 0.2146], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,723][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.1806, 0.1964, 0.1945, 0.2039, 0.2246], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,725][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.2306, 0.1705, 0.1685, 0.2044, 0.2261], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,727][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.2122, 0.2156, 0.2026, 0.1843, 0.1852], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,729][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.2699, 0.1498, 0.1727, 0.1907, 0.2169], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,730][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.1915, 0.1761, 0.2996, 0.1815, 0.1513], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,733][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.2733, 0.1944, 0.1569, 0.1803, 0.1951], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,735][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.3126, 0.1728, 0.1313, 0.2091, 0.1743], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,736][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.2993, 0.2532, 0.1086, 0.2461, 0.0928], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,737][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.2084, 0.1449, 0.1758, 0.2697, 0.2011], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,738][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.2839, 0.1878, 0.1409, 0.1727, 0.2148], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,739][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.2352, 0.1915, 0.1018, 0.1380, 0.1994, 0.1339], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,739][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.1910, 0.1783, 0.1005, 0.1127, 0.2464, 0.1712], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,740][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.1353, 0.1523, 0.1634, 0.1614, 0.1782, 0.2094], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,742][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.1888, 0.1509, 0.1446, 0.1581, 0.2231, 0.1346], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,744][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.1961, 0.1791, 0.1244, 0.1485, 0.2142, 0.1378], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,746][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.2224, 0.1071, 0.1472, 0.1620, 0.1820, 0.1795], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,747][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.1840, 0.1536, 0.2452, 0.1408, 0.1036, 0.1728], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,749][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.2502, 0.1839, 0.1177, 0.1308, 0.1647, 0.1527], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,751][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.2124, 0.1617, 0.1182, 0.1524, 0.2314, 0.1239], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,752][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.1703, 0.1687, 0.0963, 0.2571, 0.2895, 0.0181], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,755][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.1650, 0.1253, 0.1739, 0.1521, 0.1685, 0.2152], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,757][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.1952, 0.1571, 0.1074, 0.1312, 0.2721, 0.1369], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,758][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.1875, 0.1559, 0.1030, 0.1295, 0.1724, 0.1692, 0.0826],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,761][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.1704, 0.1277, 0.0766, 0.1274, 0.2325, 0.1887, 0.0766],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,762][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.1224, 0.1351, 0.1317, 0.1469, 0.1668, 0.1481, 0.1491],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,764][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.1740, 0.1118, 0.1020, 0.1664, 0.1935, 0.1433, 0.1091],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,766][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.1540, 0.1710, 0.1201, 0.1351, 0.1648, 0.1167, 0.1383],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,768][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.1766, 0.0894, 0.1197, 0.1311, 0.1592, 0.2280, 0.0959],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,770][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.1690, 0.1286, 0.2110, 0.1281, 0.0998, 0.0952, 0.1682],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,772][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.1974, 0.1483, 0.1089, 0.1196, 0.1561, 0.1979, 0.0717],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,774][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.2076, 0.1136, 0.0891, 0.1389, 0.1543, 0.1831, 0.1134],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,775][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.1435, 0.1576, 0.1038, 0.1671, 0.2196, 0.0840, 0.1243],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,777][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.1499, 0.0987, 0.1184, 0.1717, 0.1656, 0.1652, 0.1305],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,779][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.1699, 0.1418, 0.1056, 0.1222, 0.1982, 0.2112, 0.0511],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:27,781][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.1757, 0.1285, 0.0954, 0.1106, 0.1221, 0.1684, 0.0966, 0.1026],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,783][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.1639, 0.0963, 0.0851, 0.0832, 0.1814, 0.1554, 0.0760, 0.1587],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,785][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.1082, 0.1243, 0.1146, 0.1299, 0.1333, 0.1167, 0.1365, 0.1366],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,786][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ written] are: tensor([0.1415, 0.0943, 0.0919, 0.1502, 0.1426, 0.1518, 0.1107, 0.1170],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,789][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.1143, 0.1353, 0.1149, 0.1138, 0.1344, 0.0996, 0.1365, 0.1513],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,790][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.1577, 0.0799, 0.1104, 0.1053, 0.1314, 0.1946, 0.0924, 0.1283],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,792][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.1245, 0.1140, 0.2261, 0.1082, 0.0786, 0.0821, 0.1270, 0.1395],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,794][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.1779, 0.1215, 0.1185, 0.1219, 0.1261, 0.1462, 0.0855, 0.1025],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,796][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.1506, 0.0897, 0.0804, 0.1075, 0.1282, 0.2048, 0.1209, 0.1179],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,798][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.0898, 0.1316, 0.1111, 0.1705, 0.1739, 0.1542, 0.1088, 0.0600],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,799][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.1397, 0.0847, 0.0959, 0.1495, 0.1185, 0.1132, 0.1269, 0.1716],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,799][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.1510, 0.0966, 0.0854, 0.1158, 0.1437, 0.2023, 0.0816, 0.1235],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:27,800][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.1503, 0.1282, 0.0697, 0.0951, 0.1503, 0.1147, 0.0783, 0.1494, 0.0638],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,801][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.1493, 0.0951, 0.0733, 0.0701, 0.1595, 0.1639, 0.0724, 0.1635, 0.0530],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,802][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.0945, 0.0994, 0.1122, 0.1115, 0.1283, 0.1178, 0.1136, 0.1351, 0.0877],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,804][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ in] are: tensor([0.1283, 0.0777, 0.0864, 0.1284, 0.1347, 0.1450, 0.0923, 0.1201, 0.0873],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,806][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.1179, 0.1287, 0.0871, 0.1043, 0.1202, 0.1017, 0.1042, 0.1357, 0.1003],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,808][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.1357, 0.0743, 0.0896, 0.0940, 0.1284, 0.1582, 0.0880, 0.1426, 0.0891],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,810][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.1114, 0.1029, 0.1579, 0.0938, 0.0823, 0.0804, 0.0961, 0.1149, 0.1603],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,812][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.1480, 0.1258, 0.0830, 0.0917, 0.1313, 0.1494, 0.0624, 0.1506, 0.0577],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,813][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.1420, 0.0927, 0.0665, 0.1055, 0.1234, 0.1198, 0.1044, 0.1856, 0.0601],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,816][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.0812, 0.1185, 0.0882, 0.1152, 0.1441, 0.0497, 0.1344, 0.1697, 0.0991],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,817][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.0998, 0.0761, 0.0984, 0.1241, 0.1206, 0.1267, 0.0964, 0.1474, 0.1105],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,819][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.1244, 0.1080, 0.0732, 0.0885, 0.1400, 0.1513, 0.0605, 0.2078, 0.0463],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:27,901][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:27,903][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,905][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,907][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,908][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,911][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,912][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,914][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,916][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,918][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,919][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,924][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,925][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:27,927][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.6012, 0.3988], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,929][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.6517, 0.3483], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,930][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.4524, 0.5476], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,932][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.6078, 0.3922], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,933][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.4324, 0.5676], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,935][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.6708, 0.3292], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,936][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.4618, 0.5382], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,938][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.5681, 0.4319], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,939][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.6595, 0.3405], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,941][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.5780, 0.4220], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,943][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.5721, 0.4279], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,945][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.6137, 0.3863], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:27,946][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.4714, 0.3614, 0.1672], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,947][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.4696, 0.3751, 0.1553], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,950][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.3430, 0.3195, 0.3376], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,951][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.4692, 0.3123, 0.2185], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,953][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.3345, 0.3931, 0.2724], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,955][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.4530, 0.2728, 0.2743], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,956][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.2702, 0.2372, 0.4926], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,958][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.4571, 0.3517, 0.1912], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,960][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.5245, 0.3190, 0.1565], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,962][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.5521, 0.3949, 0.0531], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,963][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.4157, 0.2703, 0.3141], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,965][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.4378, 0.3585, 0.2037], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:27,967][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.3397, 0.2570, 0.1900, 0.2133], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,968][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.3854, 0.2852, 0.1764, 0.1530], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,969][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.2175, 0.2457, 0.2739, 0.2630], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,972][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.2899, 0.2230, 0.2406, 0.2464], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,973][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.2429, 0.2907, 0.2352, 0.2312], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,975][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.3351, 0.1941, 0.2549, 0.2159], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,976][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.2281, 0.2089, 0.3410, 0.2221], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,978][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.3515, 0.2756, 0.2063, 0.1666], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,980][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.3702, 0.2630, 0.1728, 0.1940], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,981][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.2875, 0.3570, 0.1776, 0.1780], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,981][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.2764, 0.1907, 0.2488, 0.2841], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,982][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.3212, 0.2867, 0.1995, 0.1926], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:27,982][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.2663, 0.2114, 0.1632, 0.1781, 0.1811], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,982][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.2967, 0.2043, 0.1177, 0.1666, 0.2146], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,983][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.1806, 0.1964, 0.1945, 0.2039, 0.2246], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,983][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.2306, 0.1705, 0.1685, 0.2044, 0.2261], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,983][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.2122, 0.2156, 0.2026, 0.1843, 0.1852], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,984][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.2699, 0.1498, 0.1727, 0.1907, 0.2169], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,984][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.1915, 0.1761, 0.2996, 0.1815, 0.1513], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,984][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.2733, 0.1944, 0.1569, 0.1803, 0.1951], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,985][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.3126, 0.1728, 0.1313, 0.2091, 0.1743], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,985][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.2993, 0.2532, 0.1086, 0.2461, 0.0928], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,987][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.2084, 0.1449, 0.1758, 0.2697, 0.2011], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,989][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.2839, 0.1878, 0.1409, 0.1727, 0.2148], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:27,990][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.2352, 0.1915, 0.1018, 0.1380, 0.1994, 0.1339], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,992][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.1910, 0.1783, 0.1005, 0.1127, 0.2464, 0.1712], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,994][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.1353, 0.1523, 0.1634, 0.1614, 0.1782, 0.2094], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,995][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.1888, 0.1509, 0.1446, 0.1581, 0.2231, 0.1346], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,997][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.1961, 0.1791, 0.1244, 0.1485, 0.2142, 0.1378], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:27,999][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.2224, 0.1071, 0.1472, 0.1620, 0.1820, 0.1795], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,001][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.1840, 0.1536, 0.2452, 0.1408, 0.1036, 0.1728], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,002][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.2502, 0.1839, 0.1177, 0.1308, 0.1647, 0.1527], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,003][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.2124, 0.1617, 0.1182, 0.1524, 0.2314, 0.1239], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,006][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.1703, 0.1687, 0.0963, 0.2571, 0.2895, 0.0181], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,007][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.1650, 0.1253, 0.1739, 0.1521, 0.1685, 0.2152], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,009][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.1952, 0.1571, 0.1074, 0.1312, 0.2721, 0.1369], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,011][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.1875, 0.1559, 0.1030, 0.1295, 0.1724, 0.1692, 0.0826],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,012][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.1704, 0.1277, 0.0766, 0.1274, 0.2325, 0.1887, 0.0766],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,014][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.1224, 0.1351, 0.1317, 0.1469, 0.1668, 0.1481, 0.1491],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,016][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.1740, 0.1118, 0.1020, 0.1664, 0.1935, 0.1433, 0.1091],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,018][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.1540, 0.1710, 0.1201, 0.1351, 0.1648, 0.1167, 0.1383],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,019][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1766, 0.0894, 0.1197, 0.1311, 0.1592, 0.2280, 0.0959],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,021][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.1690, 0.1286, 0.2110, 0.1281, 0.0998, 0.0952, 0.1682],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,023][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.1974, 0.1483, 0.1089, 0.1196, 0.1561, 0.1979, 0.0717],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,024][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.2076, 0.1136, 0.0891, 0.1389, 0.1543, 0.1831, 0.1134],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,026][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.1435, 0.1576, 0.1038, 0.1671, 0.2196, 0.0840, 0.1243],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,028][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.1499, 0.0987, 0.1184, 0.1717, 0.1656, 0.1652, 0.1305],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,029][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.1699, 0.1418, 0.1056, 0.1222, 0.1982, 0.2112, 0.0511],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,031][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.1757, 0.1285, 0.0954, 0.1106, 0.1221, 0.1684, 0.0966, 0.1026],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,033][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.1639, 0.0963, 0.0851, 0.0832, 0.1814, 0.1554, 0.0760, 0.1587],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,035][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.1082, 0.1243, 0.1146, 0.1299, 0.1333, 0.1167, 0.1365, 0.1366],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,036][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([0.1415, 0.0943, 0.0919, 0.1502, 0.1426, 0.1518, 0.1107, 0.1170],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,038][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.1143, 0.1353, 0.1149, 0.1138, 0.1344, 0.0996, 0.1365, 0.1513],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,040][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.1577, 0.0799, 0.1104, 0.1053, 0.1314, 0.1946, 0.0924, 0.1283],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,042][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.1245, 0.1140, 0.2261, 0.1082, 0.0786, 0.0821, 0.1270, 0.1395],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,043][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.1779, 0.1215, 0.1185, 0.1219, 0.1261, 0.1462, 0.0855, 0.1025],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,043][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.1506, 0.0897, 0.0804, 0.1075, 0.1282, 0.2048, 0.1209, 0.1179],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,044][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.0898, 0.1316, 0.1111, 0.1705, 0.1739, 0.1542, 0.1088, 0.0600],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,044][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.1397, 0.0847, 0.0959, 0.1495, 0.1185, 0.1132, 0.1269, 0.1716],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,044][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.1510, 0.0966, 0.0854, 0.1158, 0.1437, 0.2023, 0.0816, 0.1235],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,045][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.1503, 0.1282, 0.0697, 0.0951, 0.1503, 0.1147, 0.0783, 0.1494, 0.0638],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,045][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.1493, 0.0951, 0.0733, 0.0701, 0.1595, 0.1639, 0.0724, 0.1635, 0.0530],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,046][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.0945, 0.0994, 0.1122, 0.1115, 0.1283, 0.1178, 0.1136, 0.1351, 0.0877],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,046][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([0.1283, 0.0777, 0.0864, 0.1284, 0.1347, 0.1450, 0.0923, 0.1201, 0.0873],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,046][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.1179, 0.1287, 0.0871, 0.1043, 0.1202, 0.1017, 0.1042, 0.1357, 0.1003],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,048][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.1357, 0.0743, 0.0896, 0.0940, 0.1284, 0.1582, 0.0880, 0.1426, 0.0891],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,050][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.1114, 0.1029, 0.1579, 0.0938, 0.0823, 0.0804, 0.0961, 0.1149, 0.1603],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,051][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.1480, 0.1258, 0.0830, 0.0917, 0.1313, 0.1494, 0.0624, 0.1506, 0.0577],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,053][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.1420, 0.0927, 0.0665, 0.1055, 0.1234, 0.1198, 0.1044, 0.1856, 0.0601],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,053][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.0812, 0.1185, 0.0882, 0.1152, 0.1441, 0.0497, 0.1344, 0.1697, 0.0991],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,055][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.0998, 0.0761, 0.0984, 0.1241, 0.1206, 0.1267, 0.0964, 0.1474, 0.1105],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,056][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.1244, 0.1080, 0.0732, 0.0885, 0.1400, 0.1513, 0.0605, 0.2078, 0.0463],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,057][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:28,058][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[5549],
        [ 536],
        [1125],
        [ 778],
        [ 187],
        [2909],
        [ 239],
        [1776],
        [  19]], device='cuda:0')
[2024-07-23 21:06:28,060][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[10428],
        [  849],
        [ 1277],
        [ 1001],
        [  244],
        [ 3257],
        [  396],
        [ 2336],
        [   38]], device='cuda:0')
[2024-07-23 21:06:28,061][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[1771],
        [1408],
        [1190],
        [1094],
        [1135],
        [1276],
        [1171],
        [1066],
        [ 932]], device='cuda:0')
[2024-07-23 21:06:28,062][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[17239],
        [17292],
        [14022],
        [14977],
        [12355],
        [12300],
        [12860],
        [13575],
        [14009]], device='cuda:0')
[2024-07-23 21:06:28,064][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[2381],
        [2300],
        [2424],
        [3000],
        [2648],
        [2751],
        [2976],
        [3267],
        [3783]], device='cuda:0')
[2024-07-23 21:06:28,065][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[4815],
        [2953],
        [2812],
        [2635],
        [1921],
        [2088],
        [2045],
        [1838],
        [1759]], device='cuda:0')
[2024-07-23 21:06:28,067][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[1376],
        [1174],
        [1083],
        [ 841],
        [ 804],
        [ 825],
        [ 724],
        [1153],
        [1185]], device='cuda:0')
[2024-07-23 21:06:28,068][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[4909],
        [5722],
        [3685],
        [2623],
        [3205],
        [3940],
        [3775],
        [3385],
        [2874]], device='cuda:0')
[2024-07-23 21:06:28,070][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[ 7909],
        [14234],
        [13240],
        [11889],
        [12872],
        [13020],
        [12816],
        [13265],
        [13219]], device='cuda:0')
[2024-07-23 21:06:28,071][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[775],
        [612],
        [496],
        [460],
        [491],
        [502],
        [485],
        [489],
        [517]], device='cuda:0')
[2024-07-23 21:06:28,072][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[320],
        [273],
        [202],
        [168],
        [192],
        [185],
        [154],
        [150],
        [194]], device='cuda:0')
[2024-07-23 21:06:28,074][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[ 9978],
        [16418],
        [17188],
        [22892],
        [21951],
        [21841],
        [20567],
        [21891],
        [16787]], device='cuda:0')
[2024-07-23 21:06:28,075][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[14062],
        [13506],
        [11085],
        [13403],
        [15980],
        [12435],
        [12982],
        [13972],
        [13658]], device='cuda:0')
[2024-07-23 21:06:28,077][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[309],
        [443],
        [445],
        [404],
        [478],
        [504],
        [498],
        [536],
        [587]], device='cuda:0')
[2024-07-23 21:06:28,078][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 6],
        [ 6],
        [ 7],
        [28],
        [24],
        [13],
        [11],
        [ 8],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:28,080][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 573],
        [ 978],
        [1372],
        [1053],
        [ 977],
        [1176],
        [1304],
        [1356],
        [1088]], device='cuda:0')
[2024-07-23 21:06:28,081][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[107],
        [ 74],
        [155],
        [126],
        [223],
        [172],
        [142],
        [351],
        [354]], device='cuda:0')
[2024-07-23 21:06:28,082][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[70],
        [35],
        [48],
        [85],
        [75],
        [39],
        [44],
        [51],
        [46]], device='cuda:0')
[2024-07-23 21:06:28,084][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[ 247],
        [ 669],
        [ 484],
        [ 607],
        [ 650],
        [ 809],
        [ 902],
        [1142],
        [1056]], device='cuda:0')
[2024-07-23 21:06:28,085][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[498],
        [167],
        [126],
        [114],
        [109],
        [191],
        [173],
        [168],
        [155]], device='cuda:0')
[2024-07-23 21:06:28,087][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[1004],
        [ 921],
        [ 485],
        [ 657],
        [ 861],
        [ 899],
        [ 845],
        [ 857],
        [ 981]], device='cuda:0')
[2024-07-23 21:06:28,088][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[137],
        [ 53],
        [166],
        [112],
        [114],
        [159],
        [ 78],
        [ 41],
        [ 25]], device='cuda:0')
[2024-07-23 21:06:28,089][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[787],
        [342],
        [487],
        [478],
        [376],
        [516],
        [635],
        [707],
        [791]], device='cuda:0')
[2024-07-23 21:06:28,091][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[8870],
        [7943],
        [7574],
        [8598],
        [9498],
        [6732],
        [6122],
        [6064],
        [8058]], device='cuda:0')
[2024-07-23 21:06:28,092][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[ 40],
        [118],
        [ 99],
        [ 66],
        [ 59],
        [ 48],
        [ 77],
        [ 74],
        [131]], device='cuda:0')
[2024-07-23 21:06:28,094][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[780],
        [428],
        [344],
        [281],
        [349],
        [375],
        [430],
        [528],
        [587]], device='cuda:0')
[2024-07-23 21:06:28,095][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[1282],
        [1598],
        [1508],
        [ 949],
        [ 683],
        [ 561],
        [ 573],
        [ 670],
        [ 727]], device='cuda:0')
[2024-07-23 21:06:28,097][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[ 6850],
        [10349],
        [ 9282],
        [ 9341],
        [ 8736],
        [ 9042],
        [ 9350],
        [ 9561],
        [ 8702]], device='cuda:0')
[2024-07-23 21:06:28,098][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[28034],
        [31164],
        [40385],
        [30513],
        [30076],
        [32231],
        [33520],
        [32444],
        [36012]], device='cuda:0')
[2024-07-23 21:06:28,099][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[36],
        [36],
        [36],
        [36],
        [36],
        [36],
        [36],
        [36],
        [36]], device='cuda:0')
[2024-07-23 21:06:28,159][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:28,160][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,162][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,163][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,165][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,166][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,167][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,168][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,168][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,168][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,169][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,169][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,169][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,170][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.6668, 0.3332], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,170][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.5455, 0.4545], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,170][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.4746, 0.5254], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,170][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.5424, 0.4576], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,171][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.6678, 0.3322], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,171][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.5862, 0.4138], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,172][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.5350, 0.4650], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,173][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.4829, 0.5171], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,175][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.5930, 0.4070], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,177][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.6294, 0.3706], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,178][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.5204, 0.4796], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,180][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.5461, 0.4539], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,181][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.4963, 0.3392, 0.1644], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,183][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.3789, 0.4061, 0.2150], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,184][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.3843, 0.4155, 0.2002], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,187][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.4341, 0.3770, 0.1888], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,188][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.5596, 0.2702, 0.1703], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,189][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.4521, 0.3375, 0.2104], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,192][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.3765, 0.3374, 0.2861], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,193][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.3897, 0.3810, 0.2293], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,195][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.4989, 0.3317, 0.1694], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,197][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.5089, 0.3535, 0.1376], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,198][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.3776, 0.4433, 0.1791], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,200][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.4583, 0.3379, 0.2038], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,202][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.3732, 0.2802, 0.1699, 0.1767], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,204][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.2512, 0.2542, 0.1205, 0.3740], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,205][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.1954, 0.2617, 0.1814, 0.3615], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,206][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.3271, 0.2957, 0.1539, 0.2233], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,209][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.3520, 0.2148, 0.1662, 0.2671], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,210][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.3131, 0.2553, 0.1803, 0.2513], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,212][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.2481, 0.2246, 0.2482, 0.2791], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,213][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.2149, 0.2291, 0.1741, 0.3819], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,215][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.3588, 0.2910, 0.1464, 0.2037], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,217][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.3915, 0.2569, 0.1417, 0.2099], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,219][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.1492, 0.1978, 0.2577, 0.3952], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,220][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.2755, 0.2427, 0.2096, 0.2722], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,222][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.2935, 0.1762, 0.1352, 0.1886, 0.2065], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,223][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.1984, 0.1654, 0.1178, 0.2984, 0.2200], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,226][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.1147, 0.1310, 0.1080, 0.3979, 0.2485], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,227][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.2640, 0.1923, 0.1145, 0.2090, 0.2202], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,228][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.2811, 0.1557, 0.1087, 0.2044, 0.2501], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,229][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.2431, 0.1747, 0.1565, 0.1960, 0.2298], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,229][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.1931, 0.1717, 0.1932, 0.2386, 0.2034], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,230][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.1658, 0.1784, 0.1156, 0.3176, 0.2225], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,230][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.2817, 0.1965, 0.1131, 0.1895, 0.2193], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,230][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.2985, 0.1841, 0.1297, 0.1805, 0.2072], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,231][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.1586, 0.1562, 0.1572, 0.3801, 0.1479], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,231][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.1724, 0.1159, 0.1112, 0.2885, 0.3120], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,231][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.1863, 0.1697, 0.1044, 0.1268, 0.2106, 0.2022], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,232][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.1464, 0.1463, 0.0767, 0.2417, 0.2076, 0.1812], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,232][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.0874, 0.1309, 0.0668, 0.2854, 0.2988, 0.1308], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,233][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.2043, 0.1674, 0.0803, 0.1546, 0.1917, 0.2016], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,235][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.2070, 0.1318, 0.1018, 0.1581, 0.2284, 0.1728], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,237][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.1838, 0.1738, 0.0951, 0.1599, 0.2029, 0.1844], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,238][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.1701, 0.1471, 0.1757, 0.2296, 0.1656, 0.1119], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,239][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.1176, 0.1217, 0.1110, 0.2468, 0.1838, 0.2191], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,241][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.1748, 0.1479, 0.0920, 0.1427, 0.2216, 0.2210], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,243][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.2196, 0.1555, 0.0829, 0.1501, 0.1704, 0.2215], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,244][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.0793, 0.1165, 0.1191, 0.4144, 0.2247, 0.0459], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,246][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.1454, 0.1241, 0.1007, 0.2824, 0.2637, 0.0836], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,248][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.1652, 0.1152, 0.0859, 0.1193, 0.1473, 0.2835, 0.0835],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,250][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.1473, 0.1234, 0.0594, 0.2454, 0.1708, 0.1277, 0.1259],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,251][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.0689, 0.0973, 0.0778, 0.2336, 0.2377, 0.1473, 0.1375],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,253][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.1917, 0.1375, 0.0691, 0.1193, 0.1587, 0.1968, 0.1269],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,255][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.2031, 0.0977, 0.0768, 0.1502, 0.1991, 0.1664, 0.1066],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,256][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.1841, 0.1357, 0.0904, 0.1500, 0.2062, 0.1476, 0.0861],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,258][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.1595, 0.1368, 0.1304, 0.1867, 0.1405, 0.1019, 0.1443],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,260][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.1064, 0.1059, 0.0792, 0.2049, 0.1646, 0.2165, 0.1223],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,261][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.1601, 0.1210, 0.0677, 0.1168, 0.1879, 0.2647, 0.0817],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,263][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.1870, 0.1178, 0.0752, 0.1332, 0.1621, 0.2318, 0.0928],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,265][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.0875, 0.0915, 0.1090, 0.3594, 0.1800, 0.0680, 0.1046],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,267][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.1244, 0.1186, 0.0778, 0.2248, 0.2678, 0.0987, 0.0879],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,269][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.1319, 0.0828, 0.0792, 0.0905, 0.1307, 0.2608, 0.1206, 0.1035],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,270][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.1043, 0.0954, 0.0562, 0.1955, 0.1537, 0.1039, 0.1250, 0.1660],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,272][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.0551, 0.0725, 0.0778, 0.1914, 0.1940, 0.1754, 0.1054, 0.1284],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,273][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ written] are: tensor([0.1481, 0.1158, 0.0712, 0.1169, 0.1225, 0.1646, 0.1163, 0.1446],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,275][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.1742, 0.0866, 0.0654, 0.1118, 0.1240, 0.1700, 0.1070, 0.1609],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,277][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.1484, 0.1121, 0.0862, 0.1492, 0.1631, 0.1179, 0.0918, 0.1312],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,278][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.1261, 0.1108, 0.1284, 0.1539, 0.1151, 0.0906, 0.1264, 0.1488],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,280][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.1078, 0.1104, 0.0683, 0.1781, 0.1269, 0.1572, 0.1099, 0.1414],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,282][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.1331, 0.0960, 0.0695, 0.1049, 0.1489, 0.1950, 0.0922, 0.1605],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,284][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.1683, 0.1109, 0.0694, 0.1016, 0.1254, 0.1722, 0.1010, 0.1512],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,286][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.0700, 0.0888, 0.1346, 0.2607, 0.1482, 0.1147, 0.0922, 0.0907],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,287][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.1110, 0.0879, 0.0861, 0.1741, 0.1870, 0.0951, 0.0832, 0.1755],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,289][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.1356, 0.1080, 0.0621, 0.0874, 0.1324, 0.1825, 0.0966, 0.1405, 0.0549],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,290][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.1033, 0.1071, 0.0472, 0.1531, 0.1149, 0.0964, 0.0906, 0.1960, 0.0915],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,291][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.0475, 0.0752, 0.0543, 0.1907, 0.1415, 0.1168, 0.1179, 0.1497, 0.1064],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,291][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ in] are: tensor([0.1384, 0.1199, 0.0543, 0.0980, 0.1272, 0.1200, 0.1079, 0.1486, 0.0856],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,291][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.1439, 0.0764, 0.0476, 0.1092, 0.1431, 0.1168, 0.0852, 0.1870, 0.0908],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,292][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.1280, 0.0968, 0.0671, 0.1127, 0.1489, 0.1148, 0.0758, 0.1765, 0.0794],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,292][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.1199, 0.1055, 0.0976, 0.1290, 0.1111, 0.0893, 0.1065, 0.1415, 0.0998],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,293][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.0847, 0.0778, 0.0745, 0.1720, 0.1248, 0.1468, 0.1013, 0.1496, 0.0686],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,293][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.1202, 0.0958, 0.0457, 0.0933, 0.1536, 0.1396, 0.0667, 0.2315, 0.0535],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,293][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.1505, 0.0978, 0.0558, 0.0933, 0.1300, 0.1554, 0.0831, 0.1482, 0.0859],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,294][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.0529, 0.0786, 0.0930, 0.2700, 0.1265, 0.0562, 0.0968, 0.1339, 0.0921],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,296][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.0917, 0.0852, 0.0705, 0.1413, 0.1828, 0.0703, 0.0829, 0.1902, 0.0851],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,344][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:28,346][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,348][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,349][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,350][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,351][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,352][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,352][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,352][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,352][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,353][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,353][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,353][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,354][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.6668, 0.3332], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,354][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.5455, 0.4545], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,354][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.4746, 0.5254], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,355][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.5424, 0.4576], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,355][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.6678, 0.3322], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,356][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.5862, 0.4138], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,357][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.5350, 0.4650], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,357][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.4829, 0.5171], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,357][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.5930, 0.4070], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,358][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.6294, 0.3706], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,358][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.5204, 0.4796], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,358][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.5461, 0.4539], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,359][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.4963, 0.3392, 0.1644], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,359][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.3789, 0.4061, 0.2150], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,359][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.3843, 0.4155, 0.2002], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,360][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.4341, 0.3770, 0.1888], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,360][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.5596, 0.2702, 0.1703], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,360][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.4521, 0.3375, 0.2104], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,361][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.3765, 0.3374, 0.2861], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,361][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.3897, 0.3810, 0.2293], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,361][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.4989, 0.3317, 0.1694], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,362][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.5089, 0.3535, 0.1376], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,362][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.3776, 0.4433, 0.1791], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,362][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.4583, 0.3379, 0.2038], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,363][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.3732, 0.2802, 0.1699, 0.1767], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,363][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.2512, 0.2542, 0.1205, 0.3740], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,363][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.1954, 0.2617, 0.1814, 0.3615], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,364][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.3271, 0.2957, 0.1539, 0.2233], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,364][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.3520, 0.2148, 0.1662, 0.2671], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,364][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.3131, 0.2553, 0.1803, 0.2513], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,365][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.2481, 0.2246, 0.2482, 0.2791], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,365][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.2149, 0.2291, 0.1741, 0.3819], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,365][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.3588, 0.2910, 0.1464, 0.2037], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,366][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.3915, 0.2569, 0.1417, 0.2099], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,366][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.1492, 0.1978, 0.2577, 0.3952], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,367][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.2755, 0.2427, 0.2096, 0.2722], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,369][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.2935, 0.1762, 0.1352, 0.1886, 0.2065], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,370][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.1984, 0.1654, 0.1178, 0.2984, 0.2200], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,371][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.1147, 0.1310, 0.1080, 0.3979, 0.2485], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,372][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.2640, 0.1923, 0.1145, 0.2090, 0.2202], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,374][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.2811, 0.1557, 0.1087, 0.2044, 0.2501], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,375][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.2431, 0.1747, 0.1565, 0.1960, 0.2298], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,377][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.1931, 0.1717, 0.1932, 0.2386, 0.2034], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,379][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.1658, 0.1784, 0.1156, 0.3176, 0.2225], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,381][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.2817, 0.1965, 0.1131, 0.1895, 0.2193], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,382][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.2985, 0.1841, 0.1297, 0.1805, 0.2072], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,383][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.1586, 0.1562, 0.1572, 0.3801, 0.1479], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,386][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.1724, 0.1159, 0.1112, 0.2885, 0.3120], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,387][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.1863, 0.1697, 0.1044, 0.1268, 0.2106, 0.2022], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,389][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.1464, 0.1463, 0.0767, 0.2417, 0.2076, 0.1812], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,390][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.0874, 0.1309, 0.0668, 0.2854, 0.2988, 0.1308], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,392][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.2043, 0.1674, 0.0803, 0.1546, 0.1917, 0.2016], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,394][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.2070, 0.1318, 0.1018, 0.1581, 0.2284, 0.1728], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,395][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.1838, 0.1738, 0.0951, 0.1599, 0.2029, 0.1844], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,397][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.1701, 0.1471, 0.1757, 0.2296, 0.1656, 0.1119], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,399][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.1176, 0.1217, 0.1110, 0.2468, 0.1838, 0.2191], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,400][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.1748, 0.1479, 0.0920, 0.1427, 0.2216, 0.2210], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,402][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.2196, 0.1555, 0.0829, 0.1501, 0.1704, 0.2215], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,404][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.0793, 0.1165, 0.1191, 0.4144, 0.2247, 0.0459], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,405][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.1454, 0.1241, 0.1007, 0.2824, 0.2637, 0.0836], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,407][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.1652, 0.1152, 0.0859, 0.1193, 0.1473, 0.2835, 0.0835],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,409][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.1473, 0.1234, 0.0594, 0.2454, 0.1708, 0.1277, 0.1259],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,411][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.0689, 0.0973, 0.0778, 0.2336, 0.2377, 0.1473, 0.1375],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,413][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.1917, 0.1375, 0.0691, 0.1193, 0.1587, 0.1968, 0.1269],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,414][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.2031, 0.0977, 0.0768, 0.1502, 0.1991, 0.1664, 0.1066],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,416][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1841, 0.1357, 0.0904, 0.1500, 0.2062, 0.1476, 0.0861],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,418][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.1595, 0.1368, 0.1304, 0.1867, 0.1405, 0.1019, 0.1443],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,420][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.1064, 0.1059, 0.0792, 0.2049, 0.1646, 0.2165, 0.1223],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,421][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.1601, 0.1210, 0.0677, 0.1168, 0.1879, 0.2647, 0.0817],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,423][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.1870, 0.1178, 0.0752, 0.1332, 0.1621, 0.2318, 0.0928],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,423][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.0875, 0.0915, 0.1090, 0.3594, 0.1800, 0.0680, 0.1046],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,423][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.1244, 0.1186, 0.0778, 0.2248, 0.2678, 0.0987, 0.0879],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,424][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.1319, 0.0828, 0.0792, 0.0905, 0.1307, 0.2608, 0.1206, 0.1035],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,424][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.1043, 0.0954, 0.0562, 0.1955, 0.1537, 0.1039, 0.1250, 0.1660],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,424][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.0551, 0.0725, 0.0778, 0.1914, 0.1940, 0.1754, 0.1054, 0.1284],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,424][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([0.1481, 0.1158, 0.0712, 0.1169, 0.1225, 0.1646, 0.1163, 0.1446],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,425][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.1742, 0.0866, 0.0654, 0.1118, 0.1240, 0.1700, 0.1070, 0.1609],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,425][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.1484, 0.1121, 0.0862, 0.1492, 0.1631, 0.1179, 0.0918, 0.1312],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,425][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.1261, 0.1108, 0.1284, 0.1539, 0.1151, 0.0906, 0.1264, 0.1488],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,426][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.1078, 0.1104, 0.0683, 0.1781, 0.1269, 0.1572, 0.1099, 0.1414],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,426][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.1331, 0.0960, 0.0695, 0.1049, 0.1489, 0.1950, 0.0922, 0.1605],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,427][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.1683, 0.1109, 0.0694, 0.1016, 0.1254, 0.1722, 0.1010, 0.1512],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,428][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.0700, 0.0888, 0.1346, 0.2607, 0.1482, 0.1147, 0.0922, 0.0907],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,430][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.1110, 0.0879, 0.0861, 0.1741, 0.1870, 0.0951, 0.0832, 0.1755],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,432][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.1356, 0.1080, 0.0621, 0.0874, 0.1324, 0.1825, 0.0966, 0.1405, 0.0549],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,433][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.1033, 0.1071, 0.0472, 0.1531, 0.1149, 0.0964, 0.0906, 0.1960, 0.0915],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,435][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.0475, 0.0752, 0.0543, 0.1907, 0.1415, 0.1168, 0.1179, 0.1497, 0.1064],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,437][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([0.1384, 0.1199, 0.0543, 0.0980, 0.1272, 0.1200, 0.1079, 0.1486, 0.0856],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,438][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.1439, 0.0764, 0.0476, 0.1092, 0.1431, 0.1168, 0.0852, 0.1870, 0.0908],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,440][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.1280, 0.0968, 0.0671, 0.1127, 0.1489, 0.1148, 0.0758, 0.1765, 0.0794],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,442][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.1199, 0.1055, 0.0976, 0.1290, 0.1111, 0.0893, 0.1065, 0.1415, 0.0998],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,443][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.0847, 0.0778, 0.0745, 0.1720, 0.1248, 0.1468, 0.1013, 0.1496, 0.0686],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,445][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.1202, 0.0958, 0.0457, 0.0933, 0.1536, 0.1396, 0.0667, 0.2315, 0.0535],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,447][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.1505, 0.0978, 0.0558, 0.0933, 0.1300, 0.1554, 0.0831, 0.1482, 0.0859],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,448][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.0529, 0.0786, 0.0930, 0.2700, 0.1265, 0.0562, 0.0968, 0.1339, 0.0921],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,450][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.0917, 0.0852, 0.0705, 0.1413, 0.1828, 0.0703, 0.0829, 0.1902, 0.0851],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,451][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:28,452][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[1092],
        [   7],
        [  12],
        [  22],
        [   5],
        [  24],
        [  13],
        [  99],
        [   5]], device='cuda:0')
[2024-07-23 21:06:28,454][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[1500],
        [   8],
        [  12],
        [  28],
        [   5],
        [  24],
        [  21],
        [ 126],
        [  12]], device='cuda:0')
[2024-07-23 21:06:28,455][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[10834],
        [11471],
        [ 8153],
        [ 7626],
        [ 8371],
        [ 7709],
        [ 7350],
        [ 8231],
        [ 9675]], device='cuda:0')
[2024-07-23 21:06:28,456][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[2067],
        [1624],
        [1815],
        [2333],
        [2071],
        [1837],
        [1906],
        [1891],
        [1828]], device='cuda:0')
[2024-07-23 21:06:28,458][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[11688],
        [17954],
        [17048],
        [15331],
        [16119],
        [17790],
        [17498],
        [18528],
        [21390]], device='cuda:0')
[2024-07-23 21:06:28,459][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[1515],
        [ 813],
        [ 805],
        [ 525],
        [ 376],
        [ 390],
        [ 379],
        [ 264],
        [ 245]], device='cuda:0')
[2024-07-23 21:06:28,461][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 5310],
        [ 3836],
        [ 4861],
        [ 7195],
        [ 9679],
        [10069],
        [ 9843],
        [ 9733],
        [10072]], device='cuda:0')
[2024-07-23 21:06:28,462][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[422],
        [301],
        [507],
        [700],
        [460],
        [525],
        [532],
        [637],
        [735]], device='cuda:0')
[2024-07-23 21:06:28,463][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[1961],
        [1392],
        [1810],
        [1875],
        [2344],
        [2197],
        [2030],
        [2747],
        [2763]], device='cuda:0')
[2024-07-23 21:06:28,465][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[11758],
        [14991],
        [14784],
        [14177],
        [15134],
        [14320],
        [14361],
        [13973],
        [14209]], device='cuda:0')
[2024-07-23 21:06:28,466][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[ 709],
        [ 583],
        [ 555],
        [ 863],
        [1334],
        [2036],
        [2414],
        [2920],
        [3192]], device='cuda:0')
[2024-07-23 21:06:28,468][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[ 7847],
        [ 8045],
        [ 8720],
        [ 9923],
        [10570],
        [10421],
        [10635],
        [12022],
        [12690]], device='cuda:0')
[2024-07-23 21:06:28,469][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[ 9038],
        [13133],
        [ 9833],
        [ 5015],
        [ 5557],
        [ 5637],
        [ 5907],
        [ 5605],
        [ 4780]], device='cuda:0')
[2024-07-23 21:06:28,471][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[ 6650],
        [11284],
        [ 9399],
        [11348],
        [12254],
        [11560],
        [11236],
        [ 8569],
        [ 8998]], device='cuda:0')
[2024-07-23 21:06:28,472][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[10],
        [13],
        [29],
        [11],
        [ 9],
        [ 4],
        [ 5],
        [21],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:28,473][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 91],
        [ 26],
        [ 21],
        [ 25],
        [ 25],
        [ 55],
        [103],
        [133],
        [ 99]], device='cuda:0')
[2024-07-23 21:06:28,475][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[1347],
        [2597],
        [4484],
        [3107],
        [2698],
        [2615],
        [2639],
        [2814],
        [2925]], device='cuda:0')
[2024-07-23 21:06:28,476][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[152],
        [176],
        [250],
        [297],
        [194],
        [117],
        [ 96],
        [ 71],
        [ 71]], device='cuda:0')
[2024-07-23 21:06:28,478][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[355],
        [ 72],
        [ 34],
        [ 26],
        [ 23],
        [ 26],
        [ 27],
        [ 26],
        [ 26]], device='cuda:0')
[2024-07-23 21:06:28,479][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 903],
        [1767],
        [ 867],
        [1002],
        [ 937],
        [ 968],
        [ 983],
        [1199],
        [1276]], device='cuda:0')
[2024-07-23 21:06:28,480][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[1108],
        [1065],
        [1039],
        [ 684],
        [ 788],
        [1453],
        [1362],
        [1006],
        [ 919]], device='cuda:0')
[2024-07-23 21:06:28,482][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[143],
        [307],
        [258],
        [219],
        [166],
        [224],
        [362],
        [331],
        [390]], device='cuda:0')
[2024-07-23 21:06:28,483][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 77],
        [112],
        [ 46],
        [  2],
        [  4],
        [  8],
        [ 11],
        [ 13],
        [ 12]], device='cuda:0')
[2024-07-23 21:06:28,485][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[1412],
        [1959],
        [2128],
        [2345],
        [1953],
        [ 965],
        [ 704],
        [1133],
        [1362]], device='cuda:0')
[2024-07-23 21:06:28,486][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[254],
        [ 64],
        [ 89],
        [136],
        [ 97],
        [159],
        [161],
        [267],
        [263]], device='cuda:0')
[2024-07-23 21:06:28,487][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[4931],
        [1880],
        [4636],
        [8071],
        [4683],
        [4321],
        [5370],
        [9758],
        [5589]], device='cuda:0')
[2024-07-23 21:06:28,487][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[976],
        [329],
        [712],
        [145],
        [ 87],
        [ 69],
        [ 79],
        [112],
        [147]], device='cuda:0')
[2024-07-23 21:06:28,488][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[14578],
        [16751],
        [15545],
        [16382],
        [19997],
        [17575],
        [16933],
        [13072],
        [14313]], device='cuda:0')
[2024-07-23 21:06:28,489][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[39390],
        [33995],
        [33504],
        [39779],
        [42966],
        [41433],
        [43565],
        [39986],
        [47762]], device='cuda:0')
[2024-07-23 21:06:28,489][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[11],
        [11],
        [11],
        [11],
        [11],
        [11],
        [11],
        [11],
        [11]], device='cuda:0')
[2024-07-23 21:06:28,530][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:28,532][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,533][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,534][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,536][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,536][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,536][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,536][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,537][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,537][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,537][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,538][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,538][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,538][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.7033, 0.2967], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,539][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.5442, 0.4558], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,539][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.4087, 0.5913], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,539][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.4899, 0.5101], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,539][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.6409, 0.3591], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,540][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.5546, 0.4454], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,540][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.4948, 0.5052], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,540][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.5958, 0.4042], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,541][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.6243, 0.3757], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,541][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.5144, 0.4856], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,541][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.5530, 0.4470], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,542][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.5845, 0.4155], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,542][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.2153, 0.1082, 0.6766], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,542][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.2885, 0.3528, 0.3587], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,543][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.3400, 0.4320, 0.2280], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,552][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.3683, 0.4563, 0.1754], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,554][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.4338, 0.3288, 0.2374], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,556][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.3778, 0.3879, 0.2343], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,558][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.3156, 0.3418, 0.3425], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,559][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.4217, 0.4247, 0.1537], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,561][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.4031, 0.3379, 0.2591], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,563][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.4181, 0.3502, 0.2316], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,564][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.3946, 0.3261, 0.2793], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,565][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.4300, 0.3305, 0.2395], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,565][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.0863, 0.0344, 0.4346, 0.4446], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,565][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.1519, 0.1792, 0.3276, 0.3413], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,566][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.2428, 0.3427, 0.1948, 0.2197], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,566][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.2471, 0.3360, 0.1366, 0.2802], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,566][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.3700, 0.2446, 0.1615, 0.2240], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,566][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.2739, 0.2726, 0.2824, 0.1712], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,567][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.2421, 0.2521, 0.2022, 0.3036], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,567][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.3817, 0.3137, 0.1463, 0.1584], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,567][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.3108, 0.2287, 0.2021, 0.2584], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,568][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.2971, 0.2633, 0.1517, 0.2879], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,568][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.2759, 0.2246, 0.1829, 0.3166], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,568][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.2418, 0.2575, 0.1891, 0.3116], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,569][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.0650, 0.0322, 0.2791, 0.3264, 0.2973], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,570][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.1230, 0.1258, 0.1854, 0.3133, 0.2525], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,572][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.2184, 0.2267, 0.1286, 0.1876, 0.2386], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,574][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.1900, 0.2335, 0.1321, 0.1606, 0.2838], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,575][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.2433, 0.1216, 0.1195, 0.2152, 0.3004], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,575][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.2379, 0.1897, 0.1686, 0.1640, 0.2397], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,577][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.1569, 0.1303, 0.1493, 0.2674, 0.2962], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,579][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.2875, 0.1900, 0.0924, 0.1726, 0.2575], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,581][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.2342, 0.1650, 0.1880, 0.2164, 0.1964], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,582][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.2521, 0.1817, 0.1231, 0.2350, 0.2082], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,584][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.2104, 0.1442, 0.1400, 0.2398, 0.2656], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,586][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.2205, 0.1689, 0.1315, 0.2450, 0.2341], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,587][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.0717, 0.0491, 0.3331, 0.2485, 0.2391, 0.0583], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,589][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.0539, 0.0666, 0.1042, 0.2310, 0.2373, 0.3071], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,591][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.1662, 0.2238, 0.1007, 0.1304, 0.2191, 0.1599], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,592][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.1183, 0.1676, 0.0839, 0.1334, 0.2843, 0.2125], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,594][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.1609, 0.1088, 0.1104, 0.1234, 0.3036, 0.1928], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,596][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.1383, 0.1515, 0.1430, 0.1148, 0.2601, 0.1923], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,597][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.1300, 0.1530, 0.1177, 0.1729, 0.2354, 0.1910], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,599][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.1798, 0.1909, 0.0838, 0.1374, 0.2461, 0.1620], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,601][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.1762, 0.1359, 0.1551, 0.1292, 0.1673, 0.2363], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,602][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.1863, 0.1400, 0.1212, 0.1852, 0.1952, 0.1721], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,604][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.1519, 0.1075, 0.1001, 0.1869, 0.1812, 0.2724], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,606][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.1786, 0.1526, 0.0877, 0.1858, 0.1825, 0.2128], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,607][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.0647, 0.0285, 0.2738, 0.2699, 0.3059, 0.0289, 0.0283],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,609][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.0428, 0.0532, 0.1119, 0.1481, 0.1985, 0.4123, 0.0331],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,611][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.1198, 0.1762, 0.1066, 0.1350, 0.2206, 0.1434, 0.0985],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,613][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.1381, 0.1059, 0.0740, 0.1686, 0.1994, 0.1699, 0.1442],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,614][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.1258, 0.0841, 0.0686, 0.1248, 0.2418, 0.3028, 0.0521],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,616][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.1278, 0.1148, 0.0989, 0.1183, 0.2387, 0.2360, 0.0657],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,618][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.1048, 0.1101, 0.1163, 0.2304, 0.1886, 0.1781, 0.0718],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,619][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.1599, 0.1309, 0.0692, 0.0851, 0.2149, 0.2696, 0.0705],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,621][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.1474, 0.1035, 0.1264, 0.1528, 0.1634, 0.2084, 0.0982],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,623][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.1769, 0.1374, 0.0719, 0.1961, 0.1546, 0.1087, 0.1543],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,624][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.1435, 0.0967, 0.0888, 0.1760, 0.1934, 0.1780, 0.1237],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,626][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.1370, 0.0933, 0.0878, 0.1863, 0.1832, 0.1979, 0.1146],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,626][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.0731, 0.0268, 0.2556, 0.2343, 0.2613, 0.0262, 0.0201, 0.1027],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,627][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.0438, 0.0483, 0.0967, 0.1514, 0.1527, 0.3721, 0.0566, 0.0785],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,627][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.0982, 0.1397, 0.0932, 0.1344, 0.1740, 0.1264, 0.0968, 0.1372],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,627][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ written] are: tensor([0.0907, 0.1304, 0.0899, 0.1025, 0.1417, 0.1333, 0.0957, 0.2158],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,628][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.1283, 0.0639, 0.0423, 0.0923, 0.1418, 0.2558, 0.0602, 0.2153],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,628][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.1296, 0.1052, 0.1111, 0.1038, 0.1382, 0.1860, 0.1003, 0.1259],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,628][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.0979, 0.0824, 0.1137, 0.1656, 0.1754, 0.1200, 0.0715, 0.1734],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,629][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.1323, 0.0800, 0.0486, 0.0739, 0.1483, 0.1903, 0.0826, 0.2440],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,629][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.1544, 0.0913, 0.0976, 0.1187, 0.1483, 0.1737, 0.0955, 0.1206],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,629][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.1440, 0.1048, 0.0627, 0.1412, 0.1284, 0.1017, 0.1000, 0.2172],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,630][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.1044, 0.0874, 0.0707, 0.1373, 0.1148, 0.1256, 0.1031, 0.2568],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,630][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.1329, 0.0898, 0.0762, 0.1359, 0.1426, 0.2097, 0.1011, 0.1118],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,632][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.0595, 0.0235, 0.1994, 0.2492, 0.2627, 0.0235, 0.0208, 0.0946, 0.0668],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,634][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.0354, 0.0469, 0.0815, 0.1156, 0.1652, 0.2848, 0.0682, 0.1677, 0.0346],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,635][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.0934, 0.1261, 0.0859, 0.0932, 0.1540, 0.1290, 0.0713, 0.1345, 0.1125],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,636][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ in] are: tensor([0.0778, 0.1252, 0.0400, 0.0954, 0.1758, 0.1085, 0.0818, 0.2405, 0.0551],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,638][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.0923, 0.0798, 0.0615, 0.0769, 0.1555, 0.2521, 0.0521, 0.1686, 0.0612],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,640][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.0957, 0.1122, 0.0709, 0.0879, 0.1665, 0.1331, 0.0670, 0.1876, 0.0792],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,641][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.0864, 0.0884, 0.0881, 0.1547, 0.1442, 0.0986, 0.0615, 0.2127, 0.0654],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,643][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.1030, 0.0946, 0.0420, 0.0631, 0.1411, 0.1483, 0.0609, 0.2474, 0.0996],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,645][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.1262, 0.0793, 0.0930, 0.1155, 0.1244, 0.1348, 0.0853, 0.1472, 0.0944],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,646][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.1258, 0.1091, 0.0593, 0.1215, 0.1227, 0.0755, 0.0962, 0.1815, 0.1083],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,648][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.0939, 0.0790, 0.0582, 0.1194, 0.1445, 0.1202, 0.0973, 0.1887, 0.0989],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,650][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.1076, 0.1005, 0.0690, 0.1237, 0.1321, 0.1539, 0.0746, 0.1017, 0.1370],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,680][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:28,681][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,682][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,684][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,685][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,686][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,688][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,689][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,690][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,692][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,693][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,695][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,696][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,696][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.7033, 0.2967], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,697][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.5442, 0.4558], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,697][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.4087, 0.5913], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,697][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.4899, 0.5101], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,698][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.6409, 0.3591], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,698][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.5546, 0.4454], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,698][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.4948, 0.5052], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,699][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.5958, 0.4042], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,699][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.6243, 0.3757], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,699][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.5144, 0.4856], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,699][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.5530, 0.4470], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,700][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.5845, 0.4155], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,702][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.2153, 0.1082, 0.6766], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,704][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.2885, 0.3528, 0.3587], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,705][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.3400, 0.4320, 0.2280], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,706][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.3683, 0.4563, 0.1754], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,708][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.4338, 0.3288, 0.2374], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,710][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.3778, 0.3879, 0.2343], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,711][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.3156, 0.3418, 0.3425], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,713][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.4217, 0.4247, 0.1537], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,715][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.4031, 0.3379, 0.2591], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,717][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.4181, 0.3502, 0.2316], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,718][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.3946, 0.3261, 0.2793], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,720][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.4300, 0.3305, 0.2395], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,722][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.0863, 0.0344, 0.4346, 0.4446], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,723][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.1519, 0.1792, 0.3276, 0.3413], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,725][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.2428, 0.3427, 0.1948, 0.2197], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,727][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.2471, 0.3360, 0.1366, 0.2802], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,728][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.3700, 0.2446, 0.1615, 0.2240], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,730][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.2739, 0.2726, 0.2824, 0.1712], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,732][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.2421, 0.2521, 0.2022, 0.3036], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,733][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.3817, 0.3137, 0.1463, 0.1584], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,735][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.3108, 0.2287, 0.2021, 0.2584], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,737][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.2971, 0.2633, 0.1517, 0.2879], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,738][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.2759, 0.2246, 0.1829, 0.3166], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,740][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.2418, 0.2575, 0.1891, 0.3116], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,742][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.0650, 0.0322, 0.2791, 0.3264, 0.2973], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,744][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.1230, 0.1258, 0.1854, 0.3133, 0.2525], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,745][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.2184, 0.2267, 0.1286, 0.1876, 0.2386], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,747][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.1900, 0.2335, 0.1321, 0.1606, 0.2838], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,749][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.2433, 0.1216, 0.1195, 0.2152, 0.3004], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,750][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.2379, 0.1897, 0.1686, 0.1640, 0.2397], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,751][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.1569, 0.1303, 0.1493, 0.2674, 0.2962], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,754][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.2875, 0.1900, 0.0924, 0.1726, 0.2575], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,755][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.2342, 0.1650, 0.1880, 0.2164, 0.1964], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,757][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.2521, 0.1817, 0.1231, 0.2350, 0.2082], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,758][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.2104, 0.1442, 0.1400, 0.2398, 0.2656], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,758][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.2205, 0.1689, 0.1315, 0.2450, 0.2341], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,758][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.0717, 0.0491, 0.3331, 0.2485, 0.2391, 0.0583], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,758][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.0539, 0.0666, 0.1042, 0.2310, 0.2373, 0.3071], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,759][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.1662, 0.2238, 0.1007, 0.1304, 0.2191, 0.1599], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,759][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.1183, 0.1676, 0.0839, 0.1334, 0.2843, 0.2125], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,759][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.1609, 0.1088, 0.1104, 0.1234, 0.3036, 0.1928], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,760][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.1383, 0.1515, 0.1430, 0.1148, 0.2601, 0.1923], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,760][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.1300, 0.1530, 0.1177, 0.1729, 0.2354, 0.1910], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,760][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.1798, 0.1909, 0.0838, 0.1374, 0.2461, 0.1620], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,760][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.1762, 0.1359, 0.1551, 0.1292, 0.1673, 0.2363], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,761][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.1863, 0.1400, 0.1212, 0.1852, 0.1952, 0.1721], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,761][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.1519, 0.1075, 0.1001, 0.1869, 0.1812, 0.2724], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,763][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.1786, 0.1526, 0.0877, 0.1858, 0.1825, 0.2128], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,765][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.0647, 0.0285, 0.2738, 0.2699, 0.3059, 0.0289, 0.0283],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,766][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.0428, 0.0532, 0.1119, 0.1481, 0.1985, 0.4123, 0.0331],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,768][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.1198, 0.1762, 0.1066, 0.1350, 0.2206, 0.1434, 0.0985],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,770][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.1381, 0.1059, 0.0740, 0.1686, 0.1994, 0.1699, 0.1442],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,771][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.1258, 0.0841, 0.0686, 0.1248, 0.2418, 0.3028, 0.0521],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,773][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1278, 0.1148, 0.0989, 0.1183, 0.2387, 0.2360, 0.0657],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,775][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.1048, 0.1101, 0.1163, 0.2304, 0.1886, 0.1781, 0.0718],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,777][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.1599, 0.1309, 0.0692, 0.0851, 0.2149, 0.2696, 0.0705],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,778][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.1474, 0.1035, 0.1264, 0.1528, 0.1634, 0.2084, 0.0982],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,779][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.1769, 0.1374, 0.0719, 0.1961, 0.1546, 0.1087, 0.1543],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,782][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.1435, 0.0967, 0.0888, 0.1760, 0.1934, 0.1780, 0.1237],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,783][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.1370, 0.0933, 0.0878, 0.1863, 0.1832, 0.1979, 0.1146],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:28,784][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.0731, 0.0268, 0.2556, 0.2343, 0.2613, 0.0262, 0.0201, 0.1027],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,786][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.0438, 0.0483, 0.0967, 0.1514, 0.1527, 0.3721, 0.0566, 0.0785],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,788][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.0982, 0.1397, 0.0932, 0.1344, 0.1740, 0.1264, 0.0968, 0.1372],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,790][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([0.0907, 0.1304, 0.0899, 0.1025, 0.1417, 0.1333, 0.0957, 0.2158],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,792][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.1283, 0.0639, 0.0423, 0.0923, 0.1418, 0.2558, 0.0602, 0.2153],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,793][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.1296, 0.1052, 0.1111, 0.1038, 0.1382, 0.1860, 0.1003, 0.1259],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,795][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.0979, 0.0824, 0.1137, 0.1656, 0.1754, 0.1200, 0.0715, 0.1734],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,796][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.1323, 0.0800, 0.0486, 0.0739, 0.1483, 0.1903, 0.0826, 0.2440],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,799][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.1544, 0.0913, 0.0976, 0.1187, 0.1483, 0.1737, 0.0955, 0.1206],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,800][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.1440, 0.1048, 0.0627, 0.1412, 0.1284, 0.1017, 0.1000, 0.2172],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,801][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.1044, 0.0874, 0.0707, 0.1373, 0.1148, 0.1256, 0.1031, 0.2568],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,804][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.1329, 0.0898, 0.0762, 0.1359, 0.1426, 0.2097, 0.1011, 0.1118],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:28,805][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.0595, 0.0235, 0.1994, 0.2492, 0.2627, 0.0235, 0.0208, 0.0946, 0.0668],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,807][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.0354, 0.0469, 0.0815, 0.1156, 0.1652, 0.2848, 0.0682, 0.1677, 0.0346],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,809][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.0934, 0.1261, 0.0859, 0.0932, 0.1540, 0.1290, 0.0713, 0.1345, 0.1125],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,810][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([0.0778, 0.1252, 0.0400, 0.0954, 0.1758, 0.1085, 0.0818, 0.2405, 0.0551],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,812][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.0923, 0.0798, 0.0615, 0.0769, 0.1555, 0.2521, 0.0521, 0.1686, 0.0612],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,814][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.0957, 0.1122, 0.0709, 0.0879, 0.1665, 0.1331, 0.0670, 0.1876, 0.0792],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,816][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.0864, 0.0884, 0.0881, 0.1547, 0.1442, 0.0986, 0.0615, 0.2127, 0.0654],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,817][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.1030, 0.0946, 0.0420, 0.0631, 0.1411, 0.1483, 0.0609, 0.2474, 0.0996],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,818][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.1262, 0.0793, 0.0930, 0.1155, 0.1244, 0.1348, 0.0853, 0.1472, 0.0944],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,819][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.1258, 0.1091, 0.0593, 0.1215, 0.1227, 0.0755, 0.0962, 0.1815, 0.1083],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,819][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.0939, 0.0790, 0.0582, 0.1194, 0.1445, 0.1202, 0.0973, 0.1887, 0.0989],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,819][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.1076, 0.1005, 0.0690, 0.1237, 0.1321, 0.1539, 0.0746, 0.1017, 0.1370],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:28,820][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:28,821][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[640],
        [  2],
        [  4],
        [ 12],
        [  3],
        [  2],
        [ 14],
        [ 44],
        [ 21]], device='cuda:0')
[2024-07-23 21:06:28,822][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[746],
        [  3],
        [  3],
        [ 13],
        [  3],
        [  2],
        [ 16],
        [ 53],
        [ 36]], device='cuda:0')
[2024-07-23 21:06:28,823][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[ 6],
        [19],
        [80],
        [12],
        [13],
        [14],
        [15],
        [17],
        [15]], device='cuda:0')
[2024-07-23 21:06:28,825][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[31536],
        [42626],
        [38500],
        [35017],
        [29035],
        [32144],
        [32541],
        [34892],
        [37325]], device='cuda:0')
[2024-07-23 21:06:28,826][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[14749],
        [14600],
        [15692],
        [20022],
        [24457],
        [21103],
        [22010],
        [23208],
        [23421]], device='cuda:0')
[2024-07-23 21:06:28,827][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[159],
        [226],
        [216],
        [280],
        [321],
        [199],
        [136],
        [209],
        [246]], device='cuda:0')
[2024-07-23 21:06:28,829][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 427],
        [ 450],
        [ 396],
        [ 312],
        [ 311],
        [ 610],
        [ 993],
        [1201],
        [1202]], device='cuda:0')
[2024-07-23 21:06:28,830][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[3217],
        [2975],
        [2324],
        [2439],
        [2924],
        [2434],
        [2363],
        [2151],
        [2079]], device='cuda:0')
[2024-07-23 21:06:28,832][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[1674],
        [4224],
        [3150],
        [4664],
        [6545],
        [5399],
        [5454],
        [6889],
        [7712]], device='cuda:0')
[2024-07-23 21:06:28,833][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[14860],
        [14586],
        [12844],
        [13044],
        [14722],
        [14732],
        [15398],
        [16762],
        [17498]], device='cuda:0')
[2024-07-23 21:06:28,834][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[1324],
        [ 971],
        [ 636],
        [ 554],
        [ 459],
        [ 359],
        [ 336],
        [ 447],
        [ 524]], device='cuda:0')
[2024-07-23 21:06:28,835][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[13355],
        [13293],
        [11466],
        [ 9028],
        [ 9067],
        [10731],
        [10544],
        [10910],
        [10664]], device='cuda:0')
[2024-07-23 21:06:28,837][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[12790],
        [ 8260],
        [ 7896],
        [ 5295],
        [ 5812],
        [ 6649],
        [ 5244],
        [ 4029],
        [ 4529]], device='cuda:0')
[2024-07-23 21:06:28,838][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[1574],
        [1240],
        [1419],
        [1194],
        [1218],
        [1481],
        [1494],
        [1413],
        [1271]], device='cuda:0')
[2024-07-23 21:06:28,840][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[20],
        [74],
        [42],
        [15],
        [16],
        [82],
        [ 5],
        [ 7],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:28,841][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[15260],
        [16980],
        [12920],
        [24991],
        [32077],
        [28934],
        [30744],
        [28727],
        [29244]], device='cuda:0')
[2024-07-23 21:06:28,843][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[1412],
        [ 887],
        [ 361],
        [ 314],
        [ 283],
        [  26],
        [   7],
        [  13],
        [  33]], device='cuda:0')
[2024-07-23 21:06:28,844][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[414],
        [560],
        [403],
        [200],
        [273],
        [259],
        [259],
        [236],
        [188]], device='cuda:0')
[2024-07-23 21:06:28,845][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[6622],
        [2716],
        [2270],
        [3667],
        [3436],
        [2842],
        [3184],
        [3409],
        [3858]], device='cuda:0')
[2024-07-23 21:06:28,847][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[3977],
        [1179],
        [ 505],
        [ 633],
        [ 294],
        [ 663],
        [ 842],
        [ 599],
        [ 511]], device='cuda:0')
[2024-07-23 21:06:28,848][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[340],
        [321],
        [439],
        [410],
        [233],
        [276],
        [323],
        [524],
        [436]], device='cuda:0')
[2024-07-23 21:06:28,850][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[ 37],
        [121],
        [ 80],
        [168],
        [234],
        [149],
        [183],
        [324],
        [288]], device='cuda:0')
[2024-07-23 21:06:28,851][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[175],
        [144],
        [261],
        [245],
        [ 57],
        [ 35],
        [ 17],
        [ 24],
        [ 16]], device='cuda:0')
[2024-07-23 21:06:28,852][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[1452],
        [ 974],
        [1185],
        [ 868],
        [ 862],
        [1766],
        [1574],
        [2302],
        [2361]], device='cuda:0')
[2024-07-23 21:06:28,854][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[168],
        [125],
        [175],
        [154],
        [101],
        [ 65],
        [ 58],
        [ 29],
        [ 28]], device='cuda:0')
[2024-07-23 21:06:28,855][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[1],
        [1],
        [2],
        [2],
        [2],
        [5],
        [3],
        [2],
        [2]], device='cuda:0')
[2024-07-23 21:06:28,857][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 8680],
        [14397],
        [ 8953],
        [ 9180],
        [10328],
        [ 9157],
        [ 8822],
        [ 9479],
        [11197]], device='cuda:0')
[2024-07-23 21:06:28,858][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[32708],
        [30707],
        [34233],
        [33118],
        [38499],
        [38662],
        [41023],
        [42367],
        [42832]], device='cuda:0')
[2024-07-23 21:06:28,860][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[39776],
        [39181],
        [40088],
        [40920],
        [39326],
        [37902],
        [46562],
        [44441],
        [48707]], device='cuda:0')
[2024-07-23 21:06:28,861][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[38],
        [38],
        [38],
        [38],
        [38],
        [38],
        [38],
        [38],
        [38]], device='cuda:0')
[2024-07-23 21:06:28,904][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:28,906][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,907][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,909][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,910][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,912][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,913][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,914][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,916][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,917][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,918][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,920][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,921][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:28,923][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.4079, 0.5921], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,925][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.4107, 0.5893], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,926][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.4279, 0.5721], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,928][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.7056, 0.2944], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,930][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.2832, 0.7168], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,931][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.3354, 0.6646], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,933][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.4290, 0.5710], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,935][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.6245, 0.3755], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,936][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.3981, 0.6019], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,938][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.2079, 0.7921], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,940][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.5988, 0.4012], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,941][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.3147, 0.6853], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:28,942][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.2040, 0.3855, 0.4105], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,943][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.2335, 0.3376, 0.4289], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,943][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.2775, 0.4529, 0.2696], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,943][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.4563, 0.3861, 0.1576], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,944][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.1932, 0.4920, 0.3147], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,944][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.2045, 0.4414, 0.3541], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,944][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.2560, 0.3976, 0.3464], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,944][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.3535, 0.3686, 0.2779], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,945][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.3057, 0.4487, 0.2456], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,945][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.0486, 0.3616, 0.5899], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,945][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.4304, 0.4406, 0.1290], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,945][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.1944, 0.4346, 0.3710], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:28,946][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.1561, 0.3629, 0.2340, 0.2470], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,946][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.1632, 0.2662, 0.3995, 0.1711], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,948][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.2142, 0.3131, 0.2258, 0.2469], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,950][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.4103, 0.2730, 0.1940, 0.1228], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,951][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.1375, 0.3701, 0.1166, 0.3758], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,952][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.2263, 0.3697, 0.2529, 0.1512], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,953][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.1227, 0.2745, 0.2209, 0.3819], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,955][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.2589, 0.3149, 0.2213, 0.2049], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,956][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.2216, 0.2839, 0.2093, 0.2852], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,958][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.0446, 0.1925, 0.2497, 0.5132], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,959][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.3999, 0.2938, 0.1156, 0.1907], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,961][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.1223, 0.2708, 0.4214, 0.1855], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:28,963][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.1426, 0.1874, 0.1750, 0.2282, 0.2668], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,964][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.1088, 0.1358, 0.3751, 0.0953, 0.2850], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,967][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.1679, 0.1963, 0.1885, 0.2238, 0.2235], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,968][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.3276, 0.1454, 0.1234, 0.1628, 0.2407], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,969][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.0968, 0.1994, 0.1048, 0.2298, 0.3692], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,971][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.1431, 0.2613, 0.1710, 0.0902, 0.3343], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,973][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.0909, 0.1206, 0.2545, 0.3122, 0.2218], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,975][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.2403, 0.1974, 0.1390, 0.1509, 0.2724], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,976][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.1272, 0.2067, 0.1212, 0.2764, 0.2685], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,978][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.0293, 0.0848, 0.2349, 0.3653, 0.2857], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,980][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.2313, 0.1426, 0.0708, 0.2861, 0.2691], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,981][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.0772, 0.1358, 0.1552, 0.1723, 0.4596], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:28,983][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.0794, 0.0972, 0.1579, 0.0889, 0.2165, 0.3602], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,985][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.0555, 0.1154, 0.1662, 0.0536, 0.1404, 0.4689], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,986][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.1368, 0.1793, 0.1622, 0.1991, 0.1779, 0.1446], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,988][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.1750, 0.1225, 0.1075, 0.1037, 0.2595, 0.2318], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,990][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.0756, 0.1845, 0.1037, 0.2271, 0.2166, 0.1925], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,991][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.0824, 0.1469, 0.1694, 0.0562, 0.2019, 0.3432], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,993][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.0573, 0.1857, 0.1178, 0.2432, 0.2074, 0.1886], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,995][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.1785, 0.1681, 0.1219, 0.1502, 0.1878, 0.1935], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,997][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.1270, 0.1641, 0.1134, 0.1450, 0.2320, 0.2185], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:28,998][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.0059, 0.0417, 0.0494, 0.1436, 0.1846, 0.5747], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,000][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.1606, 0.1157, 0.0605, 0.1356, 0.2376, 0.2900], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,002][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.0476, 0.1698, 0.1040, 0.0957, 0.3093, 0.2736], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,003][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.0697, 0.1306, 0.1424, 0.2052, 0.1655, 0.1581, 0.1285],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,004][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.0436, 0.0646, 0.1507, 0.0555, 0.1418, 0.5301, 0.0136],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,004][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.1158, 0.1423, 0.1094, 0.1966, 0.1889, 0.1111, 0.1359],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,004][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.1257, 0.0852, 0.0698, 0.0657, 0.1637, 0.4317, 0.0583],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,005][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.0782, 0.1625, 0.0802, 0.2514, 0.1675, 0.1248, 0.1355],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,005][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.0952, 0.1732, 0.1160, 0.0640, 0.2442, 0.1977, 0.1096],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,005][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.0434, 0.0796, 0.1061, 0.2505, 0.1473, 0.2734, 0.0997],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,006][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.1494, 0.1202, 0.0905, 0.1534, 0.1679, 0.2300, 0.0886],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,006][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.1027, 0.1381, 0.1046, 0.1418, 0.1442, 0.2469, 0.1216],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,006][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.0103, 0.0294, 0.0614, 0.1933, 0.1550, 0.4678, 0.0829],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,006][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.1509, 0.1046, 0.0456, 0.1467, 0.2418, 0.2573, 0.0530],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,007][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.0387, 0.1059, 0.0872, 0.0956, 0.2540, 0.3264, 0.0922],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,007][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.0915, 0.1248, 0.1159, 0.1553, 0.1638, 0.1033, 0.1209, 0.1245],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,008][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.0553, 0.0966, 0.2022, 0.0431, 0.1751, 0.3614, 0.0153, 0.0509],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,009][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.1142, 0.1168, 0.0910, 0.1689, 0.1824, 0.1126, 0.0995, 0.1145],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,011][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ written] are: tensor([0.1428, 0.0623, 0.0629, 0.0710, 0.1295, 0.3704, 0.0667, 0.0945],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,013][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.0382, 0.0966, 0.0419, 0.1048, 0.0841, 0.0875, 0.0703, 0.4765],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,014][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.0782, 0.1185, 0.0859, 0.0573, 0.1504, 0.1237, 0.0764, 0.3097],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,016][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.0295, 0.0889, 0.0951, 0.1459, 0.1253, 0.2179, 0.0704, 0.2270],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,018][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.1401, 0.1008, 0.1010, 0.1046, 0.1673, 0.1844, 0.0938, 0.1078],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,019][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.0653, 0.1245, 0.0977, 0.1682, 0.1929, 0.1761, 0.0968, 0.0787],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,021][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.0183, 0.0480, 0.0913, 0.1925, 0.1318, 0.4050, 0.0846, 0.0285],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,023][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.1747, 0.0729, 0.0289, 0.1320, 0.1118, 0.2226, 0.0540, 0.2030],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,024][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.0448, 0.0804, 0.0808, 0.0775, 0.2171, 0.2930, 0.0889, 0.1175],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,025][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.0494, 0.0971, 0.1259, 0.1266, 0.1679, 0.1270, 0.0831, 0.1432, 0.0796],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,028][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.0514, 0.0874, 0.1681, 0.0328, 0.1313, 0.4139, 0.0144, 0.0418, 0.0588],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,029][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.0836, 0.1167, 0.0909, 0.1138, 0.1391, 0.0884, 0.0807, 0.1843, 0.1024],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,031][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ in] are: tensor([0.1143, 0.0631, 0.0472, 0.0450, 0.1274, 0.3301, 0.0530, 0.1565, 0.0634],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,033][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.0423, 0.1256, 0.0312, 0.1202, 0.1611, 0.0619, 0.0742, 0.3210, 0.0625],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,034][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.0720, 0.1214, 0.0855, 0.0507, 0.1588, 0.1158, 0.0572, 0.2130, 0.1258],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,036][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.0312, 0.0798, 0.0976, 0.1199, 0.1034, 0.1261, 0.0681, 0.2504, 0.1234],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,038][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.1307, 0.1338, 0.0839, 0.0901, 0.1490, 0.1585, 0.0764, 0.1273, 0.0503],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,040][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.0713, 0.1356, 0.0612, 0.1047, 0.1664, 0.1674, 0.0804, 0.0857, 0.1273],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,041][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.0083, 0.0532, 0.0466, 0.1441, 0.1118, 0.2766, 0.0604, 0.0432, 0.2559],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,043][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.1159, 0.0761, 0.0345, 0.0860, 0.1514, 0.1898, 0.0623, 0.2163, 0.0676],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,045][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.0348, 0.0904, 0.0803, 0.0657, 0.2138, 0.2447, 0.0861, 0.1032, 0.0810],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,088][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:29,088][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,089][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,089][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,089][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,090][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,090][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,090][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,091][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,091][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,091][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,091][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,092][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,092][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.4079, 0.5921], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,092][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.4107, 0.5893], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,093][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.4279, 0.5721], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,093][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.7056, 0.2944], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,093][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.2832, 0.7168], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,094][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.3354, 0.6646], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,094][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.4290, 0.5710], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,094][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.6245, 0.3755], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,095][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.3981, 0.6019], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,096][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.2079, 0.7921], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,098][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.5988, 0.4012], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,099][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.3147, 0.6853], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,101][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.2040, 0.3855, 0.4105], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,102][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.2335, 0.3376, 0.4289], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,104][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.2775, 0.4529, 0.2696], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,106][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.4563, 0.3861, 0.1576], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,108][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.1932, 0.4920, 0.3147], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,109][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.2045, 0.4414, 0.3541], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,111][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.2560, 0.3976, 0.3464], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,113][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.3535, 0.3686, 0.2779], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,114][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.3057, 0.4487, 0.2456], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,115][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.0486, 0.3616, 0.5899], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,118][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.4304, 0.4406, 0.1290], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,119][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.1944, 0.4346, 0.3710], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,121][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.1561, 0.3629, 0.2340, 0.2470], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,122][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.1632, 0.2662, 0.3995, 0.1711], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,124][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.2142, 0.3131, 0.2258, 0.2469], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,126][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.4103, 0.2730, 0.1940, 0.1228], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,127][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.1375, 0.3701, 0.1166, 0.3758], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,129][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.2263, 0.3697, 0.2529, 0.1512], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,131][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.1227, 0.2745, 0.2209, 0.3819], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,132][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.2589, 0.3149, 0.2213, 0.2049], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,134][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.2216, 0.2839, 0.2093, 0.2852], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,136][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.0446, 0.1925, 0.2497, 0.5132], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,137][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.3999, 0.2938, 0.1156, 0.1907], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,139][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.1223, 0.2708, 0.4214, 0.1855], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,141][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.1426, 0.1874, 0.1750, 0.2282, 0.2668], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,143][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.1088, 0.1358, 0.3751, 0.0953, 0.2850], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,144][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.1679, 0.1963, 0.1885, 0.2238, 0.2235], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,146][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.3276, 0.1454, 0.1234, 0.1628, 0.2407], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,148][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.0968, 0.1994, 0.1048, 0.2298, 0.3692], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,149][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.1431, 0.2613, 0.1710, 0.0902, 0.3343], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,149][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.0909, 0.1206, 0.2545, 0.3122, 0.2218], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,150][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.2403, 0.1974, 0.1390, 0.1509, 0.2724], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,150][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.1272, 0.2067, 0.1212, 0.2764, 0.2685], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,150][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.0293, 0.0848, 0.2349, 0.3653, 0.2857], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,150][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.2313, 0.1426, 0.0708, 0.2861, 0.2691], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,151][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.0772, 0.1358, 0.1552, 0.1723, 0.4596], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,151][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.0794, 0.0972, 0.1579, 0.0889, 0.2165, 0.3602], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,151][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.0555, 0.1154, 0.1662, 0.0536, 0.1404, 0.4689], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,152][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.1368, 0.1793, 0.1622, 0.1991, 0.1779, 0.1446], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,152][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.1750, 0.1225, 0.1075, 0.1037, 0.2595, 0.2318], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,153][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.0756, 0.1845, 0.1037, 0.2271, 0.2166, 0.1925], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,154][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.0824, 0.1469, 0.1694, 0.0562, 0.2019, 0.3432], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,156][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.0573, 0.1857, 0.1178, 0.2432, 0.2074, 0.1886], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,157][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.1785, 0.1681, 0.1219, 0.1502, 0.1878, 0.1935], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,159][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.1270, 0.1641, 0.1134, 0.1450, 0.2320, 0.2185], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,161][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.0059, 0.0417, 0.0494, 0.1436, 0.1846, 0.5747], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,162][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.1606, 0.1157, 0.0605, 0.1356, 0.2376, 0.2900], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,164][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.0476, 0.1698, 0.1040, 0.0957, 0.3093, 0.2736], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,166][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.0697, 0.1306, 0.1424, 0.2052, 0.1655, 0.1581, 0.1285],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,168][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.0436, 0.0646, 0.1507, 0.0555, 0.1418, 0.5301, 0.0136],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,169][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.1158, 0.1423, 0.1094, 0.1966, 0.1889, 0.1111, 0.1359],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,170][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.1257, 0.0852, 0.0698, 0.0657, 0.1637, 0.4317, 0.0583],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,173][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0782, 0.1625, 0.0802, 0.2514, 0.1675, 0.1248, 0.1355],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,174][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.0952, 0.1732, 0.1160, 0.0640, 0.2442, 0.1977, 0.1096],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,175][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.0434, 0.0796, 0.1061, 0.2505, 0.1473, 0.2734, 0.0997],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,177][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.1494, 0.1202, 0.0905, 0.1534, 0.1679, 0.2300, 0.0886],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,179][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.1027, 0.1381, 0.1046, 0.1418, 0.1442, 0.2469, 0.1216],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,181][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.0103, 0.0294, 0.0614, 0.1933, 0.1550, 0.4678, 0.0829],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,183][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.1509, 0.1046, 0.0456, 0.1467, 0.2418, 0.2573, 0.0530],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,184][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.0387, 0.1059, 0.0872, 0.0956, 0.2540, 0.3264, 0.0922],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,186][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.0915, 0.1248, 0.1159, 0.1553, 0.1638, 0.1033, 0.1209, 0.1245],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,187][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.0553, 0.0966, 0.2022, 0.0431, 0.1751, 0.3614, 0.0153, 0.0509],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,189][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.1142, 0.1168, 0.0910, 0.1689, 0.1824, 0.1126, 0.0995, 0.1145],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,191][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([0.1428, 0.0623, 0.0629, 0.0710, 0.1295, 0.3704, 0.0667, 0.0945],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,192][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.0382, 0.0966, 0.0419, 0.1048, 0.0841, 0.0875, 0.0703, 0.4765],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,195][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.0782, 0.1185, 0.0859, 0.0573, 0.1504, 0.1237, 0.0764, 0.3097],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,196][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.0295, 0.0889, 0.0951, 0.1459, 0.1253, 0.2179, 0.0704, 0.2270],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,198][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.1401, 0.1008, 0.1010, 0.1046, 0.1673, 0.1844, 0.0938, 0.1078],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,200][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.0653, 0.1245, 0.0977, 0.1682, 0.1929, 0.1761, 0.0968, 0.0787],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,201][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.0183, 0.0480, 0.0913, 0.1925, 0.1318, 0.4050, 0.0846, 0.0285],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,203][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.1747, 0.0729, 0.0289, 0.1320, 0.1118, 0.2226, 0.0540, 0.2030],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,205][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.0448, 0.0804, 0.0808, 0.0775, 0.2171, 0.2930, 0.0889, 0.1175],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,207][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.0494, 0.0971, 0.1259, 0.1266, 0.1679, 0.1270, 0.0831, 0.1432, 0.0796],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,208][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.0514, 0.0874, 0.1681, 0.0328, 0.1313, 0.4139, 0.0144, 0.0418, 0.0588],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,209][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.0836, 0.1167, 0.0909, 0.1138, 0.1391, 0.0884, 0.0807, 0.1843, 0.1024],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,210][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([0.1143, 0.0631, 0.0472, 0.0450, 0.1274, 0.3301, 0.0530, 0.1565, 0.0634],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,210][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.0423, 0.1256, 0.0312, 0.1202, 0.1611, 0.0619, 0.0742, 0.3210, 0.0625],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,210][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.0720, 0.1214, 0.0855, 0.0507, 0.1588, 0.1158, 0.0572, 0.2130, 0.1258],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,211][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.0312, 0.0798, 0.0976, 0.1199, 0.1034, 0.1261, 0.0681, 0.2504, 0.1234],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,211][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.1307, 0.1338, 0.0839, 0.0901, 0.1490, 0.1585, 0.0764, 0.1273, 0.0503],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,211][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.0713, 0.1356, 0.0612, 0.1047, 0.1664, 0.1674, 0.0804, 0.0857, 0.1273],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,212][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.0083, 0.0532, 0.0466, 0.1441, 0.1118, 0.2766, 0.0604, 0.0432, 0.2559],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,212][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.1159, 0.0761, 0.0345, 0.0860, 0.1514, 0.1898, 0.0623, 0.2163, 0.0676],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,212][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.0348, 0.0904, 0.0803, 0.0657, 0.2138, 0.2447, 0.0861, 0.1032, 0.0810],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,213][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:29,214][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[6],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:29,216][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[12],
        [ 1],
        [ 1],
        [ 1],
        [ 2],
        [ 1],
        [ 1],
        [ 4],
        [ 2]], device='cuda:0')
[2024-07-23 21:06:29,217][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[2789],
        [3168],
        [4031],
        [5421],
        [6630],
        [5891],
        [7382],
        [7598],
        [7628]], device='cuda:0')
[2024-07-23 21:06:29,219][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[ 669],
        [1534],
        [1640],
        [1490],
        [1221],
        [ 775],
        [ 758],
        [ 851],
        [ 776]], device='cuda:0')
[2024-07-23 21:06:29,220][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[4443],
        [4338],
        [5223],
        [4623],
        [4674],
        [5049],
        [4970],
        [5304],
        [5838]], device='cuda:0')
[2024-07-23 21:06:29,221][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[6553],
        [7048],
        [5419],
        [5484],
        [7439],
        [5648],
        [4315],
        [4574],
        [4818]], device='cuda:0')
[2024-07-23 21:06:29,222][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[1137],
        [ 301],
        [ 587],
        [1858],
        [1963],
        [1916],
        [2219],
        [6019],
        [4130]], device='cuda:0')
[2024-07-23 21:06:29,224][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[9957],
        [2950],
        [1721],
        [1803],
        [1978],
        [5612],
        [3890],
        [3478],
        [3752]], device='cuda:0')
[2024-07-23 21:06:29,225][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[3892],
        [3785],
        [3546],
        [3738],
        [3546],
        [4030],
        [4263],
        [3739],
        [3546]], device='cuda:0')
[2024-07-23 21:06:29,226][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[1301],
        [2677],
        [3113],
        [4531],
        [5257],
        [5594],
        [5821],
        [6602],
        [6577]], device='cuda:0')
[2024-07-23 21:06:29,227][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[4508],
        [2791],
        [3080],
        [3098],
        [3282],
        [3138],
        [2802],
        [2748],
        [2753]], device='cuda:0')
[2024-07-23 21:06:29,229][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[5280],
        [4131],
        [3488],
        [3784],
        [3880],
        [4204],
        [4287],
        [4261],
        [4419]], device='cuda:0')
[2024-07-23 21:06:29,231][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[4025],
        [3222],
        [3521],
        [3104],
        [2621],
        [1585],
        [1605],
        [2221],
        [2353]], device='cuda:0')
[2024-07-23 21:06:29,232][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[21054],
        [18943],
        [17429],
        [19497],
        [20240],
        [16056],
        [15245],
        [16423],
        [19346]], device='cuda:0')
[2024-07-23 21:06:29,233][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[29],
        [33],
        [ 6],
        [21],
        [22],
        [85],
        [16],
        [10],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:29,235][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[246],
        [627],
        [ 74],
        [115],
        [ 47],
        [206],
        [ 64],
        [ 86],
        [ 82]], device='cuda:0')
[2024-07-23 21:06:29,236][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[1137],
        [  51],
        [   8],
        [   8],
        [   2],
        [ 266],
        [ 340],
        [  89],
        [ 174]], device='cuda:0')
[2024-07-23 21:06:29,238][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[296],
        [771],
        [380],
        [395],
        [478],
        [295],
        [331],
        [428],
        [353]], device='cuda:0')
[2024-07-23 21:06:29,239][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[ 9],
        [10],
        [11],
        [ 8],
        [19],
        [32],
        [44],
        [43],
        [43]], device='cuda:0')
[2024-07-23 21:06:29,241][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 122],
        [  73],
        [  17],
        [1026],
        [ 938],
        [1130],
        [1752],
        [2540],
        [2823]], device='cuda:0')
[2024-07-23 21:06:29,242][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[408],
        [495],
        [530],
        [478],
        [ 96],
        [ 30],
        [ 24],
        [  4],
        [  9]], device='cuda:0')
[2024-07-23 21:06:29,243][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[1501],
        [ 771],
        [1189],
        [2279],
        [4329],
        [1746],
        [2193],
        [2074],
        [3187]], device='cuda:0')
[2024-07-23 21:06:29,245][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 5],
        [ 9],
        [55],
        [19],
        [ 6],
        [12],
        [14],
        [ 7],
        [ 6]], device='cuda:0')
[2024-07-23 21:06:29,246][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[2049],
        [ 354],
        [ 331],
        [ 738],
        [ 820],
        [ 452],
        [ 574],
        [ 692],
        [ 623]], device='cuda:0')
[2024-07-23 21:06:29,248][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[ 169],
        [1064],
        [3593],
        [5130],
        [3497],
        [4261],
        [4275],
        [4598],
        [7357]], device='cuda:0')
[2024-07-23 21:06:29,249][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[836],
        [719],
        [325],
        [239],
        [210],
        [233],
        [306],
        [270],
        [292]], device='cuda:0')
[2024-07-23 21:06:29,250][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 42],
        [416],
        [268],
        [337],
        [182],
        [507],
        [659],
        [906],
        [586]], device='cuda:0')
[2024-07-23 21:06:29,252][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[35588],
        [41666],
        [44473],
        [42075],
        [47818],
        [47545],
        [46986],
        [47258],
        [46684]], device='cuda:0')
[2024-07-23 21:06:29,253][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[47423],
        [44790],
        [48654],
        [46937],
        [45239],
        [32005],
        [44382],
        [45410],
        [49384]], device='cuda:0')
[2024-07-23 21:06:29,255][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[25],
        [25],
        [25],
        [25],
        [25],
        [25],
        [25],
        [25],
        [25]], device='cuda:0')
[2024-07-23 21:06:29,289][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:29,291][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,292][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,293][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,294][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,295][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,296][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,296][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,296][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,296][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,297][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,298][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,299][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,301][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.3261, 0.6739], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,303][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.2584, 0.7416], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,305][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.4026, 0.5974], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,306][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.5204, 0.4796], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,307][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.5683, 0.4317], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,310][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.8330, 0.1670], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,311][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.2154, 0.7846], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,313][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.4543, 0.5457], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,314][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.2719, 0.7281], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,316][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.8435, 0.1565], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,318][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.3103, 0.6897], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,319][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.5221, 0.4779], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,321][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.1380, 0.4380, 0.4240], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,323][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.0313, 0.2296, 0.7391], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,324][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.1760, 0.4198, 0.4042], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,326][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.3698, 0.3951, 0.2351], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,328][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.3582, 0.4635, 0.1783], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,329][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.6612, 0.2102, 0.1286], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,331][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.0721, 0.4057, 0.5222], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,333][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.1858, 0.3222, 0.4919], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,335][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.1231, 0.4590, 0.4179], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,336][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.7492, 0.1914, 0.0593], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,338][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.1687, 0.6954, 0.1359], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,340][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.0949, 0.1883, 0.7169], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,341][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.1802, 0.3512, 0.2434, 0.2252], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,341][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.0658, 0.2402, 0.6141, 0.0798], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,342][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.1373, 0.2086, 0.2587, 0.3954], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,342][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.2738, 0.4160, 0.1512, 0.1590], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,342][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.4361, 0.3187, 0.1320, 0.1131], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,342][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.5428, 0.1526, 0.1170, 0.1875], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,343][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.0563, 0.3132, 0.2891, 0.3414], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,343][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.2935, 0.2901, 0.2493, 0.1670], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,343][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.1218, 0.3514, 0.3915, 0.1353], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,344][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.6046, 0.1367, 0.0582, 0.2005], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,344][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.1961, 0.5804, 0.1802, 0.0432], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,344][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.1667, 0.1700, 0.5130, 0.1503], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,344][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.1350, 0.3086, 0.1733, 0.1668, 0.2163], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,345][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.0447, 0.1441, 0.6374, 0.0631, 0.1107], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,345][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.1014, 0.1586, 0.2124, 0.3637, 0.1639], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,346][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.2666, 0.2650, 0.1568, 0.2270, 0.0846], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,347][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.3773, 0.2415, 0.1506, 0.0931, 0.1375], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,349][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.3624, 0.0851, 0.0426, 0.1209, 0.3891], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,350][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.0476, 0.2241, 0.2617, 0.2449, 0.2216], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,352][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.1857, 0.1897, 0.1897, 0.0786, 0.3563], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,352][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.0763, 0.2683, 0.2402, 0.1182, 0.2971], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,354][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.3829, 0.0765, 0.0369, 0.1652, 0.3385], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,356][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.1522, 0.3310, 0.1252, 0.0525, 0.3389], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,357][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.1511, 0.0981, 0.3638, 0.1687, 0.2184], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,359][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.0637, 0.2253, 0.1465, 0.1492, 0.1454, 0.2699], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,361][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.0202, 0.1474, 0.5305, 0.0409, 0.1805, 0.0805], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,362][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.0502, 0.1331, 0.1374, 0.1781, 0.1048, 0.3963], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,364][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.1168, 0.2328, 0.0785, 0.1005, 0.0747, 0.3967], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,366][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.2045, 0.1775, 0.1336, 0.0798, 0.0867, 0.3179], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,367][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.2103, 0.0587, 0.0647, 0.1065, 0.3283, 0.2314], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,369][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.0178, 0.1098, 0.1960, 0.2282, 0.0934, 0.3549], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,371][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.0595, 0.0730, 0.0505, 0.0325, 0.0716, 0.7130], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,373][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([0.0472, 0.2217, 0.1883, 0.0551, 0.2577, 0.2300], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,374][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.1427, 0.0469, 0.0297, 0.1850, 0.3037, 0.2919], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,375][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.1117, 0.3391, 0.1010, 0.0500, 0.2653, 0.1331], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,378][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.0276, 0.0828, 0.2096, 0.1461, 0.1285, 0.4054], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,379][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.0991, 0.2059, 0.1187, 0.1270, 0.1568, 0.1750, 0.1175],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,380][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.0259, 0.1101, 0.4354, 0.0592, 0.1185, 0.1803, 0.0707],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,383][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.0354, 0.0838, 0.1460, 0.1633, 0.0927, 0.3521, 0.1267],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,384][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.1271, 0.1478, 0.0910, 0.1180, 0.0729, 0.3009, 0.1422],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,386][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.1480, 0.1911, 0.1149, 0.1411, 0.0784, 0.2235, 0.1030],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,388][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.1946, 0.0541, 0.0401, 0.0829, 0.2775, 0.2882, 0.0626],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,389][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.0257, 0.0999, 0.1325, 0.2290, 0.1186, 0.2369, 0.1574],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,391][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.1341, 0.1729, 0.1394, 0.0988, 0.1582, 0.1972, 0.0994],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,393][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.0368, 0.1395, 0.2175, 0.0588, 0.2433, 0.2068, 0.0974],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,395][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.1353, 0.0265, 0.0166, 0.0938, 0.2518, 0.4044, 0.0716],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,396][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.0996, 0.3001, 0.1121, 0.0399, 0.2593, 0.1724, 0.0166],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,398][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.0637, 0.0712, 0.2796, 0.1379, 0.1755, 0.1745, 0.0977],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,400][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.0607, 0.2360, 0.0911, 0.1170, 0.1046, 0.1565, 0.0931, 0.1410],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,401][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.0371, 0.1287, 0.3642, 0.0692, 0.1051, 0.1773, 0.0662, 0.0521],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,403][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.0464, 0.0720, 0.1125, 0.1388, 0.0639, 0.4224, 0.0827, 0.0614],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,403][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ written] are: tensor([0.1031, 0.1291, 0.0985, 0.1293, 0.0573, 0.2291, 0.1020, 0.1516],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,404][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.1688, 0.1347, 0.1016, 0.1440, 0.0719, 0.2144, 0.0823, 0.0824],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,404][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.1670, 0.0259, 0.0294, 0.0568, 0.2084, 0.2339, 0.0411, 0.2374],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,404][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.0301, 0.1383, 0.0968, 0.1509, 0.0973, 0.2707, 0.1150, 0.1008],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,404][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.0930, 0.0805, 0.0854, 0.0567, 0.0622, 0.1340, 0.0531, 0.4352],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,405][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.0535, 0.1129, 0.2210, 0.0716, 0.1861, 0.1270, 0.1412, 0.0867],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,405][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.1557, 0.0262, 0.0134, 0.0698, 0.1732, 0.3010, 0.0606, 0.2002],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,405][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.0789, 0.2699, 0.0548, 0.0308, 0.1626, 0.1853, 0.0089, 0.2088],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,406][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.0894, 0.0915, 0.2185, 0.0864, 0.1200, 0.1737, 0.1046, 0.1160],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,406][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.0531, 0.1839, 0.0673, 0.0741, 0.1096, 0.1049, 0.0639, 0.1425, 0.2006],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,406][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.0288, 0.1495, 0.3169, 0.0480, 0.1199, 0.1163, 0.0587, 0.0769, 0.0849],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,407][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.0452, 0.0963, 0.0843, 0.1104, 0.0878, 0.2458, 0.0791, 0.0738, 0.1773],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,409][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ in] are: tensor([0.1057, 0.1541, 0.0705, 0.0690, 0.0575, 0.1346, 0.1168, 0.1545, 0.1372],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,411][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.1703, 0.1692, 0.0901, 0.0920, 0.0973, 0.1437, 0.0826, 0.0761, 0.0788],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,412][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.1573, 0.0322, 0.0326, 0.0721, 0.1661, 0.1900, 0.0529, 0.2521, 0.0448],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,413][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.0194, 0.1253, 0.0957, 0.1641, 0.0933, 0.2110, 0.1007, 0.0703, 0.1202],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,415][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.1316, 0.1669, 0.0998, 0.0383, 0.0928, 0.2656, 0.0293, 0.0974, 0.0783],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,417][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.0449, 0.1653, 0.1610, 0.0453, 0.1726, 0.1086, 0.1259, 0.0597, 0.1167],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,419][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.1249, 0.0218, 0.0127, 0.0829, 0.1715, 0.2787, 0.0621, 0.2016, 0.0437],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,420][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.0681, 0.3173, 0.0518, 0.0211, 0.1589, 0.1011, 0.0068, 0.2612, 0.0137],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,422][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.0599, 0.0684, 0.1904, 0.1153, 0.1412, 0.1597, 0.0702, 0.1206, 0.0743],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,467][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:29,469][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,471][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,472][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,473][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,473][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,473][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,473][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,474][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,474][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,474][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,475][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,475][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,475][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.3261, 0.6739], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,476][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.2584, 0.7416], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,478][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.4026, 0.5974], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,479][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.5204, 0.4796], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,481][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.5683, 0.4317], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,482][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.8330, 0.1670], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,484][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.2154, 0.7846], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,485][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.4543, 0.5457], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,487][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.2719, 0.7281], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,488][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.8435, 0.1565], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,490][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.3103, 0.6897], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,492][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.5221, 0.4779], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,493][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.1380, 0.4380, 0.4240], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,495][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.0313, 0.2296, 0.7391], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,497][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.1760, 0.4198, 0.4042], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,499][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.3698, 0.3951, 0.2351], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,500][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.3582, 0.4635, 0.1783], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,502][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.6612, 0.2102, 0.1286], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,504][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.0721, 0.4057, 0.5222], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,505][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.1858, 0.3222, 0.4919], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,507][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.1231, 0.4590, 0.4179], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,509][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.7492, 0.1914, 0.0593], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,510][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.1687, 0.6954, 0.1359], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,512][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.0949, 0.1883, 0.7169], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,514][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.1802, 0.3512, 0.2434, 0.2252], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,515][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.0658, 0.2402, 0.6141, 0.0798], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,517][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.1373, 0.2086, 0.2587, 0.3954], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,519][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.2738, 0.4160, 0.1512, 0.1590], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,521][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.4361, 0.3187, 0.1320, 0.1131], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,522][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.5428, 0.1526, 0.1170, 0.1875], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,524][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.0563, 0.3132, 0.2891, 0.3414], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,526][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.2935, 0.2901, 0.2493, 0.1670], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,527][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.1218, 0.3514, 0.3915, 0.1353], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,529][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.6046, 0.1367, 0.0582, 0.2005], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,531][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.1961, 0.5804, 0.1802, 0.0432], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,532][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.1667, 0.1700, 0.5130, 0.1503], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,533][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.1350, 0.3086, 0.1733, 0.1668, 0.2163], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,534][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.0447, 0.1441, 0.6374, 0.0631, 0.1107], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,534][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.1014, 0.1586, 0.2124, 0.3637, 0.1639], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,534][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.2666, 0.2650, 0.1568, 0.2270, 0.0846], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,534][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.3773, 0.2415, 0.1506, 0.0931, 0.1375], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,535][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.3624, 0.0851, 0.0426, 0.1209, 0.3891], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,535][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.0476, 0.2241, 0.2617, 0.2449, 0.2216], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,535][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.1857, 0.1897, 0.1897, 0.0786, 0.3563], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,536][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.0763, 0.2683, 0.2402, 0.1182, 0.2971], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,536][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.3829, 0.0765, 0.0369, 0.1652, 0.3385], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,536][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.1522, 0.3310, 0.1252, 0.0525, 0.3389], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,536][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.1511, 0.0981, 0.3638, 0.1687, 0.2184], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,537][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.0637, 0.2253, 0.1465, 0.1492, 0.1454, 0.2699], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,537][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.0202, 0.1474, 0.5305, 0.0409, 0.1805, 0.0805], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,538][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.0502, 0.1331, 0.1374, 0.1781, 0.1048, 0.3963], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,540][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.1168, 0.2328, 0.0785, 0.1005, 0.0747, 0.3967], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,541][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.2045, 0.1775, 0.1336, 0.0798, 0.0867, 0.3179], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,543][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.2103, 0.0587, 0.0647, 0.1065, 0.3283, 0.2314], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,544][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.0178, 0.1098, 0.1960, 0.2282, 0.0934, 0.3549], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,546][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.0595, 0.0730, 0.0505, 0.0325, 0.0716, 0.7130], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,548][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.0472, 0.2217, 0.1883, 0.0551, 0.2577, 0.2300], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,549][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.1427, 0.0469, 0.0297, 0.1850, 0.3037, 0.2919], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,551][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.1117, 0.3391, 0.1010, 0.0500, 0.2653, 0.1331], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,553][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.0276, 0.0828, 0.2096, 0.1461, 0.1285, 0.4054], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,554][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.0991, 0.2059, 0.1187, 0.1270, 0.1568, 0.1750, 0.1175],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,556][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.0259, 0.1101, 0.4354, 0.0592, 0.1185, 0.1803, 0.0707],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,558][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.0354, 0.0838, 0.1460, 0.1633, 0.0927, 0.3521, 0.1267],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,559][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.1271, 0.1478, 0.0910, 0.1180, 0.0729, 0.3009, 0.1422],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,561][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.1480, 0.1911, 0.1149, 0.1411, 0.0784, 0.2235, 0.1030],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,563][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1946, 0.0541, 0.0401, 0.0829, 0.2775, 0.2882, 0.0626],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,564][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.0257, 0.0999, 0.1325, 0.2290, 0.1186, 0.2369, 0.1574],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,566][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.1341, 0.1729, 0.1394, 0.0988, 0.1582, 0.1972, 0.0994],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,567][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0368, 0.1395, 0.2175, 0.0588, 0.2433, 0.2068, 0.0974],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,569][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.1353, 0.0265, 0.0166, 0.0938, 0.2518, 0.4044, 0.0716],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,571][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.0996, 0.3001, 0.1121, 0.0399, 0.2593, 0.1724, 0.0166],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,572][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.0637, 0.0712, 0.2796, 0.1379, 0.1755, 0.1745, 0.0977],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,575][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.0607, 0.2360, 0.0911, 0.1170, 0.1046, 0.1565, 0.0931, 0.1410],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,576][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.0371, 0.1287, 0.3642, 0.0692, 0.1051, 0.1773, 0.0662, 0.0521],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,578][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.0464, 0.0720, 0.1125, 0.1388, 0.0639, 0.4224, 0.0827, 0.0614],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,579][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([0.1031, 0.1291, 0.0985, 0.1293, 0.0573, 0.2291, 0.1020, 0.1516],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,581][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.1688, 0.1347, 0.1016, 0.1440, 0.0719, 0.2144, 0.0823, 0.0824],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,583][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.1670, 0.0259, 0.0294, 0.0568, 0.2084, 0.2339, 0.0411, 0.2374],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,585][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.0301, 0.1383, 0.0968, 0.1509, 0.0973, 0.2707, 0.1150, 0.1008],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,587][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.0930, 0.0805, 0.0854, 0.0567, 0.0622, 0.1340, 0.0531, 0.4352],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,588][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.0535, 0.1129, 0.2210, 0.0716, 0.1861, 0.1270, 0.1412, 0.0867],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,590][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.1557, 0.0262, 0.0134, 0.0698, 0.1732, 0.3010, 0.0606, 0.2002],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,592][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.0789, 0.2699, 0.0548, 0.0308, 0.1626, 0.1853, 0.0089, 0.2088],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,593][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.0894, 0.0915, 0.2185, 0.0864, 0.1200, 0.1737, 0.1046, 0.1160],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,595][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.0531, 0.1839, 0.0673, 0.0741, 0.1096, 0.1049, 0.0639, 0.1425, 0.2006],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,595][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.0288, 0.1495, 0.3169, 0.0480, 0.1199, 0.1163, 0.0587, 0.0769, 0.0849],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,595][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.0452, 0.0963, 0.0843, 0.1104, 0.0878, 0.2458, 0.0791, 0.0738, 0.1773],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,596][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([0.1057, 0.1541, 0.0705, 0.0690, 0.0575, 0.1346, 0.1168, 0.1545, 0.1372],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,596][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.1703, 0.1692, 0.0901, 0.0920, 0.0973, 0.1437, 0.0826, 0.0761, 0.0788],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,596][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.1573, 0.0322, 0.0326, 0.0721, 0.1661, 0.1900, 0.0529, 0.2521, 0.0448],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,597][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.0194, 0.1253, 0.0957, 0.1641, 0.0933, 0.2110, 0.1007, 0.0703, 0.1202],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,597][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.1316, 0.1669, 0.0998, 0.0383, 0.0928, 0.2656, 0.0293, 0.0974, 0.0783],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,597][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.0449, 0.1653, 0.1610, 0.0453, 0.1726, 0.1086, 0.1259, 0.0597, 0.1167],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,598][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.1249, 0.0218, 0.0127, 0.0829, 0.1715, 0.2787, 0.0621, 0.2016, 0.0437],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,598][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.0681, 0.3173, 0.0518, 0.0211, 0.1589, 0.1011, 0.0068, 0.2612, 0.0137],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,599][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.0599, 0.0684, 0.1904, 0.1153, 0.1412, 0.1597, 0.0702, 0.1206, 0.0743],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,600][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:29,601][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[7],
        [1],
        [1],
        [1],
        [2],
        [1],
        [2],
        [2],
        [2]], device='cuda:0')
[2024-07-23 21:06:29,603][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[39],
        [ 1],
        [ 2],
        [ 1],
        [ 1],
        [ 1],
        [ 1],
        [ 2],
        [ 7]], device='cuda:0')
[2024-07-23 21:06:29,604][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[4812],
        [3331],
        [3899],
        [3646],
        [3647],
        [3847],
        [3737],
        [3552],
        [3437]], device='cuda:0')
[2024-07-23 21:06:29,605][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[4710],
        [3103],
        [2734],
        [2764],
        [2756],
        [2748],
        [2694],
        [2704],
        [2680]], device='cuda:0')
[2024-07-23 21:06:29,606][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[5648],
        [5778],
        [7052],
        [7595],
        [8143],
        [7499],
        [7700],
        [7460],
        [7810]], device='cuda:0')
[2024-07-23 21:06:29,608][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[1330],
        [2202],
        [2232],
        [2053],
        [1989],
        [1576],
        [1465],
        [1845],
        [1906]], device='cuda:0')
[2024-07-23 21:06:29,609][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 601],
        [2343],
        [3207],
        [1800],
        [2162],
        [2679],
        [1496],
        [1100],
        [ 831]], device='cuda:0')
[2024-07-23 21:06:29,610][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[13847],
        [14517],
        [14544],
        [15139],
        [11468],
        [ 8238],
        [ 7655],
        [ 8007],
        [ 8921]], device='cuda:0')
[2024-07-23 21:06:29,612][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[3506],
        [4115],
        [4988],
        [4525],
        [4963],
        [4758],
        [5015],
        [4685],
        [5175]], device='cuda:0')
[2024-07-23 21:06:29,613][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[1375],
        [1789],
        [2284],
        [1530],
        [1808],
        [3763],
        [1564],
        [1672],
        [1772]], device='cuda:0')
[2024-07-23 21:06:29,615][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[3335],
        [2380],
        [2482],
        [4753],
        [2880],
        [5022],
        [5449],
        [4820],
        [4119]], device='cuda:0')
[2024-07-23 21:06:29,616][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[ 7034],
        [10585],
        [12109],
        [11663],
        [19198],
        [18725],
        [17760],
        [14913],
        [15536]], device='cuda:0')
[2024-07-23 21:06:29,617][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[180],
        [269],
        [222],
        [116],
        [ 27],
        [ 25],
        [ 27],
        [ 33],
        [ 33]], device='cuda:0')
[2024-07-23 21:06:29,619][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[1084],
        [1284],
        [3116],
        [2580],
        [2252],
        [2112],
        [1843],
        [1743],
        [1840]], device='cuda:0')
[2024-07-23 21:06:29,621][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[13],
        [ 8],
        [ 8],
        [ 8],
        [10],
        [ 7],
        [ 9],
        [10],
        [ 7]], device='cuda:0')
[2024-07-23 21:06:29,622][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 47],
        [280],
        [133],
        [ 65],
        [154],
        [ 83],
        [ 81],
        [ 52],
        [ 55]], device='cuda:0')
[2024-07-23 21:06:29,623][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[19],
        [63],
        [53],
        [47],
        [51],
        [29],
        [15],
        [12],
        [15]], device='cuda:0')
[2024-07-23 21:06:29,624][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[31],
        [21],
        [11],
        [11],
        [ 4],
        [39],
        [52],
        [43],
        [40]], device='cuda:0')
[2024-07-23 21:06:29,626][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[ 71],
        [782],
        [269],
        [617],
        [491],
        [287],
        [472],
        [348],
        [421]], device='cuda:0')
[2024-07-23 21:06:29,628][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[15],
        [14],
        [13],
        [11],
        [12],
        [20],
        [16],
        [19],
        [16]], device='cuda:0')
[2024-07-23 21:06:29,629][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[ 76],
        [ 85],
        [111],
        [116],
        [180],
        [224],
        [230],
        [181],
        [191]], device='cuda:0')
[2024-07-23 21:06:29,630][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[15],
        [44],
        [13],
        [11],
        [ 6],
        [33],
        [20],
        [38],
        [26]], device='cuda:0')
[2024-07-23 21:06:29,632][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[52],
        [37],
        [72],
        [48],
        [83],
        [29],
        [46],
        [49],
        [44]], device='cuda:0')
[2024-07-23 21:06:29,633][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[ 39],
        [767],
        [268],
        [271],
        [215],
        [217],
        [234],
        [249],
        [436]], device='cuda:0')
[2024-07-23 21:06:29,634][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[48],
        [16],
        [11],
        [ 4],
        [ 8],
        [12],
        [14],
        [ 8],
        [ 7]], device='cuda:0')
[2024-07-23 21:06:29,636][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[298],
        [121],
        [134],
        [145],
        [ 69],
        [ 37],
        [ 37],
        [ 41],
        [ 56]], device='cuda:0')
[2024-07-23 21:06:29,638][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[245],
        [413],
        [ 65],
        [121],
        [222],
        [ 34],
        [ 99],
        [141],
        [153]], device='cuda:0')
[2024-07-23 21:06:29,639][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[4237],
        [3281],
        [6468],
        [6194],
        [5689],
        [5894],
        [4105],
        [5369],
        [5381]], device='cuda:0')
[2024-07-23 21:06:29,640][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[ 9821],
        [15601],
        [11560],
        [ 9447],
        [ 7563],
        [14698],
        [ 6743],
        [20846],
        [10749]], device='cuda:0')
[2024-07-23 21:06:29,641][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[24],
        [24],
        [24],
        [24],
        [24],
        [24],
        [24],
        [24],
        [24]], device='cuda:0')
[2024-07-23 21:06:29,688][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:29,690][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,691][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,693][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,694][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,695][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,696][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,698][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,700][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,701][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,702][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,704][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,705][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,707][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [me] are: tensor([0.6112, 0.3888], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,708][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [me] are: tensor([0.9687, 0.0313], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,710][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [me] are: tensor([0.9492, 0.0508], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,712][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [me] are: tensor([0.9744, 0.0256], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,713][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [me] are: tensor([0.8847, 0.1153], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,715][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [me] are: tensor([0.6993, 0.3007], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,717][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [me] are: tensor([0.9573, 0.0427], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,718][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [me] are: tensor([0.8506, 0.1494], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,719][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [me] are: tensor([0.9762, 0.0238], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,719][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [me] are: tensor([0.9183, 0.0817], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,720][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [me] are: tensor([0.7725, 0.2275], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,720][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [me] are: tensor([0.9527, 0.0473], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,720][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ j] are: tensor([0.3446, 0.1755, 0.4799], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,720][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ j] are: tensor([0.7144, 0.0754, 0.2102], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,721][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ j] are: tensor([0.6281, 0.1964, 0.1755], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,721][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ j] are: tensor([0.9347, 0.0510, 0.0144], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,721][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ j] are: tensor([0.3351, 0.1040, 0.5608], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,722][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ j] are: tensor([0.2620, 0.3936, 0.3444], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,722][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ j] are: tensor([0.0936, 0.0220, 0.8844], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,722][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ j] are: tensor([0.4488, 0.2573, 0.2939], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,724][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ j] are: tensor([0.9822, 0.0099, 0.0080], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,726][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ j] are: tensor([0.2457, 0.1010, 0.6534], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,727][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ j] are: tensor([0.6414, 0.1690, 0.1896], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,729][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ j] are: tensor([0.8921, 0.0603, 0.0476], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,731][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token ['] are: tensor([0.4380, 0.1268, 0.1943, 0.2409], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,732][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token ['] are: tensor([0.7947, 0.0372, 0.1486, 0.0194], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,734][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token ['] are: tensor([0.7128, 0.0884, 0.1912, 0.0075], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,736][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token ['] are: tensor([0.9447, 0.0365, 0.0153, 0.0035], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,738][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token ['] are: tensor([0.2512, 0.0373, 0.6438, 0.0678], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,739][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token ['] are: tensor([0.3630, 0.1553, 0.3725, 0.1092], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,740][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token ['] are: tensor([0.2384, 0.0155, 0.7271, 0.0190], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,743][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token ['] are: tensor([0.6378, 0.2012, 0.1265, 0.0345], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,744][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token ['] are: tensor([0.8730, 0.0276, 0.0334, 0.0660], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,745][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token ['] are: tensor([0.3116, 0.0299, 0.6449, 0.0136], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,747][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token ['] are: tensor([0.6856, 0.2488, 0.0487, 0.0170], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,749][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token ['] are: tensor([0.8245, 0.0645, 0.0999, 0.0111], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,751][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ai] are: tensor([0.1740, 0.0991, 0.1181, 0.0843, 0.5245], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,752][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ai] are: tensor([0.7659, 0.0273, 0.1529, 0.0149, 0.0390], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,754][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ai] are: tensor([0.6373, 0.0967, 0.1502, 0.0112, 0.1046], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,756][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ai] are: tensor([0.8013, 0.0311, 0.0252, 0.0071, 0.1353], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,757][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ai] are: tensor([0.3368, 0.0423, 0.4637, 0.0800, 0.0772], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,759][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ai] are: tensor([0.2057, 0.0999, 0.4257, 0.0695, 0.1993], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,761][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ai] are: tensor([0.1852, 0.0100, 0.7181, 0.0115, 0.0752], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,762][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ai] are: tensor([0.4826, 0.1879, 0.1573, 0.0349, 0.1374], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,764][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ai] are: tensor([0.8740, 0.0213, 0.0164, 0.0631, 0.0252], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,766][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ai] are: tensor([0.2898, 0.0178, 0.6481, 0.0113, 0.0330], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,767][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ai] are: tensor([0.4426, 0.1368, 0.0488, 0.0097, 0.3621], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,769][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ai] are: tensor([0.7506, 0.0262, 0.0676, 0.0108, 0.1449], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,771][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ mal] are: tensor([0.2561, 0.1456, 0.0975, 0.0638, 0.3006, 0.1364], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,772][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ mal] are: tensor([0.5452, 0.0556, 0.1589, 0.0360, 0.0823, 0.1220], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,774][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ mal] are: tensor([0.1438, 0.0612, 0.1078, 0.0046, 0.0520, 0.6306], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,776][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ mal] are: tensor([0.7067, 0.0434, 0.0208, 0.0118, 0.2004, 0.0169], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,778][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ mal] are: tensor([0.1397, 0.0637, 0.2628, 0.1010, 0.1177, 0.3152], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,779][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ mal] are: tensor([0.1602, 0.1860, 0.3874, 0.0879, 0.1624, 0.0161], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,780][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ mal] are: tensor([0.0493, 0.0110, 0.1363, 0.0102, 0.0310, 0.7623], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,780][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ mal] are: tensor([0.2355, 0.1802, 0.2138, 0.0412, 0.0757, 0.2536], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,781][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ mal] are: tensor([9.5035e-01, 9.2280e-03, 6.9318e-03, 2.1748e-02, 1.1527e-02, 2.1840e-04],
       device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,781][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ mal] are: tensor([0.1444, 0.0606, 0.5569, 0.0287, 0.0933, 0.1160], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,781][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ mal] are: tensor([0.3848, 0.2985, 0.0547, 0.0257, 0.1430, 0.0933], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,781][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ mal] are: tensor([0.5619, 0.0305, 0.0396, 0.0214, 0.1836, 0.1630], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,782][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.2596, 0.0675, 0.1277, 0.0760, 0.3077, 0.0890, 0.0725],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,782][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.5989, 0.0222, 0.1254, 0.0137, 0.0472, 0.1604, 0.0321],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,782][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.1282, 0.0146, 0.0448, 0.0022, 0.0304, 0.7763, 0.0034],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,783][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.7530, 0.0252, 0.0187, 0.0046, 0.1770, 0.0180, 0.0036],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,783][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.2565, 0.0350, 0.3258, 0.0815, 0.0753, 0.1841, 0.0418],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,783][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.0945, 0.0688, 0.2603, 0.0574, 0.0809, 0.0063, 0.4318],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,784][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.0502, 0.0043, 0.2404, 0.0069, 0.0401, 0.6545, 0.0036],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,784][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.2832, 0.1427, 0.1271, 0.0351, 0.0899, 0.2513, 0.0707],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,786][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.6386, 0.0411, 0.0594, 0.0981, 0.0472, 0.0041, 0.1115],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,788][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.0686, 0.0078, 0.7263, 0.0087, 0.0197, 0.0819, 0.0871],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,789][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.5548, 0.1886, 0.0283, 0.0185, 0.1436, 0.0065, 0.0596],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,790][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.5037, 0.0323, 0.0879, 0.0137, 0.2169, 0.1104, 0.0352],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,792][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ written] are: tensor([0.2340, 0.0736, 0.0532, 0.0518, 0.3991, 0.0641, 0.0344, 0.0898],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,794][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ written] are: tensor([0.5286, 0.0174, 0.0945, 0.0116, 0.0250, 0.1484, 0.0337, 0.1408],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,796][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ written] are: tensor([0.1569, 0.0184, 0.0415, 0.0014, 0.0301, 0.6974, 0.0021, 0.0522],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,797][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ written] are: tensor([0.6148, 0.0206, 0.0182, 0.0035, 0.1417, 0.0325, 0.0037, 0.1650],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,799][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ written] are: tensor([0.2575, 0.0258, 0.2752, 0.0436, 0.0722, 0.1956, 0.0391, 0.0910],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,800][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ written] are: tensor([0.1107, 0.0535, 0.1434, 0.0415, 0.1404, 0.0024, 0.4418, 0.0662],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,802][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ written] are: tensor([0.0685, 0.0025, 0.2974, 0.0049, 0.0200, 0.6030, 0.0026, 0.0011],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,804][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ written] are: tensor([0.3054, 0.0888, 0.0756, 0.0167, 0.0767, 0.2141, 0.0629, 0.1599],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,806][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ written] are: tensor([0.7475, 0.0169, 0.0127, 0.0576, 0.0197, 0.0011, 0.0670, 0.0775],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,807][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ written] are: tensor([0.1725, 0.0137, 0.5366, 0.0085, 0.0191, 0.0881, 0.1282, 0.0335],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,809][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ written] are: tensor([0.2186, 0.0689, 0.0181, 0.0035, 0.0378, 0.0045, 0.0089, 0.6396],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,811][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ written] are: tensor([0.4814, 0.0169, 0.0472, 0.0085, 0.1065, 0.0908, 0.0197, 0.2290],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,812][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ in] are: tensor([0.1772, 0.0635, 0.0651, 0.0622, 0.2604, 0.0740, 0.0343, 0.0476, 0.2158],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,814][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ in] are: tensor([0.4064, 0.0323, 0.1213, 0.0151, 0.0451, 0.0874, 0.0356, 0.1895, 0.0672],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,816][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ in] are: tensor([0.0921, 0.0191, 0.0328, 0.0014, 0.0281, 0.7528, 0.0024, 0.0663, 0.0049],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,817][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ in] are: tensor([0.6098, 0.0139, 0.0105, 0.0024, 0.1032, 0.0254, 0.0040, 0.2250, 0.0057],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,819][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ in] are: tensor([0.1896, 0.0291, 0.2349, 0.0568, 0.0706, 0.1268, 0.0432, 0.0579, 0.1911],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,821][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ in] are: tensor([0.0906, 0.0762, 0.1267, 0.0386, 0.1173, 0.0040, 0.3798, 0.1550, 0.0118],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,822][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ in] are: tensor([0.0732, 0.0084, 0.2640, 0.0060, 0.0367, 0.5969, 0.0026, 0.0034, 0.0088],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,824][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ in] are: tensor([0.2046, 0.1084, 0.0932, 0.0269, 0.0527, 0.1493, 0.0719, 0.2365, 0.0566],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,826][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ in] are: tensor([0.3264, 0.0431, 0.0390, 0.0545, 0.0388, 0.0040, 0.0612, 0.1019, 0.3312],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,828][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ in] are: tensor([0.1116, 0.0125, 0.6100, 0.0113, 0.0190, 0.0804, 0.1181, 0.0203, 0.0168],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,829][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ in] are: tensor([0.4176, 0.1442, 0.0447, 0.0071, 0.1360, 0.0088, 0.0248, 0.1681, 0.0487],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,831][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ in] are: tensor([0.4575, 0.0171, 0.0562, 0.0072, 0.1283, 0.1002, 0.0182, 0.2108, 0.0046],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:29,879][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:06:29,880][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,882][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,883][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,884][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,886][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,887][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,888][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,890][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,892][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,902][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,903][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,904][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Com] are: tensor([1.], device='cuda:0') for source tokens [Com]
[2024-07-23 21:06:29,906][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [me] are: tensor([0.6112, 0.3888], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,908][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [me] are: tensor([0.9687, 0.0313], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,910][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [me] are: tensor([0.9492, 0.0508], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,911][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [me] are: tensor([0.9744, 0.0256], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,911][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [me] are: tensor([0.8847, 0.1153], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,911][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [me] are: tensor([0.6993, 0.3007], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,912][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [me] are: tensor([0.9573, 0.0427], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,912][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [me] are: tensor([0.8506, 0.1494], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,912][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [me] are: tensor([0.5850, 0.4150], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,913][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [me] are: tensor([0.9183, 0.0817], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,913][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [me] are: tensor([0.7725, 0.2275], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,913][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [me] are: tensor([0.9527, 0.0473], device='cuda:0') for source tokens [Comme]
[2024-07-23 21:06:29,913][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ j] are: tensor([0.3446, 0.1755, 0.4799], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,914][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ j] are: tensor([0.7144, 0.0754, 0.2102], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,914][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ j] are: tensor([0.6281, 0.1964, 0.1755], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,914][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ j] are: tensor([0.9347, 0.0510, 0.0144], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,915][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ j] are: tensor([0.3351, 0.1040, 0.5608], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,917][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ j] are: tensor([0.2620, 0.3936, 0.3444], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,918][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ j] are: tensor([0.0936, 0.0220, 0.8844], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,920][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ j] are: tensor([0.4488, 0.2573, 0.2939], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,921][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ j] are: tensor([0.4413, 0.3435, 0.2151], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,922][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ j] are: tensor([0.2457, 0.1010, 0.6534], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,923][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ j] are: tensor([0.6414, 0.1690, 0.1896], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,925][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ j] are: tensor([0.8921, 0.0603, 0.0476], device='cuda:0') for source tokens [Comme j]
[2024-07-23 21:06:29,927][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token ['] are: tensor([0.4380, 0.1268, 0.1943, 0.2409], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,928][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token ['] are: tensor([0.7947, 0.0372, 0.1486, 0.0194], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,930][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token ['] are: tensor([0.7128, 0.0884, 0.1912, 0.0075], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,932][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token ['] are: tensor([0.9447, 0.0365, 0.0153, 0.0035], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,933][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token ['] are: tensor([0.2512, 0.0373, 0.6438, 0.0678], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,935][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token ['] are: tensor([0.3630, 0.1553, 0.3725, 0.1092], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,937][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token ['] are: tensor([0.2384, 0.0155, 0.7271, 0.0190], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,938][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token ['] are: tensor([0.6378, 0.2012, 0.1265, 0.0345], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,940][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token ['] are: tensor([0.3630, 0.1656, 0.4394, 0.0320], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,942][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token ['] are: tensor([0.3116, 0.0299, 0.6449, 0.0136], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,943][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token ['] are: tensor([0.6856, 0.2488, 0.0487, 0.0170], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,945][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token ['] are: tensor([0.8245, 0.0645, 0.0999, 0.0111], device='cuda:0') for source tokens [Comme j']
[2024-07-23 21:06:29,947][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ai] are: tensor([0.1740, 0.0991, 0.1181, 0.0843, 0.5245], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,948][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ai] are: tensor([0.7659, 0.0273, 0.1529, 0.0149, 0.0390], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,950][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ai] are: tensor([0.6373, 0.0967, 0.1502, 0.0112, 0.1046], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,952][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ai] are: tensor([0.8013, 0.0311, 0.0252, 0.0071, 0.1353], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,954][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ai] are: tensor([0.3368, 0.0423, 0.4637, 0.0800, 0.0772], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,955][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ai] are: tensor([0.2057, 0.0999, 0.4257, 0.0695, 0.1993], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,957][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ai] are: tensor([0.1852, 0.0100, 0.7181, 0.0115, 0.0752], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,959][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ai] are: tensor([0.4826, 0.1879, 0.1573, 0.0349, 0.1374], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,960][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ai] are: tensor([0.3001, 0.1779, 0.2929, 0.0386, 0.1905], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,962][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ai] are: tensor([0.2898, 0.0178, 0.6481, 0.0113, 0.0330], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,964][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ai] are: tensor([0.4426, 0.1368, 0.0488, 0.0097, 0.3621], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,965][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ai] are: tensor([0.7506, 0.0262, 0.0676, 0.0108, 0.1449], device='cuda:0') for source tokens [Comme j'ai]
[2024-07-23 21:06:29,967][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ mal] are: tensor([0.2561, 0.1456, 0.0975, 0.0638, 0.3006, 0.1364], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,969][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ mal] are: tensor([0.5452, 0.0556, 0.1589, 0.0360, 0.0823, 0.1220], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,970][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ mal] are: tensor([0.1438, 0.0612, 0.1078, 0.0046, 0.0520, 0.6306], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,972][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ mal] are: tensor([0.7067, 0.0434, 0.0208, 0.0118, 0.2004, 0.0169], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,973][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ mal] are: tensor([0.1397, 0.0637, 0.2628, 0.1010, 0.1177, 0.3152], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,973][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ mal] are: tensor([0.1602, 0.1860, 0.3874, 0.0879, 0.1624, 0.0161], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,973][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ mal] are: tensor([0.0493, 0.0110, 0.1363, 0.0102, 0.0310, 0.7623], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,974][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ mal] are: tensor([0.2355, 0.1802, 0.2138, 0.0412, 0.0757, 0.2536], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,974][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ mal] are: tensor([0.2075, 0.1413, 0.1080, 0.0133, 0.1427, 0.3872], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,974][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ mal] are: tensor([0.1444, 0.0606, 0.5569, 0.0287, 0.0933, 0.1160], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,975][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ mal] are: tensor([0.3848, 0.2985, 0.0547, 0.0257, 0.1430, 0.0933], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,975][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ mal] are: tensor([0.5619, 0.0305, 0.0396, 0.0214, 0.1836, 0.1630], device='cuda:0') for source tokens [Comme j'ai mal]
[2024-07-23 21:06:29,975][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.2596, 0.0675, 0.1277, 0.0760, 0.3077, 0.0890, 0.0725],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,975][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.5989, 0.0222, 0.1254, 0.0137, 0.0472, 0.1604, 0.0321],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,976][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.1282, 0.0146, 0.0448, 0.0022, 0.0304, 0.7763, 0.0034],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,978][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.7530, 0.0252, 0.0187, 0.0046, 0.1770, 0.0180, 0.0036],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,980][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.2565, 0.0350, 0.3258, 0.0815, 0.0753, 0.1841, 0.0418],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,981][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.0945, 0.0688, 0.2603, 0.0574, 0.0809, 0.0063, 0.4318],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,982][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.0502, 0.0043, 0.2404, 0.0069, 0.0401, 0.6545, 0.0036],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,984][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.2832, 0.1427, 0.1271, 0.0351, 0.0899, 0.2513, 0.0707],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,986][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.1376, 0.0560, 0.2058, 0.0113, 0.0745, 0.5091, 0.0058],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,988][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.0686, 0.0078, 0.7263, 0.0087, 0.0197, 0.0819, 0.0871],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,989][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.5548, 0.1886, 0.0283, 0.0185, 0.1436, 0.0065, 0.0596],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,991][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.5037, 0.0323, 0.0879, 0.0137, 0.2169, 0.1104, 0.0352],
       device='cuda:0') for source tokens [Comme j'ai mal is]
[2024-07-23 21:06:29,993][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ written] are: tensor([0.2340, 0.0736, 0.0532, 0.0518, 0.3991, 0.0641, 0.0344, 0.0898],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,994][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ written] are: tensor([0.5286, 0.0174, 0.0945, 0.0116, 0.0250, 0.1484, 0.0337, 0.1408],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,996][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ written] are: tensor([0.1569, 0.0184, 0.0415, 0.0014, 0.0301, 0.6974, 0.0021, 0.0522],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,998][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ written] are: tensor([0.6148, 0.0206, 0.0182, 0.0035, 0.1417, 0.0325, 0.0037, 0.1650],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:29,999][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ written] are: tensor([0.2575, 0.0258, 0.2752, 0.0436, 0.0722, 0.1956, 0.0391, 0.0910],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:30,001][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ written] are: tensor([0.1107, 0.0535, 0.1434, 0.0415, 0.1404, 0.0024, 0.4418, 0.0662],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:30,003][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ written] are: tensor([0.0685, 0.0025, 0.2974, 0.0049, 0.0200, 0.6030, 0.0026, 0.0011],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:30,004][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ written] are: tensor([0.3054, 0.0888, 0.0756, 0.0167, 0.0767, 0.2141, 0.0629, 0.1599],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:30,006][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ written] are: tensor([0.0916, 0.0564, 0.0511, 0.0100, 0.0566, 0.6865, 0.0052, 0.0426],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:30,008][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ written] are: tensor([0.1725, 0.0137, 0.5366, 0.0085, 0.0191, 0.0881, 0.1282, 0.0335],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:30,009][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ written] are: tensor([0.2186, 0.0689, 0.0181, 0.0035, 0.0378, 0.0045, 0.0089, 0.6396],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:30,011][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ written] are: tensor([0.4814, 0.0169, 0.0472, 0.0085, 0.1065, 0.0908, 0.0197, 0.2290],
       device='cuda:0') for source tokens [Comme j'ai mal is written]
[2024-07-23 21:06:30,013][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ in] are: tensor([0.1772, 0.0635, 0.0651, 0.0622, 0.2604, 0.0740, 0.0343, 0.0476, 0.2158],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,015][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ in] are: tensor([0.4064, 0.0323, 0.1213, 0.0151, 0.0451, 0.0874, 0.0356, 0.1895, 0.0672],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,016][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ in] are: tensor([0.0921, 0.0191, 0.0328, 0.0014, 0.0281, 0.7528, 0.0024, 0.0663, 0.0049],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,018][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ in] are: tensor([0.6098, 0.0139, 0.0105, 0.0024, 0.1032, 0.0254, 0.0040, 0.2250, 0.0057],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,020][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ in] are: tensor([0.1896, 0.0291, 0.2349, 0.0568, 0.0706, 0.1268, 0.0432, 0.0579, 0.1911],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,021][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ in] are: tensor([0.0906, 0.0762, 0.1267, 0.0386, 0.1173, 0.0040, 0.3798, 0.1550, 0.0118],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,023][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ in] are: tensor([0.0732, 0.0084, 0.2640, 0.0060, 0.0367, 0.5969, 0.0026, 0.0034, 0.0088],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,025][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ in] are: tensor([0.2046, 0.1084, 0.0932, 0.0269, 0.0527, 0.1493, 0.0719, 0.2365, 0.0566],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,026][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ in] are: tensor([0.1163, 0.0848, 0.1391, 0.0153, 0.0959, 0.4440, 0.0073, 0.0850, 0.0122],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,028][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ in] are: tensor([0.1116, 0.0125, 0.6100, 0.0113, 0.0190, 0.0804, 0.1181, 0.0203, 0.0168],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,030][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ in] are: tensor([0.4176, 0.1442, 0.0447, 0.0071, 0.1360, 0.0088, 0.0248, 0.1681, 0.0487],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,032][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ in] are: tensor([0.4575, 0.0171, 0.0562, 0.0072, 0.1283, 0.1002, 0.0182, 0.2108, 0.0046],
       device='cuda:0') for source tokens [Comme j'ai mal is written in]
[2024-07-23 21:06:30,033][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:06:30,034][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[30],
        [ 2],
        [ 2],
        [ 1],
        [ 1],
        [ 1],
        [ 1],
        [ 1],
        [ 1]], device='cuda:0')
[2024-07-23 21:06:30,035][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[118],
        [  2],
        [  2],
        [  1],
        [  1],
        [  1],
        [  1],
        [  2],
        [ 12]], device='cuda:0')
[2024-07-23 21:06:30,036][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[ 3],
        [ 4],
        [ 7],
        [ 6],
        [14],
        [ 9],
        [ 9],
        [11],
        [ 9]], device='cuda:0')
[2024-07-23 21:06:30,036][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[2418],
        [2457],
        [2902],
        [2861],
        [2943],
        [3458],
        [3263],
        [3528],
        [4085]], device='cuda:0')
[2024-07-23 21:06:30,037][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[6033],
        [6115],
        [6812],
        [6774],
        [6990],
        [5020],
        [4648],
        [4845],
        [4727]], device='cuda:0')
[2024-07-23 21:06:30,038][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[1995],
        [2011],
        [1992],
        [1990],
        [1658],
        [1514],
        [1552],
        [1480],
        [1568]], device='cuda:0')
[2024-07-23 21:06:30,039][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 462],
        [ 558],
        [1747],
        [2019],
        [1985],
        [2422],
        [2158],
        [2664],
        [6405]], device='cuda:0')
[2024-07-23 21:06:30,041][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[4386],
        [4094],
        [3755],
        [3910],
        [3291],
        [3345],
        [3036],
        [2374],
        [2006]], device='cuda:0')
[2024-07-23 21:06:30,042][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[3537],
        [3541],
        [2540],
        [2702],
        [2680],
        [2138],
        [2213],
        [2261],
        [2292]], device='cuda:0')
[2024-07-23 21:06:30,043][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[ 5049],
        [ 4347],
        [ 4036],
        [ 4408],
        [ 3316],
        [ 7787],
        [ 8810],
        [10129],
        [10070]], device='cuda:0')
[2024-07-23 21:06:30,044][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [2]], device='cuda:0')
[2024-07-23 21:06:30,046][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[4924],
        [5119],
        [3810],
        [3788],
        [3782],
        [3604],
        [3445],
        [3647],
        [3581]], device='cuda:0')
[2024-07-23 21:06:30,047][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[2524],
        [2173],
        [2480],
        [2160],
        [3303],
        [2340],
        [2129],
        [2361],
        [1951]], device='cuda:0')
[2024-07-23 21:06:30,049][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[1527],
        [1554],
        [1468],
        [1340],
        [1743],
        [1105],
        [1310],
        [1460],
        [1458]], device='cuda:0')
[2024-07-23 21:06:30,050][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[10],
        [49],
        [12],
        [ 3],
        [46],
        [13],
        [ 3],
        [31],
        [ 3]], device='cuda:0')
[2024-07-23 21:06:30,051][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 6],
        [ 5],
        [ 7],
        [ 7],
        [14],
        [12],
        [12],
        [12],
        [12]], device='cuda:0')
[2024-07-23 21:06:30,053][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[7],
        [7],
        [4],
        [4],
        [4],
        [3],
        [3],
        [3],
        [3]], device='cuda:0')
[2024-07-23 21:06:30,054][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[ 9],
        [ 9],
        [ 7],
        [ 9],
        [14],
        [ 6],
        [ 6],
        [ 6],
        [ 6]], device='cuda:0')
[2024-07-23 21:06:30,056][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[9],
        [9],
        [9],
        [9],
        [7],
        [7],
        [7],
        [6],
        [6]], device='cuda:0')
[2024-07-23 21:06:30,057][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[3],
        [3],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1],
        [1]], device='cuda:0')
[2024-07-23 21:06:30,059][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[20],
        [19],
        [20],
        [22],
        [13],
        [13],
        [ 9],
        [ 8],
        [12]], device='cuda:0')
[2024-07-23 21:06:30,060][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[10],
        [12],
        [36],
        [36],
        [35],
        [10],
        [10],
        [12],
        [11]], device='cuda:0')
[2024-07-23 21:06:30,061][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 44],
        [ 63],
        [125],
        [ 90],
        [ 92],
        [ 66],
        [ 64],
        [ 44],
        [ 38]], device='cuda:0')
[2024-07-23 21:06:30,062][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[159],
        [160],
        [154],
        [151],
        [156],
        [153],
        [150],
        [150],
        [153]], device='cuda:0')
[2024-07-23 21:06:30,064][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[22],
        [24],
        [27],
        [28],
        [29],
        [27],
        [24],
        [25],
        [25]], device='cuda:0')
[2024-07-23 21:06:30,066][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[40],
        [24],
        [28],
        [24],
        [14],
        [22],
        [19],
        [10],
        [17]], device='cuda:0')
[2024-07-23 21:06:30,067][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[48],
        [47],
        [48],
        [54],
        [41],
        [47],
        [42],
        [58],
        [54]], device='cuda:0')
[2024-07-23 21:06:30,068][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[15317],
        [14764],
        [15537],
        [15171],
        [16147],
        [18723],
        [20260],
        [24279],
        [20744]], device='cuda:0')
[2024-07-23 21:06:30,070][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[36944],
        [22511],
        [31946],
        [17390],
        [29720],
        [38437],
        [16009],
        [20091],
        [17634]], device='cuda:0')
[2024-07-23 21:06:30,071][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[38],
        [38],
        [38],
        [38],
        [38],
        [38],
        [38],
        [38],
        [38]], device='cuda:0')
