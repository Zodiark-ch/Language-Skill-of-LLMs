[2024-07-23 21:04:37,085][explain_satisfiability.py][line:85][INFO] ############ CASE TEXT isThe Big Bang Theory premieres on
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:86][INFO] ############ CASE Prediction is  CBS
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:87][INFO] ############ Refined Forward Graph
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:88][INFO] ****** Layer 1
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 0
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 1
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20']
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 2
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-23 21:04:37,085][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 3
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 4
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 5
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 6
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 7
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 8
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 9
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 10
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 11
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,086][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 12
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 13
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 14
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 15
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 16
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 17
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 18
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 19
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 20
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 21
[2024-07-23 21:04:37,087][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 22
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 23
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 24
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 25
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 26
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 27
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 28
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 0
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,088][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 1
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 2
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 3
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 4
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 5
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 6
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 7
[2024-07-23 21:04:37,089][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit27']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 8
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 9
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 10
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 11
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 12
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 13
[2024-07-23 21:04:37,090][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 14
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 15
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 16
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 17
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 18
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 19
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,091][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 20
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 21
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 22
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 23
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 24
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 25
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,092][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit9', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 26
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 27
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 28
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 0
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 1
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,093][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 2
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 3
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 4
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit19', 'circuit21', 'circuit22', 'circuit26']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 5
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 6
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-23 21:04:37,094][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 7
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 8
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 9
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 10
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit14']
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 11
[2024-07-23 21:04:37,095][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit26']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 12
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 13
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 14
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 15
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,096][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 16
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 17
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 18
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 19
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit13', 'circuit16', 'circuit24']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit25']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 20
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23']
[2024-07-23 21:04:37,097][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit13', 'circuit14', 'circuit18']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit27']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 21
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit6', 'circuit8']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit5', 'circuit6', 'circuit7']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 22
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24', 'circuit27']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 23
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit24']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 24
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,098][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 25
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit24']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 26
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 27
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 28
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 0
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,099][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 1
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24']
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 2
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit17', 'circuit26']
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 3
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 4
[2024-07-23 21:04:37,100][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 5
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 6
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 7
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit24']
[2024-07-23 21:04:37,101][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 8
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 9
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit27']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit24', 'circuit25', 'circuit27']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 10
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit20']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 11
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-23 21:04:37,102][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20']
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 12
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 13
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 14
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 15
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,103][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 16
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 17
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 18
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit13']
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 19
[2024-07-23 21:04:37,104][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 20
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 21
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 22
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,105][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 23
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 24
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 25
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 26
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,106][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 27
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 28
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 0
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 1
[2024-07-23 21:04:37,107][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit27']
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 2
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit16']
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 3
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit24']
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 4
[2024-07-23 21:04:37,108][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit24', 'circuit27']
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 5
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 6
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit13', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 7
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:04:37,109][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 8
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20']
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 9
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 10
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-23 21:04:37,110][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 11
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit24']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 12
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 13
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,111][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 14
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 15
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 16
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,112][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 17
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 18
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 19
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,113][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 20
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 21
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 22
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,114][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 23
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 24
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 25
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 26
[2024-07-23 21:04:37,115][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 27
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 28
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,116][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 0
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 1
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit17']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit10']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 2
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit19']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19']
[2024-07-23 21:04:37,117][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 3
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3', 'circuit14', 'circuit18', 'circuit19']
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 4
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 5
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,118][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 6
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 7
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,119][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 8
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit15']
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 9
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 10
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,120][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 11
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit27']
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 12
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 13
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,121][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 14
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 15
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 16
[2024-07-23 21:04:37,122][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 17
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 18
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,123][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 19
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 20
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 21
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5']
[2024-07-23 21:04:37,124][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 22
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 23
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 24
[2024-07-23 21:04:37,125][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 25
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 26
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,126][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 27
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 28
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 0
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,127][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit3', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 1
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit25']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 2
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit24', 'circuit27']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,128][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit20', 'circuit22']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit23']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 3
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit24']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 4
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit25', 'circuit27']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,129][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 5
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 6
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 7
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,130][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 8
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit14', 'circuit24', 'circuit27']
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 9
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,131][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 10
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit13', 'circuit15']
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 11
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,132][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 12
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit26']
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 13
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 14
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,133][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 15
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 16
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,134][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit4', 'circuit8', 'circuit9', 'circuit11']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 17
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit23']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 18
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,135][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 19
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 20
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 21
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,136][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 22
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 23
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,137][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 24
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 25
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit27']
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,138][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 26
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 27
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 28
[2024-07-23 21:04:37,139][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 0
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 1
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,140][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 2
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 3
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,141][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 4
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 5
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,142][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 6
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 7
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-23 21:04:37,143][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 8
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 9
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit23']
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,144][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 10
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 11
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,145][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 12
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 13
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,146][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 14
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 15
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,147][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 16
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 17
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,148][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 18
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 19
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,149][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 20
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 21
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 22
[2024-07-23 21:04:37,150][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 23
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 24
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,151][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 25
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 26
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,152][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 27
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 28
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,153][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 0
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 1
[2024-07-23 21:04:37,154][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 2
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,155][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 3
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 4
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,156][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 5
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 6
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,157][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 7
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit25']
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 8
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit24']
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,158][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 9
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit19']
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 10
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20']
[2024-07-23 21:04:37,159][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 11
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 12
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,160][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 13
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit20', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit18', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 14
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,161][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 15
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 16
[2024-07-23 21:04:37,162][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 17
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,163][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 18
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 19
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,164][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 20
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 21
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,165][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 22
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 23
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,166][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 24
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 25
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,167][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 26
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 27
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,168][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 28
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 0
[2024-07-23 21:04:37,169][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit19', 'circuit22', 'circuit23']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit25']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 1
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,170][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 2
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 3
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,171][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 4
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 5
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,172][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 6
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,173][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 7
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 8
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,174][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 9
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 10
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,175][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 11
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 12
[2024-07-23 21:04:37,176][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 13
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit20', 'circuit23']
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,177][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit22']
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 14
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 15
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,178][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 16
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 17
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,179][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 18
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,180][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 19
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 20
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,181][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 21
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 22
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,182][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 23
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 24
[2024-07-23 21:04:37,183][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 25
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,184][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 26
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 27
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,185][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 28
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,186][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 0
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit25', 'circuit27']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit19', 'circuit23', 'circuit25']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit24']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 1
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,187][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 2
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 3
[2024-07-23 21:04:37,188][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 4
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,189][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 5
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 6
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,190][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 7
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,191][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit21']
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 8
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 9
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit16', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:04:37,192][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit26']
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit23', 'circuit24', 'circuit27']
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit15', 'circuit18']
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 10
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,193][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 11
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 12
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,194][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit13']
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 13
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit27']
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit18', 'circuit24']
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit18', 'circuit21', 'circuit23', 'circuit24']
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:04:37,195][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 14
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 15
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,196][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 16
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 17
[2024-07-23 21:04:37,197][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 18
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,198][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 19
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 20
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,199][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 21
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,200][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 22
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit24']
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 23
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,201][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 24
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,202][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 25
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 26
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,203][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 27
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,204][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 28
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:37,205][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:04:38,028][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:38,028][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,029][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,029][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,029][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,030][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,030][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,030][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,031][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,031][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,031][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,031][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,032][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,033][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.8854, 0.1146], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,034][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([8.6924e-04, 9.9913e-01], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,035][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.8259, 0.1741], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,036][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.0273, 0.9727], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,037][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.1413, 0.8587], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,037][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.0288, 0.9712], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,037][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.8369, 0.1631], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,037][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.9566, 0.0434], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,038][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.8795, 0.1205], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,038][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.9027, 0.0973], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,038][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.7109, 0.2891], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,039][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.8658, 0.1342], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,041][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.5470, 0.2929, 0.1601], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,041][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([3.3207e-05, 2.3527e-03, 9.9761e-01], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,043][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.8224, 0.0838, 0.0938], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,044][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.0048, 0.0166, 0.9786], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,045][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.0775, 0.2869, 0.6356], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,046][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([1.1434e-02, 5.1528e-04, 9.8805e-01], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,046][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.5802, 0.2443, 0.1755], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,046][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.1185, 0.8568, 0.0247], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,047][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.7179, 0.1691, 0.1130], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,047][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.6913, 0.2748, 0.0339], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,047][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.5679, 0.1785, 0.2536], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,048][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.6225, 0.1470, 0.2305], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,048][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.4963, 0.3413, 0.0758, 0.0867], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,049][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([4.2808e-04, 4.4455e-03, 9.4357e-04, 9.9418e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,050][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.4943, 0.1420, 0.2734, 0.0903], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,051][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.0020, 0.0056, 0.0028, 0.9896], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,053][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.0679, 0.2362, 0.0666, 0.6293], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,053][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([6.6169e-03, 1.9717e-04, 1.6473e-05, 9.9317e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,055][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.4588, 0.2307, 0.1671, 0.1434], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,056][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.1162, 0.8136, 0.0474, 0.0227], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,058][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.6709, 0.1261, 0.1681, 0.0349], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,059][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.6352, 0.2154, 0.1052, 0.0442], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,060][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.5229, 0.1346, 0.0500, 0.2924], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,060][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.5697, 0.0928, 0.1551, 0.1825], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,061][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.6764, 0.1084, 0.0662, 0.0829, 0.0661], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,061][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([4.3028e-05, 5.4822e-04, 7.8933e-04, 3.4870e-05, 9.9858e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,061][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.5048, 0.1019, 0.0600, 0.1503, 0.1829], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,061][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([2.3054e-04, 9.1989e-05, 2.6808e-04, 7.3176e-06, 9.9940e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,062][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.0646, 0.1013, 0.0124, 0.0126, 0.8090], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,062][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([2.4103e-03, 3.4326e-05, 7.8932e-05, 1.2876e-05, 9.9746e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,062][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.4134, 0.1378, 0.0880, 0.1840, 0.1767], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,063][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.1960, 0.5605, 0.0636, 0.1143, 0.0655], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,063][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.6478, 0.1545, 0.0514, 0.1073, 0.0390], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,063][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.4617, 0.2441, 0.1425, 0.0946, 0.0572], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,064][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.4521, 0.1478, 0.0614, 0.0364, 0.3022], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,065][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([0.3860, 0.0967, 0.0889, 0.0800, 0.3485], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,067][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.3704, 0.1292, 0.1255, 0.1701, 0.1491, 0.0556], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,068][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [res] are: tensor([1.1287e-04, 7.4908e-04, 1.1385e-04, 1.0014e-04, 1.2133e-03, 9.9771e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,069][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.4120, 0.2264, 0.0775, 0.0878, 0.1376, 0.0588], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,070][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [res] are: tensor([5.4996e-05, 1.0177e-05, 1.6571e-04, 6.0710e-05, 9.5483e-01, 4.4874e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,070][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [res] are: tensor([1.2704e-03, 1.3187e-03, 4.1042e-03, 7.7896e-04, 9.4138e-01, 5.1145e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,071][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [res] are: tensor([6.0131e-03, 1.7768e-05, 3.4205e-06, 1.3011e-06, 2.1375e-05, 9.9394e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,071][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.1471, 0.1100, 0.1643, 0.0868, 0.3266, 0.1652], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,071][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.0703, 0.0077, 0.0280, 0.0118, 0.8633, 0.0190], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,071][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.3287, 0.2244, 0.1335, 0.0683, 0.1942, 0.0509], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,072][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.4363, 0.1966, 0.1098, 0.1119, 0.0935, 0.0519], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,072][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.4364, 0.1093, 0.0480, 0.0384, 0.0535, 0.3144], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,072][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.3676, 0.0685, 0.0783, 0.0896, 0.3191, 0.0769], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,073][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ on] are: tensor([0.2699, 0.0834, 0.0771, 0.1085, 0.3780, 0.0574, 0.0257],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,074][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ on] are: tensor([1.0836e-03, 2.0646e-04, 5.0111e-04, 2.0560e-05, 9.1774e-04, 3.1580e-04,
        9.9695e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,075][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.3696, 0.0935, 0.0595, 0.0557, 0.1681, 0.0691, 0.1845],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,077][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ on] are: tensor([0.0220, 0.0103, 0.0027, 0.0224, 0.1351, 0.0156, 0.7920],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,078][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.1476, 0.0982, 0.0322, 0.1118, 0.3539, 0.0227, 0.2335],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,079][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.1454, 0.0028, 0.0021, 0.0010, 0.0031, 0.0148, 0.8308],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,080][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.0772, 0.1296, 0.1701, 0.1512, 0.4139, 0.0414, 0.0167],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,080][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.1345, 0.0358, 0.1250, 0.0891, 0.2291, 0.0817, 0.3049],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,080][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.2548, 0.0958, 0.0667, 0.0326, 0.0435, 0.0713, 0.4353],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,081][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.3698, 0.1420, 0.0727, 0.0666, 0.1092, 0.0642, 0.1755],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,081][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.3728, 0.1113, 0.0591, 0.0396, 0.0652, 0.0358, 0.3161],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,081][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.2789, 0.0506, 0.0562, 0.0626, 0.3178, 0.0399, 0.1940],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,093][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:38,093][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,093][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,094][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,094][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,095][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,096][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,096][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,097][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,097][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,098][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,098][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,098][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,099][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.8854, 0.1146], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,100][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([8.6924e-04, 9.9913e-01], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,102][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.8259, 0.1741], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,103][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.0273, 0.9727], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,104][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.1413, 0.8587], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,104][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.0288, 0.9712], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,105][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.8369, 0.1631], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,105][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.9566, 0.0434], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,105][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.8795, 0.1205], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,105][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.9027, 0.0973], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,106][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.7109, 0.2891], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,106][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.8658, 0.1342], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,106][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.5470, 0.2929, 0.1601], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,106][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([3.3207e-05, 2.3527e-03, 9.9761e-01], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,107][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.8224, 0.0838, 0.0938], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,108][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.0048, 0.0166, 0.9786], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,110][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.0775, 0.2869, 0.6356], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,111][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([1.1434e-02, 5.1528e-04, 9.8805e-01], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,112][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.5802, 0.2443, 0.1755], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,113][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.1185, 0.8568, 0.0247], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,114][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.7179, 0.1691, 0.1130], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,114][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.6913, 0.2748, 0.0339], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,114][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.5679, 0.1785, 0.2536], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,114][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.6225, 0.1470, 0.2305], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,115][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.4963, 0.3413, 0.0758, 0.0867], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,115][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([4.2808e-04, 4.4455e-03, 9.4357e-04, 9.9418e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,115][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.4943, 0.1420, 0.2734, 0.0903], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,115][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.0020, 0.0056, 0.0028, 0.9896], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,116][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.0679, 0.2362, 0.0666, 0.6293], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,117][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([6.6169e-03, 1.9717e-04, 1.6473e-05, 9.9317e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,118][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.4588, 0.2307, 0.1671, 0.1434], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,120][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.1162, 0.8136, 0.0474, 0.0227], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,121][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.6709, 0.1261, 0.1681, 0.0349], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,123][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.6352, 0.2154, 0.1052, 0.0442], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,123][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.5229, 0.1346, 0.0500, 0.2924], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,123][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.5697, 0.0928, 0.1551, 0.1825], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,123][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.6764, 0.1084, 0.0662, 0.0829, 0.0661], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,124][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([4.3028e-05, 5.4822e-04, 7.8933e-04, 3.4870e-05, 9.9858e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,124][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.5048, 0.1019, 0.0600, 0.1503, 0.1829], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,124][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([2.3054e-04, 9.1989e-05, 2.6808e-04, 7.3176e-06, 9.9940e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,125][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.0646, 0.1013, 0.0124, 0.0126, 0.8090], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,125][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([2.4103e-03, 3.4326e-05, 7.8932e-05, 1.2876e-05, 9.9746e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,126][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.4134, 0.1378, 0.0880, 0.1840, 0.1767], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,127][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.1960, 0.5605, 0.0636, 0.1143, 0.0655], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,128][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.6478, 0.1545, 0.0514, 0.1073, 0.0390], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,130][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.4617, 0.2441, 0.1425, 0.0946, 0.0572], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,131][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.4521, 0.1478, 0.0614, 0.0364, 0.3022], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,132][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([0.3860, 0.0967, 0.0889, 0.0800, 0.3485], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,132][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.3704, 0.1292, 0.1255, 0.1701, 0.1491, 0.0556], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,133][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([1.1287e-04, 7.4908e-04, 1.1385e-04, 1.0014e-04, 1.2133e-03, 9.9771e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,133][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.4120, 0.2264, 0.0775, 0.0878, 0.1376, 0.0588], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,133][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([5.4996e-05, 1.0177e-05, 1.6571e-04, 6.0710e-05, 9.5483e-01, 4.4874e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,133][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([1.2704e-03, 1.3187e-03, 4.1042e-03, 7.7896e-04, 9.4138e-01, 5.1145e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,134][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([6.0131e-03, 1.7768e-05, 3.4205e-06, 1.3011e-06, 2.1375e-05, 9.9394e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,134][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.1471, 0.1100, 0.1643, 0.0868, 0.3266, 0.1652], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,134][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.0703, 0.0077, 0.0280, 0.0118, 0.8633, 0.0190], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,135][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.3287, 0.2244, 0.1335, 0.0683, 0.1942, 0.0509], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,137][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([0.4363, 0.1966, 0.1098, 0.1119, 0.0935, 0.0519], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,138][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.4364, 0.1093, 0.0480, 0.0384, 0.0535, 0.3144], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,139][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.3676, 0.0685, 0.0783, 0.0896, 0.3191, 0.0769], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,141][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.2699, 0.0834, 0.0771, 0.1085, 0.3780, 0.0574, 0.0257],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,141][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([1.0836e-03, 2.0646e-04, 5.0111e-04, 2.0560e-05, 9.1774e-04, 3.1580e-04,
        9.9695e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,142][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.3696, 0.0935, 0.0595, 0.0557, 0.1681, 0.0691, 0.1845],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,142][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.0220, 0.0103, 0.0027, 0.0224, 0.1351, 0.0156, 0.7920],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,142][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.1476, 0.0982, 0.0322, 0.1118, 0.3539, 0.0227, 0.2335],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,143][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.1454, 0.0028, 0.0021, 0.0010, 0.0031, 0.0148, 0.8308],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,143][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.0772, 0.1296, 0.1701, 0.1512, 0.4139, 0.0414, 0.0167],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,143][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.1345, 0.0358, 0.1250, 0.0891, 0.2291, 0.0817, 0.3049],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,143][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.2548, 0.0958, 0.0667, 0.0326, 0.0435, 0.0713, 0.4353],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,144][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([0.3698, 0.1420, 0.0727, 0.0666, 0.1092, 0.0642, 0.1755],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,145][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.3728, 0.1113, 0.0591, 0.0396, 0.0652, 0.0358, 0.3161],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,147][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.2789, 0.0506, 0.0562, 0.0626, 0.3178, 0.0399, 0.1940],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,148][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:38,150][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[17007],
        [17398],
        [15233],
        [13870],
        [  490],
        [12326],
        [ 1381]], device='cuda:0')
[2024-07-23 21:04:38,151][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[46197],
        [25791],
        [35799],
        [47607],
        [19702],
        [48467],
        [39461]], device='cuda:0')
[2024-07-23 21:04:38,151][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[ 7233],
        [ 8100],
        [10444],
        [ 8908],
        [ 5716],
        [ 4578],
        [ 5725]], device='cuda:0')
[2024-07-23 21:04:38,152][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[39866],
        [40743],
        [32571],
        [22679],
        [13394],
        [28253],
        [15330]], device='cuda:0')
[2024-07-23 21:04:38,153][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[12174],
        [14635],
        [13678],
        [19357],
        [ 8170],
        [11638],
        [ 7108]], device='cuda:0')
[2024-07-23 21:04:38,154][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[46297],
        [42267],
        [26340],
        [ 7838],
        [ 3433],
        [ 3479],
        [ 1266]], device='cuda:0')
[2024-07-23 21:04:38,155][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 4195],
        [ 8843],
        [10803],
        [17409],
        [14414],
        [15917],
        [ 6702]], device='cuda:0')
[2024-07-23 21:04:38,156][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[23918],
        [44481],
        [38038],
        [43060],
        [30126],
        [31875],
        [32687]], device='cuda:0')
[2024-07-23 21:04:38,157][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[32103],
        [30805],
        [28063],
        [26443],
        [21960],
        [20297],
        [14397]], device='cuda:0')
[2024-07-23 21:04:38,158][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[13640],
        [14084],
        [31424],
        [30061],
        [24285],
        [20183],
        [19408]], device='cuda:0')
[2024-07-23 21:04:38,159][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[15690],
        [15901],
        [21476],
        [26480],
        [28810],
        [41294],
        [ 5817]], device='cuda:0')
[2024-07-23 21:04:38,160][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[40297],
        [36722],
        [22922],
        [20090],
        [ 6856],
        [ 8067],
        [25924]], device='cuda:0')
[2024-07-23 21:04:38,161][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[ 5856],
        [20888],
        [28010],
        [17175],
        [21812],
        [30033],
        [ 4252]], device='cuda:0')
[2024-07-23 21:04:38,162][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[17976],
        [13681],
        [ 9194],
        [ 9799],
        [ 9165],
        [ 8950],
        [ 4367]], device='cuda:0')
[2024-07-23 21:04:38,162][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 2148],
        [19602],
        [23041],
        [23062],
        [ 4718],
        [34272],
        [ 2758]], device='cuda:0')
[2024-07-23 21:04:38,163][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[21388],
        [21947],
        [24162],
        [23246],
        [20041],
        [16694],
        [10292]], device='cuda:0')
[2024-07-23 21:04:38,164][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[2410],
        [6119],
        [7957],
        [8425],
        [6429],
        [9899],
        [6465]], device='cuda:0')
[2024-07-23 21:04:38,165][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[32668],
        [32387],
        [34232],
        [37475],
        [31653],
        [35325],
        [37294]], device='cuda:0')
[2024-07-23 21:04:38,166][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[19434],
        [12734],
        [16236],
        [13769],
        [13518],
        [12990],
        [14141]], device='cuda:0')
[2024-07-23 21:04:38,167][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 6007],
        [ 8412],
        [ 7191],
        [17187],
        [17342],
        [17863],
        [ 9876]], device='cuda:0')
[2024-07-23 21:04:38,169][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[37752],
        [11908],
        [21980],
        [24379],
        [18836],
        [16934],
        [13438]], device='cuda:0')
[2024-07-23 21:04:38,170][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[11031],
        [ 7211],
        [ 5997],
        [ 3937],
        [ 1270],
        [  312],
        [  176]], device='cuda:0')
[2024-07-23 21:04:38,171][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[32337],
        [32217],
        [ 5786],
        [ 5991],
        [ 9522],
        [14003],
        [20183]], device='cuda:0')
[2024-07-23 21:04:38,171][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[15411],
        [16360],
        [16707],
        [16491],
        [17283],
        [21551],
        [17524]], device='cuda:0')
[2024-07-23 21:04:38,172][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[38092],
        [38057],
        [35685],
        [33444],
        [26442],
        [28327],
        [34485]], device='cuda:0')
[2024-07-23 21:04:38,173][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[24917],
        [19018],
        [15207],
        [16266],
        [11908],
        [17954],
        [24940]], device='cuda:0')
[2024-07-23 21:04:38,173][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[12600],
        [11045],
        [11444],
        [10712],
        [19611],
        [18983],
        [19841]], device='cuda:0')
[2024-07-23 21:04:38,175][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[18744],
        [23346],
        [26775],
        [26674],
        [31806],
        [27977],
        [24806]], device='cuda:0')
[2024-07-23 21:04:38,176][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[44681],
        [22356],
        [19821],
        [19029],
        [39204],
        [10777],
        [43414]], device='cuda:0')
[2024-07-23 21:04:38,177][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[4220],
        [4220],
        [4220],
        [4220],
        [4220],
        [4220],
        [4220]], device='cuda:0')
[2024-07-23 21:04:38,192][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:38,192][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,192][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,193][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,194][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,194][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,195][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,195][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,195][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,195][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,196][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,196][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,196][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,197][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.1620, 0.8380], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,197][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.8429, 0.1571], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,197][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.9019, 0.0981], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,198][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.7209, 0.2791], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,198][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.9393, 0.0607], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,198][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.9335, 0.0665], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,199][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.9990, 0.0010], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,199][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.9783, 0.0217], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,200][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.9356, 0.0644], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,201][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.9464, 0.0536], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,201][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([3.7052e-04, 9.9963e-01], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,203][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.1180, 0.8820], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,204][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.0122, 0.6626, 0.3252], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,205][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.3348, 0.5844, 0.0808], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,206][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.6733, 0.1179, 0.2088], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,206][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.5346, 0.1870, 0.2784], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,206][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.8130, 0.0720, 0.1150], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,206][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.8963, 0.0606, 0.0431], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,207][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.2425, 0.1443, 0.6133], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,207][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.8593, 0.1233, 0.0174], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,207][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.8393, 0.1011, 0.0596], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,208][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.6385, 0.1070, 0.2545], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,210][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.0011, 0.4690, 0.5299], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,211][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.0962, 0.0058, 0.8980], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,212][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.0059, 0.0921, 0.0626, 0.8394], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,214][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.3013, 0.1588, 0.4871, 0.0527], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,214][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.5519, 0.0996, 0.1737, 0.1749], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,215][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.4042, 0.1158, 0.1894, 0.2907], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,215][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.7415, 0.0498, 0.0954, 0.1133], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,215][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.8971, 0.0525, 0.0344, 0.0160], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,216][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.0091, 0.0083, 0.9691, 0.0135], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,216][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.5153, 0.2154, 0.1186, 0.1507], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,216][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.6266, 0.1665, 0.0870, 0.1199], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,217][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.7191, 0.0269, 0.2076, 0.0464], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,217][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.0010, 0.2476, 0.3449, 0.4064], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,218][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.2364, 0.0029, 0.0049, 0.7557], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,219][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.0029, 0.0431, 0.1686, 0.3572, 0.4282], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,220][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.1667, 0.2061, 0.1786, 0.4270, 0.0215], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,222][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.3761, 0.0910, 0.1528, 0.1645, 0.2155], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,223][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.2959, 0.0908, 0.1401, 0.2009, 0.2723], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,224][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.5853, 0.0614, 0.1134, 0.1129, 0.1271], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,224][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.8892, 0.0525, 0.0354, 0.0147, 0.0081], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,224][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.3405, 0.0431, 0.4030, 0.0850, 0.1285], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,225][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.3644, 0.1676, 0.1207, 0.3291, 0.0183], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,225][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.6487, 0.0792, 0.0573, 0.1262, 0.0886], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,225][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.3958, 0.0337, 0.4103, 0.0537, 0.1065], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,226][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.0011, 0.1843, 0.2682, 0.3236, 0.2228], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,226][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([2.4626e-02, 2.3397e-04, 1.9315e-03, 1.0045e-03, 9.7220e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,226][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [res] are: tensor([1.0432e-04, 2.1108e-02, 3.6106e-02, 1.0909e-01, 8.3150e-01, 2.0900e-03],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,227][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [res] are: tensor([0.2771, 0.1576, 0.3269, 0.1632, 0.0504, 0.0248], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,229][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.3466, 0.0727, 0.1255, 0.1304, 0.1848, 0.1399], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,230][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [res] are: tensor([0.2569, 0.0620, 0.1022, 0.1504, 0.2118, 0.2166], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,232][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [res] are: tensor([0.5834, 0.0417, 0.0743, 0.0894, 0.0893, 0.1220], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,233][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.8882, 0.0498, 0.0330, 0.0138, 0.0077, 0.0075], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,233][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.0172, 0.0126, 0.4583, 0.0038, 0.5053, 0.0028], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,234][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.5365, 0.0518, 0.0536, 0.2020, 0.1105, 0.0456], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,234][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.4664, 0.1019, 0.0990, 0.0980, 0.1019, 0.1329], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,234][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.7481, 0.0419, 0.0353, 0.0355, 0.0426, 0.0966], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,235][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.0022, 0.1287, 0.2108, 0.2709, 0.1910, 0.1965], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,235][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [res] are: tensor([6.1594e-02, 2.8913e-04, 7.1855e-04, 8.9059e-03, 4.3898e-02, 8.8459e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,235][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ on] are: tensor([3.2568e-04, 1.4467e-02, 4.9619e-02, 4.9786e-01, 4.2799e-01, 6.4042e-03,
        3.3411e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,236][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.2627, 0.1151, 0.1513, 0.3359, 0.0476, 0.0838, 0.0038],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,237][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.2207, 0.0629, 0.0988, 0.1037, 0.1408, 0.1069, 0.2661],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,238][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ on] are: tensor([0.2473, 0.0421, 0.0667, 0.0966, 0.1418, 0.1404, 0.2651],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,240][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.3204, 0.0459, 0.0844, 0.1060, 0.1253, 0.1051, 0.2130],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,241][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.7789, 0.0644, 0.0387, 0.0188, 0.0102, 0.0104, 0.0786],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,243][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.0577, 0.0021, 0.0082, 0.0117, 0.7528, 0.1540, 0.0135],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,243][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.4350, 0.0701, 0.0487, 0.1875, 0.0881, 0.0516, 0.1190],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,243][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.4883, 0.0998, 0.0589, 0.0859, 0.0885, 0.1001, 0.0786],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,244][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.6589, 0.0314, 0.0299, 0.0423, 0.0566, 0.1061, 0.0748],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,244][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.0026, 0.1009, 0.1683, 0.2075, 0.1602, 0.1476, 0.2130],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,244][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ on] are: tensor([1.3283e-02, 2.0608e-05, 8.5306e-05, 6.9849e-04, 1.4176e-03, 3.3234e-03,
        9.8117e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,268][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:38,268][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,269][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,269][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,269][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,269][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,270][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,270][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,270][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,271][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,272][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,273][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,274][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,275][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.4999, 0.5001], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,277][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.5555, 0.4445], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,277][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.7850, 0.2150], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,278][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.5055, 0.4945], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,278][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.8980, 0.1020], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,278][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.9917, 0.0083], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,278][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.9897, 0.0103], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,279][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.9815, 0.0185], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,279][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.8608, 0.1392], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,279][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.9871, 0.0129], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,280][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.0024, 0.9976], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,280][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,282][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.3332, 0.3333, 0.3335], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,283][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.1650, 0.6371, 0.1979], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,284][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.6554, 0.1763, 0.1683], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,286][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.3449, 0.3035, 0.3516], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,286][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.7999, 0.0792, 0.1209], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,287][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.8650, 0.0782, 0.0569], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,287][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.8646, 0.1031, 0.0323], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,287][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.8949, 0.0828, 0.0223], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,288][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.8520, 0.1295, 0.0185], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,288][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.8145, 0.0432, 0.1422], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,288][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.0024, 0.3828, 0.6148], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,288][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.0283, 0.0063, 0.9654], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,289][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.2498, 0.2499, 0.2500, 0.2503], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,290][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.0882, 0.2357, 0.5353, 0.1408], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,291][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.4759, 0.1701, 0.1627, 0.1912], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,292][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.2605, 0.2126, 0.2658, 0.2611], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,294][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.6844, 0.0505, 0.1141, 0.1510], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,295][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.6603, 0.0410, 0.0627, 0.2360], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,296][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.0477, 0.0230, 0.8882, 0.0411], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,296][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.5169, 0.1748, 0.1457, 0.1626], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,296][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.6198, 0.1264, 0.0201, 0.2336], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,297][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.8629, 0.0110, 0.0962, 0.0299], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,297][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.0016, 0.2138, 0.3646, 0.4200], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,297][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.0616, 0.0027, 0.0012, 0.9345], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,297][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.1997, 0.1998, 0.2000, 0.2002, 0.2003], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,298][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([0.0398, 0.2145, 0.2650, 0.4115, 0.0692], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,298][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.3075, 0.1591, 0.1248, 0.1704, 0.2382], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,299][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.1721, 0.1099, 0.1353, 0.1486, 0.4341], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,300][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.6419, 0.0489, 0.0955, 0.1141, 0.0996], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,301][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.1784, 0.0387, 0.1803, 0.1332, 0.4694], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,303][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.2794, 0.1039, 0.1750, 0.2099, 0.2317], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,304][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.3660, 0.1292, 0.1417, 0.3427, 0.0204], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,305][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([5.5326e-01, 5.7196e-02, 1.4445e-02, 3.7486e-01, 2.4153e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,305][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.3751, 0.0142, 0.3854, 0.0435, 0.1818], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,306][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.0017, 0.1540, 0.2537, 0.2878, 0.3027], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,306][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([1.1166e-02, 6.0114e-04, 1.4063e-03, 4.1217e-04, 9.8641e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,306][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.1665, 0.1665, 0.1666, 0.1669, 0.1669, 0.1666], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,307][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.0319, 0.1239, 0.2466, 0.1914, 0.1123, 0.2940], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,307][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.2480, 0.1022, 0.1021, 0.1274, 0.1743, 0.2460], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,307][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.1276, 0.0698, 0.0849, 0.0937, 0.2879, 0.3361], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,308][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.6710, 0.0358, 0.0582, 0.1005, 0.0598, 0.0746], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,309][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.2300, 0.0119, 0.0061, 0.0113, 0.1741, 0.5665], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,311][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.0674, 0.0063, 0.0895, 0.0069, 0.8270, 0.0029], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,312][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.5065, 0.0331, 0.0581, 0.2000, 0.1265, 0.0758], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,313][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([5.4670e-01, 6.0078e-02, 1.2131e-02, 3.5641e-01, 1.2141e-04, 2.4556e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,314][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([0.7735, 0.0147, 0.0233, 0.0268, 0.0734, 0.0883], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,315][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.0019, 0.1087, 0.1870, 0.2142, 0.2297, 0.2585], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,315][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.0345, 0.0014, 0.0011, 0.0053, 0.0481, 0.9096], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,315][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.1427, 0.1427, 0.1428, 0.1430, 0.1431, 0.1428, 0.1428],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,315][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([0.0181, 0.0568, 0.0723, 0.1546, 0.0668, 0.4817, 0.1496],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,316][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.1472, 0.0754, 0.0851, 0.1011, 0.1299, 0.1704, 0.2908],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,316][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.1146, 0.0475, 0.0550, 0.0604, 0.1800, 0.2035, 0.3392],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,316][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.2549, 0.0376, 0.0793, 0.1126, 0.0885, 0.1011, 0.3261],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,317][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.0527, 0.0012, 0.0010, 0.0028, 0.0432, 0.0110, 0.8881],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,319][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.3089, 0.0134, 0.0305, 0.0670, 0.4390, 0.1034, 0.0378],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,320][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.3551, 0.0375, 0.0414, 0.1326, 0.0942, 0.0659, 0.2733],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,321][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([6.1152e-01, 7.0036e-02, 1.1000e-02, 2.7373e-01, 2.7157e-04, 3.1229e-02,
        2.2129e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,322][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([0.5881, 0.0146, 0.0313, 0.0359, 0.1039, 0.0898, 0.1365],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,323][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.0015, 0.0722, 0.1326, 0.1452, 0.1668, 0.1700, 0.3118],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,324][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([2.1775e-02, 3.6497e-04, 2.9914e-04, 2.6499e-03, 1.3906e-03, 4.3752e-03,
        9.6915e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,325][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:38,326][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[11685],
        [34433],
        [33758],
        [10905],
        [ 2158],
        [ 7213],
        [10395]], device='cuda:0')
[2024-07-23 21:04:38,326][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[14573],
        [11677],
        [ 9503],
        [ 6540],
        [  342],
        [ 6059],
        [ 3128]], device='cuda:0')
[2024-07-23 21:04:38,328][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[26024],
        [46093],
        [39391],
        [22172],
        [10169],
        [ 7926],
        [10962]], device='cuda:0')
[2024-07-23 21:04:38,329][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[41508],
        [42802],
        [43607],
        [37987],
        [37562],
        [38569],
        [39502]], device='cuda:0')
[2024-07-23 21:04:38,330][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[12245],
        [12664],
        [10784],
        [11567],
        [ 9484],
        [ 8713],
        [ 6795]], device='cuda:0')
[2024-07-23 21:04:38,331][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[28114],
        [30639],
        [32485],
        [32540],
        [31453],
        [30654],
        [29554]], device='cuda:0')
[2024-07-23 21:04:38,332][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[14511],
        [14412],
        [14316],
        [19554],
        [23514],
        [25471],
        [22325]], device='cuda:0')
[2024-07-23 21:04:38,333][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[40935],
        [41258],
        [41447],
        [41473],
        [41520],
        [41527],
        [41834]], device='cuda:0')
[2024-07-23 21:04:38,334][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[17536],
        [17513],
        [ 6881],
        [ 7626],
        [ 6910],
        [ 7074],
        [11231]], device='cuda:0')
[2024-07-23 21:04:38,335][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[27613],
        [26018],
        [15828],
        [ 1174],
        [  488],
        [  510],
        [  773]], device='cuda:0')
[2024-07-23 21:04:38,335][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[11342],
        [13485],
        [18452],
        [29060],
        [25897],
        [24386],
        [23859]], device='cuda:0')
[2024-07-23 21:04:38,336][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[36042],
        [38011],
        [14797],
        [13126],
        [ 7580],
        [26008],
        [22181]], device='cuda:0')
[2024-07-23 21:04:38,337][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[5801],
        [1174],
        [2853],
        [4040],
        [5057],
        [5862],
        [5748]], device='cuda:0')
[2024-07-23 21:04:38,338][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[12834],
        [ 8770],
        [22663],
        [36393],
        [32958],
        [17476],
        [10968]], device='cuda:0')
[2024-07-23 21:04:38,339][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 4692],
        [ 7393],
        [30104],
        [ 8543],
        [ 4911],
        [ 1487],
        [ 8489]], device='cuda:0')
[2024-07-23 21:04:38,341][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[8845],
        [8834],
        [8841],
        [8840],
        [8842],
        [8844],
        [8845]], device='cuda:0')
[2024-07-23 21:04:38,342][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[12468],
        [28196],
        [34798],
        [26645],
        [23189],
        [20256],
        [26405]], device='cuda:0')
[2024-07-23 21:04:38,343][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[10255],
        [ 9592],
        [ 9795],
        [ 9640],
        [10376],
        [10433],
        [11303]], device='cuda:0')
[2024-07-23 21:04:38,344][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[27013],
        [17312],
        [10842],
        [10130],
        [ 8514],
        [ 7689],
        [ 7359]], device='cuda:0')
[2024-07-23 21:04:38,344][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[9242],
        [9503],
        [9400],
        [5717],
        [5770],
        [5530],
        [4330]], device='cuda:0')
[2024-07-23 21:04:38,345][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[34076],
        [34128],
        [33737],
        [30161],
        [22968],
        [20718],
        [14695]], device='cuda:0')
[2024-07-23 21:04:38,346][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[31369],
        [31081],
        [29894],
        [20915],
        [10661],
        [10274],
        [11696]], device='cuda:0')
[2024-07-23 21:04:38,347][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[13223],
        [15130],
        [26453],
        [41926],
        [43039],
        [45188],
        [47060]], device='cuda:0')
[2024-07-23 21:04:38,348][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[12644],
        [13569],
        [13556],
        [15075],
        [14858],
        [14524],
        [14403]], device='cuda:0')
[2024-07-23 21:04:38,349][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[ 6143],
        [ 6086],
        [ 7126],
        [ 6748],
        [13553],
        [ 6707],
        [ 9109]], device='cuda:0')
[2024-07-23 21:04:38,350][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[ 6767],
        [11300],
        [ 9375],
        [ 8030],
        [ 9329],
        [ 8779],
        [ 9515]], device='cuda:0')
[2024-07-23 21:04:38,351][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 5931],
        [34648],
        [35919],
        [21842],
        [16990],
        [13692],
        [ 4036]], device='cuda:0')
[2024-07-23 21:04:38,352][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[30273],
        [18096],
        [16237],
        [23128],
        [31627],
        [33663],
        [34131]], device='cuda:0')
[2024-07-23 21:04:38,354][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[36592],
        [21822],
        [16807],
        [31304],
        [37149],
        [45747],
        [38950]], device='cuda:0')
[2024-07-23 21:04:38,355][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[8279],
        [8279],
        [8279],
        [8279],
        [8279],
        [8279],
        [8279]], device='cuda:0')
[2024-07-23 21:04:38,369][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:38,371][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,372][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,372][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,373][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,374][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,374][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,375][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,376][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,377][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,378][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,380][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,381][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,382][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.9896, 0.0104], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,382][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([9.4399e-04, 9.9906e-01], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,383][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.3205, 0.6795], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,384][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.5562, 0.4438], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,386][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.9738, 0.0262], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,388][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.3805, 0.6195], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,389][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.7281, 0.2719], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,390][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,391][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.5995, 0.4005], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,392][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.6865, 0.3135], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,392][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.0801, 0.9199], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,394][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.4891, 0.5109], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,395][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([9.9343e-01, 8.0707e-04, 5.7621e-03], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,397][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.0049, 0.9592, 0.0359], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,398][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.0217, 0.9652, 0.0131], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,400][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.4098, 0.2623, 0.3279], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,400][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.4275, 0.5714, 0.0011], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,401][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.1567, 0.6302, 0.2131], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,402][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.1988, 0.1730, 0.6282], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,403][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.9761, 0.0031, 0.0208], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,405][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.5436, 0.2844, 0.1719], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,407][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.3632, 0.3472, 0.2896], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,408][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.0392, 0.3504, 0.6104], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,409][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.3434, 0.3645, 0.2922], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,410][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.9288, 0.0068, 0.0293, 0.0350], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,411][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.0058, 0.3264, 0.0303, 0.6375], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,411][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.0394, 0.7667, 0.1928, 0.0012], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,413][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.2383, 0.1622, 0.2572, 0.3423], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,414][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.6173, 0.1344, 0.2473, 0.0010], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,416][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.0727, 0.3641, 0.3863, 0.1769], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,418][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.1679, 0.1482, 0.2890, 0.3949], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,419][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.9433, 0.0029, 0.0160, 0.0378], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,419][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.5031, 0.2496, 0.1322, 0.1152], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,420][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.2234, 0.1691, 0.4439, 0.1635], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,421][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.0164, 0.2154, 0.3850, 0.3831], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,422][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.2806, 0.3067, 0.2163, 0.1964], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,423][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([9.5831e-01, 2.3325e-04, 1.7861e-03, 2.5394e-03, 3.7136e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,425][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.0521, 0.0692, 0.0162, 0.8614, 0.0010], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,427][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.0454, 0.7801, 0.1178, 0.0544, 0.0022], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,428][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.0849, 0.0388, 0.0766, 0.1215, 0.6781], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,429][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.6172, 0.0466, 0.2128, 0.1116, 0.0118], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,429][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.0401, 0.2664, 0.3670, 0.2861, 0.0404], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,430][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.1989, 0.0630, 0.2336, 0.2871, 0.2173], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,432][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.6814, 0.0061, 0.0188, 0.0577, 0.2360], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,433][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.6771, 0.1758, 0.0616, 0.0592, 0.0262], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,435][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.1166, 0.1434, 0.2730, 0.2754, 0.1916], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,436][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.0145, 0.1608, 0.2558, 0.2976, 0.2713], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,437][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([0.2501, 0.2688, 0.1724, 0.1569, 0.1519], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,438][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.5529, 0.0010, 0.0052, 0.0190, 0.1864, 0.2355], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,439][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [res] are: tensor([7.6067e-03, 6.4044e-02, 1.1312e-02, 8.2482e-01, 7.4031e-04, 9.1476e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,439][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [res] are: tensor([1.0690e-04, 9.3854e-01, 3.7037e-02, 3.2475e-03, 2.1067e-02, 1.6743e-06],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,441][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [res] are: tensor([0.0927, 0.0544, 0.0922, 0.1303, 0.4510, 0.1793], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,442][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [res] are: tensor([6.7779e-02, 6.6548e-02, 2.0807e-02, 3.5139e-02, 8.0895e-01, 7.8013e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,444][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.0326, 0.2263, 0.3356, 0.2395, 0.0971, 0.0690], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,445][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.1241, 0.0545, 0.1373, 0.2944, 0.2746, 0.1151], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,447][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.2577, 0.0036, 0.0098, 0.0257, 0.0603, 0.6428], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,447][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.5236, 0.2052, 0.0909, 0.0834, 0.0392, 0.0578], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,448][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.0960, 0.1021, 0.2746, 0.1580, 0.2939, 0.0755], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,449][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.0060, 0.1166, 0.1787, 0.1967, 0.2041, 0.2979], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,450][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.1854, 0.2012, 0.1595, 0.1420, 0.1494, 0.1625], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,452][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ on] are: tensor([0.5887, 0.0008, 0.0065, 0.0142, 0.1742, 0.1853, 0.0303],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,454][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.0195, 0.1291, 0.0470, 0.2348, 0.0162, 0.0969, 0.4565],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,455][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ on] are: tensor([7.4270e-02, 2.4206e-01, 4.9223e-01, 5.6842e-02, 1.0890e-01, 2.5581e-02,
        1.1602e-04], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,456][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ on] are: tensor([0.0479, 0.0231, 0.0412, 0.0649, 0.2802, 0.0888, 0.4540],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,457][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ on] are: tensor([6.3158e-03, 4.7108e-02, 1.5397e-02, 1.1673e-02, 9.1884e-01, 1.3105e-04,
        5.3289e-04], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,457][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.0369, 0.2631, 0.1770, 0.1933, 0.0820, 0.1101, 0.1376],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,458][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.1477, 0.0128, 0.0977, 0.1397, 0.4005, 0.1184, 0.0832],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,460][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.1785, 0.0031, 0.0081, 0.0157, 0.0477, 0.3321, 0.4149],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,461][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.7850, 0.1310, 0.0293, 0.0262, 0.0085, 0.0163, 0.0037],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,463][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.0671, 0.0805, 0.1724, 0.1425, 0.2628, 0.0896, 0.1850],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,465][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.0184, 0.1095, 0.1364, 0.1395, 0.1638, 0.2083, 0.2241],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,465][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.2129, 0.2297, 0.1262, 0.1173, 0.1150, 0.1201, 0.0789],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,488][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:38,489][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,490][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,491][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,491][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,492][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,493][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,493][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,495][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,496][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,497][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,498][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,499][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,500][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.3780, 0.6220], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,501][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.6053, 0.3947], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,501][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,503][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.9978, 0.0022], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,504][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.9582, 0.0418], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,506][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.8397, 0.1603], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,508][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.5345, 0.4655], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,509][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.0064, 0.9936], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,509][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.6943, 0.3057], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,510][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.9852, 0.0148], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,511][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.5344, 0.4656], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,512][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.5859, 0.4141], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,514][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.2337, 0.5160, 0.2503], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,515][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.1035, 0.4525, 0.4441], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,516][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([5.4969e-05, 1.6321e-01, 8.3674e-01], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,518][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.9853, 0.0057, 0.0090], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,519][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.5537, 0.4304, 0.0159], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,519][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.6037, 0.2677, 0.1286], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,520][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.3505, 0.2734, 0.3762], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,521][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.0474, 0.8383, 0.1143], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,523][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.4612, 0.3241, 0.2148], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,525][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.9922, 0.0058, 0.0020], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,526][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.3879, 0.2801, 0.3321], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,527][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.3683, 0.2975, 0.3343], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,528][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.1497, 0.3749, 0.2155, 0.2600], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,529][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.0371, 0.3949, 0.3530, 0.2150], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,529][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([1.2639e-04, 1.2405e-01, 6.6354e-01, 2.1229e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,531][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.9301, 0.0103, 0.0311, 0.0285], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,533][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.6340, 0.1723, 0.1806, 0.0131], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,534][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.6109, 0.0533, 0.1191, 0.2167], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,536][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.2795, 0.2146, 0.2639, 0.2420], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,537][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.0377, 0.7635, 0.0920, 0.1069], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,538][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.3169, 0.1597, 0.2543, 0.2691], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,538][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([9.9228e-01, 4.9593e-03, 1.9188e-03, 8.4642e-04], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,539][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.2979, 0.2152, 0.2392, 0.2478], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,541][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.2665, 0.2645, 0.2948, 0.1742], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,542][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.0881, 0.2526, 0.2137, 0.3251, 0.1205], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,543][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([1.4082e-05, 7.0224e-01, 2.1754e-01, 8.0120e-02, 8.6263e-05],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,544][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([2.2965e-05, 3.8241e-03, 3.1821e-02, 1.8377e-02, 9.4595e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,546][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.9409, 0.0043, 0.0163, 0.0297, 0.0088], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,547][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.4858, 0.0625, 0.1971, 0.1835, 0.0712], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,547][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.2109, 0.0503, 0.1132, 0.4795, 0.1461], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,548][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.2546, 0.1510, 0.1908, 0.1796, 0.2240], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,549][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.0655, 0.2464, 0.1339, 0.5450, 0.0092], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,551][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.2876, 0.1502, 0.1567, 0.2174, 0.1881], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,552][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.9911, 0.0053, 0.0014, 0.0011, 0.0011], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,554][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.2353, 0.1289, 0.1711, 0.1741, 0.2907], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,556][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([0.2258, 0.2192, 0.2374, 0.1459, 0.1716], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,556][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.0704, 0.1871, 0.2017, 0.2380, 0.1366, 0.1662], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,557][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.0065, 0.3706, 0.2845, 0.1600, 0.0093, 0.1690], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,558][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([1.2580e-05, 4.0133e-03, 3.6032e-02, 1.6473e-02, 9.3961e-01, 3.8641e-03],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,559][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.9485, 0.0037, 0.0089, 0.0176, 0.0101, 0.0112], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,561][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.1452, 0.0909, 0.0357, 0.0730, 0.6308, 0.0244], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,562][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.1206, 0.0015, 0.0050, 0.0198, 0.0098, 0.8435], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,564][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.1758, 0.1360, 0.1595, 0.1682, 0.1922, 0.1683], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,565][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.0356, 0.3275, 0.1294, 0.4926, 0.0058, 0.0091], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,566][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.2096, 0.1043, 0.1409, 0.1879, 0.2775, 0.0797], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,566][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([9.9392e-01, 3.4702e-03, 9.1155e-04, 5.0791e-04, 6.3853e-04, 5.5529e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,567][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.1832, 0.1322, 0.1561, 0.1639, 0.2177, 0.1469], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,569][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.1714, 0.1923, 0.2020, 0.1244, 0.1482, 0.1616], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,571][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.0582, 0.1244, 0.1069, 0.1361, 0.1310, 0.2079, 0.2354],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,572][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([3.7882e-05, 6.9001e-01, 1.6163e-01, 8.8231e-02, 9.1880e-05, 5.8612e-02,
        1.3866e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,573][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([6.7008e-05, 6.9430e-04, 4.9149e-03, 3.6918e-03, 1.0703e-01, 2.9540e-03,
        8.8065e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,574][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.8538, 0.0074, 0.0173, 0.0296, 0.0249, 0.0470, 0.0199],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,575][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.0326, 0.1039, 0.0542, 0.0468, 0.7444, 0.0044, 0.0138],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,576][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([8.0918e-02, 5.4758e-04, 2.4157e-03, 8.3520e-03, 1.9329e-02, 8.0319e-01,
        8.5249e-02], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,576][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.2017, 0.1334, 0.1341, 0.1323, 0.1222, 0.1338, 0.1425],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,578][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.0238, 0.3349, 0.1325, 0.4868, 0.0056, 0.0097, 0.0067],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,580][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.2160, 0.1446, 0.1032, 0.1317, 0.2105, 0.0544, 0.1397],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,581][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([9.9825e-01, 1.0249e-03, 2.2676e-04, 1.1783e-04, 1.8092e-04, 1.5593e-04,
        4.6886e-05], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,582][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.1871, 0.1102, 0.1245, 0.1307, 0.1720, 0.1004, 0.1751],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,584][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.1203, 0.1511, 0.1626, 0.0995, 0.1386, 0.1501, 0.1778],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,587][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:38,588][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 8009],
        [41781],
        [33187],
        [11569],
        [ 3609],
        [ 5023],
        [ 7683]], device='cuda:0')
[2024-07-23 21:04:38,589][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[11757],
        [37953],
        [36543],
        [10781],
        [ 3809],
        [ 7982],
        [15243]], device='cuda:0')
[2024-07-23 21:04:38,591][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[4601],
        [4621],
        [4566],
        [4120],
        [4548],
        [8596],
        [7206]], device='cuda:0')
[2024-07-23 21:04:38,592][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[36667],
        [33985],
        [33933],
        [43718],
        [45782],
        [45442],
        [48476]], device='cuda:0')
[2024-07-23 21:04:38,593][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[13119],
        [43508],
        [47320],
        [47556],
        [47200],
        [47368],
        [41807]], device='cuda:0')
[2024-07-23 21:04:38,594][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[3510],
        [3794],
        [3989],
        [3987],
        [3828],
        [3912],
        [4037]], device='cuda:0')
[2024-07-23 21:04:38,595][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[40577],
        [40558],
        [30823],
        [24950],
        [27712],
        [ 1180],
        [  932]], device='cuda:0')
[2024-07-23 21:04:38,596][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[41283],
        [45884],
        [44435],
        [41320],
        [40339],
        [40009],
        [42005]], device='cuda:0')
[2024-07-23 21:04:38,598][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[23223],
        [20366],
        [ 7407],
        [12722],
        [11235],
        [ 7900],
        [ 5880]], device='cuda:0')
[2024-07-23 21:04:38,599][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[36321],
        [36528],
        [40868],
        [40275],
        [43400],
        [39986],
        [38882]], device='cuda:0')
[2024-07-23 21:04:38,600][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[24853],
        [21496],
        [21230],
        [21752],
        [22845],
        [22772],
        [23627]], device='cuda:0')
[2024-07-23 21:04:38,602][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[29914],
        [31009],
        [29396],
        [28951],
        [28446],
        [26275],
        [24682]], device='cuda:0')
[2024-07-23 21:04:38,603][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[11360],
        [19145],
        [12546],
        [ 5255],
        [ 5816],
        [ 8620],
        [ 4417]], device='cuda:0')
[2024-07-23 21:04:38,604][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[15387],
        [22649],
        [22990],
        [22279],
        [19829],
        [18155],
        [17734]], device='cuda:0')
[2024-07-23 21:04:38,605][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 6588],
        [25266],
        [ 9194],
        [ 9136],
        [ 2030],
        [ 1540],
        [ 3330]], device='cuda:0')
[2024-07-23 21:04:38,606][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[22280],
        [31148],
        [35523],
        [36893],
        [36234],
        [35045],
        [33520]], device='cuda:0')
[2024-07-23 21:04:38,607][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[5565],
        [2491],
        [2724],
        [2612],
        [2965],
        [2463],
        [2846]], device='cuda:0')
[2024-07-23 21:04:38,608][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[14117],
        [11289],
        [36082],
        [36408],
        [31199],
        [31131],
        [16390]], device='cuda:0')
[2024-07-23 21:04:38,610][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[33510],
        [33526],
        [33636],
        [34269],
        [34282],
        [34099],
        [34214]], device='cuda:0')
[2024-07-23 21:04:38,611][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[23524],
        [25109],
        [31706],
        [27399],
        [28650],
        [ 8328],
        [ 5659]], device='cuda:0')
[2024-07-23 21:04:38,612][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[ 2122],
        [ 2108],
        [ 2242],
        [ 2493],
        [ 5466],
        [11023],
        [12140]], device='cuda:0')
[2024-07-23 21:04:38,613][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[ 8767],
        [12399],
        [14473],
        [11477],
        [ 8557],
        [ 6834],
        [ 6186]], device='cuda:0')
[2024-07-23 21:04:38,614][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 3750],
        [22728],
        [21498],
        [22844],
        [30389],
        [29773],
        [29750]], device='cuda:0')
[2024-07-23 21:04:38,615][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[15388],
        [15592],
        [16562],
        [16370],
        [15851],
        [15739],
        [15916]], device='cuda:0')
[2024-07-23 21:04:38,616][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[20520],
        [20814],
        [20662],
        [20657],
        [20677],
        [20635],
        [20559]], device='cuda:0')
[2024-07-23 21:04:38,618][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[17174],
        [17782],
        [14443],
        [12159],
        [ 8232],
        [ 7759],
        [ 7242]], device='cuda:0')
[2024-07-23 21:04:38,619][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[16556],
        [20486],
        [23275],
        [22693],
        [20652],
        [20157],
        [19850]], device='cuda:0')
[2024-07-23 21:04:38,620][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[15644],
        [12624],
        [ 8294],
        [ 8995],
        [ 7822],
        [10169],
        [11457]], device='cuda:0')
[2024-07-23 21:04:38,622][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[24418],
        [26028],
        [28477],
        [34505],
        [37679],
        [42618],
        [35758]], device='cuda:0')
[2024-07-23 21:04:38,623][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[11506],
        [11506],
        [11506],
        [11506],
        [11506],
        [11506],
        [11506]], device='cuda:0')
[2024-07-23 21:04:38,663][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:38,664][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,665][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,666][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,666][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,668][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,669][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,671][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,672][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,673][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,674][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,675][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,675][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,676][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.5721, 0.4279], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,678][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.1245, 0.8755], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,679][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.8057, 0.1943], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,681][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.3055, 0.6945], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,683][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.5820, 0.4180], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,683][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.6299, 0.3701], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,684][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.4253, 0.5747], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,685][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.9905, 0.0095], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,686][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.3038, 0.6962], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,688][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.8403, 0.1597], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,689][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.2256, 0.7744], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,691][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.9170, 0.0830], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,692][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.3526, 0.2982, 0.3493], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,693][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.0221, 0.6128, 0.3651], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,693][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.9919, 0.0032, 0.0050], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,694][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.0042, 0.0013, 0.9945], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,696][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.3797, 0.3156, 0.3046], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,697][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.4558, 0.2804, 0.2638], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,699][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.1237, 0.7949, 0.0814], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,700][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.4554, 0.5271, 0.0174], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,702][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.4491, 0.1565, 0.3944], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,702][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.6397, 0.1073, 0.2530], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,703][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.1254, 0.4672, 0.4074], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,704][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.8565, 0.0528, 0.0907], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,705][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.3409, 0.1987, 0.2440, 0.2164], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,707][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.0372, 0.4113, 0.2664, 0.2852], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,708][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([9.2250e-01, 1.6793e-04, 2.4523e-02, 5.2810e-02], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,709][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.0094, 0.0012, 0.1960, 0.7934], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,711][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.2879, 0.2561, 0.2337, 0.2223], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,712][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.3237, 0.2213, 0.2183, 0.2366], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,712][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.2809, 0.2509, 0.3472, 0.1210], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,713][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.1928, 0.3784, 0.3261, 0.1026], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,715][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.4849, 0.0157, 0.2172, 0.2822], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,716][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.8064, 0.0145, 0.0412, 0.1379], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,718][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.0873, 0.3212, 0.2817, 0.3098], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,719][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.8355, 0.0194, 0.0253, 0.1199], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,720][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.2086, 0.1824, 0.2134, 0.1957, 0.2000], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,721][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.0173, 0.1149, 0.0701, 0.2660, 0.5317], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,722][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([4.5178e-03, 2.2460e-04, 4.7686e-04, 9.9475e-01, 3.4027e-05],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,722][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([2.2012e-04, 9.9572e-07, 2.9924e-05, 4.8968e-04, 9.9926e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,724][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.1546, 0.2526, 0.2067, 0.2003, 0.1858], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,725][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.2824, 0.1794, 0.1655, 0.2004, 0.1723], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,727][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.0060, 0.0072, 0.0292, 0.9493, 0.0083], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,728][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([8.1584e-03, 8.8493e-03, 3.9809e-02, 9.4302e-01, 1.6589e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,730][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.2847, 0.0157, 0.1556, 0.2625, 0.2816], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,730][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.6757, 0.0116, 0.0281, 0.1046, 0.1800], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,731][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.0679, 0.2493, 0.2210, 0.2421, 0.2198], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,732][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([0.6776, 0.0226, 0.0357, 0.1952, 0.0688], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,733][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.2643, 0.1261, 0.1582, 0.1346, 0.1587, 0.1582], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,735][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [res] are: tensor([0.0075, 0.0353, 0.0142, 0.0616, 0.1529, 0.7285], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,736][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [res] are: tensor([9.2512e-02, 6.5735e-04, 7.4186e-03, 8.9815e-01, 2.2169e-04, 1.0409e-03],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,737][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [res] are: tensor([7.8769e-07, 1.2813e-07, 2.7280e-05, 1.6141e-04, 9.9973e-01, 7.9573e-05],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,739][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [res] are: tensor([0.2010, 0.1657, 0.1525, 0.1391, 0.1692, 0.1726], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,740][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.2541, 0.1484, 0.1408, 0.1662, 0.1532, 0.1373], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,740][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.0166, 0.0138, 0.0811, 0.8285, 0.0350, 0.0250], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,741][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [res] are: tensor([1.9503e-02, 1.2315e-02, 1.1879e-01, 8.4248e-01, 6.3401e-03, 5.6914e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,742][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [res] are: tensor([6.8767e-02, 1.4332e-04, 4.3307e-03, 2.1927e-02, 7.2794e-02, 8.3204e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,744][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.5011, 0.0106, 0.0324, 0.1099, 0.1807, 0.1654], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,745][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.0531, 0.2117, 0.1870, 0.2059, 0.1922, 0.1500], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,747][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.6384, 0.0245, 0.0293, 0.1571, 0.0529, 0.0979], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,748][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ on] are: tensor([0.2093, 0.1140, 0.1395, 0.1214, 0.1388, 0.1380, 0.1391],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,749][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.0034, 0.0181, 0.0078, 0.0323, 0.1077, 0.7284, 0.1022],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,750][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ on] are: tensor([2.8198e-03, 2.2094e-05, 1.5427e-03, 9.9301e-01, 7.7996e-06, 2.5146e-03,
        7.9955e-05], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,750][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ on] are: tensor([1.0063e-03, 2.1955e-06, 1.1307e-05, 1.7913e-04, 7.5873e-02, 1.5653e-05,
        9.2291e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,752][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.2089, 0.1217, 0.1173, 0.1102, 0.1393, 0.1461, 0.1565],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,754][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.2365, 0.1308, 0.1238, 0.1587, 0.1366, 0.1280, 0.0857],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,755][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.0147, 0.0126, 0.1589, 0.7363, 0.0468, 0.0265, 0.0041],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,756][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ on] are: tensor([4.1161e-03, 4.1890e-03, 8.4231e-04, 8.8891e-01, 1.1739e-02, 8.9140e-02,
        1.0623e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,757][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ on] are: tensor([2.6776e-02, 7.5717e-05, 1.0900e-02, 1.4923e-02, 7.8285e-02, 5.0665e-01,
        3.6239e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,758][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.6475, 0.0035, 0.0173, 0.0469, 0.1329, 0.1051, 0.0469],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,759][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.0462, 0.1869, 0.1653, 0.1813, 0.1693, 0.1315, 0.1196],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,760][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.6455, 0.0212, 0.0242, 0.1424, 0.0435, 0.0765, 0.0467],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,806][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:38,807][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,809][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,809][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,810][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,811][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,811][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,812][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,813][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,814][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,814][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,815][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,816][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,816][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.4918, 0.5082], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,817][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.5652, 0.4348], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,818][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.5157, 0.4843], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,819][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.9107, 0.0893], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,820][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.8073, 0.1927], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,822][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.6833, 0.3167], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,823][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.1326, 0.8674], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,825][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.2541, 0.7459], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,825][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.1298, 0.8702], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,826][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.4786, 0.5214], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,827][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.5789, 0.4211], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,828][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.2821, 0.7179], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:38,830][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.3307, 0.3470, 0.3223], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,831][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.3712, 0.2814, 0.3474], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,833][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.2819, 0.3255, 0.3927], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,834][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.0378, 0.9605, 0.0017], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,835][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.4664, 0.2716, 0.2620], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,835][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.5890, 0.2389, 0.1721], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,836][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.0646, 0.8821, 0.0533], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,838][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.0752, 0.4845, 0.4403], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,839][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.0731, 0.7083, 0.2186], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,841][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.3139, 0.3255, 0.3606], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,843][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.3871, 0.2906, 0.3223], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,844][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.1093, 0.5842, 0.3065], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:38,844][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.2468, 0.2660, 0.2439, 0.2434], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,845][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.2678, 0.2149, 0.2652, 0.2520], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,846][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.1878, 0.2414, 0.2851, 0.2856], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,847][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.3899, 0.3073, 0.2860, 0.0169], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,849][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.5148, 0.1848, 0.1282, 0.1722], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,850][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.5112, 0.1980, 0.1432, 0.1476], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,852][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.0749, 0.6696, 0.0956, 0.1599], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,853][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.0997, 0.4009, 0.3772, 0.1222], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,854][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.1011, 0.4679, 0.1808, 0.2503], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,854][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.2049, 0.2358, 0.2819, 0.2775], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,855][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.3128, 0.2261, 0.2472, 0.2139], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,857][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.0604, 0.3751, 0.2350, 0.3295], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:38,858][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.2067, 0.2378, 0.2123, 0.2119, 0.1313], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,860][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([0.2290, 0.1737, 0.2081, 0.2112, 0.1781], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,861][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.1393, 0.1813, 0.2181, 0.2594, 0.2018], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,862][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.0066, 0.0087, 0.0043, 0.9753, 0.0052], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,863][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.3651, 0.1636, 0.2215, 0.1562, 0.0935], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,864][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.4387, 0.1756, 0.1263, 0.1331, 0.1263], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,865][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.0437, 0.3644, 0.0841, 0.4481, 0.0598], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,866][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.0426, 0.2699, 0.2467, 0.0841, 0.3567], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,868][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.0493, 0.4679, 0.1553, 0.2237, 0.1038], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,869][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.1369, 0.1975, 0.2394, 0.1931, 0.2331], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,871][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.2606, 0.1879, 0.2128, 0.1769, 0.1619], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,872][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([0.0564, 0.1749, 0.2154, 0.4491, 0.1041], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:38,872][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.1899, 0.2167, 0.1925, 0.1928, 0.1155, 0.0925], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,873][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.1846, 0.1539, 0.1955, 0.1852, 0.1567, 0.1242], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,874][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.1136, 0.1588, 0.1971, 0.2120, 0.1894, 0.1291], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,876][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.0137, 0.2593, 0.1070, 0.5073, 0.0952, 0.0174], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,877][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.2070, 0.0909, 0.2192, 0.1686, 0.2498, 0.0645], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,879][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.4003, 0.1564, 0.1120, 0.1184, 0.1127, 0.1003], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,881][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.0482, 0.3782, 0.0926, 0.3014, 0.0909, 0.0886], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,882][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.0449, 0.2386, 0.2402, 0.0744, 0.3281, 0.0738], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,882][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.0748, 0.3615, 0.1235, 0.2156, 0.1077, 0.1168], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,883][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([0.1213, 0.1793, 0.1894, 0.1880, 0.2186, 0.1034], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,885][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.2318, 0.1685, 0.1837, 0.1526, 0.1396, 0.1237], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,886][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.0367, 0.2419, 0.1371, 0.3664, 0.1430, 0.0749], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:38,888][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.1736, 0.1975, 0.1765, 0.1764, 0.1078, 0.0866, 0.0816],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,889][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([0.1726, 0.1372, 0.1675, 0.1620, 0.1384, 0.1199, 0.1026],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,890][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.0960, 0.1356, 0.1813, 0.1935, 0.1714, 0.1280, 0.0943],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,891][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.0134, 0.0577, 0.0165, 0.5842, 0.2558, 0.0700, 0.0024],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,892][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.1685, 0.0511, 0.1274, 0.1384, 0.2086, 0.1588, 0.1473],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,893][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.3844, 0.1415, 0.0988, 0.1044, 0.0988, 0.0872, 0.0850],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,894][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.0522, 0.4551, 0.0949, 0.1519, 0.0643, 0.0729, 0.1088],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,896][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.0663, 0.1644, 0.1249, 0.0458, 0.1690, 0.0391, 0.3905],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,898][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.1155, 0.2433, 0.0927, 0.1818, 0.0810, 0.1080, 0.1777],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,899][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([0.0839, 0.1413, 0.1904, 0.1257, 0.2425, 0.0956, 0.1206],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,900][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.1878, 0.1431, 0.1564, 0.1294, 0.1215, 0.1081, 0.1536],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,901][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.0362, 0.2216, 0.1698, 0.2872, 0.0953, 0.0594, 0.1305],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:38,904][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:38,906][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 7777],
        [36351],
        [26090],
        [ 4326],
        [  347],
        [ 1434],
        [ 2707]], device='cuda:0')
[2024-07-23 21:04:38,907][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 7997],
        [39073],
        [29471],
        [ 8195],
        [ 1977],
        [ 2351],
        [ 5347]], device='cuda:0')
[2024-07-23 21:04:38,909][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[33630],
        [42230],
        [43309],
        [44540],
        [45423],
        [46259],
        [46957]], device='cuda:0')
[2024-07-23 21:04:38,909][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[42307],
        [30307],
        [21877],
        [13534],
        [ 5746],
        [ 8624],
        [ 9236]], device='cuda:0')
[2024-07-23 21:04:38,910][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[13720],
        [36361],
        [14259],
        [18346],
        [38491],
        [38454],
        [38532]], device='cuda:0')
[2024-07-23 21:04:38,911][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[20245],
        [34355],
        [26693],
        [19992],
        [26885],
        [26888],
        [40706]], device='cuda:0')
[2024-07-23 21:04:38,913][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[41653],
        [40122],
        [44304],
        [44035],
        [43948],
        [44047],
        [44481]], device='cuda:0')
[2024-07-23 21:04:38,914][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[27822],
        [24801],
        [25535],
        [26596],
        [23091],
        [21764],
        [21467]], device='cuda:0')
[2024-07-23 21:04:38,915][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[41866],
        [30111],
        [23460],
        [29860],
        [13693],
        [15935],
        [17658]], device='cuda:0')
[2024-07-23 21:04:38,917][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[4379],
        [4346],
        [3619],
        [8730],
        [3495],
        [4120],
        [2820]], device='cuda:0')
[2024-07-23 21:04:38,918][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[11698],
        [ 4547],
        [11920],
        [25408],
        [25969],
        [26823],
        [24340]], device='cuda:0')
[2024-07-23 21:04:38,919][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[ 8951],
        [11099],
        [11408],
        [10054],
        [11095],
        [11214],
        [10246]], device='cuda:0')
[2024-07-23 21:04:38,920][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[20480],
        [19403],
        [19755],
        [19767],
        [21332],
        [23205],
        [24594]], device='cuda:0')
[2024-07-23 21:04:38,921][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[1812],
        [2164],
        [2352],
        [2313],
        [2975],
        [2972],
        [2908]], device='cuda:0')
[2024-07-23 21:04:38,922][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[11397],
        [37495],
        [27721],
        [ 3089],
        [  201],
        [ 5619],
        [ 7679]], device='cuda:0')
[2024-07-23 21:04:38,924][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[46596],
        [46285],
        [45923],
        [46104],
        [46310],
        [46265],
        [46212]], device='cuda:0')
[2024-07-23 21:04:38,925][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[28640],
        [20677],
        [18591],
        [18228],
        [17534],
        [17307],
        [18250]], device='cuda:0')
[2024-07-23 21:04:38,926][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[30699],
        [29335],
        [27859],
        [29613],
        [28051],
        [26996],
        [26657]], device='cuda:0')
[2024-07-23 21:04:38,928][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[29187],
        [26367],
        [23928],
        [23481],
        [31464],
        [22800],
        [19243]], device='cuda:0')
[2024-07-23 21:04:38,929][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[22172],
        [17510],
        [25155],
        [25648],
        [25588],
        [23156],
        [22042]], device='cuda:0')
[2024-07-23 21:04:38,930][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[23090],
        [16959],
        [14399],
        [13074],
        [12113],
        [11582],
        [11423]], device='cuda:0')
[2024-07-23 21:04:38,932][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[9178],
        [9161],
        [9593],
        [8967],
        [7578],
        [8089],
        [8459]], device='cuda:0')
[2024-07-23 21:04:38,933][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[2132],
        [2019],
        [2312],
        [2258],
        [2219],
        [2236],
        [1808]], device='cuda:0')
[2024-07-23 21:04:38,934][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[35919],
        [34558],
        [34978],
        [36256],
        [36873],
        [36783],
        [36489]], device='cuda:0')
[2024-07-23 21:04:38,935][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[11535],
        [11935],
        [ 9035],
        [ 8790],
        [10108],
        [10169],
        [10374]], device='cuda:0')
[2024-07-23 21:04:38,936][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[24091],
        [23741],
        [21739],
        [21752],
        [22212],
        [22221],
        [22063]], device='cuda:0')
[2024-07-23 21:04:38,937][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[40872],
        [44340],
        [44582],
        [45063],
        [44944],
        [44742],
        [45287]], device='cuda:0')
[2024-07-23 21:04:38,939][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[ 7894],
        [10517],
        [10817],
        [10475],
        [ 9895],
        [10862],
        [11059]], device='cuda:0')
[2024-07-23 21:04:38,940][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[20729],
        [12254],
        [16822],
        [29965],
        [31529],
        [30259],
        [26535]], device='cuda:0')
[2024-07-23 21:04:38,941][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[10264],
        [10264],
        [10264],
        [10264],
        [10264],
        [10264],
        [10264]], device='cuda:0')
[2024-07-23 21:04:38,996][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:38,997][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,998][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:38,999][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,000][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,001][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,002][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,003][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,004][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,006][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,007][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,007][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,008][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,009][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.2511, 0.7489], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,010][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.0484, 0.9516], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,012][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.7744, 0.2256], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,013][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([9.9949e-01, 5.1447e-04], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,015][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.4671, 0.5329], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,016][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.8373, 0.1627], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,017][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.2037, 0.7963], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,017][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.3902, 0.6098], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,018][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.1563, 0.8437], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,020][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.3586, 0.6414], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,021][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.4037, 0.5963], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,022][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([9.9997e-01, 3.2459e-05], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,024][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.1869, 0.6213, 0.1919], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,025][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.0161, 0.1272, 0.8566], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,026][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.6672, 0.0920, 0.2407], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,027][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.9747, 0.0081, 0.0172], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,027][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.3057, 0.3482, 0.3461], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,029][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.1506, 0.0741, 0.7753], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,031][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.1142, 0.4851, 0.4006], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,032][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.2428, 0.3576, 0.3996], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,034][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.0301, 0.8676, 0.1023], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,035][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.2699, 0.3596, 0.3706], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,035][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.2502, 0.3920, 0.3577], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,036][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([2.8584e-02, 9.7135e-01, 6.9199e-05], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,037][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.1862, 0.5996, 0.1947, 0.0194], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,038][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.0158, 0.0819, 0.4630, 0.4394], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,040][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.5081, 0.0692, 0.1973, 0.2254], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,041][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([9.7441e-01, 4.7409e-04, 8.9460e-03, 1.6169e-02], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,043][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.2310, 0.2596, 0.2543, 0.2552], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,044][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.2055, 0.0091, 0.4406, 0.3448], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,045][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.0639, 0.3410, 0.2909, 0.3042], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,046][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.1480, 0.2697, 0.2967, 0.2857], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,046][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.0197, 0.5223, 0.1199, 0.3381], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,048][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.1549, 0.1856, 0.2227, 0.4368], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,049][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.1833, 0.2901, 0.2644, 0.2623], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,050][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([4.6403e-04, 1.1434e-01, 5.1853e-01, 3.6667e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,052][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.1110, 0.6539, 0.1125, 0.0566, 0.0660], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,054][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.0305, 0.0316, 0.0931, 0.1111, 0.7338], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,054][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.3238, 0.0326, 0.0961, 0.1277, 0.4198], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,055][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.4513, 0.0023, 0.1548, 0.2203, 0.1713], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,056][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.1829, 0.2090, 0.2070, 0.1961, 0.2050], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,057][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.0984, 0.0141, 0.2284, 0.2911, 0.3679], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,059][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.0483, 0.2712, 0.2211, 0.2544, 0.2051], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,060][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.1235, 0.2083, 0.2407, 0.2277, 0.1997], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,062][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.0109, 0.4668, 0.1262, 0.3562, 0.0399], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,063][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.1539, 0.1518, 0.1205, 0.3516, 0.2222], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,064][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.1387, 0.2385, 0.2145, 0.2137, 0.1946], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,064][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([1.1973e-10, 1.6718e-08, 2.9957e-08, 1.0000e+00, 3.0666e-10],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,065][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.0250, 0.7270, 0.1314, 0.0256, 0.0694, 0.0216], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,067][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [res] are: tensor([0.0023, 0.0123, 0.0679, 0.0794, 0.7566, 0.0816], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,068][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.3062, 0.0244, 0.0789, 0.1088, 0.2972, 0.1845], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,069][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [res] are: tensor([9.6883e-01, 8.8322e-05, 3.4513e-03, 5.2258e-03, 1.6312e-02, 6.0956e-03],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,071][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [res] are: tensor([0.1559, 0.1767, 0.1768, 0.1703, 0.1676, 0.1527], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,072][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.1194, 0.0055, 0.0661, 0.1251, 0.3625, 0.3215], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,073][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.0406, 0.2131, 0.1803, 0.2028, 0.1848, 0.1784], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,074][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.0857, 0.1848, 0.2073, 0.1924, 0.1709, 0.1588], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,074][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.0124, 0.3020, 0.1505, 0.1346, 0.3493, 0.0513], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,076][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.0486, 0.0701, 0.1266, 0.2382, 0.3172, 0.1993], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,078][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.1111, 0.2072, 0.1838, 0.1838, 0.1667, 0.1474], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,079][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [res] are: tensor([1.5079e-07, 1.0048e-06, 1.1012e-06, 9.7614e-01, 2.3859e-02, 2.7671e-10],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,080][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ on] are: tensor([0.0996, 0.6808, 0.1015, 0.0088, 0.0430, 0.0335, 0.0328],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,082][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.0432, 0.0214, 0.0451, 0.0526, 0.2956, 0.0350, 0.5070],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,082][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.2968, 0.0240, 0.0628, 0.0932, 0.2029, 0.1435, 0.1767],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,083][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ on] are: tensor([4.9246e-01, 3.4809e-04, 2.0795e-02, 5.1561e-02, 2.0550e-01, 1.9140e-01,
        3.7928e-02], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,084][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.1323, 0.1515, 0.1529, 0.1433, 0.1423, 0.1289, 0.1488],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,085][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.0243, 0.0050, 0.0779, 0.1064, 0.3566, 0.3208, 0.1090],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,087][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.0311, 0.1852, 0.1517, 0.1662, 0.1498, 0.1503, 0.1658],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,089][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.0810, 0.1612, 0.1788, 0.1721, 0.1493, 0.1334, 0.1242],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,090][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.0211, 0.4731, 0.0919, 0.0921, 0.0715, 0.0849, 0.1655],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,091][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.0485, 0.0694, 0.1063, 0.2455, 0.2269, 0.1982, 0.1052],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,092][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.0926, 0.1839, 0.1623, 0.1627, 0.1459, 0.1279, 0.1247],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,092][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ on] are: tensor([2.7855e-11, 1.4457e-08, 6.5355e-09, 9.9997e-01, 2.7092e-05, 1.7079e-06,
        9.0522e-14], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,142][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:39,142][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,143][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,143][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,143][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,143][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,144][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,145][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,145][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,146][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,146][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,146][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,147][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,147][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.7941, 0.2059], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,147][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.7294, 0.2706], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,149][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.8811, 0.1189], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,150][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.9669, 0.0331], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,151][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.4977, 0.5023], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,153][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.8373, 0.1627], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,153][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.8689, 0.1311], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,154][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.2800, 0.7200], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,154][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.7840, 0.2160], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,154][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.9267, 0.0733], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,155][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.9159, 0.0841], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,155][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([1.0000e+00, 3.8581e-06], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,155][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.5825, 0.0328, 0.3847], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,156][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.1228, 0.0759, 0.8013], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,157][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.8701, 0.0311, 0.0989], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,158][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.6837, 0.1071, 0.2092], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,160][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.5739, 0.2969, 0.1292], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,161][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.1506, 0.0741, 0.7753], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,162][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.6526, 0.1211, 0.2264], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,163][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.0206, 0.0869, 0.8925], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,163][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.6468, 0.2815, 0.0717], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,163][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.9208, 0.0204, 0.0589], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,164][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.8503, 0.1053, 0.0444], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,164][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([3.3826e-05, 2.8319e-01, 7.1678e-01], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,164][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.5789, 0.0075, 0.0673, 0.3463], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,165][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.2930, 0.0140, 0.3389, 0.3541], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,166][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.7701, 0.0132, 0.0778, 0.1389], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,167][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.3837, 0.0193, 0.1780, 0.4190], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,168][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.8311, 0.0637, 0.0371, 0.0682], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,170][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.2055, 0.0091, 0.4406, 0.3448], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,171][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.2743, 0.0535, 0.3252, 0.3471], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,172][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.0106, 0.0202, 0.4066, 0.5627], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,172][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.5232, 0.1669, 0.1224, 0.1876], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,172][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.7125, 0.0164, 0.0968, 0.1743], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,173][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.8743, 0.0485, 0.0139, 0.0633], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,173][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([2.5264e-06, 4.9633e-07, 6.1085e-01, 3.8915e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,173][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.2115, 0.0009, 0.0110, 0.0807, 0.6959], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,174][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([0.2627, 0.0224, 0.1146, 0.2925, 0.3078], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,175][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.4549, 0.0079, 0.0381, 0.0978, 0.4012], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,176][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.0215, 0.0062, 0.2342, 0.3199, 0.4181], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,177][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.8527, 0.0082, 0.0223, 0.0437, 0.0731], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,179][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.0984, 0.0141, 0.2284, 0.2911, 0.3679], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,180][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.1535, 0.0321, 0.2211, 0.4360, 0.1573], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,181][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.0013, 0.0035, 0.0922, 0.1169, 0.7860], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,181][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.5642, 0.0697, 0.2022, 0.1047, 0.0591], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,182][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.3474, 0.0121, 0.1009, 0.1831, 0.3566], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,182][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.8096, 0.0511, 0.0385, 0.0666, 0.0342], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,182][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([5.5687e-10, 5.3359e-10, 1.3938e-02, 8.0240e-01, 1.8367e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,183][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([1.4483e-01, 4.0668e-04, 1.2927e-02, 5.2789e-02, 4.9572e-01, 2.9334e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,183][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.0945, 0.0078, 0.0929, 0.1145, 0.2463, 0.4440], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,184][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.6200, 0.0064, 0.0302, 0.0859, 0.2047, 0.0528], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,185][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.1066, 0.0040, 0.0623, 0.1378, 0.4644, 0.2249], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,186][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.8397, 0.0129, 0.0252, 0.0297, 0.0407, 0.0518], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,188][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.1194, 0.0055, 0.0661, 0.1251, 0.3625, 0.3215], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,189][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.1195, 0.0068, 0.1207, 0.1957, 0.1848, 0.3724], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,190][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([1.9179e-03, 6.2188e-04, 1.7438e-02, 3.4341e-02, 1.7445e-01, 7.7123e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,191][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.1388, 0.0194, 0.1113, 0.0120, 0.7029, 0.0156], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,191][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([0.3503, 0.0065, 0.0409, 0.1158, 0.2906, 0.1959], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,191][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.8255, 0.0265, 0.0092, 0.0438, 0.0453, 0.0498], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,192][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([3.4737e-10, 9.4506e-14, 2.5655e-06, 1.4800e-05, 9.8234e-01, 1.7643e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,192][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([1.4782e-02, 4.4112e-04, 8.5520e-03, 3.8829e-02, 4.5604e-01, 4.3507e-01,
        4.6292e-02], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,192][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([0.0300, 0.0061, 0.0997, 0.0832, 0.1949, 0.5081, 0.0779],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,193][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.4867, 0.0104, 0.0399, 0.0920, 0.2326, 0.0734, 0.0651],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,194][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.0149, 0.0014, 0.0310, 0.0817, 0.3985, 0.2833, 0.1893],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,196][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.4141, 0.0250, 0.0877, 0.0657, 0.2317, 0.1108, 0.0649],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,197][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.0243, 0.0050, 0.0779, 0.1064, 0.3566, 0.3208, 0.1090],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,199][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.0499, 0.0052, 0.0990, 0.1605, 0.1603, 0.3366, 0.1886],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,200][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.0006, 0.0006, 0.0175, 0.0349, 0.2528, 0.4438, 0.2498],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,200][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.1266, 0.1020, 0.0792, 0.0317, 0.1730, 0.2065, 0.2810],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,200][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([0.1697, 0.0042, 0.0395, 0.1166, 0.3937, 0.1750, 0.1013],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,201][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.7177, 0.0382, 0.0155, 0.0622, 0.0250, 0.0517, 0.0897],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,201][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([1.6112e-14, 9.1588e-17, 2.6333e-07, 8.3520e-05, 8.0470e-01, 1.9521e-01,
        1.7443e-06], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,203][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:39,204][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 7031],
        [25034],
        [10408],
        [ 2508],
        [  718],
        [ 1300],
        [ 5603]], device='cuda:0')
[2024-07-23 21:04:39,205][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 7814],
        [33672],
        [25332],
        [ 7245],
        [ 1915],
        [ 5183],
        [10555]], device='cuda:0')
[2024-07-23 21:04:39,206][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[1129],
        [3910],
        [3685],
        [3752],
        [3470],
        [3564],
        [3175]], device='cuda:0')
[2024-07-23 21:04:39,207][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[15926],
        [13530],
        [13562],
        [15236],
        [20789],
        [21455],
        [21789]], device='cuda:0')
[2024-07-23 21:04:39,208][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[ 7893],
        [12762],
        [10082],
        [10385],
        [11450],
        [11409],
        [11571]], device='cuda:0')
[2024-07-23 21:04:39,209][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[8789],
        [8755],
        [7662],
        [7919],
        [5203],
        [8035],
        [5542]], device='cuda:0')
[2024-07-23 21:04:39,211][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[4111],
        [3765],
        [5407],
        [6224],
        [6681],
        [6823],
        [7242]], device='cuda:0')
[2024-07-23 21:04:39,212][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[42195],
        [35263],
        [49192],
        [47465],
        [42373],
        [37755],
        [37693]], device='cuda:0')
[2024-07-23 21:04:39,213][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[20037],
        [16213],
        [15670],
        [14911],
        [14338],
        [14597],
        [15159]], device='cuda:0')
[2024-07-23 21:04:39,214][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[4622],
        [4477],
        [4039],
        [4361],
        [4045],
        [4012],
        [3597]], device='cuda:0')
[2024-07-23 21:04:39,215][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[ 5946],
        [13366],
        [14640],
        [12471],
        [12258],
        [11949],
        [12367]], device='cuda:0')
[2024-07-23 21:04:39,216][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[25548],
        [29256],
        [34931],
        [38317],
        [39025],
        [41504],
        [42044]], device='cuda:0')
[2024-07-23 21:04:39,216][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[10058],
        [10897],
        [10523],
        [10587],
        [10745],
        [11066],
        [11323]], device='cuda:0')
[2024-07-23 21:04:39,217][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[13866],
        [13864],
        [ 4320],
        [17433],
        [ 3354],
        [ 3354],
        [ 3354]], device='cuda:0')
[2024-07-23 21:04:39,218][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 3083],
        [18768],
        [ 6630],
        [ 4131],
        [10884],
        [ 4385],
        [ 8155]], device='cuda:0')
[2024-07-23 21:04:39,219][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[30321],
        [20049],
        [29068],
        [20689],
        [10224],
        [ 6145],
        [ 4926]], device='cuda:0')
[2024-07-23 21:04:39,220][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[1828],
        [6357],
        [8500],
        [5106],
        [4831],
        [5171],
        [5563]], device='cuda:0')
[2024-07-23 21:04:39,221][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[ 9452],
        [12489],
        [19279],
        [30010],
        [28959],
        [31470],
        [29194]], device='cuda:0')
[2024-07-23 21:04:39,222][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[8161],
        [7278],
        [3742],
        [3496],
        [2151],
        [2977],
        [4786]], device='cuda:0')
[2024-07-23 21:04:39,224][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[31354],
        [ 5389],
        [ 6360],
        [11642],
        [ 7896],
        [11423],
        [ 7991]], device='cuda:0')
[2024-07-23 21:04:39,225][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[ 9449],
        [13121],
        [13261],
        [12812],
        [ 8684],
        [ 6103],
        [ 5962]], device='cuda:0')
[2024-07-23 21:04:39,225][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[ 5588],
        [10396],
        [16887],
        [22012],
        [25916],
        [29131],
        [31036]], device='cuda:0')
[2024-07-23 21:04:39,226][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[33628],
        [22113],
        [31629],
        [30619],
        [27386],
        [25916],
        [27128]], device='cuda:0')
[2024-07-23 21:04:39,227][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[29356],
        [29671],
        [32166],
        [26658],
        [33653],
        [27703],
        [38816]], device='cuda:0')
[2024-07-23 21:04:39,228][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[17703],
        [13084],
        [16768],
        [11650],
        [ 9051],
        [ 6057],
        [ 6798]], device='cuda:0')
[2024-07-23 21:04:39,229][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[10598],
        [ 9723],
        [ 9830],
        [ 9620],
        [ 9989],
        [11924],
        [10769]], device='cuda:0')
[2024-07-23 21:04:39,230][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[34687],
        [34687],
        [41707],
        [38284],
        [22893],
        [28323],
        [29270]], device='cuda:0')
[2024-07-23 21:04:39,231][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[33115],
        [34036],
        [26800],
        [29444],
        [34814],
        [35338],
        [35063]], device='cuda:0')
[2024-07-23 21:04:39,232][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[41103],
        [20179],
        [21686],
        [26845],
        [11544],
        [25804],
        [12216]], device='cuda:0')
[2024-07-23 21:04:39,233][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[7004],
        [7004],
        [7004],
        [7004],
        [7004],
        [7004],
        [7004]], device='cuda:0')
[2024-07-23 21:04:39,271][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:39,272][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,272][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,273][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,273][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,273][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,274][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,275][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,276][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,277][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,278][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,279][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,280][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,280][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.0039, 0.9961], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,281][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.6036, 0.3964], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,281][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.0619, 0.9381], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,281][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.7915, 0.2085], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,282][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.9396, 0.0604], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,282][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.5218, 0.4782], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,282][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.3469, 0.6531], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,283][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.4562, 0.5438], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,294][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.1197, 0.8803], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,296][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.0597, 0.9403], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,297][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.1211, 0.8789], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,298][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.1083, 0.8917], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,298][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.0013, 0.6317, 0.3670], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,299][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.1718, 0.1919, 0.6363], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,299][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.0176, 0.5310, 0.4514], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,299][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.3987, 0.2165, 0.3848], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,300][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.3413, 0.0840, 0.5747], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,300][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.3657, 0.2967, 0.3375], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,300][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.2011, 0.3534, 0.4455], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,301][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.1029, 0.2388, 0.6583], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,303][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.0405, 0.6883, 0.2712], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,304][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.0240, 0.5165, 0.4595], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,305][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.1096, 0.4211, 0.4693], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,307][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.0482, 0.5014, 0.4504], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,307][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.0015, 0.4114, 0.2574, 0.3297], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,308][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.2388, 0.0938, 0.1598, 0.5076], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,308][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.0096, 0.3766, 0.3206, 0.2932], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,308][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.3304, 0.2486, 0.3266, 0.0944], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,309][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.3412, 0.0590, 0.4406, 0.1593], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,309][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.2772, 0.2212, 0.2555, 0.2461], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,309][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.0713, 0.2955, 0.4216, 0.2116], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,310][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.0653, 0.2177, 0.4055, 0.3115], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,311][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.0391, 0.4801, 0.4047, 0.0761], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,312][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.0133, 0.3567, 0.3184, 0.3115], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,314][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.0503, 0.2833, 0.3488, 0.3177], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,315][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.0294, 0.3430, 0.3054, 0.3222], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,317][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.0007, 0.3598, 0.1845, 0.2687, 0.1863], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,317][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.0668, 0.0639, 0.1064, 0.3217, 0.4412], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,317][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.0041, 0.3109, 0.2605, 0.2378, 0.1868], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,318][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.1207, 0.1579, 0.4182, 0.1736, 0.1296], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,318][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.2936, 0.0284, 0.1571, 0.1378, 0.3832], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,319][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.2391, 0.1726, 0.2028, 0.2003, 0.1852], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,319][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.0690, 0.2354, 0.3079, 0.2521, 0.1356], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,319][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.0615, 0.1781, 0.3599, 0.2162, 0.1843], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,321][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.0280, 0.4625, 0.2593, 0.1331, 0.1171], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,322][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.0059, 0.2886, 0.2551, 0.2485, 0.2019], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,323][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.0643, 0.2581, 0.2274, 0.2104, 0.2398], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,325][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([0.0183, 0.2605, 0.2290, 0.2389, 0.2533], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,326][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.0004, 0.3064, 0.1484, 0.2268, 0.1819, 0.1361], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,327][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [res] are: tensor([0.1038, 0.0661, 0.0786, 0.2543, 0.2959, 0.2013], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,327][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.0035, 0.2737, 0.2285, 0.2073, 0.1636, 0.1234], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,327][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [res] are: tensor([0.2834, 0.0553, 0.1860, 0.1122, 0.2851, 0.0780], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,328][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [res] are: tensor([0.0952, 0.0133, 0.1299, 0.0590, 0.4753, 0.2273], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,328][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.1724, 0.1512, 0.1699, 0.1721, 0.1611, 0.1733], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,328][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.0721, 0.2438, 0.2465, 0.2239, 0.1075, 0.1062], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,329][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.0367, 0.1759, 0.2568, 0.3131, 0.1213, 0.0961], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,330][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.0085, 0.3444, 0.2717, 0.1146, 0.1555, 0.1054], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,332][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.0054, 0.2413, 0.2131, 0.2084, 0.1707, 0.1611], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,333][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.0590, 0.2569, 0.1915, 0.1664, 0.1519, 0.1743], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,335][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.0168, 0.2052, 0.1831, 0.1909, 0.2025, 0.2015], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,335][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ on] are: tensor([0.0003, 0.2461, 0.1322, 0.1843, 0.1703, 0.1157, 0.1511],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,336][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.0450, 0.0757, 0.1350, 0.1954, 0.2700, 0.1176, 0.1613],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,336][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.0016, 0.2502, 0.2090, 0.1890, 0.1483, 0.1062, 0.0956],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,337][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ on] are: tensor([0.0808, 0.0293, 0.0952, 0.2866, 0.1903, 0.2509, 0.0669],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,337][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.0371, 0.0112, 0.1223, 0.0558, 0.4361, 0.2755, 0.0620],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,337][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.1643, 0.1251, 0.1454, 0.1459, 0.1342, 0.1470, 0.1382],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,338][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.0759, 0.1887, 0.2237, 0.1632, 0.1093, 0.1386, 0.1005],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,339][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.0367, 0.1153, 0.2088, 0.1845, 0.1542, 0.1075, 0.1928],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,340][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.0119, 0.3746, 0.2469, 0.0833, 0.1169, 0.1202, 0.0462],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,342][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.0036, 0.2134, 0.1878, 0.1829, 0.1483, 0.1391, 0.1249],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,343][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.0497, 0.2056, 0.1724, 0.1570, 0.1392, 0.1437, 0.1324],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,345][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.0130, 0.1736, 0.1520, 0.1555, 0.1630, 0.1612, 0.1816],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,385][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:39,386][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,387][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,387][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,388][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,389][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,389][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,390][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,391][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,392][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,394][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,395][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,397][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,397][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.9433, 0.0567], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,398][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.9492, 0.0508], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,399][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.5941, 0.4059], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,400][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.8278, 0.1722], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,402][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.9396, 0.0604], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,403][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.9023, 0.0977], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,405][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.9423, 0.0577], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,406][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.8187, 0.1813], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,407][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.8895, 0.1105], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,407][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.9936, 0.0064], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,408][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.9426, 0.0574], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,410][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.9390, 0.0610], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,411][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.9178, 0.0373, 0.0448], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,413][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.7178, 0.0154, 0.2668], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,415][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.5917, 0.3293, 0.0789], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,416][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.4404, 0.1900, 0.3696], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,417][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.3413, 0.0840, 0.5747], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,417][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.9533, 0.0325, 0.0143], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,418][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.7034, 0.1561, 0.1405], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,420][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.8695, 0.0587, 0.0718], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,421][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.6122, 0.0761, 0.3116], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,422][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([9.9303e-01, 6.1099e-03, 8.6003e-04], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,424][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.9881, 0.0035, 0.0084], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,426][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.8799, 0.0990, 0.0211], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,426][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.5951, 0.0275, 0.0457, 0.3318], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,427][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.5171, 0.0087, 0.0165, 0.4577], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,428][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.4169, 0.2053, 0.1464, 0.2314], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,429][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.2780, 0.0715, 0.1898, 0.4607], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,431][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.3412, 0.0590, 0.4406, 0.1593], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,433][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.4210, 0.0660, 0.0160, 0.4969], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,434][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.5278, 0.0228, 0.1326, 0.3169], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,435][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.5705, 0.0619, 0.1199, 0.2477], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,436][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.4144, 0.0640, 0.1662, 0.3554], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,437][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.8990, 0.0336, 0.0278, 0.0396], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,437][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.8664, 0.0146, 0.0466, 0.0723], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,439][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.7614, 0.0653, 0.0314, 0.1419], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,441][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.8345, 0.0188, 0.0123, 0.0730, 0.0614], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,442][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([0.7760, 0.0050, 0.0091, 0.0831, 0.1268], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,444][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.2022, 0.1140, 0.1482, 0.2538, 0.2819], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,445][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.1028, 0.0433, 0.1435, 0.3426, 0.3678], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,446][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.2936, 0.0284, 0.1571, 0.1378, 0.3832], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,446][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.8965, 0.0078, 0.0022, 0.0369, 0.0566], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,447][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.1946, 0.0210, 0.2211, 0.3498, 0.2135], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,449][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.7235, 0.0153, 0.0226, 0.0696, 0.1689], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,450][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.5646, 0.0776, 0.0418, 0.1824, 0.1336], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,452][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.9190, 0.0168, 0.0232, 0.0356, 0.0053], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,454][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.7702, 0.0044, 0.0142, 0.0849, 0.1263], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,455][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([0.7869, 0.0264, 0.0183, 0.1100, 0.0585], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,455][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.7132, 0.0346, 0.0155, 0.1378, 0.0704, 0.0287], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,456][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.9367, 0.0015, 0.0013, 0.0259, 0.0198, 0.0148], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,457][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.0916, 0.0534, 0.1094, 0.1744, 0.4466, 0.1246], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,458][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.0819, 0.0265, 0.1054, 0.1505, 0.3317, 0.3040], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,460][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.0952, 0.0133, 0.1299, 0.0590, 0.4753, 0.2273], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,462][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.8493, 0.0170, 0.0016, 0.0516, 0.0637, 0.0169], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,463][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.1737, 0.0070, 0.0582, 0.0569, 0.5902, 0.1138], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,464][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.1342, 0.0103, 0.0322, 0.0513, 0.7332, 0.0389], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,465][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.5312, 0.0345, 0.0480, 0.1294, 0.1528, 0.1041], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,466][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([0.8768, 0.0233, 0.0282, 0.0454, 0.0175, 0.0087], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,467][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.8346, 0.0027, 0.0138, 0.0403, 0.0947, 0.0139], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,468][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.8683, 0.0083, 0.0078, 0.0584, 0.0188, 0.0384], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,470][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.8263, 0.0171, 0.0075, 0.0702, 0.0477, 0.0111, 0.0202],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,471][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([9.6074e-01, 9.6499e-04, 9.1490e-04, 1.6301e-02, 1.0755e-02, 1.5960e-03,
        8.7238e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,472][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.0956, 0.0463, 0.0921, 0.1907, 0.3787, 0.1377, 0.0589],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,474][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.0407, 0.0174, 0.0782, 0.1541, 0.2500, 0.3657, 0.0939],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,475][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.0371, 0.0112, 0.1223, 0.0558, 0.4361, 0.2755, 0.0620],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,476][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.9116, 0.0129, 0.0017, 0.0441, 0.0247, 0.0020, 0.0030],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,476][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.0598, 0.0034, 0.0978, 0.1563, 0.4457, 0.2075, 0.0296],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,478][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.1307, 0.0093, 0.0393, 0.0585, 0.6654, 0.0702, 0.0265],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,479][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.5603, 0.0224, 0.0398, 0.1261, 0.1298, 0.0621, 0.0594],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,481][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([0.8628, 0.0251, 0.0260, 0.0417, 0.0194, 0.0147, 0.0103],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,483][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.8016, 0.0067, 0.0181, 0.0566, 0.0775, 0.0221, 0.0174],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,484][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.7158, 0.0283, 0.0160, 0.0903, 0.0316, 0.0447, 0.0733],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,487][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:39,489][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 7111],
        [30898],
        [14664],
        [ 6482],
        [ 2389],
        [ 2887],
        [10423]], device='cuda:0')
[2024-07-23 21:04:39,490][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 7195],
        [23171],
        [ 6699],
        [ 1244],
        [  789],
        [ 1067],
        [ 7164]], device='cuda:0')
[2024-07-23 21:04:39,492][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[36201],
        [36233],
        [36517],
        [34520],
        [32318],
        [31037],
        [29859]], device='cuda:0')
[2024-07-23 21:04:39,493][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[23116],
        [16458],
        [ 9016],
        [11713],
        [13396],
        [13246],
        [11535]], device='cuda:0')
[2024-07-23 21:04:39,494][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[2103],
        [4291],
        [4525],
        [4445],
        [4241],
        [4069],
        [4072]], device='cuda:0')
[2024-07-23 21:04:39,495][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[14760],
        [18447],
        [20053],
        [18280],
        [18192],
        [24328],
        [28087]], device='cuda:0')
[2024-07-23 21:04:39,497][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[40309],
        [38705],
        [10403],
        [11104],
        [13752],
        [11665],
        [11648]], device='cuda:0')
[2024-07-23 21:04:39,498][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[20400],
        [21514],
        [20104],
        [20885],
        [22843],
        [23579],
        [23752]], device='cuda:0')
[2024-07-23 21:04:39,499][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[15911],
        [17890],
        [ 7426],
        [ 7842],
        [ 7195],
        [ 7158],
        [ 5669]], device='cuda:0')
[2024-07-23 21:04:39,500][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[13401],
        [33057],
        [39718],
        [42159],
        [39182],
        [41636],
        [40049]], device='cuda:0')
[2024-07-23 21:04:39,501][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[46949],
        [49583],
        [49687],
        [49737],
        [49809],
        [49891],
        [49870]], device='cuda:0')
[2024-07-23 21:04:39,502][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[22618],
        [35272],
        [35428],
        [35619],
        [35913],
        [35529],
        [35097]], device='cuda:0')
[2024-07-23 21:04:39,504][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[15275],
        [24137],
        [27052],
        [31654],
        [25018],
        [24269],
        [22877]], device='cuda:0')
[2024-07-23 21:04:39,505][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[2998],
        [1000],
        [ 914],
        [ 805],
        [ 676],
        [ 791],
        [ 906]], device='cuda:0')
[2024-07-23 21:04:39,506][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[14256],
        [26023],
        [35453],
        [29975],
        [15080],
        [17049],
        [16884]], device='cuda:0')
[2024-07-23 21:04:39,508][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 8385],
        [ 6513],
        [ 6107],
        [13051],
        [ 7468],
        [ 9893],
        [ 7866]], device='cuda:0')
[2024-07-23 21:04:39,509][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[27831],
        [26231],
        [16970],
        [10617],
        [20248],
        [26344],
        [27148]], device='cuda:0')
[2024-07-23 21:04:39,510][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[19313],
        [ 2945],
        [ 3066],
        [ 2763],
        [ 1423],
        [ 1242],
        [ 1374]], device='cuda:0')
[2024-07-23 21:04:39,511][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[ 460],
        [ 299],
        [1971],
        [1973],
        [2695],
        [2262],
        [2191]], device='cuda:0')
[2024-07-23 21:04:39,512][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 8475],
        [10241],
        [29401],
        [34104],
        [28540],
        [25338],
        [26701]], device='cuda:0')
[2024-07-23 21:04:39,513][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[ 2823],
        [ 2487],
        [ 2565],
        [23617],
        [ 2286],
        [ 2578],
        [ 2593]], device='cuda:0')
[2024-07-23 21:04:39,515][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[42585],
        [44668],
        [42205],
        [43260],
        [42185],
        [41364],
        [42052]], device='cuda:0')
[2024-07-23 21:04:39,516][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[31544],
        [17329],
        [23503],
        [21315],
        [34217],
        [27817],
        [28510]], device='cuda:0')
[2024-07-23 21:04:39,517][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[21210],
        [19367],
        [12498],
        [19742],
        [12093],
        [ 9340],
        [10560]], device='cuda:0')
[2024-07-23 21:04:39,518][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[44427],
        [44512],
        [44512],
        [45431],
        [45128],
        [45242],
        [45176]], device='cuda:0')
[2024-07-23 21:04:39,520][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[20438],
        [19154],
        [20578],
        [17034],
        [14515],
        [16755],
        [16272]], device='cuda:0')
[2024-07-23 21:04:39,521][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[11637],
        [10682],
        [12551],
        [30179],
        [38732],
        [25716],
        [37648]], device='cuda:0')
[2024-07-23 21:04:39,522][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[20313],
        [27914],
        [25433],
        [18187],
        [23430],
        [25213],
        [23871]], device='cuda:0')
[2024-07-23 21:04:39,523][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[14291],
        [25761],
        [22888],
        [16594],
        [19964],
        [16071],
        [16703]], device='cuda:0')
[2024-07-23 21:04:39,524][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[7401],
        [7401],
        [7401],
        [7401],
        [7401],
        [7401],
        [7401]], device='cuda:0')
[2024-07-23 21:04:39,591][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:39,593][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,594][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,595][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,596][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,597][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,597][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,598][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,599][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,600][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,600][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,601][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,602][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,602][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.1677, 0.8323], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,603][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.3474, 0.6526], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,604][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.3495, 0.6505], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,604][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.9903, 0.0097], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,605][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.7726, 0.2274], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,606][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.9328, 0.0672], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,606][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([9.9967e-01, 3.3156e-04], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,608][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.9086, 0.0914], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,609][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.9938, 0.0062], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,611][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.2628, 0.7372], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,612][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.0962, 0.9038], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,613][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.8942, 0.1058], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,614][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.0375, 0.6025, 0.3600], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,614][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.1815, 0.4382, 0.3803], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,615][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.1999, 0.5298, 0.2702], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,617][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.9616, 0.0180, 0.0203], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,618][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.8931, 0.0710, 0.0359], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,620][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.6695, 0.1234, 0.2071], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,621][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([9.9943e-01, 2.3608e-04, 3.3314e-04], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,623][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.6836, 0.1318, 0.1846], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,623][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.9533, 0.0216, 0.0251], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,624][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.1001, 0.3794, 0.5205], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,625][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.1442, 0.5032, 0.3526], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,626][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.7549, 0.0769, 0.1682], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,628][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.0253, 0.4208, 0.2379, 0.3160], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,630][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.0399, 0.2623, 0.3577, 0.3400], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,631][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.1471, 0.4202, 0.2096, 0.2232], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,632][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.8363, 0.0296, 0.0662, 0.0680], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,633][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.8846, 0.0692, 0.0312, 0.0150], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,634][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.4928, 0.0934, 0.2490, 0.1648], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,634][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([9.9710e-01, 3.7797e-04, 7.5778e-04, 1.7685e-03], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,636][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.3241, 0.1063, 0.4372, 0.1324], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,638][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.8308, 0.0157, 0.0451, 0.1084], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,639][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.1215, 0.2242, 0.1069, 0.5473], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,641][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.1021, 0.2685, 0.1895, 0.4399], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,642][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.4206, 0.0696, 0.2157, 0.2941], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,643][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.0063, 0.3118, 0.1420, 0.2345, 0.3055], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,643][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.0748, 0.2312, 0.1887, 0.3644, 0.1408], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,644][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.1228, 0.3217, 0.1667, 0.1782, 0.2106], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,646][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.6677, 0.0355, 0.0781, 0.0853, 0.1333], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,647][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.8756, 0.0529, 0.0318, 0.0172, 0.0225], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,649][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.4193, 0.0917, 0.1630, 0.1262, 0.1998], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,650][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([9.9776e-01, 1.6163e-04, 2.7119e-04, 9.6218e-04, 8.4059e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,651][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.5330, 0.0936, 0.1909, 0.1020, 0.0806], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,652][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.7796, 0.0106, 0.0303, 0.0636, 0.1159], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,653][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.1744, 0.1398, 0.0724, 0.3268, 0.2866], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,654][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.3169, 0.3002, 0.0784, 0.1979, 0.1066], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,655][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([0.3203, 0.0215, 0.0713, 0.1920, 0.3949], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,657][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.0137, 0.2049, 0.0994, 0.1232, 0.2756, 0.2832], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,658][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [res] are: tensor([0.0433, 0.1566, 0.2355, 0.3286, 0.1046, 0.1314], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,660][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.0990, 0.2748, 0.1345, 0.1399, 0.1619, 0.1898], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,661][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [res] are: tensor([0.5405, 0.0303, 0.0727, 0.0706, 0.2192, 0.0667], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,662][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [res] are: tensor([0.7865, 0.0666, 0.0465, 0.0208, 0.0433, 0.0364], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,663][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.3148, 0.0541, 0.1448, 0.0876, 0.2286, 0.1700], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,663][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [res] are: tensor([9.9807e-01, 1.0376e-04, 2.3092e-04, 7.4792e-04, 5.2819e-04, 3.2339e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,665][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.3609, 0.0502, 0.2238, 0.0414, 0.2454, 0.0782], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,666][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.3302, 0.0094, 0.0676, 0.0557, 0.4300, 0.1070], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,668][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.2643, 0.0912, 0.0433, 0.2808, 0.1349, 0.1856], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,670][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.0822, 0.2041, 0.0902, 0.2300, 0.2286, 0.1648], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,671][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.1106, 0.0162, 0.0751, 0.0993, 0.5476, 0.1512], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,672][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ on] are: tensor([4.3002e-04, 2.6911e-01, 4.7379e-02, 3.4947e-02, 1.5921e-01, 4.4112e-01,
        4.7804e-02], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,672][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.0640, 0.1430, 0.2227, 0.1542, 0.1348, 0.2105, 0.0709],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,673][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.0648, 0.2274, 0.1109, 0.1153, 0.1509, 0.1664, 0.1643],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,675][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ on] are: tensor([0.5937, 0.0229, 0.0420, 0.0660, 0.1513, 0.0817, 0.0425],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,676][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.6394, 0.1196, 0.0712, 0.0252, 0.0437, 0.0446, 0.0563],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,678][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.2261, 0.0546, 0.0970, 0.0890, 0.2874, 0.1670, 0.0790],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,679][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ on] are: tensor([9.9749e-01, 1.5985e-04, 2.1938e-04, 8.9659e-04, 4.4470e-04, 2.9819e-04,
        4.8969e-04], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,680][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.4294, 0.0375, 0.1428, 0.0303, 0.2267, 0.0820, 0.0514],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,681][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.2966, 0.0076, 0.0541, 0.0760, 0.3696, 0.1718, 0.0242],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,682][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.1700, 0.0884, 0.0621, 0.3763, 0.0882, 0.1094, 0.1056],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,683][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.3678, 0.2723, 0.0457, 0.1535, 0.0539, 0.0801, 0.0267],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,684][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.0681, 0.0164, 0.0637, 0.0829, 0.5194, 0.2209, 0.0286],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,763][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:39,765][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,766][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,768][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,769][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,769][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,770][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,771][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,772][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,773][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,773][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,774][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,775][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,775][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.9952, 0.0048], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,776][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.9751, 0.0249], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,777][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.7546, 0.2454], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,778][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.9903, 0.0097], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,778][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.0793, 0.9207], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,779][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.3480, 0.6520], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,780][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.9961, 0.0039], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,782][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.9199, 0.0801], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,784][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.9938, 0.0062], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,785][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.2628, 0.7372], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,786][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.3127, 0.6873], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,786][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.8942, 0.1058], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,787][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.9629, 0.0174, 0.0196], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,788][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.8843, 0.0660, 0.0497], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,790][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.4651, 0.3474, 0.1875], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,792][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.9616, 0.0180, 0.0203], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,793][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.0602, 0.4450, 0.4947], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,794][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.2149, 0.4612, 0.3239], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,795][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.9947, 0.0023, 0.0030], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,796][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.8322, 0.0799, 0.0879], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,797][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.9533, 0.0216, 0.0251], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,798][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.1001, 0.3794, 0.5205], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,800][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.1390, 0.6135, 0.2475], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,801][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.7549, 0.0769, 0.1682], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:39,803][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.9291, 0.0131, 0.0366, 0.0211], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,804][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.7084, 0.0666, 0.0858, 0.1393], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,806][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.4418, 0.2233, 0.0903, 0.2445], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,808][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.8363, 0.0296, 0.0662, 0.0680], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,809][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.0344, 0.3168, 0.3527, 0.2961], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,810][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.1772, 0.3629, 0.2521, 0.2078], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,811][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.9878, 0.0019, 0.0045, 0.0058], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,812][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.6054, 0.0855, 0.1495, 0.1595], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,812][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.8308, 0.0157, 0.0451, 0.1084], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,814][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.1215, 0.2242, 0.1069, 0.5473], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,815][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.3244, 0.3657, 0.1842, 0.1258], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,817][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.4206, 0.0696, 0.2157, 0.2941], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:39,819][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.8100, 0.0139, 0.0282, 0.0242, 0.1238], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,820][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([0.7391, 0.0427, 0.0627, 0.0676, 0.0879], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,820][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.2227, 0.2029, 0.0915, 0.2412, 0.2417], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,821][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.6677, 0.0355, 0.0781, 0.0853, 0.1333], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,822][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.0294, 0.2374, 0.2656, 0.2259, 0.2418], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,823][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.1455, 0.3073, 0.2097, 0.1786, 0.1590], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,825][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.9913, 0.0011, 0.0017, 0.0038, 0.0021], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,827][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.4589, 0.0777, 0.1302, 0.1771, 0.1561], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,828][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.7796, 0.0106, 0.0303, 0.0636, 0.1159], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,829][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.1744, 0.1398, 0.0724, 0.3268, 0.2866], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,830][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.0813, 0.3013, 0.1742, 0.1420, 0.3013], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,831][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([0.3203, 0.0215, 0.0713, 0.1920, 0.3949], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:39,831][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.6371, 0.0037, 0.0256, 0.0115, 0.2113, 0.1108], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,833][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.3541, 0.0435, 0.1201, 0.0940, 0.2146, 0.1737], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,835][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.2446, 0.1603, 0.0663, 0.1670, 0.1792, 0.1826], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,836][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.5405, 0.0303, 0.0727, 0.0706, 0.2192, 0.0667], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,838][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.0235, 0.1904, 0.2070, 0.1780, 0.1910, 0.2101], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,839][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.1175, 0.2650, 0.1784, 0.1522, 0.1380, 0.1489], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,840][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([9.9401e-01, 5.3576e-04, 1.2350e-03, 2.6250e-03, 1.0124e-03, 5.7766e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,840][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.2358, 0.0733, 0.1525, 0.1227, 0.3238, 0.0920], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,841][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.3302, 0.0094, 0.0676, 0.0557, 0.4300, 0.1070], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,843][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([0.2643, 0.0912, 0.0433, 0.2808, 0.1349, 0.1856], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,844][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.1139, 0.2585, 0.0849, 0.1574, 0.2005, 0.1847], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,846][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.1106, 0.0162, 0.0751, 0.0993, 0.5476, 0.1512], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:39,848][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.7250, 0.0025, 0.0150, 0.0097, 0.1403, 0.0879, 0.0195],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,849][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([0.2941, 0.0351, 0.1017, 0.1284, 0.1782, 0.2121, 0.0505],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,849][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.2033, 0.1246, 0.0564, 0.1449, 0.1881, 0.1726, 0.1101],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,850][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.5937, 0.0229, 0.0420, 0.0660, 0.1513, 0.0817, 0.0425],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,851][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.0182, 0.1568, 0.1730, 0.1481, 0.1593, 0.1751, 0.1695],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,853][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.1002, 0.2363, 0.1535, 0.1312, 0.1186, 0.1285, 0.1317],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,854][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([9.9223e-01, 9.1578e-04, 1.3638e-03, 3.0888e-03, 9.1345e-04, 6.0081e-04,
        8.8793e-04], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,856][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.3172, 0.0531, 0.0973, 0.1052, 0.2859, 0.0905, 0.0508],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,857][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.2966, 0.0076, 0.0541, 0.0760, 0.3696, 0.1718, 0.0242],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,858][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([0.1700, 0.0884, 0.0621, 0.3763, 0.0882, 0.1094, 0.1056],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,859][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.0955, 0.2604, 0.1804, 0.0991, 0.1731, 0.0797, 0.1120],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,860][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.0681, 0.0164, 0.0637, 0.0829, 0.5194, 0.2209, 0.0286],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:39,863][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:39,865][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 6974],
        [31997],
        [19850],
        [15271],
        [ 5328],
        [ 5902],
        [13305]], device='cuda:0')
[2024-07-23 21:04:39,866][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 7260],
        [27673],
        [15286],
        [ 7022],
        [ 3745],
        [ 3775],
        [12387]], device='cuda:0')
[2024-07-23 21:04:39,868][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[15959],
        [ 8953],
        [ 9426],
        [11954],
        [16560],
        [18773],
        [18081]], device='cuda:0')
[2024-07-23 21:04:39,869][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[11099],
        [18460],
        [22983],
        [20589],
        [21206],
        [20998],
        [22471]], device='cuda:0')
[2024-07-23 21:04:39,870][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[ 6204],
        [25811],
        [25200],
        [23646],
        [19180],
        [18586],
        [19318]], device='cuda:0')
[2024-07-23 21:04:39,871][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[11972],
        [12254],
        [13217],
        [16092],
        [23794],
        [30178],
        [30472]], device='cuda:0')
[2024-07-23 21:04:39,872][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 885],
        [2987],
        [1233],
        [1235],
        [1564],
        [2728],
        [3997]], device='cuda:0')
[2024-07-23 21:04:39,873][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[ 8375],
        [12012],
        [30912],
        [33228],
        [22503],
        [13079],
        [10060]], device='cuda:0')
[2024-07-23 21:04:39,875][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[19518],
        [19466],
        [19405],
        [19104],
        [19267],
        [19321],
        [19280]], device='cuda:0')
[2024-07-23 21:04:39,876][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[32590],
        [26741],
        [34679],
        [43293],
        [46998],
        [49157],
        [49513]], device='cuda:0')
[2024-07-23 21:04:39,877][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[8286],
        [8129],
        [8086],
        [6586],
        [5488],
        [6386],
        [7321]], device='cuda:0')
[2024-07-23 21:04:39,878][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[22818],
        [30472],
        [27188],
        [29939],
        [33074],
        [29748],
        [27488]], device='cuda:0')
[2024-07-23 21:04:39,879][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[24459],
        [36597],
        [40566],
        [39810],
        [35957],
        [32448],
        [34282]], device='cuda:0')
[2024-07-23 21:04:39,880][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[42079],
        [37187],
        [25695],
        [14163],
        [32593],
        [34846],
        [35119]], device='cuda:0')
[2024-07-23 21:04:39,882][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 3373],
        [28880],
        [22730],
        [24914],
        [17676],
        [13799],
        [20894]], device='cuda:0')
[2024-07-23 21:04:39,883][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[10806],
        [10995],
        [12207],
        [14314],
        [24166],
        [25526],
        [25676]], device='cuda:0')
[2024-07-23 21:04:39,884][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[18136],
        [20675],
        [36349],
        [40710],
        [41162],
        [45806],
        [44303]], device='cuda:0')
[2024-07-23 21:04:39,885][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[ 2102],
        [26217],
        [22251],
        [18816],
        [13043],
        [ 9262],
        [ 7671]], device='cuda:0')
[2024-07-23 21:04:39,887][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[11950],
        [13557],
        [18284],
        [26816],
        [33040],
        [33112],
        [31596]], device='cuda:0')
[2024-07-23 21:04:39,888][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[42001],
        [34301],
        [31908],
        [32792],
        [33542],
        [34008],
        [34525]], device='cuda:0')
[2024-07-23 21:04:39,889][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[10283],
        [ 7219],
        [ 6993],
        [ 7652],
        [ 7349],
        [ 6940],
        [ 6535]], device='cuda:0')
[2024-07-23 21:04:39,890][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[35529],
        [35787],
        [35789],
        [35800],
        [35533],
        [35516],
        [35562]], device='cuda:0')
[2024-07-23 21:04:39,891][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[33359],
        [11111],
        [ 2619],
        [ 2496],
        [ 2008],
        [ 3514],
        [ 3631]], device='cuda:0')
[2024-07-23 21:04:39,892][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[9870],
        [9672],
        [8136],
        [7075],
        [5797],
        [7899],
        [8473]], device='cuda:0')
[2024-07-23 21:04:39,894][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[25441],
        [22449],
        [ 7845],
        [12815],
        [ 8578],
        [ 9849],
        [10531]], device='cuda:0')
[2024-07-23 21:04:39,895][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[31964],
        [19510],
        [21774],
        [24369],
        [38728],
        [35586],
        [35118]], device='cuda:0')
[2024-07-23 21:04:39,896][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[12936],
        [18888],
        [11368],
        [ 4855],
        [10353],
        [11507],
        [11350]], device='cuda:0')
[2024-07-23 21:04:39,897][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[23847],
        [25776],
        [32816],
        [30922],
        [29363],
        [25514],
        [26169]], device='cuda:0')
[2024-07-23 21:04:39,898][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[46390],
        [21212],
        [24105],
        [24110],
        [16462],
        [19228],
        [13645]], device='cuda:0')
[2024-07-23 21:04:39,899][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[6170],
        [6170],
        [6170],
        [6170],
        [6170],
        [6170],
        [6170]], device='cuda:0')
[2024-07-23 21:04:39,983][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:39,984][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,985][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,985][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,986][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,987][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,987][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,989][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,990][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,991][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,993][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,994][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,994][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:39,995][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.9985, 0.0015], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,996][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,998][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.0302, 0.9698], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:39,999][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.2190, 0.7810], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,001][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.9973, 0.0027], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,002][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.9663, 0.0337], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,004][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.9820, 0.0180], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,004][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.0674, 0.9326], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,005][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.7860, 0.2140], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,006][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.9713, 0.0287], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,007][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.0136, 0.9864], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,009][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.6581, 0.3419], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,010][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.8760, 0.0042, 0.1198], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,012][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.0012, 0.4307, 0.5681], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,013][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.0058, 0.5636, 0.4306], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,014][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.1074, 0.4664, 0.4262], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,015][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.9953, 0.0024, 0.0024], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,015][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.9842, 0.0056, 0.0101], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,017][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.9296, 0.0325, 0.0379], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,019][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.0039, 0.7525, 0.2436], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,020][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.6649, 0.1415, 0.1936], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,022][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.8932, 0.0387, 0.0681], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,023][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.0086, 0.3588, 0.6327], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,024][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.4820, 0.2352, 0.2829], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,024][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.8957, 0.0011, 0.0981, 0.0052], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,025][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.0006, 0.3154, 0.4234, 0.2605], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,027][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.0038, 0.4034, 0.3250, 0.2678], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,028][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.0712, 0.3507, 0.3133, 0.2648], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,030][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.9879, 0.0047, 0.0033, 0.0041], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,031][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.9017, 0.0143, 0.0603, 0.0237], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,033][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.7331, 0.0700, 0.0701, 0.1268], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,033][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.0177, 0.3506, 0.4095, 0.2222], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,034][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.2682, 0.2056, 0.3587, 0.1675], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,035][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.4483, 0.0876, 0.2567, 0.2074], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,036][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.0049, 0.2738, 0.4178, 0.3035], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,038][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.3446, 0.2131, 0.2525, 0.1899], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,039][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([8.6492e-01, 3.4583e-04, 2.8258e-02, 2.1173e-03, 1.0436e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,041][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.0014, 0.2012, 0.2573, 0.1731, 0.3669], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,042][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.0011, 0.3573, 0.2572, 0.2185, 0.1660], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,043][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.0481, 0.2849, 0.2596, 0.2138, 0.1936], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,044][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.9815, 0.0035, 0.0036, 0.0023, 0.0091], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,045][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.9062, 0.0089, 0.0271, 0.0183, 0.0395], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,046][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.4141, 0.0672, 0.0543, 0.1413, 0.3231], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,048][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.0032, 0.6099, 0.1259, 0.2318, 0.0293], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,049][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.1490, 0.1367, 0.1959, 0.1191, 0.3993], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,051][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.6913, 0.0066, 0.0221, 0.0153, 0.2647], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,052][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.0061, 0.0414, 0.0525, 0.1243, 0.7756], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,053][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([0.2959, 0.1692, 0.1891, 0.1711, 0.1747], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,054][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [res] are: tensor([2.8925e-01, 4.1937e-04, 3.2503e-02, 1.2121e-03, 6.0775e-01, 6.8873e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,054][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [res] are: tensor([0.0006, 0.1432, 0.1918, 0.1278, 0.2971, 0.2395], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,056][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.0013, 0.2927, 0.2169, 0.1949, 0.1533, 0.1408], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,057][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [res] are: tensor([0.0293, 0.2570, 0.2302, 0.1872, 0.1703, 0.1261], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,059][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [res] are: tensor([0.7437, 0.0324, 0.0482, 0.0187, 0.1312, 0.0259], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,061][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.8582, 0.0107, 0.0455, 0.0123, 0.0430, 0.0304], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,062][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.5559, 0.0355, 0.0315, 0.0759, 0.2344, 0.0668], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,063][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.0024, 0.3061, 0.1255, 0.2245, 0.0534, 0.2882], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,063][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.0211, 0.0391, 0.0970, 0.0448, 0.7247, 0.0733], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,064][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.1542, 0.0058, 0.0450, 0.0132, 0.7102, 0.0715], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,066][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.0047, 0.1354, 0.2068, 0.1892, 0.2349, 0.2291], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,067][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.1905, 0.1530, 0.1701, 0.1499, 0.1641, 0.1724], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,068][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ on] are: tensor([7.2263e-01, 5.8407e-05, 8.9898e-03, 2.5689e-04, 2.2841e-01, 3.5621e-02,
        4.0409e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,070][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.0007, 0.1162, 0.1542, 0.1026, 0.2266, 0.1820, 0.2178],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,072][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.0005, 0.2888, 0.2039, 0.1715, 0.1320, 0.1219, 0.0814],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,072][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ on] are: tensor([0.0231, 0.2301, 0.2035, 0.1650, 0.1534, 0.1148, 0.1102],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,073][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.9539, 0.0032, 0.0056, 0.0027, 0.0189, 0.0031, 0.0125],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,074][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.9129, 0.0050, 0.0212, 0.0077, 0.0212, 0.0218, 0.0101],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,075][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.3223, 0.0486, 0.0417, 0.0957, 0.2346, 0.0984, 0.1587],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,077][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.0008, 0.2453, 0.2436, 0.0589, 0.1616, 0.1594, 0.1303],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,079][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.0310, 0.0467, 0.1074, 0.0550, 0.6161, 0.1030, 0.0408],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,080][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.1360, 0.0049, 0.0197, 0.0204, 0.5906, 0.2044, 0.0241],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,081][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.0048, 0.1482, 0.2244, 0.1747, 0.1973, 0.1585, 0.0922],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,082][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.2247, 0.1201, 0.1436, 0.1185, 0.1375, 0.1366, 0.1190],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,156][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:40,157][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,158][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,159][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,160][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,161][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,161][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,162][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,163][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,164][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,166][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,167][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,168][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,169][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.8095, 0.1905], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,169][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.9818, 0.0182], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,170][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([6.2011e-04, 9.9938e-01], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,172][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.1596, 0.8404], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,173][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.8997, 0.1003], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,175][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.1107, 0.8893], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,176][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.2566, 0.7434], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,178][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.7581, 0.2419], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,178][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.7860, 0.2140], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,179][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.7376, 0.2624], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,180][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.0622, 0.9378], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,181][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.4064, 0.5936], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,183][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.4827, 0.0862, 0.4311], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,185][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.9817, 0.0038, 0.0144], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,186][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([1.5831e-04, 2.9221e-01, 7.0763e-01], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,187][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.1063, 0.4235, 0.4703], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,188][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.8505, 0.0835, 0.0660], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,189][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.0725, 0.4901, 0.4374], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,189][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.1639, 0.4756, 0.3605], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,191][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.6279, 0.2000, 0.1721], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,193][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.6649, 0.1415, 0.1936], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,194][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.6337, 0.1880, 0.1783], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,196][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.0022, 0.0773, 0.9206], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,197][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.1079, 0.2501, 0.6420], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,198][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.1653, 0.0829, 0.5688, 0.1829], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,199][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.8324, 0.0207, 0.0256, 0.1213], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,199][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([2.3941e-04, 3.0246e-01, 2.6587e-01, 4.3143e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,201][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.1326, 0.3542, 0.3921, 0.1211], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,202][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.6766, 0.1269, 0.0793, 0.1171], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,204][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.0331, 0.4566, 0.3549, 0.1554], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,206][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.0212, 0.4898, 0.4767, 0.0124], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,207][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.1938, 0.3794, 0.1102, 0.3167], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,208][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.2682, 0.2056, 0.3587, 0.1675], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,208][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.3254, 0.1634, 0.2194, 0.2917], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,209][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.0140, 0.0178, 0.4553, 0.5129], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,211][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.1403, 0.2313, 0.4082, 0.2202], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,212][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.1378, 0.0323, 0.3129, 0.1019, 0.4151], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,214][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([0.4840, 0.0578, 0.0233, 0.2418, 0.1932], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,215][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([5.1621e-04, 6.8558e-02, 7.2267e-02, 1.2180e-01, 7.3685e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,217][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.0761, 0.3369, 0.3676, 0.1151, 0.1044], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,217][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.6481, 0.0858, 0.0635, 0.0708, 0.1317], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,218][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.0266, 0.3482, 0.3142, 0.1258, 0.1852], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,219][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.0435, 0.5061, 0.3585, 0.0122, 0.0796], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,220][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.1297, 0.3320, 0.1140, 0.2768, 0.1474], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,222][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.1490, 0.1367, 0.1959, 0.1191, 0.3993], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,224][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.2948, 0.0517, 0.0745, 0.0985, 0.4806], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,225][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.0316, 0.0310, 0.1760, 0.1701, 0.5914], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,226][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([0.0494, 0.3199, 0.1610, 0.2330, 0.2367], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,227][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.0153, 0.0145, 0.1341, 0.0271, 0.6706, 0.1384], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,228][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.7465, 0.0136, 0.0142, 0.1076, 0.0826, 0.0356], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,229][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([3.3784e-04, 6.1134e-02, 4.7368e-02, 1.5973e-01, 2.2852e-01, 5.0290e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,230][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.0494, 0.3451, 0.3725, 0.0897, 0.0853, 0.0580], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,232][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.2673, 0.1405, 0.1212, 0.1175, 0.2391, 0.1145], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,233][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.0199, 0.3054, 0.2776, 0.0993, 0.1730, 0.1247], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,235][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.0068, 0.4893, 0.4259, 0.0058, 0.0646, 0.0077], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,236][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.1573, 0.2310, 0.0939, 0.2193, 0.1520, 0.1464], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,237][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.0211, 0.0391, 0.0970, 0.0448, 0.7247, 0.0733], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,238][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([0.0720, 0.0298, 0.0725, 0.0533, 0.5434, 0.2291], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,238][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.0064, 0.0291, 0.2943, 0.1527, 0.2626, 0.2548], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,240][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.0853, 0.2311, 0.1319, 0.1183, 0.2913, 0.1422], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,242][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.0309, 0.0124, 0.0967, 0.0239, 0.5600, 0.2433, 0.0328],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,243][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([0.5525, 0.0186, 0.0095, 0.1452, 0.0954, 0.1063, 0.0725],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,244][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([3.1160e-04, 8.5175e-02, 7.9413e-02, 1.6454e-01, 1.3076e-01, 3.2224e-01,
        2.1756e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,246][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.0469, 0.3379, 0.3701, 0.0790, 0.0790, 0.0543, 0.0327],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,247][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.5446, 0.0585, 0.0543, 0.0487, 0.1081, 0.0465, 0.1393],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,247][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.0155, 0.2872, 0.2436, 0.0875, 0.1592, 0.1170, 0.0900],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,248][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.0092, 0.4753, 0.4222, 0.0067, 0.0648, 0.0084, 0.0133],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,250][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.1413, 0.1941, 0.0781, 0.1712, 0.1530, 0.1259, 0.1364],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,251][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.0310, 0.0467, 0.1074, 0.0550, 0.6161, 0.1030, 0.0408],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,253][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([0.0585, 0.0201, 0.0318, 0.0574, 0.4038, 0.3692, 0.0592],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,255][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.0025, 0.0245, 0.2628, 0.1182, 0.1607, 0.1133, 0.3178],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,256][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.1002, 0.1648, 0.1995, 0.0865, 0.3226, 0.0678, 0.0587],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,259][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:40,261][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 7268],
        [13352],
        [ 3821],
        [  743],
        [  761],
        [  309],
        [  623]], device='cuda:0')
[2024-07-23 21:04:40,262][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 7271],
        [21287],
        [ 7042],
        [ 3955],
        [ 4014],
        [ 3374],
        [13036]], device='cuda:0')
[2024-07-23 21:04:40,263][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[39197],
        [39180],
        [43306],
        [42714],
        [39348],
        [26741],
        [35141]], device='cuda:0')
[2024-07-23 21:04:40,264][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[36718],
        [39753],
        [41397],
        [41650],
        [41781],
        [41462],
        [41335]], device='cuda:0')
[2024-07-23 21:04:40,266][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[29231],
        [20232],
        [22740],
        [26205],
        [23076],
        [23138],
        [24112]], device='cuda:0')
[2024-07-23 21:04:40,267][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[13871],
        [13693],
        [11161],
        [11490],
        [11437],
        [11483],
        [11556]], device='cuda:0')
[2024-07-23 21:04:40,268][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[11297],
        [11171],
        [11009],
        [10595],
        [10189],
        [ 7038],
        [ 9381]], device='cuda:0')
[2024-07-23 21:04:40,269][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[27200],
        [27822],
        [27457],
        [27329],
        [29581],
        [31302],
        [29506]], device='cuda:0')
[2024-07-23 21:04:40,270][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[9273],
        [9696],
        [9514],
        [8407],
        [6107],
        [4677],
        [4290]], device='cuda:0')
[2024-07-23 21:04:40,271][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[27104],
        [21856],
        [19115],
        [16165],
        [19523],
        [18707],
        [17300]], device='cuda:0')
[2024-07-23 21:04:40,273][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[25041],
        [ 3283],
        [ 3934],
        [ 2112],
        [ 8610],
        [18452],
        [14930]], device='cuda:0')
[2024-07-23 21:04:40,274][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[14254],
        [15418],
        [24332],
        [33813],
        [19813],
        [21886],
        [21123]], device='cuda:0')
[2024-07-23 21:04:40,275][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[ 6355],
        [23125],
        [35838],
        [30376],
        [13590],
        [21760],
        [20668]], device='cuda:0')
[2024-07-23 21:04:40,276][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[2808],
        [ 715],
        [ 802],
        [ 732],
        [ 976],
        [1212],
        [1238]], device='cuda:0')
[2024-07-23 21:04:40,277][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[36449],
        [ 8656],
        [13248],
        [ 5184],
        [10310],
        [10775],
        [ 7909]], device='cuda:0')
[2024-07-23 21:04:40,279][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[24815],
        [41510],
        [ 9354],
        [ 3260],
        [ 1831],
        [  859],
        [  721]], device='cuda:0')
[2024-07-23 21:04:40,280][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[41359],
        [39312],
        [39234],
        [24890],
        [ 8301],
        [17245],
        [ 9909]], device='cuda:0')
[2024-07-23 21:04:40,281][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[14942],
        [ 4305],
        [ 1890],
        [ 1651],
        [13362],
        [ 2125],
        [ 2361]], device='cuda:0')
[2024-07-23 21:04:40,282][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[1029],
        [1030],
        [1309],
        [1250],
        [1296],
        [1284],
        [1281]], device='cuda:0')
[2024-07-23 21:04:40,284][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[31620],
        [17196],
        [10987],
        [ 5807],
        [ 6034],
        [ 4227],
        [ 5527]], device='cuda:0')
[2024-07-23 21:04:40,285][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[16628],
        [ 4240],
        [ 5029],
        [ 5216],
        [ 3884],
        [ 3386],
        [ 3602]], device='cuda:0')
[2024-07-23 21:04:40,286][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[27024],
        [11643],
        [13249],
        [13146],
        [11114],
        [11556],
        [11293]], device='cuda:0')
[2024-07-23 21:04:40,287][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[36872],
        [31491],
        [28008],
        [22066],
        [19967],
        [20014],
        [20418]], device='cuda:0')
[2024-07-23 21:04:40,288][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[10178],
        [15165],
        [ 8358],
        [ 6223],
        [ 2876],
        [ 1594],
        [ 1952]], device='cuda:0')
[2024-07-23 21:04:40,289][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[33023],
        [34874],
        [18595],
        [16453],
        [ 4216],
        [ 4427],
        [ 6762]], device='cuda:0')
[2024-07-23 21:04:40,291][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[26381],
        [25839],
        [17863],
        [18663],
        [24310],
        [20479],
        [21464]], device='cuda:0')
[2024-07-23 21:04:40,292][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[8367],
        [1308],
        [1054],
        [1171],
        [1246],
        [1137],
        [1028]], device='cuda:0')
[2024-07-23 21:04:40,293][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[14198],
        [26101],
        [41885],
        [45820],
        [48330],
        [48984],
        [49140]], device='cuda:0')
[2024-07-23 21:04:40,294][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[ 9778],
        [44699],
        [46574],
        [47581],
        [48008],
        [47856],
        [40733]], device='cuda:0')
[2024-07-23 21:04:40,295][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[2958],
        [2958],
        [2958],
        [2958],
        [2958],
        [2958],
        [2958]], device='cuda:0')
[2024-07-23 21:04:40,384][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:40,385][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,385][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,386][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,387][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,388][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,388][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,390][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,391][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,392][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,393][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,394][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,395][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,395][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.9431, 0.0569], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,396][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.1697, 0.8303], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,397][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.9549, 0.0451], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,399][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.6926, 0.3074], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,400][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.4352, 0.5648], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,402][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.9702, 0.0298], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,403][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.9943, 0.0057], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,404][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.8259, 0.1741], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,405][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.9100, 0.0900], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,406][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.9382, 0.0618], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,407][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.8143, 0.1857], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,409][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.4988, 0.5012], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,410][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.8606, 0.0710, 0.0683], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,412][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.0662, 0.4940, 0.4398], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,413][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.8989, 0.0435, 0.0576], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,414][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.8014, 0.0815, 0.1171], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,415][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.1131, 0.2313, 0.6555], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,415][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.7568, 0.0302, 0.2130], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,417][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.9528, 0.0143, 0.0329], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,419][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.7492, 0.1249, 0.1259], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,420][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.8384, 0.0470, 0.1145], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,422][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.8625, 0.0622, 0.0753], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,423][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.5804, 0.1400, 0.2796], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,424][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.4878, 0.2662, 0.2460], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,424][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.8355, 0.0802, 0.0417, 0.0427], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,425][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.0124, 0.2998, 0.2639, 0.4239], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,427][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.7824, 0.0518, 0.0583, 0.1074], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,428][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.2856, 0.1390, 0.3345, 0.2409], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,430][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.0850, 0.2906, 0.3931, 0.2314], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,432][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.5114, 0.0435, 0.3325, 0.1127], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,433][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.8417, 0.0294, 0.0534, 0.0755], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,433][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.2807, 0.1823, 0.3625, 0.1745], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,434][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.3782, 0.1114, 0.3279, 0.1825], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,435][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.6947, 0.1066, 0.0887, 0.1100], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,436][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.3852, 0.1557, 0.3091, 0.1501], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,438][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.1714, 0.3682, 0.3356, 0.1248], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,440][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.8609, 0.0387, 0.0656, 0.0294, 0.0054], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,441][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.0269, 0.1384, 0.1994, 0.1807, 0.4547], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,442][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.5848, 0.0584, 0.0932, 0.1097, 0.1540], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,443][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.3849, 0.0295, 0.0456, 0.1094, 0.4306], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,444][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.1568, 0.1219, 0.2030, 0.0563, 0.4620], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,444][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.6922, 0.0140, 0.1398, 0.0369, 0.1172], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,446][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.8566, 0.0111, 0.0294, 0.0531, 0.0498], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,448][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.3164, 0.0676, 0.1544, 0.0501, 0.4116], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,449][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.3501, 0.0500, 0.1517, 0.0668, 0.3814], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,451][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.7172, 0.0671, 0.0587, 0.0712, 0.0859], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,452][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.4163, 0.0610, 0.1924, 0.0768, 0.2536], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,453][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([0.2600, 0.1357, 0.1315, 0.0483, 0.4246], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,453][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.8919, 0.0337, 0.0180, 0.0114, 0.0020, 0.0431], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,454][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [res] are: tensor([0.0224, 0.1463, 0.1657, 0.1358, 0.2777, 0.2521], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,456][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.7856, 0.0286, 0.0406, 0.0735, 0.0514, 0.0204], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,457][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [res] are: tensor([0.3373, 0.0327, 0.0820, 0.1279, 0.3052, 0.1149], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,459][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [res] are: tensor([0.0035, 0.0228, 0.1495, 0.0150, 0.7792, 0.0300], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,461][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.1225, 0.0164, 0.1662, 0.0246, 0.6277, 0.0426], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,461][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.9192, 0.0054, 0.0215, 0.0287, 0.0176, 0.0076], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,462][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.0223, 0.0196, 0.0594, 0.0093, 0.8588, 0.0306], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,463][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.0781, 0.0171, 0.1352, 0.0394, 0.6894, 0.0408], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,464][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.7259, 0.0605, 0.0446, 0.0421, 0.0988, 0.0282], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,465][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.2983, 0.0715, 0.1653, 0.0725, 0.2864, 0.1059], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,467][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.0912, 0.1362, 0.1341, 0.0475, 0.5214, 0.0695], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,469][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ on] are: tensor([0.8297, 0.0448, 0.0266, 0.0197, 0.0040, 0.0627, 0.0125],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,470][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.0155, 0.1553, 0.0853, 0.1240, 0.2646, 0.2180, 0.1374],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,471][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.5806, 0.0797, 0.0722, 0.1302, 0.0608, 0.0438, 0.0326],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,472][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ on] are: tensor([0.4084, 0.0492, 0.0794, 0.1116, 0.1619, 0.1531, 0.0365],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,473][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.0121, 0.0297, 0.1387, 0.0183, 0.7518, 0.0396, 0.0098],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,474][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.1754, 0.0178, 0.1686, 0.0285, 0.5413, 0.0516, 0.0167],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,475][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.9043, 0.0106, 0.0221, 0.0239, 0.0137, 0.0099, 0.0154],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,477][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.0548, 0.0213, 0.0736, 0.0153, 0.7971, 0.0269, 0.0110],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,479][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.1352, 0.0250, 0.1792, 0.0482, 0.5384, 0.0526, 0.0213],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,480][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.5446, 0.1104, 0.0800, 0.0684, 0.1220, 0.0442, 0.0304],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,481][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.4132, 0.0820, 0.1626, 0.0698, 0.1547, 0.0733, 0.0445],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,482][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.0610, 0.0873, 0.1252, 0.0335, 0.5162, 0.0917, 0.0850],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,582][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:40,583][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,584][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,584][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,585][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,587][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,588][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,589][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,591][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,592][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,593][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,593][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,594][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,595][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.9431, 0.0569], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,597][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.1697, 0.8303], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,598][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.9549, 0.0451], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,600][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.6926, 0.3074], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,601][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.4352, 0.5648], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,603][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.9702, 0.0298], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,603][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.9813, 0.0187], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,604][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.8259, 0.1741], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,605][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.9331, 0.0669], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,606][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.9382, 0.0618], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,608][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.8143, 0.1857], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,609][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.4988, 0.5012], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,611][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.8606, 0.0710, 0.0683], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,612][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.0662, 0.4940, 0.4398], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,613][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.8989, 0.0435, 0.0576], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,614][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.8014, 0.0815, 0.1171], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,614][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.1131, 0.2313, 0.6555], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,616][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.7568, 0.0302, 0.2130], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,617][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.9324, 0.0214, 0.0461], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,619][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.7492, 0.1249, 0.1259], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,621][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.9083, 0.0377, 0.0540], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,622][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.8625, 0.0622, 0.0753], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,622][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.5804, 0.1400, 0.2796], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,623][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.4878, 0.2662, 0.2460], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,624][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.8355, 0.0802, 0.0417, 0.0427], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,625][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.0124, 0.2998, 0.2639, 0.4239], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,627][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.7824, 0.0518, 0.0583, 0.1074], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,629][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.2856, 0.1390, 0.3345, 0.2409], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,630][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.0850, 0.2906, 0.3931, 0.2314], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,631][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.5114, 0.0435, 0.3325, 0.1127], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,632][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.7508, 0.0535, 0.0913, 0.1045], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,633][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.2807, 0.1823, 0.3625, 0.1745], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,633][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.6166, 0.1029, 0.1690, 0.1116], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,635][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.6947, 0.1066, 0.0887, 0.1100], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,637][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.3852, 0.1557, 0.3091, 0.1501], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,638][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.1714, 0.3682, 0.3356, 0.1248], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,640][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.8609, 0.0387, 0.0656, 0.0294, 0.0054], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,641][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([0.0269, 0.1384, 0.1994, 0.1807, 0.4547], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,642][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.5848, 0.0584, 0.0932, 0.1097, 0.1540], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,642][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.3849, 0.0295, 0.0456, 0.1094, 0.4306], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,643][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.1568, 0.1219, 0.2030, 0.0563, 0.4620], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,645][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.6922, 0.0140, 0.1398, 0.0369, 0.1172], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,646][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.7086, 0.0272, 0.0717, 0.0855, 0.1070], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,648][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.3164, 0.0676, 0.1544, 0.0501, 0.4116], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,650][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.5376, 0.0790, 0.1290, 0.0746, 0.1798], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,651][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.7172, 0.0671, 0.0587, 0.0712, 0.0859], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,651][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.4163, 0.0610, 0.1924, 0.0768, 0.2536], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,652][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([0.2600, 0.1357, 0.1315, 0.0483, 0.4246], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,653][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.8919, 0.0337, 0.0180, 0.0114, 0.0020, 0.0431], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,654][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.0224, 0.1463, 0.1657, 0.1358, 0.2777, 0.2521], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,656][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.7856, 0.0286, 0.0406, 0.0735, 0.0514, 0.0204], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,658][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.3373, 0.0327, 0.0820, 0.1279, 0.3052, 0.1149], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,659][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.0035, 0.0228, 0.1495, 0.0150, 0.7792, 0.0300], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,660][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.1225, 0.0164, 0.1662, 0.0246, 0.6277, 0.0426], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,661][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.7933, 0.0116, 0.0571, 0.0611, 0.0502, 0.0267], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,662][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.0223, 0.0196, 0.0594, 0.0093, 0.8588, 0.0306], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,663][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.3478, 0.0488, 0.1401, 0.0618, 0.3721, 0.0295], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,664][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([0.7259, 0.0605, 0.0446, 0.0421, 0.0988, 0.0282], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,666][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.2983, 0.0715, 0.1653, 0.0725, 0.2864, 0.1059], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,668][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.0912, 0.1362, 0.1341, 0.0475, 0.5214, 0.0695], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,669][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.8297, 0.0448, 0.0266, 0.0197, 0.0040, 0.0627, 0.0125],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,671][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([0.0155, 0.1553, 0.0853, 0.1240, 0.2646, 0.2180, 0.1374],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,672][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.5806, 0.0797, 0.0722, 0.1302, 0.0608, 0.0438, 0.0326],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,674][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.4084, 0.0492, 0.0794, 0.1116, 0.1619, 0.1531, 0.0365],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,675][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.0121, 0.0297, 0.1387, 0.0183, 0.7518, 0.0396, 0.0098],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,676][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.1754, 0.0178, 0.1686, 0.0285, 0.5413, 0.0516, 0.0167],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,677][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.6737, 0.0289, 0.0730, 0.0811, 0.0440, 0.0539, 0.0454],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,677][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.0548, 0.0213, 0.0736, 0.0153, 0.7971, 0.0269, 0.0110],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,679][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.4408, 0.0510, 0.1234, 0.0621, 0.2704, 0.0348, 0.0174],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,680][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([0.5446, 0.1104, 0.0800, 0.0684, 0.1220, 0.0442, 0.0304],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,682][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.4132, 0.0820, 0.1626, 0.0698, 0.1547, 0.0733, 0.0445],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,683][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.0610, 0.0873, 0.1252, 0.0335, 0.5162, 0.0917, 0.0850],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,687][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:40,688][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 7685],
        [10622],
        [ 3763],
        [  571],
        [  757],
        [  966],
        [  982]], device='cuda:0')
[2024-07-23 21:04:40,689][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 7676],
        [12714],
        [ 4915],
        [ 1063],
        [ 1563],
        [  624],
        [  878]], device='cuda:0')
[2024-07-23 21:04:40,691][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[ 4539],
        [ 6635],
        [12214],
        [14112],
        [12390],
        [11170],
        [16311]], device='cuda:0')
[2024-07-23 21:04:40,692][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[25965],
        [43973],
        [41010],
        [39778],
        [40707],
        [39892],
        [39430]], device='cuda:0')
[2024-07-23 21:04:40,693][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[ 1429],
        [ 4354],
        [10402],
        [25986],
        [40656],
        [23721],
        [40988]], device='cuda:0')
[2024-07-23 21:04:40,694][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[31572],
        [18518],
        [16733],
        [ 7583],
        [12883],
        [14254],
        [16554]], device='cuda:0')
[2024-07-23 21:04:40,696][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[25709],
        [33451],
        [43226],
        [43520],
        [34982],
        [29822],
        [29827]], device='cuda:0')
[2024-07-23 21:04:40,697][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[ 4442],
        [ 4883],
        [14061],
        [23983],
        [26846],
        [46234],
        [45634]], device='cuda:0')
[2024-07-23 21:04:40,698][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[ 8766],
        [ 8705],
        [10834],
        [17897],
        [17673],
        [13384],
        [13365]], device='cuda:0')
[2024-07-23 21:04:40,699][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[26591],
        [23866],
        [28105],
        [30722],
        [34188],
        [33964],
        [34235]], device='cuda:0')
[2024-07-23 21:04:40,700][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[38574],
        [28992],
        [31151],
        [17293],
        [37074],
        [39134],
        [37657]], device='cuda:0')
[2024-07-23 21:04:40,701][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[35972],
        [41045],
        [46131],
        [46390],
        [45796],
        [45152],
        [44945]], device='cuda:0')
[2024-07-23 21:04:40,703][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[36550],
        [20767],
        [13803],
        [13955],
        [18717],
        [17524],
        [17497]], device='cuda:0')
[2024-07-23 21:04:40,704][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[    9],
        [30848],
        [27926],
        [35282],
        [31737],
        [35410],
        [33875]], device='cuda:0')
[2024-07-23 21:04:40,705][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[36884],
        [11584],
        [18242],
        [ 5306],
        [10429],
        [30389],
        [12203]], device='cuda:0')
[2024-07-23 21:04:40,706][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[28304],
        [20859],
        [14173],
        [11418],
        [15026],
        [14834],
        [ 8929]], device='cuda:0')
[2024-07-23 21:04:40,707][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[ 178],
        [ 654],
        [ 573],
        [1103],
        [3291],
        [2767],
        [3053]], device='cuda:0')
[2024-07-23 21:04:40,709][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[32463],
        [41269],
        [45843],
        [45171],
        [30767],
        [43462],
        [37742]], device='cuda:0')
[2024-07-23 21:04:40,710][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[ 2940],
        [ 1815],
        [ 2894],
        [22354],
        [ 9164],
        [14544],
        [15289]], device='cuda:0')
[2024-07-23 21:04:40,711][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[470],
        [478],
        [462],
        [451],
        [240],
        [406],
        [437]], device='cuda:0')
[2024-07-23 21:04:40,712][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[29322],
        [27433],
        [11303],
        [ 4137],
        [ 5621],
        [  543],
        [  572]], device='cuda:0')
[2024-07-23 21:04:40,714][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[2278],
        [1881],
        [1112],
        [ 455],
        [ 290],
        [ 241],
        [ 493]], device='cuda:0')
[2024-07-23 21:04:40,715][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 8425],
        [11493],
        [10025],
        [22926],
        [28090],
        [30676],
        [30463]], device='cuda:0')
[2024-07-23 21:04:40,716][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[18568],
        [21452],
        [17487],
        [14622],
        [20598],
        [26852],
        [25563]], device='cuda:0')
[2024-07-23 21:04:40,717][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[27555],
        [20223],
        [22287],
        [22694],
        [14611],
        [12586],
        [18588]], device='cuda:0')
[2024-07-23 21:04:40,718][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[7929],
        [4543],
        [2118],
        [1102],
        [1146],
        [ 889],
        [ 571]], device='cuda:0')
[2024-07-23 21:04:40,719][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 5940],
        [12267],
        [20119],
        [18842],
        [23480],
        [22909],
        [20268]], device='cuda:0')
[2024-07-23 21:04:40,721][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[48142],
        [46104],
        [47241],
        [45819],
        [47579],
        [45735],
        [46445]], device='cuda:0')
[2024-07-23 21:04:40,722][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[16911],
        [47640],
        [47041],
        [44115],
        [36972],
        [35687],
        [42872]], device='cuda:0')
[2024-07-23 21:04:40,723][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[6812],
        [6812],
        [6812],
        [6812],
        [6812],
        [6812],
        [6812]], device='cuda:0')
[2024-07-23 21:04:40,822][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:40,823][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,824][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,825][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,826][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,827][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,827][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,829][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,830][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,831][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,832][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,833][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,834][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:40,834][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.9574, 0.0426], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,836][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.2154, 0.7846], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,837][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.9854, 0.0146], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,839][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.9801, 0.0199], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,840][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.2902, 0.7098], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,841][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.6816, 0.3184], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,842][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.0156, 0.9844], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,843][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.8746, 0.1254], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,844][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.8272, 0.1728], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,845][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.0069, 0.9931], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,847][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.9413, 0.0587], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,848][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.4229, 0.5771], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:40,850][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.9395, 0.0195, 0.0410], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,851][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.0979, 0.5273, 0.3749], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,851][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.9638, 0.0110, 0.0253], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,852][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.9547, 0.0170, 0.0283], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,853][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.3024, 0.4837, 0.2139], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,854][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.5191, 0.2228, 0.2581], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,856][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.0076, 0.5590, 0.4334], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,858][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.9288, 0.0398, 0.0314], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,859][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.6179, 0.1573, 0.2248], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,860][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.0038, 0.8154, 0.1809], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,861][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.7148, 0.0506, 0.2347], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,861][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.2023, 0.4383, 0.3594], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:40,862][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.5335, 0.1326, 0.1685, 0.1654], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,864][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.0357, 0.3819, 0.2765, 0.3059], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,865][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.4937, 0.1187, 0.1610, 0.2266], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,867][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.7946, 0.0238, 0.0839, 0.0977], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,868][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.0914, 0.5252, 0.1796, 0.2038], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,869][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.2304, 0.3260, 0.2439, 0.1998], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,870][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.0035, 0.4998, 0.3924, 0.1043], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,871][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.7859, 0.0421, 0.0597, 0.1123], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,871][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.3277, 0.1906, 0.2870, 0.1947], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,873][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.0010, 0.1611, 0.1429, 0.6949], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,875][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.5128, 0.0549, 0.3329, 0.0994], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,876][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.1442, 0.2428, 0.2087, 0.4044], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:40,878][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.5120, 0.1273, 0.1530, 0.1335, 0.0741], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,878][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.0642, 0.1325, 0.1563, 0.2216, 0.4254], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,879][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.5347, 0.1675, 0.0941, 0.1387, 0.0649], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,880][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.6497, 0.0318, 0.0642, 0.0299, 0.2243], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,881][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.0788, 0.2041, 0.1199, 0.1906, 0.4065], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,882][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.3339, 0.3008, 0.2039, 0.1228, 0.0385], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,884][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.0057, 0.4513, 0.3325, 0.0816, 0.1288], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,886][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.8789, 0.0254, 0.0420, 0.0251, 0.0286], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,887][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.1711, 0.2070, 0.3518, 0.1075, 0.1626], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,888][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([1.0455e-04, 3.7474e-02, 1.3453e-02, 1.1520e-01, 8.3377e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,889][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.6418, 0.0454, 0.1778, 0.0282, 0.1069], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,890][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([0.0437, 0.1353, 0.0974, 0.2080, 0.5156], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:40,891][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.5121, 0.1683, 0.1328, 0.1037, 0.0661, 0.0171], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,893][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [res] are: tensor([0.0589, 0.3158, 0.1371, 0.1931, 0.1629, 0.1322], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,894][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.7560, 0.0590, 0.0885, 0.0784, 0.0113, 0.0068], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,896][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [res] are: tensor([0.1046, 0.0018, 0.0232, 0.0027, 0.8650, 0.0027], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,897][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [res] are: tensor([0.2640, 0.1502, 0.0697, 0.1651, 0.2038, 0.1472], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,898][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.3702, 0.3280, 0.1914, 0.0746, 0.0251, 0.0107], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,898][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.0031, 0.4577, 0.2907, 0.0536, 0.0438, 0.1511], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,899][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.5936, 0.0353, 0.0680, 0.0488, 0.0834, 0.1709], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,901][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.4534, 0.0760, 0.1639, 0.0652, 0.2145, 0.0270], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,902][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.0006, 0.1082, 0.0148, 0.1124, 0.4018, 0.3622], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,904][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [res] are: tensor([0.0235, 0.0059, 0.1475, 0.0048, 0.8066, 0.0117], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,906][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.1363, 0.1506, 0.0820, 0.2268, 0.3243, 0.0799], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:40,906][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ on] are: tensor([0.4999, 0.1616, 0.1599, 0.0875, 0.0522, 0.0269, 0.0120],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,907][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.0583, 0.2240, 0.1483, 0.1935, 0.1429, 0.1398, 0.0932],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,908][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.6192, 0.0780, 0.1289, 0.1026, 0.0359, 0.0183, 0.0171],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,910][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ on] are: tensor([0.1971, 0.0025, 0.0235, 0.0033, 0.7622, 0.0044, 0.0070],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,911][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.2677, 0.1765, 0.0686, 0.1119, 0.1404, 0.1505, 0.0843],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,913][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.2711, 0.2650, 0.3167, 0.0913, 0.0305, 0.0119, 0.0136],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,914][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.0019, 0.3680, 0.2284, 0.0455, 0.0501, 0.2016, 0.1046],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,915][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.6913, 0.0397, 0.0521, 0.0204, 0.0306, 0.1140, 0.0519],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,916][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.1047, 0.1017, 0.2521, 0.0739, 0.3417, 0.0822, 0.0435],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,917][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.0011, 0.0275, 0.0146, 0.1070, 0.3180, 0.2580, 0.2738],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,918][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.1092, 0.0091, 0.1192, 0.0050, 0.7404, 0.0096, 0.0074],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:40,919][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.0847, 0.1093, 0.0834, 0.1826, 0.2552, 0.0954, 0.1895],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,017][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:41,018][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,019][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,019][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,020][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,021][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,021][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,022][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,022][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,023][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,024][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,024][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,025][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,026][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.9574, 0.0426], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,026][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.2154, 0.7846], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,027][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.9854, 0.0146], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,028][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.9801, 0.0199], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,029][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.2902, 0.7098], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,031][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.6816, 0.3184], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,032][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.0145, 0.9855], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,034][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.8644, 0.1356], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,034][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.8958, 0.1042], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,035][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.0027, 0.9973], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,036][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.9413, 0.0587], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,037][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.1191, 0.8809], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,039][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.9395, 0.0195, 0.0410], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,040][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.0979, 0.5273, 0.3749], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,042][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.9638, 0.0110, 0.0253], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,043][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.9547, 0.0170, 0.0283], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,044][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.3024, 0.4837, 0.2139], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,045][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.5191, 0.2228, 0.2581], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,045][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.0055, 0.4909, 0.5037], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,047][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.5973, 0.1540, 0.2487], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,048][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.7894, 0.0978, 0.1128], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,050][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.0013, 0.6839, 0.3148], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,052][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.7148, 0.0506, 0.2347], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,053][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.0242, 0.4402, 0.5357], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,053][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.5335, 0.1326, 0.1685, 0.1654], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,054][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.0357, 0.3819, 0.2765, 0.3059], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,055][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.4937, 0.1187, 0.1610, 0.2266], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,056][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.7946, 0.0238, 0.0839, 0.0977], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,058][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.0914, 0.5252, 0.1796, 0.2038], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,059][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.2304, 0.3260, 0.2439, 0.1998], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,061][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.0010, 0.4521, 0.4934, 0.0535], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,062][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.3848, 0.1038, 0.3306, 0.1809], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,063][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.4214, 0.1828, 0.2015, 0.1943], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,063][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([3.7098e-04, 3.9563e-01, 3.3377e-01, 2.7022e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,064][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.5128, 0.0549, 0.3329, 0.0994], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,066][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.0178, 0.2542, 0.3701, 0.3579], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,067][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.5120, 0.1273, 0.1530, 0.1335, 0.0741], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,069][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([0.0642, 0.1325, 0.1563, 0.2216, 0.4254], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,071][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.5347, 0.1675, 0.0941, 0.1387, 0.0649], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,071][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.6497, 0.0318, 0.0642, 0.0299, 0.2243], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,072][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.0788, 0.2041, 0.1199, 0.1906, 0.4065], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,073][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.3339, 0.3008, 0.2039, 0.1228, 0.0385], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,074][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.0018, 0.3660, 0.4521, 0.0492, 0.1308], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,075][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.2722, 0.0802, 0.2512, 0.0877, 0.3088], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,077][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.2643, 0.2124, 0.2653, 0.1226, 0.1353], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,078][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([1.6857e-04, 8.1401e-02, 3.9037e-02, 5.6034e-02, 8.2336e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,080][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.6418, 0.0454, 0.1778, 0.0282, 0.1069], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,081][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([0.0054, 0.0944, 0.1116, 0.1091, 0.6795], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,081][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.5121, 0.1683, 0.1328, 0.1037, 0.0661, 0.0171], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,082][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.0589, 0.3158, 0.1371, 0.1931, 0.1629, 0.1322], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,083][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.7560, 0.0590, 0.0885, 0.0784, 0.0113, 0.0068], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,084][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.1046, 0.0018, 0.0232, 0.0027, 0.8650, 0.0027], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,086][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.2640, 0.1502, 0.0697, 0.1651, 0.2038, 0.1472], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,088][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.3702, 0.3280, 0.1914, 0.0746, 0.0251, 0.0107], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,089][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.0009, 0.3810, 0.4070, 0.0315, 0.0471, 0.1325], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,090][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.1783, 0.0328, 0.1664, 0.0569, 0.5102, 0.0554], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,091][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.4819, 0.0941, 0.1324, 0.0892, 0.1778, 0.0246], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,092][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([4.3986e-04, 1.0121e-01, 3.2062e-02, 5.4552e-02, 2.9850e-01, 5.1324e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,093][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([0.0235, 0.0059, 0.1475, 0.0048, 0.8066, 0.0117], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,095][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.0183, 0.1561, 0.1286, 0.1722, 0.4745, 0.0504], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,096][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.4999, 0.1616, 0.1599, 0.0875, 0.0522, 0.0269, 0.0120],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,098][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([0.0583, 0.2240, 0.1483, 0.1935, 0.1429, 0.1398, 0.0932],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,099][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.6192, 0.0780, 0.1289, 0.1026, 0.0359, 0.0183, 0.0171],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,100][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.1971, 0.0025, 0.0235, 0.0033, 0.7622, 0.0044, 0.0070],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,100][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.2677, 0.1765, 0.0686, 0.1119, 0.1404, 0.1505, 0.0843],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,102][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.2711, 0.2650, 0.3167, 0.0913, 0.0305, 0.0119, 0.0136],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,103][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.0014, 0.3039, 0.3002, 0.0406, 0.0680, 0.2020, 0.0839],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,105][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.0889, 0.0350, 0.1795, 0.0584, 0.4637, 0.1213, 0.0532],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,106][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.1587, 0.1387, 0.2359, 0.1065, 0.2471, 0.0737, 0.0394],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,107][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([3.3239e-04, 4.3456e-02, 2.8217e-02, 4.2692e-02, 1.8287e-01, 4.4022e-01,
        2.6221e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,108][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.1092, 0.0091, 0.1192, 0.0050, 0.7404, 0.0096, 0.0074],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,109][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.0161, 0.0646, 0.1103, 0.1656, 0.3859, 0.0665, 0.1909],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,112][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:41,114][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[8820],
        [ 210],
        [  19],
        [  15],
        [   4],
        [   5],
        [   4]], device='cuda:0')
[2024-07-23 21:04:41,115][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[8671],
        [ 544],
        [  75],
        [  24],
        [   8],
        [   5],
        [   5]], device='cuda:0')
[2024-07-23 21:04:41,116][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[47520],
        [48993],
        [49142],
        [49722],
        [50091],
        [50077],
        [50023]], device='cuda:0')
[2024-07-23 21:04:41,118][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[35530],
        [31245],
        [40175],
        [40874],
        [37814],
        [39058],
        [41003]], device='cuda:0')
[2024-07-23 21:04:41,119][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[30994],
        [30520],
        [33798],
        [37049],
        [34339],
        [37716],
        [38655]], device='cuda:0')
[2024-07-23 21:04:41,120][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[22534],
        [23267],
        [24404],
        [30723],
        [38915],
        [46012],
        [45769]], device='cuda:0')
[2024-07-23 21:04:41,121][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 9176],
        [20376],
        [20580],
        [21992],
        [19565],
        [18632],
        [18160]], device='cuda:0')
[2024-07-23 21:04:41,122][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[40599],
        [12359],
        [ 5071],
        [ 2335],
        [ 2580],
        [ 3408],
        [ 2502]], device='cuda:0')
[2024-07-23 21:04:41,123][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[ 6697],
        [33000],
        [45300],
        [45531],
        [43631],
        [44462],
        [43457]], device='cuda:0')
[2024-07-23 21:04:41,125][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[19757],
        [ 3424],
        [ 7921],
        [ 2737],
        [ 5580],
        [ 3103],
        [ 2898]], device='cuda:0')
[2024-07-23 21:04:41,126][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[ 1084],
        [44301],
        [48423],
        [49426],
        [49817],
        [49682],
        [49809]], device='cuda:0')
[2024-07-23 21:04:41,127][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[ 6378],
        [10564],
        [ 7814],
        [ 9567],
        [ 2746],
        [ 7280],
        [ 9680]], device='cuda:0')
[2024-07-23 21:04:41,128][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[23166],
        [21110],
        [13629],
        [10976],
        [11973],
        [11047],
        [11142]], device='cuda:0')
[2024-07-23 21:04:41,129][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[35455],
        [48072],
        [48405],
        [45014],
        [47437],
        [47001],
        [47378]], device='cuda:0')
[2024-07-23 21:04:41,130][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[10435],
        [ 1753],
        [  224],
        [  875],
        [  220],
        [ 1813],
        [  599]], device='cuda:0')
[2024-07-23 21:04:41,132][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[1634],
        [1628],
        [1025],
        [2760],
        [2066],
        [2453],
        [2866]], device='cuda:0')
[2024-07-23 21:04:41,133][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[41180],
        [19884],
        [19283],
        [18739],
        [35152],
        [24200],
        [24163]], device='cuda:0')
[2024-07-23 21:04:41,134][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[12667],
        [12935],
        [13048],
        [17016],
        [15714],
        [12851],
        [13126]], device='cuda:0')
[2024-07-23 21:04:41,136][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[19497],
        [18927],
        [17596],
        [11446],
        [ 5385],
        [ 1180],
        [ 1294]], device='cuda:0')
[2024-07-23 21:04:41,137][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 5802],
        [32103],
        [27995],
        [26146],
        [11835],
        [13220],
        [14864]], device='cuda:0')
[2024-07-23 21:04:41,138][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[11294],
        [13910],
        [31764],
        [23987],
        [21767],
        [22238],
        [26483]], device='cuda:0')
[2024-07-23 21:04:41,139][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[12494],
        [11826],
        [21041],
        [19775],
        [21776],
        [18490],
        [14193]], device='cuda:0')
[2024-07-23 21:04:41,140][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 6416],
        [ 9413],
        [ 7389],
        [13242],
        [12747],
        [13861],
        [14623]], device='cuda:0')
[2024-07-23 21:04:41,141][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[35283],
        [ 7688],
        [ 4586],
        [ 2573],
        [ 5004],
        [ 4784],
        [ 5106]], device='cuda:0')
[2024-07-23 21:04:41,142][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[26145],
        [26257],
        [31790],
        [37315],
        [45455],
        [34437],
        [28884]], device='cuda:0')
[2024-07-23 21:04:41,144][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[5663],
        [6941],
        [5141],
        [4216],
        [2603],
        [2326],
        [2308]], device='cuda:0')
[2024-07-23 21:04:41,145][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 5463],
        [  597],
        [  757],
        [ 2770],
        [16999],
        [11899],
        [14101]], device='cuda:0')
[2024-07-23 21:04:41,147][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[42049],
        [43271],
        [42815],
        [44496],
        [44311],
        [48027],
        [47423]], device='cuda:0')
[2024-07-23 21:04:41,147][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[37335],
        [46205],
        [48885],
        [48089],
        [49877],
        [50041],
        [48845]], device='cuda:0')
[2024-07-23 21:04:41,148][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[1572],
        [1572],
        [1572],
        [1572],
        [1572],
        [1572],
        [1572]], device='cuda:0')
[2024-07-23 21:04:41,256][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:41,257][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,259][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,260][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,261][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,262][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,263][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,263][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,264][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,265][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,266][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,267][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,267][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,268][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.0913, 0.9087], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,269][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.0368, 0.9632], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,269][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.0771, 0.9229], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,270][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.6236, 0.3764], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,271][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([0.7336, 0.2664], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,272][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.9226, 0.0774], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,274][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([0.0056, 0.9944], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,276][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.2598, 0.7402], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,276][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.2447, 0.7553], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,277][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.8891, 0.1109], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,278][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.0158, 0.9842], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,278][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.0277, 0.9723], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,280][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.0542, 0.4097, 0.5362], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,281][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.0038, 0.5269, 0.4693], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,283][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.0386, 0.4108, 0.5507], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,285][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.6504, 0.1723, 0.1773], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,286][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([0.5470, 0.1740, 0.2790], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,286][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.4841, 0.0621, 0.4538], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,287][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([0.0050, 0.8487, 0.1463], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,288][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.1013, 0.3075, 0.5912], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,289][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.0698, 0.2836, 0.6466], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,291][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.4108, 0.0150, 0.5743], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,293][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.0115, 0.9594, 0.0292], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,294][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.0297, 0.8297, 0.1406], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,295][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.0059, 0.2903, 0.3782, 0.3256], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,296][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([2.5623e-04, 1.7919e-01, 4.6084e-01, 3.5971e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,297][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.0098, 0.2159, 0.5773, 0.1970], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,297][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.2423, 0.1643, 0.1162, 0.4771], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,299][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([0.2124, 0.1168, 0.3505, 0.3203], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,300][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.5604, 0.0018, 0.2328, 0.2050], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,302][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([0.0009, 0.5571, 0.3419, 0.1001], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,304][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.0378, 0.3743, 0.4734, 0.1145], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,305][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.0412, 0.1566, 0.6340, 0.1683], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,305][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.2349, 0.0009, 0.2194, 0.5448], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,306][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.0105, 0.9490, 0.0327, 0.0077], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,307][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([3.5310e-05, 8.2972e-01, 1.3158e-01, 3.8664e-02], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,308][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.0008, 0.3726, 0.2934, 0.0416, 0.2916], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,309][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([3.2398e-04, 1.5424e-01, 2.6872e-01, 5.0060e-01, 7.6117e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,311][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.0188, 0.0799, 0.4628, 0.1364, 0.3020], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,313][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.3295, 0.1012, 0.0740, 0.3853, 0.1098], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,314][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([0.2670, 0.1298, 0.2245, 0.2065, 0.1723], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,315][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.2677, 0.0030, 0.1258, 0.0229, 0.5807], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,315][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.0026, 0.5581, 0.2506, 0.0778, 0.1110], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,316][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.1094, 0.4407, 0.3484, 0.0695, 0.0320], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,317][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.0221, 0.0732, 0.2505, 0.1024, 0.5518], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,318][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([4.5176e-02, 4.1877e-04, 1.0524e-01, 1.6750e-02, 8.3241e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,320][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.1260, 0.8291, 0.0347, 0.0080, 0.0022], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,321][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([2.8560e-04, 4.4451e-01, 8.7324e-02, 5.7952e-02, 4.0993e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,323][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.0039, 0.4042, 0.2429, 0.0586, 0.2416, 0.0489], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,324][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [res] are: tensor([2.3095e-04, 1.2933e-01, 1.6046e-01, 3.1532e-01, 3.4940e-02, 3.5973e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,324][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.0097, 0.1025, 0.1633, 0.1130, 0.3245, 0.2870], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,325][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [res] are: tensor([0.1489, 0.2466, 0.1056, 0.2167, 0.0536, 0.2286], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,327][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [res] are: tensor([0.2864, 0.2112, 0.2052, 0.0710, 0.1115, 0.1148], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,328][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [res] are: tensor([1.2944e-03, 1.0614e-06, 2.3647e-03, 3.8856e-05, 9.9571e-01, 5.8804e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,329][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [res] are: tensor([0.0018, 0.5051, 0.3096, 0.0706, 0.0816, 0.0314], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,331][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.0499, 0.5419, 0.3378, 0.0302, 0.0338, 0.0064], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,332][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.0410, 0.0752, 0.4700, 0.1015, 0.1053, 0.2070], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,333][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [res] are: tensor([5.0985e-04, 4.8406e-08, 4.6919e-04, 1.6794e-05, 9.9869e-01, 3.1289e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,334][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [res] are: tensor([2.7000e-02, 9.4539e-01, 2.3557e-02, 2.7499e-03, 5.1146e-04, 7.8798e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,335][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.0016, 0.6522, 0.0828, 0.0196, 0.1728, 0.0710], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,336][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ on] are: tensor([0.0010, 0.1208, 0.3349, 0.0526, 0.3556, 0.1245, 0.0105],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,337][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ on] are: tensor([4.0057e-04, 2.2911e-02, 4.7266e-02, 1.4788e-01, 3.0955e-02, 5.5008e-01,
        2.0050e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,339][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.0097, 0.0268, 0.1384, 0.0757, 0.1508, 0.3045, 0.2941],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,340][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ on] are: tensor([0.1734, 0.1336, 0.0655, 0.2431, 0.0456, 0.2159, 0.1229],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,342][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ on] are: tensor([0.1895, 0.1148, 0.2343, 0.0931, 0.1932, 0.1290, 0.0461],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,342][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ on] are: tensor([2.1005e-02, 1.2926e-05, 5.8408e-03, 8.0298e-05, 9.6952e-01, 1.5314e-03,
        2.0115e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,343][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ on] are: tensor([0.0026, 0.3136, 0.3039, 0.0731, 0.1517, 0.0824, 0.0727],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,344][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.0644, 0.3646, 0.4765, 0.0509, 0.0253, 0.0054, 0.0130],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,345][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.0119, 0.0359, 0.1586, 0.0538, 0.0939, 0.2452, 0.4007],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,347][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ on] are: tensor([1.5185e-02, 1.4652e-06, 2.0305e-03, 5.2326e-05, 9.7899e-01, 1.4600e-03,
        2.2767e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,348][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.0831, 0.7053, 0.0318, 0.0084, 0.0017, 0.0048, 0.1650],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,350][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.0015, 0.2960, 0.1162, 0.0369, 0.2386, 0.1408, 0.1700],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,459][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:41,461][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,462][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,463][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,464][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,465][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,465][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,466][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,468][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,469][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,470][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,471][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,473][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,474][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.0913, 0.9087], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,474][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.0368, 0.9632], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,475][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.0771, 0.9229], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,476][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.6236, 0.3764], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,477][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([0.7336, 0.2664], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,477][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.9226, 0.0774], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,478][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.0056, 0.9944], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,479][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.2598, 0.7402], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,480][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.2447, 0.7553], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,480][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.8891, 0.1109], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,481][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.0158, 0.9842], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,482][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.0277, 0.9723], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,484][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.0542, 0.4097, 0.5362], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,486][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.0038, 0.5269, 0.4693], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,487][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.0386, 0.4108, 0.5507], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,488][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.6504, 0.1723, 0.1773], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,488][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([0.5470, 0.1740, 0.2790], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,489][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.4841, 0.0621, 0.4538], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,491][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.0050, 0.8487, 0.1463], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,492][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.1013, 0.3075, 0.5912], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,494][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.0698, 0.2836, 0.6466], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,495][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.4108, 0.0150, 0.5743], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,496][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.0115, 0.9594, 0.0292], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,497][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.0297, 0.8297, 0.1406], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,498][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.0059, 0.2903, 0.3782, 0.3256], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,498][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([2.5623e-04, 1.7919e-01, 4.6084e-01, 3.5971e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,500][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.0098, 0.2159, 0.5773, 0.1970], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,502][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.2423, 0.1643, 0.1162, 0.4771], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,503][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([0.2124, 0.1168, 0.3505, 0.3203], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,505][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.5604, 0.0018, 0.2328, 0.2050], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,506][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.0009, 0.5571, 0.3419, 0.1001], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,507][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.0378, 0.3743, 0.4734, 0.1145], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,507][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.0412, 0.1566, 0.6340, 0.1683], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,508][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.2349, 0.0009, 0.2194, 0.5448], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,509][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.0105, 0.9490, 0.0327, 0.0077], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,510][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([3.5310e-05, 8.2972e-01, 1.3158e-01, 3.8664e-02], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,512][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.0008, 0.3726, 0.2934, 0.0416, 0.2916], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,513][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([3.2398e-04, 1.5424e-01, 2.6872e-01, 5.0060e-01, 7.6117e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,515][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.0188, 0.0799, 0.4628, 0.1364, 0.3020], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,516][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.3295, 0.1012, 0.0740, 0.3853, 0.1098], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,516][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([0.2670, 0.1298, 0.2245, 0.2065, 0.1723], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,517][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.2677, 0.0030, 0.1258, 0.0229, 0.5807], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,519][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.0026, 0.5581, 0.2506, 0.0778, 0.1110], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,520][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.1094, 0.4407, 0.3484, 0.0695, 0.0320], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,522][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.0221, 0.0732, 0.2505, 0.1024, 0.5518], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,523][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([4.5176e-02, 4.1877e-04, 1.0524e-01, 1.6750e-02, 8.3241e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,524][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.1260, 0.8291, 0.0347, 0.0080, 0.0022], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,525][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([2.8560e-04, 4.4451e-01, 8.7324e-02, 5.7952e-02, 4.0993e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,526][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.0039, 0.4042, 0.2429, 0.0586, 0.2416, 0.0489], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,526][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([2.3095e-04, 1.2933e-01, 1.6046e-01, 3.1532e-01, 3.4940e-02, 3.5973e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,528][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.0097, 0.1025, 0.1633, 0.1130, 0.3245, 0.2870], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,530][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([0.1489, 0.2466, 0.1056, 0.2167, 0.0536, 0.2286], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,531][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([0.2864, 0.2112, 0.2052, 0.0710, 0.1115, 0.1148], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,532][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([1.2944e-03, 1.0614e-06, 2.3647e-03, 3.8856e-05, 9.9571e-01, 5.8804e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,534][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.0018, 0.5051, 0.3096, 0.0706, 0.0816, 0.0314], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,535][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.0499, 0.5419, 0.3378, 0.0302, 0.0338, 0.0064], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,535][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.0410, 0.0752, 0.4700, 0.1015, 0.1053, 0.2070], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,536][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([5.0985e-04, 4.8406e-08, 4.6919e-04, 1.6794e-05, 9.9869e-01, 3.1289e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,537][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([2.7000e-02, 9.4539e-01, 2.3557e-02, 2.7499e-03, 5.1146e-04, 7.8798e-04],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,538][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.0016, 0.6522, 0.0828, 0.0196, 0.1728, 0.0710], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,540][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.0010, 0.1208, 0.3349, 0.0526, 0.3556, 0.1245, 0.0105],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,541][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([4.0057e-04, 2.2911e-02, 4.7266e-02, 1.4788e-01, 3.0955e-02, 5.5008e-01,
        2.0050e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,543][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.0097, 0.0268, 0.1384, 0.0757, 0.1508, 0.3045, 0.2941],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,544][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([0.1734, 0.1336, 0.0655, 0.2431, 0.0456, 0.2159, 0.1229],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,545][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([0.1895, 0.1148, 0.2343, 0.0931, 0.1932, 0.1290, 0.0461],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,545][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([2.1005e-02, 1.2926e-05, 5.8408e-03, 8.0298e-05, 9.6952e-01, 1.5314e-03,
        2.0115e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,547][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.0026, 0.3136, 0.3039, 0.0731, 0.1517, 0.0824, 0.0727],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,548][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.0644, 0.3646, 0.4765, 0.0509, 0.0253, 0.0054, 0.0130],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,550][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.0119, 0.0359, 0.1586, 0.0538, 0.0939, 0.2452, 0.4007],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,551][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([1.5185e-02, 1.4652e-06, 2.0305e-03, 5.2326e-05, 9.7899e-01, 1.4600e-03,
        2.2767e-03], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,552][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.0831, 0.7053, 0.0318, 0.0084, 0.0017, 0.0048, 0.1650],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,553][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.0015, 0.2960, 0.1162, 0.0369, 0.2386, 0.1408, 0.1700],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,557][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:41,558][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[4018],
        [ 374],
        [ 100],
        [ 112],
        [   2],
        [  20],
        [   2]], device='cuda:0')
[2024-07-23 21:04:41,559][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[3468],
        [ 162],
        [  45],
        [  48],
        [   1],
        [   5],
        [   1]], device='cuda:0')
[2024-07-23 21:04:41,560][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[31318],
        [30371],
        [41845],
        [39853],
        [40514],
        [39423],
        [41999]], device='cuda:0')
[2024-07-23 21:04:41,561][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[33160],
        [40362],
        [41858],
        [38354],
        [33543],
        [29469],
        [25564]], device='cuda:0')
[2024-07-23 21:04:41,562][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[ 5883],
        [37852],
        [48136],
        [48877],
        [49759],
        [48866],
        [46943]], device='cuda:0')
[2024-07-23 21:04:41,563][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[27655],
        [46472],
        [44788],
        [47744],
        [47895],
        [48172],
        [48076]], device='cuda:0')
[2024-07-23 21:04:41,565][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 1353],
        [ 7029],
        [15731],
        [28226],
        [33571],
        [30851],
        [37391]], device='cuda:0')
[2024-07-23 21:04:41,566][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[11386],
        [13640],
        [29872],
        [34737],
        [32274],
        [31837],
        [31861]], device='cuda:0')
[2024-07-23 21:04:41,567][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[33116],
        [49015],
        [49169],
        [49124],
        [49300],
        [49302],
        [49136]], device='cuda:0')
[2024-07-23 21:04:41,569][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[35732],
        [ 8154],
        [ 6817],
        [ 6119],
        [ 6404],
        [ 6607],
        [ 6461]], device='cuda:0')
[2024-07-23 21:04:41,570][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[39729],
        [25662],
        [22531],
        [19260],
        [28784],
        [20128],
        [22485]], device='cuda:0')
[2024-07-23 21:04:41,571][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[38186],
        [35902],
        [26541],
        [30852],
        [32338],
        [32772],
        [32849]], device='cuda:0')
[2024-07-23 21:04:41,572][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[ 8028],
        [31599],
        [31371],
        [31464],
        [31195],
        [31465],
        [34792]], device='cuda:0')
[2024-07-23 21:04:41,573][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[38558],
        [34785],
        [37899],
        [38237],
        [49273],
        [45989],
        [49221]], device='cuda:0')
[2024-07-23 21:04:41,574][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[19074],
        [14868],
        [10081],
        [20373],
        [ 3614],
        [29075],
        [ 2691]], device='cuda:0')
[2024-07-23 21:04:41,575][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 2700],
        [28975],
        [25743],
        [23064],
        [25422],
        [25120],
        [26761]], device='cuda:0')
[2024-07-23 21:04:41,577][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[46126],
        [29793],
        [27220],
        [26624],
        [33959],
        [29828],
        [20236]], device='cuda:0')
[2024-07-23 21:04:41,578][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[14521],
        [21760],
        [15900],
        [13973],
        [19919],
        [25734],
        [11945]], device='cuda:0')
[2024-07-23 21:04:41,580][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[22478],
        [12166],
        [10155],
        [ 6268],
        [ 6461],
        [ 8129],
        [ 7858]], device='cuda:0')
[2024-07-23 21:04:41,581][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[22396],
        [17005],
        [16843],
        [31575],
        [25735],
        [22720],
        [22641]], device='cuda:0')
[2024-07-23 21:04:41,581][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[18210],
        [ 6768],
        [ 1158],
        [ 2064],
        [ 1774],
        [ 1745],
        [ 1742]], device='cuda:0')
[2024-07-23 21:04:41,583][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[12480],
        [10000],
        [ 8965],
        [ 8461],
        [ 9670],
        [ 8895],
        [ 7751]], device='cuda:0')
[2024-07-23 21:04:41,584][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 2808],
        [21883],
        [21800],
        [19878],
        [21204],
        [23077],
        [21621]], device='cuda:0')
[2024-07-23 21:04:41,585][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[ 1432],
        [ 2898],
        [ 5981],
        [ 7063],
        [15182],
        [ 9583],
        [ 5841]], device='cuda:0')
[2024-07-23 21:04:41,586][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[18411],
        [18755],
        [ 6527],
        [ 5985],
        [10753],
        [11225],
        [11204]], device='cuda:0')
[2024-07-23 21:04:41,588][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[16092],
        [13536],
        [13371],
        [13446],
        [13169],
        [13420],
        [14080]], device='cuda:0')
[2024-07-23 21:04:41,589][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[  288],
        [18057],
        [16958],
        [16680],
        [ 6605],
        [11069],
        [ 7580]], device='cuda:0')
[2024-07-23 21:04:41,590][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[42919],
        [27944],
        [34169],
        [33272],
        [31387],
        [30391],
        [37303]], device='cuda:0')
[2024-07-23 21:04:41,591][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[21204],
        [23249],
        [43046],
        [32819],
        [42623],
        [28514],
        [41868]], device='cuda:0')
[2024-07-23 21:04:41,592][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[2566],
        [2566],
        [2566],
        [2566],
        [2566],
        [2566],
        [2566]], device='cuda:0')
[2024-07-23 21:04:41,724][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:41,725][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,726][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,727][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,728][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,728][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,729][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,730][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,731][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,733][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,734][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,735][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,735][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,736][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Big] are: tensor([0.1255, 0.8745], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,737][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Big] are: tensor([0.2279, 0.7721], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,738][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Big] are: tensor([0.0078, 0.9922], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,740][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Big] are: tensor([0.0882, 0.9118], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,741][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Big] are: tensor([7.3362e-08, 1.0000e+00], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,743][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Big] are: tensor([0.0819, 0.9181], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,744][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Big] are: tensor([1.6419e-05, 9.9998e-01], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,744][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Big] are: tensor([0.0543, 0.9457], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,745][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Big] are: tensor([0.1043, 0.8957], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,746][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Big] are: tensor([0.1693, 0.8307], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,747][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Big] are: tensor([0.0144, 0.9856], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,749][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Big] are: tensor([0.0040, 0.9960], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,751][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Bang] are: tensor([0.0172, 0.4707, 0.5122], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,752][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Bang] are: tensor([0.0552, 0.1633, 0.7815], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,753][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Bang] are: tensor([0.0020, 0.7712, 0.2268], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,754][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Bang] are: tensor([0.1815, 0.3129, 0.5056], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,755][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Bang] are: tensor([2.0975e-06, 3.8147e-01, 6.1853e-01], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,755][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Bang] are: tensor([0.0242, 0.3671, 0.6087], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,756][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Bang] are: tensor([2.3189e-05, 9.5622e-01, 4.3754e-02], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,758][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Bang] are: tensor([0.0142, 0.2079, 0.7779], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,759][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Bang] are: tensor([0.1146, 0.4320, 0.4533], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,761][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Bang] are: tensor([0.0134, 0.4771, 0.5095], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,762][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Bang] are: tensor([0.0115, 0.0876, 0.9009], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,763][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Bang] are: tensor([0.0014, 0.7915, 0.2071], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,764][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Theory] are: tensor([0.1294, 0.1187, 0.6631, 0.0887], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,765][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Theory] are: tensor([0.0806, 0.0537, 0.6054, 0.2604], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,766][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Theory] are: tensor([0.0203, 0.2691, 0.4302, 0.2804], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,768][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Theory] are: tensor([0.1349, 0.0168, 0.6318, 0.2165], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,769][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Theory] are: tensor([8.7844e-07, 6.1639e-01, 3.3352e-01, 5.0085e-02], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,770][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Theory] are: tensor([0.0160, 0.0728, 0.5844, 0.3269], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,772][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Theory] are: tensor([3.1066e-05, 9.9384e-01, 4.9061e-03, 1.2273e-03], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,772][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Theory] are: tensor([0.0320, 0.0632, 0.5420, 0.3627], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,773][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Theory] are: tensor([0.0807, 0.3364, 0.3303, 0.2526], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,774][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Theory] are: tensor([0.0332, 0.1295, 0.5732, 0.2642], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,775][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Theory] are: tensor([0.0084, 0.0850, 0.4626, 0.4439], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,776][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Theory] are: tensor([0.1178, 0.5446, 0.2252, 0.1125], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,778][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ premie] are: tensor([0.1653, 0.1804, 0.5248, 0.0718, 0.0577], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,780][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ premie] are: tensor([0.0220, 0.0531, 0.6681, 0.1217, 0.1351], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,781][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ premie] are: tensor([0.0112, 0.2044, 0.2778, 0.3320, 0.1746], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,782][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ premie] are: tensor([0.0881, 0.0110, 0.2410, 0.0496, 0.6102], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,783][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ premie] are: tensor([6.6451e-05, 3.6207e-02, 7.4284e-02, 2.3752e-02, 8.6569e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,783][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ premie] are: tensor([0.0153, 0.0867, 0.4148, 0.2981, 0.1852], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,785][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ premie] are: tensor([0.0014, 0.8924, 0.0824, 0.0074, 0.0164], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,786][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ premie] are: tensor([0.0723, 0.0357, 0.2712, 0.1973, 0.4234], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,788][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ premie] are: tensor([0.0328, 0.2544, 0.2937, 0.1698, 0.2494], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,790][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ premie] are: tensor([0.0207, 0.0819, 0.4794, 0.1450, 0.2730], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,791][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ premie] are: tensor([0.0129, 0.0470, 0.2860, 0.1408, 0.5133], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,791][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ premie] are: tensor([0.0085, 0.5913, 0.3317, 0.0330, 0.0356], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:41,792][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [res] are: tensor([0.0769, 0.0780, 0.3079, 0.0436, 0.1550, 0.3386], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,793][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [res] are: tensor([0.0015, 0.0403, 0.7692, 0.0687, 0.0813, 0.0391], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,795][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [res] are: tensor([0.0015, 0.0792, 0.3021, 0.2737, 0.2310, 0.1126], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,796][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [res] are: tensor([3.0768e-03, 2.6829e-04, 1.5063e-02, 9.6546e-03, 9.4502e-01, 2.6921e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,797][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [res] are: tensor([1.2822e-06, 4.2133e-01, 1.3397e-01, 1.7879e-02, 3.4466e-01, 8.2170e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,798][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [res] are: tensor([0.0022, 0.1028, 0.5644, 0.0904, 0.1092, 0.1310], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,800][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [res] are: tensor([1.2348e-05, 9.8774e-01, 6.6629e-03, 6.4846e-04, 3.1266e-03, 1.8139e-03],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,800][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [res] are: tensor([0.0187, 0.0368, 0.4171, 0.0971, 0.2578, 0.1724], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,801][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [res] are: tensor([0.0424, 0.2640, 0.3091, 0.1006, 0.1342, 0.1498], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,802][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [res] are: tensor([0.0036, 0.2149, 0.2588, 0.0650, 0.2964, 0.1612], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,803][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [res] are: tensor([4.3862e-04, 2.0612e-02, 1.1590e-01, 4.1248e-02, 7.5793e-01, 6.3870e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,805][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [res] are: tensor([0.0218, 0.5788, 0.2896, 0.0158, 0.0689, 0.0250], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:41,806][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ on] are: tensor([0.1896, 0.0422, 0.3258, 0.0257, 0.0804, 0.1116, 0.2246],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,808][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ on] are: tensor([0.0100, 0.0209, 0.6646, 0.1145, 0.0814, 0.0555, 0.0530],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,809][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ on] are: tensor([0.0078, 0.0543, 0.1743, 0.1951, 0.2335, 0.1028, 0.2321],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,810][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ on] are: tensor([1.0313e-02, 8.3996e-04, 4.1266e-02, 1.6680e-02, 8.4409e-01, 4.3319e-02,
        4.3496e-02], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,810][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ on] are: tensor([1.9293e-05, 4.3770e-02, 2.6008e-02, 1.0836e-02, 7.0539e-01, 1.8754e-01,
        2.6442e-02], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,811][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ on] are: tensor([0.0306, 0.0815, 0.3558, 0.1324, 0.1190, 0.1471, 0.1336],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,812][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ on] are: tensor([1.8796e-04, 9.0505e-01, 1.8868e-02, 6.5726e-04, 5.1558e-02, 2.3280e-02,
        3.9447e-04], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,814][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ on] are: tensor([0.0750, 0.0417, 0.2707, 0.1755, 0.2036, 0.1125, 0.1210],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,816][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ on] are: tensor([0.1354, 0.2846, 0.2534, 0.0970, 0.0905, 0.0726, 0.0665],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,817][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ on] are: tensor([0.0413, 0.0597, 0.2753, 0.1362, 0.2517, 0.1260, 0.1098],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,818][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ on] are: tensor([0.0072, 0.0154, 0.1347, 0.0610, 0.6337, 0.0454, 0.1026],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,819][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ on] are: tensor([0.0447, 0.3102, 0.2330, 0.0380, 0.2076, 0.0603, 0.1063],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:41,947][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:04:41,949][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,950][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,951][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,953][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,953][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,954][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,955][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,956][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,957][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,959][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,960][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,961][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [The] are: tensor([1.], device='cuda:0') for source tokens [The]
[2024-07-23 21:04:41,962][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Big] are: tensor([0.1255, 0.8745], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,963][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Big] are: tensor([0.2279, 0.7721], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,963][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Big] are: tensor([0.0078, 0.9922], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,964][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Big] are: tensor([0.0882, 0.9118], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,965][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Big] are: tensor([2.0480e-04, 9.9980e-01], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,966][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Big] are: tensor([0.0819, 0.9181], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,966][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Big] are: tensor([0.0468, 0.9532], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,967][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Big] are: tensor([0.0543, 0.9457], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,968][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Big] are: tensor([0.0081, 0.9919], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,969][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Big] are: tensor([0.1693, 0.8307], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,970][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Big] are: tensor([0.0144, 0.9856], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,971][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Big] are: tensor([0.1120, 0.8880], device='cuda:0') for source tokens [The Big]
[2024-07-23 21:04:41,973][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Bang] are: tensor([0.0172, 0.4707, 0.5122], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,975][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Bang] are: tensor([0.0552, 0.1633, 0.7815], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,975][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Bang] are: tensor([0.0020, 0.7712, 0.2268], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,976][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Bang] are: tensor([0.1815, 0.3129, 0.5056], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,977][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Bang] are: tensor([5.9328e-05, 2.1435e-01, 7.8559e-01], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,978][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Bang] are: tensor([0.0242, 0.3671, 0.6087], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,980][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Bang] are: tensor([0.0143, 0.2721, 0.7136], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,982][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Bang] are: tensor([0.0142, 0.2079, 0.7779], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,983][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Bang] are: tensor([0.0299, 0.4125, 0.5576], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,984][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Bang] are: tensor([0.0134, 0.4771, 0.5095], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,985][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Bang] are: tensor([0.0115, 0.0876, 0.9009], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,986][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Bang] are: tensor([0.0190, 0.7631, 0.2179], device='cuda:0') for source tokens [The Big Bang]
[2024-07-23 21:04:41,986][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Theory] are: tensor([0.1294, 0.1187, 0.6631, 0.0887], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,988][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Theory] are: tensor([0.0806, 0.0537, 0.6054, 0.2604], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,989][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Theory] are: tensor([0.0203, 0.2691, 0.4302, 0.2804], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,991][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Theory] are: tensor([0.1349, 0.0168, 0.6318, 0.2165], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,992][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Theory] are: tensor([2.0242e-04, 1.2425e-01, 7.2884e-01, 1.4671e-01], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,993][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Theory] are: tensor([0.0160, 0.0728, 0.5844, 0.3269], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,994][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Theory] are: tensor([0.0329, 0.1019, 0.3837, 0.4815], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,995][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Theory] are: tensor([0.0320, 0.0632, 0.5420, 0.3627], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,996][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Theory] are: tensor([0.0019, 0.3988, 0.2589, 0.3405], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,997][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Theory] are: tensor([0.0332, 0.1295, 0.5732, 0.2642], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:41,999][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Theory] are: tensor([0.0084, 0.0850, 0.4626, 0.4439], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:42,000][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Theory] are: tensor([0.2618, 0.4636, 0.2170, 0.0576], device='cuda:0') for source tokens [The Big Bang Theory]
[2024-07-23 21:04:42,002][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ premie] are: tensor([0.1653, 0.1804, 0.5248, 0.0718, 0.0577], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,003][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ premie] are: tensor([0.0220, 0.0531, 0.6681, 0.1217, 0.1351], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,004][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ premie] are: tensor([0.0112, 0.2044, 0.2778, 0.3320, 0.1746], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,004][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ premie] are: tensor([0.0881, 0.0110, 0.2410, 0.0496, 0.6102], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,005][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ premie] are: tensor([1.5846e-04, 3.0837e-02, 3.9557e-01, 9.8941e-02, 4.7449e-01],
       device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,007][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ premie] are: tensor([0.0153, 0.0867, 0.4148, 0.2981, 0.1852], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,008][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ premie] are: tensor([0.0164, 0.0448, 0.2656, 0.3039, 0.3693], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,010][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ premie] are: tensor([0.0723, 0.0357, 0.2712, 0.1973, 0.4234], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,011][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ premie] are: tensor([0.0053, 0.1808, 0.1986, 0.1826, 0.4327], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,012][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ premie] are: tensor([0.0207, 0.0819, 0.4794, 0.1450, 0.2730], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,013][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ premie] are: tensor([0.0129, 0.0470, 0.2860, 0.1408, 0.5133], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,014][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ premie] are: tensor([0.1049, 0.5733, 0.2812, 0.0269, 0.0138], device='cuda:0') for source tokens [The Big Bang Theory premie]
[2024-07-23 21:04:42,015][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [res] are: tensor([0.0769, 0.0780, 0.3079, 0.0436, 0.1550, 0.3386], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,016][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [res] are: tensor([0.0015, 0.0403, 0.7692, 0.0687, 0.0813, 0.0391], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,018][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [res] are: tensor([0.0015, 0.0792, 0.3021, 0.2737, 0.2310, 0.1126], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,019][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [res] are: tensor([3.0768e-03, 2.6829e-04, 1.5063e-02, 9.6546e-03, 9.4502e-01, 2.6921e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,020][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [res] are: tensor([2.5692e-05, 5.2351e-02, 4.5228e-01, 6.8533e-02, 3.3926e-01, 8.7548e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,021][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [res] are: tensor([0.0022, 0.1028, 0.5644, 0.0904, 0.1092, 0.1310], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,022][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [res] are: tensor([0.0011, 0.0674, 0.2158, 0.2825, 0.2993, 0.1338], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,023][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [res] are: tensor([0.0187, 0.0368, 0.4171, 0.0971, 0.2578, 0.1724], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,023][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [res] are: tensor([0.0028, 0.1221, 0.2584, 0.0986, 0.2516, 0.2666], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,025][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [res] are: tensor([0.0036, 0.2149, 0.2588, 0.0650, 0.2964, 0.1612], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,026][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [res] are: tensor([4.3862e-04, 2.0612e-02, 1.1590e-01, 4.1248e-02, 7.5793e-01, 6.3870e-02],
       device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,028][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [res] are: tensor([0.0279, 0.7381, 0.1913, 0.0152, 0.0202, 0.0074], device='cuda:0') for source tokens [The Big Bang Theory premieres]
[2024-07-23 21:04:42,029][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ on] are: tensor([0.1896, 0.0422, 0.3258, 0.0257, 0.0804, 0.1116, 0.2246],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,030][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ on] are: tensor([0.0100, 0.0209, 0.6646, 0.1145, 0.0814, 0.0555, 0.0530],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,031][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ on] are: tensor([0.0078, 0.0543, 0.1743, 0.1951, 0.2335, 0.1028, 0.2321],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,032][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ on] are: tensor([1.0313e-02, 8.3996e-04, 4.1266e-02, 1.6680e-02, 8.4409e-01, 4.3319e-02,
        4.3496e-02], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,032][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ on] are: tensor([5.5858e-05, 2.3473e-02, 2.7862e-01, 5.5739e-02, 4.0325e-01, 9.6339e-02,
        1.4253e-01], device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,034][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ on] are: tensor([0.0306, 0.0815, 0.3558, 0.1324, 0.1190, 0.1471, 0.1336],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,035][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ on] are: tensor([0.0047, 0.0167, 0.0873, 0.1678, 0.1392, 0.0724, 0.5119],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,037][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ on] are: tensor([0.0750, 0.0417, 0.2707, 0.1755, 0.2036, 0.1125, 0.1210],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,039][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ on] are: tensor([0.0203, 0.1319, 0.2433, 0.0832, 0.2411, 0.2018, 0.0783],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,040][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ on] are: tensor([0.0413, 0.0597, 0.2753, 0.1362, 0.2517, 0.1260, 0.1098],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,040][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ on] are: tensor([0.0072, 0.0154, 0.1347, 0.0610, 0.6337, 0.0454, 0.1026],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,041][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ on] are: tensor([0.1535, 0.5524, 0.2066, 0.0213, 0.0326, 0.0078, 0.0258],
       device='cuda:0') for source tokens [The Big Bang Theory premieres on]
[2024-07-23 21:04:42,044][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:04:42,046][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[2548],
        [  80],
        [  52],
        [  50],
        [   3],
        [   2],
        [   1]], device='cuda:0')
[2024-07-23 21:04:42,047][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[2715],
        [ 181],
        [  75],
        [ 102],
        [   7],
        [  11],
        [   3]], device='cuda:0')
[2024-07-23 21:04:42,049][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[7887],
        [5899],
        [6739],
        [7950],
        [7654],
        [6862],
        [7045]], device='cuda:0')
[2024-07-23 21:04:42,050][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[31584],
        [44310],
        [41047],
        [43887],
        [43758],
        [43307],
        [45081]], device='cuda:0')
[2024-07-23 21:04:42,051][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[ 3170],
        [22381],
        [24337],
        [27819],
        [25054],
        [27063],
        [22467]], device='cuda:0')
[2024-07-23 21:04:42,052][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[23710],
        [48907],
        [49781],
        [50121],
        [50231],
        [50229],
        [50231]], device='cuda:0')
[2024-07-23 21:04:42,053][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[10237],
        [  906],
        [  935],
        [  861],
        [ 2669],
        [ 1180],
        [ 2225]], device='cuda:0')
[2024-07-23 21:04:42,054][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[17664],
        [16798],
        [11798],
        [10840],
        [12971],
        [11203],
        [12044]], device='cuda:0')
[2024-07-23 21:04:42,056][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[19120],
        [ 2031],
        [ 1971],
        [ 2018],
        [ 1940],
        [ 2023],
        [ 2069]], device='cuda:0')
[2024-07-23 21:04:42,057][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[24107],
        [45225],
        [44090],
        [47506],
        [48820],
        [48887],
        [48973]], device='cuda:0')
[2024-07-23 21:04:42,058][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[7066],
        [7059],
        [6995],
        [6905],
        [6747],
        [6698],
        [6811]], device='cuda:0')
[2024-07-23 21:04:42,059][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[37133],
        [25574],
        [32426],
        [33914],
        [32890],
        [30494],
        [32620]], device='cuda:0')
[2024-07-23 21:04:42,060][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[40632],
        [ 3317],
        [ 4521],
        [ 1866],
        [ 9695],
        [15834],
        [13423]], device='cuda:0')
[2024-07-23 21:04:42,061][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[ 9420],
        [29020],
        [29204],
        [29726],
        [29746],
        [30283],
        [33562]], device='cuda:0')
[2024-07-23 21:04:42,062][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[14914],
        [11805],
        [12045],
        [ 9218],
        [10719],
        [13512],
        [ 8184]], device='cuda:0')
[2024-07-23 21:04:42,064][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[11973],
        [11567],
        [10498],
        [10517],
        [10842],
        [11935],
        [12747]], device='cuda:0')
[2024-07-23 21:04:42,065][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[18159],
        [ 9840],
        [14100],
        [12287],
        [11852],
        [12783],
        [12121]], device='cuda:0')
[2024-07-23 21:04:42,066][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[18072],
        [11450],
        [12278],
        [14197],
        [16415],
        [18357],
        [19719]], device='cuda:0')
[2024-07-23 21:04:42,068][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[ 7108],
        [ 9125],
        [ 6218],
        [ 5750],
        [ 9745],
        [12594],
        [12480]], device='cuda:0')
[2024-07-23 21:04:42,069][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[2398],
        [5232],
        [4177],
        [4074],
        [2043],
        [2091],
        [1838]], device='cuda:0')
[2024-07-23 21:04:42,070][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[13555],
        [17235],
        [16875],
        [13094],
        [12378],
        [12527],
        [10882]], device='cuda:0')
[2024-07-23 21:04:42,071][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[18036],
        [13897],
        [17857],
        [14647],
        [18886],
        [18731],
        [ 8744]], device='cuda:0')
[2024-07-23 21:04:42,072][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 7214],
        [13755],
        [11429],
        [13065],
        [20980],
        [18521],
        [19721]], device='cuda:0')
[2024-07-23 21:04:42,073][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[22531],
        [10736],
        [11785],
        [ 9420],
        [ 9136],
        [ 9589],
        [ 9601]], device='cuda:0')
[2024-07-23 21:04:42,075][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[ 1298],
        [17461],
        [13072],
        [11570],
        [ 9135],
        [ 9501],
        [ 8318]], device='cuda:0')
[2024-07-23 21:04:42,076][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[ 8771],
        [14878],
        [19557],
        [17076],
        [21899],
        [21673],
        [23907]], device='cuda:0')
[2024-07-23 21:04:42,077][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[5293],
        [3584],
        [3213],
        [3274],
        [3215],
        [3422],
        [3640]], device='cuda:0')
[2024-07-23 21:04:42,078][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[38347],
        [31213],
        [31223],
        [33528],
        [29381],
        [27997],
        [30257]], device='cuda:0')
[2024-07-23 21:04:42,079][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[27943],
        [31460],
        [35676],
        [38669],
        [34542],
        [31617],
        [36946]], device='cuda:0')
[2024-07-23 21:04:42,080][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[4052],
        [4052],
        [4052],
        [4052],
        [4052],
        [4052],
        [4052]], device='cuda:0')
