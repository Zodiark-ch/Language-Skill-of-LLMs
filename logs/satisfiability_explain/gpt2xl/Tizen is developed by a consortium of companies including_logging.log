[2024-07-23 21:07:02,400][explain_satisfiability.py][line:85][INFO] ############ CASE TEXT isTizen is developed by a consortium of companies including
[2024-07-23 21:07:02,400][explain_satisfiability.py][line:86][INFO] ############ CASE Prediction is  Samsung
[2024-07-23 21:07:02,400][explain_satisfiability.py][line:87][INFO] ############ Refined Forward Graph
[2024-07-23 21:07:02,400][explain_satisfiability.py][line:88][INFO] ****** Layer 1
[2024-07-23 21:07:02,400][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 0
[2024-07-23 21:07:02,401][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,401][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 1
[2024-07-23 21:07:02,401][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit26']
[2024-07-23 21:07:02,401][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 2
[2024-07-23 21:07:02,401][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit24']
[2024-07-23 21:07:02,401][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 3
[2024-07-23 21:07:02,401][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,401][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 4
[2024-07-23 21:07:02,402][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,402][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 5
[2024-07-23 21:07:02,402][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,402][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 6
[2024-07-23 21:07:02,402][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,402][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 7
[2024-07-23 21:07:02,402][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,402][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 8
[2024-07-23 21:07:02,402][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,403][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 9
[2024-07-23 21:07:02,403][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-23 21:07:02,403][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 10
[2024-07-23 21:07:02,403][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,403][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 11
[2024-07-23 21:07:02,403][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-23 21:07:02,403][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 12
[2024-07-23 21:07:02,403][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit26']
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 13
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 14
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit20', 'circuit21', 'circuit26']
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 15
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 16
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 17
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 18
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit26']
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 19
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 20
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit27']
[2024-07-23 21:07:02,404][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 21
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit23', 'circuit27']
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 22
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 23
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 24
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 25
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 26
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 27
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:94][INFO] Layer 1 and circuit 28
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 0
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,405][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 1
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 2
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 3
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 4
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 5
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit4']
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 6
[2024-07-23 21:07:02,406][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 7
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 8
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 9
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 10
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 11
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 12
[2024-07-23 21:07:02,407][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit9', 'circuit11', 'circuit20', 'circuit25']
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 13
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 14
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 15
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit14', 'circuit20', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit25']
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 16
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 17
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,408][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 18
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 19
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 20
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 21
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 22
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 23
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,409][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 24
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 25
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 26
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 27
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:94][INFO] Layer 2 and circuit 28
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 0
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,410][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 1
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 2
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 3
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit7', 'circuit12', 'circuit13', 'circuit14']
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit19']
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 4
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22']
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,411][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 5
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit12', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit21']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 6
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit25']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 7
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit27']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit21']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 8
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit25', 'circuit27']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 9
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,412][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit19']
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 10
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 11
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 12
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit27']
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 13
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,413][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 14
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 15
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20']
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19']
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 16
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 17
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 18
[2024-07-23 21:07:02,414][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19']
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 19
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 20
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 21
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 22
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,415][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 23
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 24
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 25
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 26
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,416][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 27
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:94][INFO] Layer 3 and circuit 28
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 0
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 1
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit13', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-23 21:07:02,417][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 2
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19', 'circuit21']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 3
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 4
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 5
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,418][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 6
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit23']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 7
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit25']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 8
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,419][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 9
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit26']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit25']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 10
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit15']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 11
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 12
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,420][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 13
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 14
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 15
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-23 21:07:02,421][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 16
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit18', 'circuit20']
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 17
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 18
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit21']
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit26']
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 19
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,422][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit6', 'circuit8', 'circuit12', 'circuit13', 'circuit26']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 20
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit27']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 21
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit26']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 22
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17']
[2024-07-23 21:07:02,423][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 23
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 24
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit24']
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 25
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 26
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,424][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 27
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:94][INFO] Layer 4 and circuit 28
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 0
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,425][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 1
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 2
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit7', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit21']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit26']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 3
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit18', 'circuit26']
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,426][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 4
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit24']
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 5
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit15']
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit26']
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 6
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,427][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit16']
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 7
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 8
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22']
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit17']
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 9
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit4', 'circuit13', 'circuit16', 'circuit20', 'circuit21']
[2024-07-23 21:07:02,428][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 10
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 11
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit26']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit26']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 12
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,429][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit21']
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 13
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 14
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 15
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,430][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 16
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 17
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 18
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-23 21:07:02,431][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit26']
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 19
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16']
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19']
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit18']
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 20
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 21
[2024-07-23 21:07:02,432][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 22
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit19']
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 23
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 24
[2024-07-23 21:07:02,433][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit26']
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit20']
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 25
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 26
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 27
[2024-07-23 21:07:02,434][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:94][INFO] Layer 5 and circuit 28
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 0
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,435][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 1
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit3', 'circuit6']
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 2
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit18']
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 3
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,436][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit4', 'circuit9', 'circuit12', 'circuit27']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit1']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit26']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit20', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 4
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit26']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 5
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,437][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 6
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit15']
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit15']
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 7
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 8
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,438][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 9
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 10
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit26']
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit19']
[2024-07-23 21:07:02,439][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 11
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit19']
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit25']
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 12
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 13
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,440][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 14
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 15
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,441][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 16
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 17
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 18
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,442][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 19
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 20
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,443][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 21
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 22
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 23
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,444][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 24
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 25
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 26
[2024-07-23 21:07:02,445][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 27
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:94][INFO] Layer 6 and circuit 28
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,446][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 0
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 1
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,447][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 2
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit24', 'circuit27']
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 3
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit14']
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit16']
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,448][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 4
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 5
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 6
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,449][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 7
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit25']
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 8
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit12']
[2024-07-23 21:07:02,450][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 9
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 10
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,451][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 11
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 12
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,452][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 13
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 14
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 15
[2024-07-23 21:07:02,453][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 16
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 17
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,454][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 18
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 19
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,455][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 20
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 21
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,456][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 22
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 23
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,457][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 24
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 25
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 26
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,458][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 27
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:94][INFO] Layer 7 and circuit 28
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,459][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 0
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 1
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,460][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 2
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 3
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,461][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 4
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 5
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,462][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 6
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit10', 'circuit20']
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 7
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,463][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit8', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 8
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 9
[2024-07-23 21:07:02,464][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit23', 'circuit27']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit25', 'circuit27']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 10
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit20', 'circuit22']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 11
[2024-07-23 21:07:02,465][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 12
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 13
[2024-07-23 21:07:02,466][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit19']
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit27']
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 14
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,467][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 15
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 16
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,468][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 17
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 18
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,469][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 19
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 20
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,470][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 21
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 22
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,471][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 23
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 24
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,472][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 25
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 26
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,473][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 27
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:94][INFO] Layer 8 and circuit 28
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,474][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 0
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit7', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 1
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit25']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,475][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit7', 'circuit11', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 2
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 3
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit23']
[2024-07-23 21:07:02,476][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit8', 'circuit13', 'circuit15']
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 4
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,477][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 5
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 6
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,478][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 7
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 8
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,479][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 9
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit27']
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 10
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,480][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 11
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 12
[2024-07-23 21:07:02,481][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 13
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,482][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit27']
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 14
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 15
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,483][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 16
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 17
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,484][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 18
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 19
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,485][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 20
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,486][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 21
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 22
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,487][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 23
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 24
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,488][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 25
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 26
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,489][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 27
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,490][explain_satisfiability.py][line:94][INFO] Layer 9 and circuit 28
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 0
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,491][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit15', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 1
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit16', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18']
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 2
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,492][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 3
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,493][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 4
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit6', 'circuit13']
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 5
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit25']
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit11', 'circuit13', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,494][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit20']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit18']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 6
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit15']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit3']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit7']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit8']
[2024-07-23 21:07:02,495][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 7
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit15', 'circuit17', 'circuit18', 'circuit19']
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit19', 'circuit20']
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 8
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,496][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 9
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 10
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,497][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 11
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,498][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 12
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit22', 'circuit24']
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 13
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit21', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,499][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14']
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17']
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit17', 'circuit19', 'circuit21', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 14
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,500][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 15
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 16
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,501][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 17
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 18
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,502][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 19
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,503][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 20
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 21
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,504][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 22
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 23
[2024-07-23 21:07:02,505][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 24
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,506][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 25
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 26
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,507][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 27
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,508][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:94][INFO] Layer 10 and circuit 28
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 0
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-23 21:07:02,509][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit2', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit11', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit27']
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit19', 'circuit20', 'circuit22', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 1
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,510][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 2
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 3
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,511][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 4
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19']
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,512][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit21']
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit6', 'circuit10']
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 5
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit24']
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 6
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,513][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 7
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit25']
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,514][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 8
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit24']
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 9
[2024-07-23 21:07:02,515][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit21']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit22']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit21']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit25']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 10
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,516][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 11
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit13']
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 12
[2024-07-23 21:07:02,517][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit16', 'circuit18']
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 13
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-23 21:07:02,518][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit15', 'circuit23', 'circuit25']
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit21', 'circuit22', 'circuit25']
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit22', 'circuit25']
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 14
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,519][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 15
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 16
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,520][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 17
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,521][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 18
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 19
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,522][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 20
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,523][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 21
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 22
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,524][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 23
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,525][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 24
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 25
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are []
[2024-07-23 21:07:02,526][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are []
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are []
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are []
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are []
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are []
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are []
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are []
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are []
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 26
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,527][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 27
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:94][INFO] Layer 11 and circuit 28
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,528][explain_satisfiability.py][line:100][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,529][explain_satisfiability.py][line:100][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,529][explain_satisfiability.py][line:100][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,529][explain_satisfiability.py][line:100][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,529][explain_satisfiability.py][line:100][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,529][explain_satisfiability.py][line:100][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,529][explain_satisfiability.py][line:100][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,529][explain_satisfiability.py][line:100][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,529][explain_satisfiability.py][line:100][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:02,529][explain_satisfiability.py][line:100][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-23 21:07:03,546][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:03,546][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,547][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,547][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,547][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,548][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,548][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,548][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,548][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,549][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,549][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,549][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,550][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,550][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.7882, 0.2118], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,550][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [izen] are: tensor([2.5604e-05, 9.9997e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,551][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.8965, 0.1035], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,551][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.0370, 0.9630], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,551][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.1337, 0.8663], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,552][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [izen] are: tensor([7.2124e-04, 9.9928e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,554][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.7519, 0.2481], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,554][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.9873, 0.0127], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,555][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.8557, 0.1443], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,555][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [izen] are: tensor([0.9036, 0.0964], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,555][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.5635, 0.4365], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,556][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [izen] are: tensor([0.7786, 0.2214], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,556][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.5918, 0.3113, 0.0969], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,556][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.0028, 0.0011, 0.9960], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,557][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.7010, 0.0948, 0.2041], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,557][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.1242, 0.1054, 0.7704], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,557][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.5714, 0.1542, 0.2744], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,558][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ is] are: tensor([1.3849e-01, 3.7302e-04, 8.6114e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,558][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.4786, 0.4612, 0.0602], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,558][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.5130, 0.2075, 0.2795], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,559][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.3698, 0.0621, 0.5681], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,559][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.6186, 0.1268, 0.2547], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,559][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.5321, 0.0790, 0.3889], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,560][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.5483, 0.1059, 0.3458], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,566][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.4036, 0.2373, 0.2061, 0.1530], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,569][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([3.7838e-04, 7.7143e-04, 5.9755e-04, 9.9825e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,574][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.5705, 0.1983, 0.1202, 0.1111], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,574][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.0142, 0.0036, 0.0012, 0.9810], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,575][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.1537, 0.1559, 0.0271, 0.6634], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,575][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([8.3908e-03, 1.8462e-04, 1.4262e-05, 9.9141e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,575][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.3828, 0.3770, 0.0702, 0.1700], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,576][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.3018, 0.0760, 0.4603, 0.1618], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,576][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.4333, 0.1752, 0.3207, 0.0709], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,576][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([0.4808, 0.1476, 0.2527, 0.1189], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,577][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.3829, 0.0696, 0.1582, 0.3893], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,577][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.4596, 0.1125, 0.1772, 0.2508], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,581][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.3938, 0.2845, 0.1391, 0.1287, 0.0539], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,585][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ by] are: tensor([1.6501e-04, 2.4133e-04, 4.0251e-04, 2.1596e-04, 9.9898e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,593][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.3878, 0.1026, 0.1419, 0.2009, 0.1668], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,600][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.0066, 0.0121, 0.0169, 0.0898, 0.8746], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,604][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.2124, 0.0627, 0.0852, 0.4269, 0.2128], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,604][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.0444, 0.0030, 0.0122, 0.0049, 0.9354], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,605][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.2441, 0.3134, 0.0734, 0.3261, 0.0430], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,605][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.1888, 0.0458, 0.2082, 0.2986, 0.2587], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,605][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.1699, 0.0318, 0.4330, 0.0671, 0.2982], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,606][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ by] are: tensor([0.3974, 0.0727, 0.1848, 0.1287, 0.2164], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,606][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.3676, 0.0556, 0.1510, 0.0751, 0.3506], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,607][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ by] are: tensor([0.2942, 0.0668, 0.2166, 0.2170, 0.2054], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,607][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4229, 0.1729, 0.1223, 0.1597, 0.0562, 0.0660], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,607][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.6300e-03, 2.3893e-04, 2.0360e-03, 2.0198e-04, 3.8969e-03, 9.9100e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,612][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2894, 0.0604, 0.1345, 0.2324, 0.2405, 0.0429], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,620][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0327, 0.0113, 0.0502, 0.0513, 0.1428, 0.7118], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,626][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1023, 0.0280, 0.1431, 0.3485, 0.1498, 0.2282], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,634][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1562, 0.0038, 0.1236, 0.0105, 0.0723, 0.6336], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,634][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2651, 0.2643, 0.0489, 0.3725, 0.0312, 0.0180], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,635][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1274, 0.0442, 0.1247, 0.1541, 0.2616, 0.2879], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,635][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0685, 0.0181, 0.2252, 0.0240, 0.1056, 0.5586], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,635][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3287, 0.0697, 0.1477, 0.1032, 0.1962, 0.1545], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,636][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3366, 0.0590, 0.1576, 0.0577, 0.1425, 0.2467], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,636][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2503, 0.0612, 0.1644, 0.2128, 0.1667, 0.1446], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,636][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.3068, 0.0900, 0.0841, 0.1075, 0.1569, 0.1426, 0.1119],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,639][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([3.7600e-05, 5.6644e-04, 1.9895e-05, 5.2768e-03, 1.3787e-03, 7.2180e-05,
        9.9265e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,646][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.3379, 0.1568, 0.0702, 0.0970, 0.0812, 0.1032, 0.1537],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,650][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([3.4767e-03, 3.7822e-04, 2.9167e-05, 8.8224e-04, 1.9662e-04, 4.6291e-04,
        9.9457e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,658][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.0191, 0.0040, 0.0018, 0.0057, 0.0041, 0.0063, 0.9590],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,662][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([2.0129e-03, 7.4693e-04, 2.7443e-07, 7.9687e-04, 2.1529e-07, 5.6337e-08,
        9.9644e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,663][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.2272, 0.1202, 0.0742, 0.1461, 0.0444, 0.1504, 0.2375],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,664][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.1229, 0.0272, 0.1099, 0.1824, 0.1611, 0.2970, 0.0995],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,664][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([0.3307, 0.1084, 0.0855, 0.0692, 0.1644, 0.1639, 0.0778],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,665][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([0.3447, 0.1346, 0.1227, 0.0992, 0.1508, 0.1283, 0.0197],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,665][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.2737, 0.0780, 0.0885, 0.1095, 0.1057, 0.0816, 0.2630],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,665][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([0.1409, 0.0398, 0.1105, 0.1887, 0.2257, 0.1125, 0.1819],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,666][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.2428, 0.2037, 0.0830, 0.1203, 0.0430, 0.0614, 0.2062, 0.0396],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,666][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ of] are: tensor([7.7494e-04, 8.5699e-04, 3.3536e-03, 5.0378e-04, 4.3550e-02, 4.2347e-04,
        2.2118e-04, 9.5032e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,666][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.3213, 0.0431, 0.0885, 0.1434, 0.1977, 0.0615, 0.0428, 0.1017],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,667][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0073, 0.0310, 0.0047, 0.0176, 0.0624, 0.0714, 0.2478, 0.5578],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,671][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0941, 0.0293, 0.0318, 0.1651, 0.0528, 0.0525, 0.4507, 0.1236],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,678][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0430, 0.0073, 0.0925, 0.0115, 0.1067, 0.2468, 0.0029, 0.4892],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,685][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1584, 0.1635, 0.0364, 0.1950, 0.0253, 0.0190, 0.3898, 0.0126],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,692][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0631, 0.0175, 0.0483, 0.0841, 0.0977, 0.1944, 0.2575, 0.2373],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,694][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0598, 0.0120, 0.1979, 0.0285, 0.1048, 0.3941, 0.0253, 0.1776],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,694][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.2450, 0.0580, 0.1230, 0.0832, 0.1545, 0.1262, 0.0726, 0.1374],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,694][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1997, 0.0615, 0.1549, 0.0711, 0.1230, 0.1064, 0.0362, 0.2471],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,695][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.1770, 0.0538, 0.1321, 0.1751, 0.1508, 0.1020, 0.1478, 0.0614],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,695][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.2537, 0.1605, 0.1236, 0.1044, 0.0586, 0.1079, 0.0466, 0.0884, 0.0562],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,696][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([2.7629e-04, 1.0542e-03, 9.0551e-04, 9.2260e-03, 3.4137e-03, 3.4189e-04,
        9.7307e-03, 1.9215e-03, 9.7313e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,696][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.2439, 0.1981, 0.0504, 0.1486, 0.0700, 0.0545, 0.0833, 0.0496, 0.1016],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,697][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([3.2254e-03, 3.0796e-04, 1.1200e-04, 2.9879e-03, 7.0909e-04, 5.1391e-04,
        1.6020e-02, 4.1472e-03, 9.7198e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,703][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.1039, 0.0718, 0.0029, 0.0187, 0.0093, 0.0074, 0.3617, 0.0294, 0.3949],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,707][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([6.8731e-03, 1.4610e-03, 6.1370e-06, 7.0368e-04, 1.8286e-06, 2.1134e-06,
        2.0744e-04, 1.1749e-06, 9.9074e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,715][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.0991, 0.2808, 0.0145, 0.0951, 0.0137, 0.0198, 0.2912, 0.0114, 0.1744],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,721][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([0.0763, 0.0226, 0.0491, 0.0847, 0.0723, 0.1470, 0.1418, 0.2797, 0.1264],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,723][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([0.1868, 0.1788, 0.1011, 0.0676, 0.0914, 0.1500, 0.0730, 0.0973, 0.0541],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,723][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([0.2348, 0.0769, 0.1164, 0.1228, 0.1141, 0.0963, 0.0981, 0.1020, 0.0384],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,724][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.1641, 0.0525, 0.0832, 0.0922, 0.0857, 0.0679, 0.0902, 0.0718, 0.2926],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,724][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([0.2119, 0.0395, 0.0958, 0.1167, 0.1378, 0.0755, 0.1162, 0.0543, 0.1524],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,725][circuit_model.py][line:1532][INFO] ##0-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.1129, 0.0759, 0.1545, 0.1399, 0.0619, 0.0633, 0.2012, 0.0557, 0.0727,
        0.0620], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,725][circuit_model.py][line:1535][INFO] ##0-th layer ##Weight##: The head2 weight for token [ including] are: tensor([1.2446e-03, 1.2498e-04, 6.0395e-04, 4.7952e-03, 2.6471e-03, 1.9673e-03,
        9.5963e-04, 1.1198e-03, 1.6975e-04, 9.8637e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,725][circuit_model.py][line:1538][INFO] ##0-th layer ##Weight##: The head3 weight for token [ including] are: tensor([0.1595, 0.0941, 0.0923, 0.1735, 0.0830, 0.0637, 0.0504, 0.0736, 0.1716,
        0.0385], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,726][circuit_model.py][line:1541][INFO] ##0-th layer ##Weight##: The head4 weight for token [ including] are: tensor([3.2434e-03, 9.7973e-05, 2.3313e-04, 1.5561e-03, 4.4027e-04, 9.4328e-04,
        3.2246e-03, 3.6578e-03, 4.7466e-03, 9.8186e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,726][circuit_model.py][line:1544][INFO] ##0-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.0317, 0.0031, 0.0237, 0.0242, 0.0347, 0.0400, 0.0348, 0.0878, 0.1577,
        0.5625], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,727][circuit_model.py][line:1547][INFO] ##0-th layer ##Weight##: The head6 weight for token [ including] are: tensor([1.0955e-02, 8.1236e-05, 8.7969e-05, 2.4071e-03, 1.9041e-05, 4.8774e-05,
        1.3094e-04, 1.2535e-05, 2.2884e-05, 9.8623e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,731][circuit_model.py][line:1550][INFO] ##0-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.0944, 0.1592, 0.0368, 0.1522, 0.0218, 0.0307, 0.1974, 0.0219, 0.2086,
        0.0770], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,739][circuit_model.py][line:1553][INFO] ##0-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.0543, 0.0057, 0.0266, 0.0315, 0.0613, 0.1061, 0.1622, 0.1712, 0.1641,
        0.2170], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,746][circuit_model.py][line:1556][INFO] ##0-th layer ##Weight##: The head9 weight for token [ including] are: tensor([0.1124, 0.0338, 0.1723, 0.0500, 0.1323, 0.1580, 0.0281, 0.2050, 0.0669,
        0.0411], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,753][circuit_model.py][line:1559][INFO] ##0-th layer ##Weight##: The head10 weight for token [ including] are: tensor([0.1835, 0.0500, 0.1136, 0.0857, 0.1163, 0.0989, 0.0694, 0.1140, 0.0691,
        0.0997], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,754][circuit_model.py][line:1562][INFO] ##0-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.1643, 0.0363, 0.1140, 0.0883, 0.0926, 0.0820, 0.0580, 0.0832, 0.0476,
        0.2338], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,754][circuit_model.py][line:1565][INFO] ##0-th layer ##Weight##: The head12 weight for token [ including] are: tensor([0.2140, 0.0567, 0.0646, 0.1081, 0.1401, 0.0519, 0.0603, 0.0674, 0.0636,
        0.1733], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,764][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:03,764][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,764][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,765][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,765][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,765][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,765][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,766][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,766][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,766][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,766][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,767][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,767][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:03,767][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.7882, 0.2118], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,767][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([2.5604e-05, 9.9997e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,768][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.8965, 0.1035], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,768][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.0370, 0.9630], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,768][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.1337, 0.8663], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,768][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([7.2124e-04, 9.9928e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,769][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([0.7519, 0.2481], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,769][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.9873, 0.0127], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,770][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.8557, 0.1443], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,771][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([0.9036, 0.0964], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,771][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.5635, 0.4365], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,771][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([0.7786, 0.2214], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:03,772][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.5918, 0.3113, 0.0969], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,772][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.0028, 0.0011, 0.9960], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,772][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.7010, 0.0948, 0.2041], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,773][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.1242, 0.1054, 0.7704], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,773][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.5714, 0.1542, 0.2744], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,773][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([1.3849e-01, 3.7302e-04, 8.6114e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,774][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.4786, 0.4612, 0.0602], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,774][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.5130, 0.2075, 0.2795], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,774][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.3698, 0.0621, 0.5681], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,774][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.6186, 0.1268, 0.2547], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,777][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.5321, 0.0790, 0.3889], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,782][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.5483, 0.1059, 0.3458], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:03,790][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([0.4036, 0.2373, 0.2061, 0.1530], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,794][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([3.7838e-04, 7.7143e-04, 5.9755e-04, 9.9825e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,801][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([0.5705, 0.1983, 0.1202, 0.1111], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,801][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.0142, 0.0036, 0.0012, 0.9810], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,802][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.1537, 0.1559, 0.0271, 0.6634], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,802][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([8.3908e-03, 1.8462e-04, 1.4262e-05, 9.9141e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,802][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([0.3828, 0.3770, 0.0702, 0.1700], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,803][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([0.3018, 0.0760, 0.4603, 0.1618], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,803][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.4333, 0.1752, 0.3207, 0.0709], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,803][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([0.4808, 0.1476, 0.2527, 0.1189], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,804][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([0.3829, 0.0696, 0.1582, 0.3893], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,804][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([0.4596, 0.1125, 0.1772, 0.2508], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:03,809][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([0.3938, 0.2845, 0.1391, 0.1287, 0.0539], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,814][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([1.6501e-04, 2.4133e-04, 4.0251e-04, 2.1596e-04, 9.9898e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,821][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([0.3878, 0.1026, 0.1419, 0.2009, 0.1668], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,828][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([0.0066, 0.0121, 0.0169, 0.0898, 0.8746], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,831][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.2124, 0.0627, 0.0852, 0.4269, 0.2128], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,831][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.0444, 0.0030, 0.0122, 0.0049, 0.9354], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,832][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([0.2441, 0.3134, 0.0734, 0.3261, 0.0430], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,832][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([0.1888, 0.0458, 0.2082, 0.2986, 0.2587], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,832][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.1699, 0.0318, 0.4330, 0.0671, 0.2982], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,833][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([0.3974, 0.0727, 0.1848, 0.1287, 0.2164], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,833][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.3676, 0.0556, 0.1510, 0.0751, 0.3506], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,833][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([0.2942, 0.0668, 0.2166, 0.2170, 0.2054], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:03,834][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4229, 0.1729, 0.1223, 0.1597, 0.0562, 0.0660], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,834][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.6300e-03, 2.3893e-04, 2.0360e-03, 2.0198e-04, 3.8969e-03, 9.9100e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,839][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2894, 0.0604, 0.1345, 0.2324, 0.2405, 0.0429], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,847][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0327, 0.0113, 0.0502, 0.0513, 0.1428, 0.7118], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,853][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1023, 0.0280, 0.1431, 0.3485, 0.1498, 0.2282], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,861][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1562, 0.0038, 0.1236, 0.0105, 0.0723, 0.6336], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,861][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2651, 0.2643, 0.0489, 0.3725, 0.0312, 0.0180], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,861][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1274, 0.0442, 0.1247, 0.1541, 0.2616, 0.2879], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,862][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0685, 0.0181, 0.2252, 0.0240, 0.1056, 0.5586], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,862][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3287, 0.0697, 0.1477, 0.1032, 0.1962, 0.1545], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,863][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3366, 0.0590, 0.1576, 0.0577, 0.1425, 0.2467], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,863][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2503, 0.0612, 0.1644, 0.2128, 0.1667, 0.1446], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:03,863][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([0.3068, 0.0900, 0.0841, 0.1075, 0.1569, 0.1426, 0.1119],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,864][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([3.7600e-05, 5.6644e-04, 1.9895e-05, 5.2768e-03, 1.3787e-03, 7.2180e-05,
        9.9265e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,865][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([0.3379, 0.1568, 0.0702, 0.0970, 0.0812, 0.1032, 0.1537],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,869][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([3.4767e-03, 3.7822e-04, 2.9167e-05, 8.8224e-04, 1.9662e-04, 4.6291e-04,
        9.9457e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,877][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([0.0191, 0.0040, 0.0018, 0.0057, 0.0041, 0.0063, 0.9590],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,880][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([2.0129e-03, 7.4693e-04, 2.7443e-07, 7.9687e-04, 2.1529e-07, 5.6337e-08,
        9.9644e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,888][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([0.2272, 0.1202, 0.0742, 0.1461, 0.0444, 0.1504, 0.2375],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,891][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([0.1229, 0.0272, 0.1099, 0.1824, 0.1611, 0.2970, 0.0995],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,891][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([0.3307, 0.1084, 0.0855, 0.0692, 0.1644, 0.1639, 0.0778],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,891][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([0.3447, 0.1346, 0.1227, 0.0992, 0.1508, 0.1283, 0.0197],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,892][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([0.2737, 0.0780, 0.0885, 0.1095, 0.1057, 0.0816, 0.2630],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,892][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([0.1409, 0.0398, 0.1105, 0.1887, 0.2257, 0.1125, 0.1819],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:03,892][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.2428, 0.2037, 0.0830, 0.1203, 0.0430, 0.0614, 0.2062, 0.0396],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,893][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([7.7494e-04, 8.5699e-04, 3.3536e-03, 5.0378e-04, 4.3550e-02, 4.2347e-04,
        2.2118e-04, 9.5032e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,893][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3213, 0.0431, 0.0885, 0.1434, 0.1977, 0.0615, 0.0428, 0.1017],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,894][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0073, 0.0310, 0.0047, 0.0176, 0.0624, 0.0714, 0.2478, 0.5578],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,898][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0941, 0.0293, 0.0318, 0.1651, 0.0528, 0.0525, 0.4507, 0.1236],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,906][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0430, 0.0073, 0.0925, 0.0115, 0.1067, 0.2468, 0.0029, 0.4892],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,913][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1584, 0.1635, 0.0364, 0.1950, 0.0253, 0.0190, 0.3898, 0.0126],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,921][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0631, 0.0175, 0.0483, 0.0841, 0.0977, 0.1944, 0.2575, 0.2373],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,923][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0598, 0.0120, 0.1979, 0.0285, 0.1048, 0.3941, 0.0253, 0.1776],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,924][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.2450, 0.0580, 0.1230, 0.0832, 0.1545, 0.1262, 0.0726, 0.1374],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,924][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1997, 0.0615, 0.1549, 0.0711, 0.1230, 0.1064, 0.0362, 0.2471],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,924][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1770, 0.0538, 0.1321, 0.1751, 0.1508, 0.1020, 0.1478, 0.0614],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:03,925][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([0.2537, 0.1605, 0.1236, 0.1044, 0.0586, 0.1079, 0.0466, 0.0884, 0.0562],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,925][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([2.7629e-04, 1.0542e-03, 9.0551e-04, 9.2260e-03, 3.4137e-03, 3.4189e-04,
        9.7307e-03, 1.9215e-03, 9.7313e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,925][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([0.2439, 0.1981, 0.0504, 0.1486, 0.0700, 0.0545, 0.0833, 0.0496, 0.1016],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,926][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([3.2254e-03, 3.0796e-04, 1.1200e-04, 2.9879e-03, 7.0909e-04, 5.1391e-04,
        1.6020e-02, 4.1472e-03, 9.7198e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,926][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.1039, 0.0718, 0.0029, 0.0187, 0.0093, 0.0074, 0.3617, 0.0294, 0.3949],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,928][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([6.8731e-03, 1.4610e-03, 6.1370e-06, 7.0368e-04, 1.8286e-06, 2.1134e-06,
        2.0744e-04, 1.1749e-06, 9.9074e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,936][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([0.0991, 0.2808, 0.0145, 0.0951, 0.0137, 0.0198, 0.2912, 0.0114, 0.1744],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,943][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([0.0763, 0.0226, 0.0491, 0.0847, 0.0723, 0.1470, 0.1418, 0.2797, 0.1264],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,950][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([0.1868, 0.1788, 0.1011, 0.0676, 0.0914, 0.1500, 0.0730, 0.0973, 0.0541],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,953][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([0.2348, 0.0769, 0.1164, 0.1228, 0.1141, 0.0963, 0.0981, 0.1020, 0.0384],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,953][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([0.1641, 0.0525, 0.0832, 0.0922, 0.0857, 0.0679, 0.0902, 0.0718, 0.2926],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,954][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([0.2119, 0.0395, 0.0958, 0.1167, 0.1378, 0.0755, 0.1162, 0.0543, 0.1524],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:03,954][circuit_model.py][line:1570][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([0.1129, 0.0759, 0.1545, 0.1399, 0.0619, 0.0633, 0.2012, 0.0557, 0.0727,
        0.0620], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,955][circuit_model.py][line:1573][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([1.2446e-03, 1.2498e-04, 6.0395e-04, 4.7952e-03, 2.6471e-03, 1.9673e-03,
        9.5963e-04, 1.1198e-03, 1.6975e-04, 9.8637e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,955][circuit_model.py][line:1576][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([0.1595, 0.0941, 0.0923, 0.1735, 0.0830, 0.0637, 0.0504, 0.0736, 0.1716,
        0.0385], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,955][circuit_model.py][line:1579][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([3.2434e-03, 9.7973e-05, 2.3313e-04, 1.5561e-03, 4.4027e-04, 9.4328e-04,
        3.2246e-03, 3.6578e-03, 4.7466e-03, 9.8186e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,956][circuit_model.py][line:1582][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([0.0317, 0.0031, 0.0237, 0.0242, 0.0347, 0.0400, 0.0348, 0.0878, 0.1577,
        0.5625], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,956][circuit_model.py][line:1585][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([1.0955e-02, 8.1236e-05, 8.7969e-05, 2.4071e-03, 1.9041e-05, 4.8774e-05,
        1.3094e-04, 1.2535e-05, 2.2884e-05, 9.8623e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,961][circuit_model.py][line:1588][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([0.0944, 0.1592, 0.0368, 0.1522, 0.0218, 0.0307, 0.1974, 0.0219, 0.2086,
        0.0770], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,969][circuit_model.py][line:1591][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([0.0543, 0.0057, 0.0266, 0.0315, 0.0613, 0.1061, 0.1622, 0.1712, 0.1641,
        0.2170], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,975][circuit_model.py][line:1594][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([0.1124, 0.0338, 0.1723, 0.0500, 0.1323, 0.1580, 0.0281, 0.2050, 0.0669,
        0.0411], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,983][circuit_model.py][line:1597][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([0.1835, 0.0500, 0.1136, 0.0857, 0.1163, 0.0989, 0.0694, 0.1140, 0.0691,
        0.0997], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,983][circuit_model.py][line:1600][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([0.1643, 0.0363, 0.1140, 0.0883, 0.0926, 0.0820, 0.0580, 0.0832, 0.0476,
        0.2338], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,984][circuit_model.py][line:1603][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([0.2140, 0.0567, 0.0646, 0.1081, 0.1401, 0.0519, 0.0603, 0.0674, 0.0636,
        0.1733], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:03,985][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:03,986][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[8907],
        [ 775],
        [2505],
        [8906],
        [ 537],
        [6151],
        [1507],
        [1763],
        [3142],
        [2518]], device='cuda:0')
[2024-07-23 21:07:03,987][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[30534],
        [16353],
        [29465],
        [31812],
        [26554],
        [23946],
        [27896],
        [32418],
        [ 4488],
        [25975]], device='cuda:0')
[2024-07-23 21:07:03,989][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[11825],
        [19940],
        [25234],
        [29005],
        [31212],
        [26736],
        [18061],
        [14599],
        [24015],
        [13400]], device='cuda:0')
[2024-07-23 21:07:03,992][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[17736],
        [14298],
        [ 4606],
        [17673],
        [ 4959],
        [25512],
        [30887],
        [ 7123],
        [29013],
        [ 8866]], device='cuda:0')
[2024-07-23 21:07:03,996][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[20364],
        [18785],
        [15452],
        [14013],
        [15073],
        [16195],
        [14814],
        [16127],
        [11927],
        [12004]], device='cuda:0')
[2024-07-23 21:07:03,999][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[24173],
        [ 9280],
        [40418],
        [31307],
        [38590],
        [42734],
        [12657],
        [28967],
        [39076],
        [ 5936]], device='cuda:0')
[2024-07-23 21:07:04,002][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[14680],
        [ 9431],
        [11399],
        [13899],
        [18455],
        [17389],
        [  158],
        [  356],
        [  326],
        [ 3378]], device='cuda:0')
[2024-07-23 21:07:04,005][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[28204],
        [13108],
        [12939],
        [17951],
        [ 5970],
        [ 8499],
        [33530],
        [ 6772],
        [29368],
        [17472]], device='cuda:0')
[2024-07-23 21:07:04,009][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[43177],
        [42951],
        [40735],
        [41737],
        [41926],
        [41373],
        [23675],
        [ 9478],
        [13347],
        [18491]], device='cuda:0')
[2024-07-23 21:07:04,012][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[10916],
        [10664],
        [ 3648],
        [ 2892],
        [ 2032],
        [ 7204],
        [ 6086],
        [ 7830],
        [14774],
        [11952]], device='cuda:0')
[2024-07-23 21:07:04,015][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[24882],
        [18510],
        [17152],
        [11099],
        [27983],
        [13200],
        [14729],
        [21196],
        [ 8368],
        [22840]], device='cuda:0')
[2024-07-23 21:07:04,018][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[1405],
        [1540],
        [2988],
        [4759],
        [5719],
        [4011],
        [3537],
        [5522],
        [6292],
        [6003]], device='cuda:0')
[2024-07-23 21:07:04,018][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[28885],
        [18045],
        [25983],
        [10133],
        [18849],
        [39288],
        [18980],
        [26392],
        [11768],
        [22253]], device='cuda:0')
[2024-07-23 21:07:04,019][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[16009],
        [ 6398],
        [10109],
        [11121],
        [15972],
        [17666],
        [15467],
        [12951],
        [ 7952],
        [ 9931]], device='cuda:0')
[2024-07-23 21:07:04,020][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[25104],
        [ 5481],
        [36865],
        [39145],
        [ 3131],
        [26888],
        [11213],
        [26465],
        [28837],
        [21374]], device='cuda:0')
[2024-07-23 21:07:04,021][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[10965],
        [ 7656],
        [ 6983],
        [13449],
        [11499],
        [15120],
        [17094],
        [13782],
        [15873],
        [15338]], device='cuda:0')
[2024-07-23 21:07:04,023][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[4033],
        [4809],
        [2956],
        [2113],
        [8924],
        [4170],
        [4134],
        [3341],
        [8088],
        [7745]], device='cuda:0')
[2024-07-23 21:07:04,026][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[25468],
        [26304],
        [24730],
        [25971],
        [23636],
        [22338],
        [20391],
        [22215],
        [21096],
        [20316]], device='cuda:0')
[2024-07-23 21:07:04,029][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[32548],
        [ 8163],
        [21209],
        [ 8948],
        [26481],
        [24394],
        [12220],
        [14117],
        [ 7527],
        [19037]], device='cuda:0')
[2024-07-23 21:07:04,033][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 5535],
        [35259],
        [ 9307],
        [ 8289],
        [ 8401],
        [11166],
        [44406],
        [34497],
        [46863],
        [13425]], device='cuda:0')
[2024-07-23 21:07:04,036][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[  926],
        [ 1789],
        [ 8022],
        [ 7542],
        [11936],
        [10000],
        [ 3480],
        [14900],
        [ 1663],
        [11778]], device='cuda:0')
[2024-07-23 21:07:04,039][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[28529],
        [19912],
        [13856],
        [10379],
        [ 7404],
        [ 8005],
        [10457],
        [ 8786],
        [ 8292],
        [ 7153]], device='cuda:0')
[2024-07-23 21:07:04,043][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[44818],
        [44779],
        [44718],
        [43340],
        [40538],
        [36245],
        [40758],
        [44313],
        [40858],
        [39823]], device='cuda:0')
[2024-07-23 21:07:04,046][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[21440],
        [24506],
        [23124],
        [24342],
        [16896],
        [18433],
        [19697],
        [15255],
        [18824],
        [13630]], device='cuda:0')
[2024-07-23 21:07:04,049][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[39057],
        [36440],
        [41400],
        [40031],
        [38055],
        [39189],
        [37892],
        [37331],
        [35377],
        [37154]], device='cuda:0')
[2024-07-23 21:07:04,051][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[18465],
        [33933],
        [22252],
        [28666],
        [21374],
        [21753],
        [30018],
        [23518],
        [30159],
        [24363]], device='cuda:0')
[2024-07-23 21:07:04,052][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[16172],
        [24315],
        [38755],
        [41009],
        [43286],
        [42286],
        [48664],
        [48872],
        [49355],
        [48331]], device='cuda:0')
[2024-07-23 21:07:04,053][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[22511],
        [16419],
        [19940],
        [18657],
        [20313],
        [20132],
        [15241],
        [17130],
        [15920],
        [20335]], device='cuda:0')
[2024-07-23 21:07:04,054][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[16776],
        [38968],
        [ 8756],
        [ 7565],
        [42834],
        [15908],
        [31413],
        [15342],
        [15010],
        [21071]], device='cuda:0')
[2024-07-23 21:07:04,055][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[8160],
        [8160],
        [8160],
        [8160],
        [8160],
        [8160],
        [8160],
        [8160],
        [8160],
        [8160]], device='cuda:0')
[2024-07-23 21:07:04,080][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:04,086][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,091][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,097][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,099][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,099][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,099][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,100][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,100][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,100][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,101][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,101][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,101][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,101][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.5693, 0.4307], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,102][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.0421, 0.9579], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,102][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.6385, 0.3615], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,103][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.6700, 0.3300], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,107][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.9536, 0.0464], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,113][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.8721, 0.1279], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,119][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.6908, 0.3092], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,127][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.8722, 0.1278], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,130][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.0242, 0.9758], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,130][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [izen] are: tensor([0.4993, 0.5007], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,130][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.9794, 0.0206], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,131][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [izen] are: tensor([2.4106e-05, 9.9998e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,131][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.2816, 0.7025, 0.0160], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,131][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.0333, 0.5546, 0.4120], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,131][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.2243, 0.1481, 0.6276], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,132][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.4465, 0.1490, 0.4045], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,132][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.2379, 0.0357, 0.7264], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,132][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.8581, 0.1282, 0.0137], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,133][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.4585, 0.4827, 0.0588], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,133][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.5209, 0.2074, 0.2717], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,134][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ is] are: tensor([4.4602e-02, 9.5536e-01, 4.2228e-05], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,138][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.3333, 0.3343, 0.3324], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,144][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.8136, 0.0220, 0.1644], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,147][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ is] are: tensor([5.7150e-05, 1.0151e-04, 9.9984e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,155][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.3773, 0.1648, 0.3295, 0.1285], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,161][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([0.0080, 0.3544, 0.5461, 0.0915], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,161][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.1703, 0.1093, 0.4523, 0.2680], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,161][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.3502, 0.0964, 0.2631, 0.2903], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,161][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.2999, 0.0248, 0.5223, 0.1530], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,162][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.0722, 0.1557, 0.0256, 0.7465], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,162][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.4533, 0.4025, 0.0765, 0.0677], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,162][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.4395, 0.3625, 0.1194, 0.0786], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,163][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([7.1161e-03, 6.5811e-01, 2.0503e-06, 3.3477e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,163][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([0.2498, 0.2505, 0.2492, 0.2504], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,163][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.8595, 0.0150, 0.0788, 0.0466], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,164][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([2.1013e-08, 1.1690e-05, 1.0077e-06, 9.9999e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,165][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.0382, 0.0775, 0.1395, 0.7401, 0.0048], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,169][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ by] are: tensor([0.0112, 0.2986, 0.3434, 0.1605, 0.1863], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,175][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.1252, 0.0775, 0.3236, 0.1879, 0.2857], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,183][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.2941, 0.0642, 0.1753, 0.1905, 0.2760], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,190][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.3260, 0.0172, 0.4543, 0.1173, 0.0852], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,191][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.3974, 0.1355, 0.0081, 0.4426, 0.0164], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,192][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.2548, 0.5371, 0.0763, 0.1086, 0.0233], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,192][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.2614, 0.2140, 0.0964, 0.2751, 0.1531], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,192][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ by] are: tensor([8.0681e-03, 4.1691e-01, 4.9083e-06, 1.0197e-01, 4.7305e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,193][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ by] are: tensor([0.1998, 0.2004, 0.1993, 0.2003, 0.2002], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,193][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.8058, 0.0136, 0.0824, 0.0544, 0.0438], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,193][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ by] are: tensor([1.8122e-06, 7.5231e-04, 2.6562e-06, 2.6048e-05, 9.9922e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,194][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0551, 0.5627, 0.1420, 0.1698, 0.0476, 0.0227], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,194][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0059, 0.1840, 0.2236, 0.1095, 0.2513, 0.2257], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,194][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0981, 0.0602, 0.2451, 0.1442, 0.2211, 0.2314], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,195][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2273, 0.0468, 0.1316, 0.1413, 0.2049, 0.2481], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,198][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2897, 0.0162, 0.4022, 0.1041, 0.0768, 0.1110], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,203][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4266, 0.1323, 0.0067, 0.4217, 0.0109, 0.0017], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,211][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1659, 0.5576, 0.0769, 0.1196, 0.0430, 0.0370], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,217][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2086, 0.1473, 0.0754, 0.1609, 0.1683, 0.2395], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,222][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.1570e-02, 2.8185e-01, 1.1749e-05, 1.2905e-01, 5.7750e-01, 2.1643e-05],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,222][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1664, 0.1669, 0.1660, 0.1668, 0.1668, 0.1671], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,222][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.7551, 0.0123, 0.0847, 0.0530, 0.0348, 0.0601], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,223][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.9885e-06, 5.0844e-07, 3.8279e-07, 5.3525e-07, 9.4135e-08, 1.0000e+00],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,223][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.1017, 0.2925, 0.0932, 0.1672, 0.1047, 0.2179, 0.0229],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,223][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([0.0025, 0.1262, 0.2532, 0.0681, 0.1592, 0.3579, 0.0327],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,224][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.0890, 0.0519, 0.1961, 0.1198, 0.2184, 0.2206, 0.1041],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,224][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.1829, 0.0364, 0.1068, 0.1189, 0.1744, 0.2081, 0.1724],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,224][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.4048, 0.0142, 0.2842, 0.0874, 0.0659, 0.1013, 0.0422],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,225][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([0.1883, 0.1582, 0.0157, 0.5402, 0.0205, 0.0039, 0.0732],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,226][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.1376, 0.3723, 0.0647, 0.0969, 0.0306, 0.0389, 0.2589],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,230][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.1773, 0.1630, 0.0321, 0.2390, 0.0685, 0.2099, 0.1101],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,233][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([3.9893e-03, 3.4108e-01, 4.4643e-07, 2.1334e-01, 3.6458e-01, 1.7084e-06,
        7.7006e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,239][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([0.1427, 0.1431, 0.1423, 0.1430, 0.1430, 0.1433, 0.1427],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,247][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.7415, 0.0091, 0.0709, 0.0333, 0.0314, 0.0451, 0.0687],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,251][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([2.9922e-07, 1.1093e-04, 5.6485e-07, 1.2593e-03, 1.3443e-06, 7.5606e-07,
        9.9863e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,253][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0370, 0.6923, 0.0087, 0.0612, 0.0190, 0.1421, 0.0383, 0.0013],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,253][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0081, 0.1509, 0.1274, 0.0872, 0.1582, 0.3309, 0.0570, 0.0803],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,253][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0768, 0.0454, 0.1710, 0.1020, 0.1632, 0.1675, 0.0818, 0.1923],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,254][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1734, 0.0259, 0.0812, 0.0893, 0.1365, 0.1651, 0.1342, 0.1944],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,254][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.2930, 0.0138, 0.2983, 0.0873, 0.0648, 0.0958, 0.0326, 0.1144],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,254][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.2685, 0.1160, 0.0087, 0.4616, 0.0182, 0.0032, 0.1173, 0.0064],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,255][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1523, 0.3428, 0.0524, 0.0709, 0.0312, 0.0304, 0.2861, 0.0340],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,255][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1355, 0.0719, 0.0444, 0.0506, 0.1550, 0.2117, 0.1060, 0.2249],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,255][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ of] are: tensor([6.7021e-03, 3.6205e-01, 7.9147e-06, 1.1898e-01, 3.4916e-01, 1.4561e-05,
        7.4464e-02, 8.8623e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,256][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1248, 0.1252, 0.1245, 0.1251, 0.1251, 0.1254, 0.1249, 0.1249],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,258][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.6375, 0.0101, 0.0709, 0.0375, 0.0296, 0.0377, 0.0725, 0.1042],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,260][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ of] are: tensor([1.0385e-02, 3.1827e-02, 5.2103e-04, 1.2959e-03, 7.0975e-02, 1.2176e-02,
        6.6914e-02, 8.0591e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,266][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.1327, 0.0814, 0.1742, 0.1534, 0.1425, 0.1929, 0.0226, 0.0951, 0.0052],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,273][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([0.0022, 0.0847, 0.1419, 0.0613, 0.1418, 0.2718, 0.0342, 0.1897, 0.0725],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,281][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.0671, 0.0392, 0.1505, 0.0903, 0.1517, 0.1533, 0.0738, 0.1789, 0.0952],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,283][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.1353, 0.0190, 0.0649, 0.0742, 0.1174, 0.1425, 0.1147, 0.1758, 0.1562],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,284][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.3044, 0.0120, 0.2823, 0.0785, 0.0560, 0.0835, 0.0298, 0.1001, 0.0534],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,284][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([0.1369, 0.0997, 0.0123, 0.4495, 0.0169, 0.0048, 0.1356, 0.0081, 0.1361],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,284][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.1324, 0.3623, 0.0507, 0.0763, 0.0294, 0.0314, 0.2446, 0.0378, 0.0350],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,285][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([0.2806, 0.0762, 0.0339, 0.0669, 0.0745, 0.1736, 0.0698, 0.1844, 0.0400],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,285][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([3.4561e-03, 1.9981e-01, 1.9872e-06, 2.6422e-01, 4.1470e-01, 2.8943e-06,
        7.2075e-02, 3.5460e-02, 1.0263e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,285][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([0.1110, 0.1113, 0.1107, 0.1113, 0.1112, 0.1114, 0.1110, 0.1111, 0.1109],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,286][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.6288, 0.0095, 0.0639, 0.0324, 0.0320, 0.0374, 0.0625, 0.0963, 0.0373],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,286][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([4.2326e-08, 1.4585e-05, 3.8192e-07, 3.5416e-04, 5.9897e-07, 3.8845e-08,
        8.3388e-04, 2.7973e-07, 9.9880e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,286][circuit_model.py][line:1532][INFO] ##1-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.1357, 0.0848, 0.0432, 0.0996, 0.2062, 0.2885, 0.0364, 0.0890, 0.0100,
        0.0066], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,289][circuit_model.py][line:1535][INFO] ##1-th layer ##Weight##: The head2 weight for token [ including] are: tensor([0.0021, 0.0702, 0.1168, 0.0624, 0.1536, 0.2176, 0.0338, 0.1844, 0.0968,
        0.0624], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,294][circuit_model.py][line:1538][INFO] ##1-th layer ##Weight##: The head3 weight for token [ including] are: tensor([0.0611, 0.0369, 0.1476, 0.0875, 0.1276, 0.1321, 0.0651, 0.1514, 0.0785,
        0.1121], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,300][circuit_model.py][line:1541][INFO] ##1-th layer ##Weight##: The head4 weight for token [ including] are: tensor([0.1241, 0.0149, 0.0531, 0.0609, 0.0972, 0.1172, 0.0941, 0.1475, 0.1315,
        0.1595], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,307][circuit_model.py][line:1544][INFO] ##1-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.2068, 0.0122, 0.2613, 0.0736, 0.0539, 0.0771, 0.0247, 0.0863, 0.0446,
        0.1596], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,314][circuit_model.py][line:1547][INFO] ##1-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.4013, 0.1343, 0.0081, 0.2900, 0.0098, 0.0027, 0.0753, 0.0041, 0.0597,
        0.0147], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,314][circuit_model.py][line:1550][INFO] ##1-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.1337, 0.2783, 0.0551, 0.0720, 0.0330, 0.0368, 0.2972, 0.0409, 0.0434,
        0.0095], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,315][circuit_model.py][line:1553][INFO] ##1-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.1699, 0.0635, 0.0711, 0.1150, 0.0837, 0.1766, 0.0500, 0.1520, 0.0566,
        0.0615], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,315][circuit_model.py][line:1556][INFO] ##1-th layer ##Weight##: The head9 weight for token [ including] are: tensor([4.1707e-03, 2.2469e-01, 1.0686e-06, 1.1018e-01, 2.6981e-01, 3.3595e-06,
        7.8995e-02, 3.8209e-02, 1.2536e-02, 2.6141e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,316][circuit_model.py][line:1559][INFO] ##1-th layer ##Weight##: The head10 weight for token [ including] are: tensor([0.0999, 0.1002, 0.0996, 0.1001, 0.1001, 0.1003, 0.0999, 0.1000, 0.0998,
        0.1002], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,316][circuit_model.py][line:1562][INFO] ##1-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.6592, 0.0090, 0.0508, 0.0293, 0.0261, 0.0356, 0.0553, 0.0751, 0.0346,
        0.0249], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,316][circuit_model.py][line:1565][INFO] ##1-th layer ##Weight##: The head12 weight for token [ including] are: tensor([9.6328e-06, 3.1729e-03, 4.7015e-06, 2.9226e-04, 3.7044e-05, 5.8708e-08,
        5.0372e-03, 7.6972e-06, 5.4672e-04, 9.9089e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,342][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:04,343][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,343][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,344][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,344][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,344][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,345][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,345][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,345][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,345][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,346][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,346][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,346][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,348][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.5551, 0.4449], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,355][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.9667, 0.0333], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,362][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.9498, 0.0502], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,364][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.7117, 0.2883], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,364][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.4110, 0.5890], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,364][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.7232, 0.2768], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,365][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([0.9100, 0.0900], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,365][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.0422, 0.9578], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,365][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.5002, 0.4998], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,365][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([0.0043, 0.9957], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,366][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.9582, 0.0418], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,366][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([0.0303, 0.9697], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,366][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.1091, 0.8871, 0.0038], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,367][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.8551, 0.0366, 0.1083], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,367][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.6919, 0.0944, 0.2137], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,369][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.2936, 0.1485, 0.5579], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,373][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.4017, 0.4686, 0.1297], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,378][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1264, 0.0591, 0.8146], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,386][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.3674, 0.0509, 0.5816], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,393][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.0010, 0.9783, 0.0207], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,395][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.3333, 0.3331, 0.3336], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,395][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.0012, 0.2196, 0.7792], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,395][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.8453, 0.0385, 0.1162], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,395][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([5.0289e-03, 1.1436e-04, 9.9486e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,396][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([0.2482, 0.2049, 0.4760, 0.0708], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,396][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([0.7965, 0.0338, 0.1036, 0.0662], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,396][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([0.5502, 0.1290, 0.1959, 0.1249], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,397][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.2805, 0.1237, 0.4384, 0.1574], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,397][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.3003, 0.4449, 0.0887, 0.1661], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,397][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([0.1134, 0.0497, 0.6587, 0.1783], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,400][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([0.2873, 0.0430, 0.4761, 0.1936], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,404][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([0.0013, 0.4183, 0.0207, 0.5597], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,411][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.2500, 0.2498, 0.2502, 0.2499], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,417][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([0.0007, 0.1293, 0.3810, 0.4890], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,425][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([0.8735, 0.0268, 0.0660, 0.0337], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,425][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([3.1457e-03, 1.4469e-04, 1.0928e-03, 9.9562e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,425][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([0.0139, 0.0650, 0.1402, 0.7765, 0.0044], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,426][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([0.7664, 0.0301, 0.0946, 0.0628, 0.0461], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,426][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([0.3642, 0.1011, 0.1305, 0.0815, 0.3228], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,426][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([0.2208, 0.1002, 0.3460, 0.1348, 0.1983], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,427][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.2074, 0.3274, 0.0660, 0.1370, 0.2622], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,427][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.0942, 0.0796, 0.3562, 0.1164, 0.3535], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,427][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([0.1430, 0.0230, 0.2386, 0.1043, 0.4910], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,427][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([4.4261e-04, 1.2542e-01, 4.5570e-03, 8.5094e-01, 1.8643e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,428][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.2001, 0.1999, 0.2003, 0.2000, 0.1997], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,428][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([0.0005, 0.1050, 0.3719, 0.5161, 0.0066], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,428][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.8184, 0.0260, 0.0685, 0.0365, 0.0506], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,429][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([1.6498e-03, 9.9260e-05, 1.0416e-03, 5.0413e-04, 9.9671e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,431][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0205, 0.7585, 0.0871, 0.0750, 0.0521, 0.0068], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,434][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.7345, 0.0294, 0.0913, 0.0588, 0.0427, 0.0435], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,434][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2619, 0.0933, 0.1013, 0.0658, 0.2355, 0.2424], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,435][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1642, 0.0755, 0.2522, 0.1000, 0.1357, 0.2723], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,435][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1461, 0.2552, 0.0579, 0.1084, 0.2091, 0.2234], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,435][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0517, 0.0193, 0.1227, 0.0225, 0.0238, 0.7600], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,441][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0593, 0.0083, 0.0947, 0.0422, 0.2078, 0.5877], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,447][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0014, 0.1593, 0.0055, 0.7982, 0.0269, 0.0086], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,455][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1667, 0.1666, 0.1669, 0.1666, 0.1664, 0.1668], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,458][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0005, 0.1013, 0.3840, 0.5036, 0.0057, 0.0049], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,458][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7506, 0.0247, 0.0691, 0.0358, 0.0434, 0.0763], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,458][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.8783e-03, 2.7290e-05, 1.2850e-03, 7.7831e-04, 3.3271e-03, 9.8870e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,459][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([0.0516, 0.5170, 0.0845, 0.0885, 0.1088, 0.1437, 0.0059],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,459][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([0.7025, 0.0275, 0.0884, 0.0603, 0.0489, 0.0512, 0.0213],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,459][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([0.1633, 0.1087, 0.0836, 0.0523, 0.2314, 0.2409, 0.1198],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,459][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([0.1506, 0.0568, 0.2619, 0.0897, 0.1200, 0.2365, 0.0844],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,460][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([0.1585, 0.2000, 0.0589, 0.0914, 0.1886, 0.1905, 0.1122],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,460][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([0.0352, 0.0258, 0.1585, 0.0609, 0.0291, 0.6816, 0.0090],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,460][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([0.0422, 0.0092, 0.0741, 0.0375, 0.1468, 0.3502, 0.3399],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,461][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([0.0012, 0.1210, 0.0094, 0.7770, 0.0278, 0.0096, 0.0540],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,463][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([0.1429, 0.1428, 0.1430, 0.1428, 0.1426, 0.1429, 0.1429],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,466][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([4.0384e-04, 9.9839e-02, 3.4377e-01, 4.3166e-01, 7.4389e-03, 5.1515e-03,
        1.1173e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,471][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([0.7798, 0.0167, 0.0577, 0.0245, 0.0355, 0.0571, 0.0287],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,475][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([6.7534e-04, 3.3557e-05, 5.1972e-05, 1.0826e-03, 1.5177e-04, 2.8469e-04,
        9.9772e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,480][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([5.4805e-03, 8.9250e-01, 1.3832e-03, 1.5749e-02, 1.3984e-02, 5.7479e-02,
        1.3128e-02, 2.9506e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,487][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.6949, 0.0272, 0.0831, 0.0568, 0.0437, 0.0464, 0.0199, 0.0280],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,488][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0956, 0.0300, 0.0381, 0.0271, 0.1113, 0.1191, 0.0629, 0.5158],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,489][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0983, 0.0490, 0.1698, 0.0680, 0.0913, 0.1478, 0.0762, 0.2997],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,489][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1443, 0.1676, 0.0487, 0.0799, 0.1715, 0.1863, 0.1001, 0.1017],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,489][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0300, 0.0181, 0.0566, 0.0271, 0.0292, 0.4853, 0.0125, 0.3412],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,490][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0349, 0.0057, 0.0539, 0.0256, 0.1092, 0.2800, 0.2127, 0.2780],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,490][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0137, 0.2125, 0.0488, 0.1680, 0.1266, 0.0210, 0.2849, 0.1244],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,490][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.1250, 0.1249, 0.1251, 0.1250, 0.1248, 0.1251, 0.1250, 0.1250],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,491][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([3.7631e-04, 8.8394e-02, 3.4132e-01, 4.5295e-01, 5.3389e-03, 4.4301e-03,
        1.0553e-01, 1.6546e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,491][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.6561, 0.0195, 0.0574, 0.0266, 0.0361, 0.0506, 0.0301, 0.1235],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,491][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([1.2715e-02, 3.3002e-05, 1.4693e-03, 3.7554e-04, 1.6234e-02, 2.0381e-02,
        3.6019e-04, 9.4843e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,494][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([0.0635, 0.1332, 0.2901, 0.0940, 0.1694, 0.1235, 0.0069, 0.1173, 0.0021],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,501][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([0.6753, 0.0256, 0.0815, 0.0557, 0.0448, 0.0459, 0.0207, 0.0302, 0.0203],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,508][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([0.0727, 0.0241, 0.0384, 0.0266, 0.1054, 0.1123, 0.0532, 0.4162, 0.1511],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,516][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([0.1050, 0.0397, 0.1676, 0.0617, 0.0858, 0.1460, 0.0633, 0.2885, 0.0425],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,518][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.1289, 0.1566, 0.0492, 0.0718, 0.1570, 0.1641, 0.0960, 0.0996, 0.0768],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,519][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([0.0275, 0.0241, 0.1188, 0.0359, 0.0254, 0.6308, 0.0122, 0.0921, 0.0332],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,519][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([0.0342, 0.0073, 0.0585, 0.0279, 0.1010, 0.2280, 0.2321, 0.2673, 0.0436],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,519][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([5.8610e-04, 4.8242e-02, 1.0028e-02, 6.0513e-01, 4.8248e-02, 8.3118e-03,
        1.9586e-01, 4.4418e-02, 3.9182e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,520][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([0.1111, 0.1110, 0.1112, 0.1111, 0.1109, 0.1112, 0.1111, 0.1111, 0.1111],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,520][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([0.0005, 0.1028, 0.3355, 0.4354, 0.0063, 0.0047, 0.1030, 0.0021, 0.0098],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,520][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([0.6667, 0.0166, 0.0512, 0.0241, 0.0351, 0.0489, 0.0266, 0.1137, 0.0172],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,521][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([3.5052e-04, 5.3840e-05, 6.6554e-05, 9.7350e-04, 7.7478e-04, 2.2282e-04,
        9.5586e-03, 1.8593e-03, 9.8614e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,521][circuit_model.py][line:1570][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([0.0450, 0.1112, 0.0434, 0.0690, 0.3821, 0.2350, 0.0159, 0.0906, 0.0052,
        0.0026], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,521][circuit_model.py][line:1573][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([0.6612, 0.0277, 0.0871, 0.0565, 0.0433, 0.0442, 0.0188, 0.0279, 0.0187,
        0.0144], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,525][circuit_model.py][line:1576][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([0.0834, 0.0749, 0.0384, 0.0299, 0.0884, 0.0813, 0.0609, 0.3085, 0.1681,
        0.0662], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,532][circuit_model.py][line:1579][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([0.0997, 0.0401, 0.1597, 0.0591, 0.0815, 0.1353, 0.0586, 0.2795, 0.0416,
        0.0449], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,540][circuit_model.py][line:1582][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([0.0992, 0.1317, 0.0375, 0.0661, 0.1576, 0.1400, 0.0907, 0.0711, 0.0739,
        0.1322], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,546][circuit_model.py][line:1585][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([0.0278, 0.0178, 0.1080, 0.0359, 0.0239, 0.4022, 0.0132, 0.0701, 0.0180,
        0.2832], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,548][circuit_model.py][line:1588][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([0.0245, 0.0057, 0.0416, 0.0224, 0.0802, 0.1680, 0.2012, 0.2048, 0.0404,
        0.2111], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,548][circuit_model.py][line:1591][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([0.0014, 0.0878, 0.0147, 0.5483, 0.0167, 0.0066, 0.0384, 0.0170, 0.0861,
        0.1831], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,549][circuit_model.py][line:1594][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([0.1000, 0.0999, 0.1001, 0.0999, 0.0998, 0.1000, 0.1000, 0.1000, 0.1000,
        0.1002], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,549][circuit_model.py][line:1597][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([3.4376e-04, 7.6536e-02, 3.3927e-01, 4.3905e-01, 7.2602e-03, 5.8669e-03,
        1.1155e-01, 2.3561e-03, 1.0183e-02, 7.5842e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,549][circuit_model.py][line:1600][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([0.6736, 0.0164, 0.0466, 0.0220, 0.0326, 0.0493, 0.0243, 0.1014, 0.0167,
        0.0171], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,550][circuit_model.py][line:1603][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([1.5867e-03, 8.3415e-05, 1.3032e-03, 7.0358e-04, 3.6399e-03, 3.0229e-04,
        3.0022e-03, 1.3423e-02, 3.2112e-03, 9.7274e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,551][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:04,552][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[ 7625],
        [ 6375],
        [ 6863],
        [14038],
        [ 3699],
        [ 8275],
        [ 2517],
        [ 7614],
        [ 7409],
        [ 4213]], device='cuda:0')
[2024-07-23 21:07:04,554][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[12975],
        [ 1120],
        [ 5492],
        [13789],
        [  676],
        [ 7148],
        [ 1497],
        [ 3092],
        [ 2936],
        [ 5250]], device='cuda:0')
[2024-07-23 21:07:04,557][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[15878],
        [18065],
        [20653],
        [24797],
        [34304],
        [25881],
        [23705],
        [23070],
        [24415],
        [20506]], device='cuda:0')
[2024-07-23 21:07:04,561][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[28193],
        [37643],
        [35098],
        [33287],
        [32908],
        [29031],
        [26671],
        [26785],
        [25405],
        [24736]], device='cuda:0')
[2024-07-23 21:07:04,564][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[26437],
        [26392],
        [26082],
        [25813],
        [24234],
        [22835],
        [22959],
        [22395],
        [22280],
        [22501]], device='cuda:0')
[2024-07-23 21:07:04,567][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[37069],
        [37068],
        [36536],
        [36197],
        [35993],
        [35553],
        [35472],
        [34923],
        [34384],
        [33755]], device='cuda:0')
[2024-07-23 21:07:04,570][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[30752],
        [30418],
        [35630],
        [34381],
        [33366],
        [32170],
        [31132],
        [29828],
        [29510],
        [27957]], device='cuda:0')
[2024-07-23 21:07:04,574][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[42529],
        [43494],
        [43498],
        [37447],
        [40903],
        [41153],
        [38360],
        [38496],
        [36075],
        [40000]], device='cuda:0')
[2024-07-23 21:07:04,577][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[10891],
        [ 7732],
        [ 6554],
        [ 6968],
        [ 6579],
        [ 6741],
        [ 7628],
        [ 7855],
        [ 7661],
        [ 8115]], device='cuda:0')
[2024-07-23 21:07:04,580][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[ 7235],
        [ 2882],
        [ 1902],
        [ 2543],
        [ 1819],
        [ 5703],
        [ 5832],
        [13367],
        [ 9286],
        [ 6843]], device='cuda:0')
[2024-07-23 21:07:04,582][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[11059],
        [26842],
        [26642],
        [25190],
        [18051],
        [15524],
        [19542],
        [21963],
        [18004],
        [23403]], device='cuda:0')
[2024-07-23 21:07:04,583][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[3153],
        [3131],
        [3135],
        [3140],
        [3141],
        [3143],
        [3140],
        [3141],
        [3142],
        [3149]], device='cuda:0')
[2024-07-23 21:07:04,584][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[4042],
        [4170],
        [4695],
        [4698],
        [5104],
        [5633],
        [5638],
        [5931],
        [5954],
        [5892]], device='cuda:0')
[2024-07-23 21:07:04,585][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[12707],
        [35352],
        [21028],
        [16938],
        [19441],
        [19881],
        [19759],
        [27323],
        [33393],
        [16965]], device='cuda:0')
[2024-07-23 21:07:04,586][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 8309],
        [16536],
        [12092],
        [29302],
        [16509],
        [28771],
        [11491],
        [28160],
        [40529],
        [12262]], device='cuda:0')
[2024-07-23 21:07:04,588][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[16977],
        [ 6068],
        [ 1887],
        [ 4157],
        [15859],
        [ 2463],
        [ 5936],
        [ 2500],
        [15842],
        [20898]], device='cuda:0')
[2024-07-23 21:07:04,591][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[3668],
        [3675],
        [3854],
        [3963],
        [3960],
        [3953],
        [3981],
        [4028],
        [4067],
        [4094]], device='cuda:0')
[2024-07-23 21:07:04,594][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[16774],
        [16423],
        [14672],
        [13943],
        [12539],
        [12324],
        [11606],
        [ 8455],
        [ 8699],
        [ 9120]], device='cuda:0')
[2024-07-23 21:07:04,598][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[20746],
        [17886],
        [24329],
        [25583],
        [25482],
        [24938],
        [24971],
        [27813],
        [28262],
        [28060]], device='cuda:0')
[2024-07-23 21:07:04,601][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[14134],
        [ 9083],
        [ 9485],
        [ 7168],
        [ 6571],
        [ 6510],
        [ 7469],
        [ 6381],
        [ 6921],
        [ 6762]], device='cuda:0')
[2024-07-23 21:07:04,604][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[15910],
        [17204],
        [12363],
        [12341],
        [15369],
        [ 7207],
        [ 7625],
        [10802],
        [ 8528],
        [10919]], device='cuda:0')
[2024-07-23 21:07:04,607][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[6118],
        [6059],
        [4619],
        [4603],
        [3973],
        [3632],
        [4305],
        [4257],
        [4457],
        [5089]], device='cuda:0')
[2024-07-23 21:07:04,611][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[4343],
        [3273],
        [3108],
        [4446],
        [4702],
        [4492],
        [4343],
        [3291],
        [2953],
        [3119]], device='cuda:0')
[2024-07-23 21:07:04,614][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[18517],
        [18511],
        [18545],
        [18534],
        [18534],
        [18523],
        [18516],
        [18525],
        [18525],
        [18526]], device='cuda:0')
[2024-07-23 21:07:04,616][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[ 846],
        [1643],
        [4953],
        [5965],
        [6289],
        [6365],
        [6360],
        [6487],
        [6381],
        [6786]], device='cuda:0')
[2024-07-23 21:07:04,617][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[19911],
        [19888],
        [20030],
        [19888],
        [19527],
        [18740],
        [19009],
        [18984],
        [18883],
        [18753]], device='cuda:0')
[2024-07-23 21:07:04,618][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[24686],
        [ 5773],
        [ 1406],
        [ 4231],
        [ 4426],
        [ 3629],
        [ 4375],
        [18606],
        [ 3861],
        [ 3577]], device='cuda:0')
[2024-07-23 21:07:04,618][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[40444],
        [46707],
        [48688],
        [46738],
        [46447],
        [47817],
        [46977],
        [48285],
        [46642],
        [46175]], device='cuda:0')
[2024-07-23 21:07:04,619][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[31597],
        [39592],
        [34232],
        [21496],
        [32931],
        [27978],
        [39382],
        [26621],
        [15405],
        [28076]], device='cuda:0')
[2024-07-23 21:07:04,621][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723],
        [10723]], device='cuda:0')
[2024-07-23 21:07:04,647][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:04,654][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,659][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,661][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,661][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,662][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,662][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,662][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,662][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,663][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,663][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,663][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,663][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,664][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.4307, 0.5693], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,664][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [izen] are: tensor([3.3683e-04, 9.9966e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,664][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.4079, 0.5921], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,666][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [izen] are: tensor([2.2865e-07, 1.0000e+00], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,674][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.6912, 0.3088], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,681][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.1639, 0.8361], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,688][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.5944, 0.4056], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,691][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.4455, 0.5545], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,691][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.2973, 0.7027], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,691][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [izen] are: tensor([0.9110, 0.0890], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,692][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.0024, 0.9976], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,692][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [izen] are: tensor([0.1592, 0.8408], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,692][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.2889, 0.4918, 0.2193], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,693][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ is] are: tensor([4.2067e-05, 3.8316e-01, 6.1680e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,693][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.1564, 0.5574, 0.2863], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,693][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ is] are: tensor([2.1268e-07, 1.7502e-01, 8.2497e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,693][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.0467, 0.7190, 0.2343], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,694][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.0815, 0.4201, 0.4984], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,694][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.3779, 0.2776, 0.3445], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,698][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.2595, 0.3494, 0.3911], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,705][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.1339, 0.4496, 0.4166], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,712][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.3630, 0.5136, 0.1234], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,719][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.0029, 0.5533, 0.4438], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,721][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.0846, 0.3690, 0.5463], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,721][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.2414, 0.3966, 0.2048, 0.1572], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,721][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([1.7181e-04, 4.7523e-01, 1.5585e-01, 3.6875e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,722][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.0733, 0.4170, 0.2884, 0.2213], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,722][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([1.1267e-07, 2.8037e-03, 5.1507e-02, 9.4569e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,722][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.0213, 0.0191, 0.0675, 0.8921], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,722][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.0405, 0.2150, 0.3054, 0.4391], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,723][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.3023, 0.2118, 0.2526, 0.2332], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,723][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.1928, 0.2676, 0.3088, 0.2308], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,723][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.0842, 0.2384, 0.4231, 0.2543], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,724][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([0.4559, 0.3084, 0.1326, 0.1032], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,724][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.0069, 0.5508, 0.3023, 0.1399], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,729][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.0679, 0.2586, 0.3687, 0.3047], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,736][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.1738, 0.3387, 0.1195, 0.1681, 0.1999], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,740][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ by] are: tensor([1.7585e-06, 8.3402e-03, 2.8593e-03, 3.0062e-03, 9.8579e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,748][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.0525, 0.2785, 0.2035, 0.3883, 0.0772], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,751][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ by] are: tensor([1.9341e-07, 1.5390e-04, 3.2470e-03, 1.3096e-01, 8.6563e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,751][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.0014, 0.0024, 0.0063, 0.9166, 0.0733], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,751][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.0414, 0.2334, 0.2598, 0.3640, 0.1013], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,751][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.2498, 0.1675, 0.1904, 0.1916, 0.2007], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,752][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.1538, 0.2228, 0.2288, 0.1777, 0.2168], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,752][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.0827, 0.1504, 0.3068, 0.3069, 0.1532], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,752][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ by] are: tensor([0.2298, 0.2713, 0.1513, 0.2759, 0.0717], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,753][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.0266, 0.5030, 0.2796, 0.1735, 0.0174], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,753][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ by] are: tensor([0.0619, 0.1970, 0.2519, 0.2354, 0.2538], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,753][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1498, 0.2570, 0.1094, 0.1105, 0.2674, 0.1059], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,753][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.7124e-06, 3.8790e-03, 2.3834e-03, 2.1403e-03, 5.2230e-01, 4.6929e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,754][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0426, 0.2165, 0.1701, 0.3218, 0.1650, 0.0839], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,756][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.7674e-08, 9.3278e-05, 1.1283e-03, 5.2036e-02, 5.5000e-01, 3.9675e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,763][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0029, 0.0059, 0.0091, 0.2174, 0.3961, 0.3685], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,770][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0368, 0.2156, 0.2368, 0.3505, 0.1038, 0.0565], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,778][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2029, 0.1400, 0.1618, 0.1578, 0.1649, 0.1726], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,780][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1237, 0.1793, 0.1827, 0.1411, 0.1773, 0.1960], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,781][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0627, 0.1654, 0.2138, 0.2443, 0.2109, 0.1028], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,781][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2345, 0.2675, 0.1226, 0.1263, 0.1785, 0.0707], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,781][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0027, 0.4774, 0.3390, 0.1661, 0.0093, 0.0054], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,782][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0457, 0.1481, 0.1939, 0.1882, 0.2042, 0.2199], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,782][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.1345, 0.2225, 0.0915, 0.1102, 0.2482, 0.0944, 0.0987],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,782][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([2.9727e-06, 2.7105e-03, 2.0948e-03, 2.5297e-03, 3.7366e-01, 6.0178e-01,
        1.7223e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,783][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.0192, 0.2058, 0.1067, 0.1706, 0.2027, 0.1588, 0.1362],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,783][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([6.0593e-08, 2.3571e-06, 1.4351e-04, 9.5658e-03, 1.5272e-01, 3.0039e-01,
        5.3718e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,783][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([5.0602e-04, 1.2370e-04, 3.7798e-04, 3.8840e-03, 7.9402e-03, 4.2600e-02,
        9.4457e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,783][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([0.0249, 0.1600, 0.2314, 0.3415, 0.0937, 0.0576, 0.0909],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,788][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.1784, 0.1247, 0.1423, 0.1394, 0.1468, 0.1507, 0.1177],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,796][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.1110, 0.1428, 0.1711, 0.1255, 0.1633, 0.1830, 0.1032],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,803][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([0.0353, 0.1204, 0.1944, 0.1942, 0.2102, 0.1314, 0.1142],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,810][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([0.2166, 0.1071, 0.1401, 0.1371, 0.1497, 0.2014, 0.0480],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,811][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.0133, 0.5905, 0.2445, 0.1251, 0.0135, 0.0078, 0.0054],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,811][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([0.0219, 0.0641, 0.0729, 0.0873, 0.1168, 0.1412, 0.4958],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,811][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.1101, 0.2566, 0.0815, 0.0806, 0.1304, 0.0775, 0.1592, 0.1040],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,811][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ of] are: tensor([4.8389e-05, 3.1680e-03, 5.2091e-03, 8.5324e-03, 3.7423e-01, 5.0364e-01,
        9.2685e-02, 1.2477e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,812][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0231, 0.1420, 0.0656, 0.1266, 0.0820, 0.0993, 0.4255, 0.0360],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,812][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ of] are: tensor([5.7016e-10, 2.0075e-07, 3.5002e-06, 2.5964e-04, 2.3659e-03, 2.9665e-03,
        9.4965e-03, 9.8491e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,812][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ of] are: tensor([7.2084e-06, 1.2135e-05, 7.5093e-06, 1.9140e-04, 3.2432e-04, 6.1214e-04,
        9.8115e-01, 1.7700e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,813][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0521, 0.1992, 0.1799, 0.2433, 0.0912, 0.0570, 0.0950, 0.0822],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,813][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1689, 0.0997, 0.1205, 0.1189, 0.1325, 0.1359, 0.1015, 0.1223],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,813][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0939, 0.1334, 0.1442, 0.1066, 0.1374, 0.1562, 0.0889, 0.1395],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,818][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0521, 0.1610, 0.1497, 0.1753, 0.1331, 0.0903, 0.1457, 0.0927],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,826][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0884, 0.2854, 0.0803, 0.0945, 0.0705, 0.1955, 0.1082, 0.0772],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,833][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0069, 0.6693, 0.2083, 0.0953, 0.0089, 0.0052, 0.0033, 0.0027],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,840][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0146, 0.0454, 0.0487, 0.0638, 0.0866, 0.1119, 0.3669, 0.2622],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:04,840][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.0976, 0.1553, 0.0783, 0.0866, 0.1882, 0.0677, 0.1105, 0.1449, 0.0709],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,841][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([1.3895e-07, 7.8511e-04, 1.0162e-03, 1.0580e-03, 4.0746e-01, 4.8847e-01,
        2.1402e-02, 1.5534e-03, 7.8259e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,841][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.0162, 0.1314, 0.0768, 0.1154, 0.0655, 0.1239, 0.1872, 0.1547, 0.1290],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,841][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([1.1202e-09, 1.5383e-07, 2.4161e-06, 1.0795e-04, 1.3662e-03, 2.4489e-03,
        5.6322e-03, 9.3348e-01, 5.6963e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,842][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([4.2052e-05, 1.3213e-05, 1.5413e-05, 3.2232e-04, 5.4504e-04, 1.6601e-03,
        3.2525e-01, 6.7049e-02, 6.0511e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,842][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([0.0222, 0.1166, 0.1695, 0.2443, 0.0688, 0.0447, 0.0718, 0.1005, 0.1615],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,842][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.1412, 0.0925, 0.1096, 0.1082, 0.1163, 0.1192, 0.0945, 0.1106, 0.1078],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,843][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([0.0853, 0.1114, 0.1314, 0.0992, 0.1301, 0.1404, 0.0827, 0.1278, 0.0916],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,843][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([0.0348, 0.0807, 0.1556, 0.1220, 0.1685, 0.0975, 0.0936, 0.1656, 0.0817],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,843][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([0.1560, 0.1226, 0.0854, 0.1208, 0.1243, 0.1378, 0.0836, 0.1091, 0.0605],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,848][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.0015, 0.5489, 0.3006, 0.1264, 0.0076, 0.0048, 0.0024, 0.0025, 0.0054],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,856][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([0.0111, 0.0354, 0.0362, 0.0450, 0.0657, 0.0786, 0.2944, 0.2239, 0.2096],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:04,862][circuit_model.py][line:1532][INFO] ##2-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.0893, 0.1285, 0.0737, 0.0791, 0.1473, 0.0647, 0.1132, 0.1102, 0.0974,
        0.0966], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,867][circuit_model.py][line:1535][INFO] ##2-th layer ##Weight##: The head2 weight for token [ including] are: tensor([8.4972e-07, 1.9209e-03, 2.9072e-03, 1.8633e-03, 4.7135e-01, 3.5006e-01,
        2.2829e-02, 1.6243e-03, 7.0514e-02, 7.6934e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,873][circuit_model.py][line:1538][INFO] ##2-th layer ##Weight##: The head3 weight for token [ including] are: tensor([0.0124, 0.0749, 0.0568, 0.0842, 0.0901, 0.1051, 0.1538, 0.1380, 0.2336,
        0.0510], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,873][circuit_model.py][line:1541][INFO] ##2-th layer ##Weight##: The head4 weight for token [ including] are: tensor([6.8774e-11, 6.9955e-08, 1.2194e-06, 9.2212e-05, 7.4452e-04, 1.0457e-03,
        2.3367e-03, 5.9653e-01, 4.8280e-02, 3.5097e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,873][circuit_model.py][line:1544][INFO] ##2-th layer ##Weight##: The head5 weight for token [ including] are: tensor([1.8915e-05, 4.8925e-07, 5.0052e-06, 6.8003e-05, 1.5573e-04, 6.1932e-04,
        2.6331e-02, 1.2419e-02, 1.1563e-01, 8.4476e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,874][circuit_model.py][line:1547][INFO] ##2-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.0180, 0.1366, 0.1602, 0.2428, 0.0660, 0.0392, 0.0625, 0.0833, 0.1463,
        0.0452], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,874][circuit_model.py][line:1550][INFO] ##2-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.1232, 0.0817, 0.0943, 0.0969, 0.1025, 0.1064, 0.0857, 0.0986, 0.0990,
        0.1118], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,874][circuit_model.py][line:1553][INFO] ##2-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.0777, 0.1033, 0.1154, 0.0890, 0.1155, 0.1268, 0.0759, 0.1128, 0.0843,
        0.0993], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,875][circuit_model.py][line:1556][INFO] ##2-th layer ##Weight##: The head9 weight for token [ including] are: tensor([0.0328, 0.0870, 0.1330, 0.1231, 0.1100, 0.0722, 0.0906, 0.1266, 0.1026,
        0.1221], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,875][circuit_model.py][line:1559][INFO] ##2-th layer ##Weight##: The head10 weight for token [ including] are: tensor([0.1410, 0.1091, 0.0595, 0.0670, 0.0765, 0.1401, 0.1176, 0.0739, 0.1842,
        0.0311], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,875][circuit_model.py][line:1562][INFO] ##2-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.0010, 0.4742, 0.3346, 0.1585, 0.0086, 0.0053, 0.0024, 0.0027, 0.0056,
        0.0070], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,876][circuit_model.py][line:1565][INFO] ##2-th layer ##Weight##: The head12 weight for token [ including] are: tensor([0.0140, 0.0407, 0.0434, 0.0522, 0.0666, 0.0816, 0.2430, 0.1802, 0.1776,
        0.1006], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:04,891][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:04,896][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,897][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,897][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,897][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,898][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,898][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,898][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,899][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,899][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,899][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,900][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,900][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:04,900][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.3940, 0.6060], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,900][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.3827, 0.6173], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,901][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.0027, 0.9973], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,901][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.1448, 0.8552], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,901][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.0299, 0.9701], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,902][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.1051, 0.8949], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,902][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([0.0531, 0.9469], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,902][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.1660, 0.8340], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,903][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.0508, 0.9492], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,903][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([0.0124, 0.9876], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,903][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.0882, 0.9118], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,904][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([0.3781, 0.6219], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:04,904][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.2612, 0.4875, 0.2513], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,904][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.1821, 0.3174, 0.5006], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,905][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([1.4775e-05, 1.3597e-01, 8.6402e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,905][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.0046, 0.3637, 0.6317], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,905][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0009, 0.6114, 0.3877], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,906][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.0023, 0.1659, 0.8318], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,906][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.1407, 0.6494, 0.2100], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,906][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.0103, 0.0391, 0.9506], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,907][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0057, 0.1940, 0.8004], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,910][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([1.9147e-04, 1.8657e-01, 8.1323e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,916][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.0885, 0.6204, 0.2912], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,924][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.3797, 0.4549, 0.1654], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:04,924][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([0.2192, 0.3696, 0.2191, 0.1921], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,924][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([0.0609, 0.1190, 0.0861, 0.7340], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,925][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([9.5456e-07, 2.8388e-03, 3.8582e-01, 6.1134e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,925][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.0017, 0.1025, 0.1993, 0.6965], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,925][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([2.1747e-04, 1.2723e-02, 1.0497e-01, 8.8209e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,925][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([4.1757e-04, 2.5710e-02, 5.0193e-01, 4.7194e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,926][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([0.0664, 0.4905, 0.1656, 0.2775], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,926][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([0.0049, 0.0112, 0.3210, 0.6629], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,926][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.0008, 0.0187, 0.5662, 0.4143], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,927][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([6.7900e-05, 4.5104e-02, 2.3528e-01, 7.1955e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,927][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([0.0424, 0.4433, 0.2001, 0.3142], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,932][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([0.2486, 0.4091, 0.1093, 0.2329], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:04,940][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([0.1365, 0.3188, 0.1238, 0.1836, 0.2373], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,946][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([0.0950, 0.0741, 0.2170, 0.5147, 0.0992], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,951][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([2.9493e-07, 4.2555e-04, 2.7435e-02, 5.4142e-01, 4.3072e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,954][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([4.8570e-04, 9.8898e-03, 5.9779e-02, 4.9972e-01, 4.3012e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,954][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([1.4638e-05, 1.4488e-03, 9.0191e-03, 9.3548e-01, 5.4036e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,954][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([1.6226e-04, 6.3566e-03, 1.0723e-01, 1.9032e-01, 6.9594e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,955][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([0.0794, 0.4194, 0.1445, 0.1976, 0.1591], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,955][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([0.0011, 0.0025, 0.0652, 0.1309, 0.8003], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,955][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([4.5520e-04, 3.9431e-03, 6.6902e-02, 7.2795e-01, 2.0075e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,955][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([1.2550e-05, 5.1779e-03, 6.2684e-02, 4.7789e-01, 4.5423e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,956][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.0410, 0.3526, 0.1595, 0.2626, 0.1844], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,956][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([0.1873, 0.2784, 0.0944, 0.2031, 0.2368], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:04,956][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1259, 0.2233, 0.1060, 0.1143, 0.2828, 0.1477], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,957][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1017, 0.1210, 0.1557, 0.3452, 0.1005, 0.1760], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,957][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.5935e-08, 5.6529e-05, 2.1355e-03, 5.6841e-02, 7.7345e-01, 1.6752e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,959][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.5055e-04, 7.6971e-03, 1.2181e-02, 1.2717e-01, 5.2826e-01, 3.2443e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,964][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([3.9938e-05, 5.4992e-03, 1.9217e-02, 3.0862e-01, 4.4143e-01, 2.2519e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,967][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.0730e-05, 1.4699e-03, 1.9106e-02, 4.0019e-02, 6.5019e-01, 2.8917e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,975][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0874, 0.3097, 0.1528, 0.2097, 0.1594, 0.0810], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,982][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0006, 0.0011, 0.0281, 0.0563, 0.3788, 0.5350], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,984][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.3984e-04, 3.3843e-03, 3.7428e-02, 3.6316e-01, 4.4802e-01, 1.4787e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,984][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([7.4678e-06, 2.5554e-03, 1.9047e-02, 1.3006e-01, 4.0183e-01, 4.4650e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,984][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0456, 0.2880, 0.1398, 0.2213, 0.1612, 0.1441], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,985][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1628, 0.2609, 0.0862, 0.1700, 0.2367, 0.0834], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:04,985][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([0.0950, 0.1890, 0.0827, 0.1184, 0.2594, 0.1249, 0.1305],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,985][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([0.0338, 0.1082, 0.0558, 0.6561, 0.0459, 0.0374, 0.0627],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,985][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([2.5031e-09, 2.8046e-06, 9.6005e-05, 1.0126e-03, 6.0558e-02, 7.3650e-02,
        8.6468e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,986][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([1.4960e-05, 2.0044e-04, 5.0233e-03, 1.7823e-02, 8.7538e-02, 3.2694e-01,
        5.6246e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,986][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([1.4169e-05, 4.8026e-04, 3.7533e-03, 2.6066e-02, 4.3420e-02, 1.3503e-01,
        7.9123e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,986][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([7.2113e-06, 1.2254e-04, 4.5161e-03, 7.0435e-03, 9.6091e-02, 2.2788e-01,
        6.6434e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,987][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([0.0420, 0.3486, 0.1145, 0.1967, 0.1278, 0.0507, 0.1197],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,992][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([0.0004, 0.0010, 0.0257, 0.0421, 0.2826, 0.3642, 0.2839],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:04,996][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([3.8875e-05, 3.6477e-04, 5.4301e-03, 4.6012e-02, 1.9438e-01, 1.3588e-01,
        6.1789e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,000][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([1.4628e-06, 2.8081e-04, 7.7103e-03, 2.9903e-02, 1.0499e-01, 1.9455e-01,
        6.6256e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,008][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([0.0245, 0.2578, 0.1178, 0.2033, 0.1224, 0.1021, 0.1721],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,013][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([0.1486, 0.2811, 0.0632, 0.1630, 0.1394, 0.0661, 0.1387],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,014][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0639, 0.1981, 0.0746, 0.0810, 0.1518, 0.1081, 0.1871, 0.1354],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,014][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0314, 0.0147, 0.1608, 0.0696, 0.0454, 0.5216, 0.0993, 0.0572],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,014][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([8.9491e-10, 1.3254e-07, 4.3784e-06, 6.5943e-05, 1.4911e-03, 2.0559e-03,
        8.4547e-01, 1.5091e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,015][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([2.1965e-05, 1.8154e-04, 1.9090e-03, 1.2925e-02, 3.4936e-02, 9.8415e-02,
        4.2606e-01, 4.2556e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,015][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([3.2603e-07, 5.2138e-05, 7.8541e-05, 1.3962e-03, 1.9011e-03, 2.0884e-03,
        9.5558e-01, 3.8905e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,015][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([5.1642e-06, 4.0613e-05, 9.2708e-04, 1.9281e-03, 1.9216e-02, 3.6451e-02,
        3.5626e-01, 5.8517e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,016][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0775, 0.2357, 0.1377, 0.1575, 0.1246, 0.0886, 0.1125, 0.0658],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,016][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([1.6269e-04, 1.7979e-04, 5.3018e-03, 9.9171e-03, 7.4290e-02, 9.7511e-02,
        8.0062e-02, 7.3258e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,016][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([4.7044e-05, 4.2860e-04, 4.4793e-03, 3.5248e-02, 4.8469e-02, 4.3683e-02,
        4.0589e-01, 4.6176e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,017][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([4.6021e-07, 5.5193e-05, 7.1097e-04, 3.3514e-03, 8.0472e-03, 3.0264e-02,
        3.7952e-01, 5.7805e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,021][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0302, 0.2151, 0.1109, 0.1540, 0.1206, 0.1114, 0.1481, 0.1096],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,029][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1135, 0.1609, 0.0726, 0.1260, 0.1745, 0.0742, 0.1201, 0.1582],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,036][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([0.0740, 0.1172, 0.0688, 0.0822, 0.1895, 0.0875, 0.1265, 0.1768, 0.0776],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,043][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([0.0452, 0.1644, 0.0380, 0.5323, 0.0422, 0.0158, 0.0555, 0.0382, 0.0684],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,044][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([2.4982e-10, 4.4722e-08, 1.1826e-06, 1.5857e-05, 2.3073e-04, 7.1790e-04,
        8.7945e-02, 4.5311e-01, 4.5798e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,044][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([4.8082e-06, 2.6977e-05, 2.8120e-04, 1.3691e-03, 5.8260e-03, 2.1490e-02,
        1.1941e-01, 3.8542e-01, 4.6617e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,044][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([1.2361e-06, 6.6828e-05, 1.9248e-04, 2.7280e-03, 3.5734e-03, 6.0747e-03,
        2.9809e-01, 1.5779e-01, 5.3148e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,044][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([1.0428e-06, 7.7709e-06, 2.1514e-04, 5.7055e-04, 3.9460e-03, 1.1546e-02,
        1.0268e-01, 5.1669e-01, 3.6435e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,045][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([0.0357, 0.2881, 0.1046, 0.1354, 0.1162, 0.0433, 0.0917, 0.0467, 0.1383],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,045][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([1.0772e-04, 1.8590e-04, 5.2967e-03, 9.0294e-03, 6.1699e-02, 8.1121e-02,
        6.2151e-02, 5.7201e-01, 2.0840e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,045][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([1.5055e-05, 4.9647e-05, 7.3545e-04, 2.6867e-03, 2.2225e-02, 2.7145e-02,
        1.3115e-01, 5.1659e-01, 2.9940e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,046][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([2.2180e-07, 1.1694e-05, 2.2837e-04, 1.1820e-03, 4.7493e-03, 8.5648e-03,
        7.2105e-02, 4.3000e-01, 4.8316e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,046][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([0.0183, 0.1819, 0.0934, 0.1558, 0.1001, 0.0836, 0.1286, 0.0818, 0.1565],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,046][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([0.1237, 0.1885, 0.0634, 0.1070, 0.1624, 0.0518, 0.1161, 0.1037, 0.0834],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,051][circuit_model.py][line:1570][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([0.0617, 0.0950, 0.0617, 0.0725, 0.1543, 0.0846, 0.1283, 0.1360, 0.1024,
        0.1036], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,059][circuit_model.py][line:1573][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([0.0205, 0.0565, 0.0523, 0.3949, 0.0423, 0.0533, 0.0613, 0.0431, 0.0752,
        0.2006], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,063][circuit_model.py][line:1576][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([2.8548e-11, 9.5422e-10, 3.5299e-08, 3.3285e-07, 2.1658e-05, 6.2881e-05,
        2.2092e-03, 1.3962e-02, 3.7846e-01, 6.0529e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,068][circuit_model.py][line:1579][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([3.0196e-06, 1.7856e-05, 1.0253e-04, 1.1175e-03, 2.8434e-03, 1.4730e-02,
        4.2652e-02, 1.4973e-01, 3.5471e-01, 4.3410e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,071][circuit_model.py][line:1582][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([8.4820e-07, 3.9606e-06, 1.0416e-04, 9.5687e-04, 1.7344e-03, 3.9147e-03,
        4.0986e-02, 5.1548e-02, 1.7828e-01, 7.2247e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,073][circuit_model.py][line:1585][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([5.1756e-07, 1.7626e-06, 3.9413e-05, 1.4162e-04, 1.5582e-03, 3.6995e-03,
        1.8170e-02, 9.8918e-02, 1.2411e-01, 7.5336e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,073][circuit_model.py][line:1588][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([0.0363, 0.2632, 0.0929, 0.1233, 0.0879, 0.0491, 0.0790, 0.0360, 0.1419,
        0.0904], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,074][circuit_model.py][line:1591][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([6.5991e-05, 1.1384e-04, 3.1473e-03, 5.5395e-03, 4.0913e-02, 4.9021e-02,
        3.9197e-02, 3.4255e-01, 1.1885e-01, 4.0060e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,074][circuit_model.py][line:1594][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([6.4270e-06, 1.5771e-05, 3.7371e-04, 9.2086e-04, 4.2016e-03, 5.3217e-03,
        3.0189e-02, 1.1028e-01, 1.1163e-01, 7.3705e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,074][circuit_model.py][line:1597][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([4.2813e-08, 1.2094e-06, 2.5960e-05, 1.5381e-04, 7.0097e-04, 2.9777e-03,
        2.8976e-02, 6.9962e-02, 3.9132e-01, 5.0588e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,075][circuit_model.py][line:1600][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([0.0180, 0.1647, 0.0777, 0.1299, 0.0847, 0.0746, 0.1042, 0.0649, 0.1309,
        0.1504], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,075][circuit_model.py][line:1603][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([0.0916, 0.1813, 0.0500, 0.1085, 0.1252, 0.0503, 0.1104, 0.0737, 0.1034,
        0.1056], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,076][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:05,077][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[8468],
        [ 258],
        [ 210],
        [ 760],
        [  28],
        [ 181],
        [ 209],
        [ 566],
        [ 976],
        [ 402]], device='cuda:0')
[2024-07-23 21:07:05,079][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 7699],
        [ 6864],
        [ 8269],
        [14445],
        [ 4286],
        [ 7738],
        [ 3433],
        [11323],
        [ 8823],
        [ 5485]], device='cuda:0')
[2024-07-23 21:07:05,083][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[27093],
        [22354],
        [21658],
        [21882],
        [22843],
        [24787],
        [24887],
        [24650],
        [25342],
        [26031]], device='cuda:0')
[2024-07-23 21:07:05,086][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[126],
        [112],
        [ 73],
        [109],
        [ 71],
        [ 71],
        [ 81],
        [ 75],
        [ 61],
        [ 60]], device='cuda:0')
[2024-07-23 21:07:05,089][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[ 3365],
        [ 8632],
        [10996],
        [11548],
        [11633],
        [12198],
        [12794],
        [11652],
        [11986],
        [11229]], device='cuda:0')
[2024-07-23 21:07:05,092][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[2273],
        [ 332],
        [ 221],
        [  77],
        [ 143],
        [ 108],
        [  66],
        [ 325],
        [ 334],
        [ 228]], device='cuda:0')
[2024-07-23 21:07:05,096][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 6880],
        [11479],
        [22248],
        [26601],
        [27006],
        [20591],
        [20965],
        [21096],
        [20040],
        [19794]], device='cuda:0')
[2024-07-23 21:07:05,099][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[43363],
        [43095],
        [43003],
        [42401],
        [42619],
        [42665],
        [42573],
        [42949],
        [42785],
        [42947]], device='cuda:0')
[2024-07-23 21:07:05,102][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[27905],
        [36622],
        [33261],
        [34553],
        [32456],
        [31835],
        [32348],
        [30632],
        [30928],
        [30239]], device='cuda:0')
[2024-07-23 21:07:05,106][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[12335],
        [11529],
        [11320],
        [10985],
        [11266],
        [12106],
        [11867],
        [12092],
        [12254],
        [12196]], device='cuda:0')
[2024-07-23 21:07:05,108][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[38115],
        [39187],
        [42748],
        [44096],
        [43008],
        [42277],
        [42340],
        [42120],
        [41783],
        [41775]], device='cuda:0')
[2024-07-23 21:07:05,109][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[34044],
        [32672],
        [21722],
        [22942],
        [19238],
        [21812],
        [24083],
        [24622],
        [26012],
        [28688]], device='cuda:0')
[2024-07-23 21:07:05,109][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[24859],
        [ 4949],
        [ 7706],
        [ 7775],
        [ 8077],
        [ 8276],
        [ 7539],
        [ 7014],
        [ 7862],
        [ 8452]], device='cuda:0')
[2024-07-23 21:07:05,110][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[38751],
        [35423],
        [32823],
        [31970],
        [29490],
        [27708],
        [20009],
        [17277],
        [15634],
        [16008]], device='cuda:0')
[2024-07-23 21:07:05,111][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[8440],
        [9216],
        [2146],
        [3254],
        [ 324],
        [ 438],
        [5840],
        [3992],
        [6310],
        [4197]], device='cuda:0')
[2024-07-23 21:07:05,113][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 8434],
        [12308],
        [10548],
        [ 9638],
        [10118],
        [10081],
        [10539],
        [11260],
        [10814],
        [10626]], device='cuda:0')
[2024-07-23 21:07:05,116][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[27478],
        [36438],
        [41466],
        [34084],
        [37394],
        [38503],
        [34669],
        [40869],
        [35567],
        [36461]], device='cuda:0')
[2024-07-23 21:07:05,120][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[ 2338],
        [ 7717],
        [ 2353],
        [ 1523],
        [ 3745],
        [ 9984],
        [11521],
        [10705],
        [ 4754],
        [ 2623]], device='cuda:0')
[2024-07-23 21:07:05,123][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[ 3382],
        [ 6038],
        [14179],
        [ 9325],
        [ 9793],
        [18803],
        [13322],
        [13212],
        [ 9496],
        [13329]], device='cuda:0')
[2024-07-23 21:07:05,126][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[13779],
        [ 6046],
        [10109],
        [ 4321],
        [ 3959],
        [13555],
        [12562],
        [ 9655],
        [19954],
        [22344]], device='cuda:0')
[2024-07-23 21:07:05,129][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[26629],
        [27146],
        [28392],
        [28796],
        [18869],
        [17917],
        [23047],
        [23617],
        [25889],
        [12604]], device='cuda:0')
[2024-07-23 21:07:05,133][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[1422],
        [1675],
        [1908],
        [2152],
        [1912],
        [1865],
        [2022],
        [1866],
        [1840],
        [1956]], device='cuda:0')
[2024-07-23 21:07:05,136][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[6630],
        [6645],
        [5145],
        [2401],
        [7135],
        [5547],
        [5619],
        [7331],
        [8162],
        [8325]], device='cuda:0')
[2024-07-23 21:07:05,139][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[14820],
        [20492],
        [14565],
        [14640],
        [27753],
        [24695],
        [29233],
        [24227],
        [21929],
        [18648]], device='cuda:0')
[2024-07-23 21:07:05,141][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[3843],
        [2979],
        [3384],
        [3420],
        [3941],
        [4077],
        [3619],
        [3320],
        [2917],
        [3059]], device='cuda:0')
[2024-07-23 21:07:05,142][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[17274],
        [20300],
        [19560],
        [19691],
        [20235],
        [19363],
        [19061],
        [18375],
        [19985],
        [19370]], device='cuda:0')
[2024-07-23 21:07:05,143][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[13800],
        [20992],
        [21474],
        [27229],
        [20244],
        [20018],
        [23849],
        [20533],
        [20802],
        [25269]], device='cuda:0')
[2024-07-23 21:07:05,144][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[27818],
        [23857],
        [23959],
        [29390],
        [27024],
        [20448],
        [19602],
        [21710],
        [21261],
        [25007]], device='cuda:0')
[2024-07-23 21:07:05,144][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[39058],
        [20952],
        [37159],
        [39550],
        [37099],
        [41010],
        [28932],
        [26941],
        [37147],
        [40865]], device='cuda:0')
[2024-07-23 21:07:05,146][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[14168],
        [14168],
        [14168],
        [14168],
        [14168],
        [14168],
        [14168],
        [14168],
        [14168],
        [14168]], device='cuda:0')
[2024-07-23 21:07:05,174][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:05,177][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,180][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,184][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,188][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,191][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,197][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,200][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,202][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,202][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,203][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,203][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,203][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,204][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.9639, 0.0361], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,204][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.0073, 0.9927], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,204][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.6697, 0.3303], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,204][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.4765, 0.5235], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,205][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.9785, 0.0215], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,210][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.9966, 0.0034], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,217][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.4359, 0.5641], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,223][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.4852, 0.5148], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,231][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.0790, 0.9210], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,231][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [izen] are: tensor([0.3967, 0.6033], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,231][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.6209, 0.3791], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,231][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [izen] are: tensor([0.7439, 0.2561], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,232][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.6932, 0.0180, 0.2888], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,232][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.0023, 0.1496, 0.8481], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,232][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.4498, 0.2783, 0.2719], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,233][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.0970, 0.6832, 0.2198], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,233][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.4197, 0.1033, 0.4771], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,233][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.9950, 0.0025, 0.0025], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,233][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.2464, 0.3759, 0.3776], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,234][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.2103, 0.2183, 0.5713], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,238][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.0402, 0.4886, 0.4712], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,246][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.2101, 0.3306, 0.4593], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,252][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.3890, 0.2866, 0.3245], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,259][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.7333, 0.2610, 0.0057], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,260][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.7491, 0.0120, 0.2090, 0.0300], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,260][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([0.0008, 0.0655, 0.5193, 0.4145], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,260][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.4308, 0.2099, 0.2137, 0.1457], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,261][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.0705, 0.5263, 0.2842, 0.1190], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,261][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.7041, 0.0935, 0.1523, 0.0501], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,261][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.9736, 0.0048, 0.0059, 0.0157], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,261][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.1951, 0.2924, 0.2962, 0.2163], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,262][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.1380, 0.1415, 0.4080, 0.3125], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,262][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.0244, 0.3843, 0.4712, 0.1201], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,262][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([0.1300, 0.2594, 0.3778, 0.2328], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,264][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.2870, 0.1856, 0.2191, 0.3083], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,270][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.6845, 0.2836, 0.0050, 0.0269], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,277][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.5970, 0.0169, 0.2017, 0.0220, 0.1624], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,284][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ by] are: tensor([0.0011, 0.0658, 0.2924, 0.2957, 0.3450], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,288][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.3757, 0.1935, 0.1855, 0.1348, 0.1104], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,289][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.1068, 0.1953, 0.2278, 0.4238, 0.0463], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,289][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.3539, 0.2169, 0.2826, 0.0760, 0.0706], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,289][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.9671, 0.0042, 0.0048, 0.0121, 0.0117], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,289][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.1429, 0.2093, 0.2312, 0.1822, 0.2344], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,290][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.1168, 0.1209, 0.3059, 0.2359, 0.2205], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,290][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.0252, 0.3330, 0.3314, 0.1202, 0.1902], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,290][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ by] are: tensor([0.1147, 0.2138, 0.2850, 0.2166, 0.1699], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,291][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.2260, 0.1596, 0.1679, 0.2238, 0.2227], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,291][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ by] are: tensor([0.3192, 0.3244, 0.0270, 0.3267, 0.0026], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,291][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5090, 0.0151, 0.1607, 0.0203, 0.0717, 0.2231], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,296][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0007, 0.0402, 0.1978, 0.1993, 0.2886, 0.2734], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,303][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2971, 0.1689, 0.1639, 0.1214, 0.1084, 0.1404], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,310][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0384, 0.4315, 0.1278, 0.2671, 0.1151, 0.0201], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,317][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1596, 0.1536, 0.1987, 0.0356, 0.1559, 0.2967], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,317][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9832, 0.0017, 0.0019, 0.0052, 0.0056, 0.0024], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,318][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1243, 0.1956, 0.1887, 0.1625, 0.2025, 0.1264], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,318][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1014, 0.1036, 0.2475, 0.1862, 0.1840, 0.1773], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,318][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0174, 0.3177, 0.2786, 0.0916, 0.2216, 0.0731], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,319][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1035, 0.1794, 0.2491, 0.1597, 0.1626, 0.1457], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,319][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1725, 0.1162, 0.1288, 0.1596, 0.1647, 0.2582], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,319][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1476, 0.2132, 0.0052, 0.5134, 0.1180, 0.0026], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,319][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.6808, 0.0089, 0.1275, 0.0137, 0.0606, 0.1022, 0.0062],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,320][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([1.9990e-04, 1.7032e-02, 1.5127e-01, 1.3883e-01, 1.9239e-01, 2.2657e-01,
        2.7371e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,320][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.2906, 0.1594, 0.1578, 0.1177, 0.0804, 0.1014, 0.0927],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,325][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.0185, 0.5733, 0.0883, 0.1775, 0.1067, 0.0233, 0.0124],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,332][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.3070, 0.4292, 0.0604, 0.1118, 0.0469, 0.0400, 0.0047],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,339][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([0.9742, 0.0021, 0.0030, 0.0076, 0.0078, 0.0031, 0.0021],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,346][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.1058, 0.1481, 0.1524, 0.1320, 0.1862, 0.1212, 0.1544],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,346][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.0775, 0.0824, 0.2276, 0.1788, 0.1521, 0.1422, 0.1393],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,346][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([0.0160, 0.2569, 0.2301, 0.1008, 0.2443, 0.0950, 0.0569],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,347][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([0.0792, 0.1428, 0.2449, 0.1217, 0.1690, 0.1489, 0.0935],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,347][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.1482, 0.0909, 0.1000, 0.1294, 0.1447, 0.2177, 0.1691],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,347][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([0.2098, 0.0359, 0.0081, 0.5183, 0.0376, 0.1551, 0.0352],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,347][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.4746, 0.0170, 0.1561, 0.0243, 0.0863, 0.1434, 0.0091, 0.0892],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,348][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0005, 0.0226, 0.0948, 0.0987, 0.1661, 0.1755, 0.2102, 0.2317],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,348][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2699, 0.1411, 0.1283, 0.0958, 0.0710, 0.1009, 0.0920, 0.1009],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,348][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0298, 0.4925, 0.0781, 0.1858, 0.0366, 0.0309, 0.1363, 0.0100],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,350][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.3282, 0.0928, 0.2078, 0.0773, 0.0644, 0.1659, 0.0228, 0.0408],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,358][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.8676, 0.0112, 0.0114, 0.0253, 0.0220, 0.0120, 0.0105, 0.0398],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,364][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0776, 0.1243, 0.1307, 0.1144, 0.1364, 0.1097, 0.1779, 0.1290],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,371][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0777, 0.0786, 0.1800, 0.1435, 0.1342, 0.1350, 0.1427, 0.1082],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,374][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0138, 0.1950, 0.1836, 0.0538, 0.1929, 0.0927, 0.0580, 0.2102],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,374][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0795, 0.1417, 0.1822, 0.1186, 0.1314, 0.1374, 0.0758, 0.1334],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,374][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1110, 0.0776, 0.0860, 0.1129, 0.1311, 0.1866, 0.1411, 0.1539],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,375][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ of] are: tensor([6.4542e-03, 8.4040e-02, 1.9795e-04, 1.8258e-02, 1.3989e-03, 1.5663e-03,
        8.8804e-01, 4.1408e-05], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,375][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.5884, 0.0104, 0.1353, 0.0147, 0.0512, 0.1083, 0.0042, 0.0719, 0.0156],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,375][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([1.2269e-04, 1.1975e-02, 1.0660e-01, 9.5091e-02, 1.3003e-01, 1.5044e-01,
        1.8830e-01, 1.9385e-01, 1.2360e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,376][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.2338, 0.1287, 0.1166, 0.0914, 0.0635, 0.0881, 0.0817, 0.0913, 0.1049],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,376][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.0183, 0.3719, 0.1113, 0.1660, 0.1192, 0.0274, 0.0625, 0.0509, 0.0725],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,376][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.5378, 0.0878, 0.0413, 0.0847, 0.0599, 0.1042, 0.0302, 0.0290, 0.0252],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,377][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([0.9512, 0.0027, 0.0038, 0.0083, 0.0086, 0.0037, 0.0025, 0.0146, 0.0046],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,381][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.0676, 0.1120, 0.1161, 0.1034, 0.1313, 0.0916, 0.1536, 0.1179, 0.1064],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,389][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([0.0597, 0.0588, 0.1679, 0.1296, 0.1135, 0.1105, 0.1075, 0.1105, 0.1421],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,395][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([0.0093, 0.1443, 0.1558, 0.0473, 0.1679, 0.0542, 0.0459, 0.2837, 0.0916],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,402][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([0.0638, 0.1289, 0.1855, 0.1002, 0.1245, 0.1173, 0.0845, 0.1251, 0.0703],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,402][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.1046, 0.0631, 0.0721, 0.0960, 0.1043, 0.1651, 0.1254, 0.1406, 0.1289],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,403][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([0.1632, 0.1655, 0.0141, 0.1955, 0.0313, 0.0637, 0.2640, 0.0611, 0.0415],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,403][circuit_model.py][line:1532][INFO] ##3-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.4780, 0.0110, 0.1473, 0.0161, 0.0743, 0.1193, 0.0059, 0.0754, 0.0106,
        0.0621], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,403][circuit_model.py][line:1535][INFO] ##3-th layer ##Weight##: The head2 weight for token [ including] are: tensor([0.0003, 0.0171, 0.0958, 0.0940, 0.1133, 0.1246, 0.1510, 0.1679, 0.1223,
        0.1137], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,404][circuit_model.py][line:1538][INFO] ##3-th layer ##Weight##: The head3 weight for token [ including] are: tensor([0.2193, 0.1161, 0.1152, 0.0835, 0.0620, 0.0871, 0.0750, 0.0841, 0.0946,
        0.0631], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,404][circuit_model.py][line:1541][INFO] ##3-th layer ##Weight##: The head4 weight for token [ including] are: tensor([0.0277, 0.2379, 0.1152, 0.0713, 0.1040, 0.1014, 0.0388, 0.1846, 0.0973,
        0.0217], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,404][circuit_model.py][line:1544][INFO] ##3-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.1454, 0.0423, 0.1011, 0.0113, 0.0518, 0.1144, 0.0081, 0.0240, 0.0481,
        0.4535], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,405][circuit_model.py][line:1547][INFO] ##3-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.9518, 0.0030, 0.0034, 0.0071, 0.0075, 0.0036, 0.0025, 0.0146, 0.0045,
        0.0020], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,405][circuit_model.py][line:1550][INFO] ##3-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.0640, 0.0980, 0.1004, 0.0946, 0.1114, 0.0876, 0.1314, 0.1026, 0.1063,
        0.1037], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,410][circuit_model.py][line:1553][INFO] ##3-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.0530, 0.0550, 0.1465, 0.1108, 0.0995, 0.0992, 0.0982, 0.1038, 0.1335,
        0.1006], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,417][circuit_model.py][line:1556][INFO] ##3-th layer ##Weight##: The head9 weight for token [ including] are: tensor([0.0075, 0.1705, 0.1801, 0.0585, 0.1225, 0.0581, 0.0562, 0.1776, 0.1142,
        0.0548], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,423][circuit_model.py][line:1559][INFO] ##3-th layer ##Weight##: The head10 weight for token [ including] are: tensor([0.0583, 0.1068, 0.1645, 0.1050, 0.1063, 0.1090, 0.0884, 0.1164, 0.0651,
        0.0802], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,430][circuit_model.py][line:1562][INFO] ##3-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.0925, 0.0594, 0.0710, 0.0853, 0.0910, 0.1473, 0.1116, 0.1147, 0.1129,
        0.1143], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,431][circuit_model.py][line:1565][INFO] ##3-th layer ##Weight##: The head12 weight for token [ including] are: tensor([0.1672, 0.0699, 0.0011, 0.0736, 0.0073, 0.0325, 0.2631, 0.0095, 0.3691,
        0.0067], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,470][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:05,475][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,478][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,482][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,487][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,488][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,489][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,489][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,489][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,489][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,490][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,490][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,490][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,490][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.0947, 0.9053], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,491][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.4006, 0.5994], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,491][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.7760, 0.2240], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,491][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.2154, 0.7846], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,496][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.6115, 0.3885], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,503][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.7645, 0.2355], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,510][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([0.0095, 0.9905], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,517][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.3995, 0.6005], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,517][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.1111, 0.8889], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,517][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([0.6763, 0.3237], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,517][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.8613, 0.1387], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,518][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([0.6438, 0.3562], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,518][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([4.2417e-04, 3.6955e-02, 9.6262e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,518][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.2356, 0.3183, 0.4461], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,518][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.0277, 0.8547, 0.1177], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,519][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.0341, 0.8642, 0.1017], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,519][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0356, 0.2355, 0.7289], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,519][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.4261, 0.3516, 0.2223], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,520][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.0050, 0.4708, 0.5242], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,524][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.1344, 0.7214, 0.1442], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,531][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0507, 0.7867, 0.1627], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,538][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.1409, 0.7449, 0.1142], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,545][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.5997, 0.0622, 0.3380], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,545][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.1615, 0.7582, 0.0803], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,545][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([6.8389e-04, 2.4362e-02, 8.9514e-01, 7.9813e-02], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,545][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([0.1567, 0.2396, 0.4381, 0.1655], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,546][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([0.0398, 0.5487, 0.2862, 0.1253], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,546][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.0611, 0.5904, 0.0797, 0.2688], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,546][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.0991, 0.2869, 0.5345, 0.0795], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,547][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([0.2083, 0.2047, 0.1042, 0.4828], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,547][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([0.0183, 0.1560, 0.2110, 0.6147], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,547][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([0.0953, 0.5063, 0.2198, 0.1786], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,547][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.0208, 0.5529, 0.4128, 0.0135], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,551][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([0.1353, 0.4192, 0.1670, 0.2785], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,558][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([0.4953, 0.0342, 0.0349, 0.4356], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,565][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([0.1824, 0.3674, 0.0674, 0.3829], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,568][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([6.3060e-04, 1.9537e-02, 2.5588e-01, 3.6401e-02, 6.8755e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,573][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([0.1399, 0.2193, 0.3688, 0.1562, 0.1158], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,573][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([0.0462, 0.7008, 0.0467, 0.1188, 0.0876], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,573][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([0.0321, 0.4521, 0.0892, 0.3373, 0.0893], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,574][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.0372, 0.2861, 0.5517, 0.0647, 0.0603], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,574][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.1909, 0.2150, 0.0490, 0.3493, 0.1959], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,574][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([0.0044, 0.1240, 0.1495, 0.4372, 0.2848], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,574][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([0.0772, 0.3532, 0.1393, 0.2985, 0.1317], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,575][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.0165, 0.6063, 0.2174, 0.0845, 0.0753], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,575][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([0.1629, 0.3634, 0.0322, 0.3799, 0.0615], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,575][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.1932, 0.0739, 0.0885, 0.2396, 0.4048], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,576][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([0.2638, 0.5096, 0.0171, 0.1617, 0.0477], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,577][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.4332e-04, 1.1151e-02, 1.5299e-01, 1.7763e-02, 2.3158e-01, 5.8638e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,585][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1092, 0.1763, 0.2464, 0.1381, 0.1267, 0.2032], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,591][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0510, 0.7458, 0.0118, 0.0248, 0.1205, 0.0462], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,598][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0101, 0.5854, 0.0504, 0.2288, 0.0429, 0.0824], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,600][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0502, 0.1898, 0.3357, 0.0365, 0.1353, 0.2525], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,601][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1755, 0.1118, 0.0243, 0.2393, 0.1711, 0.2780], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,601][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0026, 0.1236, 0.1386, 0.3189, 0.2870, 0.1292], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,601][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0604, 0.3156, 0.1428, 0.1870, 0.2044, 0.0897], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,602][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0049, 0.6516, 0.1457, 0.0371, 0.1588, 0.0018], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,602][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0497, 0.6292, 0.0396, 0.1400, 0.0677, 0.0738], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,602][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2503, 0.0820, 0.0427, 0.2245, 0.1210, 0.2795], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,603][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2133, 0.5086, 0.0130, 0.1533, 0.0837, 0.0281], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,603][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([0.0008, 0.0217, 0.3853, 0.0367, 0.1206, 0.4034, 0.0315],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,603][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([0.0806, 0.1366, 0.2537, 0.1120, 0.1202, 0.2050, 0.0919],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,605][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([0.0196, 0.3611, 0.0204, 0.0309, 0.2108, 0.3026, 0.0546],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,613][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([0.0405, 0.4017, 0.0542, 0.1812, 0.0599, 0.0892, 0.1733],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,619][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([0.0159, 0.5713, 0.1830, 0.0970, 0.0654, 0.0636, 0.0040],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,626][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([0.0452, 0.0452, 0.0187, 0.1928, 0.1202, 0.2171, 0.3608],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,628][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([0.0058, 0.0535, 0.0719, 0.2693, 0.1542, 0.0867, 0.3586],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,629][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([0.0663, 0.2720, 0.1129, 0.1565, 0.2226, 0.1294, 0.0403],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,629][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([0.0223, 0.3810, 0.1016, 0.0914, 0.3914, 0.0077, 0.0045],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,629][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([0.1325, 0.3363, 0.0408, 0.0646, 0.0773, 0.1253, 0.2233],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,630][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([0.2318, 0.0369, 0.0148, 0.4205, 0.0996, 0.0374, 0.1590],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,630][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([0.1520, 0.1094, 0.0214, 0.1987, 0.1339, 0.0998, 0.2848],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,630][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([4.6547e-05, 2.0541e-03, 1.5970e-02, 4.1493e-03, 3.3048e-02, 4.9526e-02,
        4.9657e-03, 8.9024e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,631][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0885, 0.1456, 0.2290, 0.1010, 0.0911, 0.1755, 0.0876, 0.0817],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,631][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0546, 0.0327, 0.0029, 0.0105, 0.2132, 0.4009, 0.2204, 0.0648],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,631][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0133, 0.4038, 0.0308, 0.1495, 0.0330, 0.0714, 0.2232, 0.0750],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,636][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0284, 0.0890, 0.4395, 0.0501, 0.0902, 0.2235, 0.0173, 0.0620],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,643][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0227, 0.0179, 0.0136, 0.0918, 0.0715, 0.0809, 0.5999, 0.1018],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,649][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0005, 0.0718, 0.0671, 0.2015, 0.1410, 0.0804, 0.2786, 0.1591],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,656][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0355, 0.2754, 0.1031, 0.1524, 0.1350, 0.0963, 0.0728, 0.1294],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,656][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0042, 0.3525, 0.2342, 0.0190, 0.3042, 0.0161, 0.0217, 0.0481],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,657][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0364, 0.1426, 0.0093, 0.0370, 0.0388, 0.1120, 0.5486, 0.0753],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,657][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0667, 0.0087, 0.0206, 0.2798, 0.0835, 0.0509, 0.0343, 0.4556],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,657][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0304, 0.0821, 0.0019, 0.0171, 0.0497, 0.0305, 0.7641, 0.0243],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,658][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([7.2611e-05, 1.2125e-03, 7.7065e-02, 3.3944e-03, 1.9235e-02, 7.0192e-02,
        1.4918e-03, 8.2146e-01, 5.8768e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,658][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([0.0679, 0.1130, 0.2009, 0.0985, 0.0962, 0.1657, 0.0925, 0.0931, 0.0724],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,658][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([0.0163, 0.1902, 0.0075, 0.0119, 0.0784, 0.2048, 0.1260, 0.2684, 0.0965],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,659][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([0.0186, 0.3304, 0.0450, 0.1332, 0.0427, 0.0623, 0.1544, 0.0965, 0.1170],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,659][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.0520, 0.2155, 0.1746, 0.1425, 0.1162, 0.1629, 0.0513, 0.0594, 0.0256],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,664][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([0.0100, 0.0190, 0.0118, 0.0678, 0.0668, 0.0958, 0.5119, 0.0799, 0.1370],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,671][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([0.0036, 0.0485, 0.0608, 0.1867, 0.1174, 0.0696, 0.2405, 0.0859, 0.1869],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,677][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([0.0399, 0.2129, 0.0804, 0.1040, 0.1262, 0.0786, 0.0497, 0.1947, 0.1136],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,684][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([0.0105, 0.2399, 0.1209, 0.0177, 0.3590, 0.0027, 0.0132, 0.2218, 0.0143],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,684][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([0.0795, 0.2905, 0.0271, 0.0212, 0.0330, 0.1062, 0.3272, 0.0728, 0.0425],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,685][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([0.1743, 0.0183, 0.0136, 0.3045, 0.0276, 0.0153, 0.0859, 0.0600, 0.3005],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,685][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([0.0493, 0.1227, 0.0065, 0.0611, 0.0746, 0.0423, 0.4759, 0.0881, 0.0794],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:05,685][circuit_model.py][line:1570][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([2.9769e-05, 1.1122e-03, 1.9668e-02, 2.0501e-03, 2.2451e-02, 4.1780e-02,
        1.8429e-03, 8.8862e-01, 2.2153e-03, 2.0231e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,686][circuit_model.py][line:1573][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([0.0584, 0.1036, 0.1926, 0.0817, 0.0801, 0.1538, 0.0765, 0.0733, 0.0656,
        0.1144], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,686][circuit_model.py][line:1576][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([0.0288, 0.0550, 0.0013, 0.0027, 0.0823, 0.2164, 0.2040, 0.1308, 0.2439,
        0.0348], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,686][circuit_model.py][line:1579][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([0.0202, 0.2886, 0.0364, 0.1173, 0.0372, 0.0889, 0.1406, 0.0910, 0.1228,
        0.0569], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,687][circuit_model.py][line:1582][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([0.0306, 0.1220, 0.3314, 0.0184, 0.0854, 0.1457, 0.0120, 0.0434, 0.0339,
        0.1770], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,687][circuit_model.py][line:1585][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([0.0472, 0.0458, 0.0152, 0.0438, 0.0437, 0.0841, 0.3203, 0.2083, 0.1534,
        0.0380], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,691][circuit_model.py][line:1588][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([0.0007, 0.0475, 0.0565, 0.1435, 0.1031, 0.0547, 0.2167, 0.0999, 0.1509,
        0.1265], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,699][circuit_model.py][line:1591][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([0.0331, 0.1385, 0.0753, 0.0980, 0.0915, 0.0796, 0.0632, 0.1942, 0.1866,
        0.0401], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,705][circuit_model.py][line:1594][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([0.0035, 0.4157, 0.1858, 0.0455, 0.1162, 0.0071, 0.0561, 0.0676, 0.0862,
        0.0164], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,712][circuit_model.py][line:1597][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([0.0551, 0.1948, 0.0088, 0.0315, 0.0269, 0.0885, 0.4496, 0.0497, 0.0881,
        0.0070], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,712][circuit_model.py][line:1600][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([0.1197, 0.0120, 0.0388, 0.1481, 0.0880, 0.1170, 0.0743, 0.0968, 0.1234,
        0.1820], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,712][circuit_model.py][line:1603][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([0.0569, 0.0663, 0.0017, 0.0133, 0.0241, 0.0350, 0.6254, 0.0244, 0.1384,
        0.0145], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:05,713][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:05,714][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[7721],
        [ 138],
        [ 812],
        [1266],
        [ 139],
        [ 394],
        [ 918],
        [2769],
        [1183],
        [1075]], device='cuda:0')
[2024-07-23 21:07:05,715][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[8321],
        [ 160],
        [ 215],
        [ 644],
        [  25],
        [  51],
        [ 163],
        [ 789],
        [ 579],
        [ 369]], device='cuda:0')
[2024-07-23 21:07:05,717][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[3571],
        [3801],
        [3686],
        [3821],
        [3343],
        [3799],
        [3627],
        [3387],
        [3472],
        [3495]], device='cuda:0')
[2024-07-23 21:07:05,720][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[ 7808],
        [13546],
        [ 4158],
        [ 5726],
        [ 3466],
        [ 2416],
        [ 3737],
        [ 2765],
        [ 3321],
        [ 3630]], device='cuda:0')
[2024-07-23 21:07:05,723][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[1361],
        [1782],
        [1715],
        [1465],
        [1470],
        [1477],
        [1489],
        [1502],
        [1456],
        [1529]], device='cuda:0')
[2024-07-23 21:07:05,726][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[19057],
        [31991],
        [39711],
        [38890],
        [31466],
        [34684],
        [36057],
        [32174],
        [32573],
        [31663]], device='cuda:0')
[2024-07-23 21:07:05,729][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 209],
        [ 208],
        [ 822],
        [ 340],
        [1235],
        [2058],
        [2519],
        [1226],
        [ 674],
        [2212]], device='cuda:0')
[2024-07-23 21:07:05,732][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[43194],
        [43295],
        [43340],
        [43789],
        [43844],
        [43523],
        [43713],
        [45767],
        [44422],
        [44432]], device='cuda:0')
[2024-07-23 21:07:05,735][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[7321],
        [6855],
        [4993],
        [5111],
        [3998],
        [3920],
        [3649],
        [3449],
        [3029],
        [3267]], device='cuda:0')
[2024-07-23 21:07:05,739][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[3635],
        [3943],
        [6424],
        [6686],
        [6721],
        [6825],
        [7203],
        [6941],
        [7319],
        [7289]], device='cuda:0')
[2024-07-23 21:07:05,742][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[5119],
        [3855],
        [5778],
        [6806],
        [5470],
        [5238],
        [5110],
        [5766],
        [6293],
        [6244]], device='cuda:0')
[2024-07-23 21:07:05,745][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[43631],
        [38680],
        [41111],
        [40344],
        [43014],
        [43851],
        [44476],
        [43845],
        [44149],
        [43612]], device='cuda:0')
[2024-07-23 21:07:05,747][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[44103],
        [40558],
        [35787],
        [34303],
        [32459],
        [32760],
        [31169],
        [29789],
        [29744],
        [30159]], device='cuda:0')
[2024-07-23 21:07:05,748][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[38913],
        [41541],
        [41729],
        [40780],
        [24705],
        [19887],
        [16433],
        [42851],
        [40743],
        [47365]], device='cuda:0')
[2024-07-23 21:07:05,748][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 4168],
        [39085],
        [41049],
        [44388],
        [48761],
        [49537],
        [43987],
        [49385],
        [47985],
        [45578]], device='cuda:0')
[2024-07-23 21:07:05,749][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[28189],
        [27994],
        [29561],
        [29288],
        [25185],
        [25815],
        [27157],
        [27061],
        [27280],
        [27023]], device='cuda:0')
[2024-07-23 21:07:05,750][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[13190],
        [ 9357],
        [ 9774],
        [ 8954],
        [ 8575],
        [ 9324],
        [ 9620],
        [ 9993],
        [ 9502],
        [ 9128]], device='cuda:0')
[2024-07-23 21:07:05,752][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[20531],
        [22321],
        [24331],
        [24744],
        [23779],
        [23687],
        [22156],
        [17528],
        [22174],
        [20790]], device='cuda:0')
[2024-07-23 21:07:05,755][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[14837],
        [18365],
        [16284],
        [12371],
        [10783],
        [11731],
        [10908],
        [10747],
        [10478],
        [10291]], device='cuda:0')
[2024-07-23 21:07:05,758][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[6399],
        [7506],
        [5371],
        [5621],
        [5534],
        [4932],
        [7778],
        [5345],
        [5518],
        [5290]], device='cuda:0')
[2024-07-23 21:07:05,761][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[1418],
        [ 489],
        [ 426],
        [1159],
        [ 760],
        [ 957],
        [1796],
        [3345],
        [3599],
        [5313]], device='cuda:0')
[2024-07-23 21:07:05,764][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[15794],
        [18381],
        [21580],
        [20311],
        [25758],
        [27205],
        [21321],
        [24643],
        [22458],
        [23830]], device='cuda:0')
[2024-07-23 21:07:05,767][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[1358],
        [1586],
        [1472],
        [1320],
        [1287],
        [1267],
        [1302],
        [1308],
        [1322],
        [1396]], device='cuda:0')
[2024-07-23 21:07:05,770][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[17166],
        [ 8508],
        [10769],
        [15471],
        [12711],
        [12655],
        [17590],
        [20715],
        [24817],
        [16670]], device='cuda:0')
[2024-07-23 21:07:05,773][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[ 8527],
        [17752],
        [ 8211],
        [ 8783],
        [ 6305],
        [ 7238],
        [ 8516],
        [ 6890],
        [ 8324],
        [ 6912]], device='cuda:0')
[2024-07-23 21:07:05,776][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[35975],
        [32571],
        [20178],
        [13104],
        [13692],
        [15778],
        [11393],
        [14225],
        [17139],
        [ 8427]], device='cuda:0')
[2024-07-23 21:07:05,778][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 6145],
        [15554],
        [15453],
        [30511],
        [23777],
        [22345],
        [13768],
        [ 6292],
        [ 7817],
        [ 6202]], device='cuda:0')
[2024-07-23 21:07:05,779][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[36817],
        [29723],
        [35619],
        [33174],
        [35683],
        [35333],
        [34913],
        [37141],
        [35075],
        [37182]], device='cuda:0')
[2024-07-23 21:07:05,780][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[36954],
        [27982],
        [20931],
        [18246],
        [16355],
        [12129],
        [23664],
        [13448],
        [15402],
        [18475]], device='cuda:0')
[2024-07-23 21:07:05,780][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[29336],
        [29336],
        [29336],
        [29336],
        [29336],
        [29336],
        [29336],
        [29336],
        [29336],
        [29336]], device='cuda:0')
[2024-07-23 21:07:05,818][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:05,823][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,827][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,830][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,834][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,835][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,836][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,836][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,836][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,836][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,837][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,837][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,837][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:05,837][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.0319, 0.9681], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,838][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.2398, 0.7602], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,838][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.4453, 0.5547], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,838][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.0436, 0.9564], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,843][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.4630, 0.5370], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,850][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.3457, 0.6543], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,856][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.1605, 0.8395], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,862][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.0460, 0.9540], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,863][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.8624, 0.1376], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,863][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [izen] are: tensor([0.1873, 0.8127], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,863][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.4081, 0.5919], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,863][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [izen] are: tensor([9.9930e-01, 6.9696e-04], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:05,864][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.0311, 0.4732, 0.4957], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,864][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.1232, 0.4403, 0.4365], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,864][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.2933, 0.3630, 0.3436], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,865][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.0412, 0.7149, 0.2438], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,865][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.3072, 0.3577, 0.3352], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,865][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.1960, 0.3991, 0.4049], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,869][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.0658, 0.5372, 0.3970], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,875][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.0072, 0.9890, 0.0039], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,882][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.6541, 0.1609, 0.1850], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,888][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.0396, 0.7120, 0.2485], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,890][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.2410, 0.3511, 0.4078], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,890][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.7838, 0.0183, 0.1979], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:05,890][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.0125, 0.3953, 0.3578, 0.2344], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,890][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([0.0756, 0.3132, 0.3346, 0.2766], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,891][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.2232, 0.2834, 0.2664, 0.2270], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,891][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.0265, 0.5215, 0.1986, 0.2534], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,891][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.2368, 0.2834, 0.2639, 0.2160], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,892][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.1446, 0.2924, 0.3979, 0.1652], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,892][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.0562, 0.4594, 0.3948, 0.0895], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,892][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.0010, 0.9679, 0.0274, 0.0037], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,892][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.5664, 0.1325, 0.1660, 0.1352], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,897][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([0.0306, 0.3684, 0.4134, 0.1876], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,904][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.1695, 0.2470, 0.2834, 0.3001], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,910][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.0816, 0.0018, 0.0368, 0.8799], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:05,916][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.0124, 0.2618, 0.3051, 0.2069, 0.2138], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,917][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ by] are: tensor([0.0667, 0.2509, 0.2563, 0.2217, 0.2044], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,917][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.1807, 0.2268, 0.2148, 0.1840, 0.1937], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,917][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.0213, 0.4491, 0.1549, 0.1976, 0.1771], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,918][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.1945, 0.2318, 0.2158, 0.1760, 0.1819], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,918][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.1247, 0.2351, 0.2644, 0.1090, 0.2668], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,918][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.0486, 0.3653, 0.3145, 0.1029, 0.1688], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,919][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.1162, 0.8103, 0.0093, 0.0019, 0.0623], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,919][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.4363, 0.1003, 0.1335, 0.1208, 0.2092], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,919][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ by] are: tensor([0.0573, 0.2202, 0.3879, 0.2222, 0.1124], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,919][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.1325, 0.1934, 0.2211, 0.2357, 0.2173], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,921][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ by] are: tensor([5.1238e-04, 3.1664e-04, 6.1663e-03, 4.9787e-01, 4.9513e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:05,923][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0093, 0.2263, 0.2258, 0.1769, 0.1986, 0.1630], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,923][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0552, 0.2001, 0.2057, 0.1853, 0.1784, 0.1752], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,924][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1514, 0.1859, 0.1756, 0.1532, 0.1602, 0.1736], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,924][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0267, 0.3614, 0.1286, 0.1547, 0.1843, 0.1443], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,930][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1613, 0.1886, 0.1771, 0.1472, 0.1514, 0.1744], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,937][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0818, 0.1790, 0.2172, 0.1108, 0.2521, 0.1591], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,943][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0353, 0.2994, 0.2737, 0.0862, 0.2072, 0.0983], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,945][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0186, 0.9262, 0.0080, 0.0016, 0.0293, 0.0162], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,945][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4662, 0.0749, 0.0952, 0.0889, 0.1552, 0.1195], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,945][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0438, 0.3163, 0.2042, 0.1593, 0.1731, 0.1033], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,946][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1107, 0.1565, 0.1750, 0.1854, 0.1721, 0.2003], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,946][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.8029e-04, 2.9555e-04, 4.1146e-03, 1.0945e-01, 6.4080e-01, 2.4516e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:05,946][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.0102, 0.1970, 0.1939, 0.1215, 0.2093, 0.1289, 0.1392],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,946][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([0.0433, 0.1692, 0.1828, 0.1529, 0.1529, 0.1587, 0.1401],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,947][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.1260, 0.1594, 0.1517, 0.1295, 0.1367, 0.1502, 0.1466],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,947][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.0205, 0.3311, 0.1129, 0.1442, 0.1468, 0.1465, 0.0980],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,947][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.1386, 0.1646, 0.1541, 0.1265, 0.1300, 0.1498, 0.1365],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,951][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([0.0665, 0.1576, 0.2124, 0.1024, 0.2590, 0.1394, 0.0627],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,957][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.0262, 0.2330, 0.2701, 0.0823, 0.1960, 0.1218, 0.0706],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,964][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.0018, 0.9326, 0.0221, 0.0034, 0.0139, 0.0120, 0.0142],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,970][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([0.4901, 0.0602, 0.0784, 0.0677, 0.1252, 0.0975, 0.0809],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,972][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([0.0247, 0.1728, 0.2630, 0.1482, 0.1047, 0.1746, 0.1120],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,972][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.0881, 0.1293, 0.1467, 0.1603, 0.1481, 0.1688, 0.1586],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,972][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([1.3283e-03, 7.0699e-05, 1.2674e-03, 1.4209e-01, 6.0213e-02, 4.2620e-01,
        3.6884e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:05,973][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0055, 0.1528, 0.1637, 0.1142, 0.1338, 0.1377, 0.1389, 0.1534],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,973][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0275, 0.1578, 0.1597, 0.1403, 0.1331, 0.1406, 0.1248, 0.1162],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,973][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1101, 0.1404, 0.1332, 0.1133, 0.1192, 0.1314, 0.1277, 0.1247],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,974][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0083, 0.2832, 0.1122, 0.1230, 0.1234, 0.1296, 0.1016, 0.1186],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,974][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1231, 0.1462, 0.1364, 0.1120, 0.1150, 0.1325, 0.1201, 0.1147],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,974][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0947, 0.1615, 0.1773, 0.0719, 0.1864, 0.1610, 0.0531, 0.0941],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,975][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0226, 0.2258, 0.2277, 0.0615, 0.1623, 0.1046, 0.0733, 0.1223],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,979][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.2054, 0.5995, 0.0138, 0.0012, 0.0690, 0.0246, 0.0035, 0.0830],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,986][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.2853, 0.0754, 0.0950, 0.0898, 0.1323, 0.1002, 0.0903, 0.1318],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,992][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0244, 0.2186, 0.1816, 0.1009, 0.1118, 0.1693, 0.0611, 0.1323],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,999][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0772, 0.1138, 0.1289, 0.1393, 0.1270, 0.1465, 0.1365, 0.1309],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,999][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ of] are: tensor([5.2797e-01, 1.8817e-07, 6.9346e-06, 2.1862e-03, 1.1637e-02, 2.2922e-01,
        2.2861e-01, 3.6662e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:05,999][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.0067, 0.1460, 0.1381, 0.0995, 0.1358, 0.1110, 0.1119, 0.1648, 0.0862],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,000][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([0.0277, 0.1342, 0.1408, 0.1198, 0.1153, 0.1262, 0.1077, 0.1127, 0.1156],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,000][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.0968, 0.1253, 0.1183, 0.1001, 0.1049, 0.1157, 0.1135, 0.1110, 0.1144],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,000][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.0070, 0.2487, 0.0966, 0.1124, 0.1161, 0.1162, 0.0890, 0.1156, 0.0985],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,001][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.1103, 0.1307, 0.1220, 0.0995, 0.1025, 0.1194, 0.1078, 0.1029, 0.1050],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,001][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([0.0606, 0.1504, 0.1727, 0.0791, 0.2062, 0.1105, 0.0551, 0.1087, 0.0567],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,001][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.0170, 0.1956, 0.2102, 0.0575, 0.1615, 0.0893, 0.0592, 0.1425, 0.0671],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,002][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([7.8646e-04, 9.3709e-01, 2.7911e-02, 2.3728e-03, 1.1163e-02, 1.0161e-02,
        9.0252e-03, 7.5880e-04, 7.3020e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,005][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([0.3714, 0.0560, 0.0704, 0.0574, 0.1047, 0.0810, 0.0694, 0.1117, 0.0780],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,011][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([0.0099, 0.0803, 0.1270, 0.0548, 0.0989, 0.0858, 0.0735, 0.4331, 0.0368],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,018][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.0674, 0.0978, 0.1123, 0.1236, 0.1131, 0.1288, 0.1223, 0.1178, 0.1169],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,022][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([4.5447e-04, 2.3497e-05, 2.2971e-04, 2.5510e-02, 2.5894e-02, 1.4690e-01,
        2.2598e-01, 9.5065e-04, 5.7406e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,026][circuit_model.py][line:1532][INFO] ##4-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.0059, 0.1236, 0.1368, 0.0916, 0.1085, 0.0939, 0.1164, 0.1465, 0.0794,
        0.0974], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,026][circuit_model.py][line:1535][INFO] ##4-th layer ##Weight##: The head2 weight for token [ including] are: tensor([0.0273, 0.1146, 0.1259, 0.1054, 0.1059, 0.1122, 0.0998, 0.1013, 0.1068,
        0.1009], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,027][circuit_model.py][line:1538][INFO] ##4-th layer ##Weight##: The head3 weight for token [ including] are: tensor([0.0870, 0.1133, 0.1075, 0.0918, 0.0948, 0.1044, 0.1023, 0.1007, 0.1033,
        0.0948], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,027][circuit_model.py][line:1541][INFO] ##4-th layer ##Weight##: The head4 weight for token [ including] are: tensor([0.0097, 0.2182, 0.0888, 0.1042, 0.1091, 0.1104, 0.0810, 0.1144, 0.1004,
        0.0637], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,027][circuit_model.py][line:1544][INFO] ##4-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.0998, 0.1187, 0.1108, 0.0899, 0.0926, 0.1082, 0.0978, 0.0931, 0.0950,
        0.0941], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,028][circuit_model.py][line:1547][INFO] ##4-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.0559, 0.1418, 0.1701, 0.0757, 0.1898, 0.1244, 0.0558, 0.1068, 0.0559,
        0.0239], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,028][circuit_model.py][line:1550][INFO] ##4-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.0177, 0.1779, 0.1768, 0.0546, 0.1494, 0.0682, 0.0726, 0.1364, 0.1052,
        0.0412], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,028][circuit_model.py][line:1553][INFO] ##4-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.0110, 0.8485, 0.0196, 0.0054, 0.0365, 0.0246, 0.0163, 0.0127, 0.0026,
        0.0228], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,029][circuit_model.py][line:1556][INFO] ##4-th layer ##Weight##: The head9 weight for token [ including] are: tensor([0.4122, 0.0421, 0.0548, 0.0487, 0.0936, 0.0697, 0.0581, 0.0996, 0.0630,
        0.0582], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,031][circuit_model.py][line:1559][INFO] ##4-th layer ##Weight##: The head10 weight for token [ including] are: tensor([0.0162, 0.0789, 0.1064, 0.0989, 0.0471, 0.1669, 0.0633, 0.3598, 0.0509,
        0.0117], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,038][circuit_model.py][line:1562][INFO] ##4-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.0613, 0.0897, 0.1031, 0.1110, 0.1013, 0.1182, 0.1083, 0.1054, 0.1046,
        0.0971], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,041][circuit_model.py][line:1565][INFO] ##4-th layer ##Weight##: The head12 weight for token [ including] are: tensor([3.0379e-06, 2.6394e-05, 3.0431e-04, 9.2986e-03, 5.4620e-02, 1.4007e-01,
        2.1465e-01, 2.5396e-02, 4.7958e-01, 7.6053e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,080][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:06,084][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,084][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,084][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,085][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,085][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,085][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,086][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,086][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,086][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,086][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,088][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,091][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,094][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.3707, 0.6293], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,100][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.0702, 0.9298], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,107][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.3624, 0.6376], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,112][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.0588, 0.9412], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,112][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.7210, 0.2790], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,113][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.4325, 0.5675], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,113][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([0.7361, 0.2639], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,113][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.0018, 0.9982], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,113][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.9045, 0.0955], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,114][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([0.7754, 0.2246], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,114][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.3663, 0.6337], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,114][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([3.9511e-10, 1.0000e+00], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,114][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.2234, 0.3868, 0.3898], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,118][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.0471, 0.5460, 0.4069], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,124][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.2249, 0.6244, 0.1507], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,129][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([1.9239e-04, 9.9973e-01, 8.1264e-05], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,135][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.5921, 0.2253, 0.1826], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,139][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.3012, 0.3901, 0.3087], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,139][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.5020, 0.3218, 0.1762], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,139][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([3.1088e-04, 5.6585e-01, 4.3383e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,140][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.8877, 0.0579, 0.0544], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,140][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.3964, 0.4549, 0.1487], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,140][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.1616, 0.5591, 0.2794], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,140][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([5.0168e-12, 1.0000e+00, 3.1404e-06], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,141][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([0.0734, 0.3487, 0.3240, 0.2539], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,141][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([0.0219, 0.3747, 0.3350, 0.2684], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,141][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([0.1126, 0.3704, 0.4190, 0.0979], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,142][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([3.8630e-03, 9.6788e-01, 6.5535e-04, 2.7603e-02], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,145][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.5617, 0.1932, 0.1560, 0.0891], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,151][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([0.2453, 0.2975, 0.2312, 0.2259], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,159][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([0.4102, 0.2456, 0.1258, 0.2183], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,162][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([1.8295e-04, 4.2019e-01, 4.1132e-01, 1.6830e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,166][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.7942, 0.0611, 0.0587, 0.0861], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,166][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([0.1487, 0.4652, 0.2026, 0.1836], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,167][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([0.0743, 0.3186, 0.2039, 0.4031], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,167][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([9.0706e-12, 9.8716e-01, 1.2530e-02, 3.0877e-04], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,167][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([0.0724, 0.2388, 0.2416, 0.2102, 0.2370], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,168][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([0.0301, 0.3097, 0.2562, 0.2208, 0.1833], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,168][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([0.2215, 0.4207, 0.1715, 0.1136, 0.0727], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,168][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([2.8826e-03, 6.9881e-01, 6.7454e-04, 2.9631e-01, 1.3263e-03],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,168][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.4965, 0.1744, 0.1430, 0.0842, 0.1018], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,169][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.2012, 0.2414, 0.1880, 0.1849, 0.1847], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,169][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([0.3229, 0.1989, 0.1058, 0.1844, 0.1880], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,170][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([2.8729e-04, 3.2351e-01, 2.1635e-01, 8.3407e-02, 3.7644e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,176][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.7348, 0.0550, 0.0533, 0.0726, 0.0843], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,183][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([0.0487, 0.4041, 0.1218, 0.3296, 0.0958], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,189][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.0605, 0.4102, 0.0989, 0.3199, 0.1104], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,193][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([4.1678e-14, 9.9926e-01, 1.0320e-05, 7.0699e-04, 1.7878e-05],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,194][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0907, 0.1914, 0.1782, 0.1694, 0.2151, 0.1552], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,194][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0257, 0.2408, 0.2031, 0.1878, 0.1716, 0.1710], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,194][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1711, 0.3826, 0.1612, 0.0726, 0.0878, 0.1247], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,195][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.8155e-03, 9.3900e-01, 3.1097e-04, 3.5433e-02, 2.2066e-02, 3.7513e-04],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,195][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4170, 0.1595, 0.1318, 0.0804, 0.0945, 0.1169], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,195][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1566, 0.2013, 0.1580, 0.1613, 0.1581, 0.1648], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,196][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2486, 0.1807, 0.0917, 0.1745, 0.1729, 0.1316], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,196][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0003, 0.2237, 0.1574, 0.0648, 0.2711, 0.2827], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,196][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7166, 0.0481, 0.0455, 0.0621, 0.0707, 0.0570], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,198][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0749, 0.3674, 0.1107, 0.2183, 0.1487, 0.0800], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,205][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0535, 0.3219, 0.1153, 0.2932, 0.1157, 0.1004], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,209][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.1175e-11, 9.9969e-01, 5.3460e-06, 3.1433e-05, 2.4866e-04, 2.0116e-05],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,216][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([0.0685, 0.1644, 0.1567, 0.1245, 0.2098, 0.1424, 0.1337],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,221][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([0.0144, 0.2063, 0.1910, 0.1484, 0.1416, 0.1665, 0.1317],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,221][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([0.0863, 0.4258, 0.1897, 0.1342, 0.0529, 0.0949, 0.0161],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,221][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([0.0109, 0.7102, 0.0007, 0.0582, 0.0164, 0.0117, 0.1919],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,222][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([0.4057, 0.1398, 0.1144, 0.0671, 0.0804, 0.0998, 0.0929],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,222][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([0.1387, 0.1738, 0.1362, 0.1341, 0.1335, 0.1405, 0.1431],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,222][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([0.2593, 0.1452, 0.0687, 0.1363, 0.1284, 0.1114, 0.1507],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,223][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([1.1856e-04, 1.8707e-01, 1.7733e-01, 6.6811e-02, 2.2470e-01, 2.3746e-01,
        1.0651e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,223][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([0.6115, 0.0536, 0.0479, 0.0690, 0.0746, 0.0675, 0.0759],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,223][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([0.0638, 0.2822, 0.1156, 0.1155, 0.1341, 0.0982, 0.1906],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,224][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([0.0541, 0.2798, 0.1053, 0.2776, 0.0797, 0.1532, 0.0504],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,225][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([2.3857e-14, 9.9998e-01, 6.0392e-06, 1.3333e-06, 4.6218e-07, 1.7020e-05,
        1.0395e-09], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,231][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0402, 0.1602, 0.1386, 0.1229, 0.1514, 0.1235, 0.1385, 0.1246],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,238][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0122, 0.1983, 0.1557, 0.1387, 0.1204, 0.1463, 0.1191, 0.1092],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,244][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1061, 0.3137, 0.1487, 0.0796, 0.0729, 0.0906, 0.0910, 0.0974],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,248][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([2.0707e-03, 7.5351e-01, 2.5072e-04, 4.6345e-02, 1.7832e-03, 6.7581e-04,
        1.9475e-01, 6.1142e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,248][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.3674, 0.1296, 0.1057, 0.0624, 0.0746, 0.0916, 0.0854, 0.0832],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,249][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.1294, 0.1558, 0.1189, 0.1179, 0.1157, 0.1237, 0.1274, 0.1112],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,249][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1592, 0.1300, 0.0681, 0.1334, 0.1162, 0.0981, 0.1618, 0.1333],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,249][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([1.2056e-04, 5.1668e-02, 2.4763e-02, 9.0346e-03, 6.8074e-02, 7.2630e-02,
        2.0017e-02, 7.5369e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,250][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.6093, 0.0445, 0.0404, 0.0579, 0.0617, 0.0493, 0.0651, 0.0717],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,250][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0684, 0.1792, 0.0694, 0.0916, 0.1273, 0.0891, 0.2918, 0.0833],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,250][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0992, 0.2486, 0.0488, 0.2232, 0.1182, 0.0775, 0.0809, 0.1036],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,251][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([1.2481e-10, 9.5921e-01, 3.1945e-08, 4.0786e-06, 2.4947e-05, 2.1894e-03,
        3.7451e-02, 1.1193e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,251][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([0.0367, 0.1354, 0.1196, 0.0996, 0.1451, 0.1158, 0.1160, 0.1406, 0.0912],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,255][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([0.0078, 0.1645, 0.1427, 0.1204, 0.1025, 0.1302, 0.0995, 0.1195, 0.1127],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,261][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([0.0694, 0.2505, 0.2264, 0.1026, 0.0337, 0.0843, 0.0669, 0.1131, 0.0530],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,265][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([4.4567e-03, 3.5952e-01, 2.0847e-04, 2.3072e-02, 2.9454e-03, 9.8193e-04,
        2.6582e-01, 2.0097e-03, 3.4098e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,271][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.3470, 0.1195, 0.0965, 0.0563, 0.0672, 0.0849, 0.0783, 0.0760, 0.0744],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,275][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([0.1169, 0.1424, 0.1090, 0.1064, 0.1054, 0.1130, 0.1138, 0.1008, 0.0922],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,276][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([0.1730, 0.1158, 0.0562, 0.1043, 0.1046, 0.0845, 0.1213, 0.1177, 0.1227],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,276][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([3.2724e-05, 8.8682e-02, 7.2628e-02, 2.3447e-02, 9.4642e-02, 1.0396e-01,
        4.7237e-02, 5.2177e-01, 4.7603e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,276][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([0.5046, 0.0498, 0.0451, 0.0655, 0.0666, 0.0599, 0.0706, 0.0747, 0.0634],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,277][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([0.0460, 0.1098, 0.0553, 0.0708, 0.0925, 0.0647, 0.3598, 0.0743, 0.1268],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,277][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([0.1349, 0.2679, 0.0653, 0.1003, 0.1039, 0.1126, 0.0522, 0.0465, 0.1164],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,277][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([4.6909e-15, 9.9993e-01, 7.2865e-08, 6.5195e-08, 3.1106e-06, 4.0558e-05,
        2.7623e-06, 1.6329e-05, 2.6376e-06], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,278][circuit_model.py][line:1570][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([0.0403, 0.1153, 0.1158, 0.0882, 0.1242, 0.1045, 0.1098, 0.1292, 0.0788,
        0.0940], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,278][circuit_model.py][line:1573][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([0.0097, 0.1320, 0.1281, 0.0968, 0.0938, 0.1191, 0.0976, 0.1090, 0.1086,
        0.1054], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,278][circuit_model.py][line:1576][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([0.0621, 0.2438, 0.1448, 0.0380, 0.0390, 0.1107, 0.0693, 0.0763, 0.0465,
        0.1697], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,280][circuit_model.py][line:1579][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([2.6340e-03, 1.4968e-01, 1.8292e-04, 2.2728e-02, 2.4848e-03, 1.9912e-03,
        1.1284e-01, 1.7691e-03, 7.0493e-01, 7.5550e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,287][circuit_model.py][line:1582][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([0.3385, 0.1107, 0.0892, 0.0503, 0.0617, 0.0791, 0.0725, 0.0706, 0.0681,
        0.0594], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,293][circuit_model.py][line:1585][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([0.1058, 0.1274, 0.0981, 0.0960, 0.0957, 0.1025, 0.1035, 0.0922, 0.0842,
        0.0945], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,300][circuit_model.py][line:1588][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([0.1341, 0.0922, 0.0477, 0.0956, 0.0947, 0.0755, 0.1183, 0.1041, 0.1292,
        0.1086], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,303][circuit_model.py][line:1591][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([1.0053e-04, 6.9031e-02, 4.6104e-02, 2.3328e-02, 8.4216e-02, 8.8277e-02,
        4.4127e-02, 4.1244e-01, 4.6338e-02, 1.8604e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,303][circuit_model.py][line:1594][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([0.4771, 0.0455, 0.0412, 0.0553, 0.0627, 0.0519, 0.0634, 0.0719, 0.0622,
        0.0689], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,303][circuit_model.py][line:1597][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([0.0295, 0.1088, 0.0374, 0.0610, 0.0735, 0.0649, 0.3639, 0.0753, 0.1591,
        0.0266], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,304][circuit_model.py][line:1600][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([0.0160, 0.2185, 0.0491, 0.1242, 0.0530, 0.0558, 0.0297, 0.0490, 0.0176,
        0.3871], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,304][circuit_model.py][line:1603][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([4.1694e-13, 9.9578e-01, 2.1035e-07, 1.3161e-06, 2.7517e-05, 7.8875e-04,
        8.1903e-04, 1.4021e-04, 2.4055e-03, 4.0490e-05], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,305][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:06,306][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[7250],
        [ 129],
        [  85],
        [ 243],
        [   1],
        [   9],
        [ 120],
        [ 336],
        [  23],
        [ 118]], device='cuda:0')
[2024-07-23 21:07:06,308][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[7595],
        [  57],
        [ 267],
        [ 546],
        [  21],
        [  72],
        [ 829],
        [2111],
        [ 650],
        [ 792]], device='cuda:0')
[2024-07-23 21:07:06,311][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[7044],
        [ 739],
        [2487],
        [3157],
        [3062],
        [2965],
        [3115],
        [3518],
        [3349],
        [3776]], device='cuda:0')
[2024-07-23 21:07:06,314][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[25394],
        [25429],
        [27791],
        [28190],
        [30271],
        [31395],
        [31130],
        [31239],
        [31798],
        [31627]], device='cuda:0')
[2024-07-23 21:07:06,317][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[36620],
        [36988],
        [38780],
        [39126],
        [40027],
        [39817],
        [40151],
        [40458],
        [41273],
        [41489]], device='cuda:0')
[2024-07-23 21:07:06,320][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[44708],
        [39019],
        [39583],
        [38682],
        [38762],
        [37754],
        [38247],
        [37649],
        [37789],
        [37931]], device='cuda:0')
[2024-07-23 21:07:06,323][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[1972],
        [2010],
        [1970],
        [1835],
        [1822],
        [1868],
        [1872],
        [1858],
        [1879],
        [1856]], device='cuda:0')
[2024-07-23 21:07:06,326][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[11082],
        [ 6932],
        [ 5970],
        [ 6506],
        [ 6266],
        [ 5656],
        [ 5372],
        [ 5375],
        [ 5106],
        [ 5062]], device='cuda:0')
[2024-07-23 21:07:06,329][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[3232],
        [5585],
        [6677],
        [6562],
        [6585],
        [6854],
        [6906],
        [7870],
        [8026],
        [7633]], device='cuda:0')
[2024-07-23 21:07:06,332][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[3773],
        [7867],
        [8186],
        [8167],
        [7213],
        [8109],
        [8252],
        [6142],
        [8206],
        [8300]], device='cuda:0')
[2024-07-23 21:07:06,334][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[10785],
        [10576],
        [11628],
        [11263],
        [11039],
        [10189],
        [10238],
        [ 9926],
        [10051],
        [ 9843]], device='cuda:0')
[2024-07-23 21:07:06,335][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[29850],
        [25837],
        [23365],
        [20702],
        [20099],
        [21960],
        [17835],
        [18333],
        [14694],
        [16038]], device='cuda:0')
[2024-07-23 21:07:06,335][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[30500],
        [32536],
        [29602],
        [29769],
        [28745],
        [27971],
        [27744],
        [26889],
        [26524],
        [26324]], device='cuda:0')
[2024-07-23 21:07:06,336][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[32994],
        [32996],
        [36474],
        [49241],
        [49056],
        [47921],
        [48940],
        [44870],
        [49623],
        [49538]], device='cuda:0')
[2024-07-23 21:07:06,337][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[ 1968],
        [26348],
        [ 8009],
        [14731],
        [ 2253],
        [ 5430],
        [ 3949],
        [ 3681],
        [ 2609],
        [ 2648]], device='cuda:0')
[2024-07-23 21:07:06,338][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[3710],
        [3773],
        [3544],
        [2924],
        [2948],
        [3012],
        [2875],
        [2617],
        [2684],
        [2525]], device='cuda:0')
[2024-07-23 21:07:06,341][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[18362],
        [10547],
        [14893],
        [15643],
        [16881],
        [17138],
        [16827],
        [16603],
        [17269],
        [16883]], device='cuda:0')
[2024-07-23 21:07:06,344][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[2493],
        [1990],
        [1822],
        [1154],
        [ 638],
        [1003],
        [ 754],
        [1083],
        [1141],
        [ 861]], device='cuda:0')
[2024-07-23 21:07:06,347][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[ 973],
        [2493],
        [2514],
        [2396],
        [1386],
        [2446],
        [1946],
        [1972],
        [ 970],
        [ 952]], device='cuda:0')
[2024-07-23 21:07:06,350][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[10332],
        [10521],
        [ 9610],
        [ 9730],
        [ 9407],
        [ 8808],
        [ 9060],
        [ 9076],
        [ 9059],
        [ 8961]], device='cuda:0')
[2024-07-23 21:07:06,353][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[2311],
        [3321],
        [2926],
        [2770],
        [2594],
        [2419],
        [2400],
        [2366],
        [2347],
        [2324]], device='cuda:0')
[2024-07-23 21:07:06,356][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[13262],
        [15963],
        [16541],
        [16693],
        [18441],
        [18946],
        [17995],
        [17096],
        [16302],
        [15320]], device='cuda:0')
[2024-07-23 21:07:06,360][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[18748],
        [43597],
        [40868],
        [39746],
        [39368],
        [39218],
        [39306],
        [30314],
        [32064],
        [33605]], device='cuda:0')
[2024-07-23 21:07:06,363][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[15145],
        [19179],
        [19240],
        [20461],
        [20476],
        [19653],
        [20113],
        [19635],
        [20404],
        [20381]], device='cuda:0')
[2024-07-23 21:07:06,365][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[36691],
        [30840],
        [25970],
        [24739],
        [24118],
        [23838],
        [23510],
        [22059],
        [20752],
        [20161]], device='cuda:0')
[2024-07-23 21:07:06,366][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[1558],
        [4262],
        [4309],
        [3106],
        [3654],
        [3216],
        [3234],
        [3978],
        [3285],
        [4622]], device='cuda:0')
[2024-07-23 21:07:06,367][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[26105],
        [11950],
        [11950],
        [11962],
        [11952],
        [11951],
        [11950],
        [11614],
        [11950],
        [11920]], device='cuda:0')
[2024-07-23 21:07:06,367][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[43544],
        [39673],
        [39735],
        [40198],
        [40620],
        [40556],
        [40780],
        [40854],
        [41457],
        [41726]], device='cuda:0')
[2024-07-23 21:07:06,368][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[47011],
        [41407],
        [43563],
        [42174],
        [46419],
        [44586],
        [44816],
        [44822],
        [44566],
        [45778]], device='cuda:0')
[2024-07-23 21:07:06,370][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[12099],
        [12099],
        [12099],
        [12099],
        [12099],
        [12099],
        [12099],
        [12099],
        [12099],
        [12099]], device='cuda:0')
[2024-07-23 21:07:06,399][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:06,400][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,400][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,401][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,402][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,402][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,403][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,404][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,404][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,405][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,405][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,406][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,407][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,407][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.8495, 0.1505], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,410][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.5040, 0.4960], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,411][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.0546, 0.9454], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,412][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.8818, 0.1182], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,412][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.4757, 0.5243], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,413][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.1500, 0.8500], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,418][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.9753, 0.0247], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,425][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.0935, 0.9065], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,431][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.3428, 0.6572], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,438][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [izen] are: tensor([0.5400, 0.4600], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,438][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.6237, 0.3763], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,439][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [izen] are: tensor([0.4444, 0.5556], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,440][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.8363, 0.0845, 0.0791], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,440][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.2990, 0.3312, 0.3699], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,445][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.0138, 0.7858, 0.2005], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,452][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.6917, 0.1392, 0.1690], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,458][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.3356, 0.3527, 0.3116], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,465][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.0858, 0.7753, 0.1390], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,466][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.6470, 0.3522, 0.0008], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,466][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.0416, 0.5110, 0.4474], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,467][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.1958, 0.4172, 0.3870], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,468][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.3634, 0.3048, 0.3318], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,472][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.4923, 0.2729, 0.2347], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,479][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.2637, 0.3471, 0.3893], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,485][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.8634, 0.0568, 0.0518, 0.0279], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,492][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([0.2008, 0.2241, 0.2496, 0.3255], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,493][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.0114, 0.6561, 0.1726, 0.1599], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,494][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.5386, 0.1574, 0.1531, 0.1509], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,494][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.2834, 0.2723, 0.2370, 0.2073], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,495][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.0704, 0.5694, 0.2268, 0.1334], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,500][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.5615, 0.1547, 0.2827, 0.0011], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,507][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.0335, 0.3632, 0.2810, 0.3223], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,513][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.1357, 0.2693, 0.2598, 0.3353], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,519][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([0.2817, 0.2369, 0.2593, 0.2221], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,520][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.4608, 0.2107, 0.1843, 0.1442], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,521][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.2113, 0.2349, 0.2572, 0.2966], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,522][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.8293, 0.0575, 0.0500, 0.0274, 0.0358], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,522][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ by] are: tensor([0.1812, 0.1593, 0.1849, 0.2512, 0.2233], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,527][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.0245, 0.4854, 0.1076, 0.1292, 0.2532], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,534][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.4207, 0.0594, 0.1709, 0.2570, 0.0921], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,540][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.2358, 0.2173, 0.1939, 0.1686, 0.1843], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,547][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.0631, 0.4024, 0.1603, 0.2826, 0.0916], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,548][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.8675, 0.1100, 0.0158, 0.0057, 0.0010], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,549][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.0195, 0.2822, 0.2453, 0.2857, 0.1674], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,549][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.1328, 0.2228, 0.1779, 0.2751, 0.1914], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,550][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ by] are: tensor([0.2306, 0.1931, 0.2111, 0.1799, 0.1852], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,555][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.3751, 0.1859, 0.1582, 0.1191, 0.1617], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,562][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ by] are: tensor([0.1483, 0.1840, 0.2124, 0.2467, 0.2086], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,568][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.7699, 0.0608, 0.0562, 0.0305, 0.0412, 0.0414], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,576][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1462, 0.1380, 0.1584, 0.2065, 0.1858, 0.1650], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,578][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0257, 0.3964, 0.0921, 0.1068, 0.2102, 0.1688], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,579][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.3743, 0.0829, 0.1457, 0.2309, 0.1166, 0.0496], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,580][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1780, 0.1872, 0.1659, 0.1522, 0.1634, 0.1534], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,580][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0640, 0.2852, 0.1086, 0.2417, 0.1904, 0.1100], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,581][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([8.2068e-01, 1.6297e-01, 2.8795e-03, 2.8481e-03, 1.0439e-02, 1.7894e-04],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,586][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0130, 0.2653, 0.2255, 0.2547, 0.1455, 0.0961], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,593][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1197, 0.1975, 0.1400, 0.2287, 0.1705, 0.1435], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,599][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1891, 0.1595, 0.1731, 0.1494, 0.1535, 0.1753], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,604][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3248, 0.1598, 0.1359, 0.1041, 0.1348, 0.1405], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,607][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1476, 0.1537, 0.1751, 0.1904, 0.1671, 0.1661], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:06,608][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.7799, 0.0505, 0.0476, 0.0262, 0.0313, 0.0322, 0.0323],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,609][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([0.1167, 0.1093, 0.1256, 0.1712, 0.1510, 0.1361, 0.1902],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,610][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.0076, 0.4186, 0.0904, 0.0832, 0.1946, 0.1350, 0.0707],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,610][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.3682, 0.1020, 0.1419, 0.1396, 0.1173, 0.0771, 0.0539],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,613][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.1601, 0.1640, 0.1454, 0.1286, 0.1420, 0.1334, 0.1265],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,620][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([0.0224, 0.2531, 0.1466, 0.1432, 0.1111, 0.1692, 0.1543],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,624][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([5.8326e-01, 1.2195e-01, 9.8860e-02, 5.8771e-03, 1.4802e-01, 4.1588e-02,
        4.4676e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,631][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.0187, 0.2414, 0.1964, 0.2259, 0.1144, 0.0786, 0.1246],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,636][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([0.0704, 0.1541, 0.1531, 0.2251, 0.1338, 0.1238, 0.1396],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,637][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([0.1644, 0.1381, 0.1510, 0.1292, 0.1336, 0.1540, 0.1297],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,638][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.2698, 0.1392, 0.1164, 0.0983, 0.1152, 0.1193, 0.1417],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,639][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([0.1126, 0.1395, 0.1516, 0.1674, 0.1462, 0.1422, 0.1405],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:06,640][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.8589, 0.0343, 0.0296, 0.0141, 0.0181, 0.0193, 0.0169, 0.0088],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,646][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.1052, 0.1043, 0.1194, 0.1475, 0.1326, 0.1219, 0.1633, 0.1058],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,652][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0154, 0.3522, 0.0636, 0.0795, 0.1576, 0.1314, 0.0801, 0.1202],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,659][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.3582, 0.0699, 0.1046, 0.1317, 0.1011, 0.0683, 0.0816, 0.0846],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,664][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1572, 0.1434, 0.1257, 0.1118, 0.1241, 0.1189, 0.1131, 0.1057],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,665][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0416, 0.2839, 0.0978, 0.1468, 0.0820, 0.1453, 0.1626, 0.0399],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,666][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ of] are: tensor([4.9887e-01, 4.6700e-01, 4.1604e-03, 1.0783e-02, 1.1853e-03, 2.4738e-03,
        1.5461e-02, 6.1794e-05], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,667][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0111, 0.1995, 0.1736, 0.1905, 0.1257, 0.0827, 0.1431, 0.0736],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,669][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0546, 0.1389, 0.0974, 0.1621, 0.1265, 0.1204, 0.1722, 0.1279],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,675][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1460, 0.1227, 0.1331, 0.1148, 0.1175, 0.1347, 0.1167, 0.1146],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,682][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.2239, 0.1252, 0.1091, 0.0849, 0.1126, 0.1146, 0.1148, 0.1149],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,689][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0725, 0.1245, 0.1438, 0.1607, 0.1321, 0.1320, 0.1257, 0.1086],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:06,693][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.7921, 0.0419, 0.0369, 0.0202, 0.0251, 0.0257, 0.0271, 0.0130, 0.0180],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,694][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([0.0874, 0.0899, 0.1005, 0.1294, 0.1156, 0.1073, 0.1496, 0.0902, 0.1300],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,695][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.0076, 0.3232, 0.0668, 0.0652, 0.1540, 0.1144, 0.0646, 0.1493, 0.0549],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,695][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.2856, 0.0594, 0.0857, 0.0917, 0.1085, 0.0589, 0.0803, 0.1575, 0.0725],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,700][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.1384, 0.1343, 0.1164, 0.1023, 0.1121, 0.1065, 0.1028, 0.0964, 0.0908],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,706][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([0.0206, 0.2687, 0.1098, 0.1098, 0.0781, 0.0990, 0.1235, 0.0722, 0.1183],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,713][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.5991, 0.2505, 0.0284, 0.0041, 0.0357, 0.0524, 0.0037, 0.0201, 0.0059],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,719][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([0.0137, 0.2028, 0.1627, 0.1818, 0.1061, 0.0720, 0.1183, 0.0605, 0.0821],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,721][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([0.0410, 0.1182, 0.1092, 0.1629, 0.1193, 0.1055, 0.1177, 0.1197, 0.1065],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,722][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([0.1313, 0.1108, 0.1203, 0.1035, 0.1055, 0.1225, 0.1037, 0.1018, 0.1007],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,723][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.2320, 0.1109, 0.0939, 0.0771, 0.0907, 0.0946, 0.1127, 0.0952, 0.0928],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,724][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([0.0906, 0.1106, 0.1206, 0.1329, 0.1171, 0.1149, 0.1099, 0.0973, 0.1061],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:06,729][circuit_model.py][line:1532][INFO] ##5-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.7256, 0.0496, 0.0436, 0.0239, 0.0313, 0.0319, 0.0305, 0.0156, 0.0215,
        0.0265], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,736][circuit_model.py][line:1535][INFO] ##5-th layer ##Weight##: The head2 weight for token [ including] are: tensor([0.0794, 0.0791, 0.0925, 0.1170, 0.1061, 0.0971, 0.1307, 0.0823, 0.1137,
        0.1020], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,742][circuit_model.py][line:1538][INFO] ##5-th layer ##Weight##: The head3 weight for token [ including] are: tensor([0.0112, 0.2967, 0.0502, 0.0608, 0.1373, 0.1150, 0.0638, 0.1340, 0.0620,
        0.0691], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,749][circuit_model.py][line:1541][INFO] ##5-th layer ##Weight##: The head4 weight for token [ including] are: tensor([0.1883, 0.0762, 0.1005, 0.1120, 0.0862, 0.0897, 0.0729, 0.1754, 0.0611,
        0.0377], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,750][circuit_model.py][line:1544][INFO] ##5-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.1298, 0.1197, 0.1065, 0.0920, 0.1007, 0.0987, 0.0939, 0.0884, 0.0835,
        0.0868], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,751][circuit_model.py][line:1547][INFO] ##5-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.0206, 0.1610, 0.0896, 0.1088, 0.0650, 0.1193, 0.1180, 0.0515, 0.2229,
        0.0432], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,751][circuit_model.py][line:1550][INFO] ##5-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.3767, 0.1446, 0.0899, 0.0019, 0.2483, 0.0696, 0.0038, 0.0567, 0.0079,
        0.0006], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,756][circuit_model.py][line:1553][INFO] ##5-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.0145, 0.1813, 0.1448, 0.1611, 0.0986, 0.0685, 0.1183, 0.0597, 0.0852,
        0.0680], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,762][circuit_model.py][line:1556][INFO] ##5-th layer ##Weight##: The head9 weight for token [ including] are: tensor([0.0432, 0.1146, 0.0787, 0.1309, 0.0907, 0.0842, 0.1392, 0.0902, 0.1190,
        0.1093], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,769][circuit_model.py][line:1559][INFO] ##5-th layer ##Weight##: The head10 weight for token [ including] are: tensor([0.1225, 0.1018, 0.1104, 0.0940, 0.0957, 0.1124, 0.0954, 0.0922, 0.0923,
        0.0833], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,775][circuit_model.py][line:1562][INFO] ##5-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.2156, 0.1056, 0.0874, 0.0706, 0.0911, 0.0864, 0.0984, 0.0894, 0.0741,
        0.0814], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,777][circuit_model.py][line:1565][INFO] ##5-th layer ##Weight##: The head12 weight for token [ including] are: tensor([0.0749, 0.1031, 0.1102, 0.1222, 0.1053, 0.1055, 0.0999, 0.0863, 0.0961,
        0.0965], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:06,846][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:06,847][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,848][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,848][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,849][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,850][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,851][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,853][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,855][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,860][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,865][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,871][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,876][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:06,876][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([9.9919e-01, 8.0880e-04], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,877][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.9143, 0.0857], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,878][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.2894, 0.7106], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,878][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.0530, 0.9470], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,883][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.0078, 0.9922], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,890][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.2602, 0.7398], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,896][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([0.2503, 0.7497], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,903][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.7630, 0.2370], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,904][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.0331, 0.9669], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,904][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([0.9981, 0.0019], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,905][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.9872, 0.0128], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,906][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([0.6252, 0.3748], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:06,908][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([9.9991e-01, 1.3339e-05, 7.8901e-05], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,915][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.9974, 0.0012, 0.0013], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,921][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.2669, 0.2817, 0.4514], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,928][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.0213, 0.6743, 0.3044], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,931][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0021, 0.8955, 0.1024], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,931][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1702, 0.5403, 0.2895], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,932][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.2223, 0.6475, 0.1302], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,933][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.7394, 0.1654, 0.0952], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,937][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0196, 0.3668, 0.6136], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,945][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.9829, 0.0082, 0.0088], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,951][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.9714, 0.0063, 0.0223], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,958][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.6993, 0.1171, 0.1836], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:06,959][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([9.9988e-01, 7.5973e-06, 4.3318e-05, 7.3991e-05], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,960][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([9.9744e-01, 4.2607e-04, 2.4835e-04, 1.8834e-03], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,960][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([0.0950, 0.3590, 0.3610, 0.1850], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,961][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.0195, 0.6315, 0.2544, 0.0946], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,966][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.0017, 0.7999, 0.1070, 0.0913], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,973][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([0.1083, 0.4259, 0.3771, 0.0887], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,980][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([0.0599, 0.7855, 0.0881, 0.0665], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,987][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([0.4559, 0.3581, 0.0522, 0.1339], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,987][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.0099, 0.2109, 0.3673, 0.4119], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,988][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([0.9752, 0.0070, 0.0097, 0.0081], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,989][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([0.9707, 0.0114, 0.0149, 0.0030], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,990][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([0.9465, 0.0169, 0.0157, 0.0209], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:06,992][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([9.9987e-01, 5.2811e-06, 2.2228e-05, 3.2940e-05, 6.6780e-05],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:06,996][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([9.9967e-01, 4.5792e-05, 2.8778e-05, 1.2186e-04, 1.2945e-04],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,003][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([0.1049, 0.5189, 0.0983, 0.1579, 0.1200], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,008][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([0.0438, 0.6160, 0.1900, 0.1027, 0.0476], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,015][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.0051, 0.6447, 0.0679, 0.0691, 0.2132], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,016][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.0407, 0.3610, 0.2876, 0.1930, 0.1177], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,017][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([0.0965, 0.7475, 0.0446, 0.0896, 0.0219], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,018][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([0.6093, 0.2005, 0.0325, 0.0986, 0.0590], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,018][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.0069, 0.1667, 0.2528, 0.3602, 0.2134], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,023][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([0.9643, 0.0039, 0.0069, 0.0078, 0.0171], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,030][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.9658, 0.0097, 0.0142, 0.0031, 0.0073], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,037][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([0.9151, 0.0186, 0.0252, 0.0124, 0.0288], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,041][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([9.9980e-01, 5.1884e-06, 2.0954e-05, 3.8466e-05, 7.1206e-05, 6.6682e-05],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,044][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.9940e-01, 6.4300e-05, 4.2012e-05, 2.1336e-04, 1.3200e-04, 1.5276e-04],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,045][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0870, 0.5661, 0.0798, 0.0695, 0.1291, 0.0683], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,045][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0243, 0.7010, 0.1072, 0.0909, 0.0413, 0.0352], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,046][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0048, 0.5563, 0.0606, 0.0602, 0.1821, 0.1361], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,047][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0737, 0.2211, 0.2074, 0.1484, 0.2007, 0.1488], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,054][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1471, 0.7046, 0.0498, 0.0526, 0.0292, 0.0165], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,060][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.2602, 0.4668, 0.0511, 0.1145, 0.0569, 0.0505], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,067][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0047, 0.1441, 0.2051, 0.2994, 0.1895, 0.1572], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,072][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.9536, 0.0045, 0.0058, 0.0078, 0.0164, 0.0119], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,073][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9297, 0.0110, 0.0201, 0.0047, 0.0116, 0.0229], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,074][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.8654, 0.0099, 0.0117, 0.0070, 0.0140, 0.0920], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,075][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([9.9972e-01, 2.6982e-06, 1.9621e-05, 4.1539e-05, 1.3014e-04, 6.4498e-05,
        2.3518e-05], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,075][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([9.9749e-01, 5.9075e-04, 1.8088e-04, 5.4928e-04, 9.4415e-04, 1.2625e-04,
        1.1530e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,080][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([0.0061, 0.6512, 0.1187, 0.0711, 0.0885, 0.0431, 0.0213],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,088][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([0.0038, 0.7210, 0.1378, 0.0731, 0.0281, 0.0195, 0.0165],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,094][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([0.0013, 0.5372, 0.0678, 0.0540, 0.1708, 0.1160, 0.0529],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,101][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([0.0265, 0.2011, 0.2220, 0.0971, 0.1600, 0.2491, 0.0442],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,102][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([0.0940, 0.4993, 0.1373, 0.0919, 0.0707, 0.0717, 0.0351],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,102][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([0.2790, 0.4229, 0.0511, 0.1245, 0.0497, 0.0540, 0.0189],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,103][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([0.0056, 0.1083, 0.1799, 0.2381, 0.1532, 0.1409, 0.1741],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,104][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([0.9259, 0.0093, 0.0079, 0.0100, 0.0296, 0.0147, 0.0026],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,111][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([0.9435, 0.0064, 0.0146, 0.0041, 0.0085, 0.0151, 0.0078],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,117][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([0.8710, 0.0135, 0.0122, 0.0157, 0.0158, 0.0560, 0.0158],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,122][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([9.9899e-01, 1.2667e-05, 8.4699e-05, 8.6647e-05, 3.5294e-04, 2.4362e-04,
        1.2435e-04, 1.0029e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,125][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([9.9164e-01, 6.8710e-04, 5.1391e-04, 8.7640e-04, 1.7803e-03, 6.9770e-04,
        1.5289e-03, 2.2723e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,129][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0448, 0.3008, 0.0483, 0.0530, 0.2095, 0.1730, 0.1129, 0.0577],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,130][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0088, 0.4981, 0.0903, 0.1141, 0.0822, 0.0694, 0.0984, 0.0388],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,131][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0035, 0.4437, 0.0397, 0.0410, 0.1534, 0.1221, 0.0534, 0.1432],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,132][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0285, 0.2590, 0.1573, 0.1441, 0.0986, 0.1829, 0.0870, 0.0425],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,136][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2269, 0.2984, 0.0380, 0.0371, 0.0494, 0.0928, 0.1569, 0.1006],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,142][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1709, 0.3316, 0.0345, 0.0603, 0.0942, 0.1336, 0.1274, 0.0476],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,150][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0068, 0.0947, 0.1289, 0.1873, 0.1305, 0.1201, 0.1796, 0.1521],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,156][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.9158, 0.0069, 0.0103, 0.0080, 0.0257, 0.0175, 0.0057, 0.0100],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,157][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.9442, 0.0039, 0.0112, 0.0021, 0.0064, 0.0142, 0.0049, 0.0131],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,158][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.8559, 0.0078, 0.0081, 0.0057, 0.0127, 0.0489, 0.0039, 0.0572],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,159][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([9.9976e-01, 1.9960e-06, 1.2243e-05, 1.8959e-05, 7.1885e-05, 5.0453e-05,
        1.7463e-05, 3.1475e-05, 3.3678e-05], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,160][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([9.9779e-01, 5.4677e-05, 4.3340e-05, 1.6231e-04, 4.3983e-04, 1.0871e-04,
        1.3308e-04, 3.3413e-04, 9.3145e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,164][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([0.0095, 0.5520, 0.0516, 0.0511, 0.1146, 0.0751, 0.0610, 0.0415, 0.0435],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,170][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([0.0034, 0.7223, 0.0832, 0.0589, 0.0324, 0.0252, 0.0348, 0.0170, 0.0229],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,177][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.0011, 0.4490, 0.0523, 0.0420, 0.1400, 0.1002, 0.0476, 0.1312, 0.0367],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,183][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([0.0220, 0.2249, 0.1995, 0.1038, 0.0923, 0.1340, 0.0473, 0.0824, 0.0938],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,185][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([0.0890, 0.5466, 0.0532, 0.0351, 0.0449, 0.0681, 0.0580, 0.0620, 0.0431],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,186][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([0.1727, 0.4123, 0.0376, 0.0685, 0.0692, 0.1211, 0.0542, 0.0226, 0.0418],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,187][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([0.0033, 0.0798, 0.1401, 0.1759, 0.1217, 0.1129, 0.1338, 0.1388, 0.0937],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,188][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([0.9062, 0.0074, 0.0094, 0.0140, 0.0269, 0.0150, 0.0049, 0.0090, 0.0071],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,192][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([0.9297, 0.0062, 0.0110, 0.0026, 0.0055, 0.0102, 0.0049, 0.0140, 0.0161],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,200][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([0.9357, 0.0065, 0.0030, 0.0041, 0.0049, 0.0209, 0.0026, 0.0166, 0.0058],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,203][circuit_model.py][line:1570][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([9.9981e-01, 7.3572e-07, 7.9302e-06, 1.0035e-05, 4.0718e-05, 3.5113e-05,
        2.2843e-05, 1.4694e-05, 4.0418e-05, 2.1798e-05], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,208][circuit_model.py][line:1573][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([9.8874e-01, 1.5770e-04, 1.3746e-04, 4.7237e-04, 1.1751e-03, 5.4240e-04,
        2.0564e-03, 1.2015e-03, 4.1812e-03, 1.3370e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,213][circuit_model.py][line:1576][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([0.0264, 0.4736, 0.0459, 0.0378, 0.1239, 0.1082, 0.0599, 0.0341, 0.0564,
        0.0339], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,214][circuit_model.py][line:1579][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([0.0120, 0.4741, 0.1190, 0.0797, 0.0564, 0.0606, 0.0876, 0.0332, 0.0639,
        0.0135], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,214][circuit_model.py][line:1582][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([0.0017, 0.4320, 0.0388, 0.0383, 0.1367, 0.1021, 0.0451, 0.1228, 0.0381,
        0.0445], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,215][circuit_model.py][line:1585][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([0.0203, 0.1733, 0.1657, 0.0878, 0.0835, 0.1777, 0.0468, 0.0521, 0.1531,
        0.0397], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,219][circuit_model.py][line:1588][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([0.1807, 0.3135, 0.0337, 0.0447, 0.0636, 0.0874, 0.0706, 0.0585, 0.0744,
        0.0729], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,226][circuit_model.py][line:1591][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([0.1486, 0.3462, 0.0242, 0.0513, 0.0512, 0.1182, 0.0731, 0.0311, 0.1178,
        0.0383], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,233][circuit_model.py][line:1594][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([0.0034, 0.0744, 0.1062, 0.1521, 0.1012, 0.0956, 0.1500, 0.1199, 0.1017,
        0.0955], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,239][circuit_model.py][line:1597][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([0.8826, 0.0080, 0.0073, 0.0116, 0.0239, 0.0165, 0.0067, 0.0127, 0.0235,
        0.0072], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,241][circuit_model.py][line:1600][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([0.8214, 0.0127, 0.0274, 0.0052, 0.0126, 0.0236, 0.0114, 0.0294, 0.0365,
        0.0199], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,242][circuit_model.py][line:1603][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([0.7686, 0.0067, 0.0071, 0.0082, 0.0206, 0.0582, 0.0092, 0.0596, 0.0268,
        0.0348], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,245][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:07,248][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[7073],
        [1468],
        [1121],
        [ 973],
        [  72],
        [ 251],
        [1070],
        [2535],
        [ 927],
        [1430]], device='cuda:0')
[2024-07-23 21:07:07,251][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[7246],
        [ 287],
        [ 127],
        [ 344],
        [   1],
        [  23],
        [ 301],
        [ 458],
        [  44],
        [ 236]], device='cuda:0')
[2024-07-23 21:07:07,254][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[ 1906],
        [ 3931],
        [ 4961],
        [ 4684],
        [ 6068],
        [ 8898],
        [ 8494],
        [ 5428],
        [ 8329],
        [11446]], device='cuda:0')
[2024-07-23 21:07:07,257][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[1391],
        [1158],
        [1097],
        [ 952],
        [ 902],
        [ 890],
        [ 799],
        [ 785],
        [ 742],
        [ 748]], device='cuda:0')
[2024-07-23 21:07:07,260][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[42627],
        [39351],
        [39833],
        [40031],
        [38719],
        [38934],
        [38945],
        [38139],
        [37895],
        [38138]], device='cuda:0')
[2024-07-23 21:07:07,263][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[11310],
        [15046],
        [19256],
        [27043],
        [26445],
        [24656],
        [22287],
        [21153],
        [22962],
        [22961]], device='cuda:0')
[2024-07-23 21:07:07,267][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[33222],
        [37193],
        [34760],
        [34617],
        [35394],
        [35557],
        [35686],
        [35567],
        [35662],
        [35104]], device='cuda:0')
[2024-07-23 21:07:07,270][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[25179],
        [16382],
        [15821],
        [16539],
        [18373],
        [18913],
        [18132],
        [18063],
        [16458],
        [16001]], device='cuda:0')
[2024-07-23 21:07:07,272][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[14383],
        [14254],
        [16124],
        [17065],
        [13797],
        [14201],
        [13470],
        [15858],
        [12600],
        [13561]], device='cuda:0')
[2024-07-23 21:07:07,273][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[  926],
        [24106],
        [24971],
        [24259],
        [22780],
        [22488],
        [21130],
        [19789],
        [19302],
        [18108]], device='cuda:0')
[2024-07-23 21:07:07,275][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[ 4797],
        [29782],
        [33077],
        [34063],
        [31737],
        [30721],
        [32486],
        [30335],
        [30413],
        [29679]], device='cuda:0')
[2024-07-23 21:07:07,276][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[31454],
        [30338],
        [29298],
        [28454],
        [27396],
        [26976],
        [26751],
        [26567],
        [26220],
        [25998]], device='cuda:0')
[2024-07-23 21:07:07,278][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[34112],
        [28740],
        [29812],
        [31175],
        [32102],
        [29282],
        [28633],
        [27703],
        [26490],
        [26973]], device='cuda:0')
[2024-07-23 21:07:07,281][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[13923],
        [19324],
        [18582],
        [20967],
        [20974],
        [20456],
        [23025],
        [23740],
        [23908],
        [23996]], device='cuda:0')
[2024-07-23 21:07:07,284][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[13538],
        [34862],
        [31952],
        [25814],
        [27155],
        [27651],
        [26946],
        [28977],
        [32031],
        [25432]], device='cuda:0')
[2024-07-23 21:07:07,287][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[22184],
        [22066],
        [22171],
        [22165],
        [22166],
        [22157],
        [22147],
        [22045],
        [22155],
        [22157]], device='cuda:0')
[2024-07-23 21:07:07,290][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[35476],
        [28424],
        [35319],
        [35334],
        [35461],
        [35451],
        [35366],
        [35124],
        [35396],
        [35012]], device='cuda:0')
[2024-07-23 21:07:07,293][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[43041],
        [11036],
        [10529],
        [ 8939],
        [ 8747],
        [ 8852],
        [ 8794],
        [ 6960],
        [ 7600],
        [ 7305]], device='cuda:0')
[2024-07-23 21:07:07,296][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[8290],
        [5573],
        [4930],
        [5062],
        [5117],
        [5074],
        [5007],
        [4923],
        [4847],
        [4721]], device='cuda:0')
[2024-07-23 21:07:07,299][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[20560],
        [31385],
        [31648],
        [31200],
        [28392],
        [26902],
        [26319],
        [26070],
        [26032],
        [25602]], device='cuda:0')
[2024-07-23 21:07:07,302][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[20224],
        [45450],
        [44082],
        [43749],
        [43817],
        [43307],
        [43001],
        [44261],
        [44105],
        [43992]], device='cuda:0')
[2024-07-23 21:07:07,304][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[39145],
        [21499],
        [21360],
        [20054],
        [20129],
        [20245],
        [19880],
        [22313],
        [20060],
        [22624]], device='cuda:0')
[2024-07-23 21:07:07,305][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[12605],
        [ 8820],
        [10835],
        [13833],
        [12071],
        [16097],
        [16646],
        [21215],
        [18972],
        [21004]], device='cuda:0')
[2024-07-23 21:07:07,307][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[7555],
        [ 301],
        [ 361],
        [ 341],
        [ 272],
        [ 265],
        [ 298],
        [ 308],
        [ 326],
        [ 372]], device='cuda:0')
[2024-07-23 21:07:07,308][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[10142],
        [10090],
        [ 9740],
        [ 9510],
        [ 9434],
        [ 9376],
        [ 8908],
        [ 9067],
        [ 8833],
        [ 8849]], device='cuda:0')
[2024-07-23 21:07:07,311][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[26523],
        [26182],
        [25451],
        [25599],
        [25572],
        [24153],
        [24751],
        [24740],
        [24509],
        [22664]], device='cuda:0')
[2024-07-23 21:07:07,314][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[  815],
        [17118],
        [18962],
        [ 2289],
        [ 4495],
        [ 7280],
        [ 7632],
        [ 6047],
        [ 2244],
        [12967]], device='cuda:0')
[2024-07-23 21:07:07,317][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[23832],
        [28200],
        [27037],
        [29365],
        [29820],
        [28639],
        [28513],
        [27428],
        [29134],
        [27117]], device='cuda:0')
[2024-07-23 21:07:07,320][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[ 7224],
        [21942],
        [21635],
        [22588],
        [22352],
        [21698],
        [23196],
        [21644],
        [21149],
        [22588]], device='cuda:0')
[2024-07-23 21:07:07,324][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[8645],
        [8645],
        [8645],
        [8645],
        [8645],
        [8645],
        [8645],
        [8645],
        [8645],
        [8645]], device='cuda:0')
[2024-07-23 21:07:07,388][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:07,392][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,393][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,394][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,394][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,395][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,397][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,400][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,402][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,406][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,410][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,414][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,419][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,423][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.6939, 0.3061], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,424][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.5128, 0.4872], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,425][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.4335, 0.5665], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,426][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.1366, 0.8634], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,426][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.9857, 0.0143], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,431][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.2162, 0.7838], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,438][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.1055, 0.8945], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,444][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.3545, 0.6455], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,451][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.2157, 0.7843], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,451][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [izen] are: tensor([0.6781, 0.3219], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,452][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.0434, 0.9566], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,453][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [izen] are: tensor([0.0657, 0.9343], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,453][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.6427, 0.1481, 0.2091], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,458][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.1455, 0.1069, 0.7475], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,465][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.2852, 0.3700, 0.3448], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,471][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.0411, 0.5130, 0.4458], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,478][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.9561, 0.0120, 0.0319], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,479][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.1237, 0.4152, 0.4611], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,479][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.1058, 0.3963, 0.4978], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,480][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.3356, 0.4595, 0.2049], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,481][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.4547, 0.3642, 0.1812], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,485][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.6080, 0.1976, 0.1944], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,492][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.0231, 0.4717, 0.5052], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,498][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.1308, 0.5469, 0.3223], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,505][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.3838, 0.3313, 0.2341, 0.0508], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,506][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([0.0323, 0.1656, 0.6114, 0.1907], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,507][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.2097, 0.2851, 0.2690, 0.2362], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,507][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.0319, 0.3431, 0.3502, 0.2748], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,508][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.8810, 0.0122, 0.0320, 0.0748], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,513][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.0750, 0.2921, 0.3286, 0.3042], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,520][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.0638, 0.2804, 0.2997, 0.3561], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,526][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.0953, 0.7343, 0.1352, 0.0351], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,532][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.1612, 0.6321, 0.1588, 0.0479], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,533][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([0.4556, 0.2441, 0.1841, 0.1162], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,534][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.0155, 0.2951, 0.3140, 0.3755], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,535][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.0543, 0.6554, 0.2018, 0.0885], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:07,535][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.7006, 0.2419, 0.0281, 0.0131, 0.0163], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,540][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ by] are: tensor([0.0095, 0.5690, 0.1977, 0.1459, 0.0780], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,547][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.1744, 0.2172, 0.2087, 0.1836, 0.2160], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,553][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.0274, 0.3151, 0.2359, 0.1733, 0.2483], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,560][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.7764, 0.0134, 0.0345, 0.0772, 0.0985], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,560][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.0617, 0.2234, 0.2469, 0.2309, 0.2372], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,561][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.0165, 0.2673, 0.2028, 0.1776, 0.3359], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,562][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.0866, 0.7621, 0.0780, 0.0413, 0.0320], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,563][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.2147, 0.6622, 0.0454, 0.0387, 0.0390], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,569][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ by] are: tensor([0.5627, 0.1721, 0.1330, 0.0854, 0.0467], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,575][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.0115, 0.2318, 0.2469, 0.2981, 0.2118], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,582][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ by] are: tensor([0.0650, 0.8182, 0.0440, 0.0245, 0.0482], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:07,587][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4305, 0.4653, 0.0316, 0.0127, 0.0269, 0.0330], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,588][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0108, 0.6939, 0.0867, 0.1053, 0.0626, 0.0406], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,588][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1367, 0.1765, 0.1688, 0.1509, 0.1775, 0.1895], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,589][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0423, 0.2453, 0.1495, 0.1325, 0.2013, 0.2291], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,592][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8319, 0.0070, 0.0188, 0.0462, 0.0608, 0.0354], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,599][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0550, 0.1751, 0.1910, 0.1802, 0.1857, 0.2131], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,605][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0356, 0.1431, 0.1632, 0.1404, 0.2288, 0.2890], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,612][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1609, 0.6800, 0.0598, 0.0334, 0.0310, 0.0350], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,614][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1690, 0.7455, 0.0221, 0.0129, 0.0311, 0.0194], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,615][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.5641, 0.1481, 0.1199, 0.0740, 0.0382, 0.0557], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,616][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0120, 0.1890, 0.1994, 0.2342, 0.1747, 0.1908], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,616][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0291, 0.8279, 0.0338, 0.0239, 0.0462, 0.0391], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:07,621][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.0486, 0.8105, 0.0812, 0.0190, 0.0162, 0.0191, 0.0054],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,627][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([0.0057, 0.3370, 0.4827, 0.1004, 0.0589, 0.0132, 0.0021],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,634][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.1057, 0.1564, 0.1487, 0.1335, 0.1568, 0.1678, 0.1310],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,640][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.0131, 0.2324, 0.1960, 0.1253, 0.1671, 0.1830, 0.0831],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,641][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.6650, 0.0122, 0.0304, 0.0617, 0.0789, 0.0520, 0.0999],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,642][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([0.0357, 0.1513, 0.1698, 0.1560, 0.1580, 0.1850, 0.1442],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,643][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.0125, 0.1241, 0.1252, 0.1390, 0.1727, 0.1124, 0.3141],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,644][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.0195, 0.7977, 0.0872, 0.0340, 0.0246, 0.0202, 0.0168],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,648][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([0.0133, 0.8637, 0.0690, 0.0188, 0.0225, 0.0093, 0.0034],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,656][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([0.4761, 0.1589, 0.1232, 0.0737, 0.0529, 0.0648, 0.0504],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,662][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.0103, 0.1548, 0.1615, 0.1932, 0.1431, 0.1536, 0.1834],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,668][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([0.0073, 0.8087, 0.0752, 0.0341, 0.0310, 0.0337, 0.0100],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:07,669][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.5194, 0.1789, 0.0217, 0.0138, 0.0663, 0.1292, 0.0339, 0.0367],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,670][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0244, 0.2588, 0.0751, 0.0905, 0.1679, 0.1176, 0.0535, 0.2121],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,671][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1018, 0.1362, 0.1314, 0.1147, 0.1375, 0.1492, 0.1138, 0.1155],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,673][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0152, 0.2055, 0.0854, 0.0851, 0.1493, 0.1718, 0.0963, 0.1914],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,680][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.5852, 0.0172, 0.0306, 0.0646, 0.0681, 0.0549, 0.0979, 0.0816],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,686][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0334, 0.1296, 0.1445, 0.1337, 0.1387, 0.1623, 0.1264, 0.1315],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,693][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0130, 0.1148, 0.1092, 0.0832, 0.1470, 0.1323, 0.1504, 0.2500],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,696][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1940, 0.4740, 0.0511, 0.0323, 0.0542, 0.0724, 0.0500, 0.0720],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,696][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.3750, 0.2924, 0.0224, 0.0182, 0.0985, 0.1304, 0.0345, 0.0286],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,697][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.4225, 0.1314, 0.1167, 0.0739, 0.0563, 0.0690, 0.0680, 0.0622],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,698][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0072, 0.1350, 0.1420, 0.1678, 0.1228, 0.1356, 0.1641, 0.1255],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,702][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0330, 0.4443, 0.0271, 0.0229, 0.1298, 0.1752, 0.0940, 0.0737],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:07,708][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.1691, 0.6354, 0.0363, 0.0165, 0.0432, 0.0483, 0.0191, 0.0172, 0.0149],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,715][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([0.0036, 0.4253, 0.2381, 0.1019, 0.1031, 0.0368, 0.0082, 0.0792, 0.0038],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,721][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.0898, 0.1191, 0.1147, 0.1012, 0.1215, 0.1308, 0.1010, 0.1044, 0.1175],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,723][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.0104, 0.1803, 0.1458, 0.1002, 0.1204, 0.1423, 0.0812, 0.1726, 0.0468],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,724][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.5360, 0.0097, 0.0237, 0.0509, 0.0624, 0.0401, 0.0833, 0.0785, 0.1154],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,725][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([0.0298, 0.1160, 0.1286, 0.1187, 0.1219, 0.1428, 0.1110, 0.1155, 0.1156],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,726][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.0152, 0.0777, 0.0997, 0.0950, 0.1288, 0.0942, 0.1700, 0.0962, 0.2232],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,730][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([0.0508, 0.7437, 0.0558, 0.0209, 0.0302, 0.0297, 0.0229, 0.0276, 0.0184],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,737][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([0.0389, 0.8148, 0.0255, 0.0121, 0.0459, 0.0338, 0.0133, 0.0075, 0.0081],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,743][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([0.4954, 0.1077, 0.0818, 0.0580, 0.0463, 0.0568, 0.0474, 0.0513, 0.0553],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,750][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.0077, 0.1158, 0.1215, 0.1456, 0.1081, 0.1182, 0.1402, 0.1084, 0.1345],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,751][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([0.0109, 0.7099, 0.0348, 0.0215, 0.0530, 0.0894, 0.0366, 0.0293, 0.0147],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:07,752][circuit_model.py][line:1532][INFO] ##6-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.3461, 0.4297, 0.0245, 0.0133, 0.0405, 0.0675, 0.0231, 0.0183, 0.0197,
        0.0171], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,752][circuit_model.py][line:1535][INFO] ##6-th layer ##Weight##: The head2 weight for token [ including] are: tensor([0.0089, 0.4898, 0.1161, 0.0830, 0.1066, 0.0499, 0.0266, 0.0760, 0.0212,
        0.0219], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,757][circuit_model.py][line:1538][INFO] ##6-th layer ##Weight##: The head3 weight for token [ including] are: tensor([0.0792, 0.1092, 0.1047, 0.0931, 0.1093, 0.1187, 0.0920, 0.0931, 0.1071,
        0.0935], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,763][circuit_model.py][line:1541][INFO] ##6-th layer ##Weight##: The head4 weight for token [ including] are: tensor([0.0219, 0.1845, 0.0983, 0.0872, 0.1248, 0.1445, 0.0753, 0.1645, 0.0489,
        0.0501], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,770][circuit_model.py][line:1544][INFO] ##6-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.5575, 0.0093, 0.0215, 0.0446, 0.0550, 0.0395, 0.0696, 0.0661, 0.0980,
        0.0388], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,776][circuit_model.py][line:1547][INFO] ##6-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.0266, 0.1034, 0.1143, 0.1060, 0.1084, 0.1269, 0.0994, 0.1030, 0.1036,
        0.1084], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,778][circuit_model.py][line:1550][INFO] ##6-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.0122, 0.0929, 0.0907, 0.0662, 0.1049, 0.0897, 0.1059, 0.0920, 0.1159,
        0.2296], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,778][circuit_model.py][line:1553][INFO] ##6-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.0579, 0.6260, 0.0503, 0.0234, 0.0354, 0.0404, 0.0312, 0.0586, 0.0416,
        0.0352], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,779][circuit_model.py][line:1556][INFO] ##6-th layer ##Weight##: The head9 weight for token [ including] are: tensor([0.1972, 0.4694, 0.0211, 0.0133, 0.0878, 0.1096, 0.0335, 0.0196, 0.0253,
        0.0232], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,780][circuit_model.py][line:1559][INFO] ##6-th layer ##Weight##: The head10 weight for token [ including] are: tensor([0.5414, 0.0904, 0.0753, 0.0531, 0.0355, 0.0477, 0.0499, 0.0370, 0.0457,
        0.0241], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,785][circuit_model.py][line:1562][INFO] ##6-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.0057, 0.1041, 0.1117, 0.1315, 0.0969, 0.1063, 0.1239, 0.0977, 0.1209,
        0.1011], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,792][circuit_model.py][line:1565][INFO] ##6-th layer ##Weight##: The head12 weight for token [ including] are: tensor([0.0163, 0.5763, 0.0200, 0.0152, 0.0801, 0.1154, 0.0564, 0.0348, 0.0299,
        0.0556], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:07,871][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:07,875][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,879][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,883][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,886][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,890][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,892][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,892][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,893][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,894][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,898][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,903][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,908][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:07,914][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.6806, 0.3194], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,918][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.1070, 0.8930], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,919][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.8631, 0.1369], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,920][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.7801, 0.2199], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,921][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([9.9928e-01, 7.1517e-04], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,921][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.1914, 0.8086], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,926][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([0.9985, 0.0015], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,933][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.3545, 0.6455], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,939][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.2157, 0.7843], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,946][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([0.5539, 0.4461], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,946][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.8473, 0.1527], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,947][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([0.0657, 0.9343], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:07,948][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.6337, 0.1518, 0.2145], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,949][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.1102, 0.5235, 0.3662], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,953][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.7209, 0.1498, 0.1294], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,960][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.7156, 0.1494, 0.1351], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,966][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.9899, 0.0042, 0.0059], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,973][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.1810, 0.5437, 0.2753], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,974][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([9.9716e-01, 7.0869e-04, 2.1352e-03], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,974][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.3356, 0.4595, 0.2049], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,975][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.4547, 0.3642, 0.1812], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,976][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.4370, 0.0916, 0.4714], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,980][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.9071, 0.0537, 0.0392], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,987][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.1308, 0.5469, 0.3223], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:07,993][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([0.3688, 0.3406, 0.2388, 0.0518], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,000][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([0.0077, 0.7583, 0.1689, 0.0651], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,001][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([0.5866, 0.1500, 0.1371, 0.1263], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,002][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.7181, 0.1347, 0.1173, 0.0299], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,002][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.9686, 0.0120, 0.0112, 0.0082], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,003][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([0.0918, 0.6272, 0.1780, 0.1030], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,005][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([9.9706e-01, 5.8005e-04, 1.1620e-03, 1.1949e-03], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,011][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([0.0953, 0.7343, 0.1352, 0.0351], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,018][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.1612, 0.6321, 0.1588, 0.0479], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,024][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([0.3626, 0.0959, 0.2287, 0.3128], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,028][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([0.9007, 0.0170, 0.0210, 0.0613], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,029][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([0.0543, 0.6554, 0.2018, 0.0885], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,029][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([0.6840, 0.2572, 0.0288, 0.0135, 0.0165], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,030][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([0.0104, 0.8643, 0.0542, 0.0307, 0.0405], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,035][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([0.6541, 0.0803, 0.0694, 0.0655, 0.1307], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,042][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([0.6006, 0.2264, 0.1103, 0.0236, 0.0391], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,048][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.9833, 0.0018, 0.0035, 0.0025, 0.0088], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,055][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.1335, 0.5690, 0.1015, 0.0604, 0.1356], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,055][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([9.9700e-01, 2.1220e-04, 4.9795e-04, 2.3758e-04, 2.0570e-03],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,056][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([0.0866, 0.7621, 0.0780, 0.0413, 0.0320], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,057][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.2147, 0.6622, 0.0454, 0.0387, 0.0390], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,058][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([0.5836, 0.0256, 0.0985, 0.1421, 0.1503], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,064][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.9077, 0.0112, 0.0157, 0.0351, 0.0302], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,070][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([0.0650, 0.8182, 0.0440, 0.0245, 0.0482], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,077][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4145, 0.4820, 0.0314, 0.0127, 0.0267, 0.0328], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,082][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0171, 0.8602, 0.0256, 0.0198, 0.0326, 0.0448], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,083][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.5690, 0.0685, 0.0508, 0.0674, 0.1169, 0.1275], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,083][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.7637, 0.0999, 0.0378, 0.0121, 0.0284, 0.0580], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,084][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.9640, 0.0033, 0.0051, 0.0034, 0.0173, 0.0069], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,087][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1349, 0.4692, 0.0642, 0.0401, 0.1067, 0.1849], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,091][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([9.9514e-01, 1.8984e-04, 5.5650e-04, 2.1871e-04, 1.7649e-03, 2.1290e-03],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,097][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1609, 0.6800, 0.0598, 0.0334, 0.0310, 0.0350], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,104][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1690, 0.7455, 0.0221, 0.0129, 0.0311, 0.0194], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,109][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3286, 0.0217, 0.1325, 0.0985, 0.1535, 0.2653], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,110][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9382, 0.0035, 0.0071, 0.0137, 0.0210, 0.0164], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,111][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0291, 0.8279, 0.0338, 0.0239, 0.0462, 0.0391], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,111][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([0.0426, 0.8205, 0.0796, 0.0183, 0.0154, 0.0182, 0.0053],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,112][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([0.0032, 0.8621, 0.0750, 0.0172, 0.0256, 0.0142, 0.0027],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,117][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([0.4300, 0.0861, 0.0642, 0.0705, 0.1563, 0.1600, 0.0328],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,124][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([0.3821, 0.2464, 0.1640, 0.0417, 0.0547, 0.0969, 0.0141],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,130][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([0.9335, 0.0092, 0.0100, 0.0055, 0.0315, 0.0084, 0.0019],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,137][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([0.0288, 0.5936, 0.1124, 0.0433, 0.0806, 0.1101, 0.0313],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,137][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([9.9688e-01, 2.6893e-04, 3.9885e-04, 1.8734e-04, 1.0553e-03, 9.1539e-04,
        2.9244e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,138][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([0.0195, 0.7977, 0.0872, 0.0340, 0.0246, 0.0202, 0.0168],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,139][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([0.0133, 0.8637, 0.0690, 0.0188, 0.0225, 0.0093, 0.0034],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,144][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([0.1739, 0.0429, 0.1199, 0.1341, 0.2794, 0.1805, 0.0694],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,151][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([0.9193, 0.0029, 0.0052, 0.0132, 0.0220, 0.0146, 0.0228],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,157][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([0.0073, 0.8087, 0.0752, 0.0341, 0.0310, 0.0337, 0.0100],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,164][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.4938, 0.1913, 0.0223, 0.0143, 0.0688, 0.1347, 0.0365, 0.0383],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,164][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0221, 0.5171, 0.0349, 0.0285, 0.1053, 0.1438, 0.0516, 0.0967],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,165][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.4571, 0.0479, 0.0545, 0.0661, 0.1346, 0.1549, 0.0436, 0.0412],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,166][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.5291, 0.1228, 0.0525, 0.0168, 0.0517, 0.1152, 0.0278, 0.0842],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,167][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.9510, 0.0021, 0.0045, 0.0039, 0.0227, 0.0106, 0.0031, 0.0022],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,171][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0648, 0.1984, 0.0432, 0.0292, 0.1821, 0.3318, 0.0699, 0.0805],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,176][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([9.8981e-01, 3.2478e-04, 9.9311e-04, 4.0021e-04, 3.2981e-03, 2.8465e-03,
        3.8471e-04, 1.9419e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,182][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1940, 0.4740, 0.0511, 0.0323, 0.0542, 0.0724, 0.0500, 0.0720],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,189][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.3750, 0.2924, 0.0224, 0.0182, 0.0985, 0.1304, 0.0345, 0.0286],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,191][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.1093, 0.0064, 0.0633, 0.0428, 0.1495, 0.1592, 0.2708, 0.1987],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,192][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.8146, 0.0057, 0.0170, 0.0329, 0.0403, 0.0318, 0.0374, 0.0203],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,193][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0330, 0.4443, 0.0271, 0.0229, 0.1298, 0.1752, 0.0940, 0.0737],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,194][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([0.1532, 0.6541, 0.0355, 0.0162, 0.0423, 0.0471, 0.0194, 0.0170, 0.0152],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,198][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([0.0089, 0.7754, 0.0408, 0.0155, 0.0530, 0.0485, 0.0109, 0.0340, 0.0131],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,204][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([0.4833, 0.0444, 0.0419, 0.0563, 0.1170, 0.1291, 0.0284, 0.0474, 0.0522],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,211][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([0.4949, 0.1569, 0.0670, 0.0202, 0.0405, 0.0984, 0.0168, 0.0860, 0.0193],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,217][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.9307, 0.0081, 0.0076, 0.0059, 0.0299, 0.0098, 0.0028, 0.0022, 0.0029],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,221][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([0.0350, 0.4688, 0.0574, 0.0313, 0.1076, 0.1766, 0.0425, 0.0421, 0.0387],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,222][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([9.9570e-01, 1.5688e-04, 3.7616e-04, 1.3889e-04, 1.3630e-03, 1.0603e-03,
        1.6596e-04, 5.2603e-04, 5.1697e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,223][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([0.0508, 0.7437, 0.0558, 0.0209, 0.0302, 0.0297, 0.0229, 0.0276, 0.0184],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,223][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([0.0389, 0.8148, 0.0255, 0.0121, 0.0459, 0.0338, 0.0133, 0.0075, 0.0081],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,228][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([0.2777, 0.0019, 0.0154, 0.0232, 0.1094, 0.0808, 0.0834, 0.1122, 0.2960],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,234][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([0.9150, 0.0011, 0.0032, 0.0080, 0.0196, 0.0149, 0.0173, 0.0086, 0.0122],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,241][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([0.0109, 0.7099, 0.0348, 0.0215, 0.0530, 0.0894, 0.0366, 0.0293, 0.0147],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,247][circuit_model.py][line:1570][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([0.3279, 0.4460, 0.0242, 0.0133, 0.0404, 0.0677, 0.0240, 0.0184, 0.0206,
        0.0175], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,249][circuit_model.py][line:1573][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([0.0081, 0.6954, 0.0223, 0.0157, 0.0517, 0.0764, 0.0253, 0.0413, 0.0398,
        0.0241], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,249][circuit_model.py][line:1576][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([0.3388, 0.0522, 0.0535, 0.0807, 0.1175, 0.1521, 0.0391, 0.0470, 0.0631,
        0.0560], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,250][circuit_model.py][line:1579][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([0.4301, 0.1893, 0.0531, 0.0219, 0.0570, 0.0986, 0.0193, 0.0796, 0.0247,
        0.0264], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,251][circuit_model.py][line:1582][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([0.9195, 0.0066, 0.0078, 0.0061, 0.0272, 0.0173, 0.0045, 0.0030, 0.0039,
        0.0042], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,256][circuit_model.py][line:1585][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([0.0587, 0.2450, 0.0343, 0.0274, 0.1204, 0.2643, 0.0462, 0.0540, 0.0585,
        0.0913], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,260][circuit_model.py][line:1588][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([9.8776e-01, 4.3095e-04, 7.8573e-04, 5.2297e-04, 2.6361e-03, 2.4326e-03,
        4.9958e-04, 1.4868e-03, 1.4993e-03, 1.9441e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,266][circuit_model.py][line:1591][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([0.0579, 0.6260, 0.0503, 0.0234, 0.0354, 0.0404, 0.0312, 0.0586, 0.0416,
        0.0352], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,273][circuit_model.py][line:1594][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([0.1972, 0.4694, 0.0211, 0.0133, 0.0878, 0.1096, 0.0335, 0.0196, 0.0253,
        0.0232], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,276][circuit_model.py][line:1597][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([0.0884, 0.0026, 0.0190, 0.0333, 0.0578, 0.1022, 0.2534, 0.0731, 0.2847,
        0.0855], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,276][circuit_model.py][line:1600][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([0.8682, 0.0028, 0.0093, 0.0147, 0.0248, 0.0214, 0.0179, 0.0145, 0.0140,
        0.0122], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,277][circuit_model.py][line:1603][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([0.0163, 0.5763, 0.0200, 0.0152, 0.0801, 0.1154, 0.0564, 0.0348, 0.0299,
        0.0556], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,281][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:08,284][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[8339],
        [1685],
        [ 874],
        [ 767],
        [  69],
        [  99],
        [1091],
        [1128],
        [ 490],
        [1198]], device='cuda:0')
[2024-07-23 21:07:08,287][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[8591],
        [4770],
        [2726],
        [1816],
        [  68],
        [ 113],
        [3025],
        [1405],
        [1124],
        [2616]], device='cuda:0')
[2024-07-23 21:07:08,290][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[9846],
        [7381],
        [5663],
        [7834],
        [6542],
        [8038],
        [9778],
        [5516],
        [9020],
        [7973]], device='cuda:0')
[2024-07-23 21:07:08,293][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[12516],
        [ 8922],
        [18266],
        [17002],
        [ 9261],
        [ 8601],
        [12030],
        [ 6086],
        [ 8623],
        [ 7239]], device='cuda:0')
[2024-07-23 21:07:08,296][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[17449],
        [23513],
        [24334],
        [24374],
        [23936],
        [24224],
        [25337],
        [25750],
        [25982],
        [26159]], device='cuda:0')
[2024-07-23 21:07:08,299][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[11506],
        [ 8480],
        [10654],
        [12059],
        [14110],
        [15410],
        [15385],
        [16520],
        [16247],
        [16586]], device='cuda:0')
[2024-07-23 21:07:08,302][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[38087],
        [37332],
        [35239],
        [29261],
        [21730],
        [25358],
        [16457],
        [14320],
        [12676],
        [13361]], device='cuda:0')
[2024-07-23 21:07:08,305][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[20743],
        [16218],
        [12920],
        [12783],
        [12311],
        [11973],
        [11668],
        [11391],
        [11219],
        [11125]], device='cuda:0')
[2024-07-23 21:07:08,307][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[2165],
        [3616],
        [3656],
        [3705],
        [4008],
        [4115],
        [3744],
        [3883],
        [4023],
        [3845]], device='cuda:0')
[2024-07-23 21:07:08,308][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[31255],
        [27182],
        [28101],
        [27268],
        [27147],
        [27532],
        [27216],
        [27858],
        [27458],
        [28074]], device='cuda:0')
[2024-07-23 21:07:08,309][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[12656],
        [ 9598],
        [13005],
        [12540],
        [11522],
        [11133],
        [11507],
        [21240],
        [12440],
        [18636]], device='cuda:0')
[2024-07-23 21:07:08,311][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[33986],
        [27397],
        [25301],
        [23854],
        [24258],
        [24189],
        [23148],
        [21900],
        [22766],
        [23078]], device='cuda:0')
[2024-07-23 21:07:08,314][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[1749],
        [4440],
        [6157],
        [6283],
        [6195],
        [6156],
        [6390],
        [6525],
        [7158],
        [7248]], device='cuda:0')
[2024-07-23 21:07:08,317][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[45835],
        [33441],
        [31494],
        [29743],
        [32472],
        [31793],
        [31173],
        [28336],
        [30514],
        [29927]], device='cuda:0')
[2024-07-23 21:07:08,320][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[26390],
        [28557],
        [22744],
        [32085],
        [33231],
        [30676],
        [32228],
        [34030],
        [29855],
        [27080]], device='cuda:0')
[2024-07-23 21:07:08,323][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[37447],
        [37293],
        [38837],
        [29163],
        [38897],
        [28752],
        [20819],
        [37183],
        [22869],
        [27837]], device='cuda:0')
[2024-07-23 21:07:08,326][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[47685],
        [12659],
        [19654],
        [14527],
        [13118],
        [13043],
        [13317],
        [20138],
        [14463],
        [15647]], device='cuda:0')
[2024-07-23 21:07:08,329][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[27848],
        [28268],
        [34399],
        [34336],
        [34561],
        [36640],
        [37135],
        [37378],
        [38469],
        [39037]], device='cuda:0')
[2024-07-23 21:07:08,332][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[23820],
        [34291],
        [25426],
        [25112],
        [29725],
        [20013],
        [29150],
        [20309],
        [23189],
        [24970]], device='cuda:0')
[2024-07-23 21:07:08,335][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[44421],
        [44409],
        [44086],
        [43356],
        [43720],
        [42774],
        [40193],
        [41994],
        [40174],
        [39388]], device='cuda:0')
[2024-07-23 21:07:08,338][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[15780],
        [12631],
        [22564],
        [22352],
        [24376],
        [28187],
        [24864],
        [35694],
        [29620],
        [34291]], device='cuda:0')
[2024-07-23 21:07:08,339][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[30007],
        [29834],
        [29894],
        [29812],
        [29961],
        [29957],
        [29929],
        [29963],
        [29957],
        [29844]], device='cuda:0')
[2024-07-23 21:07:08,340][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 7746],
        [16740],
        [15850],
        [17476],
        [17575],
        [17527],
        [18259],
        [20035],
        [19221],
        [20497]], device='cuda:0')
[2024-07-23 21:07:08,341][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[40669],
        [14720],
        [17301],
        [13062],
        [13962],
        [13504],
        [12348],
        [14156],
        [12142],
        [12519]], device='cuda:0')
[2024-07-23 21:07:08,343][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[19851],
        [12063],
        [10198],
        [ 9132],
        [ 7223],
        [ 8151],
        [ 9631],
        [11760],
        [ 9269],
        [12557]], device='cuda:0')
[2024-07-23 21:07:08,346][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[29215],
        [39933],
        [39197],
        [36886],
        [36320],
        [34451],
        [35684],
        [35650],
        [34981],
        [35274]], device='cuda:0')
[2024-07-23 21:07:08,349][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 9815],
        [36083],
        [38018],
        [37495],
        [36171],
        [36149],
        [36294],
        [28709],
        [34603],
        [30886]], device='cuda:0')
[2024-07-23 21:07:08,352][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[ 6331],
        [10521],
        [ 7929],
        [11690],
        [ 9731],
        [11779],
        [13305],
        [ 7040],
        [12497],
        [ 9095]], device='cuda:0')
[2024-07-23 21:07:08,355][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[12781],
        [ 8480],
        [ 8032],
        [ 9602],
        [ 8728],
        [13071],
        [12563],
        [15662],
        [16103],
        [18613]], device='cuda:0')
[2024-07-23 21:07:08,358][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[3433],
        [3433],
        [3433],
        [3433],
        [3433],
        [3433],
        [3433],
        [3433],
        [3433],
        [3433]], device='cuda:0')
[2024-07-23 21:07:08,443][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:08,448][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,452][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,454][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,455][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,456][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,456][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,458][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,461][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,465][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,470][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,475][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,480][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,482][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.0103, 0.9897], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,483][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.9318, 0.0682], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,484][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.0011, 0.9989], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,484][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.1173, 0.8827], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,489][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.0359, 0.9641], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,495][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.9723, 0.0277], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,502][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.6100, 0.3900], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,508][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.0876, 0.9124], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,509][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.0208, 0.9792], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,510][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [izen] are: tensor([0.0264, 0.9736], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,511][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.0020, 0.9980], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,512][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [izen] are: tensor([0.9715, 0.0285], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,514][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.0142, 0.5843, 0.4015], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,521][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.4693, 0.1863, 0.3444], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,527][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.0019, 0.4037, 0.5945], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,534][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.2236, 0.4906, 0.2858], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,537][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.0410, 0.3527, 0.6063], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,537][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.9454, 0.0328, 0.0219], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,538][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.3881, 0.1734, 0.4384], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,539][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.2341, 0.5312, 0.2347], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,540][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.0126, 0.9086, 0.0788], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,546][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.0084, 0.5740, 0.4176], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,549][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ is] are: tensor([5.2594e-04, 3.4227e-01, 6.5720e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,556][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.9396, 0.0293, 0.0312], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,562][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.0166, 0.7536, 0.1201, 0.1096], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,564][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([0.2773, 0.2153, 0.3234, 0.1839], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,565][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.0023, 0.1747, 0.1764, 0.6466], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,565][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.1618, 0.5619, 0.1855, 0.0908], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,566][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.0185, 0.4043, 0.4776, 0.0996], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,570][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.8703, 0.0800, 0.0319, 0.0179], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,576][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.1791, 0.1428, 0.3341, 0.3440], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,583][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.1913, 0.3626, 0.1232, 0.3229], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,589][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.0015, 0.9603, 0.0240, 0.0142], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,591][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([0.0063, 0.5723, 0.2755, 0.1460], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,592][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([4.1517e-04, 2.9999e-01, 4.3125e-01, 2.6834e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,593][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.8007, 0.0523, 0.0518, 0.0952], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:08,593][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.0482, 0.8028, 0.0266, 0.0752, 0.0472], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,598][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ by] are: tensor([0.0231, 0.0794, 0.1944, 0.0996, 0.6035], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,605][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.0060, 0.0516, 0.0922, 0.1489, 0.7013], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,611][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.1490, 0.6166, 0.0676, 0.0488, 0.1179], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,618][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.0310, 0.5494, 0.1927, 0.0737, 0.1532], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,618][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.9018, 0.0525, 0.0162, 0.0125, 0.0170], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,619][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.2130, 0.0836, 0.2266, 0.2606, 0.2162], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,620][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.2786, 0.2646, 0.0827, 0.1951, 0.1790], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,621][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.0040, 0.9504, 0.0089, 0.0180, 0.0188], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,625][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ by] are: tensor([0.0124, 0.7608, 0.0792, 0.0607, 0.0870], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,632][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.0031, 0.0831, 0.4055, 0.3400, 0.1682], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,638][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ by] are: tensor([0.8398, 0.0207, 0.0272, 0.0631, 0.0493], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:08,645][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0053, 0.9046, 0.0117, 0.0474, 0.0128, 0.0183], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,646][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0075, 0.0869, 0.1739, 0.0734, 0.4447, 0.2136], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,647][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0010, 0.0149, 0.0438, 0.0716, 0.2949, 0.5737], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,648][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1566, 0.5343, 0.0556, 0.0358, 0.1017, 0.1161], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,652][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0421, 0.4494, 0.1177, 0.0407, 0.1619, 0.1883], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,659][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9356, 0.0182, 0.0092, 0.0080, 0.0175, 0.0114], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,665][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1339, 0.0664, 0.1900, 0.2175, 0.1821, 0.2102], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,672][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3560, 0.1125, 0.0590, 0.1319, 0.1895, 0.1510], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,673][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0020, 0.9734, 0.0041, 0.0061, 0.0084, 0.0061], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,673][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0036, 0.8222, 0.0436, 0.0327, 0.0500, 0.0478], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,674][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0013, 0.0932, 0.3877, 0.2584, 0.1050, 0.1543], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,675][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.6714, 0.0240, 0.0300, 0.0658, 0.0823, 0.1265], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:08,681][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.0022, 0.8433, 0.0768, 0.0680, 0.0022, 0.0010, 0.0065],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,687][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([0.1627, 0.0709, 0.0977, 0.0536, 0.3436, 0.1513, 0.1201],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,694][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.0010, 0.0973, 0.0845, 0.1560, 0.2537, 0.2607, 0.1468],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,699][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.0250, 0.7034, 0.1055, 0.0423, 0.0564, 0.0493, 0.0180],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,700][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.0011, 0.6512, 0.1610, 0.0382, 0.0773, 0.0503, 0.0210],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,701][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([0.7792, 0.0858, 0.0326, 0.0236, 0.0378, 0.0185, 0.0225],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,702][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.1190, 0.0616, 0.1742, 0.1965, 0.1635, 0.1813, 0.1039],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,706][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.3675, 0.1275, 0.0535, 0.1060, 0.1116, 0.0926, 0.1413],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,709][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([2.5627e-04, 9.7555e-01, 9.2410e-03, 5.3749e-03, 6.0112e-03, 2.7350e-03,
        8.2849e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,714][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([2.2581e-04, 8.6907e-01, 7.0932e-02, 2.7074e-02, 1.7368e-02, 1.1536e-02,
        3.7950e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,720][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.0004, 0.3629, 0.3239, 0.1646, 0.0441, 0.0389, 0.0651],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,726][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([0.7529, 0.0185, 0.0200, 0.0325, 0.0575, 0.0699, 0.0487],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:08,727][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0049, 0.0745, 0.0050, 0.0327, 0.0483, 0.2035, 0.6078, 0.0233],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,728][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.1172, 0.0507, 0.1161, 0.0374, 0.2279, 0.1365, 0.0772, 0.2370],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,729][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ of] are: tensor([1.1272e-04, 1.9839e-02, 3.3155e-02, 5.9456e-02, 2.9276e-01, 2.5853e-01,
        1.7375e-01, 1.6239e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,731][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.1585, 0.2517, 0.0394, 0.0339, 0.1534, 0.2486, 0.0418, 0.0727],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,738][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0185, 0.1891, 0.0598, 0.0394, 0.2348, 0.3325, 0.0564, 0.0696],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,744][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.7107, 0.0505, 0.0256, 0.0234, 0.0602, 0.0424, 0.0309, 0.0563],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,751][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0928, 0.0491, 0.1437, 0.1675, 0.1457, 0.1706, 0.0998, 0.1308],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,754][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1627, 0.1148, 0.0596, 0.1509, 0.1638, 0.1193, 0.1468, 0.0821],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,755][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0043, 0.8597, 0.0055, 0.0090, 0.0496, 0.0439, 0.0127, 0.0153],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,755][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0047, 0.4056, 0.0538, 0.0511, 0.1693, 0.2102, 0.0458, 0.0594],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,756][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0003, 0.1104, 0.2974, 0.1819, 0.0802, 0.0771, 0.2029, 0.0498],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,760][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.5383, 0.0144, 0.0330, 0.0565, 0.0751, 0.1208, 0.1103, 0.0516],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:08,766][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.0056, 0.6457, 0.0136, 0.0407, 0.0181, 0.0299, 0.1829, 0.0029, 0.0605],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,773][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([0.0314, 0.0749, 0.1009, 0.0474, 0.2721, 0.1351, 0.0941, 0.1889, 0.0551],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,779][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.0008, 0.0257, 0.0410, 0.0717, 0.1884, 0.1539, 0.1303, 0.1514, 0.2368],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,781][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.0864, 0.4535, 0.0617, 0.0350, 0.1195, 0.1455, 0.0352, 0.0355, 0.0276],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,782][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.0053, 0.4430, 0.0725, 0.0325, 0.1621, 0.1736, 0.0479, 0.0321, 0.0310],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,783][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([0.8332, 0.0377, 0.0140, 0.0151, 0.0299, 0.0165, 0.0163, 0.0258, 0.0114],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,784][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.0802, 0.0468, 0.1299, 0.1436, 0.1282, 0.1409, 0.0868, 0.1218, 0.1218],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,788][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([0.3436, 0.0644, 0.0422, 0.0950, 0.1077, 0.0903, 0.1030, 0.0643, 0.0894],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,793][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([6.9520e-04, 9.6538e-01, 3.4247e-03, 3.3755e-03, 1.0150e-02, 8.2072e-03,
        2.1519e-03, 3.4644e-03, 3.1497e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,799][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([0.0010, 0.7043, 0.0503, 0.0293, 0.0729, 0.0728, 0.0211, 0.0218, 0.0266],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,806][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.0018, 0.0956, 0.2326, 0.1790, 0.0800, 0.0688, 0.1838, 0.0707, 0.0878],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,808][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([0.6185, 0.0119, 0.0205, 0.0330, 0.0656, 0.0797, 0.0489, 0.0486, 0.0732],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:08,809][circuit_model.py][line:1532][INFO] ##7-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.0075, 0.3116, 0.0096, 0.0493, 0.0369, 0.0813, 0.2183, 0.0100, 0.1154,
        0.1600], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,810][circuit_model.py][line:1535][INFO] ##7-th layer ##Weight##: The head2 weight for token [ including] are: tensor([0.0068, 0.0478, 0.1071, 0.0453, 0.2501, 0.1412, 0.1011, 0.1750, 0.0592,
        0.0663], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,811][circuit_model.py][line:1538][INFO] ##7-th layer ##Weight##: The head3 weight for token [ including] are: tensor([5.7343e-05, 9.8728e-03, 1.6067e-02, 3.3692e-02, 1.8427e-01, 2.5348e-01,
        1.8375e-01, 5.4805e-02, 1.6552e-01, 9.8492e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,812][circuit_model.py][line:1541][INFO] ##7-th layer ##Weight##: The head4 weight for token [ including] are: tensor([0.0549, 0.5285, 0.0356, 0.0236, 0.1062, 0.1361, 0.0291, 0.0287, 0.0260,
        0.0312], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,816][circuit_model.py][line:1544][INFO] ##7-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.0061, 0.2354, 0.0425, 0.0242, 0.1756, 0.2822, 0.0605, 0.0436, 0.0480,
        0.0819], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,823][circuit_model.py][line:1547][INFO] ##7-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.5538, 0.1289, 0.0339, 0.0316, 0.0486, 0.0427, 0.0377, 0.0604, 0.0294,
        0.0329], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,829][circuit_model.py][line:1550][INFO] ##7-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.0664, 0.0430, 0.1149, 0.1256, 0.1075, 0.1260, 0.0765, 0.1029, 0.1041,
        0.1332], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,836][circuit_model.py][line:1553][INFO] ##7-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.2299, 0.0614, 0.0356, 0.0756, 0.1370, 0.1043, 0.1089, 0.0709, 0.0948,
        0.0815], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,837][circuit_model.py][line:1556][INFO] ##7-th layer ##Weight##: The head9 weight for token [ including] are: tensor([5.2581e-04, 9.2839e-01, 3.4479e-03, 5.3773e-03, 1.7853e-02, 1.6158e-02,
        5.2854e-03, 7.5972e-03, 1.0387e-02, 4.9827e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,838][circuit_model.py][line:1559][INFO] ##7-th layer ##Weight##: The head10 weight for token [ including] are: tensor([0.0015, 0.5674, 0.0334, 0.0223, 0.1022, 0.1207, 0.0265, 0.0263, 0.0416,
        0.0581], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,838][circuit_model.py][line:1562][INFO] ##7-th layer ##Weight##: The head11 weight for token [ including] are: tensor([2.6543e-04, 8.6334e-02, 2.0289e-01, 1.7346e-01, 5.8843e-02, 6.4910e-02,
        2.8121e-01, 2.8001e-02, 6.9430e-02, 3.4661e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,843][circuit_model.py][line:1565][INFO] ##7-th layer ##Weight##: The head12 weight for token [ including] are: tensor([0.5460, 0.0102, 0.0199, 0.0559, 0.0514, 0.0832, 0.0753, 0.0304, 0.0818,
        0.0458], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:08,932][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:08,937][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,940][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,942][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,943][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,944][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,945][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,945][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,946][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,947][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,948][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,948][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,949][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:08,950][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.0040, 0.9960], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,950][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.9474, 0.0526], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,954][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.0038, 0.9962], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,959][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.1173, 0.8827], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,959][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.0359, 0.9641], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,960][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.9723, 0.0277], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,961][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([0.9744, 0.0256], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,962][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.1047, 0.8953], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,966][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.0208, 0.9792], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,973][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([0.0264, 0.9736], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,979][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.0020, 0.9980], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,986][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([0.9715, 0.0285], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:08,987][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.0137, 0.5710, 0.4153], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,987][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.8084, 0.1135, 0.0781], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,988][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.0089, 0.4291, 0.5619], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,992][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.2236, 0.4906, 0.2858], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:08,998][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0410, 0.3527, 0.6063], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,005][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.9454, 0.0328, 0.0219], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,011][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.8657, 0.0548, 0.0795], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,013][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.2566, 0.5319, 0.2114], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,014][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0126, 0.9086, 0.0788], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,014][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.0084, 0.5740, 0.4176], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,015][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([5.2594e-04, 3.4227e-01, 6.5720e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,016][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.9396, 0.0293, 0.0312], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,020][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([0.0025, 0.7447, 0.2035, 0.0493], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,026][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([0.8476, 0.0924, 0.0399, 0.0201], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,033][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([0.0107, 0.2412, 0.2485, 0.4996], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,039][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.1618, 0.5619, 0.1855, 0.0908], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,043][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.0185, 0.4043, 0.4776, 0.0996], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,044][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([0.8703, 0.0800, 0.0319, 0.0179], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,045][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([0.8179, 0.0907, 0.0643, 0.0271], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,045][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([0.2191, 0.3879, 0.1128, 0.2802], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,046][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.0015, 0.9603, 0.0240, 0.0142], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,052][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([0.0063, 0.5723, 0.2755, 0.1460], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,056][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([4.1517e-04, 2.9999e-01, 4.3125e-01, 2.6834e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,063][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([0.8007, 0.0523, 0.0518, 0.0952], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,069][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([0.0194, 0.8902, 0.0353, 0.0142, 0.0409], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,071][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([0.8180, 0.0599, 0.0575, 0.0265, 0.0380], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,071][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([0.0169, 0.0805, 0.1884, 0.1896, 0.5246], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,072][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([0.1490, 0.6166, 0.0676, 0.0488, 0.1179], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,073][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.0310, 0.5494, 0.1927, 0.0737, 0.1532], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,077][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.9018, 0.0525, 0.0162, 0.0125, 0.0170], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,083][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([0.8845, 0.0235, 0.0322, 0.0182, 0.0415], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,090][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([0.2972, 0.2901, 0.0771, 0.1719, 0.1636], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,096][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.0040, 0.9504, 0.0089, 0.0180, 0.0188], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,098][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([0.0124, 0.7608, 0.0792, 0.0607, 0.0870], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,099][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.0031, 0.0831, 0.4055, 0.3400, 0.1682], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,099][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([0.8398, 0.0207, 0.0272, 0.0631, 0.0493], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,100][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0131, 0.9024, 0.0205, 0.0086, 0.0238, 0.0315], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,104][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.7707, 0.0698, 0.0505, 0.0318, 0.0495, 0.0277], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,105][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0047, 0.0457, 0.1405, 0.1379, 0.3350, 0.3362], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,111][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1566, 0.5343, 0.0556, 0.0358, 0.1017, 0.1161], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,118][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0421, 0.4494, 0.1177, 0.0407, 0.1619, 0.1883], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,124][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9356, 0.0182, 0.0092, 0.0080, 0.0175, 0.0114], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,126][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8300, 0.0293, 0.0352, 0.0212, 0.0482, 0.0361], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,127][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.3688, 0.1241, 0.0564, 0.1212, 0.1787, 0.1508], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,128][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0020, 0.9734, 0.0041, 0.0061, 0.0084, 0.0061], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,129][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0036, 0.8222, 0.0436, 0.0327, 0.0500, 0.0478], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,133][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0013, 0.0932, 0.3877, 0.2584, 0.1050, 0.1543], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,139][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.6714, 0.0240, 0.0300, 0.0658, 0.0823, 0.1265], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,143][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([3.3919e-04, 9.3134e-01, 4.5332e-02, 8.3838e-03, 6.8892e-03, 6.7098e-03,
        1.0051e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,149][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([0.6184, 0.1700, 0.0777, 0.0235, 0.0215, 0.0159, 0.0730],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,154][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([0.0043, 0.1640, 0.1534, 0.1750, 0.2198, 0.1374, 0.1463],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,154][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([0.0250, 0.7034, 0.1055, 0.0423, 0.0564, 0.0493, 0.0180],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,155][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([0.0011, 0.6512, 0.1610, 0.0382, 0.0773, 0.0503, 0.0210],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,156][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([0.7792, 0.0858, 0.0326, 0.0236, 0.0378, 0.0185, 0.0225],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,158][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([0.6834, 0.0844, 0.0632, 0.0328, 0.0614, 0.0391, 0.0356],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,166][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([0.4429, 0.1352, 0.0471, 0.0860, 0.0947, 0.0805, 0.1138],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,169][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([2.5627e-04, 9.7555e-01, 9.2410e-03, 5.3749e-03, 6.0112e-03, 2.7350e-03,
        8.2849e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,173][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([2.2581e-04, 8.6907e-01, 7.0932e-02, 2.7074e-02, 1.7368e-02, 1.1536e-02,
        3.7950e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,180][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([0.0004, 0.3629, 0.3239, 0.1646, 0.0441, 0.0389, 0.0651],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,181][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([0.7529, 0.0185, 0.0200, 0.0325, 0.0575, 0.0699, 0.0487],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,182][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0499, 0.2899, 0.0192, 0.0145, 0.1353, 0.3344, 0.0434, 0.1134],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,183][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.6473, 0.0651, 0.0497, 0.0402, 0.0512, 0.0410, 0.0689, 0.0366],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,184][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0012, 0.0515, 0.0896, 0.0988, 0.2661, 0.1458, 0.1806, 0.1664],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,188][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.1585, 0.2517, 0.0394, 0.0339, 0.1534, 0.2486, 0.0418, 0.0727],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,194][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0185, 0.1891, 0.0598, 0.0394, 0.2348, 0.3325, 0.0564, 0.0696],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,201][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.7107, 0.0505, 0.0256, 0.0234, 0.0602, 0.0424, 0.0309, 0.0563],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,207][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.6676, 0.0376, 0.0546, 0.0283, 0.0655, 0.0513, 0.0307, 0.0645],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,209][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1990, 0.1277, 0.0569, 0.1375, 0.1513, 0.1130, 0.1319, 0.0826],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,210][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0043, 0.8597, 0.0055, 0.0090, 0.0496, 0.0439, 0.0127, 0.0153],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,211][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0047, 0.4056, 0.0538, 0.0511, 0.1693, 0.2102, 0.0458, 0.0594],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,211][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0003, 0.1104, 0.2974, 0.1819, 0.0802, 0.0771, 0.2029, 0.0498],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,215][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.5383, 0.0144, 0.0330, 0.0565, 0.0751, 0.1208, 0.1103, 0.0516],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,221][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([0.0017, 0.8869, 0.0144, 0.0052, 0.0226, 0.0391, 0.0082, 0.0115, 0.0105],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,229][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([0.7096, 0.0612, 0.0429, 0.0234, 0.0385, 0.0282, 0.0394, 0.0220, 0.0349],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,235][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([0.0067, 0.0549, 0.0956, 0.0990, 0.1863, 0.1049, 0.1404, 0.1525, 0.1597],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,237][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([0.0864, 0.4535, 0.0617, 0.0350, 0.1195, 0.1455, 0.0352, 0.0355, 0.0276],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,237][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.0053, 0.4430, 0.0725, 0.0325, 0.1621, 0.1736, 0.0479, 0.0321, 0.0310],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,238][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([0.8332, 0.0377, 0.0140, 0.0151, 0.0299, 0.0165, 0.0163, 0.0258, 0.0114],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,239][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([0.6594, 0.0471, 0.0367, 0.0247, 0.0630, 0.0323, 0.0278, 0.0723, 0.0368],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,244][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([0.4152, 0.0696, 0.0382, 0.0785, 0.0938, 0.0820, 0.0851, 0.0610, 0.0767],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,248][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([6.9520e-04, 9.6538e-01, 3.4247e-03, 3.3755e-03, 1.0150e-02, 8.2072e-03,
        2.1519e-03, 3.4644e-03, 3.1497e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,254][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([0.0010, 0.7043, 0.0503, 0.0293, 0.0729, 0.0728, 0.0211, 0.0218, 0.0266],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,261][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([0.0018, 0.0956, 0.2326, 0.1790, 0.0800, 0.0688, 0.1838, 0.0707, 0.0878],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,264][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([0.6185, 0.0119, 0.0205, 0.0330, 0.0656, 0.0797, 0.0489, 0.0486, 0.0732],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,265][circuit_model.py][line:1570][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([0.0108, 0.5894, 0.0143, 0.0092, 0.0670, 0.1672, 0.0160, 0.0378, 0.0282,
        0.0601], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,265][circuit_model.py][line:1573][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([0.5304, 0.0790, 0.0562, 0.0353, 0.0687, 0.0457, 0.0756, 0.0322, 0.0492,
        0.0276], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,266][circuit_model.py][line:1576][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([0.0006, 0.0309, 0.0516, 0.0689, 0.1989, 0.1380, 0.1982, 0.0817, 0.1304,
        0.1007], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,271][circuit_model.py][line:1579][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([0.0549, 0.5285, 0.0356, 0.0236, 0.1062, 0.1361, 0.0291, 0.0287, 0.0260,
        0.0312], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,278][circuit_model.py][line:1582][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([0.0061, 0.2354, 0.0425, 0.0242, 0.1756, 0.2822, 0.0605, 0.0436, 0.0480,
        0.0819], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,284][circuit_model.py][line:1585][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([0.5538, 0.1289, 0.0339, 0.0316, 0.0486, 0.0427, 0.0377, 0.0604, 0.0294,
        0.0329], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,291][circuit_model.py][line:1588][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([0.5440, 0.0594, 0.0426, 0.0330, 0.0672, 0.0485, 0.0348, 0.0767, 0.0537,
        0.0401], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,292][circuit_model.py][line:1591][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([0.2772, 0.0666, 0.0334, 0.0654, 0.1256, 0.0996, 0.0946, 0.0710, 0.0853,
        0.0814], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,293][circuit_model.py][line:1594][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([5.2581e-04, 9.2839e-01, 3.4479e-03, 5.3773e-03, 1.7853e-02, 1.6158e-02,
        5.2854e-03, 7.5972e-03, 1.0387e-02, 4.9827e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,294][circuit_model.py][line:1597][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([0.0015, 0.5674, 0.0334, 0.0223, 0.1022, 0.1207, 0.0265, 0.0263, 0.0416,
        0.0581], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,295][circuit_model.py][line:1600][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([2.6543e-04, 8.6334e-02, 2.0289e-01, 1.7346e-01, 5.8843e-02, 6.4910e-02,
        2.8121e-01, 2.8001e-02, 6.9430e-02, 3.4661e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,301][circuit_model.py][line:1603][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([0.5460, 0.0102, 0.0199, 0.0559, 0.0514, 0.0832, 0.0753, 0.0304, 0.0818,
        0.0458], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,305][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:09,308][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[10011],
        [ 1877],
        [  538],
        [  773],
        [   67],
        [  159],
        [ 1403],
        [  707],
        [  604],
        [  941]], device='cuda:0')
[2024-07-23 21:07:09,311][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[9161],
        [5583],
        [2381],
        [1768],
        [ 189],
        [ 294],
        [2995],
        [2297],
        [1324],
        [2564]], device='cuda:0')
[2024-07-23 21:07:09,314][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[25003],
        [ 1107],
        [ 1514],
        [ 1305],
        [ 1201],
        [ 1165],
        [ 1235],
        [ 5232],
        [ 1714],
        [ 3027]], device='cuda:0')
[2024-07-23 21:07:09,317][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[30401],
        [34783],
        [41475],
        [42613],
        [38958],
        [39464],
        [39231],
        [38960],
        [39378],
        [39173]], device='cuda:0')
[2024-07-23 21:07:09,320][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[13449],
        [14074],
        [25386],
        [35684],
        [25732],
        [30516],
        [30647],
        [27852],
        [26583],
        [29155]], device='cuda:0')
[2024-07-23 21:07:09,322][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[   65],
        [10574],
        [ 5364],
        [ 6420],
        [ 7657],
        [ 5823],
        [ 8221],
        [ 3357],
        [ 5421],
        [ 6440]], device='cuda:0')
[2024-07-23 21:07:09,324][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[31942],
        [15675],
        [17483],
        [16678],
        [15325],
        [13584],
        [14895],
        [11116],
        [13000],
        [12247]], device='cuda:0')
[2024-07-23 21:07:09,325][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[37007],
        [39341],
        [41593],
        [44037],
        [43752],
        [42503],
        [46539],
        [47709],
        [46352],
        [47134]], device='cuda:0')
[2024-07-23 21:07:09,326][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[1128],
        [3649],
        [3600],
        [4021],
        [4099],
        [4119],
        [3940],
        [3797],
        [3719],
        [3667]], device='cuda:0')
[2024-07-23 21:07:09,329][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[26303],
        [32484],
        [32151],
        [30796],
        [29261],
        [26688],
        [28596],
        [26566],
        [28584],
        [27568]], device='cuda:0')
[2024-07-23 21:07:09,332][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[16697],
        [34643],
        [35092],
        [34760],
        [34559],
        [34656],
        [34702],
        [34523],
        [34648],
        [34592]], device='cuda:0')
[2024-07-23 21:07:09,335][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[34657],
        [26695],
        [23464],
        [24086],
        [26172],
        [26395],
        [26043],
        [24248],
        [25471],
        [25260]], device='cuda:0')
[2024-07-23 21:07:09,338][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[ 7586],
        [20059],
        [ 7147],
        [ 5168],
        [ 2492],
        [ 2927],
        [ 7050],
        [ 4764],
        [ 4853],
        [ 6281]], device='cuda:0')
[2024-07-23 21:07:09,341][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[ 7124],
        [ 5868],
        [ 6607],
        [12978],
        [13527],
        [26473],
        [20799],
        [27652],
        [27057],
        [29184]], device='cuda:0')
[2024-07-23 21:07:09,344][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[14607],
        [ 7683],
        [ 6332],
        [ 9373],
        [11321],
        [10952],
        [11640],
        [ 8969],
        [13187],
        [ 9976]], device='cuda:0')
[2024-07-23 21:07:09,348][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[30833],
        [17870],
        [17011],
        [17362],
        [17607],
        [17410],
        [17504],
        [12415],
        [16891],
        [14794]], device='cuda:0')
[2024-07-23 21:07:09,351][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[28704],
        [17295],
        [ 9847],
        [ 9301],
        [ 9715],
        [12249],
        [24497],
        [27361],
        [22947],
        [27131]], device='cuda:0')
[2024-07-23 21:07:09,353][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[27732],
        [22507],
        [15401],
        [ 1944],
        [20413],
        [25361],
        [15509],
        [21970],
        [17939],
        [18911]], device='cuda:0')
[2024-07-23 21:07:09,354][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[20979],
        [ 8995],
        [ 9145],
        [10063],
        [ 7376],
        [ 6616],
        [ 7926],
        [ 3643],
        [ 5109],
        [ 5388]], device='cuda:0')
[2024-07-23 21:07:09,355][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[35037],
        [  647],
        [ 6763],
        [ 6777],
        [ 5013],
        [ 9710],
        [ 3248],
        [25678],
        [10550],
        [21543]], device='cuda:0')
[2024-07-23 21:07:09,357][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[12765],
        [13033],
        [12435],
        [ 9816],
        [10763],
        [11255],
        [ 7160],
        [ 6384],
        [ 6544],
        [ 7103]], device='cuda:0')
[2024-07-23 21:07:09,359][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[36904],
        [35527],
        [38733],
        [40671],
        [40162],
        [42017],
        [45461],
        [45415],
        [45155],
        [46060]], device='cuda:0')
[2024-07-23 21:07:09,362][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[32083],
        [11598],
        [ 8631],
        [ 6301],
        [ 4424],
        [ 2813],
        [ 6380],
        [ 4283],
        [ 4968],
        [ 4164]], device='cuda:0')
[2024-07-23 21:07:09,365][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[25034],
        [ 4390],
        [ 3799],
        [ 4182],
        [ 4124],
        [ 4271],
        [ 4281],
        [ 3785],
        [ 4243],
        [ 4107]], device='cuda:0')
[2024-07-23 21:07:09,368][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[ 1100],
        [13767],
        [16263],
        [13868],
        [12653],
        [13112],
        [13728],
        [ 9937],
        [12738],
        [11006]], device='cuda:0')
[2024-07-23 21:07:09,371][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[46456],
        [ 6169],
        [20768],
        [17471],
        [26690],
        [27850],
        [17145],
        [27530],
        [26193],
        [27097]], device='cuda:0')
[2024-07-23 21:07:09,374][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[35895],
        [31965],
        [28393],
        [13648],
        [19486],
        [10932],
        [16340],
        [15294],
        [13870],
        [14509]], device='cuda:0')
[2024-07-23 21:07:09,377][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[ 9029],
        [42192],
        [39324],
        [44305],
        [43465],
        [43501],
        [38347],
        [38972],
        [39568],
        [36791]], device='cuda:0')
[2024-07-23 21:07:09,380][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[25331],
        [40619],
        [39821],
        [38234],
        [34414],
        [33276],
        [34334],
        [33458],
        [30579],
        [32108]], device='cuda:0')
[2024-07-23 21:07:09,383][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[2729],
        [2729],
        [2729],
        [2729],
        [2729],
        [2729],
        [2729],
        [2729],
        [2729],
        [2729]], device='cuda:0')
[2024-07-23 21:07:09,465][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:09,467][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,468][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,468][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,469][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,470][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,473][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,476][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,482][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,483][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,484][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,485][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,485][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,486][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.9710, 0.0290], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,491][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,498][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.5272, 0.4728], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,504][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.0405, 0.9595], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,510][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.0183, 0.9817], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,511][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.0399, 0.9601], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,512][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.1200, 0.8800], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,512][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.0079, 0.9921], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,513][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.3385, 0.6615], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,518][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [izen] are: tensor([0.2350, 0.7650], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,525][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.0871, 0.9129], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,531][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [izen] are: tensor([0.0998, 0.9002], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,538][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.9397, 0.0362, 0.0241], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,538][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.0012, 0.8363, 0.1624], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,539][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.4514, 0.3855, 0.1631], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,540][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.0280, 0.7767, 0.1953], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,540][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.0150, 0.6407, 0.3443], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,545][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.0231, 0.3763, 0.6006], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,552][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.0234, 0.4000, 0.5766], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,559][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.0049, 0.4285, 0.5666], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,566][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.2313, 0.5689, 0.1998], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,566][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ is] are: tensor([0.1372, 0.4636, 0.3992], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,567][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.0485, 0.7744, 0.1771], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,568][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.0303, 0.4742, 0.4956], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:09,568][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.9567, 0.0177, 0.0105, 0.0152], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,573][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([0.0008, 0.6976, 0.1537, 0.1479], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,580][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.2083, 0.2773, 0.1307, 0.3837], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,587][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.0592, 0.5194, 0.2092, 0.2121], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,593][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.0029, 0.8081, 0.1022, 0.0867], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,594][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.0038, 0.3502, 0.4843, 0.1616], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,595][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.0113, 0.3480, 0.4935, 0.1472], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,596][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.0031, 0.3045, 0.4069, 0.2855], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,600][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.1027, 0.6482, 0.1300, 0.1191], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,606][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([0.1063, 0.3323, 0.2664, 0.2950], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,613][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.0379, 0.7307, 0.1192, 0.1122], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,619][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.0122, 0.5265, 0.2534, 0.2079], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:09,621][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.8278, 0.0118, 0.0055, 0.0073, 0.1476], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,622][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ by] are: tensor([0.0039, 0.5846, 0.1401, 0.1631, 0.1083], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,623][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.2451, 0.1799, 0.0921, 0.1856, 0.2974], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,624][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.0392, 0.5783, 0.1510, 0.1466, 0.0848], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,628][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.0075, 0.8893, 0.0223, 0.0283, 0.0527], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,634][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.0038, 0.4520, 0.1103, 0.1135, 0.3204], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,641][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.0259, 0.3129, 0.4211, 0.1236, 0.1164], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,647][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.0017, 0.2431, 0.2928, 0.2287, 0.2337], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,649][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.1941, 0.3369, 0.1932, 0.1575, 0.1184], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,650][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ by] are: tensor([0.0811, 0.2698, 0.2210, 0.2239, 0.2042], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,651][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.0780, 0.5467, 0.0968, 0.0741, 0.2043], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,651][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ by] are: tensor([0.0145, 0.4460, 0.1956, 0.1789, 0.1650], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:09,654][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3566, 0.0036, 0.0025, 0.0033, 0.0596, 0.5744], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,661][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0035, 0.4115, 0.1011, 0.1768, 0.1484, 0.1586], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,667][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1643, 0.2120, 0.0905, 0.1649, 0.2377, 0.1306], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,674][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0302, 0.6066, 0.1155, 0.1282, 0.0808, 0.0387], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,677][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0035, 0.9122, 0.0113, 0.0128, 0.0190, 0.0412], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,678][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0030, 0.6046, 0.0518, 0.0514, 0.1741, 0.1151], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,678][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0210, 0.2247, 0.3419, 0.1083, 0.0998, 0.2043], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,679][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0048, 0.2058, 0.2202, 0.1855, 0.1867, 0.1969], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,681][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0895, 0.3739, 0.1130, 0.1840, 0.1406, 0.0990], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,687][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0661, 0.1947, 0.1827, 0.1737, 0.1758, 0.2070], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,694][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0653, 0.4493, 0.0786, 0.0615, 0.1792, 0.1662], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,701][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0155, 0.4297, 0.1413, 0.1116, 0.1497, 0.1521], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:09,705][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.3471, 0.0051, 0.0022, 0.0033, 0.0605, 0.5804, 0.0014],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,706][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([0.0013, 0.5261, 0.1552, 0.1475, 0.0572, 0.0565, 0.0563],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,706][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.0723, 0.1778, 0.0677, 0.1350, 0.2088, 0.1366, 0.2017],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,707][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.0040, 0.7128, 0.1055, 0.1001, 0.0226, 0.0096, 0.0453],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,708][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([1.7697e-04, 9.3255e-01, 2.0893e-02, 1.6868e-02, 1.0543e-02, 1.5443e-02,
        3.5243e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,712][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([1.1912e-04, 6.1421e-01, 1.4974e-01, 3.4288e-02, 1.1267e-01, 6.6754e-02,
        2.2228e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,718][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.0290, 0.2680, 0.3359, 0.0891, 0.0803, 0.1287, 0.0688],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,725][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.0016, 0.1877, 0.2252, 0.1590, 0.1544, 0.1648, 0.1073],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,731][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([0.0675, 0.2687, 0.1383, 0.0585, 0.2530, 0.1427, 0.0713],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,733][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([0.0648, 0.1807, 0.1578, 0.1610, 0.1481, 0.1655, 0.1221],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,734][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.0120, 0.6360, 0.1034, 0.0618, 0.0901, 0.0630, 0.0336],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,734][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([0.0026, 0.4683, 0.1988, 0.1633, 0.0827, 0.0652, 0.0192],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:09,735][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.2493, 0.0074, 0.0038, 0.0056, 0.0830, 0.6118, 0.0019, 0.0371],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,736][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0013, 0.4940, 0.1094, 0.1176, 0.0889, 0.0704, 0.0627, 0.0557],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,741][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1064, 0.0815, 0.0663, 0.1762, 0.2076, 0.1418, 0.1547, 0.0656],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,748][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0246, 0.3103, 0.1313, 0.1756, 0.1277, 0.0703, 0.1069, 0.0534],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,754][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0062, 0.2051, 0.0082, 0.0161, 0.1117, 0.3949, 0.0471, 0.2108],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,761][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0011, 0.1558, 0.0283, 0.0257, 0.2924, 0.3001, 0.0991, 0.0975],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,761][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0176, 0.1951, 0.3048, 0.0930, 0.0605, 0.1199, 0.0832, 0.1260],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,762][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0012, 0.1387, 0.1641, 0.1439, 0.1518, 0.1721, 0.1244, 0.1039],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,763][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.1283, 0.2525, 0.1075, 0.1003, 0.0891, 0.1707, 0.1074, 0.0442],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,765][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0418, 0.1476, 0.1468, 0.1400, 0.1324, 0.1556, 0.0977, 0.1381],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,771][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0389, 0.2197, 0.0607, 0.0612, 0.2152, 0.2014, 0.0664, 0.1366],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,778][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0129, 0.2275, 0.1278, 0.1278, 0.1767, 0.2026, 0.0370, 0.0877],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:09,784][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.4446, 0.0043, 0.0015, 0.0022, 0.0527, 0.4781, 0.0007, 0.0140, 0.0018],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,788][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([0.0030, 0.4193, 0.1116, 0.1566, 0.0721, 0.0646, 0.0660, 0.0578, 0.0490],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,789][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.1416, 0.1068, 0.0687, 0.1182, 0.1861, 0.1053, 0.1076, 0.0558, 0.1100],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,790][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.0125, 0.5307, 0.0995, 0.1140, 0.0632, 0.0305, 0.0556, 0.0241, 0.0700],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,791][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.0011, 0.7901, 0.0087, 0.0115, 0.0320, 0.0937, 0.0123, 0.0281, 0.0223],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,792][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([1.4282e-04, 4.1005e-01, 6.2732e-02, 3.0450e-02, 2.0154e-01, 1.6672e-01,
        6.5046e-02, 4.3539e-02, 1.9785e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,798][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.0144, 0.1963, 0.3097, 0.0805, 0.0668, 0.1234, 0.0712, 0.0834, 0.0542],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,805][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([0.0011, 0.1439, 0.1615, 0.1276, 0.1268, 0.1453, 0.0967, 0.0885, 0.1085],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,811][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([0.1200, 0.1462, 0.1053, 0.0681, 0.1857, 0.1354, 0.0940, 0.0469, 0.0984],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,816][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([0.0423, 0.1438, 0.1231, 0.1254, 0.1124, 0.1229, 0.0926, 0.1122, 0.1253],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,816][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.0259, 0.4686, 0.0623, 0.0488, 0.1344, 0.1019, 0.0357, 0.0608, 0.0617],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,817][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([0.0075, 0.4363, 0.1161, 0.1295, 0.0918, 0.0892, 0.0231, 0.0438, 0.0627],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:09,818][circuit_model.py][line:1532][INFO] ##8-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.3117, 0.0042, 0.0017, 0.0028, 0.0643, 0.5749, 0.0010, 0.0216, 0.0023,
        0.0156], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,822][circuit_model.py][line:1535][INFO] ##8-th layer ##Weight##: The head2 weight for token [ including] are: tensor([0.0006, 0.4668, 0.0861, 0.1227, 0.0822, 0.0601, 0.0540, 0.0416, 0.0375,
        0.0484], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,828][circuit_model.py][line:1538][INFO] ##8-th layer ##Weight##: The head3 weight for token [ including] are: tensor([0.0685, 0.1145, 0.0548, 0.0985, 0.1758, 0.1126, 0.1090, 0.0619, 0.0996,
        0.1048], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,835][circuit_model.py][line:1541][INFO] ##8-th layer ##Weight##: The head4 weight for token [ including] are: tensor([0.0045, 0.5207, 0.0904, 0.1096, 0.0611, 0.0239, 0.0557, 0.0162, 0.0691,
        0.0486], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,841][circuit_model.py][line:1544][INFO] ##8-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.0018, 0.3738, 0.0059, 0.0117, 0.0589, 0.2014, 0.0215, 0.0640, 0.0534,
        0.2076], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,843][circuit_model.py][line:1547][INFO] ##8-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.0005, 0.3370, 0.0302, 0.0230, 0.1645, 0.1816, 0.0847, 0.0622, 0.0301,
        0.0862], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,844][circuit_model.py][line:1550][INFO] ##8-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.0105, 0.1828, 0.3422, 0.0666, 0.0590, 0.1188, 0.0521, 0.0742, 0.0404,
        0.0534], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,845][circuit_model.py][line:1553][INFO] ##8-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.0008, 0.1295, 0.1467, 0.1123, 0.1172, 0.1376, 0.0919, 0.0818, 0.1018,
        0.0804], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,845][circuit_model.py][line:1556][INFO] ##8-th layer ##Weight##: The head9 weight for token [ including] are: tensor([0.0375, 0.2307, 0.1048, 0.0932, 0.0888, 0.1903, 0.0756, 0.0603, 0.1095,
        0.0093], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,850][circuit_model.py][line:1559][INFO] ##8-th layer ##Weight##: The head10 weight for token [ including] are: tensor([0.0252, 0.1262, 0.1146, 0.1106, 0.1085, 0.1206, 0.0822, 0.1043, 0.1059,
        0.1019], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,857][circuit_model.py][line:1562][INFO] ##8-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.0163, 0.3193, 0.0511, 0.0421, 0.1510, 0.1285, 0.0439, 0.0732, 0.0721,
        0.1025], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,863][circuit_model.py][line:1565][INFO] ##8-th layer ##Weight##: The head12 weight for token [ including] are: tensor([0.0025, 0.4246, 0.0923, 0.0958, 0.1033, 0.1056, 0.0217, 0.0386, 0.0696,
        0.0460], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:09,961][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:09,963][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,965][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,968][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,971][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,975][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,979][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,983][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,986][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,988][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,989][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,989][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,990][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:09,991][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.9947, 0.0053], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:09,995][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,002][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.5272, 0.4728], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,008][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.0405, 0.9595], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,015][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.0183, 0.9817], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,016][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.2521, 0.7479], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,016][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([0.2367, 0.7633], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,017][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.0240, 0.9760], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,018][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.0295, 0.9705], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,022][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([0.2839, 0.7161], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,029][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.0871, 0.9129], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,035][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([0.0998, 0.9002], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,042][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.9787, 0.0101, 0.0111], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,043][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.0012, 0.8363, 0.1624], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,044][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.4514, 0.3855, 0.1631], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,044][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.0280, 0.7767, 0.1953], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,045][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0150, 0.6407, 0.3443], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,050][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.2525, 0.4509, 0.2966], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,057][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([0.5116, 0.3861, 0.1022], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,063][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.0727, 0.3347, 0.5926], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,069][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0103, 0.9246, 0.0651], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,070][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([0.1036, 0.7817, 0.1147], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,071][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.0485, 0.7744, 0.1771], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,072][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.0303, 0.4742, 0.4956], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,072][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([0.9781, 0.0083, 0.0073, 0.0062], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,077][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([0.0008, 0.6976, 0.1537, 0.1479], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,084][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([0.2083, 0.2773, 0.1307, 0.3837], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,090][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.0592, 0.5194, 0.2092, 0.2121], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,097][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.0029, 0.8081, 0.1022, 0.0867], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,097][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([0.1045, 0.6059, 0.1995, 0.0900], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,098][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([0.4979, 0.3923, 0.0737, 0.0360], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,099][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([0.0121, 0.6254, 0.2659, 0.0966], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,100][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.0063, 0.8787, 0.0571, 0.0580], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,104][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([0.0869, 0.7568, 0.0799, 0.0764], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,111][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([0.0379, 0.7307, 0.1192, 0.1122], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,117][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([0.0122, 0.5265, 0.2534, 0.2079], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,124][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([0.9212, 0.0045, 0.0035, 0.0029, 0.0679], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,125][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([0.0039, 0.5846, 0.1401, 0.1631, 0.1083], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,126][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([0.2451, 0.1799, 0.0921, 0.1856, 0.2974], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,126][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([0.0392, 0.5783, 0.1510, 0.1466, 0.0848], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,127][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.0075, 0.8893, 0.0223, 0.0283, 0.0527], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,133][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.3135, 0.5487, 0.0410, 0.0335, 0.0633], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,139][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([0.4886, 0.3794, 0.0412, 0.0292, 0.0616], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,146][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([0.0759, 0.8051, 0.0165, 0.0104, 0.0921], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,151][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.0101, 0.8564, 0.0371, 0.0652, 0.0312], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,152][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([0.0469, 0.6537, 0.0823, 0.0857, 0.1314], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,153][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.0780, 0.5467, 0.0968, 0.0741, 0.2043], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,154][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([0.0145, 0.4460, 0.1956, 0.1789, 0.1650], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,155][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4761, 0.0016, 0.0017, 0.0014, 0.0326, 0.4866], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,161][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0035, 0.4115, 0.1011, 0.1768, 0.1484, 0.1586], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,168][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1643, 0.2120, 0.0905, 0.1649, 0.2377, 0.1306], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,174][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0302, 0.6066, 0.1155, 0.1282, 0.0808, 0.0387], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,179][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0035, 0.9122, 0.0113, 0.0128, 0.0190, 0.0412], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,179][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1536, 0.7122, 0.0205, 0.0179, 0.0449, 0.0509], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,180][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6319, 0.1990, 0.0303, 0.0247, 0.0589, 0.0551], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,181][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0171, 0.9078, 0.0066, 0.0034, 0.0268, 0.0382], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,183][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0283, 0.8034, 0.0365, 0.0659, 0.0421, 0.0239], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,190][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0868, 0.6054, 0.0652, 0.0583, 0.0971, 0.0872], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,196][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0653, 0.4493, 0.0786, 0.0615, 0.1792, 0.1662], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,204][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0155, 0.4297, 0.1413, 0.1116, 0.1497, 0.1521], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,206][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([0.4299, 0.0026, 0.0018, 0.0016, 0.0359, 0.5273, 0.0008],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,207][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([0.0013, 0.5261, 0.1552, 0.1475, 0.0572, 0.0565, 0.0563],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,208][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([0.0723, 0.1778, 0.0677, 0.1350, 0.2088, 0.1366, 0.2017],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,208][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([0.0040, 0.7128, 0.1055, 0.1001, 0.0226, 0.0096, 0.0453],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,210][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([1.7697e-04, 9.3255e-01, 2.0893e-02, 1.6868e-02, 1.0543e-02, 1.5443e-02,
        3.5243e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,216][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([0.0025, 0.9233, 0.0389, 0.0130, 0.0122, 0.0087, 0.0015],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,223][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([0.5063, 0.2339, 0.0508, 0.0341, 0.0638, 0.0587, 0.0524],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,226][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([5.5229e-04, 9.5597e-01, 2.0182e-02, 5.4731e-03, 8.3411e-03, 9.0593e-03,
        4.2115e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,233][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([0.0049, 0.7977, 0.0728, 0.0606, 0.0347, 0.0135, 0.0159],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,234][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([0.0264, 0.6845, 0.0782, 0.0572, 0.0697, 0.0468, 0.0372],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,235][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([0.0120, 0.6360, 0.1034, 0.0618, 0.0901, 0.0630, 0.0336],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,236][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([0.0026, 0.4683, 0.1988, 0.1633, 0.0827, 0.0652, 0.0192],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,238][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3485, 0.0032, 0.0028, 0.0025, 0.0488, 0.5646, 0.0009, 0.0288],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,245][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0013, 0.4940, 0.1094, 0.1176, 0.0889, 0.0704, 0.0627, 0.0557],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,251][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1064, 0.0815, 0.0663, 0.1762, 0.2076, 0.1418, 0.1547, 0.0656],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,258][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0246, 0.3103, 0.1313, 0.1756, 0.1277, 0.0703, 0.1069, 0.0534],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,261][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0062, 0.2051, 0.0082, 0.0161, 0.1117, 0.3949, 0.0471, 0.2108],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,261][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.1527, 0.2069, 0.0197, 0.0206, 0.1587, 0.3068, 0.0330, 0.1016],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,262][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.3784, 0.2388, 0.0472, 0.0350, 0.0751, 0.0676, 0.0416, 0.1161],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,263][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0498, 0.0962, 0.0043, 0.0045, 0.1898, 0.5509, 0.0131, 0.0913],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,267][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0292, 0.6788, 0.0500, 0.0775, 0.0546, 0.0385, 0.0389, 0.0326],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,275][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0836, 0.3268, 0.0623, 0.0743, 0.1056, 0.1011, 0.0577, 0.1885],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,281][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0389, 0.2197, 0.0607, 0.0612, 0.2152, 0.2014, 0.0664, 0.1366],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,287][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0129, 0.2275, 0.1278, 0.1278, 0.1767, 0.2026, 0.0370, 0.0877],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,288][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([5.2121e-01, 2.5386e-03, 1.4424e-03, 1.3134e-03, 3.3755e-02, 4.2517e-01,
        4.9100e-04, 1.2927e-02, 1.1537e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,289][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([0.0030, 0.4193, 0.1116, 0.1566, 0.0721, 0.0646, 0.0660, 0.0578, 0.0490],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,290][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([0.1416, 0.1068, 0.0687, 0.1182, 0.1861, 0.1053, 0.1076, 0.0558, 0.1100],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,294][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([0.0125, 0.5307, 0.0995, 0.1140, 0.0632, 0.0305, 0.0556, 0.0241, 0.0700],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,300][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.0011, 0.7901, 0.0087, 0.0115, 0.0320, 0.0937, 0.0123, 0.0281, 0.0223],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,307][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([0.0151, 0.7676, 0.0247, 0.0159, 0.0611, 0.0691, 0.0094, 0.0184, 0.0187],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,313][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([0.4730, 0.1480, 0.0499, 0.0304, 0.0633, 0.0503, 0.0377, 0.0690, 0.0785],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,315][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([0.0021, 0.8652, 0.0055, 0.0035, 0.0325, 0.0715, 0.0034, 0.0091, 0.0071],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,315][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([0.0071, 0.8139, 0.0305, 0.0387, 0.0391, 0.0159, 0.0149, 0.0146, 0.0254],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,316][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([0.0426, 0.5418, 0.0662, 0.0506, 0.0717, 0.0511, 0.0257, 0.0979, 0.0526],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,317][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([0.0259, 0.4686, 0.0623, 0.0488, 0.1344, 0.1019, 0.0357, 0.0608, 0.0617],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,319][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([0.0075, 0.4363, 0.1161, 0.1295, 0.0918, 0.0892, 0.0231, 0.0438, 0.0627],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,322][circuit_model.py][line:1570][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([3.9771e-01, 2.0508e-03, 1.5492e-03, 1.4894e-03, 4.0530e-02, 5.2884e-01,
        5.1441e-04, 1.7969e-02, 1.2835e-03, 8.0629e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,329][circuit_model.py][line:1573][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([0.0006, 0.4668, 0.0861, 0.1227, 0.0822, 0.0601, 0.0540, 0.0416, 0.0375,
        0.0484], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,335][circuit_model.py][line:1576][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([0.0685, 0.1145, 0.0548, 0.0985, 0.1758, 0.1126, 0.1090, 0.0619, 0.0996,
        0.1048], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,342][circuit_model.py][line:1579][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([0.0045, 0.5207, 0.0904, 0.1096, 0.0611, 0.0239, 0.0557, 0.0162, 0.0691,
        0.0486], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,343][circuit_model.py][line:1582][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([0.0018, 0.3738, 0.0059, 0.0117, 0.0589, 0.2014, 0.0215, 0.0640, 0.0534,
        0.2076], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,344][circuit_model.py][line:1585][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([0.0655, 0.4446, 0.0139, 0.0146, 0.1036, 0.1703, 0.0203, 0.0427, 0.0530,
        0.0715], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,345][circuit_model.py][line:1588][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([0.3283, 0.3074, 0.0324, 0.0240, 0.0565, 0.0513, 0.0272, 0.0657, 0.0697,
        0.0374], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,349][circuit_model.py][line:1591][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([0.0050, 0.3171, 0.0035, 0.0030, 0.1308, 0.4018, 0.0078, 0.0340, 0.0368,
        0.0601], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,356][circuit_model.py][line:1594][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([0.0013, 0.8737, 0.0196, 0.0292, 0.0221, 0.0111, 0.0107, 0.0096, 0.0172,
        0.0056], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,362][circuit_model.py][line:1597][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([0.0207, 0.5724, 0.0440, 0.0413, 0.0631, 0.0523, 0.0242, 0.0812, 0.0457,
        0.0550], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,369][circuit_model.py][line:1600][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([0.0163, 0.3193, 0.0511, 0.0421, 0.1510, 0.1285, 0.0439, 0.0732, 0.0721,
        0.1025], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,370][circuit_model.py][line:1603][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([0.0025, 0.4246, 0.0923, 0.0958, 0.1033, 0.1056, 0.0217, 0.0386, 0.0696,
        0.0460], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,373][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:10,376][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[5697],
        [6495],
        [ 868],
        [2420],
        [ 610],
        [ 633],
        [1711],
        [1557],
        [2103],
        [ 945]], device='cuda:0')
[2024-07-23 21:07:10,379][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[ 5902],
        [10735],
        [ 2624],
        [ 5695],
        [ 1631],
        [ 2045],
        [ 5309],
        [ 3527],
        [ 5471],
        [ 2254]], device='cuda:0')
[2024-07-23 21:07:10,383][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[2400],
        [1851],
        [1502],
        [1716],
        [ 622],
        [2250],
        [2274],
        [2569],
        [2113],
        [2524]], device='cuda:0')
[2024-07-23 21:07:10,386][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[18815],
        [15395],
        [18363],
        [19122],
        [20316],
        [21900],
        [21798],
        [21213],
        [22246],
        [21964]], device='cuda:0')
[2024-07-23 21:07:10,389][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[ 4158],
        [47170],
        [46792],
        [42673],
        [38861],
        [39150],
        [37856],
        [32657],
        [36769],
        [35415]], device='cuda:0')
[2024-07-23 21:07:10,392][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[ 8139],
        [ 9973],
        [10733],
        [ 9317],
        [ 8948],
        [ 8938],
        [ 9583],
        [ 8259],
        [ 9338],
        [ 9362]], device='cuda:0')
[2024-07-23 21:07:10,395][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[39078],
        [19246],
        [26501],
        [21584],
        [20767],
        [21175],
        [20415],
        [45121],
        [25591],
        [41378]], device='cuda:0')
[2024-07-23 21:07:10,398][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[13284],
        [23419],
        [24759],
        [24834],
        [26743],
        [25571],
        [25111],
        [27769],
        [26214],
        [26689]], device='cuda:0')
[2024-07-23 21:07:10,400][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[7468],
        [4124],
        [3350],
        [3292],
        [2933],
        [2478],
        [2625],
        [2698],
        [2624],
        [2722]], device='cuda:0')
[2024-07-23 21:07:10,401][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[25429],
        [18474],
        [25196],
        [23611],
        [19897],
        [20577],
        [19897],
        [19004],
        [18307],
        [18252]], device='cuda:0')
[2024-07-23 21:07:10,403][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[16373],
        [   48],
        [   83],
        [   62],
        [  152],
        [  130],
        [  140],
        [  161],
        [  204],
        [  167]], device='cuda:0')
[2024-07-23 21:07:10,404][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[3169],
        [5126],
        [4212],
        [3984],
        [3613],
        [3302],
        [3741],
        [3958],
        [4706],
        [4474]], device='cuda:0')
[2024-07-23 21:07:10,406][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[40139],
        [ 1496],
        [ 1281],
        [ 1454],
        [ 1563],
        [ 1930],
        [ 1537],
        [ 4590],
        [ 1980],
        [ 2916]], device='cuda:0')
[2024-07-23 21:07:10,409][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[25627],
        [47672],
        [46822],
        [47316],
        [47596],
        [47746],
        [47630],
        [46789],
        [47743],
        [47757]], device='cuda:0')
[2024-07-23 21:07:10,412][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[16400],
        [16427],
        [13423],
        [15319],
        [15974],
        [14341],
        [ 9399],
        [15281],
        [11270],
        [16577]], device='cuda:0')
[2024-07-23 21:07:10,415][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[36607],
        [36395],
        [35181],
        [35334],
        [29502],
        [ 9825],
        [ 9485],
        [ 8900],
        [10033],
        [ 9169]], device='cuda:0')
[2024-07-23 21:07:10,418][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[3908],
        [2486],
        [2175],
        [2106],
        [1825],
        [1684],
        [1826],
        [1891],
        [2191],
        [2006]], device='cuda:0')
[2024-07-23 21:07:10,421][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[21973],
        [ 3037],
        [ 3436],
        [ 1988],
        [ 3491],
        [ 3446],
        [ 3211],
        [ 3705],
        [ 4833],
        [ 5286]], device='cuda:0')
[2024-07-23 21:07:10,424][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[33947],
        [16144],
        [18038],
        [21243],
        [20471],
        [20429],
        [18836],
        [22414],
        [20449],
        [20596]], device='cuda:0')
[2024-07-23 21:07:10,427][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 1712],
        [20383],
        [16843],
        [19575],
        [19893],
        [19720],
        [20069],
        [ 6072],
        [17299],
        [ 6410]], device='cuda:0')
[2024-07-23 21:07:10,430][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[19604],
        [25575],
        [17461],
        [20906],
        [22329],
        [25009],
        [26191],
        [16482],
        [25540],
        [21562]], device='cuda:0')
[2024-07-23 21:07:10,432][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[11322],
        [12541],
        [ 8629],
        [ 8317],
        [ 7594],
        [ 4999],
        [ 5709],
        [ 6025],
        [ 5013],
        [ 6504]], device='cuda:0')
[2024-07-23 21:07:10,433][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 1556],
        [15085],
        [18336],
        [17378],
        [15412],
        [15234],
        [15449],
        [15222],
        [15286],
        [14278]], device='cuda:0')
[2024-07-23 21:07:10,434][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[12970],
        [26406],
        [25999],
        [25329],
        [25163],
        [24808],
        [24789],
        [23775],
        [25061],
        [25513]], device='cuda:0')
[2024-07-23 21:07:10,436][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[21468],
        [36869],
        [37267],
        [37316],
        [37635],
        [37931],
        [37607],
        [37693],
        [37922],
        [38194]], device='cuda:0')
[2024-07-23 21:07:10,439][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[10322],
        [ 4868],
        [ 5069],
        [ 4996],
        [ 5839],
        [ 5630],
        [ 5431],
        [ 5475],
        [ 5946],
        [ 6081]], device='cuda:0')
[2024-07-23 21:07:10,442][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 3279],
        [14987],
        [24796],
        [22988],
        [26609],
        [26175],
        [25301],
        [27729],
        [25516],
        [25919]], device='cuda:0')
[2024-07-23 21:07:10,443][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[45370],
        [34075],
        [34743],
        [34207],
        [33725],
        [36310],
        [36432],
        [38357],
        [35169],
        [37342]], device='cuda:0')
[2024-07-23 21:07:10,446][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[29802],
        [29258],
        [29794],
        [29627],
        [28386],
        [29761],
        [34733],
        [32138],
        [33331],
        [28447]], device='cuda:0')
[2024-07-23 21:07:10,449][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[4317],
        [4317],
        [4317],
        [4317],
        [4317],
        [4317],
        [4317],
        [4317],
        [4317],
        [4317]], device='cuda:0')
[2024-07-23 21:07:10,551][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:10,553][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,555][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,558][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,561][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,565][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,569][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,573][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,578][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,578][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,579][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,580][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,580][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:10,584][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.1071, 0.8929], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,590][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.0011, 0.9989], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,597][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.6930, 0.3070], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,603][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.9924, 0.0076], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,605][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.9739, 0.0261], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,606][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.0178, 0.9822], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,606][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [izen] are: tensor([3.8692e-04, 9.9961e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,607][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.0101, 0.9899], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,608][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [izen] are: tensor([9.9942e-01, 5.8384e-04], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,611][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [izen] are: tensor([5.3443e-04, 9.9947e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,617][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.0115, 0.9885], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,624][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [izen] are: tensor([0.0064, 0.9936], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:10,630][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.0864, 0.4571, 0.4565], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,632][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ is] are: tensor([4.2019e-04, 9.0318e-01, 9.6397e-02], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,633][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ is] are: tensor([0.2757, 0.5363, 0.1879], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,634][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.9830, 0.0118, 0.0052], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,634][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.9138, 0.0365, 0.0497], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,637][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.0129, 0.8971, 0.0899], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,641][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ is] are: tensor([1.3190e-04, 8.8545e-01, 1.1442e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,647][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.0018, 0.8066, 0.1916], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,654][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.9843, 0.0117, 0.0040], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,658][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ is] are: tensor([4.7302e-05, 6.7211e-01, 3.2784e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,660][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.0045, 0.5778, 0.4177], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,660][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.0089, 0.6084, 0.3827], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:10,661][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.0345, 0.3435, 0.3403, 0.2817], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,662][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([0.0010, 0.8466, 0.0926, 0.0599], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,663][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([0.6879, 0.2158, 0.0709, 0.0254], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,669][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.9718, 0.0215, 0.0045, 0.0023], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,676][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.8887, 0.0278, 0.0373, 0.0462], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,682][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.0358, 0.8401, 0.0906, 0.0336], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,687][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([2.2215e-04, 7.7325e-01, 1.0837e-01, 1.1815e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,689][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([6.9177e-04, 7.2659e-01, 1.1471e-01, 1.5800e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,690][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.9701, 0.0173, 0.0044, 0.0082], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,691][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([8.0993e-05, 4.7299e-01, 3.5906e-01, 1.6788e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,691][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.0020, 0.6991, 0.1875, 0.1114], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,692][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.0034, 0.4876, 0.1822, 0.3268], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:10,698][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.0332, 0.2484, 0.2459, 0.2373, 0.2353], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,702][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ by] are: tensor([6.9237e-04, 7.0536e-01, 7.6969e-02, 4.4404e-02, 1.7258e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,709][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ by] are: tensor([0.2261, 0.3724, 0.1280, 0.0382, 0.2353], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,712][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ by] are: tensor([9.8866e-01, 9.3341e-03, 5.8448e-04, 3.9396e-04, 1.0244e-03],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,716][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.9020, 0.0172, 0.0246, 0.0322, 0.0240], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,717][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.0267, 0.7586, 0.1121, 0.0337, 0.0690], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,718][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ by] are: tensor([2.4716e-04, 5.5836e-01, 1.1271e-01, 1.2707e-01, 2.0162e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,719][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ by] are: tensor([7.5914e-04, 8.1043e-01, 5.0384e-02, 6.7853e-02, 7.0576e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,719][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.9558, 0.0220, 0.0042, 0.0076, 0.0104], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,721][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ by] are: tensor([1.4350e-04, 2.6802e-01, 3.4872e-01, 2.0686e-01, 1.7626e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,728][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.0086, 0.8063, 0.0302, 0.0220, 0.1329], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,734][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ by] are: tensor([0.0122, 0.2562, 0.1667, 0.3668, 0.1982], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:10,741][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0311, 0.2062, 0.1976, 0.1819, 0.2013, 0.1819], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,744][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0007, 0.4146, 0.0722, 0.0603, 0.1972, 0.2550], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,745][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2154, 0.2996, 0.1382, 0.0431, 0.1922, 0.1116], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,745][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.7368e-01, 2.2219e-02, 8.1820e-04, 5.2268e-04, 1.4420e-03, 1.3219e-03],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,746][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.7145, 0.0419, 0.0582, 0.0770, 0.0522, 0.0563], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,748][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0377, 0.7505, 0.0909, 0.0298, 0.0570, 0.0342], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,753][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.8929e-04, 4.5612e-01, 8.6852e-02, 1.2102e-01, 2.0728e-01, 1.2854e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,759][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0012, 0.7844, 0.0355, 0.0588, 0.0642, 0.0558], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,766][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.9718, 0.0083, 0.0023, 0.0037, 0.0049, 0.0090], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,769][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.5454e-05, 2.4360e-01, 2.4220e-01, 1.5179e-01, 1.7826e-01, 1.8408e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,771][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0025, 0.8360, 0.0109, 0.0086, 0.0478, 0.0942], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,772][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0075, 0.1974, 0.1402, 0.2636, 0.1988, 0.1924], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:10,773][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.0147, 0.1856, 0.1716, 0.1376, 0.1927, 0.1675, 0.1304],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,773][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([0.0008, 0.3352, 0.0851, 0.0635, 0.1293, 0.1231, 0.2630],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,778][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([0.1671, 0.3106, 0.1500, 0.0344, 0.2081, 0.0920, 0.0378],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,784][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.7275, 0.2482, 0.0101, 0.0044, 0.0051, 0.0031, 0.0015],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,791][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.6477, 0.0440, 0.0569, 0.0721, 0.0392, 0.0403, 0.0998],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,797][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([0.0370, 0.7472, 0.0988, 0.0361, 0.0286, 0.0215, 0.0309],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,798][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([2.1193e-04, 4.0898e-01, 1.4125e-01, 1.2940e-01, 1.5608e-01, 1.0886e-01,
        5.5218e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,799][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([1.0178e-04, 8.4230e-01, 5.1157e-02, 5.3006e-02, 2.7480e-02, 1.8753e-02,
        7.2023e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,800][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([0.8569, 0.0494, 0.0113, 0.0160, 0.0163, 0.0272, 0.0230],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,801][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([4.3334e-05, 4.2669e-01, 2.1826e-01, 1.3502e-01, 7.9501e-02, 8.9858e-02,
        5.0628e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,802][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([2.5316e-05, 9.4522e-01, 1.9508e-02, 9.4425e-03, 1.2497e-02, 1.2739e-02,
        5.6323e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,808][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([0.0063, 0.2747, 0.1390, 0.1756, 0.1137, 0.1539, 0.1368],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:10,815][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0191, 0.1564, 0.1235, 0.1467, 0.1271, 0.1377, 0.1252, 0.1644],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,821][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0007, 0.2533, 0.0699, 0.0400, 0.1299, 0.1955, 0.1885, 0.1220],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,826][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1217, 0.2726, 0.1494, 0.0640, 0.1666, 0.1005, 0.0504, 0.0748],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,826][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ of] are: tensor([9.8199e-01, 6.1821e-03, 5.7496e-04, 4.8817e-04, 2.7818e-03, 3.4938e-03,
        1.4167e-03, 3.0775e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,827][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.4884, 0.0396, 0.0744, 0.0964, 0.0530, 0.0597, 0.1247, 0.0636],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,828][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0256, 0.6533, 0.0909, 0.0450, 0.0453, 0.0343, 0.0322, 0.0733],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,829][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ of] are: tensor([1.5053e-04, 4.4620e-01, 8.5155e-02, 1.4242e-01, 1.2665e-01, 8.5174e-02,
        5.7096e-02, 5.7151e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,835][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0010, 0.5636, 0.0556, 0.0839, 0.1021, 0.1150, 0.0336, 0.0452],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,841][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.9573, 0.0061, 0.0025, 0.0040, 0.0048, 0.0105, 0.0071, 0.0076],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,845][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ of] are: tensor([3.2397e-05, 3.2602e-01, 1.9345e-01, 1.5226e-01, 1.0286e-01, 1.1294e-01,
        4.3976e-02, 6.8468e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,851][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0029, 0.0418, 0.0025, 0.0043, 0.1638, 0.6274, 0.0085, 0.1488],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,853][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0025, 0.1555, 0.1269, 0.2053, 0.1225, 0.1285, 0.1558, 0.1031],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:10,854][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.0115, 0.1338, 0.1132, 0.0869, 0.1424, 0.1284, 0.0836, 0.1776, 0.1226],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,855][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([0.0012, 0.1089, 0.0729, 0.0468, 0.1685, 0.1661, 0.2372, 0.1039, 0.0946],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,855][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([0.2152, 0.2724, 0.1074, 0.0280, 0.1816, 0.0742, 0.0322, 0.0751, 0.0139],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,860][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.9292, 0.0557, 0.0016, 0.0010, 0.0034, 0.0032, 0.0015, 0.0024, 0.0020],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,867][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.5267, 0.0298, 0.0551, 0.0784, 0.0406, 0.0440, 0.1128, 0.0501, 0.0626],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,873][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([0.0768, 0.5888, 0.0733, 0.0304, 0.0515, 0.0329, 0.0297, 0.0683, 0.0483],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,878][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([2.1760e-04, 2.8896e-01, 9.4673e-02, 1.1780e-01, 1.6319e-01, 1.1831e-01,
        5.5706e-02, 6.9618e-02, 9.1525e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,880][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([5.0694e-04, 7.8351e-01, 3.3390e-02, 4.5218e-02, 3.8928e-02, 3.6863e-02,
        1.2098e-02, 1.8620e-02, 3.0870e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,881][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([0.9458, 0.0104, 0.0026, 0.0047, 0.0050, 0.0096, 0.0067, 0.0064, 0.0088],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,882][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([5.0288e-05, 2.7551e-01, 1.5983e-01, 1.4532e-01, 1.0151e-01, 1.1858e-01,
        4.6710e-02, 8.9612e-02, 6.2892e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,882][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([4.4479e-04, 6.6107e-01, 7.6264e-03, 6.2484e-03, 7.5791e-02, 1.9725e-01,
        3.8588e-03, 2.6606e-02, 2.1102e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,887][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([0.0052, 0.1078, 0.0989, 0.1959, 0.1144, 0.1458, 0.1295, 0.1180, 0.0845],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:10,893][circuit_model.py][line:1532][INFO] ##9-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.0157, 0.1142, 0.0993, 0.0911, 0.1050, 0.1046, 0.0834, 0.1352, 0.1288,
        0.1226], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,897][circuit_model.py][line:1535][INFO] ##9-th layer ##Weight##: The head2 weight for token [ including] are: tensor([5.8390e-05, 2.5121e-01, 3.6708e-02, 3.5974e-02, 1.1994e-01, 1.3030e-01,
        1.2638e-01, 6.8848e-02, 8.1579e-02, 1.4899e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,903][circuit_model.py][line:1538][INFO] ##9-th layer ##Weight##: The head3 weight for token [ including] are: tensor([0.1262, 0.2169, 0.1550, 0.0416, 0.1910, 0.0972, 0.0415, 0.0769, 0.0205,
        0.0333], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,907][circuit_model.py][line:1541][INFO] ##9-th layer ##Weight##: The head4 weight for token [ including] are: tensor([0.9325, 0.0399, 0.0011, 0.0010, 0.0050, 0.0058, 0.0024, 0.0039, 0.0042,
        0.0043], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,908][circuit_model.py][line:1544][INFO] ##9-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.4228, 0.0447, 0.0661, 0.0930, 0.0456, 0.0516, 0.1195, 0.0461, 0.0567,
        0.0540], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,909][circuit_model.py][line:1547][INFO] ##9-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.0088, 0.6519, 0.0571, 0.0240, 0.0444, 0.0291, 0.0233, 0.0581, 0.0457,
        0.0577], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,910][circuit_model.py][line:1550][INFO] ##9-th layer ##Weight##: The head7 weight for token [ including] are: tensor([4.1922e-05, 4.6351e-01, 6.8587e-02, 8.2905e-02, 1.0683e-01, 6.3655e-02,
        3.4909e-02, 2.7420e-02, 6.7833e-02, 8.4303e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,912][circuit_model.py][line:1553][INFO] ##9-th layer ##Weight##: The head8 weight for token [ including] are: tensor([9.0199e-05, 7.3986e-01, 2.0573e-02, 3.0218e-02, 6.0839e-02, 5.5315e-02,
        1.0165e-02, 1.3364e-02, 4.0682e-02, 2.8895e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,919][circuit_model.py][line:1556][INFO] ##9-th layer ##Weight##: The head9 weight for token [ including] are: tensor([0.8589, 0.0346, 0.0060, 0.0101, 0.0126, 0.0238, 0.0137, 0.0145, 0.0175,
        0.0084], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,922][circuit_model.py][line:1559][INFO] ##9-th layer ##Weight##: The head10 weight for token [ including] are: tensor([1.7172e-05, 3.2113e-01, 1.5550e-01, 1.0025e-01, 7.2922e-02, 9.8910e-02,
        3.4829e-02, 5.3884e-02, 3.5404e-02, 1.2715e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,930][circuit_model.py][line:1562][INFO] ##9-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.0008, 0.1255, 0.0021, 0.0037, 0.1183, 0.4631, 0.0051, 0.0578, 0.0396,
        0.1841], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:10,935][circuit_model.py][line:1565][INFO] ##9-th layer ##Weight##: The head12 weight for token [ including] are: tensor([0.0019, 0.1067, 0.0699, 0.1628, 0.1097, 0.1428, 0.1069, 0.0988, 0.0934,
        0.1071], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,046][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:11,048][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,049][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,050][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,051][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,052][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,053][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,053][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,054][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,055][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,055][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,056][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,057][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,059][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.0035, 0.9965], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,061][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.0027, 0.9973], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,061][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.6334, 0.3666], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,062][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.5183, 0.4817], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,063][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,063][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.0178, 0.9822], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,064][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([3.8692e-04, 9.9961e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,065][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([0.0101, 0.9899], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,066][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.4184, 0.5816], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,066][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([5.3443e-04, 9.9947e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,068][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([0.0115, 0.9885], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,073][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([0.0064, 0.9936], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,080][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.0036, 0.9459, 0.0505], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,086][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([0.0018, 0.8748, 0.1234], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,088][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([0.0403, 0.5966, 0.3631], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,089][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.2586, 0.4468, 0.2945], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,089][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0023, 0.8826, 0.1150], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,090][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.0129, 0.8971, 0.0899], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,091][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([1.3190e-04, 8.8545e-01, 1.1442e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,097][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([0.0018, 0.8066, 0.1916], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,103][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0527, 0.8241, 0.1232], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,107][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([4.7302e-05, 6.7211e-01, 3.2784e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,114][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([0.0045, 0.5778, 0.4177], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,115][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([0.0089, 0.6084, 0.3827], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,116][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([0.0090, 0.9201, 0.0382, 0.0327], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,117][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([0.0024, 0.8198, 0.1096, 0.0682], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,118][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([0.0496, 0.6065, 0.2514, 0.0924], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,122][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.0754, 0.7053, 0.1474, 0.0719], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,128][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.0041, 0.8311, 0.1024, 0.0625], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,135][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([0.0358, 0.8401, 0.0906, 0.0336], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,138][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([2.2215e-04, 7.7325e-01, 1.0837e-01, 1.1815e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,142][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([6.9177e-04, 7.2659e-01, 1.1471e-01, 1.5800e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,143][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.0336, 0.7732, 0.0787, 0.1144], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,144][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([8.0993e-05, 4.7299e-01, 3.5906e-01, 1.6788e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,145][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([0.0020, 0.6991, 0.1875, 0.1114], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,145][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([0.0034, 0.4876, 0.1822, 0.3268], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,150][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([0.0074, 0.8206, 0.0315, 0.0524, 0.0880], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,157][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([0.0035, 0.6582, 0.1013, 0.0568, 0.1803], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,163][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([0.0105, 0.6905, 0.1277, 0.0527, 0.1187], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,170][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([0.2223, 0.7208, 0.0105, 0.0079, 0.0385], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,171][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.0178, 0.6910, 0.1542, 0.0968, 0.0402], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,172][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.0267, 0.7586, 0.1121, 0.0337, 0.0690], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,173][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([2.4716e-04, 5.5836e-01, 1.1271e-01, 1.2707e-01, 2.0162e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,173][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([7.5914e-04, 8.1043e-01, 5.0384e-02, 6.7853e-02, 7.0576e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,178][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.0355, 0.7484, 0.0476, 0.0672, 0.1014], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,183][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([1.4350e-04, 2.6802e-01, 3.4872e-01, 2.0686e-01, 1.7626e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,189][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([0.0086, 0.8063, 0.0302, 0.0220, 0.1329], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,194][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([0.0122, 0.2562, 0.1667, 0.3668, 0.1982], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,199][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0133, 0.7727, 0.0335, 0.0488, 0.0872, 0.0445], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,199][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0031, 0.3945, 0.0960, 0.0735, 0.1995, 0.2334], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,200][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0157, 0.5581, 0.1246, 0.0759, 0.1514, 0.0744], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,201][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0614, 0.8992, 0.0044, 0.0024, 0.0162, 0.0164], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,202][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0077, 0.6752, 0.1315, 0.1090, 0.0409, 0.0356], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,208][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0377, 0.7505, 0.0909, 0.0298, 0.0570, 0.0342], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,212][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.8929e-04, 4.5612e-01, 8.6852e-02, 1.2102e-01, 2.0728e-01, 1.2854e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,219][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0012, 0.7844, 0.0355, 0.0588, 0.0642, 0.0558], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,225][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0855, 0.5703, 0.0622, 0.0799, 0.1169, 0.0851], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,227][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([6.5454e-05, 2.4360e-01, 2.4220e-01, 1.5179e-01, 1.7826e-01, 1.8408e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,228][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0025, 0.8360, 0.0109, 0.0086, 0.0478, 0.0942], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,228][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0075, 0.1974, 0.1402, 0.2636, 0.1988, 0.1924], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,229][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([0.0079, 0.7176, 0.0419, 0.0591, 0.0823, 0.0439, 0.0473],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,233][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([0.0021, 0.3905, 0.0984, 0.0661, 0.1227, 0.1110, 0.2092],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,240][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([0.0054, 0.5943, 0.1565, 0.0843, 0.0820, 0.0434, 0.0341],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,244][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([2.5920e-04, 9.8701e-01, 6.6518e-03, 1.9819e-03, 2.8665e-03, 1.1550e-03,
        7.2383e-05], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,250][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([0.0040, 0.6399, 0.1228, 0.0977, 0.0164, 0.0130, 0.1062],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,255][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([0.0370, 0.7472, 0.0988, 0.0361, 0.0286, 0.0215, 0.0309],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,255][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([2.1193e-04, 4.0898e-01, 1.4125e-01, 1.2940e-01, 1.5608e-01, 1.0886e-01,
        5.5218e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,256][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([1.0178e-04, 8.4230e-01, 5.1157e-02, 5.3006e-02, 2.7480e-02, 1.8753e-02,
        7.2023e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,257][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([0.0230, 0.6631, 0.0722, 0.0720, 0.0671, 0.0513, 0.0513],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,258][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([4.3334e-05, 4.2669e-01, 2.1826e-01, 1.3502e-01, 7.9501e-02, 8.9858e-02,
        5.0628e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,261][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([2.5316e-05, 9.4522e-01, 1.9508e-02, 9.4425e-03, 1.2497e-02, 1.2739e-02,
        5.6323e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,267][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([0.0063, 0.2747, 0.1390, 0.1756, 0.1137, 0.1539, 0.1368],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,275][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0192, 0.5109, 0.0477, 0.1048, 0.1352, 0.0811, 0.0473, 0.0538],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,281][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0025, 0.2392, 0.0796, 0.0555, 0.1396, 0.1751, 0.1872, 0.1213],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,283][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0287, 0.2671, 0.1757, 0.1061, 0.1464, 0.1146, 0.0615, 0.0999],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,283][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.1363, 0.0807, 0.0034, 0.0050, 0.2097, 0.4814, 0.0121, 0.0714],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,284][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0042, 0.4235, 0.1466, 0.1500, 0.0347, 0.0359, 0.1774, 0.0277],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,285][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0256, 0.6533, 0.0909, 0.0450, 0.0453, 0.0343, 0.0322, 0.0733],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,287][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([1.5053e-04, 4.4620e-01, 8.5155e-02, 1.4242e-01, 1.2665e-01, 8.5174e-02,
        5.7096e-02, 5.7151e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,294][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0010, 0.5636, 0.0556, 0.0839, 0.1021, 0.1150, 0.0336, 0.0452],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,301][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0614, 0.3580, 0.0787, 0.1015, 0.1205, 0.1153, 0.0891, 0.0755],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,305][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([3.2397e-05, 3.2602e-01, 1.9345e-01, 1.5226e-01, 1.0286e-01, 1.1294e-01,
        4.3976e-02, 6.8468e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,310][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0029, 0.0418, 0.0025, 0.0043, 0.1638, 0.6274, 0.0085, 0.1488],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,311][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0025, 0.1555, 0.1269, 0.2053, 0.1225, 0.1285, 0.1558, 0.1031],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,312][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([0.0179, 0.5830, 0.0378, 0.0559, 0.1234, 0.0542, 0.0310, 0.0293, 0.0674],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,313][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([0.0035, 0.1438, 0.0830, 0.0572, 0.1615, 0.1468, 0.2112, 0.0991, 0.0941],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,317][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([0.0149, 0.4533, 0.1098, 0.0600, 0.1316, 0.0654, 0.0312, 0.0582, 0.0754],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,323][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([0.0053, 0.9224, 0.0035, 0.0019, 0.0252, 0.0332, 0.0013, 0.0033, 0.0040],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,330][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.0062, 0.3876, 0.1427, 0.1395, 0.0276, 0.0245, 0.2037, 0.0217, 0.0466],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,336][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([0.0768, 0.5888, 0.0733, 0.0304, 0.0515, 0.0329, 0.0297, 0.0683, 0.0483],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,338][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([2.1760e-04, 2.8896e-01, 9.4673e-02, 1.1780e-01, 1.6319e-01, 1.1831e-01,
        5.5706e-02, 6.9618e-02, 9.1525e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,339][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([5.0694e-04, 7.8351e-01, 3.3390e-02, 4.5218e-02, 3.8928e-02, 3.6863e-02,
        1.2098e-02, 1.8620e-02, 3.0870e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,340][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([0.0703, 0.4752, 0.0504, 0.0801, 0.0750, 0.0662, 0.0533, 0.0386, 0.0909],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,341][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([5.0288e-05, 2.7551e-01, 1.5983e-01, 1.4532e-01, 1.0151e-01, 1.1858e-01,
        4.6710e-02, 8.9612e-02, 6.2892e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,342][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([4.4479e-04, 6.6107e-01, 7.6264e-03, 6.2484e-03, 7.5791e-02, 1.9725e-01,
        3.8588e-03, 2.6606e-02, 2.1102e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,348][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([0.0052, 0.1078, 0.0989, 0.1959, 0.1144, 0.1458, 0.1295, 0.1180, 0.0845],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,355][circuit_model.py][line:1570][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([0.0008, 0.7767, 0.0189, 0.0379, 0.0708, 0.0275, 0.0134, 0.0129, 0.0297,
        0.0115], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,361][circuit_model.py][line:1573][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([0.0003, 0.2732, 0.0471, 0.0415, 0.1152, 0.1102, 0.1115, 0.0684, 0.0718,
        0.1608], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,365][circuit_model.py][line:1576][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([0.0020, 0.5423, 0.0836, 0.0599, 0.0983, 0.0538, 0.0269, 0.0488, 0.0500,
        0.0345], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,366][circuit_model.py][line:1579][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([0.0270, 0.3156, 0.0020, 0.0028, 0.1437, 0.3489, 0.0063, 0.0252, 0.0514,
        0.0771], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,367][circuit_model.py][line:1582][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([0.0028, 0.4946, 0.1259, 0.1146, 0.0214, 0.0220, 0.1614, 0.0108, 0.0243,
        0.0221], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,368][circuit_model.py][line:1585][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([0.0088, 0.6519, 0.0571, 0.0240, 0.0444, 0.0291, 0.0233, 0.0581, 0.0457,
        0.0577], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,369][circuit_model.py][line:1588][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([4.1922e-05, 4.6351e-01, 6.8587e-02, 8.2905e-02, 1.0683e-01, 6.3655e-02,
        3.4909e-02, 2.7420e-02, 6.7833e-02, 8.4303e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,373][circuit_model.py][line:1591][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([9.0199e-05, 7.3986e-01, 2.0573e-02, 3.0218e-02, 6.0839e-02, 5.5315e-02,
        1.0165e-02, 1.3364e-02, 4.0682e-02, 2.8895e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,380][circuit_model.py][line:1594][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([0.0061, 0.6897, 0.0335, 0.0481, 0.0596, 0.0433, 0.0290, 0.0207, 0.0478,
        0.0222], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,383][circuit_model.py][line:1597][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([1.7172e-05, 3.2113e-01, 1.5550e-01, 1.0025e-01, 7.2922e-02, 9.8910e-02,
        3.4829e-02, 5.3884e-02, 3.5404e-02, 1.2715e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,390][circuit_model.py][line:1600][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([0.0008, 0.1255, 0.0021, 0.0037, 0.1183, 0.4631, 0.0051, 0.0578, 0.0396,
        0.1841], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,393][circuit_model.py][line:1603][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([0.0019, 0.1067, 0.0699, 0.1628, 0.1097, 0.1428, 0.1069, 0.0988, 0.0934,
        0.1071], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,396][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:11,398][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[4322],
        [3029],
        [ 378],
        [ 828],
        [ 222],
        [ 164],
        [ 723],
        [ 361],
        [ 475],
        [ 119]], device='cuda:0')
[2024-07-23 21:07:11,401][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[4687],
        [4866],
        [ 780],
        [1390],
        [ 519],
        [ 367],
        [1280],
        [ 887],
        [1162],
        [ 458]], device='cuda:0')
[2024-07-23 21:07:11,404][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[3006],
        [1431],
        [6853],
        [3476],
        [5821],
        [6384],
        [7680],
        [6312],
        [6740],
        [6110]], device='cuda:0')
[2024-07-23 21:07:11,407][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[19260],
        [25553],
        [25556],
        [25847],
        [23616],
        [19236],
        [16224],
        [15790],
        [12289],
        [14201]], device='cuda:0')
[2024-07-23 21:07:11,410][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[6431],
        [1638],
        [2225],
        [1839],
        [2318],
        [2550],
        [2183],
        [2144],
        [2045],
        [2040]], device='cuda:0')
[2024-07-23 21:07:11,413][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[28826],
        [29310],
        [29891],
        [30604],
        [29525],
        [30427],
        [43770],
        [29708],
        [33049],
        [32660]], device='cuda:0')
[2024-07-23 21:07:11,416][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[ 657],
        [ 812],
        [1814],
        [1576],
        [1231],
        [3944],
        [3928],
        [5777],
        [5240],
        [6626]], device='cuda:0')
[2024-07-23 21:07:11,419][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[14950],
        [  991],
        [  930],
        [  926],
        [  899],
        [  935],
        [  964],
        [ 1179],
        [ 1281],
        [ 1315]], device='cuda:0')
[2024-07-23 21:07:11,422][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[33151],
        [14401],
        [14377],
        [14676],
        [17624],
        [20646],
        [19701],
        [18922],
        [22665],
        [21117]], device='cuda:0')
[2024-07-23 21:07:11,424][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[16178],
        [37409],
        [33809],
        [31546],
        [34248],
        [33205],
        [34463],
        [26562],
        [33246],
        [32337]], device='cuda:0')
[2024-07-23 21:07:11,425][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[49246],
        [49295],
        [49898],
        [50096],
        [50166],
        [50038],
        [50246],
        [50075],
        [50138],
        [50230]], device='cuda:0')
[2024-07-23 21:07:11,427][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[41270],
        [42503],
        [42387],
        [40364],
        [37114],
        [36579],
        [39898],
        [37919],
        [36995],
        [37471]], device='cuda:0')
[2024-07-23 21:07:11,428][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[20896],
        [27120],
        [25365],
        [25666],
        [26128],
        [25959],
        [26829],
        [14543],
        [24222],
        [16120]], device='cuda:0')
[2024-07-23 21:07:11,431][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[31643],
        [18259],
        [20571],
        [23365],
        [26275],
        [27005],
        [26723],
        [26536],
        [26952],
        [27463]], device='cuda:0')
[2024-07-23 21:07:11,434][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[12677],
        [11666],
        [14331],
        [13840],
        [10500],
        [11103],
        [12941],
        [11751],
        [10861],
        [ 8913]], device='cuda:0')
[2024-07-23 21:07:11,437][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 9450],
        [31642],
        [32057],
        [31788],
        [32032],
        [32317],
        [33502],
        [33989],
        [34151],
        [33056]], device='cuda:0')
[2024-07-23 21:07:11,440][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[12190],
        [ 5185],
        [ 4663],
        [ 4786],
        [ 5030],
        [ 4914],
        [ 8304],
        [ 7111],
        [ 7409],
        [ 5794]], device='cuda:0')
[2024-07-23 21:07:11,443][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[ 6295],
        [23715],
        [26639],
        [26150],
        [26029],
        [26644],
        [26246],
        [28941],
        [27620],
        [27124]], device='cuda:0')
[2024-07-23 21:07:11,446][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[2179],
        [ 172],
        [ 558],
        [1199],
        [ 740],
        [1228],
        [1419],
        [1790],
        [1414],
        [1430]], device='cuda:0')
[2024-07-23 21:07:11,449][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 2032],
        [ 9782],
        [10226],
        [10201],
        [10562],
        [10740],
        [10955],
        [11952],
        [12007],
        [11622]], device='cuda:0')
[2024-07-23 21:07:11,452][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[10735],
        [ 5993],
        [ 6013],
        [ 6030],
        [ 6311],
        [ 6381],
        [ 6303],
        [ 7144],
        [ 7743],
        [ 7944]], device='cuda:0')
[2024-07-23 21:07:11,455][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[22494],
        [11369],
        [10221],
        [ 8586],
        [ 5885],
        [ 5738],
        [ 5017],
        [ 5292],
        [ 4420],
        [ 4819]], device='cuda:0')
[2024-07-23 21:07:11,456][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[16027],
        [28832],
        [26220],
        [26166],
        [27691],
        [28111],
        [27928],
        [26243],
        [28221],
        [28478]], device='cuda:0')
[2024-07-23 21:07:11,457][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[14449],
        [24701],
        [25946],
        [26094],
        [25142],
        [24382],
        [24995],
        [23492],
        [23213],
        [23924]], device='cuda:0')
[2024-07-23 21:07:11,458][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[14632],
        [ 7515],
        [ 8264],
        [10726],
        [16385],
        [16627],
        [10971],
        [13399],
        [14176],
        [11279]], device='cuda:0')
[2024-07-23 21:07:11,460][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[14172],
        [18699],
        [17390],
        [18902],
        [18118],
        [18739],
        [18666],
        [29541],
        [19360],
        [27020]], device='cuda:0')
[2024-07-23 21:07:11,463][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 5659],
        [11662],
        [ 8573],
        [ 9502],
        [ 8742],
        [ 8289],
        [ 8447],
        [ 9035],
        [ 9062],
        [ 9472]], device='cuda:0')
[2024-07-23 21:07:11,466][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[47793],
        [43971],
        [44288],
        [43297],
        [43674],
        [42894],
        [42432],
        [37919],
        [41012],
        [40398]], device='cuda:0')
[2024-07-23 21:07:11,469][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[36296],
        [41211],
        [35240],
        [35106],
        [35709],
        [37583],
        [35774],
        [40144],
        [38227],
        [37184]], device='cuda:0')
[2024-07-23 21:07:11,472][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[2503],
        [2503],
        [2503],
        [2503],
        [2503],
        [2503],
        [2503],
        [2503],
        [2503],
        [2503]], device='cuda:0')
[2024-07-23 21:07:11,576][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:11,576][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,577][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,578][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,578][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,579][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,580][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,580][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,581][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,582][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,582][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,583][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,584][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:11,588][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.1155, 0.8845], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,592][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.0182, 0.9818], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,592][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,593][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.0144, 0.9856], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,594][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.0414, 0.9586], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,595][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [izen] are: tensor([0.6810, 0.3190], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,599][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.0215, 0.9785], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,604][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [izen] are: tensor([5.7014e-05, 9.9994e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,610][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.0039, 0.9961], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,614][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [izen] are: tensor([2.7713e-04, 9.9972e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,619][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.6590, 0.3410], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,620][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [izen] are: tensor([9.9998e-01, 1.6127e-05], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:11,620][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.0146, 0.3502, 0.6352], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,621][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ is] are: tensor([0.0013, 0.7181, 0.2806], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,622][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ is] are: tensor([8.5476e-05, 5.3001e-01, 4.6991e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,626][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.0042, 0.3556, 0.6402], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,633][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.0209, 0.5948, 0.3843], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,639][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ is] are: tensor([0.3268, 0.3541, 0.3191], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,646][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.0048, 0.3363, 0.6589], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,647][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ is] are: tensor([3.9151e-06, 9.6006e-01, 3.9938e-02], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,648][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.0010, 0.4802, 0.5188], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,648][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ is] are: tensor([2.3511e-04, 2.5048e-01, 7.4929e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,649][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.0572, 0.9333, 0.0095], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,651][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ is] are: tensor([9.9966e-01, 1.4567e-04, 1.9350e-04], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:11,658][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.0203, 0.3581, 0.5845, 0.0371], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,661][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([4.7197e-04, 6.4444e-01, 2.2989e-01, 1.2520e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,666][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([5.8710e-05, 3.9201e-01, 4.2595e-01, 1.8199e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,672][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.0062, 0.2506, 0.3848, 0.3584], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,674][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.0079, 0.3930, 0.2804, 0.3187], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,674][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([0.1950, 0.2565, 0.1313, 0.4173], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,675][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.0028, 0.2177, 0.4520, 0.3275], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,676][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([1.0688e-05, 8.1965e-01, 5.3087e-02, 1.2725e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,680][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.0009, 0.4312, 0.3206, 0.2474], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,683][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([9.0824e-05, 3.8980e-01, 4.1514e-01, 1.9498e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,690][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.0254, 0.9502, 0.0076, 0.0168], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,694][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([9.9943e-01, 1.3837e-04, 1.7211e-04, 2.6402e-04], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:11,701][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.0112, 0.2632, 0.4353, 0.0324, 0.2580], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,701][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ by] are: tensor([3.9979e-04, 3.7979e-01, 1.3383e-01, 7.4982e-02, 4.1100e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,702][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ by] are: tensor([1.4996e-04, 3.7890e-01, 3.4031e-01, 1.8918e-01, 9.1459e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,703][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.0056, 0.1598, 0.2542, 0.3192, 0.2611], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,704][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.0124, 0.3430, 0.2232, 0.3307, 0.0908], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,707][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ by] are: tensor([0.2828, 0.0583, 0.0150, 0.0776, 0.5663], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,708][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.0021, 0.1700, 0.3288, 0.2462, 0.2529], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,712][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ by] are: tensor([1.8360e-05, 7.4387e-01, 5.1304e-02, 1.4848e-01, 5.6324e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,716][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ by] are: tensor([2.4290e-04, 6.8879e-02, 9.3287e-02, 8.8857e-02, 7.4873e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,720][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ by] are: tensor([3.8502e-04, 8.0851e-01, 4.0875e-02, 1.6559e-02, 1.3367e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,727][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.0485, 0.9187, 0.0078, 0.0187, 0.0064], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,729][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ by] are: tensor([9.9520e-01, 5.7410e-04, 9.8289e-04, 8.6920e-04, 2.3731e-03],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:11,730][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0156, 0.2367, 0.3364, 0.0320, 0.1662, 0.2131], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,731][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.9776e-04, 3.7945e-01, 9.1762e-02, 5.4107e-02, 2.9497e-01, 1.7951e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,731][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.7276e-05, 3.0631e-01, 2.8396e-01, 1.1177e-01, 6.7206e-02, 2.3066e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,732][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0010, 0.0607, 0.0868, 0.1162, 0.0872, 0.6480], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,738][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0111, 0.2421, 0.1632, 0.2386, 0.0719, 0.2732], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,745][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1912, 0.0468, 0.0097, 0.0628, 0.4226, 0.2668], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,752][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0028, 0.1360, 0.2412, 0.1787, 0.1874, 0.2538], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,756][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.6109e-05, 7.5984e-01, 4.6344e-02, 9.4196e-02, 4.1003e-02, 5.8599e-02],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,757][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.6155e-04, 7.8983e-02, 8.8692e-02, 4.9199e-02, 5.1860e-01, 2.6436e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,758][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([5.4659e-04, 8.4617e-01, 1.4478e-02, 3.4069e-03, 3.3107e-02, 1.0229e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,759][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0302, 0.9288, 0.0078, 0.0194, 0.0071, 0.0068], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,760][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.9860e-01, 5.0681e-05, 1.5127e-04, 1.2376e-04, 3.9012e-04, 6.8445e-04],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:11,761][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.0026, 0.1866, 0.4045, 0.0212, 0.1730, 0.2048, 0.0072],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,765][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([1.7883e-04, 3.4564e-01, 9.9040e-02, 5.3456e-02, 2.7075e-01, 1.5041e-01,
        8.0529e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,770][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([2.2493e-05, 3.2334e-01, 2.7702e-01, 1.3320e-01, 3.7081e-02, 1.5094e-01,
        7.8404e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,776][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.0013, 0.0639, 0.1350, 0.1167, 0.0849, 0.4061, 0.1921],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,783][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.0036, 0.2089, 0.1441, 0.1788, 0.0566, 0.2391, 0.1688],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,786][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([0.0349, 0.1005, 0.0319, 0.1174, 0.4474, 0.2156, 0.0523],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,787][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.0012, 0.1113, 0.2231, 0.1592, 0.1633, 0.2404, 0.1015],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,787][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([1.1541e-05, 5.3366e-01, 7.4965e-02, 1.1596e-01, 8.0219e-02, 1.1071e-01,
        8.4463e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,788][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([1.9557e-04, 4.8253e-02, 5.7272e-02, 5.2611e-02, 2.7860e-01, 1.9407e-01,
        3.6900e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,789][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([7.2037e-07, 7.7784e-01, 1.5103e-01, 3.4546e-02, 1.2803e-02, 2.3530e-02,
        2.4795e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,794][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.0280, 0.8952, 0.0095, 0.0187, 0.0064, 0.0071, 0.0351],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,798][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([9.9664e-01, 8.3698e-05, 2.2359e-04, 2.2835e-04, 4.9182e-04, 2.1042e-03,
        2.3296e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:11,804][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0143, 0.1839, 0.3047, 0.0349, 0.1382, 0.2269, 0.0138, 0.0834],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,809][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ of] are: tensor([2.0016e-04, 2.9881e-01, 9.7505e-02, 4.8088e-02, 2.5088e-01, 1.3172e-01,
        7.3793e-02, 9.8999e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,813][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ of] are: tensor([2.3237e-05, 2.2691e-01, 2.5019e-01, 1.3162e-01, 5.0019e-02, 1.4791e-01,
        8.6339e-02, 1.0699e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,815][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0005, 0.0491, 0.0883, 0.1021, 0.0737, 0.4551, 0.1588, 0.0724],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,815][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0065, 0.1981, 0.1194, 0.1870, 0.0517, 0.2059, 0.1980, 0.0335],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,816][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.1084, 0.0125, 0.0037, 0.0232, 0.3283, 0.2892, 0.0443, 0.1905],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,817][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0011, 0.0996, 0.1947, 0.1405, 0.1464, 0.2217, 0.0896, 0.1065],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,819][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ of] are: tensor([1.2528e-06, 5.9900e-01, 5.4326e-02, 1.5275e-01, 4.3860e-02, 8.1448e-02,
        4.8762e-02, 1.9856e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,824][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ of] are: tensor([1.1287e-05, 5.7966e-02, 6.2563e-02, 3.5102e-02, 2.6980e-01, 1.6325e-01,
        2.2161e-01, 1.8970e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,827][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ of] are: tensor([1.1658e-04, 9.7979e-03, 1.1899e-03, 7.6404e-04, 9.2519e-02, 8.8232e-01,
        8.2500e-04, 1.2464e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,835][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0253, 0.8908, 0.0084, 0.0170, 0.0057, 0.0054, 0.0334, 0.0141],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,841][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.9469, 0.0013, 0.0049, 0.0034, 0.0066, 0.0223, 0.0034, 0.0111],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:11,843][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.0048, 0.2010, 0.3211, 0.0254, 0.1518, 0.1935, 0.0093, 0.0523, 0.0406],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,844][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([1.9991e-04, 2.2862e-01, 6.9977e-02, 4.2106e-02, 2.3235e-01, 1.3006e-01,
        6.2386e-02, 9.7012e-02, 1.3729e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,845][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([4.7745e-05, 2.5954e-01, 2.0874e-01, 9.2665e-02, 5.5144e-02, 1.1634e-01,
        4.9982e-02, 9.8866e-02, 1.1868e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,845][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.0017, 0.0626, 0.0907, 0.0746, 0.0757, 0.3791, 0.1387, 0.0678, 0.1092],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,850][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.0033, 0.1628, 0.1019, 0.1394, 0.0460, 0.1844, 0.1497, 0.0277, 0.1847],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,858][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([0.0565, 0.0328, 0.0084, 0.0482, 0.3475, 0.2284, 0.0498, 0.1378, 0.0906],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,864][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.0013, 0.0923, 0.1762, 0.1278, 0.1331, 0.1934, 0.0832, 0.0954, 0.0973],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,869][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([2.6284e-05, 4.9681e-01, 5.5132e-02, 1.1834e-01, 8.0472e-02, 7.6349e-02,
        3.5795e-02, 3.4175e-02, 1.0290e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,871][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([9.1548e-05, 3.1726e-02, 4.4829e-02, 3.0567e-02, 2.6668e-01, 1.6075e-01,
        1.8709e-01, 1.9429e-01, 8.3977e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,872][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([7.0212e-06, 5.1603e-01, 1.0141e-02, 3.6515e-03, 6.9323e-02, 3.8749e-01,
        1.0919e-03, 3.4957e-03, 8.7607e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,873][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.0211, 0.8975, 0.0061, 0.0135, 0.0048, 0.0050, 0.0241, 0.0111, 0.0168],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,873][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([9.9578e-01, 5.7005e-05, 1.1656e-04, 1.7142e-04, 4.7297e-04, 1.9859e-03,
        1.7614e-04, 9.2055e-04, 3.1724e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:11,876][circuit_model.py][line:1532][INFO] ##10-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.0029, 0.2166, 0.2387, 0.0285, 0.1231, 0.1756, 0.0119, 0.0481, 0.0445,
        0.1101], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,881][circuit_model.py][line:1535][INFO] ##10-th layer ##Weight##: The head2 weight for token [ including] are: tensor([7.0123e-05, 2.5631e-01, 5.3667e-02, 2.8180e-02, 1.6718e-01, 9.2635e-02,
        4.5188e-02, 6.7203e-02, 1.2459e-01, 1.6498e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,884][circuit_model.py][line:1538][INFO] ##10-th layer ##Weight##: The head3 weight for token [ including] are: tensor([1.5616e-05, 2.3884e-01, 1.9210e-01, 7.3628e-02, 3.2874e-02, 1.1363e-01,
        5.6346e-02, 7.8578e-02, 1.1077e-01, 1.0322e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,889][circuit_model.py][line:1541][INFO] ##10-th layer ##Weight##: The head4 weight for token [ including] are: tensor([3.0090e-04, 3.3051e-02, 7.1703e-02, 7.6622e-02, 6.6961e-02, 3.7620e-01,
        1.0275e-01, 5.7335e-02, 1.0433e-01, 1.1074e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,895][circuit_model.py][line:1544][INFO] ##10-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.0033, 0.1415, 0.0940, 0.1340, 0.0368, 0.1706, 0.1312, 0.0215, 0.1673,
        0.0999], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,900][circuit_model.py][line:1547][INFO] ##10-th layer ##Weight##: The head6 weight for token [ including] are: tensor([0.0369, 0.0307, 0.0068, 0.0391, 0.3123, 0.1909, 0.0368, 0.1265, 0.0708,
        0.1491], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,901][circuit_model.py][line:1550][INFO] ##10-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.0007, 0.0780, 0.1567, 0.1145, 0.1167, 0.1765, 0.0737, 0.0833, 0.0870,
        0.1128], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,901][circuit_model.py][line:1553][INFO] ##10-th layer ##Weight##: The head8 weight for token [ including] are: tensor([2.0415e-06, 6.8924e-01, 3.8119e-02, 6.8863e-02, 3.3889e-02, 5.2635e-02,
        2.1425e-02, 1.2906e-02, 3.8828e-02, 4.4091e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,902][circuit_model.py][line:1556][INFO] ##10-th layer ##Weight##: The head9 weight for token [ including] are: tensor([1.4611e-05, 1.9532e-02, 2.4193e-02, 1.9204e-02, 2.6265e-01, 1.3750e-01,
        1.5801e-01, 1.8343e-01, 8.1016e-02, 1.1445e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,904][circuit_model.py][line:1559][INFO] ##10-th layer ##Weight##: The head10 weight for token [ including] are: tensor([1.7199e-05, 1.5059e-02, 3.1493e-04, 1.9153e-04, 5.9066e-02, 8.8872e-01,
        2.7658e-04, 3.8895e-03, 7.1280e-03, 2.5342e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,910][circuit_model.py][line:1562][INFO] ##10-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.0085, 0.9403, 0.0032, 0.0075, 0.0025, 0.0026, 0.0160, 0.0069, 0.0104,
        0.0021], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:11,915][circuit_model.py][line:1565][INFO] ##10-th layer ##Weight##: The head12 weight for token [ including] are: tensor([9.9769e-01, 6.1419e-05, 1.2135e-04, 8.7838e-05, 1.3706e-04, 1.2366e-03,
        1.0193e-04, 3.5750e-04, 1.5867e-04, 4.3260e-05], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,030][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:12,035][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,038][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,042][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,046][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,046][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,047][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,048][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,050][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,053][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,058][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,063][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,069][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,072][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([4.9288e-05, 9.9995e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,074][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([2.6848e-06, 1.0000e+00], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,075][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,075][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.0014, 0.9986], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,076][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([0.3733, 0.6267], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,078][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([0.0081, 0.9919], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,081][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([1.5516e-04, 9.9984e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,086][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([4.4929e-05, 9.9996e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,092][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.0039, 0.9961], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,097][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([2.7713e-04, 9.9972e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,100][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([7.1119e-05, 9.9993e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,102][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([3.8747e-05, 9.9996e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,103][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([9.0829e-07, 8.1636e-01, 1.8364e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,103][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([2.9736e-07, 4.8835e-01, 5.1165e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,104][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([8.5476e-05, 5.3001e-01, 4.6991e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,105][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([0.0024, 0.4595, 0.5381], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,109][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([0.0029, 0.4198, 0.5774], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,116][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([0.0019, 0.1538, 0.8444], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,120][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([1.1780e-06, 3.0093e-01, 6.9907e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,124][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([3.4170e-06, 9.7439e-01, 2.5606e-02], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,129][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([0.0010, 0.4802, 0.5188], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,130][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([2.3511e-04, 2.5048e-01, 7.4929e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,131][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([6.4908e-06, 9.9719e-01, 2.8015e-03], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,132][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([1.7235e-06, 7.5884e-01, 2.4116e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,132][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([6.4877e-07, 7.5222e-01, 1.9604e-01, 5.1742e-02], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,134][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([5.0575e-07, 2.7480e-01, 4.2110e-01, 3.0410e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,139][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([5.8710e-05, 3.9201e-01, 4.2595e-01, 1.8199e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,145][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([0.0009, 0.3702, 0.3642, 0.2646], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,152][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([0.0014, 0.4546, 0.4644, 0.0797], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,157][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([0.0013, 0.1986, 0.6131, 0.1870], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,157][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([1.6046e-06, 2.0197e-01, 6.4725e-01, 1.5078e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,158][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([8.8554e-06, 9.0828e-01, 3.4049e-02, 5.7660e-02], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,159][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.0009, 0.4312, 0.3206, 0.2474], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,160][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([9.0824e-05, 3.8980e-01, 4.1514e-01, 1.9498e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,162][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([8.8286e-06, 9.8757e-01, 4.7736e-03, 7.6511e-03], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,166][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([8.2685e-06, 4.9253e-01, 3.7406e-01, 1.3341e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,169][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([1.1602e-06, 6.6706e-01, 1.3024e-01, 5.5963e-02, 1.4674e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,174][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([5.1396e-07, 2.0842e-01, 2.4346e-01, 2.0098e-01, 3.4714e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,177][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([1.4996e-04, 3.7890e-01, 3.4031e-01, 1.8918e-01, 9.1459e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,184][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([0.0050, 0.2116, 0.2455, 0.3071, 0.2308], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,185][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([0.0055, 0.2589, 0.3641, 0.0621, 0.3094], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,186][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([0.0160, 0.5393, 0.0810, 0.0238, 0.3399], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,186][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([1.8311e-06, 2.2259e-01, 4.3371e-01, 1.4004e-01, 2.0366e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,187][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([2.4333e-05, 8.4672e-01, 4.7598e-02, 5.6207e-02, 4.9450e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,189][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([2.4290e-04, 6.8879e-02, 9.3287e-02, 8.8857e-02, 7.4873e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,193][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([3.8502e-04, 8.0851e-01, 4.0875e-02, 1.6559e-02, 1.3367e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,197][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([3.1083e-05, 9.8595e-01, 4.8022e-03, 8.0551e-03, 1.1615e-03],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,201][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([3.4887e-05, 3.9749e-01, 2.6603e-01, 7.6868e-02, 2.5958e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,205][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.1244e-06, 6.6246e-01, 8.7003e-02, 4.6118e-02, 9.7254e-02, 1.0716e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,209][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.5135e-07, 2.2030e-01, 1.3135e-01, 1.0904e-01, 2.7010e-01, 2.6922e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,212][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.7276e-05, 3.0631e-01, 2.8396e-01, 1.1177e-01, 6.7206e-02, 2.3066e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,212][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0014, 0.1313, 0.1074, 0.1039, 0.0770, 0.5790], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,213][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0012, 0.1252, 0.1499, 0.0305, 0.1807, 0.5126], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,214][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0035, 0.3514, 0.0228, 0.0087, 0.1195, 0.4940], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,215][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.0157e-06, 1.4350e-01, 2.5437e-01, 1.0442e-01, 1.8078e-01, 3.1693e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,219][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.6255e-05, 8.4650e-01, 4.2627e-02, 3.9799e-02, 3.5200e-02, 3.5850e-02],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,223][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.6155e-04, 7.8983e-02, 8.8692e-02, 4.9199e-02, 5.1860e-01, 2.6436e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,227][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([5.4659e-04, 8.4617e-01, 1.4478e-02, 3.4069e-03, 3.3107e-02, 1.0229e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,231][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([3.3419e-05, 9.8657e-01, 3.4323e-03, 6.8784e-03, 1.0730e-03, 2.0144e-03],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,234][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.6932e-06, 5.4289e-01, 1.8149e-01, 7.9880e-02, 1.0751e-01, 8.8220e-02],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,239][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([1.1857e-07, 4.7414e-01, 1.8347e-01, 6.0814e-02, 9.8547e-02, 1.6107e-01,
        2.1969e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,239][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([8.9790e-08, 1.3113e-01, 1.5334e-01, 1.3017e-01, 1.9433e-01, 2.0594e-01,
        1.8509e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,240][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([2.2493e-05, 3.2334e-01, 2.7702e-01, 1.3320e-01, 3.7081e-02, 1.5094e-01,
        7.8404e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,241][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([3.1111e-04, 1.2926e-01, 1.9946e-01, 1.2392e-01, 8.2910e-02, 3.3310e-01,
        1.3104e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,243][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([0.0003, 0.2025, 0.1938, 0.0377, 0.1918, 0.3027, 0.0712],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,246][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([1.0112e-05, 6.2779e-01, 1.5238e-01, 4.4913e-02, 5.8669e-02, 1.1457e-01,
        1.6671e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,251][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([2.1030e-07, 9.1555e-02, 4.1064e-01, 9.6824e-02, 9.6827e-02, 2.6161e-01,
        4.2546e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,254][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([7.1002e-06, 7.4655e-01, 4.0810e-02, 3.4646e-02, 3.8878e-02, 4.0839e-02,
        9.8272e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,258][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([1.9557e-04, 4.8253e-02, 5.7272e-02, 5.2611e-02, 2.7860e-01, 1.9407e-01,
        3.6900e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,262][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([7.2037e-07, 7.7784e-01, 1.5103e-01, 3.4546e-02, 1.2803e-02, 2.3530e-02,
        2.4795e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,266][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([8.3478e-06, 9.6366e-01, 7.5351e-03, 8.4400e-03, 1.0880e-03, 3.1917e-03,
        1.6076e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,267][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([4.6566e-07, 2.5600e-01, 2.9435e-01, 6.4690e-02, 1.8417e-01, 8.4782e-02,
        1.1600e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,267][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([3.2050e-06, 4.5302e-01, 1.3924e-01, 8.7108e-02, 1.1203e-01, 1.4804e-01,
        3.7891e-02, 2.2676e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,268][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([1.0824e-07, 1.9236e-01, 1.5684e-01, 1.2288e-01, 1.9014e-01, 1.4586e-01,
        1.1613e-01, 7.5784e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,269][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([2.3237e-05, 2.2691e-01, 2.5019e-01, 1.3162e-01, 5.0019e-02, 1.4791e-01,
        8.6339e-02, 1.0699e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,273][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([1.9966e-04, 1.3157e-01, 1.0429e-01, 1.0539e-01, 6.8158e-02, 4.1604e-01,
        1.0298e-01, 7.1377e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,276][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([5.6900e-05, 8.0568e-02, 1.2331e-01, 2.2971e-02, 1.5625e-01, 4.3101e-01,
        7.9835e-02, 1.0600e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,280][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([4.3326e-04, 3.5190e-03, 8.1370e-04, 7.1197e-04, 8.8819e-02, 8.7723e-01,
        2.5069e-03, 2.5972e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,284][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([4.0808e-07, 7.6088e-02, 2.5535e-01, 9.2035e-02, 1.3545e-01, 3.5228e-01,
        5.8421e-02, 3.0375e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,288][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([1.9094e-06, 7.8121e-01, 4.0367e-02, 5.1228e-02, 3.1271e-02, 3.8848e-02,
        4.0749e-02, 1.6322e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,292][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([1.1287e-05, 5.7966e-02, 6.2563e-02, 3.5102e-02, 2.6980e-01, 1.6325e-01,
        2.2161e-01, 1.8970e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,293][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([1.1658e-04, 9.7979e-03, 1.1899e-03, 7.6404e-04, 9.2519e-02, 8.8232e-01,
        8.2500e-04, 1.2464e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,294][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([1.1296e-05, 9.5147e-01, 6.8435e-03, 1.2344e-02, 1.5568e-03, 3.0239e-03,
        1.9184e-02, 5.5660e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,295][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([3.2932e-07, 3.3350e-01, 1.8774e-01, 1.1286e-01, 1.7571e-01, 1.0473e-01,
        5.4779e-02, 3.0676e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,296][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([5.9761e-07, 3.9420e-01, 1.0583e-01, 6.0159e-02, 1.4271e-01, 1.5292e-01,
        2.0405e-02, 1.9530e-02, 1.0424e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,297][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([2.7111e-07, 8.5320e-02, 8.8715e-02, 1.1423e-01, 2.0803e-01, 1.9679e-01,
        1.1630e-01, 8.7917e-02, 1.0270e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,301][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([4.7745e-05, 2.5954e-01, 2.0874e-01, 9.2665e-02, 5.5144e-02, 1.1634e-01,
        4.9982e-02, 9.8866e-02, 1.1868e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,308][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([0.0007, 0.1825, 0.1146, 0.0763, 0.0769, 0.3127, 0.0818, 0.0571, 0.0975],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,314][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([0.0004, 0.1139, 0.1593, 0.0158, 0.1992, 0.2816, 0.0402, 0.0655, 0.1241],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,318][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([1.9832e-04, 1.1464e-01, 9.0454e-03, 4.9743e-03, 1.0359e-01, 7.1815e-01,
        3.8414e-03, 7.9672e-03, 3.7598e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,321][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([1.3046e-06, 6.7410e-02, 2.4693e-01, 8.1949e-02, 1.4982e-01, 3.2584e-01,
        3.7951e-02, 3.0458e-02, 5.9641e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,321][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([3.5018e-05, 6.6346e-01, 3.7199e-02, 4.6386e-02, 5.7606e-02, 4.4583e-02,
        4.0916e-02, 2.5810e-02, 8.4008e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,322][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([9.1548e-05, 3.1726e-02, 4.4829e-02, 3.0567e-02, 2.6668e-01, 1.6075e-01,
        1.8709e-01, 1.9429e-01, 8.3977e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,323][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([7.0212e-06, 5.1603e-01, 1.0141e-02, 3.6515e-03, 6.9323e-02, 3.8749e-01,
        1.0919e-03, 3.4957e-03, 8.7607e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,324][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([1.5729e-05, 9.6048e-01, 5.7078e-03, 9.5866e-03, 1.4275e-03, 2.8205e-03,
        1.1221e-02, 3.3641e-03, 5.3740e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,328][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([2.7147e-06, 1.1596e-01, 2.0174e-01, 7.8003e-02, 1.9044e-01, 1.5951e-01,
        6.4516e-02, 3.0039e-02, 1.5980e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,332][circuit_model.py][line:1570][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([1.3135e-07, 4.1334e-01, 9.1013e-02, 4.3792e-02, 1.0502e-01, 1.4876e-01,
        1.5382e-02, 1.4747e-02, 6.7692e-02, 1.0026e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,336][circuit_model.py][line:1573][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([7.1416e-08, 1.1904e-01, 8.2059e-02, 6.2902e-02, 1.4127e-01, 1.0806e-01,
        8.5006e-02, 5.7444e-02, 1.1966e-01, 2.2456e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,340][circuit_model.py][line:1576][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([1.5616e-05, 2.3884e-01, 1.9210e-01, 7.3628e-02, 3.2874e-02, 1.1363e-01,
        5.6346e-02, 7.8578e-02, 1.1077e-01, 1.0322e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,343][circuit_model.py][line:1579][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([6.1681e-05, 8.1555e-02, 8.3477e-02, 6.9106e-02, 6.7484e-02, 4.0651e-01,
        5.6732e-02, 5.5072e-02, 1.1011e-01, 6.9895e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,348][circuit_model.py][line:1582][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([9.3867e-05, 7.6749e-02, 6.6400e-02, 1.2203e-02, 1.5669e-01, 3.4470e-01,
        3.4144e-02, 4.3207e-02, 1.7465e-01, 9.1171e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,350][circuit_model.py][line:1585][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([3.3436e-04, 4.9323e-03, 4.2727e-04, 3.5394e-04, 5.5369e-02, 8.3349e-01,
        1.2782e-03, 9.6344e-03, 3.7608e-02, 5.6567e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,351][circuit_model.py][line:1588][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([1.7277e-07, 8.1071e-02, 2.1141e-01, 6.0204e-02, 1.4661e-01, 2.9888e-01,
        3.8273e-02, 2.9025e-02, 5.0381e-02, 8.4142e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,352][circuit_model.py][line:1591][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([2.5040e-06, 8.3720e-01, 2.4915e-02, 2.2170e-02, 2.0700e-02, 2.3246e-02,
        1.9993e-02, 8.7117e-03, 2.6525e-02, 1.6531e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,353][circuit_model.py][line:1594][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([1.4611e-05, 1.9532e-02, 2.4193e-02, 1.9204e-02, 2.6265e-01, 1.3750e-01,
        1.5801e-01, 1.8343e-01, 8.1016e-02, 1.1445e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,354][circuit_model.py][line:1597][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([1.7199e-05, 1.5059e-02, 3.1493e-04, 1.9153e-04, 5.9066e-02, 8.8872e-01,
        2.7658e-04, 3.8895e-03, 7.1280e-03, 2.5342e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,358][circuit_model.py][line:1600][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([4.2442e-06, 9.6577e-01, 3.3216e-03, 7.3258e-03, 9.4494e-04, 1.9289e-03,
        1.0924e-02, 3.4934e-03, 5.2602e-03, 1.0302e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,362][circuit_model.py][line:1603][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([1.9003e-07, 2.0300e-01, 1.3897e-01, 7.1514e-02, 1.6268e-01, 1.3961e-01,
        4.0362e-02, 2.0418e-02, 1.2031e-01, 1.0314e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,366][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:12,369][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[5801],
        [ 858],
        [ 167],
        [ 355],
        [  86],
        [  91],
        [ 277],
        [  51],
        [ 122],
        [  33]], device='cuda:0')
[2024-07-23 21:07:12,372][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[4249],
        [2025],
        [ 412],
        [ 837],
        [ 224],
        [ 228],
        [ 616],
        [ 151],
        [ 290],
        [  96]], device='cuda:0')
[2024-07-23 21:07:12,375][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[13474],
        [ 3794],
        [28362],
        [28335],
        [36018],
        [35937],
        [38344],
        [37402],
        [35953],
        [32163]], device='cuda:0')
[2024-07-23 21:07:12,378][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[24624],
        [ 6907],
        [ 6702],
        [ 6463],
        [ 5548],
        [ 5980],
        [ 5995],
        [ 6315],
        [ 6165],
        [ 6161]], device='cuda:0')
[2024-07-23 21:07:12,381][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[ 6871],
        [19706],
        [18502],
        [17626],
        [16210],
        [12732],
        [15990],
        [14944],
        [15315],
        [15205]], device='cuda:0')
[2024-07-23 21:07:12,382][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[40414],
        [14929],
        [13493],
        [ 9243],
        [ 9158],
        [ 4647],
        [ 5246],
        [ 5236],
        [ 5636],
        [ 6925]], device='cuda:0')
[2024-07-23 21:07:12,383][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[15153],
        [15716],
        [13750],
        [11042],
        [11324],
        [ 8163],
        [ 7373],
        [ 7353],
        [ 6534],
        [ 6856]], device='cuda:0')
[2024-07-23 21:07:12,384][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[23278],
        [15527],
        [15633],
        [13535],
        [12766],
        [12278],
        [12332],
        [12354],
        [12351],
        [12375]], device='cuda:0')
[2024-07-23 21:07:12,386][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[22695],
        [24673],
        [16507],
        [18743],
        [18480],
        [18300],
        [18161],
        [17822],
        [19535],
        [19556]], device='cuda:0')
[2024-07-23 21:07:12,389][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[1429],
        [2910],
        [3006],
        [3379],
        [3760],
        [3613],
        [4516],
        [4253],
        [3781],
        [3215]], device='cuda:0')
[2024-07-23 21:07:12,392][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[20074],
        [11605],
        [17861],
        [18479],
        [32054],
        [32052],
        [30870],
        [29009],
        [30068],
        [28102]], device='cuda:0')
[2024-07-23 21:07:12,395][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[31729],
        [31891],
        [31525],
        [31926],
        [32527],
        [33162],
        [32285],
        [38062],
        [36168],
        [38074]], device='cuda:0')
[2024-07-23 21:07:12,398][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[38260],
        [10173],
        [ 7476],
        [ 7424],
        [ 7476],
        [ 7481],
        [ 7559],
        [ 7498],
        [ 7533],
        [ 7453]], device='cuda:0')
[2024-07-23 21:07:12,401][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[ 9567],
        [ 9566],
        [ 9568],
        [ 9563],
        [ 9557],
        [ 9569],
        [ 9599],
        [10267],
        [ 9584],
        [ 9577]], device='cuda:0')
[2024-07-23 21:07:12,404][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[21137],
        [ 2001],
        [ 1589],
        [ 1256],
        [  905],
        [ 1380],
        [ 1073],
        [ 1016],
        [ 1340],
        [ 1321]], device='cuda:0')
[2024-07-23 21:07:12,407][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[ 4137],
        [16401],
        [16324],
        [16170],
        [13758],
        [13744],
        [13149],
        [12472],
        [11735],
        [11977]], device='cuda:0')
[2024-07-23 21:07:12,410][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[31854],
        [36276],
        [30847],
        [28246],
        [27443],
        [25980],
        [26878],
        [24371],
        [20430],
        [17756]], device='cuda:0')
[2024-07-23 21:07:12,412][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[18280],
        [ 3914],
        [ 7003],
        [ 9368],
        [ 9678],
        [10277],
        [ 9672],
        [10654],
        [10638],
        [10862]], device='cuda:0')
[2024-07-23 21:07:12,413][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[37295],
        [20151],
        [26066],
        [24315],
        [23235],
        [26233],
        [25761],
        [25482],
        [24517],
        [23779]], device='cuda:0')
[2024-07-23 21:07:12,414][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[12151],
        [10016],
        [ 9150],
        [ 9019],
        [ 9142],
        [ 4638],
        [ 5936],
        [ 4250],
        [ 4797],
        [ 4208]], device='cuda:0')
[2024-07-23 21:07:12,416][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[ 4401],
        [12522],
        [14556],
        [16098],
        [14603],
        [ 9710],
        [13657],
        [ 8075],
        [ 8357],
        [ 7931]], device='cuda:0')
[2024-07-23 21:07:12,419][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[18521],
        [21355],
        [18549],
        [20246],
        [19968],
        [18828],
        [20436],
        [20720],
        [20328],
        [19705]], device='cuda:0')
[2024-07-23 21:07:12,422][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 8111],
        [15932],
        [15950],
        [15962],
        [15273],
        [15140],
        [14387],
        [14648],
        [13919],
        [15283]], device='cuda:0')
[2024-07-23 21:07:12,425][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[4286],
        [3002],
        [2084],
        [3010],
        [2235],
        [2738],
        [3338],
        [3566],
        [3594],
        [3718]], device='cuda:0')
[2024-07-23 21:07:12,428][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[17139],
        [21360],
        [14473],
        [15317],
        [20658],
        [19487],
        [19236],
        [ 7805],
        [14069],
        [ 7580]], device='cuda:0')
[2024-07-23 21:07:12,431][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[ 9429],
        [22894],
        [22882],
        [22835],
        [22838],
        [22824],
        [22697],
        [22623],
        [22674],
        [22703]], device='cuda:0')
[2024-07-23 21:07:12,434][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 6401],
        [16945],
        [16633],
        [16389],
        [16379],
        [16471],
        [14807],
        [15159],
        [12793],
        [13874]], device='cuda:0')
[2024-07-23 21:07:12,437][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[36374],
        [26717],
        [28334],
        [27685],
        [28817],
        [31869],
        [30527],
        [35077],
        [35555],
        [37302]], device='cuda:0')
[2024-07-23 21:07:12,440][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[19358],
        [39882],
        [41056],
        [40726],
        [43401],
        [42849],
        [43533],
        [44173],
        [43445],
        [44435]], device='cuda:0')
[2024-07-23 21:07:12,443][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[6803],
        [6803],
        [6803],
        [6803],
        [6803],
        [6803],
        [6803],
        [6803],
        [6803],
        [6803]], device='cuda:0')
[2024-07-23 21:07:12,568][circuit_model.py][line:1111][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:12,572][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,576][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,580][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,583][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,586][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,587][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,588][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,588][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,590][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,595][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,601][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,606][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:12,612][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [izen] are: tensor([0.0373, 0.9627], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,614][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [izen] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,614][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [izen] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,615][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [izen] are: tensor([0.1903, 0.8097], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,616][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [izen] are: tensor([0.0044, 0.9956], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,618][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [izen] are: tensor([8.1778e-06, 9.9999e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,625][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [izen] are: tensor([0.0321, 0.9679], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,631][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [izen] are: tensor([0.9357, 0.0643], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,638][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [izen] are: tensor([0.7492, 0.2508], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,640][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [izen] are: tensor([1.0000e+00, 1.0469e-06], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,641][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [izen] are: tensor([0.9989, 0.0011], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,642][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [izen] are: tensor([0.0863, 0.9137], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:12,642][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ is] are: tensor([0.0174, 0.8482, 0.1344], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,643][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ is] are: tensor([3.4737e-05, 2.0028e-01, 7.9968e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,644][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ is] are: tensor([5.0655e-05, 9.0632e-01, 9.3632e-02], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,648][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ is] are: tensor([0.0739, 0.4619, 0.4642], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,655][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ is] are: tensor([0.0010, 0.7659, 0.2331], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,659][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ is] are: tensor([1.3751e-07, 4.2202e-01, 5.7798e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,666][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ is] are: tensor([0.0052, 0.4481, 0.5468], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,668][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ is] are: tensor([0.7033, 0.2229, 0.0739], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,669][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ is] are: tensor([0.7185, 0.1461, 0.1354], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,670][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ is] are: tensor([9.9998e-01, 1.6947e-05, 8.9233e-07], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,670][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ is] are: tensor([0.9459, 0.0117, 0.0424], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,671][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ is] are: tensor([0.0056, 0.5562, 0.4382], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:12,676][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ developed] are: tensor([0.0114, 0.3538, 0.0960, 0.5389], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,680][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ developed] are: tensor([1.3116e-05, 1.6066e-01, 6.5746e-01, 1.8186e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,683][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ developed] are: tensor([6.7769e-05, 8.7060e-01, 7.3923e-02, 5.5409e-02], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,691][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ developed] are: tensor([0.0592, 0.2363, 0.2041, 0.5004], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,696][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ developed] are: tensor([0.0077, 0.7891, 0.1706, 0.0326], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,696][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ developed] are: tensor([8.6313e-08, 1.7514e-01, 3.8017e-01, 4.4468e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,697][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ developed] are: tensor([0.0016, 0.2911, 0.3569, 0.3504], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,698][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ developed] are: tensor([0.6658, 0.1488, 0.0462, 0.1393], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,698][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ developed] are: tensor([0.0192, 0.3648, 0.3897, 0.2262], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,700][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ developed] are: tensor([1.0000e+00, 2.9737e-07, 2.6484e-09, 4.6375e-08], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,707][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ developed] are: tensor([0.9784, 0.0035, 0.0065, 0.0115], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,713][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ developed] are: tensor([0.0007, 0.3970, 0.5252, 0.0771], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:12,720][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ by] are: tensor([0.0314, 0.2880, 0.0653, 0.4632, 0.1522], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,723][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ by] are: tensor([1.5441e-04, 2.5102e-01, 4.4515e-01, 1.9159e-01, 1.1209e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,724][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ by] are: tensor([6.8604e-05, 7.5192e-01, 8.8408e-02, 8.6175e-02, 7.3431e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,724][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ by] are: tensor([0.0501, 0.1611, 0.1222, 0.2826, 0.3839], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,725][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ by] are: tensor([0.0023, 0.5306, 0.2479, 0.0540, 0.1653], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,726][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ by] are: tensor([1.5097e-07, 1.1808e-01, 1.9849e-01, 3.3847e-01, 3.4497e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,732][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ by] are: tensor([0.0019, 0.2666, 0.3153, 0.3075, 0.1086], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,738][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ by] are: tensor([0.3692, 0.1856, 0.0570, 0.1922, 0.1959], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,745][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ by] are: tensor([0.0261, 0.2778, 0.3279, 0.2009, 0.1673], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,748][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ by] are: tensor([9.9998e-01, 1.3971e-05, 5.7896e-07, 8.1118e-07, 2.8029e-07],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,750][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ by] are: tensor([0.9285, 0.0049, 0.0079, 0.0120, 0.0466], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,751][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ by] are: tensor([0.0007, 0.5475, 0.2907, 0.0401, 0.1210], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:12,752][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0185, 0.1629, 0.0327, 0.2103, 0.0627, 0.5128], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,752][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.9811e-05, 7.8950e-02, 2.4051e-01, 7.5902e-02, 4.8762e-02, 5.5585e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,754][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([9.1718e-05, 7.0518e-01, 8.4489e-02, 8.1013e-02, 8.6547e-02, 4.2675e-02],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,760][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0369, 0.1223, 0.0991, 0.1957, 0.2703, 0.2757], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,767][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0018, 0.4817, 0.1768, 0.0556, 0.1070, 0.1769], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,770][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([4.9522e-08, 5.3617e-02, 1.1548e-01, 1.8736e-01, 1.3633e-01, 5.0722e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,777][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0023, 0.2439, 0.2883, 0.2444, 0.0921, 0.1291], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,778][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3475, 0.1582, 0.0459, 0.1649, 0.1671, 0.1165], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,779][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2349, 0.1639, 0.1540, 0.1513, 0.1428, 0.1531], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,779][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.0000e+00, 3.5743e-06, 1.5079e-07, 3.7853e-07, 1.3752e-07, 7.4007e-07],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,781][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6057, 0.0105, 0.0246, 0.0241, 0.1296, 0.2055], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,786][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0005, 0.4884, 0.1883, 0.0458, 0.1089, 0.1680], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:12,793][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ consortium] are: tensor([0.0084, 0.0712, 0.0331, 0.2558, 0.0606, 0.3979, 0.1731],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,797][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ consortium] are: tensor([5.9314e-06, 6.8008e-02, 3.0395e-01, 8.3471e-02, 3.7509e-02, 3.2621e-01,
        1.8085e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,800][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ consortium] are: tensor([3.2058e-05, 7.0675e-01, 9.0318e-02, 7.4706e-02, 5.6806e-02, 3.0509e-02,
        4.0877e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,805][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ consortium] are: tensor([0.0258, 0.1026, 0.0893, 0.1922, 0.2436, 0.2406, 0.1059],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,805][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ consortium] are: tensor([0.0033, 0.3792, 0.2583, 0.0385, 0.1408, 0.1533, 0.0266],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,806][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ consortium] are: tensor([3.4485e-08, 6.4735e-02, 1.6956e-01, 1.3640e-01, 1.1912e-01, 3.7182e-01,
        1.3836e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,807][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ consortium] are: tensor([0.0018, 0.2363, 0.2794, 0.2370, 0.0796, 0.1118, 0.0541],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,811][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ consortium] are: tensor([0.5133, 0.1098, 0.0320, 0.0930, 0.1160, 0.0728, 0.0632],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,817][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ consortium] are: tensor([0.0102, 0.1954, 0.2317, 0.1307, 0.1057, 0.1958, 0.1306],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,822][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ consortium] are: tensor([9.9992e-01, 1.4593e-05, 3.0017e-06, 1.7613e-06, 2.6508e-06, 2.7080e-05,
        2.8502e-05], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,828][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ consortium] are: tensor([0.7202, 0.0144, 0.0213, 0.0233, 0.0728, 0.1353, 0.0125],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,832][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ consortium] are: tensor([4.1712e-05, 2.2125e-01, 3.0178e-01, 6.1812e-02, 1.2529e-01, 2.7100e-01,
        1.8825e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:12,833][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0081, 0.0801, 0.0351, 0.1763, 0.0460, 0.4072, 0.1201, 0.1271],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,833][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ of] are: tensor([3.7223e-06, 6.3246e-02, 1.5085e-01, 7.8233e-02, 5.7253e-02, 4.8572e-01,
        1.4227e-01, 2.2423e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,834][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ of] are: tensor([2.0017e-05, 5.2141e-01, 1.1174e-01, 1.1750e-01, 9.6124e-02, 5.0033e-02,
        7.0416e-02, 3.2767e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,837][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0610, 0.1043, 0.0730, 0.1383, 0.1985, 0.2376, 0.1158, 0.0716],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,844][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0006, 0.2645, 0.2459, 0.0550, 0.1355, 0.2050, 0.0324, 0.0611],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,847][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ of] are: tensor([2.4969e-08, 4.4741e-02, 1.1747e-01, 1.5690e-01, 1.1411e-01, 4.0705e-01,
        8.6939e-02, 7.2794e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,854][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0018, 0.1778, 0.2475, 0.2206, 0.0931, 0.1325, 0.0608, 0.0659],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,859][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.3179, 0.1316, 0.0456, 0.1333, 0.1243, 0.0921, 0.0737, 0.0816],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,860][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0410, 0.1508, 0.1659, 0.1266, 0.1200, 0.1528, 0.1160, 0.1269],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,861][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ of] are: tensor([9.9917e-01, 7.2165e-05, 1.7210e-05, 1.2692e-05, 4.9452e-06, 1.0030e-04,
        2.9475e-04, 3.2840e-04], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,861][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1101, 0.0134, 0.0434, 0.0513, 0.1942, 0.4221, 0.0203, 0.1451],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,863][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ of] are: tensor([2.5456e-04, 2.0380e-01, 1.2557e-01, 5.4959e-02, 1.4027e-01, 2.8297e-01,
        2.3036e-02, 1.6914e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:12,869][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ companies] are: tensor([0.0201, 0.0360, 0.0198, 0.0958, 0.0381, 0.4231, 0.0755, 0.1222, 0.1696],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,873][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ companies] are: tensor([8.7578e-06, 9.2054e-02, 2.3940e-01, 6.5267e-02, 4.5290e-02, 3.5592e-01,
        1.6884e-01, 2.5245e-02, 7.9693e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,877][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ companies] are: tensor([7.6877e-05, 6.1704e-01, 6.9790e-02, 6.7989e-02, 5.9319e-02, 3.2115e-02,
        3.4216e-02, 2.5564e-02, 9.3888e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,884][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ companies] are: tensor([0.0350, 0.0913, 0.0684, 0.1443, 0.2012, 0.2143, 0.0992, 0.0578, 0.0885],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,886][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ companies] are: tensor([0.0108, 0.4973, 0.1317, 0.0440, 0.1029, 0.0985, 0.0279, 0.0422, 0.0447],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,887][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ companies] are: tensor([3.6978e-08, 3.5804e-02, 1.1337e-01, 1.3551e-01, 1.5046e-01, 2.9730e-01,
        7.8575e-02, 1.1122e-01, 7.7766e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,888][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ companies] are: tensor([0.0017, 0.2022, 0.2465, 0.2100, 0.0702, 0.1028, 0.0468, 0.0533, 0.0665],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,889][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ companies] are: tensor([0.5356, 0.0734, 0.0217, 0.0629, 0.0843, 0.0534, 0.0397, 0.0549, 0.0742],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,893][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ companies] are: tensor([0.0036, 0.1693, 0.1800, 0.0972, 0.0784, 0.1565, 0.0967, 0.1052, 0.1133],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,894][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ companies] are: tensor([1.0000e+00, 7.3856e-07, 3.2615e-08, 1.3896e-07, 5.2461e-08, 5.3089e-07,
        2.3250e-06, 7.2580e-07, 2.2239e-07], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,900][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ companies] are: tensor([0.5939, 0.0090, 0.0129, 0.0139, 0.0817, 0.1611, 0.0060, 0.0673, 0.0542],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,904][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ companies] are: tensor([2.1605e-04, 1.7253e-01, 1.3145e-01, 3.7478e-02, 1.4762e-01, 2.4374e-01,
        1.4935e-02, 1.1936e-01, 1.3267e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:12,910][circuit_model.py][line:1532][INFO] ##11-th layer ##Weight##: The head1 weight for token [ including] are: tensor([0.0029, 0.0713, 0.0217, 0.0812, 0.0292, 0.3466, 0.0508, 0.1034, 0.1400,
        0.1529], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,914][circuit_model.py][line:1535][INFO] ##11-th layer ##Weight##: The head2 weight for token [ including] are: tensor([3.4673e-06, 7.6786e-02, 2.3415e-01, 5.0874e-02, 5.1677e-02, 4.2557e-01,
        8.4757e-02, 1.9928e-02, 8.5106e-03, 4.7743e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,915][circuit_model.py][line:1538][INFO] ##11-th layer ##Weight##: The head3 weight for token [ including] are: tensor([1.6161e-05, 6.0550e-01, 5.7166e-02, 4.1120e-02, 6.4278e-02, 3.4461e-02,
        2.6244e-02, 2.3809e-02, 1.0549e-01, 4.1913e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,916][circuit_model.py][line:1541][INFO] ##11-th layer ##Weight##: The head4 weight for token [ including] are: tensor([0.0225, 0.0804, 0.0583, 0.1265, 0.1912, 0.2110, 0.0955, 0.0528, 0.0896,
        0.0722], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,917][circuit_model.py][line:1544][INFO] ##11-th layer ##Weight##: The head5 weight for token [ including] are: tensor([0.0018, 0.5110, 0.1434, 0.0300, 0.0831, 0.1210, 0.0213, 0.0341, 0.0285,
        0.0258], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,919][circuit_model.py][line:1547][INFO] ##11-th layer ##Weight##: The head6 weight for token [ including] are: tensor([5.9493e-09, 4.4102e-02, 1.1167e-01, 1.0539e-01, 1.4070e-01, 3.1433e-01,
        6.0737e-02, 7.6124e-02, 4.3352e-02, 1.0359e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,925][circuit_model.py][line:1550][INFO] ##11-th layer ##Weight##: The head7 weight for token [ including] are: tensor([0.0008, 0.1692, 0.2155, 0.1903, 0.0768, 0.1082, 0.0441, 0.0482, 0.0743,
        0.0727], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,932][circuit_model.py][line:1553][INFO] ##11-th layer ##Weight##: The head8 weight for token [ including] are: tensor([0.3235, 0.1523, 0.0322, 0.0917, 0.1131, 0.0685, 0.0438, 0.0659, 0.0905,
        0.0186], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,938][circuit_model.py][line:1556][INFO] ##11-th layer ##Weight##: The head9 weight for token [ including] are: tensor([0.0096, 0.1408, 0.1557, 0.0940, 0.0749, 0.1374, 0.0933, 0.0981, 0.1077,
        0.0886], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,942][circuit_model.py][line:1559][INFO] ##11-th layer ##Weight##: The head10 weight for token [ including] are: tensor([9.9986e-01, 2.8442e-05, 5.7388e-07, 2.3063e-06, 4.0336e-07, 6.8086e-06,
        8.1270e-05, 1.2735e-05, 1.0066e-05, 6.5316e-07], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,943][circuit_model.py][line:1562][INFO] ##11-th layer ##Weight##: The head11 weight for token [ including] are: tensor([0.1071, 0.0091, 0.0215, 0.0197, 0.1301, 0.2639, 0.0068, 0.0753, 0.0526,
        0.3140], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:12,943][circuit_model.py][line:1565][INFO] ##11-th layer ##Weight##: The head12 weight for token [ including] are: tensor([8.8785e-05, 1.7849e-01, 7.4924e-02, 3.5365e-02, 1.0377e-01, 2.2316e-01,
        1.3191e-02, 9.8372e-02, 1.7911e-01, 9.3539e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,074][circuit_model.py][line:1216][INFO] ############showing the attention weight of each circuit
[2024-07-23 21:07:13,079][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,082][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,085][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,085][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,086][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,087][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,089][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,089][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,090][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,091][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,092][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,093][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [T] are: tensor([1.], device='cuda:0') for source tokens [T]
[2024-07-23 21:07:13,094][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [izen] are: tensor([0.0373, 0.9627], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,094][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [izen] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,096][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [izen] are: tensor([3.0458e-05, 9.9997e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,103][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [izen] are: tensor([0.0117, 0.9883], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,106][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [izen] are: tensor([1.2909e-05, 9.9999e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,111][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [izen] are: tensor([8.1778e-06, 9.9999e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,114][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [izen] are: tensor([3.0291e-05, 9.9997e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,118][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [izen] are: tensor([1.9175e-04, 9.9981e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,119][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [izen] are: tensor([0.0056, 0.9944], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,120][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [izen] are: tensor([2.6970e-05, 9.9997e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,120][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [izen] are: tensor([1.7465e-05, 9.9998e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,121][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [izen] are: tensor([3.2244e-05, 9.9997e-01], device='cuda:0') for source tokens [Tizen]
[2024-07-23 21:07:13,126][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ is] are: tensor([0.0174, 0.8482, 0.1344], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,130][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ is] are: tensor([3.4737e-05, 2.0028e-01, 7.9968e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,134][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ is] are: tensor([1.3877e-07, 1.3513e-01, 8.6487e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,138][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ is] are: tensor([4.9611e-05, 3.1376e-01, 6.8619e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,141][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ is] are: tensor([3.3748e-07, 3.4516e-01, 6.5483e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,146][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ is] are: tensor([1.3751e-07, 4.2202e-01, 5.7798e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,146][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ is] are: tensor([5.6824e-07, 2.7174e-01, 7.2826e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,147][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ is] are: tensor([3.4544e-06, 2.4237e-01, 7.5763e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,148][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ is] are: tensor([4.6386e-04, 2.7327e-01, 7.2627e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,148][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ is] are: tensor([7.5225e-07, 1.1501e-01, 8.8499e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,150][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ is] are: tensor([4.0133e-08, 2.6201e-01, 7.3799e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,153][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ is] are: tensor([4.3320e-07, 2.2645e-01, 7.7355e-01], device='cuda:0') for source tokens [Tizen is]
[2024-07-23 21:07:13,160][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ developed] are: tensor([0.0114, 0.3538, 0.0960, 0.5389], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,164][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ developed] are: tensor([1.3116e-05, 1.6066e-01, 6.5746e-01, 1.8186e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,168][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ developed] are: tensor([2.5328e-07, 1.4332e-01, 7.8437e-01, 7.2303e-02], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,172][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ developed] are: tensor([6.0538e-07, 2.2028e-01, 7.1339e-01, 6.6327e-02], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,176][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ developed] are: tensor([5.9365e-07, 3.1180e-01, 6.0511e-01, 8.3090e-02], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,177][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ developed] are: tensor([8.6313e-08, 1.7514e-01, 3.8017e-01, 4.4468e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,177][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ developed] are: tensor([4.3016e-07, 1.1060e-01, 6.5499e-01, 2.3442e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,178][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ developed] are: tensor([1.6986e-05, 1.0136e-01, 4.9223e-01, 4.0640e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,179][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ developed] are: tensor([0.0012, 0.1341, 0.5442, 0.3205], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,181][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ developed] are: tensor([2.6514e-07, 5.3879e-02, 7.7868e-01, 1.6744e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,185][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ developed] are: tensor([4.0382e-08, 1.5530e-01, 6.6515e-01, 1.7955e-01], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,189][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ developed] are: tensor([6.3253e-08, 1.9604e-01, 7.8540e-01, 1.8559e-02], device='cuda:0') for source tokens [Tizen is developed]
[2024-07-23 21:07:13,196][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ by] are: tensor([0.0314, 0.2880, 0.0653, 0.4632, 0.1522], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,199][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ by] are: tensor([1.5441e-04, 2.5102e-01, 4.4515e-01, 1.9159e-01, 1.1209e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,203][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ by] are: tensor([8.6760e-07, 1.2728e-01, 7.1931e-01, 1.2567e-01, 2.7729e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,204][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ by] are: tensor([2.8472e-06, 4.1393e-01, 4.9331e-01, 6.9916e-02, 2.2847e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,205][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ by] are: tensor([2.9141e-06, 1.7501e-01, 3.8656e-01, 6.3447e-02, 3.7497e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,205][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ by] are: tensor([1.5097e-07, 1.1808e-01, 1.9849e-01, 3.3847e-01, 3.4497e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,206][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ by] are: tensor([4.4186e-06, 1.0451e-01, 4.4648e-01, 3.0665e-01, 1.4236e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,208][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ by] are: tensor([1.5698e-05, 4.0648e-02, 3.0097e-01, 4.9585e-01, 1.6251e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,215][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ by] are: tensor([0.0055, 0.2799, 0.4113, 0.1954, 0.1079], device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,219][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ by] are: tensor([1.6914e-06, 3.3382e-02, 4.3898e-01, 2.9317e-01, 2.3447e-01],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,223][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ by] are: tensor([9.2357e-08, 3.0440e-01, 4.8633e-01, 1.5420e-01, 5.5065e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,227][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ by] are: tensor([2.2142e-08, 2.5622e-01, 7.2150e-01, 1.2244e-02, 1.0028e-02],
       device='cuda:0') for source tokens [Tizen is developed by]
[2024-07-23 21:07:13,231][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0185, 0.1629, 0.0327, 0.2103, 0.0627, 0.5128], device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,232][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.9811e-05, 7.8950e-02, 2.4051e-01, 7.5902e-02, 4.8762e-02, 5.5585e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,232][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.8920e-07, 1.2352e-01, 6.5375e-01, 1.1530e-01, 2.4872e-02, 8.2564e-02],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,233][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([4.0003e-07, 4.3900e-01, 4.6443e-01, 4.7133e-02, 2.9210e-02, 2.0234e-02],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,234][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([4.9360e-07, 1.4155e-01, 3.4839e-01, 4.2734e-02, 1.6985e-01, 2.9748e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,236][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.9522e-08, 5.3617e-02, 1.1548e-01, 1.8736e-01, 1.3633e-01, 5.0722e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,240][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([3.6235e-06, 1.3699e-01, 4.7178e-01, 1.6150e-01, 5.5210e-02, 1.7451e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,244][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([7.1609e-06, 2.7421e-02, 1.4523e-01, 2.4479e-01, 9.4015e-02, 4.8854e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,248][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([3.5175e-04, 1.1067e-01, 1.9595e-01, 7.0210e-02, 6.2175e-02, 5.6063e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,251][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.8835e-06, 2.1924e-02, 2.4667e-01, 1.4821e-01, 1.5110e-01, 4.3209e-01],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,256][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([3.6472e-08, 2.2079e-01, 5.8083e-01, 1.1038e-01, 3.2279e-02, 5.5721e-02],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,258][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.9830e-08, 3.0841e-01, 6.4183e-01, 2.2290e-02, 1.1041e-02, 1.6432e-02],
       device='cuda:0') for source tokens [Tizen is developed by a]
[2024-07-23 21:07:13,259][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ consortium] are: tensor([0.0084, 0.0712, 0.0331, 0.2558, 0.0606, 0.3979, 0.1731],
       device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,260][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ consortium] are: tensor([5.9314e-06, 6.8008e-02, 3.0395e-01, 8.3471e-02, 3.7509e-02, 3.2621e-01,
        1.8085e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,261][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ consortium] are: tensor([7.2334e-08, 7.1998e-02, 7.2312e-01, 7.9080e-02, 1.6628e-02, 8.9104e-02,
        2.0064e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,262][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ consortium] are: tensor([1.0071e-08, 2.2215e-01, 6.8905e-01, 6.2539e-02, 1.5053e-02, 8.8989e-03,
        2.3031e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,265][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ consortium] are: tensor([7.0012e-07, 1.9379e-01, 4.6711e-01, 7.2915e-02, 1.0634e-01, 1.4873e-01,
        1.1111e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,268][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ consortium] are: tensor([3.4485e-08, 6.4735e-02, 1.6956e-01, 1.3640e-01, 1.1912e-01, 3.7182e-01,
        1.3836e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,273][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ consortium] are: tensor([6.2364e-07, 1.1874e-01, 5.3289e-01, 1.2600e-01, 3.1664e-02, 1.3255e-01,
        5.8151e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,276][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ consortium] are: tensor([2.7376e-06, 1.5979e-02, 2.0247e-01, 1.9217e-01, 9.8966e-02, 3.6841e-01,
        1.2200e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,281][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ consortium] are: tensor([7.4386e-05, 3.0667e-02, 2.1467e-01, 1.1378e-01, 7.5936e-02, 5.1576e-01,
        4.9110e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,284][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ consortium] are: tensor([3.0160e-07, 1.4969e-02, 1.7779e-01, 1.2925e-01, 5.8931e-02, 1.5942e-01,
        4.5964e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,286][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ consortium] are: tensor([2.7345e-08, 1.9384e-01, 5.9475e-01, 1.3278e-01, 2.2892e-02, 4.6547e-02,
        9.1824e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,287][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ consortium] are: tensor([5.8300e-09, 1.1567e-01, 8.2359e-01, 2.2412e-02, 1.2507e-02, 2.2841e-02,
        2.9807e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium]
[2024-07-23 21:07:13,288][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0081, 0.0801, 0.0351, 0.1763, 0.0460, 0.4072, 0.1201, 0.1271],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,288][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([3.7223e-06, 6.3246e-02, 1.5085e-01, 7.8233e-02, 5.7253e-02, 4.8572e-01,
        1.4227e-01, 2.2423e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,290][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([1.9798e-07, 7.2343e-02, 5.9567e-01, 1.6400e-01, 2.6619e-02, 9.9194e-02,
        2.9676e-02, 1.2495e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,293][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([4.8722e-07, 1.3061e-01, 5.1535e-01, 1.3753e-01, 7.2812e-02, 1.0858e-01,
        2.3167e-02, 1.1958e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,298][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([3.4500e-07, 9.0060e-02, 2.2777e-01, 8.9998e-02, 2.4820e-01, 2.9054e-01,
        8.9133e-03, 4.4525e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,301][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([2.4969e-08, 4.4741e-02, 1.1747e-01, 1.5690e-01, 1.1411e-01, 4.0705e-01,
        8.6939e-02, 7.2794e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,306][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([1.5233e-06, 7.3529e-02, 3.1603e-01, 2.7944e-01, 5.6569e-02, 1.6716e-01,
        5.3421e-02, 5.3842e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,309][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([6.9143e-07, 6.7799e-03, 9.2352e-02, 2.0710e-01, 9.3328e-02, 4.5230e-01,
        9.2871e-02, 5.5275e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,313][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0031, 0.0509, 0.0547, 0.0240, 0.1145, 0.6805, 0.0203, 0.0521],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,314][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([6.8379e-07, 1.1948e-02, 9.7673e-02, 1.6805e-01, 9.3051e-02, 2.5610e-01,
        3.1102e-01, 6.2156e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,315][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([1.0250e-09, 7.5790e-02, 6.8187e-01, 1.0419e-01, 3.7552e-02, 9.4598e-02,
        2.4804e-03, 3.5160e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,316][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([5.3848e-08, 2.2669e-01, 4.7579e-01, 7.8338e-02, 3.5999e-02, 5.6992e-02,
        5.8528e-03, 1.2034e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of]
[2024-07-23 21:07:13,318][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ companies] are: tensor([0.0201, 0.0360, 0.0198, 0.0958, 0.0381, 0.4231, 0.0755, 0.1222, 0.1696],
       device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,323][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ companies] are: tensor([8.7578e-06, 9.2054e-02, 2.3940e-01, 6.5267e-02, 4.5290e-02, 3.5592e-01,
        1.6884e-01, 2.5245e-02, 7.9693e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,326][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ companies] are: tensor([3.7228e-07, 1.2586e-01, 5.7512e-01, 1.2874e-01, 2.2931e-02, 9.6863e-02,
        1.9029e-02, 1.4414e-02, 1.7041e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,331][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ companies] are: tensor([7.8009e-08, 3.6970e-01, 4.8387e-01, 5.0884e-02, 3.0589e-02, 3.4309e-02,
        4.2441e-03, 3.3612e-03, 2.3046e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,334][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ companies] are: tensor([1.0049e-06, 1.5772e-01, 4.0137e-01, 6.6484e-02, 1.3545e-01, 1.7005e-01,
        8.7687e-03, 2.8921e-02, 3.1239e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,339][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ companies] are: tensor([3.6978e-08, 3.5804e-02, 1.1337e-01, 1.3551e-01, 1.5046e-01, 2.9730e-01,
        7.8575e-02, 1.1122e-01, 7.7766e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,341][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ companies] are: tensor([1.2539e-06, 8.4248e-02, 4.1361e-01, 1.4308e-01, 5.2574e-02, 1.7307e-01,
        5.4498e-02, 5.3713e-02, 2.5192e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,342][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ companies] are: tensor([1.8828e-06, 1.3304e-02, 1.9791e-01, 1.4128e-01, 8.7480e-02, 3.1402e-01,
        8.1062e-02, 7.6095e-02, 8.8855e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,342][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ companies] are: tensor([5.3811e-04, 6.1910e-02, 6.0124e-02, 3.8844e-02, 7.0437e-02, 5.4658e-01,
        2.5996e-02, 6.0808e-02, 1.3476e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,343][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ companies] are: tensor([1.2672e-06, 1.2049e-02, 8.1114e-02, 1.5207e-01, 9.4495e-02, 1.7615e-01,
        3.9679e-01, 4.8003e-02, 3.9328e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,345][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ companies] are: tensor([2.0036e-08, 1.7468e-01, 4.9079e-01, 1.2475e-01, 4.7597e-02, 1.1240e-01,
        5.2566e-03, 8.7285e-03, 3.5798e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,348][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ companies] are: tensor([9.4304e-08, 1.9839e-01, 5.5855e-01, 3.8973e-02, 3.7315e-02, 5.0671e-02,
        5.2868e-03, 9.4617e-02, 1.6198e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies]
[2024-07-23 21:07:13,355][circuit_model.py][line:1570][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ including] are: tensor([0.0029, 0.0713, 0.0217, 0.0812, 0.0292, 0.3466, 0.0508, 0.1034, 0.1400,
        0.1529], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,359][circuit_model.py][line:1573][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ including] are: tensor([3.4673e-06, 7.6786e-02, 2.3415e-01, 5.0874e-02, 5.1677e-02, 4.2557e-01,
        8.4757e-02, 1.9928e-02, 8.5106e-03, 4.7743e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,363][circuit_model.py][line:1576][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ including] are: tensor([1.1152e-07, 7.3158e-02, 6.3102e-01, 7.6800e-02, 3.0130e-02, 1.0446e-01,
        9.5631e-03, 1.0471e-02, 1.9031e-02, 4.5359e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,366][circuit_model.py][line:1579][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ including] are: tensor([3.7764e-08, 3.3778e-01, 3.5171e-01, 3.1282e-02, 4.8148e-02, 1.0331e-01,
        5.1112e-03, 4.6495e-03, 7.3232e-02, 4.4775e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,368][circuit_model.py][line:1582][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ including] are: tensor([3.9353e-07, 1.8198e-01, 3.2990e-01, 3.5870e-02, 1.2113e-01, 1.7089e-01,
        3.5122e-03, 2.0131e-02, 1.1053e-02, 1.2553e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,369][circuit_model.py][line:1585][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ including] are: tensor([5.9493e-09, 4.4102e-02, 1.1167e-01, 1.0539e-01, 1.4070e-01, 3.1433e-01,
        6.0737e-02, 7.6124e-02, 4.3352e-02, 1.0359e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,370][circuit_model.py][line:1588][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ including] are: tensor([8.0019e-07, 8.5972e-02, 3.7859e-01, 1.5758e-01, 4.7785e-02, 1.1755e-01,
        2.8610e-02, 4.5364e-02, 1.4314e-02, 1.2424e-01], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,371][circuit_model.py][line:1591][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ including] are: tensor([1.0781e-06, 1.5296e-02, 1.6889e-01, 1.7550e-01, 9.3205e-02, 3.1982e-01,
        4.8257e-02, 4.3694e-02, 6.2595e-02, 7.2740e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,373][circuit_model.py][line:1594][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ including] are: tensor([1.3440e-04, 2.0809e-02, 2.5209e-02, 1.7709e-02, 6.9830e-02, 6.3636e-01,
        1.4350e-02, 4.6339e-02, 1.4081e-01, 2.8449e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,377][circuit_model.py][line:1597][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ including] are: tensor([2.0820e-07, 1.2138e-02, 1.0818e-01, 9.1682e-02, 9.2479e-02, 2.1231e-01,
        3.2246e-01, 4.8990e-02, 2.7231e-02, 8.4527e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,381][circuit_model.py][line:1600][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ including] are: tensor([1.4155e-08, 9.5613e-02, 6.0050e-01, 6.1615e-02, 5.5322e-02, 1.6228e-01,
        1.5945e-03, 6.3294e-03, 1.0757e-02, 5.9814e-03], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,385][circuit_model.py][line:1603][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ including] are: tensor([8.4260e-08, 2.9492e-01, 4.4320e-01, 5.9218e-02, 2.7973e-02, 5.0394e-02,
        4.2438e-03, 8.5160e-02, 2.3555e-02, 1.1345e-02], device='cuda:0') for source tokens [Tizen is developed by a consortium of companies including]
[2024-07-23 21:07:13,389][circuit_model.py][line:1378][INFO] ############showing the lable-rank of each circuit
[2024-07-23 21:07:13,392][circuit_model.py][line:1466][INFO] The CircuitSUM has label_rank 
 tensor([[5260],
        [ 806],
        [  40],
        [  54],
        [  17],
        [   8],
        [  38],
        [   2],
        [  10],
        [   1]], device='cuda:0')
[2024-07-23 21:07:13,395][circuit_model.py][line:1468][INFO] The Circuit0 has label_rank 
 tensor([[4651],
        [ 961],
        [  46],
        [ 130],
        [  78],
        [  29],
        [  90],
        [   5],
        [  26],
        [   7]], device='cuda:0')
[2024-07-23 21:07:13,397][circuit_model.py][line:1470][INFO] The Circuit1 has label_rank 
 tensor([[8777],
        [2530],
        [2759],
        [1312],
        [1498],
        [3313],
        [2750],
        [3346],
        [3686],
        [4136]], device='cuda:0')
[2024-07-23 21:07:13,399][circuit_model.py][line:1472][INFO] The Circuit2 has label_rank 
 tensor([[25600],
        [ 5912],
        [ 5751],
        [ 5277],
        [ 4993],
        [ 4756],
        [ 5491],
        [ 5157],
        [ 5290],
        [ 4728]], device='cuda:0')
[2024-07-23 21:07:13,400][circuit_model.py][line:1474][INFO] The Circuit3 has label_rank 
 tensor([[21886],
        [36531],
        [38357],
        [38132],
        [39358],
        [39271],
        [38016],
        [37121],
        [36355],
        [35921]], device='cuda:0')
[2024-07-23 21:07:13,401][circuit_model.py][line:1476][INFO] The Circuit4 has label_rank 
 tensor([[1233],
        [3017],
        [1872],
        [1546],
        [1771],
        [2114],
        [1883],
        [1705],
        [1674],
        [1428]], device='cuda:0')
[2024-07-23 21:07:13,403][circuit_model.py][line:1478][INFO] The Circuit5 has label_rank 
 tensor([[9015],
        [7270],
        [5629],
        [5738],
        [4252],
        [3948],
        [3649],
        [3341],
        [4065],
        [3982]], device='cuda:0')
[2024-07-23 21:07:13,406][circuit_model.py][line:1480][INFO] The Circuit6 has label_rank 
 tensor([[41654],
        [25039],
        [19344],
        [18216],
        [17296],
        [19029],
        [20473],
        [19619],
        [19110],
        [19596]], device='cuda:0')
[2024-07-23 21:07:13,409][circuit_model.py][line:1482][INFO] The Circuit7 has label_rank 
 tensor([[32156],
        [11611],
        [12927],
        [14230],
        [14177],
        [14075],
        [13514],
        [13538],
        [13358],
        [13338]], device='cuda:0')
[2024-07-23 21:07:13,412][circuit_model.py][line:1484][INFO] The Circuit8 has label_rank 
 tensor([[1830],
        [2443],
        [4343],
        [3329],
        [4247],
        [3127],
        [2673],
        [2329],
        [2420],
        [3005]], device='cuda:0')
[2024-07-23 21:07:13,415][circuit_model.py][line:1486][INFO] The Circuit9 has label_rank 
 tensor([[8843],
        [8761],
        [8769],
        [5862],
        [5839],
        [7360],
        [5920],
        [5903],
        [5971],
        [5988]], device='cuda:0')
[2024-07-23 21:07:13,418][circuit_model.py][line:1488][INFO] The Circuit10 has label_rank 
 tensor([[39999],
        [39999],
        [40004],
        [39999],
        [40003],
        [40000],
        [39999],
        [39963],
        [39999],
        [39985]], device='cuda:0')
[2024-07-23 21:07:13,421][circuit_model.py][line:1490][INFO] The Circuit11 has label_rank 
 tensor([[19993],
        [19987],
        [19575],
        [20196],
        [19034],
        [16759],
        [17726],
        [18799],
        [16623],
        [11837]], device='cuda:0')
[2024-07-23 21:07:13,424][circuit_model.py][line:1492][INFO] The Circuit12 has label_rank 
 tensor([[ 7727],
        [14967],
        [17460],
        [18789],
        [18687],
        [21944],
        [25829],
        [27487],
        [27494],
        [27727]], device='cuda:0')
[2024-07-23 21:07:13,427][circuit_model.py][line:1494][INFO] The Circuit13 has label_rank 
 tensor([[10975],
        [ 2285],
        [ 1633],
        [ 5654],
        [ 2921],
        [ 3577],
        [ 2926],
        [ 3038],
        [ 4709],
        [ 1731]], device='cuda:0')
[2024-07-23 21:07:13,429][circuit_model.py][line:1496][INFO] The Circuit14 has label_rank 
 tensor([[8845],
        [7379],
        [7133],
        [8848],
        [8577],
        [7472],
        [7935],
        [7261],
        [7470],
        [7334]], device='cuda:0')
[2024-07-23 21:07:13,430][circuit_model.py][line:1498][INFO] The Circuit15 has label_rank 
 tensor([[20616],
        [12341],
        [15846],
        [16222],
        [16326],
        [18316],
        [18199],
        [18654],
        [18197],
        [18238]], device='cuda:0')
[2024-07-23 21:07:13,431][circuit_model.py][line:1500][INFO] The Circuit16 has label_rank 
 tensor([[42413],
        [30549],
        [26130],
        [26406],
        [26571],
        [26671],
        [26707],
        [27121],
        [27131],
        [27190]], device='cuda:0')
[2024-07-23 21:07:13,433][circuit_model.py][line:1502][INFO] The Circuit17 has label_rank 
 tensor([[30063],
        [21934],
        [21387],
        [21415],
        [21584],
        [21677],
        [21539],
        [22515],
        [21973],
        [23007]], device='cuda:0')
[2024-07-23 21:07:13,436][circuit_model.py][line:1504][INFO] The Circuit18 has label_rank 
 tensor([[ 1608],
        [13642],
        [13658],
        [13818],
        [12984],
        [11241],
        [12460],
        [11020],
        [12076],
        [11358]], device='cuda:0')
[2024-07-23 21:07:13,439][circuit_model.py][line:1506][INFO] The Circuit19 has label_rank 
 tensor([[2124],
        [3925],
        [4340],
        [5321],
        [5162],
        [5409],
        [5320],
        [5476],
        [5517],
        [5187]], device='cuda:0')
[2024-07-23 21:07:13,442][circuit_model.py][line:1508][INFO] The Circuit20 has label_rank 
 tensor([[ 5695],
        [14600],
        [18222],
        [19529],
        [21326],
        [21640],
        [21029],
        [22351],
        [22448],
        [23322]], device='cuda:0')
[2024-07-23 21:07:13,445][circuit_model.py][line:1510][INFO] The Circuit21 has label_rank 
 tensor([[ 9713],
        [11326],
        [ 9085],
        [ 7920],
        [ 8227],
        [12438],
        [11265],
        [12050],
        [10846],
        [11336]], device='cuda:0')
[2024-07-23 21:07:13,448][circuit_model.py][line:1512][INFO] The Circuit22 has label_rank 
 tensor([[15709],
        [10451],
        [10071],
        [ 9869],
        [ 9582],
        [ 9592],
        [ 9498],
        [ 9517],
        [ 9855],
        [ 9886]], device='cuda:0')
[2024-07-23 21:07:13,451][circuit_model.py][line:1514][INFO] The Circuit23 has label_rank 
 tensor([[7161],
        [7748],
        [4061],
        [4138],
        [4291],
        [3888],
        [3733],
        [3677],
        [3647],
        [3633]], device='cuda:0')
[2024-07-23 21:07:13,454][circuit_model.py][line:1516][INFO] The Circuit24 has label_rank 
 tensor([[2347],
        [3088],
        [2402],
        [2546],
        [2353],
        [2289],
        [2329],
        [2312],
        [2075],
        [2059]], device='cuda:0')
[2024-07-23 21:07:13,457][circuit_model.py][line:1518][INFO] The Circuit25 has label_rank 
 tensor([[ 6903],
        [20673],
        [14496],
        [14250],
        [14813],
        [15230],
        [13692],
        [14987],
        [14739],
        [15563]], device='cuda:0')
[2024-07-23 21:07:13,460][circuit_model.py][line:1520][INFO] The Circuit26 has label_rank 
 tensor([[30346],
        [30736],
        [34272],
        [33411],
        [32874],
        [31694],
        [31810],
        [31247],
        [31678],
        [31603]], device='cuda:0')
[2024-07-23 21:07:13,461][circuit_model.py][line:1522][INFO] The Circuit27 has label_rank 
 tensor([[36121],
        [44381],
        [45079],
        [40959],
        [42857],
        [41111],
        [43028],
        [43102],
        [41850],
        [44302]], device='cuda:0')
[2024-07-23 21:07:13,462][circuit_model.py][line:1524][INFO] The Circuit28 has label_rank 
 tensor([[11941],
        [11941],
        [11941],
        [11941],
        [11941],
        [11941],
        [11941],
        [11941],
        [11941],
        [11941]], device='cuda:0')
