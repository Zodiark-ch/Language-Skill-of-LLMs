[2024-07-24 10:30:04,085][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isAfter Rebecca and Amy went to the station, Amy gave a necklace to
[2024-07-24 10:30:04,085][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Rebecca
[2024-07-24 10:30:04,085][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:30:04,085][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:30:04,085][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:30:04,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,086][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:30:04,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,086][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:30:04,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,086][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:30:04,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,087][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:30:04,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,087][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:30:04,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,087][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:30:04,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,087][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:30:04,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,088][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:30:04,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,088][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:30:04,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,088][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:30:04,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,088][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:30:04,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,089][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:30:04,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,089][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:30:04,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,089][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:30:04,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit27']
[2024-07-24 10:30:04,089][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit4', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,090][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,091][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,092][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit13', 'circuit17', 'circuit20']
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15']
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:30:04,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit26']
[2024-07-24 10:30:04,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7']
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:30:04,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit16', 'circuit17', 'circuit18', 'circuit20']
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit27']
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,097][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,098][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:30:04,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit25']
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:30:04,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit5', 'circuit10', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit22']
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit24']
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,103][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit18']
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,105][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit18', 'circuit20', 'circuit22']
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:30:04,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit15']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:30:04,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,108][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit15']
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit21']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:30:04,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:30:04,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7']
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit23', 'circuit27']
[2024-07-24 10:30:04,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit12', 'circuit28']
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit14', 'circuit15', 'circuit20', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit22', 'circuit23']
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22']
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,115][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit6', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit24']
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit21', 'circuit23']
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23']
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:30:04,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:30:04,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit11', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit28']
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2']
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit12']
[2024-07-24 10:30:04,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit8', 'circuit11', 'circuit12', 'circuit28']
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,123][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:30:04,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,127][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit15', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit23']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit24', 'circuit27']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit20']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:30:04,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit11', 'circuit27']
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,129][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,130][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit12']
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,131][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit22', 'circuit23']
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:30:04,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit9', 'circuit10', 'circuit13', 'circuit15', 'circuit16']
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:30:04,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24']
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,134][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21']
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,135][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,136][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,137][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,138][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,140][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,141][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,142][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,143][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,146][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15']
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit26']
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit13', 'circuit17', 'circuit20', 'circuit23']
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit24', 'circuit27']
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,147][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,149][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit8', 'circuit15', 'circuit17', 'circuit22']
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit22', 'circuit23']
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,150][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit26']
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit18']
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit26']
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:30:04,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit26']
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit9', 'circuit13']
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit12']
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit14', 'circuit24']
[2024-07-24 10:30:04,152][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit22', 'circuit27']
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit28']
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,155][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:30:04,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,159][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:30:04,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,162][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit8', 'circuit15', 'circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17']
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit17']
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit20', 'circuit24']
[2024-07-24 10:30:04,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit25']
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit27']
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19']
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit11', 'circuit26']
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit16']
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit19', 'circuit20', 'circuit25']
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit26']
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit23']
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18']
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit18', 'circuit19']
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit18', 'circuit22', 'circuit25']
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit21']
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:30:04,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:30:04,177][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,178][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:30:04,179][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,180][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,181][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,182][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit23']
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit17']
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,183][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit13', 'circuit16']
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit6', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15']
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit18']
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20']
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:30:04,184][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit27']
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,185][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit15', 'circuit16', 'circuit17']
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit16']
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,186][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:30:04,187][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit11', 'circuit27']
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit27']
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit15']
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16']
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,188][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20']
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit20']
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,189][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:30:04,190][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,191][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit22']
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,192][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,193][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,194][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,195][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,196][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,197][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,198][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,199][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,200][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,201][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,202][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,203][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,204][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit12', 'circuit13', 'circuit16', 'circuit19', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,205][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,206][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit15']
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,207][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,208][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,209][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,210][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:30:04,211][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit24']
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17']
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit19', 'circuit22', 'circuit25']
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17']
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,212][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,213][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit21', 'circuit22']
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit19', 'circuit21']
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13']
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,214][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,215][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,216][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,217][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,218][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,219][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,220][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,221][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,222][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,223][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,224][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,225][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,226][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,227][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit8', 'circuit14', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit3', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,228][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:30:04,229][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20']
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,230][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit14']
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,231][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,232][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,233][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,234][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,235][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit22', 'circuit26']
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit25']
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,236][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit16']
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:30:04,237][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,238][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit27']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit19', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,239][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,240][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,241][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,242][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,243][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:30:04,244][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,245][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,246][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,247][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,248][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,249][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:30:04,250][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,251][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:30:04,252][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:04,253][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:30:05,235][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:05,237][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,238][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,238][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,238][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,239][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,239][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,239][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,251][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,253][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,257][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,259][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,260][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,260][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.8198, 0.1802], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,260][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([1.2604e-04, 9.9987e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,261][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.8170, 0.1830], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,261][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0823, 0.9177], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,261][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.1456, 0.8544], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,262][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0297, 0.9703], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,263][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.7729, 0.2271], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,266][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.9761, 0.0239], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,270][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.8263, 0.1737], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,273][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.8951, 0.1049], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,275][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.7426, 0.2574], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,275][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.6576, 0.3424], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,276][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8047, 0.1271, 0.0682], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,276][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.4096e-03, 5.3376e-04, 9.9506e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,276][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4105, 0.0594, 0.5301], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,277][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2416, 0.0504, 0.7080], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,277][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.6551, 0.1531, 0.1918], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,277][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1835, 0.0096, 0.8069], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,278][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6599, 0.3161, 0.0240], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,279][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4310, 0.3476, 0.2215], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,282][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2518, 0.0471, 0.7011], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,286][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5986, 0.1546, 0.2468], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,289][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6778, 0.0853, 0.2370], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,291][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5380, 0.1243, 0.3376], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,291][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.2688, 0.1740, 0.2096, 0.3476], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,292][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([4.6278e-05, 1.6901e-04, 3.5896e-05, 9.9975e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,292][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.5631, 0.1142, 0.0941, 0.2286], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,292][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([9.6716e-03, 1.5940e-03, 2.3172e-04, 9.8850e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,293][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.0536, 0.1479, 0.0089, 0.7895], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,293][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([7.3251e-03, 2.7338e-04, 4.6307e-06, 9.9240e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,293][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.4073, 0.2691, 0.1094, 0.2142], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,295][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.4363, 0.0970, 0.3387, 0.1281], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,298][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.4855, 0.1654, 0.2178, 0.1313], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,302][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.5116, 0.2014, 0.2292, 0.0578], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,306][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.4358, 0.0916, 0.1548, 0.3179], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,306][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.2740, 0.1981, 0.3657, 0.1622], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,307][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.4962, 0.0715, 0.0878, 0.0708, 0.2738], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,307][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0012, 0.0031, 0.0018, 0.0032, 0.9908], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,307][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.6005, 0.0709, 0.1899, 0.0525, 0.0861], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,308][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0308, 0.0014, 0.0020, 0.0010, 0.9647], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,308][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.3537, 0.0380, 0.0519, 0.2038, 0.3526], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,309][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ went] are: tensor([2.6716e-02, 1.0307e-04, 6.5625e-05, 6.7345e-05, 9.7305e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,309][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2453, 0.2452, 0.0372, 0.4359, 0.0365], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,309][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2240, 0.1216, 0.2381, 0.2180, 0.1983], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,311][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.3724, 0.1185, 0.3627, 0.0858, 0.0607], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,314][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.4243, 0.1375, 0.2074, 0.1168, 0.1140], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,318][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.4135, 0.0900, 0.1862, 0.0502, 0.2601], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,322][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.4715, 0.0997, 0.2348, 0.0753, 0.1187], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,322][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4607, 0.0852, 0.0620, 0.1097, 0.2493, 0.0330], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,323][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.9584e-03, 4.2953e-04, 6.7536e-02, 8.9304e-04, 8.4792e-04, 9.2434e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,323][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3788, 0.0638, 0.1706, 0.0662, 0.0769, 0.2437], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,323][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0323, 0.0055, 0.0211, 0.0158, 0.4578, 0.4676], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,324][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1517, 0.0460, 0.0256, 0.0425, 0.6059, 0.1283], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,324][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0848, 0.0034, 0.1476, 0.0024, 0.0158, 0.7459], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,325][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3087, 0.1176, 0.0169, 0.0986, 0.0804, 0.3777], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,326][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1330, 0.0682, 0.1132, 0.1601, 0.2889, 0.2364], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,329][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0607, 0.0125, 0.3510, 0.0134, 0.0657, 0.4967], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,333][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3520, 0.1025, 0.1884, 0.0844, 0.0885, 0.1842], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,337][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3426, 0.0807, 0.2363, 0.0598, 0.0885, 0.1921], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,338][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3361, 0.1067, 0.1786, 0.0720, 0.1234, 0.1832], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,338][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4485, 0.1880, 0.0394, 0.1515, 0.1202, 0.0207, 0.0317],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,339][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.1015e-03, 7.7434e-04, 6.6693e-02, 1.7771e-03, 1.9109e-04, 8.7239e-02,
        8.3422e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,339][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3345, 0.0603, 0.1425, 0.0383, 0.1100, 0.2743, 0.0401],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,339][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0505, 0.0087, 0.0233, 0.0140, 0.0852, 0.1822, 0.6361],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,340][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2988, 0.0446, 0.0416, 0.0610, 0.2883, 0.1237, 0.1422],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,340][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1793, 0.0187, 0.1519, 0.0110, 0.0411, 0.1352, 0.4630],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,340][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2566, 0.3122, 0.0060, 0.3406, 0.0718, 0.0095, 0.0035],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,342][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1167, 0.0373, 0.0812, 0.0961, 0.1442, 0.2255, 0.2991],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,345][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0307, 0.0078, 0.1971, 0.0082, 0.0527, 0.2111, 0.4923],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,351][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3167, 0.1015, 0.1544, 0.0756, 0.0774, 0.1501, 0.1243],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,353][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.3515, 0.0723, 0.1687, 0.0662, 0.0446, 0.1146, 0.1821],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,353][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2736, 0.1025, 0.1433, 0.0815, 0.1042, 0.1391, 0.1559],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,354][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.3156, 0.1030, 0.1404, 0.0831, 0.0800, 0.0680, 0.1073, 0.1027],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,354][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ station] are: tensor([5.8183e-04, 1.0674e-03, 4.0089e-03, 4.4793e-03, 1.0886e-03, 1.8360e-03,
        4.8220e-04, 9.8646e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,354][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.2832, 0.1693, 0.0831, 0.0635, 0.0726, 0.0875, 0.0704, 0.1703],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,355][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ station] are: tensor([1.2223e-02, 4.6110e-04, 1.7870e-04, 6.5920e-03, 6.2486e-03, 1.4307e-03,
        9.6664e-04, 9.7190e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,355][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0573, 0.0279, 0.0055, 0.0717, 0.0303, 0.0101, 0.0164, 0.7809],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,356][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ station] are: tensor([1.2817e-02, 1.2282e-03, 1.8588e-05, 3.4319e-04, 5.4268e-05, 3.4095e-06,
        4.1091e-06, 9.8553e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,362][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2426, 0.2603, 0.0411, 0.1513, 0.0258, 0.0272, 0.0345, 0.2173],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,366][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0589, 0.0330, 0.0442, 0.1768, 0.0933, 0.1691, 0.2854, 0.1393],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,367][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.2370, 0.0651, 0.1607, 0.0543, 0.0618, 0.1437, 0.1123, 0.1650],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,367][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.2807, 0.1206, 0.1432, 0.1056, 0.0840, 0.1211, 0.1276, 0.0171],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,368][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1562, 0.0746, 0.1429, 0.0890, 0.0576, 0.1071, 0.0993, 0.2733],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,368][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.2454, 0.0596, 0.1118, 0.0557, 0.0987, 0.1728, 0.0503, 0.2057],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,368][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4453, 0.0816, 0.0205, 0.1310, 0.1203, 0.0188, 0.0595, 0.1093, 0.0138],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,369][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([3.4281e-03, 7.3966e-04, 2.5553e-02, 9.1909e-04, 5.2651e-04, 9.1213e-03,
        1.2507e-03, 1.1294e-04, 9.5835e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,369][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2756, 0.0347, 0.1205, 0.0189, 0.0475, 0.0609, 0.0138, 0.0116, 0.4164],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,372][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0514, 0.0013, 0.0081, 0.0026, 0.0735, 0.0445, 0.1174, 0.0662, 0.6350],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,377][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5150, 0.0200, 0.0153, 0.0492, 0.0715, 0.0515, 0.0282, 0.0749, 0.1743],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,381][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1393, 0.0182, 0.2003, 0.0205, 0.0601, 0.0995, 0.1485, 0.0197, 0.2939],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,381][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2876, 0.1996, 0.0100, 0.2586, 0.0619, 0.0198, 0.0065, 0.1499, 0.0061],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,382][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0515, 0.0258, 0.0327, 0.0751, 0.0666, 0.0876, 0.1725, 0.1522, 0.3359],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,382][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0343, 0.0068, 0.1784, 0.0050, 0.0216, 0.1584, 0.2319, 0.0123, 0.3514],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,382][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2661, 0.0882, 0.1350, 0.0661, 0.0722, 0.1251, 0.0992, 0.0461, 0.1019],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,383][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2277, 0.0864, 0.1638, 0.0705, 0.0696, 0.1358, 0.0988, 0.0368, 0.1105],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,383][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2472, 0.0771, 0.1215, 0.0576, 0.0915, 0.1111, 0.0632, 0.0953, 0.1354],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,387][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.1121, 0.0907, 0.0868, 0.1918, 0.0182, 0.0952, 0.0723, 0.0487, 0.0699,
        0.2143], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,390][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([2.3585e-05, 6.5517e-05, 1.3426e-05, 5.4074e-01, 1.0560e-05, 7.5926e-06,
        1.2112e-05, 2.6993e-05, 3.8046e-06, 4.5910e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,395][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.2903, 0.0816, 0.0598, 0.1707, 0.0578, 0.0427, 0.0795, 0.0170, 0.0569,
        0.1437], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,397][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([1.1357e-03, 2.8172e-05, 2.4673e-06, 1.7396e-02, 1.1067e-05, 1.5544e-05,
        3.3051e-05, 2.3681e-04, 6.7503e-05, 9.8107e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,397][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.0108, 0.0188, 0.0014, 0.1296, 0.0034, 0.0043, 0.0043, 0.0031, 0.0086,
        0.8159], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,398][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([1.5946e-03, 1.0210e-04, 9.0777e-07, 5.5921e-01, 2.4163e-06, 3.7435e-08,
        3.8929e-07, 6.3991e-06, 2.1484e-07, 4.3908e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,398][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.2051, 0.1858, 0.0644, 0.1702, 0.0235, 0.0192, 0.0477, 0.0640, 0.0610,
        0.1591], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,398][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.1387, 0.0164, 0.0481, 0.0237, 0.0547, 0.1158, 0.1591, 0.0217, 0.2779,
        0.1438], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,399][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.2313, 0.0909, 0.1239, 0.0877, 0.0521, 0.0928, 0.0903, 0.0386, 0.1149,
        0.0774], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,399][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.2419, 0.1223, 0.1264, 0.0345, 0.0568, 0.1066, 0.1014, 0.0636, 0.1145,
        0.0320], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,400][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.1483, 0.0581, 0.0818, 0.2864, 0.0271, 0.0590, 0.0544, 0.0246, 0.0498,
        0.2105], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,403][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0935, 0.0844, 0.1190, 0.0712, 0.1389, 0.0919, 0.0938, 0.1001, 0.1075,
        0.0997], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,409][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2913, 0.0310, 0.0351, 0.0343, 0.2357, 0.0229, 0.0217, 0.0519, 0.0251,
        0.0379, 0.2132], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,411][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([9.4310e-04, 3.7818e-03, 2.3495e-03, 1.0285e-03, 8.8099e-03, 1.1932e-03,
        3.2090e-04, 1.6694e-04, 3.6626e-04, 6.1971e-04, 9.8042e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,411][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.3199, 0.0339, 0.0776, 0.0687, 0.0895, 0.1182, 0.0765, 0.0164, 0.0480,
        0.0615, 0.0897], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,412][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([2.3858e-03, 3.2197e-05, 2.9796e-05, 1.6460e-05, 1.0951e-03, 1.3025e-04,
        1.9874e-04, 5.5593e-04, 1.7818e-03, 8.1308e-04, 9.9296e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,412][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1335, 0.0163, 0.0139, 0.0230, 0.0382, 0.0314, 0.0207, 0.0234, 0.0449,
        0.1103, 0.5445], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,413][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.7284e-02, 6.8195e-04, 3.9492e-05, 9.1995e-05, 1.0248e-02, 4.1284e-06,
        1.4022e-05, 2.1766e-06, 1.9004e-06, 3.4559e-05, 9.4160e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,413][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1364, 0.1483, 0.0189, 0.2054, 0.0300, 0.0137, 0.0181, 0.1253, 0.0152,
        0.2562, 0.0323], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,414][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0475, 0.0122, 0.0211, 0.0232, 0.0240, 0.0481, 0.0805, 0.0472, 0.1975,
        0.2485, 0.2503], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,414][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1314, 0.0457, 0.1429, 0.0288, 0.0479, 0.1360, 0.1859, 0.0374, 0.1665,
        0.0311, 0.0465], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,417][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1957, 0.0772, 0.1038, 0.0620, 0.0849, 0.1012, 0.0829, 0.0613, 0.0916,
        0.0647, 0.0747], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,423][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1656, 0.0856, 0.0980, 0.0422, 0.1045, 0.0933, 0.0658, 0.0254, 0.0713,
        0.0344, 0.2139], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,425][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.3061, 0.0468, 0.1289, 0.0371, 0.0517, 0.1093, 0.0485, 0.0516, 0.1063,
        0.0351, 0.0785], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,426][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2691, 0.1025, 0.0253, 0.1063, 0.0661, 0.0163, 0.0302, 0.0660, 0.0261,
        0.1371, 0.1306, 0.0243], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,426][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.0289e-03, 1.8992e-03, 3.7230e-03, 1.6979e-03, 1.0803e-04, 9.8199e-03,
        3.0918e-02, 5.2302e-05, 1.0073e-03, 1.1025e-03, 2.1845e-04, 9.4642e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,427][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1899, 0.0515, 0.1238, 0.0429, 0.0856, 0.2006, 0.0283, 0.0184, 0.0817,
        0.0419, 0.1092, 0.0263], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,427][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.2162e-02, 6.7027e-04, 9.5468e-04, 5.6903e-04, 2.0055e-03, 4.1403e-03,
        1.6307e-02, 7.3671e-03, 4.9920e-02, 2.0461e-02, 1.3571e-01, 7.4974e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,427][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0618, 0.0120, 0.0063, 0.0081, 0.0633, 0.0164, 0.0177, 0.0173, 0.0319,
        0.0453, 0.5371, 0.1827], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,428][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0654, 0.0101, 0.1042, 0.0030, 0.0110, 0.0923, 0.2242, 0.0021, 0.0313,
        0.0013, 0.0075, 0.4475], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,429][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1560, 0.1473, 0.0044, 0.1664, 0.0646, 0.0083, 0.0034, 0.1280, 0.0031,
        0.2299, 0.0830, 0.0056], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,433][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0359, 0.0062, 0.0116, 0.0106, 0.0243, 0.0234, 0.0408, 0.0335, 0.1203,
        0.1043, 0.2967, 0.2925], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,438][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0159, 0.0038, 0.0798, 0.0050, 0.0219, 0.0965, 0.2264, 0.0124, 0.1529,
        0.0069, 0.0279, 0.3505], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,440][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1874, 0.0619, 0.1069, 0.0588, 0.0536, 0.1023, 0.0871, 0.0419, 0.0841,
        0.0587, 0.0698, 0.0876], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,440][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1732, 0.0662, 0.1108, 0.0536, 0.0383, 0.1031, 0.1103, 0.0281, 0.0725,
        0.0431, 0.0401, 0.1606], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,441][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2005, 0.0681, 0.0878, 0.0415, 0.0691, 0.0972, 0.0528, 0.0725, 0.1003,
        0.0413, 0.0965, 0.0724], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,441][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1998, 0.1109, 0.1362, 0.0636, 0.0186, 0.1261, 0.0614, 0.0375, 0.0874,
        0.0544, 0.0222, 0.0550, 0.0270], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,442][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([2.9205e-04, 1.9909e-02, 2.8746e-04, 4.2218e-03, 6.2903e-04, 1.5392e-04,
        7.2814e-05, 9.6465e-05, 1.5889e-04, 2.3786e-03, 1.0218e-03, 9.7887e-05,
        9.7068e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,442][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.2410, 0.0832, 0.0871, 0.0468, 0.1108, 0.0529, 0.0937, 0.0393, 0.0324,
        0.0378, 0.0796, 0.0757, 0.0196], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,442][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([1.0432e-03, 9.1255e-06, 6.5395e-07, 4.9460e-05, 6.4645e-05, 3.0923e-06,
        2.1788e-06, 6.0181e-04, 1.7009e-05, 1.5450e-03, 2.8186e-03, 8.4061e-05,
        9.9376e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,444][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([2.1623e-02, 5.9759e-03, 4.4355e-04, 1.9878e-02, 4.6098e-03, 7.3642e-04,
        1.1447e-03, 1.0761e-03, 1.9895e-03, 7.8462e-02, 3.4949e-02, 3.0882e-03,
        8.2602e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,446][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([2.2824e-05, 3.3534e-05, 1.5530e-09, 7.6150e-07, 1.7649e-07, 7.5638e-11,
        5.9341e-11, 1.7489e-07, 1.7791e-10, 2.0384e-07, 8.0125e-09, 6.4062e-11,
        9.9994e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,452][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1121, 0.1528, 0.0669, 0.1765, 0.0151, 0.0136, 0.0476, 0.0392, 0.0559,
        0.1672, 0.0133, 0.0512, 0.0887], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,454][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0425, 0.0056, 0.0225, 0.0059, 0.0218, 0.0464, 0.0489, 0.0117, 0.1251,
        0.0312, 0.2329, 0.3534, 0.0521], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,455][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.2238, 0.0505, 0.0604, 0.0569, 0.0488, 0.0397, 0.0487, 0.0422, 0.0403,
        0.0481, 0.0438, 0.0428, 0.2539], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,455][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.2116, 0.0753, 0.0977, 0.0424, 0.0548, 0.0825, 0.0753, 0.0609, 0.0836,
        0.0398, 0.0883, 0.0792, 0.0085], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,456][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.1470, 0.0688, 0.0958, 0.0582, 0.0557, 0.0727, 0.0472, 0.0259, 0.0627,
        0.0435, 0.0464, 0.0481, 0.2278], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,456][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0824, 0.0630, 0.0736, 0.0381, 0.0767, 0.0850, 0.0710, 0.0511, 0.0951,
        0.0428, 0.1223, 0.1142, 0.0848], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,456][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2096, 0.0363, 0.0220, 0.0484, 0.1233, 0.0119, 0.0267, 0.0526, 0.0233,
        0.0619, 0.1322, 0.0268, 0.2091, 0.0158], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,457][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([2.8448e-03, 1.0125e-04, 2.1796e-02, 1.6938e-04, 2.6962e-04, 4.6066e-01,
        1.1716e-03, 1.1461e-04, 4.8511e-03, 1.0519e-04, 3.8283e-04, 7.0084e-04,
        8.8092e-06, 5.0682e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,460][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1961, 0.0381, 0.0969, 0.0426, 0.0541, 0.1470, 0.0287, 0.0151, 0.0579,
        0.0400, 0.0667, 0.0258, 0.0221, 0.1691], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,463][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.1820e-03, 8.9376e-05, 2.0026e-04, 1.1918e-04, 2.9128e-03, 2.0541e-03,
        2.5590e-03, 6.0660e-04, 6.8161e-03, 3.3256e-03, 2.5789e-01, 7.1838e-02,
        5.8318e-02, 5.8909e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,468][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0364, 0.0047, 0.0032, 0.0039, 0.0605, 0.0118, 0.0072, 0.0167, 0.0104,
        0.0210, 0.3357, 0.0753, 0.1820, 0.2314], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,469][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([2.2190e-02, 1.4232e-03, 6.2518e-02, 9.5518e-04, 8.8791e-03, 3.8624e-01,
        1.4335e-01, 1.5451e-03, 1.3961e-02, 4.0628e-04, 4.4240e-03, 9.7398e-02,
        2.6597e-04, 2.5645e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,469][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1135, 0.0485, 0.0050, 0.0439, 0.0336, 0.1505, 0.0032, 0.0676, 0.0039,
        0.0624, 0.0514, 0.0055, 0.1361, 0.2750], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,470][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0261, 0.0040, 0.0062, 0.0082, 0.0124, 0.0086, 0.0192, 0.0145, 0.0492,
        0.0650, 0.1194, 0.1624, 0.2180, 0.2869], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,470][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0133, 0.0026, 0.0881, 0.0034, 0.0195, 0.1201, 0.1623, 0.0097, 0.1386,
        0.0043, 0.0188, 0.1904, 0.0090, 0.2200], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,471][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1580, 0.0534, 0.0904, 0.0449, 0.0482, 0.0864, 0.0772, 0.0369, 0.0723,
        0.0448, 0.0638, 0.0820, 0.0394, 0.1021], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,471][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1250, 0.0432, 0.1076, 0.0395, 0.0665, 0.1204, 0.0838, 0.0281, 0.0768,
        0.0330, 0.0591, 0.0824, 0.0229, 0.1118], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,474][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1700, 0.0567, 0.0774, 0.0395, 0.0636, 0.0766, 0.0373, 0.0608, 0.0807,
        0.0378, 0.0854, 0.0498, 0.0851, 0.0791], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,486][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:05,490][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,493][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,493][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,493][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,494][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,494][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,494][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,495][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,495][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,495][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,496][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,496][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,496][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.8198, 0.1802], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,497][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([1.2604e-04, 9.9987e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,497][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.8170, 0.1830], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,497][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.0823, 0.9177], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,498][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.1456, 0.8544], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,498][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.0297, 0.9703], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,498][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.7729, 0.2271], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,499][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.9761, 0.0239], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,499][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.8263, 0.1737], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,499][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.8951, 0.1049], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,500][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.7426, 0.2574], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,500][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.6576, 0.3424], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,500][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8047, 0.1271, 0.0682], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,501][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.4096e-03, 5.3376e-04, 9.9506e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,501][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4105, 0.0594, 0.5301], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,501][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2416, 0.0504, 0.7080], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,502][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6551, 0.1531, 0.1918], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,502][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1835, 0.0096, 0.8069], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,502][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6599, 0.3161, 0.0240], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,503][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4310, 0.3476, 0.2215], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,503][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2518, 0.0471, 0.7011], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,503][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5986, 0.1546, 0.2468], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,504][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6778, 0.0853, 0.2370], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,504][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5380, 0.1243, 0.3376], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,504][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.2688, 0.1740, 0.2096, 0.3476], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,505][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([4.6278e-05, 1.6901e-04, 3.5896e-05, 9.9975e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,505][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.5631, 0.1142, 0.0941, 0.2286], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,506][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([9.6716e-03, 1.5940e-03, 2.3172e-04, 9.8850e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,506][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.0536, 0.1479, 0.0089, 0.7895], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,506][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([7.3251e-03, 2.7338e-04, 4.6307e-06, 9.9240e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,508][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.4073, 0.2691, 0.1094, 0.2142], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,512][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.4363, 0.0970, 0.3387, 0.1281], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,518][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.4855, 0.1654, 0.2178, 0.1313], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,518][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.5116, 0.2014, 0.2292, 0.0578], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,518][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.4358, 0.0916, 0.1548, 0.3179], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,519][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.2740, 0.1981, 0.3657, 0.1622], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,519][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.4962, 0.0715, 0.0878, 0.0708, 0.2738], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,520][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0012, 0.0031, 0.0018, 0.0032, 0.9908], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,520][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.6005, 0.0709, 0.1899, 0.0525, 0.0861], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,520][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0308, 0.0014, 0.0020, 0.0010, 0.9647], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,521][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.3537, 0.0380, 0.0519, 0.2038, 0.3526], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,522][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([2.6716e-02, 1.0307e-04, 6.5625e-05, 6.7345e-05, 9.7305e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,528][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.2453, 0.2452, 0.0372, 0.4359, 0.0365], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,532][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2240, 0.1216, 0.2381, 0.2180, 0.1983], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,532][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.3724, 0.1185, 0.3627, 0.0858, 0.0607], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,532][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.4243, 0.1375, 0.2074, 0.1168, 0.1140], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,533][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.4135, 0.0900, 0.1862, 0.0502, 0.2601], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,533][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.4715, 0.0997, 0.2348, 0.0753, 0.1187], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,534][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.4607, 0.0852, 0.0620, 0.1097, 0.2493, 0.0330], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,534][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.9584e-03, 4.2953e-04, 6.7536e-02, 8.9304e-04, 8.4792e-04, 9.2434e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,534][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3788, 0.0638, 0.1706, 0.0662, 0.0769, 0.2437], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,535][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0323, 0.0055, 0.0211, 0.0158, 0.4578, 0.4676], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,538][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1517, 0.0460, 0.0256, 0.0425, 0.6059, 0.1283], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,544][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0848, 0.0034, 0.1476, 0.0024, 0.0158, 0.7459], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,546][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3087, 0.1176, 0.0169, 0.0986, 0.0804, 0.3777], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,546][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1330, 0.0682, 0.1132, 0.1601, 0.2889, 0.2364], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,547][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0607, 0.0125, 0.3510, 0.0134, 0.0657, 0.4967], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,547][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3520, 0.1025, 0.1884, 0.0844, 0.0885, 0.1842], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,547][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3426, 0.0807, 0.2363, 0.0598, 0.0885, 0.1921], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,548][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3361, 0.1067, 0.1786, 0.0720, 0.1234, 0.1832], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,548][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4485, 0.1880, 0.0394, 0.1515, 0.1202, 0.0207, 0.0317],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,548][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([9.1015e-03, 7.7434e-04, 6.6693e-02, 1.7771e-03, 1.9109e-04, 8.7239e-02,
        8.3422e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,550][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3345, 0.0603, 0.1425, 0.0383, 0.1100, 0.2743, 0.0401],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,556][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0505, 0.0087, 0.0233, 0.0140, 0.0852, 0.1822, 0.6361],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,560][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2988, 0.0446, 0.0416, 0.0610, 0.2883, 0.1237, 0.1422],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,560][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.1793, 0.0187, 0.1519, 0.0110, 0.0411, 0.1352, 0.4630],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,561][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2566, 0.3122, 0.0060, 0.3406, 0.0718, 0.0095, 0.0035],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,561][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1167, 0.0373, 0.0812, 0.0961, 0.1442, 0.2255, 0.2991],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,561][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0307, 0.0078, 0.1971, 0.0082, 0.0527, 0.2111, 0.4923],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,562][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3167, 0.1015, 0.1544, 0.0756, 0.0774, 0.1501, 0.1243],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,562][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.3515, 0.0723, 0.1687, 0.0662, 0.0446, 0.1146, 0.1821],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,563][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.2736, 0.1025, 0.1433, 0.0815, 0.1042, 0.1391, 0.1559],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,566][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.3156, 0.1030, 0.1404, 0.0831, 0.0800, 0.0680, 0.1073, 0.1027],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,568][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([5.8183e-04, 1.0674e-03, 4.0089e-03, 4.4793e-03, 1.0886e-03, 1.8360e-03,
        4.8220e-04, 9.8646e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,574][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2832, 0.1693, 0.0831, 0.0635, 0.0726, 0.0875, 0.0704, 0.1703],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,574][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([1.2223e-02, 4.6110e-04, 1.7870e-04, 6.5920e-03, 6.2486e-03, 1.4307e-03,
        9.6664e-04, 9.7190e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,575][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0573, 0.0279, 0.0055, 0.0717, 0.0303, 0.0101, 0.0164, 0.7809],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,575][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([1.2817e-02, 1.2282e-03, 1.8588e-05, 3.4319e-04, 5.4268e-05, 3.4095e-06,
        4.1091e-06, 9.8553e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,575][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.2426, 0.2603, 0.0411, 0.1513, 0.0258, 0.0272, 0.0345, 0.2173],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,576][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0589, 0.0330, 0.0442, 0.1768, 0.0933, 0.1691, 0.2854, 0.1393],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,576][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2370, 0.0651, 0.1607, 0.0543, 0.0618, 0.1437, 0.1123, 0.1650],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,577][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.2807, 0.1206, 0.1432, 0.1056, 0.0840, 0.1211, 0.1276, 0.0171],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,580][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.1562, 0.0746, 0.1429, 0.0890, 0.0576, 0.1071, 0.0993, 0.2733],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,584][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.2454, 0.0596, 0.1118, 0.0557, 0.0987, 0.1728, 0.0503, 0.2057],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,588][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4453, 0.0816, 0.0205, 0.1310, 0.1203, 0.0188, 0.0595, 0.1093, 0.0138],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,588][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([3.4281e-03, 7.3966e-04, 2.5553e-02, 9.1909e-04, 5.2651e-04, 9.1213e-03,
        1.2507e-03, 1.1294e-04, 9.5835e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,589][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2756, 0.0347, 0.1205, 0.0189, 0.0475, 0.0609, 0.0138, 0.0116, 0.4164],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,589][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0514, 0.0013, 0.0081, 0.0026, 0.0735, 0.0445, 0.1174, 0.0662, 0.6350],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,590][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5150, 0.0200, 0.0153, 0.0492, 0.0715, 0.0515, 0.0282, 0.0749, 0.1743],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,590][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1393, 0.0182, 0.2003, 0.0205, 0.0601, 0.0995, 0.1485, 0.0197, 0.2939],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,590][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2876, 0.1996, 0.0100, 0.2586, 0.0619, 0.0198, 0.0065, 0.1499, 0.0061],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,591][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0515, 0.0258, 0.0327, 0.0751, 0.0666, 0.0876, 0.1725, 0.1522, 0.3359],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,594][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0343, 0.0068, 0.1784, 0.0050, 0.0216, 0.1584, 0.2319, 0.0123, 0.3514],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,600][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2661, 0.0882, 0.1350, 0.0661, 0.0722, 0.1251, 0.0992, 0.0461, 0.1019],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,602][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2277, 0.0864, 0.1638, 0.0705, 0.0696, 0.1358, 0.0988, 0.0368, 0.1105],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,602][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2472, 0.0771, 0.1215, 0.0576, 0.0915, 0.1111, 0.0632, 0.0953, 0.1354],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,603][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.1121, 0.0907, 0.0868, 0.1918, 0.0182, 0.0952, 0.0723, 0.0487, 0.0699,
        0.2143], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,603][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([2.3585e-05, 6.5517e-05, 1.3426e-05, 5.4074e-01, 1.0560e-05, 7.5926e-06,
        1.2112e-05, 2.6993e-05, 3.8046e-06, 4.5910e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,604][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.2903, 0.0816, 0.0598, 0.1707, 0.0578, 0.0427, 0.0795, 0.0170, 0.0569,
        0.1437], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,604][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([1.1357e-03, 2.8172e-05, 2.4673e-06, 1.7396e-02, 1.1067e-05, 1.5544e-05,
        3.3051e-05, 2.3681e-04, 6.7503e-05, 9.8107e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,604][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.0108, 0.0188, 0.0014, 0.1296, 0.0034, 0.0043, 0.0043, 0.0031, 0.0086,
        0.8159], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,605][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([1.5946e-03, 1.0210e-04, 9.0777e-07, 5.5921e-01, 2.4163e-06, 3.7435e-08,
        3.8929e-07, 6.3991e-06, 2.1484e-07, 4.3908e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,608][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.2051, 0.1858, 0.0644, 0.1702, 0.0235, 0.0192, 0.0477, 0.0640, 0.0610,
        0.1591], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,614][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.1387, 0.0164, 0.0481, 0.0237, 0.0547, 0.1158, 0.1591, 0.0217, 0.2779,
        0.1438], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,616][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.2313, 0.0909, 0.1239, 0.0877, 0.0521, 0.0928, 0.0903, 0.0386, 0.1149,
        0.0774], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,616][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.2419, 0.1223, 0.1264, 0.0345, 0.0568, 0.1066, 0.1014, 0.0636, 0.1145,
        0.0320], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,617][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.1483, 0.0581, 0.0818, 0.2864, 0.0271, 0.0590, 0.0544, 0.0246, 0.0498,
        0.2105], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,617][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0935, 0.0844, 0.1190, 0.0712, 0.1389, 0.0919, 0.0938, 0.1001, 0.1075,
        0.0997], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,618][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2913, 0.0310, 0.0351, 0.0343, 0.2357, 0.0229, 0.0217, 0.0519, 0.0251,
        0.0379, 0.2132], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,618][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([9.4310e-04, 3.7818e-03, 2.3495e-03, 1.0285e-03, 8.8099e-03, 1.1932e-03,
        3.2090e-04, 1.6694e-04, 3.6626e-04, 6.1971e-04, 9.8042e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,618][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.3199, 0.0339, 0.0776, 0.0687, 0.0895, 0.1182, 0.0765, 0.0164, 0.0480,
        0.0615, 0.0897], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,619][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.3858e-03, 3.2197e-05, 2.9796e-05, 1.6460e-05, 1.0951e-03, 1.3025e-04,
        1.9874e-04, 5.5593e-04, 1.7818e-03, 8.1308e-04, 9.9296e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,622][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1335, 0.0163, 0.0139, 0.0230, 0.0382, 0.0314, 0.0207, 0.0234, 0.0449,
        0.1103, 0.5445], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,626][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.7284e-02, 6.8195e-04, 3.9492e-05, 9.1995e-05, 1.0248e-02, 4.1284e-06,
        1.4022e-05, 2.1766e-06, 1.9004e-06, 3.4559e-05, 9.4160e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,630][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.1364, 0.1483, 0.0189, 0.2054, 0.0300, 0.0137, 0.0181, 0.1253, 0.0152,
        0.2562, 0.0323], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,630][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0475, 0.0122, 0.0211, 0.0232, 0.0240, 0.0481, 0.0805, 0.0472, 0.1975,
        0.2485, 0.2503], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,631][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1314, 0.0457, 0.1429, 0.0288, 0.0479, 0.1360, 0.1859, 0.0374, 0.1665,
        0.0311, 0.0465], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,631][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1957, 0.0772, 0.1038, 0.0620, 0.0849, 0.1012, 0.0829, 0.0613, 0.0916,
        0.0647, 0.0747], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,632][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1656, 0.0856, 0.0980, 0.0422, 0.1045, 0.0933, 0.0658, 0.0254, 0.0713,
        0.0344, 0.2139], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,632][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.3061, 0.0468, 0.1289, 0.0371, 0.0517, 0.1093, 0.0485, 0.0516, 0.1063,
        0.0351, 0.0785], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,632][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2691, 0.1025, 0.0253, 0.1063, 0.0661, 0.0163, 0.0302, 0.0660, 0.0261,
        0.1371, 0.1306, 0.0243], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,634][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.0289e-03, 1.8992e-03, 3.7230e-03, 1.6979e-03, 1.0803e-04, 9.8199e-03,
        3.0918e-02, 5.2302e-05, 1.0073e-03, 1.1025e-03, 2.1845e-04, 9.4642e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,638][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1899, 0.0515, 0.1238, 0.0429, 0.0856, 0.2006, 0.0283, 0.0184, 0.0817,
        0.0419, 0.1092, 0.0263], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,642][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.2162e-02, 6.7027e-04, 9.5468e-04, 5.6903e-04, 2.0055e-03, 4.1403e-03,
        1.6307e-02, 7.3671e-03, 4.9920e-02, 2.0461e-02, 1.3571e-01, 7.4974e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,644][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0618, 0.0120, 0.0063, 0.0081, 0.0633, 0.0164, 0.0177, 0.0173, 0.0319,
        0.0453, 0.5371, 0.1827], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,644][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0654, 0.0101, 0.1042, 0.0030, 0.0110, 0.0923, 0.2242, 0.0021, 0.0313,
        0.0013, 0.0075, 0.4475], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,645][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1560, 0.1473, 0.0044, 0.1664, 0.0646, 0.0083, 0.0034, 0.1280, 0.0031,
        0.2299, 0.0830, 0.0056], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,645][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0359, 0.0062, 0.0116, 0.0106, 0.0243, 0.0234, 0.0408, 0.0335, 0.1203,
        0.1043, 0.2967, 0.2925], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,646][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0159, 0.0038, 0.0798, 0.0050, 0.0219, 0.0965, 0.2264, 0.0124, 0.1529,
        0.0069, 0.0279, 0.3505], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,646][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1874, 0.0619, 0.1069, 0.0588, 0.0536, 0.1023, 0.0871, 0.0419, 0.0841,
        0.0587, 0.0698, 0.0876], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,646][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1732, 0.0662, 0.1108, 0.0536, 0.0383, 0.1031, 0.1103, 0.0281, 0.0725,
        0.0431, 0.0401, 0.1606], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,650][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2005, 0.0681, 0.0878, 0.0415, 0.0691, 0.0972, 0.0528, 0.0725, 0.1003,
        0.0413, 0.0965, 0.0724], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,654][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.1998, 0.1109, 0.1362, 0.0636, 0.0186, 0.1261, 0.0614, 0.0375, 0.0874,
        0.0544, 0.0222, 0.0550, 0.0270], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,658][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([2.9205e-04, 1.9909e-02, 2.8746e-04, 4.2218e-03, 6.2903e-04, 1.5392e-04,
        7.2814e-05, 9.6465e-05, 1.5889e-04, 2.3786e-03, 1.0218e-03, 9.7887e-05,
        9.7068e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,658][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.2410, 0.0832, 0.0871, 0.0468, 0.1108, 0.0529, 0.0937, 0.0393, 0.0324,
        0.0378, 0.0796, 0.0757, 0.0196], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,659][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([1.0432e-03, 9.1255e-06, 6.5395e-07, 4.9460e-05, 6.4645e-05, 3.0923e-06,
        2.1788e-06, 6.0181e-04, 1.7009e-05, 1.5450e-03, 2.8186e-03, 8.4061e-05,
        9.9376e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,659][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([2.1623e-02, 5.9759e-03, 4.4355e-04, 1.9878e-02, 4.6098e-03, 7.3642e-04,
        1.1447e-03, 1.0761e-03, 1.9895e-03, 7.8462e-02, 3.4949e-02, 3.0882e-03,
        8.2602e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,660][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([2.2824e-05, 3.3534e-05, 1.5530e-09, 7.6150e-07, 1.7649e-07, 7.5638e-11,
        5.9341e-11, 1.7489e-07, 1.7791e-10, 2.0384e-07, 8.0125e-09, 6.4062e-11,
        9.9994e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,660][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.1121, 0.1528, 0.0669, 0.1765, 0.0151, 0.0136, 0.0476, 0.0392, 0.0559,
        0.1672, 0.0133, 0.0512, 0.0887], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,660][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0425, 0.0056, 0.0225, 0.0059, 0.0218, 0.0464, 0.0489, 0.0117, 0.1251,
        0.0312, 0.2329, 0.3534, 0.0521], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,662][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.2238, 0.0505, 0.0604, 0.0569, 0.0488, 0.0397, 0.0487, 0.0422, 0.0403,
        0.0481, 0.0438, 0.0428, 0.2539], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,668][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.2116, 0.0753, 0.0977, 0.0424, 0.0548, 0.0825, 0.0753, 0.0609, 0.0836,
        0.0398, 0.0883, 0.0792, 0.0085], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,672][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.1470, 0.0688, 0.0958, 0.0582, 0.0557, 0.0727, 0.0472, 0.0259, 0.0627,
        0.0435, 0.0464, 0.0481, 0.2278], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,673][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0824, 0.0630, 0.0736, 0.0381, 0.0767, 0.0850, 0.0710, 0.0511, 0.0951,
        0.0428, 0.1223, 0.1142, 0.0848], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,673][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2096, 0.0363, 0.0220, 0.0484, 0.1233, 0.0119, 0.0267, 0.0526, 0.0233,
        0.0619, 0.1322, 0.0268, 0.2091, 0.0158], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,673][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([2.8448e-03, 1.0125e-04, 2.1796e-02, 1.6938e-04, 2.6962e-04, 4.6066e-01,
        1.1716e-03, 1.1461e-04, 4.8511e-03, 1.0519e-04, 3.8283e-04, 7.0084e-04,
        8.8092e-06, 5.0682e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,674][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1961, 0.0381, 0.0969, 0.0426, 0.0541, 0.1470, 0.0287, 0.0151, 0.0579,
        0.0400, 0.0667, 0.0258, 0.0221, 0.1691], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,674][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.1820e-03, 8.9376e-05, 2.0026e-04, 1.1918e-04, 2.9128e-03, 2.0541e-03,
        2.5590e-03, 6.0660e-04, 6.8161e-03, 3.3256e-03, 2.5789e-01, 7.1838e-02,
        5.8318e-02, 5.8909e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,675][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0364, 0.0047, 0.0032, 0.0039, 0.0605, 0.0118, 0.0072, 0.0167, 0.0104,
        0.0210, 0.3357, 0.0753, 0.1820, 0.2314], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,676][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.2190e-02, 1.4232e-03, 6.2518e-02, 9.5518e-04, 8.8791e-03, 3.8624e-01,
        1.4335e-01, 1.5451e-03, 1.3961e-02, 4.0628e-04, 4.4240e-03, 9.7398e-02,
        2.6597e-04, 2.5645e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,681][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1135, 0.0485, 0.0050, 0.0439, 0.0336, 0.1505, 0.0032, 0.0676, 0.0039,
        0.0624, 0.0514, 0.0055, 0.1361, 0.2750], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,687][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0261, 0.0040, 0.0062, 0.0082, 0.0124, 0.0086, 0.0192, 0.0145, 0.0492,
        0.0650, 0.1194, 0.1624, 0.2180, 0.2869], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,687][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0133, 0.0026, 0.0881, 0.0034, 0.0195, 0.1201, 0.1623, 0.0097, 0.1386,
        0.0043, 0.0188, 0.1904, 0.0090, 0.2200], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,687][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1580, 0.0534, 0.0904, 0.0449, 0.0482, 0.0864, 0.0772, 0.0369, 0.0723,
        0.0448, 0.0638, 0.0820, 0.0394, 0.1021], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,688][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1250, 0.0432, 0.1076, 0.0395, 0.0665, 0.1204, 0.0838, 0.0281, 0.0768,
        0.0330, 0.0591, 0.0824, 0.0229, 0.1118], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,688][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1700, 0.0567, 0.0774, 0.0395, 0.0636, 0.0766, 0.0373, 0.0608, 0.0807,
        0.0378, 0.0854, 0.0498, 0.0851, 0.0791], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,690][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:05,691][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[22848],
        [    1],
        [13853],
        [  499],
        [ 5896],
        [11644],
        [17384],
        [ 8884],
        [ 3749],
        [  494],
        [  778],
        [ 9372],
        [ 8027],
        [11849]], device='cuda:0')
[2024-07-24 10:30:05,694][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[48339],
        [    1],
        [45756],
        [  945],
        [47048],
        [47542],
        [41955],
        [45438],
        [45275],
        [  502],
        [42705],
        [35354],
        [39687],
        [43894]], device='cuda:0')
[2024-07-24 10:30:05,696][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[1850],
        [1797],
        [1089],
        [1140],
        [ 665],
        [ 705],
        [ 745],
        [ 367],
        [ 532],
        [1238],
        [ 845],
        [ 746],
        [ 669],
        [ 376]], device='cuda:0')
[2024-07-24 10:30:05,699][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[45234],
        [ 7108],
        [19718],
        [22101],
        [15726],
        [27060],
        [40415],
        [27624],
        [ 8482],
        [22108],
        [ 6694],
        [39727],
        [15450],
        [27111]], device='cuda:0')
[2024-07-24 10:30:05,701][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 5273],
        [ 4353],
        [18454],
        [ 6968],
        [ 9683],
        [11951],
        [10507],
        [ 9905],
        [ 9940],
        [ 5874],
        [ 8300],
        [11109],
        [ 6081],
        [10685]], device='cuda:0')
[2024-07-24 10:30:05,704][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[47477],
        [12406],
        [49107],
        [19672],
        [41474],
        [46089],
        [46821],
        [41090],
        [46945],
        [13844],
        [22670],
        [38332],
        [23443],
        [38981]], device='cuda:0')
[2024-07-24 10:30:05,705][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[11517],
        [ 1379],
        [ 5932],
        [15160],
        [11445],
        [11518],
        [ 8445],
        [38581],
        [ 8988],
        [20749],
        [16432],
        [14452],
        [28474],
        [12059]], device='cuda:0')
[2024-07-24 10:30:05,706][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43367],
        [ 1203],
        [16057],
        [ 3276],
        [17737],
        [14239],
        [21233],
        [39001],
        [17368],
        [ 3308],
        [27455],
        [15988],
        [ 6844],
        [13716]], device='cuda:0')
[2024-07-24 10:30:05,707][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[39592],
        [16332],
        [ 8231],
        [ 1669],
        [  429],
        [12428],
        [  429],
        [ 1492],
        [ 1214],
        [ 1079],
        [  497],
        [  753],
        [  661],
        [ 9343]], device='cuda:0')
[2024-07-24 10:30:05,708][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[26827],
        [25456],
        [ 6030],
        [22890],
        [20793],
        [34755],
        [37925],
        [34308],
        [13776],
        [20722],
        [23872],
        [35966],
        [35696],
        [37027]], device='cuda:0')
[2024-07-24 10:30:05,711][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 4837],
        [ 2766],
        [ 9711],
        [ 1104],
        [ 2301],
        [11852],
        [ 9389],
        [ 2102],
        [14159],
        [ 1020],
        [ 5640],
        [13449],
        [22802],
        [13637]], device='cuda:0')
[2024-07-24 10:30:05,713][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[21956],
        [17834],
        [21363],
        [16815],
        [16383],
        [24214],
        [23244],
        [19978],
        [25158],
        [23172],
        [22535],
        [23584],
        [22670],
        [25156]], device='cuda:0')
[2024-07-24 10:30:05,716][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[30389],
        [40679],
        [26564],
        [45045],
        [22544],
        [19357],
        [41551],
        [36341],
        [29515],
        [47886],
        [18218],
        [44396],
        [33257],
        [29112]], device='cuda:0')
[2024-07-24 10:30:05,719][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[43260],
        [29676],
        [28011],
        [13148],
        [27155],
        [19844],
        [24902],
        [23278],
        [20431],
        [13935],
        [22341],
        [18672],
        [15221],
        [16743]], device='cuda:0')
[2024-07-24 10:30:05,721][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[22104],
        [    7],
        [30675],
        [ 3653],
        [41807],
        [27041],
        [43894],
        [33428],
        [ 6901],
        [ 3449],
        [11849],
        [25116],
        [21191],
        [26403]], device='cuda:0')
[2024-07-24 10:30:05,722][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[6872],
        [4466],
        [4801],
        [4400],
        [2544],
        [2590],
        [3334],
        [1631],
        [1699],
        [2096],
        [1804],
        [2043],
        [2092],
        [3138]], device='cuda:0')
[2024-07-24 10:30:05,723][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8747],
        [24374],
        [13980],
        [18761],
        [22197],
        [ 9277],
        [ 8933],
        [26507],
        [20296],
        [18549],
        [26694],
        [ 8518],
        [15506],
        [ 8904]], device='cuda:0')
[2024-07-24 10:30:05,724][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[38123],
        [38400],
        [30391],
        [38680],
        [35443],
        [24857],
        [22359],
        [35405],
        [ 7198],
        [34707],
        [29798],
        [21789],
        [30561],
        [17097]], device='cuda:0')
[2024-07-24 10:30:05,725][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8662],
        [ 9266],
        [16221],
        [12416],
        [ 6208],
        [10164],
        [14021],
        [10270],
        [13324],
        [13680],
        [12496],
        [15268],
        [17969],
        [16628]], device='cuda:0')
[2024-07-24 10:30:05,728][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 9930],
        [16463],
        [12211],
        [ 8018],
        [ 8502],
        [ 7636],
        [ 8599],
        [17658],
        [11524],
        [ 6035],
        [10569],
        [ 9487],
        [20335],
        [ 8741]], device='cuda:0')
[2024-07-24 10:30:05,731][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 9314],
        [35566],
        [33822],
        [45580],
        [42375],
        [38196],
        [42121],
        [35074],
        [39891],
        [45676],
        [38149],
        [44978],
        [30113],
        [41753]], device='cuda:0')
[2024-07-24 10:30:05,733][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[37638],
        [18767],
        [12680],
        [ 8242],
        [ 4838],
        [34684],
        [ 4532],
        [ 3948],
        [ 4540],
        [ 7584],
        [ 3956],
        [ 4302],
        [ 6058],
        [28550]], device='cuda:0')
[2024-07-24 10:30:05,736][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 9359],
        [ 9545],
        [13812],
        [12339],
        [13522],
        [ 5476],
        [ 5571],
        [ 7567],
        [ 4221],
        [ 7966],
        [14688],
        [ 6803],
        [ 5377],
        [ 5367]], device='cuda:0')
[2024-07-24 10:30:05,738][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[13357],
        [11809],
        [ 8738],
        [10542],
        [11089],
        [ 7584],
        [ 5359],
        [12876],
        [ 3664],
        [10120],
        [ 6956],
        [ 4711],
        [15765],
        [ 4802]], device='cuda:0')
[2024-07-24 10:30:05,739][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22222],
        [21140],
        [16332],
        [15584],
        [16147],
        [13841],
        [12896],
        [12810],
        [10863],
        [10354],
        [11634],
        [11141],
        [11604],
        [10743]], device='cuda:0')
[2024-07-24 10:30:05,740][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[42294],
        [39794],
        [46492],
        [43098],
        [45748],
        [48078],
        [47210],
        [45403],
        [47858],
        [42278],
        [48208],
        [47355],
        [45289],
        [48149]], device='cuda:0')
[2024-07-24 10:30:05,741][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7371],
        [19489],
        [ 7822],
        [24466],
        [10837],
        [18917],
        [18326],
        [23514],
        [29028],
        [31633],
        [22309],
        [27521],
        [30604],
        [27459]], device='cuda:0')
[2024-07-24 10:30:05,743][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[21628],
        [22298],
        [23017],
        [23741],
        [23991],
        [22080],
        [29047],
        [21187],
        [29891],
        [28207],
        [23155],
        [29234],
        [20954],
        [25189]], device='cuda:0')
[2024-07-24 10:30:05,745][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23298],
        [50200],
        [15789],
        [43299],
        [ 7372],
        [19268],
        [ 4334],
        [13584],
        [39453],
        [43656],
        [33785],
        [20455],
        [24469],
        [19706]], device='cuda:0')
[2024-07-24 10:30:05,748][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9951],
        [9951],
        [9951],
        [9951],
        [9951],
        [9951],
        [9951],
        [9951],
        [9951],
        [9951],
        [9951],
        [9951],
        [9951],
        [9951]], device='cuda:0')
[2024-07-24 10:30:05,768][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:05,769][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,769][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,769][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,770][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,770][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,770][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,771][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,771][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,771][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,772][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,772][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,772][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:05,773][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.2556, 0.7444], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,773][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.9260, 0.0740], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,773][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.9005, 0.0995], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,774][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.6638, 0.3362], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,774][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.1532, 0.8468], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,774][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.5809, 0.4191], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,775][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.8752, 0.1248], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,775][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.8278, 0.1722], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,775][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.9902, 0.0098], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,776][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.9952, 0.0048], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,776][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0011, 0.9989], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,776][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.2691, 0.7309], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:05,777][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0278, 0.9357, 0.0365], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,777][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8575, 0.1080, 0.0345], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,777][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4682, 0.0911, 0.4407], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,778][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4623, 0.2743, 0.2635], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,778][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1005, 0.6266, 0.2729], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,778][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4736, 0.0640, 0.4624], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,783][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6856, 0.1264, 0.1880], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,788][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.7196, 0.1404, 0.1399], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,789][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8734, 0.0144, 0.1121], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,790][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7455, 0.0140, 0.2405], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,790][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0039, 0.5212, 0.4749], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,790][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5493, 0.0039, 0.4468], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:05,791][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.0131, 0.2471, 0.0159, 0.7240], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,791][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.8919, 0.0650, 0.0276, 0.0156], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,792][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.3272, 0.0756, 0.3886, 0.2086], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,792][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.3883, 0.1949, 0.2183, 0.1985], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,792][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.0577, 0.3991, 0.2320, 0.3112], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,795][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0282, 0.8664, 0.0234, 0.0820], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,800][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.4111, 0.2869, 0.1145, 0.1874], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,804][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.5782, 0.1620, 0.2011, 0.0586], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,804][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.8141, 0.0101, 0.1475, 0.0283], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,804][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.4496, 0.0637, 0.4479, 0.0389], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,805][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.0020, 0.3359, 0.3582, 0.3039], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,805][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0044, 0.0017, 0.0038, 0.9901], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:05,806][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0578, 0.0422, 0.0296, 0.3735, 0.4970], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,806][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.8696, 0.0759, 0.0270, 0.0167, 0.0107], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,806][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.2189, 0.0689, 0.2778, 0.1667, 0.2677], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,807][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.3068, 0.1650, 0.1631, 0.1700, 0.1951], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,810][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0432, 0.3004, 0.1505, 0.2245, 0.2813], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,814][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.4213, 0.0742, 0.1812, 0.0609, 0.2623], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,818][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.8263, 0.0105, 0.1195, 0.0280, 0.0157], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,819][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.4560, 0.1573, 0.0920, 0.2370, 0.0578], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,819][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.7633, 0.0146, 0.0982, 0.0313, 0.0925], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,819][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.5849, 0.0413, 0.2449, 0.0670, 0.0619], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,820][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0027, 0.2307, 0.2144, 0.2435, 0.3087], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,820][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ went] are: tensor([1.9892e-02, 7.6185e-04, 2.6494e-02, 1.9415e-03, 9.5091e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:05,820][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.6450e-04, 1.9668e-03, 1.6497e-04, 8.5580e-03, 9.8853e-01, 1.5592e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,821][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.7923, 0.1076, 0.0337, 0.0228, 0.0138, 0.0299], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,821][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1821, 0.0608, 0.1922, 0.1267, 0.1804, 0.2579], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,824][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2554, 0.1380, 0.1260, 0.1598, 0.1728, 0.1481], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,829][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0532, 0.2486, 0.1148, 0.2603, 0.2144, 0.1087], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,833][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0319, 0.0182, 0.0155, 0.0477, 0.0086, 0.8782], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,833][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3761, 0.0638, 0.3129, 0.0339, 0.0734, 0.1398], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,833][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3862, 0.1044, 0.1253, 0.1411, 0.0568, 0.1862], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,834][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.7091, 0.0304, 0.0679, 0.0345, 0.0648, 0.0933], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,834][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.6726, 0.0139, 0.1459, 0.0474, 0.0391, 0.0811], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,835][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0042, 0.1672, 0.1532, 0.1923, 0.2352, 0.2480], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,835][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1861, 0.0058, 0.1247, 0.0161, 0.0076, 0.6597], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:05,835][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0199, 0.0663, 0.0165, 0.4549, 0.3233, 0.0903, 0.0288],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,836][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.7545, 0.1034, 0.0331, 0.0220, 0.0137, 0.0290, 0.0443],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,839][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1404, 0.0488, 0.1523, 0.1011, 0.1454, 0.2057, 0.2064],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,843][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2231, 0.1229, 0.1174, 0.1402, 0.1436, 0.1160, 0.1368],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,847][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0413, 0.2263, 0.1059, 0.2349, 0.2022, 0.0827, 0.1067],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,848][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1719, 0.1349, 0.0753, 0.2162, 0.0805, 0.2223, 0.0990],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,848][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2389, 0.2005, 0.2124, 0.0531, 0.0307, 0.1384, 0.1261],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,848][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2366, 0.1097, 0.0704, 0.1670, 0.0716, 0.1079, 0.2368],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,849][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.5858, 0.0292, 0.0802, 0.0305, 0.0543, 0.1037, 0.1162],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,849][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.4503, 0.0240, 0.1848, 0.0498, 0.0561, 0.0592, 0.1759],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,849][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0037, 0.1285, 0.1218, 0.1546, 0.1875, 0.1953, 0.2086],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,850][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0299, 0.0032, 0.0254, 0.0150, 0.0061, 0.0364, 0.8840],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:05,850][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ station] are: tensor([3.9813e-04, 3.4652e-02, 1.4976e-03, 1.5688e-01, 7.5860e-01, 2.2885e-02,
        1.8975e-02, 6.1122e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,854][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.8232, 0.0619, 0.0234, 0.0136, 0.0094, 0.0238, 0.0370, 0.0077],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,859][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1056, 0.0384, 0.1331, 0.0843, 0.1274, 0.1913, 0.1893, 0.1306],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,864][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.2407, 0.0930, 0.1166, 0.1042, 0.1245, 0.1217, 0.1048, 0.0946],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,864][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0269, 0.1527, 0.1167, 0.1767, 0.1669, 0.0733, 0.0754, 0.2114],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,864][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.1137, 0.0240, 0.0602, 0.0576, 0.2554, 0.1422, 0.1452, 0.2018],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,865][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.1248, 0.0786, 0.2906, 0.0367, 0.0525, 0.0835, 0.0985, 0.2347],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,865][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.2865, 0.0862, 0.0974, 0.1105, 0.0503, 0.1224, 0.2075, 0.0392],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,866][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.4189, 0.0215, 0.0856, 0.0491, 0.1157, 0.1069, 0.1674, 0.0349],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,866][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.4509, 0.0312, 0.0859, 0.0501, 0.1506, 0.0627, 0.1455, 0.0232],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,869][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0017, 0.1135, 0.1179, 0.1259, 0.1527, 0.1725, 0.1679, 0.1480],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,873][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ station] are: tensor([7.0761e-03, 5.8718e-04, 1.2084e-02, 1.2460e-02, 3.4798e-03, 1.3396e-02,
        5.3100e-03, 9.4561e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:05,877][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0367, 0.0894, 0.0144, 0.4568, 0.2123, 0.0372, 0.0881, 0.0551, 0.0100],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,878][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6842, 0.1064, 0.0337, 0.0218, 0.0137, 0.0279, 0.0429, 0.0121, 0.0574],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,878][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0913, 0.0370, 0.1069, 0.0740, 0.1046, 0.1445, 0.1431, 0.1035, 0.1951],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,879][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1901, 0.0934, 0.0956, 0.1047, 0.1148, 0.0990, 0.0909, 0.1020, 0.1093],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,879][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0319, 0.1864, 0.0809, 0.1757, 0.1678, 0.0594, 0.0656, 0.1672, 0.0651],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,879][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0432, 0.0286, 0.0196, 0.0753, 0.0373, 0.0373, 0.0862, 0.0178, 0.6547],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,880][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2036, 0.0932, 0.1329, 0.0499, 0.0484, 0.0825, 0.0885, 0.2125, 0.0884],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,880][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1926, 0.1014, 0.0531, 0.1403, 0.0552, 0.0770, 0.1317, 0.1543, 0.0944],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,883][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4964, 0.0302, 0.0910, 0.0308, 0.0614, 0.0733, 0.0986, 0.0471, 0.0712],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,888][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3149, 0.0376, 0.1603, 0.0556, 0.0802, 0.0498, 0.1629, 0.0340, 0.1047],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,892][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0036, 0.0829, 0.0786, 0.1098, 0.1331, 0.1352, 0.1343, 0.1252, 0.1972],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,892][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1165, 0.0443, 0.0551, 0.1690, 0.0353, 0.0592, 0.0861, 0.0903, 0.3442],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:05,893][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.0025, 0.0509, 0.0037, 0.1491, 0.3926, 0.0087, 0.1650, 0.0245, 0.0194,
        0.1836], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,893][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.7261, 0.0610, 0.0270, 0.0149, 0.0112, 0.0280, 0.0425, 0.0091, 0.0646,
        0.0156], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,893][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0665, 0.0286, 0.0911, 0.0598, 0.0909, 0.1321, 0.1312, 0.0937, 0.1827,
        0.1235], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,894][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.1742, 0.0823, 0.0949, 0.0849, 0.1040, 0.0896, 0.0869, 0.0854, 0.1136,
        0.0842], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,894][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.0225, 0.1641, 0.0970, 0.1234, 0.1257, 0.0608, 0.0689, 0.1496, 0.0756,
        0.1124], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,898][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0072, 0.4345, 0.0170, 0.0727, 0.0051, 0.1044, 0.0441, 0.0044, 0.2213,
        0.0893], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,903][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.1009, 0.1311, 0.0596, 0.0905, 0.0445, 0.0686, 0.0932, 0.1685, 0.1871,
        0.0560], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,906][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.1106, 0.0362, 0.0516, 0.0148, 0.0762, 0.1108, 0.2192, 0.0750, 0.2973,
        0.0081], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,906][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.4768, 0.0065, 0.0639, 0.0166, 0.0829, 0.0542, 0.1178, 0.0183, 0.1425,
        0.0204], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,906][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.1663, 0.0455, 0.1202, 0.0248, 0.0964, 0.0945, 0.2511, 0.0328, 0.1380,
        0.0304], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,907][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.0028, 0.0803, 0.0814, 0.0924, 0.1110, 0.1258, 0.1163, 0.1030, 0.1657,
        0.1215], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,907][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([8.1555e-05, 3.6652e-04, 1.3172e-04, 4.0290e-01, 1.1362e-04, 2.4695e-04,
        2.8804e-04, 2.1322e-04, 1.4725e-02, 5.8094e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:05,908][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0024, 0.0145, 0.0070, 0.0715, 0.6671, 0.0171, 0.0242, 0.0340, 0.0210,
        0.0826, 0.0586], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,908][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.6968, 0.0788, 0.0279, 0.0168, 0.0110, 0.0257, 0.0403, 0.0097, 0.0584,
        0.0162, 0.0184], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,909][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0594, 0.0287, 0.0800, 0.0562, 0.0806, 0.1125, 0.1095, 0.0825, 0.1522,
        0.1079, 0.1305], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,912][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1644, 0.0680, 0.0790, 0.0789, 0.0932, 0.0882, 0.0733, 0.0822, 0.1011,
        0.0807, 0.0910], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,918][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0188, 0.1398, 0.0649, 0.1135, 0.1335, 0.0494, 0.0495, 0.1498, 0.0597,
        0.1073, 0.1141], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,920][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1013, 0.0360, 0.0410, 0.0268, 0.2205, 0.1086, 0.1001, 0.0091, 0.2611,
        0.0285, 0.0669], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,920][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1968, 0.0102, 0.1153, 0.0178, 0.0527, 0.1017, 0.1329, 0.0523, 0.2009,
        0.0160, 0.1033], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,921][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1062, 0.0570, 0.0559, 0.0895, 0.0350, 0.1044, 0.1523, 0.1385, 0.1931,
        0.0438, 0.0242], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,921][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.4730, 0.0103, 0.0622, 0.0208, 0.0659, 0.0661, 0.0970, 0.0235, 0.0900,
        0.0263, 0.0649], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,922][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.2450, 0.0198, 0.0612, 0.0296, 0.0733, 0.0854, 0.2451, 0.0170, 0.1088,
        0.0365, 0.0781], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,922][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0022, 0.0612, 0.0601, 0.0810, 0.1008, 0.1010, 0.0968, 0.0902, 0.1402,
        0.1138, 0.1527], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,923][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0160, 0.0015, 0.0065, 0.0018, 0.0024, 0.0067, 0.0012, 0.0021, 0.0614,
        0.0012, 0.8994], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:05,928][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0022, 0.0182, 0.0049, 0.1144, 0.3919, 0.0112, 0.0363, 0.0033, 0.0162,
        0.1416, 0.2350, 0.0247], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,934][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.6492, 0.0924, 0.0296, 0.0194, 0.0122, 0.0249, 0.0376, 0.0106, 0.0516,
        0.0181, 0.0190, 0.0353], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,934][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0549, 0.0270, 0.0687, 0.0508, 0.0697, 0.0954, 0.0946, 0.0718, 0.1281,
        0.0948, 0.1137, 0.1305], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,934][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1416, 0.0708, 0.0679, 0.0767, 0.0824, 0.0716, 0.0797, 0.0798, 0.0877,
        0.0778, 0.0849, 0.0790], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,935][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0235, 0.1052, 0.0660, 0.1086, 0.0936, 0.0503, 0.0608, 0.1649, 0.0604,
        0.1039, 0.1044, 0.0582], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,935][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0531, 0.0763, 0.0364, 0.1019, 0.0437, 0.1050, 0.0704, 0.0381, 0.3192,
        0.0676, 0.0520, 0.0362], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,936][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1515, 0.0965, 0.1460, 0.0436, 0.0299, 0.1118, 0.1047, 0.0409, 0.1507,
        0.0224, 0.0482, 0.0537], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,936][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1305, 0.0451, 0.0452, 0.0681, 0.0311, 0.0900, 0.1339, 0.0745, 0.1574,
        0.0242, 0.0389, 0.1611], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,937][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4520, 0.0225, 0.0570, 0.0216, 0.0438, 0.0675, 0.0883, 0.0315, 0.0578,
        0.0255, 0.0507, 0.0818], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,940][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2427, 0.0200, 0.0685, 0.0377, 0.0727, 0.0411, 0.1896, 0.0217, 0.0665,
        0.0343, 0.0791, 0.1262], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,946][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0034, 0.0502, 0.0481, 0.0699, 0.0803, 0.0869, 0.0879, 0.0733, 0.1261,
        0.1012, 0.1461, 0.1266], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,948][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([5.2012e-03, 4.5396e-04, 2.2292e-03, 2.6269e-03, 2.3271e-03, 9.7859e-03,
        5.0931e-03, 6.1170e-04, 5.8611e-02, 4.7820e-03, 1.4147e-03, 9.0686e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:05,948][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0003, 0.0098, 0.0010, 0.1868, 0.1075, 0.0025, 0.0243, 0.0144, 0.0030,
        0.2409, 0.2926, 0.0576, 0.0591], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,949][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.7478, 0.0493, 0.0191, 0.0114, 0.0081, 0.0193, 0.0288, 0.0064, 0.0451,
        0.0123, 0.0139, 0.0298, 0.0086], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,949][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0422, 0.0207, 0.0587, 0.0415, 0.0615, 0.0878, 0.0855, 0.0648, 0.1215,
        0.0862, 0.1090, 0.1234, 0.0972], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,950][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.1349, 0.0638, 0.0730, 0.0753, 0.0801, 0.0699, 0.0635, 0.0697, 0.0898,
        0.0752, 0.0772, 0.0640, 0.0635], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,950][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0192, 0.1079, 0.0847, 0.0902, 0.0884, 0.0518, 0.0434, 0.1029, 0.0709,
        0.0825, 0.0993, 0.0421, 0.1166], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,954][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0256, 0.0404, 0.0114, 0.2803, 0.0452, 0.0256, 0.0885, 0.0878, 0.0714,
        0.1366, 0.0310, 0.0784, 0.0779], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,960][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.2515, 0.1415, 0.0466, 0.1015, 0.0337, 0.0368, 0.0601, 0.0045, 0.1088,
        0.0719, 0.0588, 0.0468, 0.0375], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,962][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1145, 0.0712, 0.0274, 0.0334, 0.1206, 0.0633, 0.0784, 0.0444, 0.1303,
        0.0180, 0.0929, 0.2024, 0.0034], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,962][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.2808, 0.0077, 0.0414, 0.0306, 0.0677, 0.0466, 0.1067, 0.0275, 0.1222,
        0.0435, 0.0641, 0.1174, 0.0438], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,963][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.1013, 0.0148, 0.0344, 0.0213, 0.0744, 0.0848, 0.2288, 0.0072, 0.1078,
        0.0438, 0.0907, 0.1832, 0.0075], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,963][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0020, 0.0477, 0.0501, 0.0640, 0.0740, 0.0785, 0.0755, 0.0656, 0.1064,
        0.0857, 0.1176, 0.0996, 0.1332], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,964][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0175, 0.0046, 0.0146, 0.0108, 0.0016, 0.0136, 0.0086, 0.0020, 0.0768,
        0.0044, 0.0029, 0.0081, 0.8345], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:05,964][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([5.7047e-04, 1.2586e-03, 1.1986e-04, 5.2928e-03, 7.3077e-01, 8.8295e-06,
        1.2420e-03, 4.4195e-04, 6.5323e-04, 6.7584e-03, 2.2062e-01, 5.7252e-03,
        2.6536e-02, 7.9757e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,964][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.6079, 0.0958, 0.0301, 0.0201, 0.0123, 0.0242, 0.0365, 0.0108, 0.0492,
        0.0183, 0.0185, 0.0338, 0.0132, 0.0293], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,968][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0430, 0.0233, 0.0548, 0.0426, 0.0569, 0.0754, 0.0740, 0.0574, 0.0997,
        0.0758, 0.0916, 0.1008, 0.0837, 0.1211], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,972][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1238, 0.0594, 0.0563, 0.0719, 0.0783, 0.0669, 0.0610, 0.0692, 0.0741,
        0.0732, 0.0770, 0.0606, 0.0667, 0.0617], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,976][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0226, 0.0986, 0.0465, 0.1013, 0.0846, 0.0446, 0.0475, 0.1168, 0.0435,
        0.0971, 0.0986, 0.0469, 0.1141, 0.0373], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,977][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0019, 0.0030, 0.0022, 0.0159, 0.0035, 0.2280, 0.0147, 0.0020, 0.0109,
        0.0215, 0.0017, 0.0276, 0.0015, 0.6657], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,977][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1284, 0.0303, 0.1476, 0.0132, 0.0483, 0.0662, 0.0688, 0.0859, 0.1191,
        0.0093, 0.1065, 0.0752, 0.0445, 0.0568], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,977][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0898, 0.0338, 0.0376, 0.0526, 0.0213, 0.0745, 0.0964, 0.0815, 0.1428,
        0.0154, 0.0263, 0.1193, 0.1017, 0.1069], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,978][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4068, 0.0240, 0.0456, 0.0223, 0.0439, 0.0570, 0.0751, 0.0317, 0.0445,
        0.0248, 0.0498, 0.0852, 0.0403, 0.0490], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,978][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1971, 0.0129, 0.0429, 0.0243, 0.0675, 0.0265, 0.2511, 0.0169, 0.0422,
        0.0205, 0.0881, 0.1605, 0.0235, 0.0260], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,982][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0045, 0.0334, 0.0314, 0.0517, 0.0586, 0.0621, 0.0601, 0.0519, 0.0888,
        0.0787, 0.1129, 0.0882, 0.1363, 0.1415], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:05,988][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0205, 0.0010, 0.0163, 0.0040, 0.0019, 0.1535, 0.0071, 0.0044, 0.2448,
        0.0099, 0.0046, 0.0318, 0.0042, 0.4960], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,002][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:06,004][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,005][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,005][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,005][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,006][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,008][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,009][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,009][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,009][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,009][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,010][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,010][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,010][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.8734, 0.1266], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,011][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.5227, 0.4773], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,011][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.8870, 0.1130], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,011][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.6198, 0.3802], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,012][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([6.1981e-04, 9.9938e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,012][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.6766, 0.3234], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,012][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([9.6327e-04, 9.9904e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,013][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.2263, 0.7737], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,013][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.6984, 0.3016], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,013][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.6623, 0.3377], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,014][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([5.3450e-04, 9.9947e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,014][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.0420, 0.9580], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,014][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3717, 0.4519, 0.1763], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,015][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1277, 0.7856, 0.0867], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,015][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3804, 0.0866, 0.5330], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,015][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4086, 0.2756, 0.3158], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,016][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([2.8780e-04, 3.3762e-01, 6.6209e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,016][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1442, 0.0033, 0.8525], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,016][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([7.9715e-05, 9.9979e-01, 1.3440e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,017][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2518, 0.4708, 0.2773], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,017][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1783, 0.0092, 0.8125], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,018][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1443, 0.7188, 0.1368], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,018][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0024, 0.5478, 0.4498], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,018][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3298, 0.0010, 0.6692], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,019][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.1322, 0.0921, 0.0520, 0.7237], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,022][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.0783, 0.2074, 0.4348, 0.2795], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,026][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.2599, 0.0672, 0.4303, 0.2425], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,026][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.3189, 0.1979, 0.2438, 0.2395], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,026][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.0539, 0.1346, 0.7896, 0.0219], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,027][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0122, 0.8653, 0.0384, 0.0840], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,027][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([5.9161e-05, 3.1216e-01, 3.1560e-03, 6.8463e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,027][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0932, 0.4763, 0.1758, 0.2547], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,028][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0940, 0.0157, 0.7776, 0.1126], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,028][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.3607, 0.5884, 0.0336, 0.0172], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,031][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.0012, 0.3585, 0.3913, 0.2490], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,035][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([8.0718e-04, 6.1950e-04, 2.2580e-03, 9.9632e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,039][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.4682, 0.0120, 0.0732, 0.2698, 0.1769], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,040][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0409, 0.1494, 0.0962, 0.6851, 0.0284], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,040][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.1563, 0.0566, 0.2740, 0.1747, 0.3383], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,040][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.2505, 0.1590, 0.1906, 0.1914, 0.2085], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,041][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0011, 0.1192, 0.4098, 0.0059, 0.4640], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,041][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0331, 0.0014, 0.3811, 0.0007, 0.5837], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,042][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0069, 0.0081, 0.0085, 0.8296, 0.1469], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,042][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0749, 0.2635, 0.1224, 0.2704, 0.2687], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,042][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.1361, 0.0165, 0.6258, 0.2082, 0.0133], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,045][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1023, 0.5059, 0.0110, 0.0267, 0.3541], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,050][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0014, 0.2711, 0.2412, 0.2209, 0.2653], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,054][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([4.1130e-03, 1.6741e-04, 2.0752e-02, 2.3227e-04, 9.7474e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,054][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.2507e-02, 1.8666e-03, 1.4565e-03, 1.8208e-02, 9.5575e-01, 2.1356e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,055][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0395, 0.0926, 0.1512, 0.5553, 0.1457, 0.0157], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,055][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1196, 0.0476, 0.1757, 0.1225, 0.2057, 0.3289], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,055][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2033, 0.1363, 0.1519, 0.1681, 0.1732, 0.1671], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,056][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0042, 0.0982, 0.3788, 0.0064, 0.3483, 0.1641], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,056][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.7551e-02, 1.5372e-03, 1.6364e-01, 6.7493e-04, 9.1744e-02, 7.2485e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,057][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.7606e-05, 2.4258e-03, 1.8318e-05, 2.1192e-03, 9.9515e-01, 2.6546e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,062][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0960, 0.1792, 0.1011, 0.2372, 0.1929, 0.1937], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,068][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0861, 0.0086, 0.2190, 0.1511, 0.0037, 0.5315], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,068][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2415, 0.1873, 0.0328, 0.0197, 0.0550, 0.4637], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,068][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0024, 0.2077, 0.1818, 0.1840, 0.2102, 0.2139], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,069][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1016, 0.0027, 0.1795, 0.0026, 0.0014, 0.7122], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,069][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1603, 0.0188, 0.0388, 0.2664, 0.0796, 0.4070, 0.0292],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,069][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0792, 0.1200, 0.1648, 0.1874, 0.2788, 0.1405, 0.0295],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,070][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0872, 0.0363, 0.1319, 0.0927, 0.1569, 0.2485, 0.2465],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,070][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1765, 0.1210, 0.1335, 0.1475, 0.1495, 0.1418, 0.1302],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,071][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0063, 0.0885, 0.3566, 0.0070, 0.3010, 0.1530, 0.0876],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,074][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0637, 0.0114, 0.2849, 0.0035, 0.3797, 0.1778, 0.0790],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,078][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([8.9364e-05, 7.7790e-01, 2.4990e-04, 1.8716e-02, 2.0115e-01, 1.8984e-03,
        2.6370e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,082][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0852, 0.1430, 0.0792, 0.1982, 0.1625, 0.1377, 0.1941],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,082][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0307, 0.0033, 0.1079, 0.0529, 0.0017, 0.1913, 0.6122],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,083][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0493, 0.3653, 0.0259, 0.0172, 0.1296, 0.1242, 0.2884],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,083][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0023, 0.1598, 0.1475, 0.1540, 0.1732, 0.1741, 0.1890],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,083][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0225, 0.0027, 0.0397, 0.0054, 0.0026, 0.0219, 0.9052],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,084][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0069, 0.0235, 0.0075, 0.2508, 0.4395, 0.2051, 0.0472, 0.0197],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,084][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0268, 0.1862, 0.0825, 0.1731, 0.3859, 0.0420, 0.0924, 0.0111],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,088][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0649, 0.0272, 0.1098, 0.0739, 0.1314, 0.2200, 0.2158, 0.1570],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,094][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.1674, 0.0948, 0.1235, 0.1183, 0.1295, 0.1336, 0.1174, 0.1155],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,096][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0310, 0.0620, 0.3185, 0.0083, 0.2557, 0.1571, 0.1253, 0.0420],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,096][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0084, 0.0027, 0.0228, 0.0054, 0.3056, 0.6452, 0.0073, 0.0025],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,097][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([4.2438e-06, 1.3467e-03, 7.6280e-04, 2.4266e-03, 1.5205e-01, 5.4849e-03,
        2.4740e-07, 8.3793e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,097][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0470, 0.2001, 0.0698, 0.1718, 0.1996, 0.0937, 0.1534, 0.0646],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,097][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0168, 0.0034, 0.0896, 0.0453, 0.0027, 0.1572, 0.6809, 0.0042],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,098][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0974, 0.2721, 0.0098, 0.0272, 0.1423, 0.1961, 0.2544, 0.0007],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,098][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0009, 0.1487, 0.1542, 0.1294, 0.1494, 0.1644, 0.1560, 0.0970],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,098][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([2.4157e-03, 1.4706e-04, 9.7364e-03, 2.6882e-03, 7.1186e-04, 4.8484e-03,
        7.8885e-04, 9.7866e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,100][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2951, 0.0226, 0.0319, 0.2629, 0.0470, 0.1476, 0.0937, 0.0608, 0.0384],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,106][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0254, 0.1721, 0.1077, 0.2464, 0.2122, 0.0444, 0.0708, 0.0615, 0.0595],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,110][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0524, 0.0256, 0.0850, 0.0625, 0.1035, 0.1597, 0.1562, 0.1196, 0.2356],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,110][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1403, 0.0940, 0.1045, 0.1135, 0.1163, 0.1115, 0.0985, 0.1098, 0.1116],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,111][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0104, 0.0741, 0.3142, 0.0059, 0.2470, 0.1203, 0.0797, 0.0224, 0.1260],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,111][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0152, 0.0030, 0.1273, 0.0015, 0.3680, 0.0799, 0.0643, 0.0859, 0.2550],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,111][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([5.1908e-06, 1.1337e-02, 7.8122e-06, 6.5364e-03, 6.3104e-02, 2.4054e-04,
        3.1631e-08, 9.1874e-01, 2.7452e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,112][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0634, 0.1037, 0.0697, 0.1540, 0.1114, 0.1257, 0.1557, 0.0867, 0.1298],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,112][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0177, 0.0037, 0.0517, 0.0690, 0.0012, 0.0966, 0.4369, 0.0052, 0.3179],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,113][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0693, 0.1175, 0.0261, 0.0080, 0.0214, 0.1856, 0.0768, 0.0021, 0.4933],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,116][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0023, 0.1141, 0.1056, 0.1187, 0.1364, 0.1319, 0.1290, 0.0871, 0.1748],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,122][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1789, 0.0856, 0.1519, 0.1467, 0.0294, 0.0678, 0.0560, 0.0974, 0.1863],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,124][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.0228, 0.0159, 0.0101, 0.1240, 0.1495, 0.0405, 0.2911, 0.0413, 0.0984,
        0.2062], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,124][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.0219, 0.0566, 0.1256, 0.0750, 0.2579, 0.0514, 0.1209, 0.0298, 0.1778,
        0.0831], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,125][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0373, 0.0186, 0.0690, 0.0480, 0.0859, 0.1398, 0.1377, 0.1034, 0.2120,
        0.1482], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,125][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.1290, 0.0796, 0.0975, 0.0957, 0.1054, 0.1033, 0.0911, 0.0970, 0.1065,
        0.0951], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,125][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.1495, 0.0174, 0.1344, 0.0126, 0.0857, 0.1123, 0.1294, 0.0546, 0.2569,
        0.0471], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,126][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0031, 0.6494, 0.0252, 0.0688, 0.0069, 0.0322, 0.0081, 0.0929, 0.0281,
        0.0854], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,126][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([1.0417e-05, 2.7933e-02, 5.0108e-04, 1.0151e-01, 3.2943e-02, 6.3932e-03,
        1.2211e-06, 2.3355e-01, 2.7430e-03, 5.9441e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,126][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0353, 0.1629, 0.0619, 0.0856, 0.1364, 0.0834, 0.1380, 0.0859, 0.1042,
        0.1065], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,127][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0093, 0.0018, 0.0771, 0.0115, 0.0014, 0.1617, 0.4662, 0.0029, 0.2544,
        0.0136], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,130][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.0851, 0.1484, 0.0080, 0.0043, 0.2244, 0.1189, 0.0488, 0.0033, 0.3550,
        0.0039], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,135][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.0017, 0.1130, 0.1174, 0.1002, 0.1153, 0.1294, 0.1153, 0.0741, 0.1521,
        0.0816], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,138][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([1.2511e-05, 4.0380e-04, 9.8540e-05, 7.8562e-01, 2.0930e-05, 4.3950e-05,
        2.9939e-05, 3.3185e-05, 3.0037e-03, 2.1073e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,139][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0291, 0.0069, 0.0261, 0.0793, 0.2928, 0.1124, 0.0477, 0.0731, 0.1416,
        0.1221, 0.0689], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,139][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0073, 0.0589, 0.0255, 0.3080, 0.0205, 0.0147, 0.0719, 0.0255, 0.0546,
        0.3888, 0.0243], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,139][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0332, 0.0192, 0.0597, 0.0450, 0.0742, 0.1142, 0.1095, 0.0876, 0.1674,
        0.1246, 0.1653], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,140][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1169, 0.0714, 0.0872, 0.0887, 0.0945, 0.0957, 0.0825, 0.0877, 0.0964,
        0.0885, 0.0905], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,140][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0084, 0.0678, 0.3032, 0.0053, 0.2249, 0.1139, 0.0709, 0.0190, 0.1176,
        0.0062, 0.0629], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,141][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.5989e-02, 8.8259e-04, 1.0601e-01, 1.7172e-04, 2.4387e-01, 4.0406e-02,
        1.9741e-02, 4.2511e-01, 1.0920e-01, 3.6305e-04, 3.8257e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,141][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([3.3868e-04, 1.1068e-02, 8.1050e-03, 3.0030e-02, 1.0630e-01, 3.9379e-03,
        7.2088e-08, 4.5729e-01, 6.1636e-05, 1.4284e-01, 2.4004e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,144][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0385, 0.1258, 0.0521, 0.1137, 0.1227, 0.0799, 0.1068, 0.0683, 0.0842,
        0.1419, 0.0660], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,150][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0200, 0.0011, 0.0762, 0.0138, 0.0012, 0.1136, 0.4632, 0.0017, 0.2926,
        0.0159, 0.0006], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,152][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0421, 0.1118, 0.0052, 0.0060, 0.0458, 0.1017, 0.4108, 0.0007, 0.2498,
        0.0055, 0.0204], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,153][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0012, 0.0871, 0.0900, 0.0938, 0.1157, 0.1103, 0.1034, 0.0735, 0.1394,
        0.0831, 0.1026], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,153][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([8.0981e-03, 1.1248e-03, 1.1471e-02, 4.6200e-04, 9.4894e-04, 4.0317e-03,
        2.1770e-04, 6.4653e-04, 2.4518e-02, 7.0110e-05, 9.4841e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,153][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0260, 0.0076, 0.0182, 0.1043, 0.1602, 0.0715, 0.0602, 0.0055, 0.1012,
        0.1712, 0.2111, 0.0629], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,154][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0279, 0.0297, 0.0329, 0.1698, 0.0527, 0.0414, 0.0950, 0.0273, 0.0987,
        0.2116, 0.2042, 0.0089], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,154][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0286, 0.0172, 0.0494, 0.0391, 0.0620, 0.0943, 0.0922, 0.0742, 0.1380,
        0.1070, 0.1413, 0.1566], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,154][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1053, 0.0699, 0.0784, 0.0842, 0.0868, 0.0842, 0.0770, 0.0827, 0.0862,
        0.0839, 0.0839, 0.0777], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,155][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0514, 0.0313, 0.2042, 0.0076, 0.1401, 0.1130, 0.1003, 0.0330, 0.1778,
        0.0176, 0.0865, 0.0372], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,156][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0103, 0.0059, 0.0924, 0.0010, 0.1966, 0.0599, 0.0217, 0.4046, 0.1023,
        0.0011, 0.0893, 0.0148], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,159][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([7.6010e-05, 1.1180e-01, 4.1785e-04, 3.8469e-02, 1.0592e-01, 2.5047e-03,
        9.0394e-07, 4.4035e-01, 9.0754e-05, 1.3414e-01, 1.6622e-01, 1.1940e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,164][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0538, 0.0775, 0.0492, 0.1034, 0.0925, 0.0895, 0.1077, 0.0532, 0.0871,
        0.1249, 0.0629, 0.0983], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,167][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0160, 0.0012, 0.0619, 0.0294, 0.0007, 0.0820, 0.3693, 0.0016, 0.2958,
        0.0337, 0.0005, 0.1079], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,167][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0308, 0.1608, 0.0096, 0.0071, 0.0634, 0.1009, 0.1324, 0.0019, 0.3270,
        0.0065, 0.0217, 0.1380], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,167][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0020, 0.0774, 0.0751, 0.0869, 0.0951, 0.0990, 0.1000, 0.0605, 0.1286,
        0.0752, 0.0989, 0.1013], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,168][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.5842e-03, 4.8068e-04, 4.2306e-03, 1.0433e-03, 1.5792e-03, 8.6838e-03,
        1.6532e-03, 1.4085e-04, 2.0930e-02, 3.0489e-04, 2.0795e-04, 9.5616e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,168][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0034, 0.0040, 0.0032, 0.1656, 0.0329, 0.0131, 0.0426, 0.0265, 0.0168,
        0.2849, 0.2453, 0.1487, 0.0130], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,168][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0168, 0.0580, 0.0643, 0.0921, 0.1911, 0.0335, 0.0687, 0.0095, 0.0915,
        0.1013, 0.1692, 0.0872, 0.0168], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,169][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0219, 0.0125, 0.0404, 0.0306, 0.0529, 0.0838, 0.0809, 0.0646, 0.1270,
        0.0936, 0.1318, 0.1448, 0.1155], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,172][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.1004, 0.0592, 0.0754, 0.0754, 0.0816, 0.0812, 0.0713, 0.0745, 0.0835,
        0.0754, 0.0774, 0.0715, 0.0732], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,178][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.2110, 0.0143, 0.0972, 0.0103, 0.0609, 0.0751, 0.0891, 0.0427, 0.1819,
        0.0416, 0.0815, 0.0635, 0.0311], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,180][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0135, 0.0155, 0.0560, 0.0195, 0.0551, 0.2538, 0.0230, 0.2999, 0.0530,
        0.0092, 0.0530, 0.0204, 0.1281], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,181][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([2.5672e-07, 1.1659e-04, 7.0526e-06, 4.3558e-05, 1.1694e-05, 6.1581e-06,
        1.1339e-09, 6.1069e-06, 5.6331e-07, 1.0433e-04, 1.5753e-04, 1.0528e-07,
        9.9955e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,181][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0298, 0.1202, 0.0365, 0.1004, 0.1078, 0.0589, 0.0987, 0.0557, 0.0683,
        0.1287, 0.0745, 0.0897, 0.0308], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,182][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0171, 0.0071, 0.0582, 0.0350, 0.0022, 0.0950, 0.3120, 0.0089, 0.2578,
        0.0427, 0.0010, 0.1569, 0.0062], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,182][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0413, 0.0618, 0.0110, 0.0059, 0.0620, 0.0759, 0.1196, 0.0012, 0.3144,
        0.0054, 0.0301, 0.2590, 0.0125], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,182][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0011, 0.0742, 0.0797, 0.0811, 0.0897, 0.0907, 0.0858, 0.0571, 0.1111,
        0.0688, 0.0848, 0.0833, 0.0925], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,183][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([9.4116e-03, 2.2810e-03, 1.7039e-02, 2.8343e-03, 4.3645e-04, 7.1054e-03,
        2.2020e-03, 4.4264e-04, 2.2242e-02, 2.5780e-04, 4.4126e-04, 1.1538e-03,
        9.3415e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,183][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.3380e-02, 9.2599e-04, 7.8486e-04, 8.0721e-03, 5.2346e-01, 8.6529e-05,
        3.7439e-03, 1.1374e-03, 6.6873e-03, 1.3498e-02, 3.9330e-01, 2.5449e-02,
        9.3301e-03, 1.4078e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,185][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0141, 0.0280, 0.0611, 0.1866, 0.0479, 0.0042, 0.0544, 0.0255, 0.0655,
        0.2100, 0.1284, 0.0750, 0.0948, 0.0045], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,191][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0220, 0.0146, 0.0379, 0.0315, 0.0483, 0.0705, 0.0680, 0.0560, 0.1011,
        0.0806, 0.1070, 0.1135, 0.0971, 0.1520], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,195][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0918, 0.0596, 0.0672, 0.0740, 0.0756, 0.0731, 0.0647, 0.0709, 0.0737,
        0.0734, 0.0724, 0.0652, 0.0718, 0.0664], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,195][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0799, 0.0331, 0.2021, 0.0074, 0.1324, 0.0979, 0.0888, 0.0311, 0.1535,
        0.0179, 0.0790, 0.0342, 0.0093, 0.0332], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,195][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([5.0141e-03, 3.4144e-03, 1.4694e-01, 3.6884e-04, 6.2993e-02, 5.0350e-01,
        2.5355e-02, 1.1404e-02, 4.6187e-02, 2.6689e-04, 2.3378e-02, 1.7782e-02,
        1.0176e-02, 1.4321e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,196][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([8.7209e-06, 2.1221e-04, 5.8304e-06, 2.1326e-04, 1.6574e-01, 4.8773e-05,
        8.2824e-08, 5.1276e-03, 9.7866e-06, 7.8441e-04, 2.6779e-01, 6.5144e-06,
        5.5976e-01, 2.9009e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,196][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0411, 0.0696, 0.0409, 0.0895, 0.0750, 0.0799, 0.0906, 0.0483, 0.0831,
        0.1075, 0.0544, 0.0837, 0.0715, 0.0648], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,197][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0145, 0.0020, 0.0340, 0.0323, 0.0008, 0.0848, 0.2965, 0.0020, 0.2266,
        0.0383, 0.0005, 0.1520, 0.0022, 0.1133], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,197][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0718, 0.0523, 0.0089, 0.0065, 0.0152, 0.1212, 0.1601, 0.0008, 0.2021,
        0.0063, 0.0102, 0.2334, 0.0095, 0.1020], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,201][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0030, 0.0595, 0.0572, 0.0738, 0.0808, 0.0821, 0.0776, 0.0493, 0.1015,
        0.0651, 0.0834, 0.0765, 0.0945, 0.0956], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,204][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.0809e-02, 7.9751e-04, 5.4304e-02, 1.0153e-03, 6.6110e-04, 3.1170e-01,
        1.3321e-03, 1.2160e-03, 7.9821e-02, 3.4781e-04, 5.4435e-04, 4.1912e-03,
        7.7107e-04, 5.2249e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,205][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:06,208][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15218],
        [  103],
        [15016],
        [ 1823],
        [ 3639],
        [ 3489],
        [ 9696],
        [ 2970],
        [ 2510],
        [ 2520],
        [ 1576],
        [ 2725],
        [ 4412],
        [ 4652]], device='cuda:0')
[2024-07-24 10:30:06,211][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13995],
        [    1],
        [18763],
        [ 2154],
        [11767],
        [12142],
        [21930],
        [ 5242],
        [ 7529],
        [ 3574],
        [ 1934],
        [ 9630],
        [12966],
        [15647]], device='cuda:0')
[2024-07-24 10:30:06,212][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[26303],
        [16470],
        [15460],
        [11724],
        [ 1813],
        [ 1553],
        [ 3452],
        [ 1443],
        [ 4047],
        [ 1495],
        [ 1207],
        [  889],
        [ 2094],
        [  992]], device='cuda:0')
[2024-07-24 10:30:06,212][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[42524],
        [42293],
        [42093],
        [42198],
        [42145],
        [41896],
        [41800],
        [42004],
        [41534],
        [41721],
        [41601],
        [41458],
        [41816],
        [41248]], device='cuda:0')
[2024-07-24 10:30:06,213][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 3604],
        [ 3930],
        [ 5137],
        [ 5720],
        [ 7149],
        [ 9116],
        [10866],
        [11608],
        [13468],
        [15064],
        [15968],
        [17650],
        [18275],
        [19429]], device='cuda:0')
[2024-07-24 10:30:06,214][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[26686],
        [25280],
        [23742],
        [22108],
        [22053],
        [21019],
        [20393],
        [20874],
        [20960],
        [20598],
        [21549],
        [20759],
        [21113],
        [20950]], device='cuda:0')
[2024-07-24 10:30:06,215][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[12227],
        [ 4708],
        [ 4416],
        [ 4230],
        [ 4460],
        [ 4817],
        [ 5891],
        [ 4898],
        [ 4939],
        [ 4866],
        [ 5062],
        [ 5828],
        [ 4997],
        [ 5072]], device='cuda:0')
[2024-07-24 10:30:06,218][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[20610],
        [32189],
        [ 3009],
        [31941],
        [ 9322],
        [11835],
        [15301],
        [21964],
        [  967],
        [16313],
        [ 4443],
        [ 4252],
        [13574],
        [15661]], device='cuda:0')
[2024-07-24 10:30:06,221][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12439],
        [ 4829],
        [ 9097],
        [ 3770],
        [14426],
        [17370],
        [ 9054],
        [29528],
        [28875],
        [26333],
        [29390],
        [21182],
        [ 8773],
        [24486]], device='cuda:0')
[2024-07-24 10:30:06,223][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[38565],
        [ 2989],
        [11789],
        [ 4155],
        [  291],
        [ 1460],
        [  654],
        [ 1877],
        [  512],
        [ 7191],
        [ 1030],
        [ 2446],
        [ 3069],
        [ 1921]], device='cuda:0')
[2024-07-24 10:30:06,226][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9000],
        [ 9558],
        [ 9897],
        [10554],
        [ 8856],
        [11105],
        [12195],
        [11409],
        [11922],
        [ 9687],
        [ 9262],
        [12419],
        [16043],
        [16504]], device='cuda:0')
[2024-07-24 10:30:06,228][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24248],
        [24500],
        [ 8991],
        [ 6370],
        [13104],
        [14350],
        [12457],
        [20050],
        [10874],
        [11810],
        [20350],
        [22583],
        [22515],
        [22708]], device='cuda:0')
[2024-07-24 10:30:06,229][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[10494],
        [36924],
        [36508],
        [38929],
        [42659],
        [43551],
        [44505],
        [44542],
        [44997],
        [45207],
        [46200],
        [46358],
        [46265],
        [46924]], device='cuda:0')
[2024-07-24 10:30:06,230][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[42191],
        [47883],
        [43291],
        [39473],
        [44387],
        [46395],
        [44385],
        [31292],
        [40070],
        [44235],
        [33646],
        [42950],
        [41339],
        [42971]], device='cuda:0')
[2024-07-24 10:30:06,231][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[17117],
        [19116],
        [21137],
        [13223],
        [36803],
        [23771],
        [23338],
        [41126],
        [20422],
        [28243],
        [13586],
        [28433],
        [21369],
        [21474]], device='cuda:0')
[2024-07-24 10:30:06,232][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[35204],
        [35371],
        [36523],
        [20499],
        [35905],
        [11236],
        [34400],
        [16394],
        [34725],
        [ 6516],
        [20190],
        [24107],
        [20907],
        [12027]], device='cuda:0')
[2024-07-24 10:30:06,235][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8861],
        [13291],
        [31261],
        [24246],
        [29889],
        [22744],
        [13194],
        [ 9969],
        [14875],
        [13954],
        [24790],
        [14254],
        [10191],
        [14535]], device='cuda:0')
[2024-07-24 10:30:06,237][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[13380],
        [13075],
        [11781],
        [11443],
        [ 9013],
        [ 8949],
        [ 8425],
        [ 8118],
        [ 7527],
        [ 6809],
        [ 6323],
        [ 5669],
        [ 5090],
        [ 4713]], device='cuda:0')
[2024-07-24 10:30:06,240][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[20253],
        [19803],
        [19189],
        [18921],
        [18809],
        [18676],
        [18625],
        [18207],
        [17907],
        [17834],
        [17769],
        [17781],
        [17688],
        [17684]], device='cuda:0')
[2024-07-24 10:30:06,243][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 3857],
        [16324],
        [11988],
        [11264],
        [10700],
        [10593],
        [10991],
        [11233],
        [11480],
        [13031],
        [11484],
        [12796],
        [12272],
        [12158]], device='cuda:0')
[2024-07-24 10:30:06,245][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[30505],
        [32814],
        [38282],
        [28044],
        [43667],
        [34643],
        [43163],
        [34953],
        [43572],
        [27703],
        [41411],
        [42298],
        [40830],
        [39771]], device='cuda:0')
[2024-07-24 10:30:06,246][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30554],
        [23702],
        [23712],
        [18721],
        [20528],
        [21017],
        [19829],
        [38999],
        [39660],
        [22155],
        [22054],
        [20479],
        [ 8290],
        [ 7752]], device='cuda:0')
[2024-07-24 10:30:06,247][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 8594],
        [30369],
        [22835],
        [35494],
        [33095],
        [28047],
        [26396],
        [27703],
        [24408],
        [28488],
        [30632],
        [28198],
        [29751],
        [25564]], device='cuda:0')
[2024-07-24 10:30:06,248][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[29938],
        [28118],
        [26075],
        [27671],
        [30251],
        [24073],
        [34428],
        [35341],
        [34641],
        [33153],
        [33973],
        [34641],
        [34286],
        [33007]], device='cuda:0')
[2024-07-24 10:30:06,249][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[13119],
        [12667],
        [11568],
        [11470],
        [10330],
        [14655],
        [11957],
        [12751],
        [18945],
        [17498],
        [14872],
        [15010],
        [14492],
        [14528]], device='cuda:0')
[2024-07-24 10:30:06,250][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17120],
        [ 8569],
        [ 8883],
        [ 8148],
        [ 7345],
        [ 8301],
        [ 8881],
        [ 8694],
        [ 8633],
        [ 8352],
        [ 7620],
        [ 7535],
        [ 7562],
        [ 7523]], device='cuda:0')
[2024-07-24 10:30:06,252][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[35756],
        [21480],
        [37545],
        [18997],
        [ 9615],
        [23302],
        [18152],
        [22135],
        [29131],
        [15958],
        [17300],
        [11926],
        [28381],
        [12777]], device='cuda:0')
[2024-07-24 10:30:06,255][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[15247],
        [24447],
        [23866],
        [31867],
        [27796],
        [32313],
        [30760],
        [27648],
        [19644],
        [36209],
        [28216],
        [30315],
        [31289],
        [36313]], device='cuda:0')
[2024-07-24 10:30:06,258][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[11727],
        [23900],
        [22152],
        [34300],
        [ 4201],
        [21383],
        [ 8182],
        [13287],
        [17368],
        [23401],
        [35300],
        [18128],
        [27281],
        [30415]], device='cuda:0')
[2024-07-24 10:30:06,260][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[13685],
        [13685],
        [13685],
        [13685],
        [13685],
        [13685],
        [13685],
        [13685],
        [13685],
        [13685],
        [13685],
        [13685],
        [13685],
        [13685]], device='cuda:0')
[2024-07-24 10:30:06,287][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:06,287][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,288][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,288][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,288][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,289][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,289][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,289][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,289][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,291][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,291][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,291][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,292][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,292][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.7879, 0.2121], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,292][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.6645, 0.3355], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,293][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0073, 0.9927], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,293][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.5408, 0.4592], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,293][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0518, 0.9482], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,294][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.3164, 0.6836], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,294][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.2947, 0.7053], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,294][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.6580, 0.3420], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,295][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.3441, 0.6559], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,295][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.8270, 0.1730], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,295][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.3041, 0.6959], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,297][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.2465, 0.7535], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,299][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6014, 0.2375, 0.1612], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,301][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6489, 0.1498, 0.2014], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,301][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([3.4174e-05, 4.0722e-01, 5.9274e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,302][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3010, 0.2116, 0.4874], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,302][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0017, 0.7463, 0.2519], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,302][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1684, 0.7609, 0.0707], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,303][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2651, 0.4398, 0.2950], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,303][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4303, 0.3453, 0.2244], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,303][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0133, 0.2095, 0.7772], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,304][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5086, 0.3778, 0.1136], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,304][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4162, 0.4355, 0.1483], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,305][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1681, 0.5288, 0.3031], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,305][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.3838, 0.1861, 0.1680, 0.2621], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,305][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.3336, 0.2241, 0.1718, 0.2705], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,306][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([2.1670e-06, 1.1061e-02, 2.0390e-01, 7.8504e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,306][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.1617, 0.1007, 0.2421, 0.4955], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,306][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([2.3755e-04, 3.5791e-02, 9.5628e-02, 8.6834e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,307][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0258, 0.2638, 0.6639, 0.0465], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,307][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.0891, 0.2674, 0.1393, 0.5042], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,307][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.2244, 0.3987, 0.3133, 0.0636], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,308][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0029, 0.0373, 0.9356, 0.0242], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,308][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.4203, 0.1967, 0.2439, 0.1391], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,308][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.1971, 0.3959, 0.0996, 0.3073], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,313][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0895, 0.2715, 0.1510, 0.4880], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,315][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.3180, 0.1529, 0.1739, 0.2903, 0.0649], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,315][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.3895, 0.1545, 0.1440, 0.2693, 0.0426], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,316][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ went] are: tensor([1.2681e-06, 2.3054e-03, 5.4985e-02, 6.7316e-01, 2.6955e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,316][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0880, 0.0664, 0.1608, 0.3302, 0.3545], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,316][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ went] are: tensor([2.6037e-04, 1.5588e-02, 1.5889e-01, 3.3174e-01, 4.9353e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,317][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0095, 0.3340, 0.3629, 0.2820, 0.0117], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,317][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0824, 0.1571, 0.0972, 0.4079, 0.2554], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,317][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.3037, 0.2958, 0.2251, 0.0506, 0.1248], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,320][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0370, 0.0932, 0.6517, 0.1447, 0.0735], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,325][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.2551, 0.1810, 0.1694, 0.3014, 0.0930], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,330][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.1221, 0.3457, 0.0841, 0.2064, 0.2417], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,331][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0544, 0.1877, 0.0942, 0.3449, 0.3188], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,331][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3998, 0.1269, 0.1227, 0.1931, 0.0615, 0.0961], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,331][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3395, 0.0860, 0.1224, 0.2614, 0.0298, 0.1608], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,331][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.3906e-07, 8.5775e-05, 3.0385e-03, 4.9578e-02, 4.3879e-01, 5.0851e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,332][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1262, 0.0735, 0.1207, 0.2319, 0.2459, 0.2019], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,332][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([2.0346e-05, 6.0112e-03, 4.9662e-03, 3.7211e-02, 8.4591e-01, 1.0588e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,332][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0206, 0.4488, 0.3285, 0.1823, 0.0139, 0.0058], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,333][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1059, 0.1322, 0.1159, 0.3188, 0.2205, 0.1066], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,333][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.4849, 0.1688, 0.0784, 0.0195, 0.0516, 0.1968], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,334][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.9194e-04, 1.9783e-02, 1.7553e-01, 1.5577e-02, 7.6010e-01, 2.8717e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,339][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1947, 0.2073, 0.1216, 0.3267, 0.1135, 0.0363], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,344][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1887, 0.2190, 0.1111, 0.1453, 0.2065, 0.1293], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,345][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0582, 0.1681, 0.0916, 0.3031, 0.3152, 0.0637], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,345][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3000, 0.1207, 0.1080, 0.2205, 0.0739, 0.1156, 0.0612],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,345][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.3290, 0.1217, 0.1448, 0.1478, 0.0312, 0.0988, 0.1267],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,346][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.7025e-08, 3.0616e-05, 4.9248e-04, 9.0123e-03, 3.6598e-02, 7.9891e-01,
        1.5495e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,346][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0906, 0.0602, 0.1026, 0.1929, 0.2006, 0.1617, 0.1914],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,346][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([4.0494e-05, 1.3407e-02, 9.6375e-03, 9.7667e-02, 2.7269e-01, 3.0161e-01,
        3.0495e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,347][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0116, 0.1518, 0.5281, 0.1703, 0.0386, 0.0950, 0.0045],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,347][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0803, 0.1243, 0.0931, 0.2927, 0.2192, 0.0869, 0.1035],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,347][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.2562, 0.1708, 0.1056, 0.0285, 0.0675, 0.2533, 0.1181],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,348][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([7.3387e-05, 6.4728e-03, 2.1552e-01, 1.0280e-02, 1.1717e-01, 6.2796e-01,
        2.2524e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,353][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.2961, 0.1719, 0.1162, 0.1639, 0.0893, 0.1014, 0.0612],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,358][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2021, 0.1688, 0.0987, 0.1438, 0.1736, 0.1085, 0.1044],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,359][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0492, 0.1585, 0.0866, 0.2766, 0.2630, 0.0729, 0.0931],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,359][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.2728, 0.1413, 0.0836, 0.1889, 0.0825, 0.0811, 0.0651, 0.0847],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,359][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.3403, 0.1211, 0.1281, 0.1729, 0.0296, 0.0756, 0.1129, 0.0195],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,360][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ station] are: tensor([2.8764e-09, 3.6717e-06, 6.6518e-05, 1.5269e-03, 9.5044e-03, 1.7087e-01,
        2.4624e-01, 5.7179e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,360][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0467, 0.0310, 0.0757, 0.1175, 0.1380, 0.0983, 0.1191, 0.3737],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,360][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ station] are: tensor([3.1043e-06, 2.4375e-03, 2.2722e-03, 4.2901e-02, 8.5483e-02, 9.7820e-02,
        3.1496e-01, 4.5413e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,361][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0185, 0.2989, 0.2344, 0.2652, 0.0499, 0.0825, 0.0479, 0.0026],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,361][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0439, 0.1194, 0.0656, 0.2870, 0.2092, 0.0560, 0.0829, 0.1360],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,361][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.1768, 0.1711, 0.1088, 0.0328, 0.0720, 0.2446, 0.1197, 0.0742],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,365][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0015, 0.0118, 0.2591, 0.0168, 0.0960, 0.4336, 0.1446, 0.0367],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,370][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.1283, 0.1406, 0.0862, 0.2541, 0.1829, 0.0488, 0.1260, 0.0333],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,372][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1009, 0.1913, 0.0552, 0.1291, 0.1829, 0.0522, 0.0876, 0.2009],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,373][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0385, 0.1137, 0.0670, 0.2160, 0.2086, 0.0488, 0.0784, 0.2291],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,373][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2413, 0.1053, 0.0836, 0.1723, 0.0710, 0.0896, 0.0635, 0.0893, 0.0842],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,373][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2806, 0.1027, 0.1013, 0.1443, 0.0306, 0.0703, 0.1633, 0.0209, 0.0859],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,374][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([1.3776e-09, 8.0199e-07, 1.4069e-05, 4.7345e-04, 1.2283e-03, 1.1989e-02,
        4.6760e-02, 2.7412e-01, 6.6541e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,374][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0524, 0.0320, 0.0535, 0.0985, 0.1059, 0.0833, 0.0991, 0.3253, 0.1500],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,374][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([1.0253e-05, 1.9259e-03, 1.4765e-03, 8.2392e-03, 1.3496e-02, 4.1409e-02,
        1.6208e-01, 3.8839e-01, 3.8298e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,375][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0130, 0.1661, 0.3698, 0.0950, 0.0645, 0.0803, 0.0424, 0.0957, 0.0734],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,375][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0620, 0.0900, 0.0694, 0.2126, 0.1557, 0.0653, 0.0835, 0.1291, 0.1324],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,378][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5186, 0.0760, 0.0319, 0.0089, 0.0226, 0.0834, 0.0401, 0.0298, 0.1887],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,383][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0005, 0.0102, 0.1683, 0.0096, 0.0632, 0.2761, 0.0968, 0.0235, 0.3519],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,386][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1624, 0.1393, 0.0840, 0.1684, 0.1069, 0.0481, 0.1156, 0.1221, 0.0533],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,387][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1349, 0.1550, 0.0606, 0.1290, 0.1456, 0.0470, 0.0841, 0.1823, 0.0616],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,387][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0380, 0.1176, 0.0645, 0.1965, 0.1770, 0.0436, 0.0682, 0.2180, 0.0766],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,387][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.1896, 0.0877, 0.0734, 0.1178, 0.0631, 0.0752, 0.0609, 0.0763, 0.0993,
        0.1565], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,388][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.2042, 0.1372, 0.0935, 0.1550, 0.0718, 0.0211, 0.0687, 0.0566, 0.0879,
        0.1041], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,388][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([2.4704e-10, 2.9224e-08, 3.8680e-07, 2.1063e-06, 1.0628e-05, 4.3390e-04,
        1.3263e-03, 8.3800e-03, 9.1360e-02, 8.9849e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,388][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0272, 0.0144, 0.0325, 0.0575, 0.0700, 0.0510, 0.0628, 0.2533, 0.1131,
        0.3182], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,389][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([1.2969e-06, 4.6135e-05, 1.1422e-04, 1.0598e-03, 1.0239e-03, 3.7527e-03,
        1.1577e-02, 1.9546e-02, 8.2993e-02, 8.7989e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,389][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0132, 0.1023, 0.2865, 0.0176, 0.0303, 0.0812, 0.0761, 0.1258, 0.2523,
        0.0146], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,392][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.0311, 0.0883, 0.0495, 0.1674, 0.1623, 0.0376, 0.0509, 0.1086, 0.0946,
        0.2097], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,397][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.1347, 0.1267, 0.0750, 0.0183, 0.0444, 0.1537, 0.0739, 0.0456, 0.2836,
        0.0441], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,400][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0005, 0.0071, 0.1947, 0.0036, 0.0274, 0.1871, 0.0540, 0.0816, 0.4336,
        0.0104], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,401][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.1592, 0.0750, 0.0910, 0.0496, 0.1635, 0.0537, 0.1194, 0.1480, 0.0927,
        0.0480], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,401][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.0752, 0.1552, 0.0386, 0.1264, 0.1406, 0.0326, 0.0781, 0.1706, 0.0549,
        0.1277], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,402][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0300, 0.0870, 0.0490, 0.1597, 0.1491, 0.0345, 0.0565, 0.1806, 0.0611,
        0.1926], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,402][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1404, 0.0787, 0.0710, 0.1267, 0.0780, 0.0922, 0.0610, 0.0742, 0.0810,
        0.1690, 0.0277], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,402][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1623, 0.1331, 0.1344, 0.0981, 0.0645, 0.0457, 0.1141, 0.0274, 0.0818,
        0.0853, 0.0534], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,403][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([5.4312e-11, 2.5608e-09, 6.5415e-08, 1.2355e-06, 1.6497e-06, 4.3810e-05,
        2.0847e-04, 8.5482e-04, 2.8622e-02, 7.7856e-01, 1.9171e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,403][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0350, 0.0212, 0.0356, 0.0574, 0.0654, 0.0509, 0.0602, 0.1843, 0.0909,
        0.2186, 0.1803], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,403][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([2.4861e-06, 4.8035e-05, 2.3697e-04, 6.2287e-04, 9.8234e-04, 5.1148e-03,
        1.1983e-02, 1.5468e-02, 1.3164e-01, 3.4720e-01, 4.8670e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,406][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0099, 0.1425, 0.1913, 0.0806, 0.0247, 0.0847, 0.0991, 0.1089, 0.1845,
        0.0713, 0.0025], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,411][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0348, 0.0613, 0.0422, 0.1706, 0.1121, 0.0384, 0.0518, 0.0883, 0.0969,
        0.2140, 0.0897], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,415][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.2156, 0.0981, 0.0476, 0.0124, 0.0315, 0.1176, 0.0556, 0.0378, 0.2642,
        0.0401, 0.0795], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,415][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0036, 0.0074, 0.1016, 0.0071, 0.0105, 0.2644, 0.0748, 0.0256, 0.4650,
        0.0181, 0.0219], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,415][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1346, 0.0989, 0.0693, 0.1310, 0.0780, 0.0487, 0.1029, 0.0730, 0.0994,
        0.1383, 0.0258], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,416][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0698, 0.1368, 0.0405, 0.0968, 0.1396, 0.0382, 0.0636, 0.1400, 0.0563,
        0.1055, 0.1129], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,416][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0225, 0.0748, 0.0381, 0.1473, 0.1287, 0.0256, 0.0412, 0.1672, 0.0490,
        0.1831, 0.1225], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,416][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1693, 0.0559, 0.0767, 0.1136, 0.0418, 0.0769, 0.0516, 0.0724, 0.0860,
        0.1526, 0.0446, 0.0585], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,417][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1994, 0.1267, 0.1054, 0.1173, 0.0275, 0.0519, 0.0735, 0.0194, 0.0595,
        0.1041, 0.0306, 0.0846], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,417][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.3823e-11, 7.0774e-10, 1.4654e-08, 2.5534e-07, 1.2013e-06, 2.5337e-05,
        3.7987e-05, 2.6658e-04, 5.2790e-03, 1.3062e-01, 5.1431e-01, 3.4946e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,417][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0337, 0.0193, 0.0295, 0.0491, 0.0557, 0.0436, 0.0505, 0.1561, 0.0737,
        0.1827, 0.1590, 0.1471], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,419][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([1.1125e-06, 2.6502e-05, 4.6649e-05, 1.6017e-04, 7.2655e-04, 1.0830e-03,
        1.7759e-03, 4.4541e-03, 2.9400e-02, 8.2699e-02, 6.3013e-01, 2.4949e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,424][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0083, 0.1185, 0.1442, 0.0975, 0.0359, 0.0851, 0.0278, 0.1933, 0.1503,
        0.0865, 0.0512, 0.0014], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,428][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0365, 0.0598, 0.0466, 0.1384, 0.1082, 0.0435, 0.0535, 0.0925, 0.0934,
        0.1710, 0.0978, 0.0587], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,429][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.2730, 0.0604, 0.0367, 0.0085, 0.0231, 0.0991, 0.0441, 0.0290, 0.2286,
        0.0336, 0.0647, 0.0992], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,429][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([6.5369e-05, 2.2322e-03, 5.0675e-02, 2.9879e-03, 2.3783e-02, 8.3260e-02,
        1.9299e-02, 5.3815e-02, 2.1577e-01, 1.2508e-02, 5.2715e-01, 8.4540e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,430][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1370, 0.0963, 0.0675, 0.1094, 0.0700, 0.0489, 0.0491, 0.1066, 0.0852,
        0.1025, 0.0868, 0.0407], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,430][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1080, 0.0972, 0.0448, 0.1028, 0.1053, 0.0525, 0.0597, 0.1234, 0.0464,
        0.1072, 0.1015, 0.0511], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,430][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0238, 0.0749, 0.0399, 0.1376, 0.1224, 0.0297, 0.0412, 0.1662, 0.0469,
        0.1557, 0.1101, 0.0516], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,431][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1191, 0.0653, 0.0570, 0.1248, 0.0513, 0.0617, 0.0390, 0.0894, 0.0637,
        0.1651, 0.0576, 0.0491, 0.0567], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,431][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.2380, 0.0800, 0.0797, 0.0943, 0.0275, 0.0265, 0.1060, 0.0223, 0.0544,
        0.0694, 0.0238, 0.1153, 0.0627], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,431][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([4.1152e-12, 2.8236e-10, 6.7063e-09, 5.6743e-08, 2.1153e-07, 6.0367e-06,
        1.7727e-05, 1.1206e-04, 2.2615e-03, 2.0001e-02, 6.4377e-02, 6.5447e-01,
        2.5876e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,435][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0191, 0.0129, 0.0298, 0.0404, 0.0531, 0.0341, 0.0384, 0.1193, 0.0630,
        0.1435, 0.1157, 0.1098, 0.2208], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,438][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([5.5408e-07, 5.3048e-06, 5.5825e-05, 1.4189e-04, 1.3642e-04, 1.2076e-03,
        1.9299e-03, 3.4181e-03, 2.9294e-02, 7.3623e-02, 1.1491e-01, 4.1033e-01,
        3.6495e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,442][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0083, 0.2564, 0.0742, 0.1159, 0.0453, 0.0473, 0.0333, 0.1466, 0.0749,
        0.0908, 0.0748, 0.0298, 0.0025], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,443][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0247, 0.0558, 0.0344, 0.1368, 0.1101, 0.0317, 0.0415, 0.0721, 0.0780,
        0.1747, 0.0950, 0.0464, 0.0990], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,443][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1320, 0.0515, 0.0446, 0.0112, 0.0283, 0.1125, 0.0519, 0.0331, 0.2529,
        0.0400, 0.0782, 0.1207, 0.0433], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,444][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0011, 0.0071, 0.1249, 0.0043, 0.0166, 0.1221, 0.0520, 0.0357, 0.4973,
        0.0104, 0.0842, 0.0298, 0.0145], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,444][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0848, 0.0789, 0.0429, 0.1199, 0.0918, 0.0380, 0.0600, 0.0672, 0.0508,
        0.1286, 0.1146, 0.0737, 0.0487], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,444][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0503, 0.0888, 0.0377, 0.0880, 0.1085, 0.0309, 0.0453, 0.1364, 0.0759,
        0.0961, 0.1007, 0.0509, 0.0905], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,445][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0204, 0.0575, 0.0343, 0.1122, 0.1142, 0.0294, 0.0433, 0.1388, 0.0470,
        0.1405, 0.1012, 0.0513, 0.1100], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,445][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1837, 0.0593, 0.0517, 0.0887, 0.0273, 0.0395, 0.0320, 0.0521, 0.0616,
        0.1177, 0.0362, 0.0533, 0.1294, 0.0674], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,446][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1500, 0.0599, 0.0690, 0.1273, 0.0243, 0.0557, 0.1032, 0.0178, 0.0578,
        0.1120, 0.0363, 0.1000, 0.0456, 0.0410], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,449][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([3.7874e-12, 4.0227e-12, 1.0497e-10, 2.0535e-09, 1.3330e-08, 1.4522e-08,
        6.1023e-07, 1.5717e-06, 2.7222e-05, 9.0770e-04, 6.4339e-03, 2.7865e-02,
        8.4787e-02, 8.7998e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,454][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0300, 0.0163, 0.0219, 0.0346, 0.0399, 0.0316, 0.0373, 0.1062, 0.0519,
        0.1187, 0.1096, 0.0997, 0.2046, 0.0978], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,457][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.1810e-07, 2.4114e-06, 2.2823e-06, 1.0605e-05, 2.8528e-04, 3.7266e-05,
        1.4865e-04, 1.2108e-03, 1.5100e-03, 6.4237e-03, 1.3631e-01, 4.1452e-02,
        5.2982e-01, 2.8278e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,457][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0106, 0.2083, 0.1738, 0.0982, 0.0074, 0.0025, 0.0210, 0.1028, 0.0623,
        0.0811, 0.1395, 0.0091, 0.0814, 0.0020], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,457][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0368, 0.0466, 0.0439, 0.1162, 0.0815, 0.0385, 0.0498, 0.0721, 0.0856,
        0.1422, 0.0825, 0.0565, 0.1022, 0.0456], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,458][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2343, 0.0409, 0.0329, 0.0096, 0.0230, 0.0822, 0.0406, 0.0282, 0.1771,
        0.0338, 0.0552, 0.0838, 0.0329, 0.1254], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,458][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([5.4624e-05, 3.5627e-03, 3.1225e-02, 2.2353e-03, 1.1436e-01, 4.4031e-03,
        1.6101e-02, 5.8807e-03, 2.5807e-01, 7.3171e-03, 4.9323e-01, 1.9185e-02,
        3.1326e-02, 1.3049e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,458][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0833, 0.0857, 0.0510, 0.1276, 0.0455, 0.0162, 0.0626, 0.0603, 0.0568,
        0.1211, 0.0615, 0.0907, 0.1165, 0.0211], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,459][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0964, 0.0800, 0.0504, 0.0657, 0.0968, 0.0638, 0.0556, 0.0928, 0.0669,
        0.0708, 0.0901, 0.0477, 0.0512, 0.0719], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,459][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0255, 0.0640, 0.0363, 0.1149, 0.1086, 0.0229, 0.0394, 0.1364, 0.0436,
        0.1316, 0.0973, 0.0509, 0.1071, 0.0216], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,475][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:06,479][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,481][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,482][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,482][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,482][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,483][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,483][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,483][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,484][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,484][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,484][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,485][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,486][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.7255, 0.2745], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,486][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.6711, 0.3289], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,486][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.9909, 0.0091], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,487][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.9935, 0.0065], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,487][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.9761, 0.0239], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,488][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.2544, 0.7456], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,488][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.6588, 0.3412], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,488][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.3839, 0.6161], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,489][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.8941, 0.1059], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,489][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0148, 0.9852], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,489][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.1531, 0.8469], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,490][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.5633, 0.4367], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,490][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5238, 0.2566, 0.2196], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,490][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4184, 0.1534, 0.4282], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,491][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3051, 0.6919, 0.0030], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,492][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([9.9635e-01, 3.5516e-03, 9.9216e-05], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,494][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3249, 0.2549, 0.4202], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,499][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0926, 0.3071, 0.6003], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,502][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4808, 0.1024, 0.4168], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,503][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2080, 0.3164, 0.4756], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,503][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5771, 0.1262, 0.2968], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,503][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.0286e-04, 2.8051e-01, 7.1899e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,504][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0768, 0.3833, 0.5399], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,504][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2118, 0.1472, 0.6410], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,504][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.3346, 0.1921, 0.2507, 0.2226], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,505][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.1761, 0.0968, 0.5850, 0.1422], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,505][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.3004, 0.1539, 0.5150, 0.0307], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,506][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([9.9551e-01, 4.0521e-03, 1.7979e-04, 2.5878e-04], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,511][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.4220, 0.1234, 0.2353, 0.2192], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,517][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0211, 0.0872, 0.2379, 0.6538], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,517][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.1942, 0.0558, 0.4080, 0.3421], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,517][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.1315, 0.2102, 0.3176, 0.3407], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,518][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.3440, 0.0619, 0.3587, 0.2354], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,518][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([9.7622e-05, 3.0277e-02, 5.1826e-01, 4.5137e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,519][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.0442, 0.2323, 0.3302, 0.3933], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,519][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.1968, 0.1603, 0.5233, 0.1195], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,519][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.2989, 0.1543, 0.2507, 0.2329, 0.0631], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,520][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.1599, 0.0961, 0.4405, 0.1591, 0.1444], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,521][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([5.7214e-01, 1.1845e-01, 1.2520e-01, 1.8409e-01, 1.2402e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,523][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([9.9664e-01, 2.6764e-03, 1.8615e-04, 2.5355e-04, 2.4398e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,529][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.6290, 0.0131, 0.3102, 0.0299, 0.0177], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,531][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0200, 0.0849, 0.1795, 0.4496, 0.2660], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,532][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1518, 0.0372, 0.2317, 0.2782, 0.3010], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,532][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0893, 0.1449, 0.2202, 0.2365, 0.3092], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,532][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.3635, 0.0688, 0.1606, 0.2666, 0.1404], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,533][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([1.7948e-05, 1.0206e-02, 1.0411e-01, 4.5131e-01, 4.3436e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,533][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0292, 0.1524, 0.2169, 0.2554, 0.3461], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,533][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1636, 0.1308, 0.4503, 0.1059, 0.1495], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,534][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3584, 0.1503, 0.1684, 0.1578, 0.0649, 0.1002], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,534][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1634, 0.0587, 0.2257, 0.1256, 0.1460, 0.2807], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,535][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([7.7378e-01, 7.1758e-03, 1.9497e-02, 1.2438e-01, 7.5124e-02, 4.0981e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,538][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.8918e-01, 3.7773e-03, 3.3238e-04, 4.2918e-04, 7.6197e-04, 5.5241e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,544][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1167, 0.1161, 0.2446, 0.1478, 0.2970, 0.0778], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,546][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0153, 0.0754, 0.1307, 0.4611, 0.2803, 0.0372], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,546][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1131, 0.0233, 0.1372, 0.1826, 0.1369, 0.4069], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,547][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0677, 0.1063, 0.1637, 0.1760, 0.2311, 0.2551], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,547][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1047, 0.0511, 0.1162, 0.1964, 0.4761, 0.0555], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,547][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([6.8918e-06, 2.8946e-03, 1.6284e-02, 1.4862e-01, 2.2708e-01, 6.0511e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,548][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0267, 0.1469, 0.1789, 0.2145, 0.2685, 0.1645], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,548][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0821, 0.0501, 0.3992, 0.0548, 0.1088, 0.3050], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,548][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.2714, 0.1358, 0.1418, 0.1850, 0.0792, 0.1267, 0.0600],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,550][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1038, 0.0587, 0.2487, 0.0811, 0.0795, 0.3329, 0.0952],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,554][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.4927, 0.1170, 0.0727, 0.0847, 0.1809, 0.0505, 0.0014],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,558][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([9.7478e-01, 3.2017e-03, 2.9785e-04, 3.6152e-04, 7.1958e-04, 1.1339e-02,
        9.3001e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,560][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.2688, 0.1105, 0.2338, 0.1454, 0.0277, 0.1296, 0.0843],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,561][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0130, 0.0631, 0.1266, 0.4175, 0.2606, 0.0476, 0.0716],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,561][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0633, 0.0158, 0.0775, 0.1106, 0.1087, 0.2432, 0.3809],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,561][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0587, 0.0883, 0.1363, 0.1423, 0.1859, 0.2056, 0.1830],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,562][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.1433, 0.0500, 0.1559, 0.1744, 0.2498, 0.1654, 0.0611],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,562][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.4824e-06, 9.5507e-04, 4.5867e-03, 3.5396e-02, 9.2384e-02, 4.6847e-01,
        3.9820e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,562][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0233, 0.1263, 0.1519, 0.1816, 0.2267, 0.1393, 0.1508],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,563][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0779, 0.0439, 0.3588, 0.0364, 0.0874, 0.2723, 0.1234],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,565][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.2333, 0.1514, 0.1165, 0.1596, 0.0978, 0.0920, 0.0690, 0.0804],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,570][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0884, 0.0474, 0.1682, 0.1094, 0.0948, 0.2123, 0.0973, 0.1823],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,575][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2775, 0.1972, 0.1206, 0.1811, 0.0619, 0.0229, 0.1354, 0.0033],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,575][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([9.5086e-01, 8.4192e-03, 4.6708e-04, 9.7752e-04, 1.8496e-03, 1.0335e-02,
        2.3175e-02, 3.9171e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,575][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.2515, 0.1113, 0.1791, 0.0821, 0.1124, 0.0537, 0.1970, 0.0130],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,576][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0109, 0.0398, 0.0900, 0.2795, 0.1923, 0.0305, 0.0650, 0.2920],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,576][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0573, 0.0075, 0.0655, 0.0715, 0.0551, 0.2024, 0.3558, 0.1848],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,577][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0485, 0.0723, 0.1115, 0.1133, 0.1486, 0.1666, 0.1489, 0.1902],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,577][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.1413, 0.0253, 0.1088, 0.1420, 0.2206, 0.1262, 0.0874, 0.1484],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,577][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([5.6204e-07, 1.5588e-04, 1.9048e-03, 1.0823e-02, 2.9573e-02, 1.9400e-01,
        4.2404e-01, 3.3951e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,579][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0161, 0.0889, 0.1229, 0.1453, 0.1962, 0.1094, 0.1136, 0.2076],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,585][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0933, 0.0853, 0.2488, 0.0723, 0.0925, 0.1644, 0.1576, 0.0858],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,589][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2289, 0.1158, 0.1124, 0.1462, 0.0742, 0.1056, 0.0682, 0.0821, 0.0667],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,589][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1047, 0.0425, 0.1308, 0.0777, 0.0906, 0.1715, 0.1009, 0.1552, 0.1261],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,590][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1521, 0.0725, 0.0269, 0.3693, 0.1304, 0.0284, 0.1752, 0.0376, 0.0076],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,590][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([9.8297e-01, 2.1181e-03, 9.7820e-05, 1.4267e-04, 2.9116e-04, 6.3938e-03,
        5.5270e-03, 1.5073e-03, 9.4778e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,591][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1182, 0.1699, 0.1269, 0.0750, 0.0185, 0.0529, 0.2465, 0.0893, 0.1029],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,591][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0099, 0.0387, 0.0782, 0.2532, 0.1598, 0.0297, 0.0487, 0.3371, 0.0447],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,591][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0380, 0.0078, 0.0475, 0.0477, 0.0582, 0.1229, 0.1673, 0.1479, 0.3627],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,592][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0389, 0.0587, 0.0929, 0.0948, 0.1244, 0.1386, 0.1249, 0.1630, 0.1637],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,595][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1475, 0.0406, 0.0837, 0.1198, 0.2047, 0.1010, 0.0683, 0.1518, 0.0825],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,598][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.1163e-07, 7.5330e-05, 3.9170e-04, 2.9366e-03, 7.1701e-03, 5.2690e-02,
        1.0428e-01, 3.2866e-01, 5.0380e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,603][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0174, 0.0917, 0.1100, 0.1304, 0.1628, 0.1010, 0.1077, 0.1760, 0.1030],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,604][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0736, 0.0396, 0.2712, 0.0395, 0.0685, 0.1901, 0.1213, 0.0498, 0.1463],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,604][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.1687, 0.0895, 0.1135, 0.0979, 0.0719, 0.0929, 0.0714, 0.0714, 0.1053,
        0.1177], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,605][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.0620, 0.0329, 0.2236, 0.0337, 0.0435, 0.2746, 0.0543, 0.0968, 0.1627,
        0.0159], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,605][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0365, 0.0074, 0.0514, 0.0022, 0.0164, 0.0222, 0.4577, 0.1240, 0.2786,
        0.0037], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,606][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([9.7577e-01, 3.0232e-03, 1.2020e-04, 1.5598e-04, 4.2523e-04, 6.6694e-03,
        8.8811e-03, 2.3989e-03, 1.9352e-03, 6.2216e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,606][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.1670, 0.0447, 0.0982, 0.0868, 0.0267, 0.0648, 0.0783, 0.1356, 0.1930,
        0.1048], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,606][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0052, 0.0181, 0.0485, 0.1325, 0.0947, 0.0151, 0.0306, 0.1772, 0.0265,
        0.4516], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,610][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.0126, 0.0039, 0.0335, 0.0237, 0.0448, 0.0866, 0.1153, 0.0851, 0.3663,
        0.2283], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,614][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0330, 0.0531, 0.0817, 0.0858, 0.1130, 0.1255, 0.1115, 0.1485, 0.1474,
        0.1004], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,618][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.1069, 0.0182, 0.0995, 0.0621, 0.1549, 0.0922, 0.0575, 0.1873, 0.1201,
        0.1013], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,618][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([1.3312e-07, 7.3768e-06, 1.1354e-04, 1.3306e-04, 1.8078e-03, 1.5422e-02,
        1.7844e-02, 5.2998e-02, 3.3592e-01, 5.7575e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,619][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.0151, 0.0793, 0.1004, 0.1191, 0.1533, 0.0908, 0.0946, 0.1608, 0.0864,
        0.1002], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,619][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0735, 0.0574, 0.1953, 0.0408, 0.0887, 0.1436, 0.1310, 0.0955, 0.1322,
        0.0420], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,620][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1259, 0.0845, 0.0955, 0.1134, 0.0992, 0.1059, 0.0651, 0.0737, 0.0722,
        0.1355, 0.0291], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,620][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0492, 0.0338, 0.1778, 0.0478, 0.0464, 0.2446, 0.0565, 0.1217, 0.1492,
        0.0239, 0.0492], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,620][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([5.1198e-02, 1.0664e-02, 2.4926e-02, 1.0984e-01, 2.6295e-03, 9.6907e-03,
        9.0950e-02, 2.9923e-02, 5.3522e-01, 1.3480e-01, 1.5331e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,621][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([9.1789e-01, 7.3240e-03, 7.0718e-04, 1.1084e-03, 1.3032e-03, 1.6531e-02,
        2.3345e-02, 8.4006e-03, 5.4415e-03, 3.7158e-03, 1.4237e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,624][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.2378, 0.0241, 0.1852, 0.0426, 0.0163, 0.0748, 0.1097, 0.0234, 0.2286,
        0.0542, 0.0033], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,630][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0048, 0.0180, 0.0418, 0.1245, 0.0662, 0.0109, 0.0228, 0.1612, 0.0198,
        0.4685, 0.0616], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,632][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0165, 0.0029, 0.0197, 0.0221, 0.0266, 0.0661, 0.0840, 0.0697, 0.2795,
        0.2172, 0.1958], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,633][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0281, 0.0456, 0.0714, 0.0752, 0.0992, 0.1114, 0.0986, 0.1319, 0.1306,
        0.0891, 0.1189], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,633][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1421, 0.0315, 0.0700, 0.0846, 0.0612, 0.1275, 0.0779, 0.1109, 0.1128,
        0.1143, 0.0673], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,633][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.4933e-08, 2.8273e-06, 2.5308e-05, 1.4149e-04, 2.2486e-04, 2.1690e-03,
        4.6787e-03, 1.4584e-02, 1.1938e-01, 6.9618e-01, 1.6261e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,634][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0150, 0.0697, 0.0889, 0.1041, 0.1331, 0.0819, 0.0853, 0.1443, 0.0812,
        0.0924, 0.1041], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,634][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0623, 0.0440, 0.1717, 0.0412, 0.0560, 0.1735, 0.1458, 0.0667, 0.1435,
        0.0424, 0.0530], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,635][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1722, 0.0594, 0.1085, 0.0978, 0.0443, 0.0942, 0.0587, 0.0723, 0.0768,
        0.1174, 0.0480, 0.0507], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,635][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0668, 0.0378, 0.1483, 0.0512, 0.0527, 0.1982, 0.0657, 0.1159, 0.1301,
        0.0316, 0.0523, 0.0493], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,637][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.4112e-01, 2.8754e-03, 8.1382e-02, 2.5622e-02, 1.1471e-01, 2.8529e-02,
        7.3154e-02, 1.5570e-01, 3.1246e-01, 4.8417e-02, 1.5767e-02, 2.6174e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,640][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([9.2419e-01, 3.6724e-03, 3.1941e-04, 4.3814e-04, 6.3982e-04, 8.9096e-03,
        1.1640e-02, 4.0039e-03, 2.6247e-03, 1.7609e-03, 1.8327e-02, 2.3471e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,645][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1854, 0.0402, 0.2168, 0.0359, 0.0194, 0.0763, 0.0819, 0.0246, 0.2053,
        0.0391, 0.0158, 0.0592], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,647][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0029, 0.0156, 0.0340, 0.1351, 0.0660, 0.0104, 0.0175, 0.1701, 0.0163,
        0.4603, 0.0603, 0.0115], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,647][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0084, 0.0027, 0.0134, 0.0149, 0.0143, 0.0418, 0.0572, 0.0371, 0.1697,
        0.1365, 0.1379, 0.3662], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,648][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0272, 0.0423, 0.0660, 0.0689, 0.0907, 0.1004, 0.0887, 0.1178, 0.1167,
        0.0810, 0.1071, 0.0932], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,648][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0681, 0.0163, 0.0619, 0.0694, 0.1049, 0.0537, 0.0336, 0.1393, 0.0737,
        0.1093, 0.2354, 0.0344], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,648][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.0158e-08, 1.4724e-06, 7.0168e-06, 4.7668e-05, 9.2697e-05, 7.1452e-04,
        6.5355e-04, 8.5129e-03, 4.0614e-02, 2.1673e-01, 3.0533e-01, 4.2730e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,649][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0153, 0.0709, 0.0823, 0.0965, 0.1170, 0.0765, 0.0809, 0.1275, 0.0789,
        0.0895, 0.0961, 0.0685], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,649][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0563, 0.0301, 0.2037, 0.0294, 0.0537, 0.1723, 0.0946, 0.0419, 0.1352,
        0.0306, 0.0651, 0.0871], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,651][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.1068, 0.0745, 0.0847, 0.1123, 0.0619, 0.0751, 0.0440, 0.0926, 0.0598,
        0.1301, 0.0750, 0.0434, 0.0399], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,657][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0513, 0.0249, 0.1427, 0.0474, 0.0459, 0.1889, 0.0558, 0.1208, 0.1220,
        0.0267, 0.0663, 0.0512, 0.0561], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,661][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0185, 0.0208, 0.0383, 0.1995, 0.0072, 0.0083, 0.0722, 0.0156, 0.4851,
        0.1117, 0.0026, 0.0123, 0.0080], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,661][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([8.1832e-01, 7.6134e-03, 3.7485e-04, 1.1984e-03, 1.9491e-03, 9.1725e-03,
        1.7556e-02, 6.6216e-03, 4.1791e-03, 4.4378e-03, 2.5725e-02, 6.7822e-02,
        3.5033e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,662][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.2047, 0.0265, 0.1172, 0.0617, 0.0137, 0.0565, 0.0779, 0.0192, 0.2487,
        0.0735, 0.0261, 0.0555, 0.0187], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,662][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0023, 0.0114, 0.0344, 0.1142, 0.0877, 0.0119, 0.0276, 0.1477, 0.0222,
        0.3989, 0.0761, 0.0170, 0.0485], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,663][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0060, 0.0014, 0.0109, 0.0088, 0.0113, 0.0330, 0.0427, 0.0236, 0.1786,
        0.0826, 0.1273, 0.3706, 0.1032], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,663][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0245, 0.0391, 0.0605, 0.0627, 0.0839, 0.0949, 0.0825, 0.1065, 0.1090,
        0.0725, 0.0994, 0.0865, 0.0780], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,664][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0802, 0.0130, 0.0690, 0.0505, 0.1012, 0.0714, 0.0432, 0.1092, 0.0801,
        0.0770, 0.1752, 0.0617, 0.0684], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,665][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([6.5292e-09, 5.7098e-07, 4.0692e-06, 2.1810e-05, 6.5628e-05, 6.0501e-04,
        6.5223e-04, 3.2456e-03, 2.0284e-02, 7.8078e-02, 1.6543e-01, 3.7187e-01,
        3.5975e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,669][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0109, 0.0627, 0.0816, 0.0953, 0.1241, 0.0713, 0.0747, 0.1303, 0.0670,
        0.0764, 0.0873, 0.0551, 0.0630], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,674][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0502, 0.0553, 0.1269, 0.0533, 0.0732, 0.0978, 0.0859, 0.0886, 0.0999,
        0.0526, 0.0570, 0.0858, 0.0734], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,676][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1849, 0.0734, 0.0741, 0.0780, 0.0320, 0.0430, 0.0367, 0.0564, 0.0555,
        0.0899, 0.0461, 0.0512, 0.1208, 0.0580], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,676][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0800, 0.0346, 0.1118, 0.0483, 0.0553, 0.1419, 0.0687, 0.0959, 0.0996,
        0.0321, 0.0549, 0.0482, 0.0534, 0.0754], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,676][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.6704e-01, 1.5951e-03, 1.2547e-02, 4.5072e-02, 5.9296e-02, 3.8223e-05,
        1.7218e-01, 8.1514e-03, 2.0863e-01, 3.8293e-02, 5.4536e-03, 3.5033e-02,
        4.6619e-02, 4.7207e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,677][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.2299e-01, 4.8360e-03, 4.4580e-04, 5.9693e-04, 7.9100e-04, 5.0571e-03,
        1.1870e-02, 4.4169e-03, 2.9464e-03, 1.9031e-03, 2.4977e-02, 4.4226e-02,
        4.4640e-02, 3.0301e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,677][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0634, 0.0563, 0.1177, 0.0605, 0.1153, 0.0355, 0.0471, 0.0791, 0.0979,
        0.0763, 0.0719, 0.0553, 0.0916, 0.0319], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,678][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0032, 0.0138, 0.0307, 0.1187, 0.0685, 0.0071, 0.0188, 0.1553, 0.0177,
        0.3914, 0.0709, 0.0143, 0.0832, 0.0064], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,678][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0064, 0.0008, 0.0068, 0.0059, 0.0065, 0.0164, 0.0326, 0.0112, 0.1255,
        0.0532, 0.0616, 0.2204, 0.0545, 0.3982], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,682][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0235, 0.0358, 0.0560, 0.0582, 0.0765, 0.0839, 0.0750, 0.0987, 0.0975,
        0.0680, 0.0889, 0.0780, 0.0705, 0.0894], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,686][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0421, 0.0202, 0.0440, 0.0678, 0.1601, 0.0171, 0.0276, 0.0730, 0.0573,
        0.0857, 0.2031, 0.0456, 0.1373, 0.0190], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,690][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.3605e-09, 5.8431e-08, 2.3641e-07, 2.4494e-06, 3.0421e-06, 1.0389e-05,
        5.1636e-05, 2.1581e-04, 1.4579e-03, 9.3521e-03, 9.9203e-03, 5.5228e-02,
        1.8821e-01, 7.3555e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,690][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0133, 0.0659, 0.0733, 0.0867, 0.1027, 0.0676, 0.0718, 0.1110, 0.0692,
        0.0796, 0.0831, 0.0599, 0.0683, 0.0475], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,691][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0376, 0.0210, 0.1771, 0.0229, 0.0462, 0.1281, 0.0933, 0.0221, 0.1281,
        0.0231, 0.0427, 0.0809, 0.0288, 0.1482], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,692][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:06,693][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14565],
        [   48],
        [19632],
        [ 3232],
        [ 3470],
        [ 4717],
        [ 9644],
        [ 4309],
        [ 2376],
        [ 3337],
        [ 1381],
        [ 3959],
        [ 6967],
        [ 5475]], device='cuda:0')
[2024-07-24 10:30:06,694][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[16112],
        [   40],
        [16278],
        [ 1453],
        [ 4260],
        [ 4076],
        [ 9285],
        [ 2792],
        [ 2107],
        [ 1668],
        [ 1748],
        [ 1751],
        [ 4498],
        [ 3983]], device='cuda:0')
[2024-07-24 10:30:06,697][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[40633],
        [40999],
        [40769],
        [40241],
        [40425],
        [40217],
        [40281],
        [39484],
        [38818],
        [38576],
        [38624],
        [38864],
        [38667],
        [39082]], device='cuda:0')
[2024-07-24 10:30:06,700][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[24586],
        [ 3309],
        [ 7660],
        [  236],
        [  375],
        [  570],
        [  695],
        [  597],
        [  487],
        [  169],
        [  170],
        [  171],
        [  276],
        [  161]], device='cuda:0')
[2024-07-24 10:30:06,702][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4435],
        [ 5359],
        [ 4793],
        [14681],
        [32780],
        [42237],
        [20851],
        [32928],
        [30215],
        [21675],
        [27053],
        [36538],
        [16525],
        [28941]], device='cuda:0')
[2024-07-24 10:30:06,705][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[12209],
        [12650],
        [12185],
        [11596],
        [11792],
        [11899],
        [11681],
        [11331],
        [11216],
        [10638],
        [10828],
        [10790],
        [10865],
        [10855]], device='cuda:0')
[2024-07-24 10:30:06,707][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[37539],
        [47700],
        [48721],
        [47481],
        [49175],
        [46441],
        [47633],
        [37128],
        [38056],
        [46679],
        [48944],
        [47626],
        [49700],
        [49482]], device='cuda:0')
[2024-07-24 10:30:06,708][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[26403],
        [32803],
        [32830],
        [22755],
        [23537],
        [26521],
        [21442],
        [26656],
        [23714],
        [24022],
        [25740],
        [22224],
        [28011],
        [27187]], device='cuda:0')
[2024-07-24 10:30:06,709][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[29692],
        [20810],
        [21500],
        [24602],
        [28443],
        [28357],
        [28972],
        [28528],
        [28578],
        [28219],
        [28967],
        [28971],
        [29093],
        [28875]], device='cuda:0')
[2024-07-24 10:30:06,710][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[45354],
        [45863],
        [45202],
        [44999],
        [44586],
        [44398],
        [43652],
        [43360],
        [42455],
        [42092],
        [41759],
        [41191],
        [40738],
        [40772]], device='cuda:0')
[2024-07-24 10:30:06,712][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[29695],
        [24634],
        [47975],
        [48367],
        [48001],
        [18668],
        [46507],
        [47369],
        [48186],
        [48599],
        [48542],
        [48780],
        [49125],
        [47805]], device='cuda:0')
[2024-07-24 10:30:06,714][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[31065],
        [26329],
        [20640],
        [24033],
        [23794],
        [23413],
        [26516],
        [26335],
        [25796],
        [30051],
        [26145],
        [27093],
        [27621],
        [26948]], device='cuda:0')
[2024-07-24 10:30:06,717][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[13319],
        [10047],
        [13033],
        [11445],
        [10487],
        [12484],
        [12232],
        [12848],
        [13712],
        [12766],
        [10869],
        [11080],
        [10529],
        [11858]], device='cuda:0')
[2024-07-24 10:30:06,719][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[19506],
        [ 8078],
        [ 9231],
        [12589],
        [17466],
        [18862],
        [19173],
        [21866],
        [21412],
        [21878],
        [22708],
        [22897],
        [23379],
        [23221]], device='cuda:0')
[2024-07-24 10:30:06,722][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12924],
        [20126],
        [31110],
        [11770],
        [33498],
        [45459],
        [37912],
        [46879],
        [34364],
        [21898],
        [25363],
        [45655],
        [34762],
        [40078]], device='cuda:0')
[2024-07-24 10:30:06,724][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18178],
        [17764],
        [18451],
        [18096],
        [17562],
        [18368],
        [17794],
        [17593],
        [18734],
        [18920],
        [18121],
        [18400],
        [18103],
        [19451]], device='cuda:0')
[2024-07-24 10:30:06,725][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[29134],
        [28090],
        [27522],
        [25093],
        [23478],
        [21717],
        [21089],
        [17913],
        [17841],
        [18972],
        [17943],
        [17818],
        [17545],
        [17788]], device='cuda:0')
[2024-07-24 10:30:06,726][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[29059],
        [29122],
        [21431],
        [25064],
        [27940],
        [28871],
        [26837],
        [23878],
        [24694],
        [30674],
        [25344],
        [29674],
        [25461],
        [29849]], device='cuda:0')
[2024-07-24 10:30:06,727][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[23606],
        [23588],
        [23599],
        [23595],
        [23600],
        [23615],
        [23665],
        [23669],
        [23622],
        [23611],
        [23596],
        [24005],
        [24862],
        [24756]], device='cuda:0')
[2024-07-24 10:30:06,729][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20333],
        [20580],
        [20058],
        [23440],
        [19763],
        [24586],
        [22869],
        [24690],
        [23308],
        [22036],
        [20598],
        [20719],
        [21935],
        [24827]], device='cuda:0')
[2024-07-24 10:30:06,731][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[5066],
        [5495],
        [5265],
        [6422],
        [6370],
        [6365],
        [6166],
        [6536],
        [6502],
        [6980],
        [7009],
        [7034],
        [6850],
        [6922]], device='cuda:0')
[2024-07-24 10:30:06,734][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[12202],
        [ 3944],
        [ 4615],
        [17505],
        [31230],
        [25845],
        [20890],
        [17309],
        [16998],
        [22064],
        [25461],
        [19232],
        [15485],
        [13669]], device='cuda:0')
[2024-07-24 10:30:06,737][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13230],
        [11984],
        [10947],
        [10461],
        [ 9742],
        [ 9720],
        [ 9244],
        [ 8719],
        [ 8267],
        [ 8229],
        [ 8085],
        [ 7874],
        [ 7883],
        [ 7902]], device='cuda:0')
[2024-07-24 10:30:06,739][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[32586],
        [32534],
        [33816],
        [33115],
        [30068],
        [22867],
        [28045],
        [27571],
        [27691],
        [28014],
        [29692],
        [28292],
        [28860],
        [27634]], device='cuda:0')
[2024-07-24 10:30:06,742][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[18315],
        [ 8560],
        [13490],
        [13056],
        [14594],
        [15581],
        [14376],
        [14409],
        [14930],
        [11746],
        [11753],
        [13426],
        [13769],
        [15066]], device='cuda:0')
[2024-07-24 10:30:06,743][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[14736],
        [17824],
        [16738],
        [17049],
        [16928],
        [17021],
        [17219],
        [17675],
        [17680],
        [17966],
        [18046],
        [18163],
        [18343],
        [18612]], device='cuda:0')
[2024-07-24 10:30:06,743][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[19498],
        [15506],
        [10759],
        [10972],
        [11015],
        [11257],
        [11814],
        [12880],
        [11560],
        [12282],
        [12180],
        [11288],
        [11953],
        [11697]], device='cuda:0')
[2024-07-24 10:30:06,744][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[16450],
        [20745],
        [22395],
        [19281],
        [18084],
        [18911],
        [19698],
        [20286],
        [20895],
        [20463],
        [20256],
        [20646],
        [20646],
        [19125]], device='cuda:0')
[2024-07-24 10:30:06,746][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[34535],
        [28102],
        [26113],
        [34949],
        [19934],
        [20338],
        [20757],
        [18530],
        [20917],
        [34589],
        [28209],
        [14070],
        [29885],
        [23995]], device='cuda:0')
[2024-07-24 10:30:06,748][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[11343],
        [11343],
        [11343],
        [11343],
        [11343],
        [11343],
        [11343],
        [11343],
        [11343],
        [11343],
        [11343],
        [11343],
        [11343],
        [11343]], device='cuda:0')
[2024-07-24 10:30:06,771][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:06,773][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,774][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,774][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,775][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,775][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,775][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,776][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,776][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,776][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,777][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,777][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,777][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:06,778][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.7537, 0.2463], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,778][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.1659, 0.8341], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,778][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.4217, 0.5783], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,779][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.2648, 0.7352], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,779][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.7153, 0.2847], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,779][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.4709, 0.5291], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,780][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.4249, 0.5751], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,780][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.8346, 0.1654], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,781][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.9563, 0.0437], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,781][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.3891, 0.6109], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,781][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.2787, 0.7213], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,782][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.2906, 0.7094], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:06,782][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5859, 0.1445, 0.2695], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,782][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0731, 0.4742, 0.4526], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,783][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0022, 0.9854, 0.0124], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,783][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0604, 0.6588, 0.2808], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,783][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4550, 0.2278, 0.3172], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,786][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3208, 0.3641, 0.3151], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,788][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1403, 0.1812, 0.6785], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,788][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4968, 0.1679, 0.3353], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,789][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4428, 0.5380, 0.0191], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,789][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2264, 0.3442, 0.4294], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,790][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1830, 0.4991, 0.3179], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,793][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1281, 0.4998, 0.3721], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:06,796][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.5103, 0.0991, 0.1904, 0.2002], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,797][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.0297, 0.1527, 0.2355, 0.5822], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,797][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0189, 0.6679, 0.0606, 0.2526], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,797][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0582, 0.1870, 0.1415, 0.6133], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,798][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.3929, 0.2112, 0.2610, 0.1350], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,798][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.2216, 0.2558, 0.2234, 0.2992], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,799][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.0777, 0.1000, 0.5522, 0.2701], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,799][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.2873, 0.1228, 0.5458, 0.0440], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,804][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.2322, 0.0980, 0.6276, 0.0422], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,808][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.0975, 0.3206, 0.3274, 0.2545], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,810][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.0965, 0.3564, 0.1644, 0.3827], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,811][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0941, 0.3074, 0.2124, 0.3861], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:06,811][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.4940, 0.0930, 0.1650, 0.1261, 0.1219], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,811][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0212, 0.0953, 0.1885, 0.5645, 0.1305], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,812][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0263, 0.5713, 0.0107, 0.1922, 0.1995], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,812][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0460, 0.0706, 0.1228, 0.7289, 0.0318], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,812][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2853, 0.1881, 0.1807, 0.1560, 0.1899], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,813][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1755, 0.1911, 0.1838, 0.2316, 0.2180], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,813][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0655, 0.0647, 0.2708, 0.1380, 0.4610], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,817][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2542, 0.1203, 0.4808, 0.0865, 0.0583], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,822][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.4594, 0.1320, 0.3105, 0.0769, 0.0212], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,825][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.2987, 0.0262, 0.2900, 0.2503, 0.1348], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,825][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0821, 0.2440, 0.1022, 0.2410, 0.3308], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,825][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0913, 0.2127, 0.1432, 0.2555, 0.2973], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:06,826][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3633, 0.0856, 0.1436, 0.1157, 0.1029, 0.1889], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,826][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0167, 0.1019, 0.1379, 0.5586, 0.1269, 0.0581], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,826][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.8203e-04, 1.8480e-01, 4.5105e-03, 1.1027e-01, 6.9968e-01, 5.5182e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,827][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0093, 0.0898, 0.0556, 0.6840, 0.1442, 0.0171], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,830][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2471, 0.1287, 0.1775, 0.1208, 0.1699, 0.1560], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,836][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1485, 0.1626, 0.1479, 0.1912, 0.1837, 0.1661], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,838][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0355, 0.0431, 0.1798, 0.0994, 0.3665, 0.2756], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,839][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2553, 0.1400, 0.2017, 0.0628, 0.1211, 0.2190], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,839][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1124, 0.3203, 0.3506, 0.0558, 0.1491, 0.0117], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,839][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0487, 0.0345, 0.1804, 0.1398, 0.5850, 0.0115], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,840][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0694, 0.1835, 0.1118, 0.1636, 0.2533, 0.2184], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,840][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0598, 0.1654, 0.1160, 0.2022, 0.2318, 0.2248], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:06,841][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2930, 0.0698, 0.1212, 0.1083, 0.0823, 0.1437, 0.1817],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,841][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0114, 0.0970, 0.1089, 0.4459, 0.1101, 0.0475, 0.1793],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,842][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([1.8035e-04, 1.1217e-01, 5.4645e-03, 1.1383e-01, 7.6566e-01, 9.1528e-04,
        1.7727e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,846][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0154, 0.1028, 0.0609, 0.6020, 0.0989, 0.0426, 0.0775],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,851][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2091, 0.1133, 0.1525, 0.1123, 0.1330, 0.1312, 0.1486],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,853][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.1253, 0.1399, 0.1246, 0.1656, 0.1539, 0.1381, 0.1526],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,853][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0109, 0.0290, 0.1295, 0.0759, 0.2834, 0.2354, 0.2359],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,854][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1267, 0.1325, 0.2310, 0.0589, 0.1375, 0.2497, 0.0637],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,854][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1818, 0.1686, 0.0941, 0.2062, 0.1960, 0.1460, 0.0072],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,854][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1768, 0.0835, 0.1666, 0.1242, 0.3460, 0.0798, 0.0230],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,855][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0452, 0.1674, 0.0845, 0.1651, 0.2636, 0.1358, 0.1385],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,855][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0595, 0.1403, 0.0746, 0.1428, 0.1770, 0.1651, 0.2407],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:06,859][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.3105, 0.0566, 0.1109, 0.0772, 0.0644, 0.1435, 0.1603, 0.0766],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,864][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0122, 0.0728, 0.1159, 0.3485, 0.0970, 0.0508, 0.2064, 0.0965],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,866][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ station] are: tensor([8.4373e-05, 1.3074e-01, 6.1549e-03, 1.8255e-01, 6.7098e-01, 1.0084e-03,
        7.7000e-03, 7.8426e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,867][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0250, 0.0665, 0.0589, 0.5888, 0.0547, 0.0570, 0.1116, 0.0374],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,867][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.1909, 0.0964, 0.1343, 0.1045, 0.1444, 0.1168, 0.1204, 0.0924],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,868][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.1073, 0.1200, 0.1108, 0.1432, 0.1464, 0.1204, 0.1396, 0.1123],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,868][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0269, 0.0324, 0.1359, 0.0656, 0.2319, 0.2081, 0.2424, 0.0567],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,869][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.4377, 0.0855, 0.1283, 0.0359, 0.0834, 0.1303, 0.0397, 0.0590],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,869][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.2009, 0.1504, 0.1188, 0.1480, 0.0972, 0.2502, 0.0327, 0.0017],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,869][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0627, 0.1383, 0.1719, 0.1861, 0.1319, 0.0839, 0.0608, 0.1644],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,873][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0402, 0.1202, 0.0771, 0.1442, 0.2138, 0.1277, 0.0952, 0.1815],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,877][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0487, 0.1115, 0.0605, 0.1127, 0.1465, 0.1324, 0.1973, 0.1905],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:06,881][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2452, 0.0571, 0.1009, 0.0827, 0.0690, 0.1233, 0.1435, 0.0640, 0.1142],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,881][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0105, 0.0688, 0.0876, 0.3838, 0.0740, 0.0387, 0.1627, 0.0739, 0.0999],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,882][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([6.3657e-06, 1.1384e-01, 5.4798e-03, 2.3281e-01, 6.3166e-01, 5.6923e-04,
        1.3831e-02, 1.7419e-03, 6.0966e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,882][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0107, 0.1038, 0.0424, 0.4971, 0.0872, 0.0332, 0.1244, 0.0656, 0.0357],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,883][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1816, 0.0828, 0.1219, 0.0815, 0.1059, 0.1087, 0.1151, 0.0970, 0.1054],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,883][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0984, 0.1112, 0.0981, 0.1292, 0.1241, 0.1084, 0.1237, 0.1036, 0.1034],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,883][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0110, 0.0255, 0.1053, 0.0643, 0.2357, 0.1918, 0.1918, 0.0582, 0.1164],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,887][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1528, 0.0588, 0.1070, 0.0348, 0.0818, 0.1381, 0.0839, 0.2627, 0.0801],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,893][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0476, 0.0653, 0.0489, 0.1414, 0.3838, 0.0493, 0.1183, 0.1351, 0.0103],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,895][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1044, 0.0574, 0.1150, 0.1454, 0.1137, 0.0255, 0.0524, 0.3668, 0.0195],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,895][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0396, 0.1184, 0.0891, 0.1072, 0.1646, 0.1195, 0.1065, 0.1469, 0.1081],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,896][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0352, 0.0880, 0.0481, 0.1046, 0.1222, 0.1094, 0.1730, 0.1770, 0.1426],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:06,896][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.2639, 0.0464, 0.0897, 0.0926, 0.0522, 0.1081, 0.1284, 0.0460, 0.0973,
        0.0753], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,896][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.0106, 0.0589, 0.0863, 0.2243, 0.0784, 0.0395, 0.1424, 0.0945, 0.1100,
        0.1553], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,897][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([6.3907e-05, 8.9709e-02, 1.3999e-02, 1.7377e-01, 7.1298e-01, 4.0294e-04,
        7.4115e-03, 6.4396e-04, 7.2695e-05, 9.4013e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,897][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0202, 0.0708, 0.0671, 0.2664, 0.0636, 0.0504, 0.0815, 0.0684, 0.0541,
        0.2575], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,898][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.1884, 0.0905, 0.1169, 0.0584, 0.0906, 0.1004, 0.1096, 0.0932, 0.0950,
        0.0570], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,901][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0836, 0.0994, 0.0847, 0.1153, 0.1152, 0.0939, 0.1115, 0.0934, 0.0949,
        0.1082], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,905][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.0074, 0.0162, 0.0942, 0.0476, 0.1893, 0.1835, 0.2275, 0.0488, 0.1597,
        0.0257], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,909][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.1463, 0.0471, 0.1480, 0.0181, 0.1015, 0.1583, 0.0877, 0.1443, 0.1115,
        0.0372], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,910][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.1146, 0.0497, 0.2736, 0.0157, 0.2025, 0.1180, 0.0464, 0.0710, 0.0835,
        0.0250], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,910][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.0303, 0.1351, 0.1239, 0.1162, 0.1653, 0.0473, 0.0461, 0.1955, 0.0418,
        0.0985], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,910][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.0311, 0.1190, 0.0544, 0.1289, 0.1713, 0.0931, 0.0869, 0.1287, 0.0640,
        0.1227], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,911][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0331, 0.0774, 0.0372, 0.0745, 0.1069, 0.0859, 0.1381, 0.1452, 0.1116,
        0.1900], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:06,911][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2487, 0.0508, 0.0910, 0.0578, 0.0550, 0.1178, 0.1237, 0.0500, 0.0996,
        0.0465, 0.0591], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,912][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0098, 0.0436, 0.0800, 0.2173, 0.0759, 0.0405, 0.1813, 0.0664, 0.1036,
        0.1436, 0.0380], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,913][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([2.7042e-03, 4.0607e-01, 3.2467e-03, 3.3422e-01, 2.1072e-01, 4.4823e-04,
        6.7215e-03, 1.0230e-03, 9.0159e-05, 5.4423e-03, 2.9314e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,919][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0139, 0.0320, 0.0652, 0.3248, 0.0348, 0.0501, 0.0644, 0.0427, 0.0518,
        0.3078, 0.0124], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,923][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1594, 0.0763, 0.1026, 0.0680, 0.0916, 0.0932, 0.0997, 0.0928, 0.0849,
        0.0661, 0.0653], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,923][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0772, 0.0907, 0.0792, 0.1058, 0.1019, 0.0861, 0.0988, 0.0863, 0.0862,
        0.0975, 0.0903], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,924][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0130, 0.0213, 0.0922, 0.0509, 0.1662, 0.1430, 0.1639, 0.0478, 0.1213,
        0.0255, 0.1551], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,924][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1169, 0.0403, 0.0949, 0.0272, 0.0556, 0.1355, 0.0709, 0.2115, 0.1133,
        0.0606, 0.0733], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,925][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0510, 0.0240, 0.0945, 0.0147, 0.2846, 0.0768, 0.0251, 0.3389, 0.0681,
        0.0206, 0.0017], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,925][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0840, 0.0232, 0.1653, 0.0852, 0.1500, 0.1010, 0.1213, 0.0557, 0.1107,
        0.0737, 0.0300], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,926][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0327, 0.0821, 0.0538, 0.0760, 0.1828, 0.1021, 0.0750, 0.1173, 0.0694,
        0.0738, 0.1350], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,926][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0396, 0.0662, 0.0317, 0.0627, 0.0839, 0.0748, 0.1054, 0.1114, 0.0908,
        0.1423, 0.1911], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:06,929][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2046, 0.0459, 0.0762, 0.0705, 0.0523, 0.0954, 0.1130, 0.0475, 0.0852,
        0.0585, 0.0439, 0.1070], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,935][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0067, 0.0551, 0.0629, 0.2526, 0.0603, 0.0327, 0.1122, 0.0673, 0.0834,
        0.1729, 0.0510, 0.0430], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,937][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.4977e-04, 1.2929e-01, 2.3450e-03, 1.7470e-01, 5.6882e-01, 1.9251e-04,
        4.5423e-03, 2.7018e-03, 7.3640e-05, 3.0663e-03, 1.1126e-01, 2.7559e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,938][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0073, 0.0486, 0.0348, 0.3087, 0.0670, 0.0285, 0.0483, 0.0651, 0.0404,
        0.2971, 0.0379, 0.0163], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,938][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1381, 0.0727, 0.0900, 0.0665, 0.0846, 0.0799, 0.0898, 0.0831, 0.0791,
        0.0656, 0.0701, 0.0805], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,939][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0730, 0.0815, 0.0725, 0.0952, 0.0915, 0.0806, 0.0906, 0.0777, 0.0794,
        0.0867, 0.0826, 0.0886], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,939][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0045, 0.0169, 0.0729, 0.0473, 0.1665, 0.1489, 0.1495, 0.0445, 0.0938,
        0.0223, 0.1623, 0.0707], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,940][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0691, 0.0402, 0.0820, 0.0281, 0.0532, 0.1139, 0.0453, 0.2571, 0.0881,
        0.0591, 0.1222, 0.0418], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,943][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0356, 0.0347, 0.0935, 0.1103, 0.1829, 0.1048, 0.0058, 0.1715, 0.0728,
        0.1687, 0.0185, 0.0007], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,947][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0773, 0.0478, 0.0901, 0.0455, 0.1771, 0.0343, 0.0124, 0.2632, 0.0252,
        0.0459, 0.1720, 0.0092], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,951][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0278, 0.0928, 0.0498, 0.0833, 0.1394, 0.0822, 0.0747, 0.1124, 0.0592,
        0.0806, 0.1196, 0.0783], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,952][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0398, 0.0607, 0.0269, 0.0514, 0.0717, 0.0607, 0.0872, 0.0873, 0.0690,
        0.1139, 0.1528, 0.1787], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:06,952][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.2369, 0.0438, 0.0753, 0.0525, 0.0450, 0.0928, 0.1053, 0.0407, 0.0843,
        0.0416, 0.0389, 0.0841, 0.0588], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,952][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0068, 0.0438, 0.0625, 0.2560, 0.0719, 0.0276, 0.0977, 0.0632, 0.0735,
        0.1605, 0.0528, 0.0340, 0.0498], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,953][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([6.6956e-04, 6.7337e-02, 5.7235e-03, 1.3027e-01, 7.4904e-01, 3.3578e-04,
        5.1858e-03, 6.1475e-04, 2.7765e-05, 1.1561e-03, 2.9629e-02, 3.4573e-03,
        6.5589e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,953][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0083, 0.0401, 0.0330, 0.3229, 0.0166, 0.0299, 0.0809, 0.0297, 0.0286,
        0.3043, 0.0328, 0.0687, 0.0041], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,954][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.1338, 0.0783, 0.0889, 0.0639, 0.0774, 0.0857, 0.0745, 0.0858, 0.0736,
        0.0615, 0.0574, 0.0645, 0.0546], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,956][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0619, 0.0719, 0.0649, 0.0879, 0.0863, 0.0723, 0.0845, 0.0722, 0.0748,
        0.0814, 0.0817, 0.0831, 0.0771], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,961][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0110, 0.0164, 0.0757, 0.0392, 0.1458, 0.1421, 0.1616, 0.0302, 0.1135,
        0.0201, 0.1395, 0.0815, 0.0235], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,966][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.2163, 0.0413, 0.0532, 0.0296, 0.0418, 0.0815, 0.0370, 0.0838, 0.0897,
        0.0688, 0.0949, 0.0814, 0.0807], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,966][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0933, 0.0224, 0.0785, 0.0556, 0.3156, 0.1132, 0.0178, 0.1413, 0.0373,
        0.0590, 0.0531, 0.0093, 0.0036], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,966][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0433, 0.0667, 0.1151, 0.0589, 0.1401, 0.1158, 0.0568, 0.0660, 0.0697,
        0.0413, 0.0143, 0.0564, 0.1556], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,967][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0266, 0.0861, 0.0463, 0.0866, 0.1195, 0.0856, 0.0647, 0.1006, 0.0586,
        0.0805, 0.1050, 0.0633, 0.0766], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,967][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0370, 0.0538, 0.0184, 0.0398, 0.0612, 0.0489, 0.0698, 0.0673, 0.0528,
        0.0797, 0.1263, 0.1649, 0.1802], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:06,968][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1827, 0.0406, 0.0688, 0.0557, 0.0474, 0.0908, 0.0993, 0.0447, 0.0778,
        0.0467, 0.0421, 0.0844, 0.0431, 0.0762], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,971][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0060, 0.0407, 0.0565, 0.2330, 0.0536, 0.0248, 0.1164, 0.0504, 0.0796,
        0.1568, 0.0495, 0.0480, 0.0650, 0.0199], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,975][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([4.2693e-04, 7.5588e-02, 9.8720e-04, 1.2238e-01, 5.4486e-01, 1.7858e-05,
        4.4044e-03, 1.4320e-03, 3.7934e-05, 2.4594e-03, 1.6639e-01, 7.8817e-03,
        6.9053e-02, 4.0862e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,979][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0033, 0.0380, 0.0261, 0.3342, 0.0764, 0.0067, 0.0568, 0.0503, 0.0236,
        0.3057, 0.0348, 0.0290, 0.0101, 0.0050], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,980][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1209, 0.0573, 0.0807, 0.0527, 0.0759, 0.0725, 0.0760, 0.0674, 0.0695,
        0.0515, 0.0622, 0.0661, 0.0802, 0.0670], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,980][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0626, 0.0703, 0.0616, 0.0820, 0.0793, 0.0705, 0.0786, 0.0649, 0.0677,
        0.0731, 0.0722, 0.0773, 0.0722, 0.0676], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,981][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0070, 0.0150, 0.0665, 0.0392, 0.1483, 0.1245, 0.1325, 0.0417, 0.0852,
        0.0168, 0.1259, 0.0583, 0.0268, 0.1124], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,981][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0599, 0.0381, 0.0541, 0.0212, 0.0324, 0.0540, 0.0392, 0.1274, 0.0617,
        0.0461, 0.0832, 0.0690, 0.2582, 0.0555], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,982][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0345, 0.1401, 0.1273, 0.0235, 0.0528, 0.0034, 0.1145, 0.1846, 0.1395,
        0.0307, 0.0257, 0.0081, 0.1113, 0.0039], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,982][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0149, 0.0131, 0.0581, 0.0517, 0.2064, 0.0042, 0.0219, 0.1677, 0.0156,
        0.0582, 0.1071, 0.0190, 0.2572, 0.0047], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,985][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0259, 0.0714, 0.0438, 0.0675, 0.1033, 0.0914, 0.0565, 0.0916, 0.0566,
        0.0649, 0.1167, 0.0527, 0.0687, 0.0888], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:06,990][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0317, 0.0427, 0.0176, 0.0322, 0.0484, 0.0419, 0.0591, 0.0605, 0.0494,
        0.0757, 0.1099, 0.1343, 0.1580, 0.1387], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,023][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:07,024][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,024][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,024][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,025][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,025][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,026][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,026][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,027][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,030][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,032][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,045][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,049][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,053][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.3997, 0.6003], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,053][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.1344, 0.8656], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,054][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.4217, 0.5783], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,054][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([4.8023e-05, 9.9995e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,054][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.9959, 0.0041], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,055][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.4551, 0.5449], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,055][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([1.3624e-05, 9.9999e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,055][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.2020, 0.7980], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,059][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.4270, 0.5730], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,065][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.5733, 0.4267], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,067][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.7274, 0.2726], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,067][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.2304, 0.7696], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,067][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3182, 0.1164, 0.5654], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,068][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0569, 0.7061, 0.2370], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,068][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0022, 0.9854, 0.0124], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,069][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([8.8742e-10, 9.9958e-01, 4.2388e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,069][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.8667, 0.0696, 0.0637], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,069][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3510, 0.2459, 0.4031], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,070][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.2359e-09, 1.1803e-07, 1.0000e+00], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,071][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([4.1755e-04, 9.6203e-01, 3.7554e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,075][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0067, 0.9085, 0.0849], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,081][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0443, 0.8568, 0.0989], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,081][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5051, 0.1444, 0.3505], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,082][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0821, 0.2887, 0.6291], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,082][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.1906, 0.0731, 0.3324, 0.4038], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,082][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.0298, 0.1929, 0.1988, 0.5785], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,083][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0189, 0.6679, 0.0606, 0.2526], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,083][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([5.7732e-07, 2.8452e-05, 5.5638e-09, 9.9997e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,084][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.8308, 0.0784, 0.0770, 0.0137], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,087][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0677, 0.1067, 0.2118, 0.6138], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,091][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([1.9477e-07, 1.1361e-10, 7.6169e-04, 9.9924e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,095][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0023, 0.8093, 0.0730, 0.1154], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,095][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0251, 0.4830, 0.1823, 0.3096], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,095][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.0768, 0.2664, 0.1813, 0.4754], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,096][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.2904, 0.1449, 0.2836, 0.2811], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,096][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0121, 0.1195, 0.2721, 0.5963], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,097][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.2687, 0.1095, 0.2825, 0.0967, 0.2427], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,097][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0169, 0.0958, 0.1183, 0.6960, 0.0731], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,097][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0263, 0.5713, 0.0107, 0.1922, 0.1995], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,098][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([2.0419e-10, 2.9371e-06, 7.0541e-09, 9.4258e-01, 5.7414e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,101][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.8764, 0.0455, 0.0178, 0.0275, 0.0327], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,105][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0808, 0.0731, 0.1285, 0.3868, 0.3308], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,109][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([8.0028e-10, 1.4933e-11, 4.1048e-04, 7.9201e-01, 2.0758e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,109][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0028, 0.1318, 0.0097, 0.1953, 0.6604], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,110][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0307, 0.3239, 0.0584, 0.0782, 0.5087], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,110][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1480, 0.1528, 0.1279, 0.1100, 0.4613], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,111][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.2657, 0.1404, 0.2170, 0.2505, 0.1264], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,111][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0084, 0.0952, 0.2557, 0.4427, 0.1980], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,111][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1625, 0.0643, 0.1742, 0.0566, 0.0895, 0.4529], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,112][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0138, 0.1319, 0.0799, 0.6868, 0.0775, 0.0101], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,115][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.8203e-04, 1.8480e-01, 4.5105e-03, 1.1027e-01, 6.9968e-01, 5.5182e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,119][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.0859e-15, 3.8286e-06, 1.5086e-09, 9.1732e-01, 8.2673e-02, 5.5435e-10],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,123][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.8639, 0.0369, 0.0133, 0.0173, 0.0328, 0.0359], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,123][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0641, 0.0647, 0.1059, 0.3289, 0.3556, 0.0808], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,124][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([7.6769e-15, 1.5269e-09, 3.0159e-03, 3.3036e-01, 6.6662e-01, 2.6633e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,124][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.2117e-05, 1.0968e-01, 3.1706e-03, 1.3600e-01, 7.5052e-01, 6.1043e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,124][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([3.4791e-04, 1.7014e-01, 2.4402e-02, 4.7772e-02, 7.5421e-01, 3.1275e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,125][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0021, 0.0971, 0.0252, 0.0680, 0.8059, 0.0017], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,125][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3031, 0.0981, 0.2103, 0.1358, 0.0901, 0.1626], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,125][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0011, 0.0499, 0.1142, 0.5200, 0.2851, 0.0297], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,126][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1134, 0.0416, 0.1684, 0.0800, 0.0633, 0.2911, 0.2422],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,129][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0069, 0.1596, 0.0598, 0.6411, 0.0744, 0.0086, 0.0495],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,133][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.8035e-04, 1.1217e-01, 5.4645e-03, 1.1383e-01, 7.6566e-01, 9.1528e-04,
        1.7727e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,135][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.3195e-14, 7.4423e-07, 2.6595e-10, 9.8978e-01, 1.0216e-02, 3.2571e-12,
        1.2142e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,137][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.8384, 0.0311, 0.0167, 0.0305, 0.0276, 0.0298, 0.0260],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,138][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0534, 0.0489, 0.0835, 0.3314, 0.2770, 0.0542, 0.1516],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,138][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.4868e-13, 6.9802e-11, 9.2955e-04, 5.8140e-01, 4.1744e-01, 1.3139e-07,
        2.2274e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,138][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([6.9843e-06, 4.2912e-02, 2.7719e-03, 1.4806e-01, 8.0542e-01, 1.8811e-04,
        6.4690e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,139][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([2.4965e-04, 1.0456e-01, 1.9142e-02, 1.2023e-01, 7.5062e-01, 2.0959e-03,
        3.1087e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,139][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0022, 0.1690, 0.0373, 0.1938, 0.5872, 0.0036, 0.0070],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,139][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1552, 0.0882, 0.1552, 0.1500, 0.1085, 0.0595, 0.2834],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,143][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0023, 0.1228, 0.1623, 0.4312, 0.1756, 0.0409, 0.0649],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,149][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.1037, 0.0301, 0.1449, 0.0338, 0.0391, 0.3587, 0.1604, 0.1293],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,151][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0150, 0.1113, 0.1062, 0.5290, 0.0801, 0.0157, 0.1188, 0.0238],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,151][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([8.4373e-05, 1.3074e-01, 6.1549e-03, 1.8255e-01, 6.7098e-01, 1.0084e-03,
        7.7000e-03, 7.8426e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,151][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([3.5095e-12, 4.6644e-06, 3.5436e-09, 9.3909e-01, 6.0876e-02, 1.1373e-10,
        2.6059e-05, 7.6917e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,152][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.6697, 0.0231, 0.0243, 0.0637, 0.1328, 0.0429, 0.0389, 0.0046],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,152][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0326, 0.0438, 0.0826, 0.2454, 0.2130, 0.0401, 0.1349, 0.2076],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,153][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([5.6364e-13, 4.8395e-10, 2.4428e-03, 3.4438e-01, 6.5221e-01, 8.6293e-07,
        9.4910e-04, 1.7817e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,153][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([2.7124e-06, 1.8901e-02, 3.7015e-03, 1.2630e-01, 8.4922e-01, 2.1480e-04,
        1.6192e-03, 4.6328e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,153][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([8.2774e-05, 6.3789e-02, 1.0598e-02, 9.2358e-02, 8.2887e-01, 1.2823e-03,
        2.7850e-03, 2.3642e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,157][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0014, 0.0664, 0.0396, 0.1677, 0.7024, 0.0068, 0.0122, 0.0036],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,161][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.2168, 0.0556, 0.1729, 0.1267, 0.0703, 0.0740, 0.1876, 0.0961],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,165][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0042, 0.0963, 0.1652, 0.3631, 0.1543, 0.0427, 0.0537, 0.1204],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,165][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0965, 0.0343, 0.1539, 0.0444, 0.0505, 0.2484, 0.1427, 0.0663, 0.1630],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,166][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0089, 0.1103, 0.0551, 0.6693, 0.0435, 0.0075, 0.0634, 0.0187, 0.0233],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,166][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([6.3657e-06, 1.1384e-01, 5.4798e-03, 2.3281e-01, 6.3166e-01, 5.6923e-04,
        1.3831e-02, 1.7419e-03, 6.0966e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,167][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([2.3074e-19, 1.6937e-07, 2.2375e-10, 9.8788e-01, 1.2041e-02, 2.2931e-12,
        7.0211e-05, 4.0059e-06, 2.1006e-14], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,167][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5316, 0.0561, 0.0343, 0.0971, 0.0626, 0.0452, 0.0287, 0.0098, 0.1346],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,167][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0348, 0.0339, 0.0603, 0.2223, 0.2035, 0.0375, 0.1145, 0.2024, 0.0908],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,169][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([7.2853e-19, 5.7200e-10, 4.1593e-03, 2.8349e-01, 7.1081e-01, 2.8779e-07,
        1.5302e-03, 7.3368e-06, 6.1311e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,172][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([3.8491e-07, 2.9296e-02, 1.8816e-03, 1.5727e-01, 8.0670e-01, 1.3554e-04,
        3.2813e-03, 1.4088e-03, 2.7570e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,175][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([1.3595e-05, 2.9598e-02, 9.9720e-03, 6.0320e-02, 8.8890e-01, 1.0841e-03,
        8.1443e-03, 1.7418e-03, 2.3099e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,179][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0005, 0.2367, 0.0312, 0.3285, 0.3751, 0.0039, 0.0162, 0.0067, 0.0012],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,179][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1422, 0.0529, 0.1908, 0.0776, 0.0420, 0.0598, 0.2031, 0.0545, 0.1770],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,180][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0007, 0.1010, 0.1332, 0.3335, 0.1572, 0.0454, 0.0837, 0.1187, 0.0267],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,180][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.0615, 0.0254, 0.1081, 0.1519, 0.0365, 0.1677, 0.1188, 0.0318, 0.1185,
        0.1798], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,180][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.0145, 0.1004, 0.0972, 0.2880, 0.0829, 0.0150, 0.0957, 0.0392, 0.0563,
        0.2109], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,181][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([6.3907e-05, 8.9709e-02, 1.3999e-02, 1.7377e-01, 7.1298e-01, 4.0294e-04,
        7.4115e-03, 6.4396e-04, 7.2695e-05, 9.4013e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,181][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([4.9188e-14, 1.6300e-06, 1.0780e-09, 9.8656e-01, 1.3421e-02, 3.8626e-12,
        1.6669e-05, 1.6603e-06, 2.9355e-13, 1.1033e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,182][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.3460, 0.1446, 0.0915, 0.0205, 0.0723, 0.0932, 0.0687, 0.0063, 0.1262,
        0.0306], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,185][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0300, 0.0358, 0.0662, 0.1782, 0.1760, 0.0333, 0.1095, 0.1517, 0.0815,
        0.1378], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,187][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([9.8039e-10, 1.3235e-08, 7.1679e-03, 4.7205e-01, 5.0633e-01, 4.8481e-06,
        1.5137e-03, 6.2181e-05, 1.1432e-08, 1.2878e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,191][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([1.3026e-06, 1.3624e-02, 1.7569e-03, 1.0024e-02, 9.7334e-01, 7.2344e-05,
        8.9834e-04, 2.5625e-04, 7.7774e-06, 2.2170e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,193][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([4.6695e-05, 2.8205e-02, 1.2821e-02, 5.0652e-02, 9.0292e-01, 6.2163e-04,
        2.6026e-03, 1.4639e-03, 1.0124e-04, 5.6148e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,194][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.0030, 0.0813, 0.0866, 0.3110, 0.4591, 0.0075, 0.0267, 0.0096, 0.0029,
        0.0123], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,194][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.1154, 0.0566, 0.1094, 0.1069, 0.0618, 0.0429, 0.2011, 0.0658, 0.1039,
        0.1363], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,194][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0025, 0.0528, 0.0977, 0.2776, 0.1105, 0.0215, 0.0343, 0.1198, 0.0113,
        0.2722], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,195][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0953, 0.0405, 0.1123, 0.0221, 0.0497, 0.2669, 0.1021, 0.0413, 0.1272,
        0.0229, 0.1198], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,195][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0121, 0.0677, 0.0718, 0.3214, 0.0725, 0.0138, 0.1296, 0.0220, 0.0485,
        0.2242, 0.0164], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,196][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([2.7042e-03, 4.0607e-01, 3.2467e-03, 3.3422e-01, 2.1072e-01, 4.4823e-04,
        6.7215e-03, 1.0230e-03, 9.0159e-05, 5.4423e-03, 2.9314e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,197][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.0251e-13, 3.4045e-06, 5.3387e-10, 9.8126e-01, 1.8594e-02, 2.8741e-11,
        1.0459e-04, 4.2557e-05, 7.0569e-12, 2.0817e-08, 9.8410e-08],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,203][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.5652, 0.0502, 0.0279, 0.0376, 0.0779, 0.0443, 0.0315, 0.0135, 0.0733,
        0.0318, 0.0467], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,207][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0371, 0.0325, 0.0527, 0.1635, 0.1502, 0.0296, 0.0821, 0.1502, 0.0655,
        0.1281, 0.1084], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,209][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([3.5287e-15, 7.5760e-10, 2.3854e-03, 4.2493e-01, 5.6829e-01, 2.6912e-07,
        6.5529e-04, 1.2418e-05, 1.0927e-09, 3.7254e-03, 2.9981e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,209][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([2.6446e-04, 3.1065e-02, 1.9250e-03, 1.3337e-01, 8.2275e-01, 6.6251e-05,
        1.2414e-03, 6.9766e-04, 6.0177e-05, 7.7119e-04, 7.7887e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,210][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.5688e-03, 8.5469e-02, 1.1977e-02, 3.6759e-02, 8.4119e-01, 8.3841e-04,
        4.2842e-03, 1.9111e-03, 4.1607e-04, 8.7806e-04, 1.4710e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,210][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0197, 0.0989, 0.0496, 0.0991, 0.6400, 0.0049, 0.0194, 0.0050, 0.0062,
        0.0069, 0.0502], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,211][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1124, 0.0447, 0.1170, 0.0674, 0.0725, 0.0706, 0.1500, 0.0758, 0.1275,
        0.0877, 0.0745], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,211][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0021, 0.0733, 0.0973, 0.2625, 0.0961, 0.0167, 0.0358, 0.0841, 0.0196,
        0.2404, 0.0722], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,211][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0643, 0.0297, 0.0892, 0.0566, 0.0394, 0.1736, 0.1118, 0.0453, 0.0980,
        0.0640, 0.0425, 0.1857], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,212][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0050, 0.0967, 0.0417, 0.4003, 0.0420, 0.0086, 0.0427, 0.0251, 0.0258,
        0.2691, 0.0305, 0.0125], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,213][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.4977e-04, 1.2929e-01, 2.3450e-03, 1.7470e-01, 5.6882e-01, 1.9251e-04,
        4.5423e-03, 2.7018e-03, 7.3640e-05, 3.0663e-03, 1.1126e-01, 2.7559e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,217][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.8992e-15, 7.7458e-07, 4.5555e-11, 9.5314e-01, 4.6837e-02, 5.4007e-13,
        2.0264e-05, 6.5322e-06, 4.4778e-14, 5.1698e-10, 1.1772e-08, 1.0280e-08],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,222][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4215, 0.0879, 0.0272, 0.0584, 0.0533, 0.0462, 0.0328, 0.0134, 0.0806,
        0.0575, 0.0648, 0.0565], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,223][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0273, 0.0262, 0.0440, 0.1555, 0.1346, 0.0282, 0.0746, 0.1370, 0.0614,
        0.1294, 0.1065, 0.0752], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,224][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.4554e-15, 4.3185e-09, 5.1165e-03, 3.8805e-01, 6.0236e-01, 5.7311e-07,
        9.2086e-04, 1.3065e-05, 1.5666e-09, 3.5377e-03, 8.2621e-07, 3.5654e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,224][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.5255e-05, 2.6049e-02, 9.1508e-04, 1.1498e-01, 8.0441e-01, 4.2780e-05,
        9.3467e-04, 8.1909e-04, 1.9654e-05, 9.5395e-04, 4.9573e-02, 1.2842e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,224][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.2209e-04, 4.6851e-02, 5.7048e-03, 8.6252e-02, 7.9123e-01, 4.1073e-04,
        1.7692e-03, 1.2648e-03, 1.7635e-04, 2.4450e-03, 5.6345e-02, 7.3274e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,225][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0015, 0.0655, 0.0154, 0.0801, 0.4423, 0.0014, 0.0054, 0.0062, 0.0008,
        0.0056, 0.3650, 0.0108], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,225][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0974, 0.0530, 0.1086, 0.0733, 0.0569, 0.0450, 0.1623, 0.0620, 0.0906,
        0.0933, 0.0597, 0.0980], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,226][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0003, 0.0804, 0.0815, 0.2291, 0.0995, 0.0146, 0.0388, 0.0833, 0.0146,
        0.2450, 0.0951, 0.0178], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,227][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0861, 0.0265, 0.0946, 0.0237, 0.0352, 0.1809, 0.0880, 0.0298, 0.1008,
        0.0253, 0.0387, 0.0847, 0.1858], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,233][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0081, 0.0684, 0.0490, 0.4054, 0.0771, 0.0075, 0.0377, 0.0194, 0.0230,
        0.2479, 0.0306, 0.0097, 0.0164], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,236][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([6.6956e-04, 6.7337e-02, 5.7235e-03, 1.3027e-01, 7.4904e-01, 3.3578e-04,
        5.1858e-03, 6.1475e-04, 2.7765e-05, 1.1561e-03, 2.9629e-02, 3.4573e-03,
        6.5589e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,238][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([7.3191e-12, 1.0272e-06, 9.7776e-10, 9.4743e-01, 5.2563e-02, 2.3935e-12,
        6.8584e-06, 1.2620e-06, 1.8168e-14, 1.5759e-10, 1.1594e-09, 4.3124e-10,
        9.2872e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,238][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.3705, 0.0864, 0.0480, 0.0476, 0.0586, 0.0781, 0.0351, 0.0185, 0.0629,
        0.0414, 0.0878, 0.0630, 0.0022], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,238][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0139, 0.0240, 0.0409, 0.1379, 0.1259, 0.0221, 0.0757, 0.1092, 0.0538,
        0.1054, 0.1100, 0.0745, 0.1068], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,239][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([1.2531e-09, 1.6248e-08, 6.4471e-03, 4.6871e-01, 5.0666e-01, 9.5800e-06,
        2.0348e-03, 1.4408e-04, 5.0579e-08, 1.5254e-02, 1.0223e-05, 6.2188e-06,
        7.2383e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,239][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([2.9071e-05, 1.8742e-02, 2.9133e-03, 1.2049e-01, 8.4061e-01, 4.7066e-05,
        1.2226e-03, 3.8513e-04, 8.7444e-06, 2.2637e-04, 1.1931e-02, 4.1681e-04,
        2.9774e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,240][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([2.3296e-04, 1.9728e-02, 3.9788e-03, 4.1911e-02, 9.1902e-01, 2.1618e-04,
        7.3933e-04, 4.7909e-04, 2.5905e-05, 4.4846e-04, 1.0963e-02, 8.4782e-04,
        1.4075e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,240][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0066, 0.0509, 0.0352, 0.1690, 0.6190, 0.0034, 0.0138, 0.0072, 0.0010,
        0.0058, 0.0567, 0.0105, 0.0209], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,243][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.1047, 0.0396, 0.0951, 0.0666, 0.0302, 0.0345, 0.1245, 0.0718, 0.0946,
        0.0829, 0.0484, 0.0692, 0.1378], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,248][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0021, 0.1742, 0.1398, 0.2144, 0.0908, 0.0124, 0.0188, 0.0732, 0.0123,
        0.1610, 0.0441, 0.0074, 0.0495], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,252][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0641, 0.0253, 0.0747, 0.0241, 0.0361, 0.1874, 0.0808, 0.0514, 0.0889,
        0.0268, 0.0465, 0.0773, 0.0560, 0.1605], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,252][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0067, 0.0729, 0.0446, 0.3975, 0.0399, 0.0053, 0.0554, 0.0153, 0.0267,
        0.2451, 0.0314, 0.0181, 0.0385, 0.0026], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,253][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.2693e-04, 7.5588e-02, 9.8720e-04, 1.2238e-01, 5.4486e-01, 1.7858e-05,
        4.4044e-03, 1.4320e-03, 3.7934e-05, 2.4594e-03, 1.6639e-01, 7.8817e-03,
        6.9053e-02, 4.0862e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,253][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([4.1243e-14, 4.2635e-07, 1.8827e-10, 8.7292e-01, 1.2700e-01, 4.1379e-13,
        5.6792e-05, 1.6832e-05, 2.9338e-14, 2.2986e-10, 5.8784e-09, 8.8930e-09,
        2.8071e-06, 4.3642e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,254][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.4318, 0.0721, 0.0236, 0.0362, 0.0666, 0.0554, 0.0279, 0.0081, 0.0528,
        0.0348, 0.0969, 0.0455, 0.0153, 0.0329], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,254][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0279, 0.0239, 0.0425, 0.1138, 0.1290, 0.0283, 0.0689, 0.1032, 0.0553,
        0.0920, 0.0870, 0.0655, 0.1308, 0.0321], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,254][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.6411e-15, 3.8183e-09, 4.2683e-03, 2.0215e-01, 7.8804e-01, 6.2911e-07,
        1.5084e-03, 2.2847e-05, 3.8456e-09, 3.9230e-03, 1.1790e-06, 8.0940e-07,
        7.8500e-05, 8.2371e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,256][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.7402e-05, 3.5863e-02, 8.2785e-04, 1.2992e-01, 6.6072e-01, 1.6315e-05,
        1.1875e-03, 8.0259e-04, 1.5768e-05, 9.3068e-04, 6.3708e-02, 3.1015e-03,
        9.6340e-02, 6.5199e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,258][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([6.6690e-04, 9.8237e-02, 6.6960e-03, 5.2259e-02, 7.0352e-01, 1.4721e-04,
        4.5521e-03, 1.0522e-03, 2.2070e-04, 1.1913e-03, 6.4318e-02, 1.1447e-02,
        3.6329e-02, 1.9358e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,262][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.7018e-03, 3.7693e-02, 8.5815e-03, 6.7541e-02, 5.7736e-01, 2.1822e-04,
        5.9498e-03, 1.9928e-03, 6.6375e-04, 5.0578e-03, 2.5350e-01, 1.6692e-02,
        1.9201e-02, 3.8450e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,266][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1098, 0.0380, 0.0849, 0.0615, 0.0335, 0.0602, 0.0916, 0.0562, 0.0961,
        0.0801, 0.0630, 0.0479, 0.1080, 0.0691], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,266][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0002, 0.0304, 0.0489, 0.2211, 0.1255, 0.0024, 0.0342, 0.0578, 0.0083,
        0.1811, 0.0737, 0.0117, 0.1739, 0.0306], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,268][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:07,269][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14666],
        [ 3063],
        [14852],
        [ 8367],
        [ 6996],
        [ 7195],
        [18675],
        [ 8110],
        [ 8597],
        [12080],
        [ 6079],
        [12600],
        [17830],
        [10888]], device='cuda:0')
[2024-07-24 10:30:07,270][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14560],
        [ 2313],
        [24962],
        [ 9464],
        [10690],
        [ 6824],
        [18980],
        [ 7184],
        [ 6303],
        [ 8340],
        [ 3797],
        [ 6511],
        [10778],
        [ 7365]], device='cuda:0')
[2024-07-24 10:30:07,273][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[12517],
        [11085],
        [10900],
        [10619],
        [11084],
        [10721],
        [10247],
        [10521],
        [10638],
        [10355],
        [10555],
        [10436],
        [10588],
        [10396]], device='cuda:0')
[2024-07-24 10:30:07,275][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[12075],
        [ 7810],
        [12011],
        [ 6600],
        [ 7023],
        [ 7176],
        [ 9323],
        [10721],
        [10296],
        [10466],
        [11356],
        [ 9933],
        [10089],
        [10803]], device='cuda:0')
[2024-07-24 10:30:07,278][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[44795],
        [38286],
        [32535],
        [34530],
        [34453],
        [33123],
        [32836],
        [33425],
        [33686],
        [33297],
        [34845],
        [34235],
        [33073],
        [34146]], device='cuda:0')
[2024-07-24 10:30:07,280][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[13119],
        [21268],
        [24323],
        [20997],
        [19971],
        [18453],
        [19982],
        [20810],
        [20481],
        [20650],
        [20640],
        [19575],
        [20819],
        [19048]], device='cuda:0')
[2024-07-24 10:30:07,283][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[15825],
        [14417],
        [12345],
        [11514],
        [ 9333],
        [ 9089],
        [ 8662],
        [ 7379],
        [ 7598],
        [ 7679],
        [ 7250],
        [ 7155],
        [ 6862],
        [ 6789]], device='cuda:0')
[2024-07-24 10:30:07,284][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[29163],
        [26797],
        [25057],
        [23547],
        [22522],
        [24390],
        [24716],
        [25579],
        [25083],
        [24469],
        [23109],
        [23036],
        [23485],
        [24268]], device='cuda:0')
[2024-07-24 10:30:07,285][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[34537],
        [45975],
        [45745],
        [46406],
        [46595],
        [46453],
        [46514],
        [46582],
        [46563],
        [46494],
        [46746],
        [46780],
        [46769],
        [46678]], device='cuda:0')
[2024-07-24 10:30:07,286][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[17870],
        [12630],
        [ 7720],
        [ 5727],
        [ 4700],
        [ 4168],
        [ 3570],
        [ 6925],
        [ 3543],
        [ 3568],
        [ 2421],
        [ 2008],
        [ 2691],
        [ 1762]], device='cuda:0')
[2024-07-24 10:30:07,287][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 5563],
        [ 5425],
        [ 7134],
        [22051],
        [13257],
        [17454],
        [16269],
        [14978],
        [16256],
        [20192],
        [24661],
        [27236],
        [18591],
        [21823]], device='cuda:0')
[2024-07-24 10:30:07,289][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[43271],
        [29142],
        [28081],
        [24995],
        [31932],
        [24592],
        [29280],
        [26505],
        [26824],
        [25591],
        [31191],
        [32310],
        [31215],
        [32002]], device='cuda:0')
[2024-07-24 10:30:07,292][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[48559],
        [37135],
        [39671],
        [38194],
        [41223],
        [43999],
        [43853],
        [43065],
        [43617],
        [42565],
        [43871],
        [44214],
        [44055],
        [45096]], device='cuda:0')
[2024-07-24 10:30:07,295][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[1148],
        [1878],
        [1941],
        [2668],
        [2267],
        [2307],
        [2105],
        [2293],
        [2237],
        [2435],
        [2214],
        [2000],
        [2339],
        [2574]], device='cuda:0')
[2024-07-24 10:30:07,297][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[29628],
        [ 8790],
        [ 1988],
        [ 6415],
        [ 2441],
        [ 5055],
        [16711],
        [ 5435],
        [20002],
        [23980],
        [15386],
        [26689],
        [27380],
        [16424]], device='cuda:0')
[2024-07-24 10:30:07,300][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23458],
        [19516],
        [23374],
        [20887],
        [20377],
        [19810],
        [19716],
        [18887],
        [19521],
        [18463],
        [20157],
        [18649],
        [18056],
        [19185]], device='cuda:0')
[2024-07-24 10:30:07,300][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[35422],
        [37421],
        [32865],
        [29789],
        [30237],
        [31020],
        [31718],
        [30799],
        [31667],
        [30094],
        [30141],
        [31487],
        [30953],
        [31209]], device='cuda:0')
[2024-07-24 10:30:07,301][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[9735],
        [3333],
        [2660],
        [3643],
        [4142],
        [5188],
        [5453],
        [5944],
        [6450],
        [6045],
        [5235],
        [5819],
        [5742],
        [6017]], device='cuda:0')
[2024-07-24 10:30:07,302][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[25892],
        [12826],
        [12827],
        [16369],
        [14555],
        [13757],
        [16030],
        [14434],
        [15963],
        [15907],
        [15737],
        [14879],
        [14704],
        [12358]], device='cuda:0')
[2024-07-24 10:30:07,304][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 3272],
        [ 3256],
        [ 3341],
        [ 3451],
        [ 3475],
        [ 3974],
        [ 4119],
        [ 8443],
        [ 9049],
        [12330],
        [10822],
        [12556],
        [15161],
        [16111]], device='cuda:0')
[2024-07-24 10:30:07,306][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[29190],
        [25950],
        [28077],
        [28483],
        [28008],
        [28078],
        [27520],
        [28149],
        [27776],
        [27728],
        [27910],
        [27489],
        [27045],
        [27217]], device='cuda:0')
[2024-07-24 10:30:07,309][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[29706],
        [12826],
        [29451],
        [12432],
        [18474],
        [19695],
        [20747],
        [19707],
        [19817],
        [20339],
        [19876],
        [19839],
        [20379],
        [20092]], device='cuda:0')
[2024-07-24 10:30:07,311][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[26245],
        [19140],
        [16895],
        [19294],
        [16032],
        [14882],
        [14600],
        [14141],
        [14708],
        [12750],
        [14391],
        [14473],
        [14147],
        [13999]], device='cuda:0')
[2024-07-24 10:30:07,314][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[32958],
        [20015],
        [14198],
        [10860],
        [20095],
        [24875],
        [24640],
        [25230],
        [24979],
        [24716],
        [25731],
        [26699],
        [24866],
        [27475]], device='cuda:0')
[2024-07-24 10:30:07,316][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26294],
        [17512],
        [ 8307],
        [ 6120],
        [ 4813],
        [ 3311],
        [ 3804],
        [ 3388],
        [ 4290],
        [ 3927],
        [ 3506],
        [ 5119],
        [ 3438],
        [ 4058]], device='cuda:0')
[2024-07-24 10:30:07,317][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[34870],
        [37199],
        [38825],
        [32945],
        [34382],
        [34109],
        [35530],
        [35899],
        [36519],
        [34003],
        [34718],
        [33188],
        [31536],
        [30454]], device='cuda:0')
[2024-07-24 10:30:07,318][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10245],
        [35568],
        [40140],
        [42024],
        [41857],
        [42055],
        [41630],
        [41923],
        [41904],
        [42382],
        [42506],
        [42536],
        [42006],
        [41743]], device='cuda:0')
[2024-07-24 10:30:07,319][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[21419],
        [31107],
        [31849],
        [34918],
        [34168],
        [33147],
        [32333],
        [30715],
        [29007],
        [29435],
        [29944],
        [28190],
        [29147],
        [28609]], device='cuda:0')
[2024-07-24 10:30:07,320][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 7047],
        [31951],
        [36523],
        [30138],
        [29478],
        [36162],
        [27541],
        [35175],
        [29492],
        [28816],
        [28814],
        [28127],
        [33678],
        [31972]], device='cuda:0')
[2024-07-24 10:30:07,323][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[5137],
        [5137],
        [5137],
        [5137],
        [5137],
        [5137],
        [5137],
        [5137],
        [5137],
        [5137],
        [5137],
        [5137],
        [5137],
        [5137]], device='cuda:0')
[2024-07-24 10:30:07,359][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:07,359][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,359][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,360][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,361][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,361][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,361][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,362][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,362][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,362][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,363][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,363][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,363][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,364][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.4774, 0.5226], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,364][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.7319, 0.2681], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,364][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.3430, 0.6570], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,365][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.3790, 0.6210], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,365][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.9513, 0.0487], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,365][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.0931, 0.9069], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,366][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.6274, 0.3726], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,366][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.3344, 0.6656], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,366][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.6300, 0.3700], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,367][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.5051, 0.4949], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,367][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.4541, 0.5459], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,367][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([9.9982e-01, 1.8453e-04], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,368][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2894, 0.3680, 0.3426], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,370][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.6745, 0.2300, 0.0955], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,371][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7451, 0.1340, 0.1209], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,371][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0034, 0.9303, 0.0663], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,371][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8181, 0.0531, 0.1288], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,372][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0018, 0.9703, 0.0280], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,372][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4223, 0.4563, 0.1214], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,373][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0327, 0.0734, 0.8939], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,373][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6982, 0.2254, 0.0764], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,373][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2341, 0.4367, 0.3292], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,374][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2748, 0.2889, 0.4363], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,374][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([2.8330e-10, 1.0000e+00, 1.2675e-09], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,374][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.2163, 0.2448, 0.2819, 0.2570], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,377][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.5792, 0.2020, 0.0953, 0.1235], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,381][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.2480, 0.5348, 0.0655, 0.1517], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,383][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0481, 0.6073, 0.1269, 0.2176], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,384][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.6781, 0.0541, 0.0896, 0.1782], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,384][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0030, 0.0718, 0.0048, 0.9204], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,384][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.3442, 0.3152, 0.1775, 0.1632], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,385][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0149, 0.0449, 0.5837, 0.3565], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,385][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.6232, 0.2177, 0.0581, 0.1010], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,385][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.1337, 0.2282, 0.2031, 0.4350], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,386][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.2126, 0.2435, 0.0258, 0.5182], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,386][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([2.9315e-04, 9.9967e-01, 3.3099e-06, 3.5029e-05], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,389][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.1686, 0.1973, 0.2317, 0.2214, 0.1810], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,394][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.4572, 0.2271, 0.1152, 0.1424, 0.0581], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,397][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.3313, 0.4766, 0.1307, 0.0543, 0.0071], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,398][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0024, 0.5592, 0.0208, 0.1219, 0.2957], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,398][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.6078, 0.0446, 0.0871, 0.1498, 0.1106], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,398][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0029, 0.0478, 0.0012, 0.2957, 0.6525], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,399][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2441, 0.2957, 0.1209, 0.2794, 0.0599], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,399][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0381, 0.0427, 0.5415, 0.2253, 0.1524], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,399][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.6340, 0.1271, 0.0319, 0.0630, 0.1440], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,400][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.1283, 0.1905, 0.1996, 0.2930, 0.1886], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,400][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0583, 0.0250, 0.0280, 0.2851, 0.6036], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,401][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ went] are: tensor([8.7514e-06, 9.2232e-01, 1.0431e-08, 3.6737e-05, 7.7634e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,406][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1299, 0.1815, 0.1674, 0.1914, 0.1839, 0.1459], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,411][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.4959, 0.2010, 0.0720, 0.1104, 0.0496, 0.0712], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,412][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.6385, 0.0773, 0.0636, 0.0116, 0.0115, 0.1974], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,412][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0009, 0.3306, 0.0111, 0.1304, 0.5217, 0.0053], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,412][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.7113, 0.0309, 0.0661, 0.0930, 0.0725, 0.0263], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,413][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.4326e-07, 4.1886e-03, 5.9754e-05, 3.4860e-02, 9.6081e-01, 7.8388e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,413][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.3358, 0.1937, 0.0777, 0.2505, 0.0649, 0.0773], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,414][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0208, 0.0297, 0.5177, 0.1754, 0.1388, 0.1174], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,414][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5818, 0.1326, 0.0436, 0.0674, 0.1264, 0.0482], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,414][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0734, 0.1550, 0.1408, 0.3142, 0.2064, 0.1101], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,418][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0974, 0.0888, 0.1565, 0.1077, 0.3776, 0.1720], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,421][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.9440e-13, 5.0136e-03, 3.5624e-13, 1.8834e-08, 9.9499e-01, 3.1857e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,425][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1113, 0.1501, 0.1467, 0.1533, 0.1487, 0.1424, 0.1476],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,426][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.4643, 0.1928, 0.0586, 0.1195, 0.0489, 0.0433, 0.0726],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,426][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.6320, 0.1503, 0.0450, 0.0055, 0.0124, 0.1411, 0.0137],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,427][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0016, 0.2321, 0.0140, 0.1170, 0.6272, 0.0028, 0.0052],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,427][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.6464, 0.0319, 0.0646, 0.1060, 0.0687, 0.0231, 0.0593],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,427][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([5.0859e-06, 5.9655e-03, 1.5347e-04, 7.6577e-02, 9.1691e-01, 8.4832e-05,
        3.0614e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,428][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.2342, 0.2168, 0.0716, 0.2503, 0.0733, 0.0802, 0.0736],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,428][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0421, 0.0286, 0.3800, 0.1576, 0.1213, 0.0696, 0.2008],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,430][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.5866, 0.1345, 0.0392, 0.0574, 0.1029, 0.0419, 0.0375],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,435][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0686, 0.1354, 0.1224, 0.2460, 0.1628, 0.1071, 0.1577],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,439][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0725, 0.1079, 0.0228, 0.1974, 0.5440, 0.0176, 0.0377],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,440][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([6.1782e-10, 1.3569e-02, 2.0805e-09, 2.0688e-05, 9.8641e-01, 4.1294e-09,
        1.4926e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,440][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0943, 0.1206, 0.1330, 0.1347, 0.1155, 0.1216, 0.1364, 0.1440],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,441][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.3307, 0.1953, 0.0829, 0.1072, 0.0733, 0.0823, 0.1053, 0.0229],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,441][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.2125, 0.3188, 0.1087, 0.0375, 0.0256, 0.1249, 0.0403, 0.1317],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,441][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0020, 0.3518, 0.0103, 0.2161, 0.4070, 0.0012, 0.0069, 0.0047],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,442][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.4665, 0.0354, 0.0737, 0.1165, 0.0861, 0.0277, 0.0702, 0.1239],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,442][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ station] are: tensor([1.4444e-06, 4.9046e-03, 1.6772e-04, 5.5577e-02, 9.3849e-01, 6.6703e-05,
        5.1048e-04, 2.8370e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,445][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.2555, 0.1877, 0.0727, 0.1691, 0.0596, 0.0851, 0.0745, 0.0957],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,450][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0427, 0.0386, 0.4391, 0.2246, 0.0785, 0.0342, 0.1015, 0.0407],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,453][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.5014, 0.1417, 0.0346, 0.0547, 0.1057, 0.0296, 0.0272, 0.1050],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,454][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0558, 0.1144, 0.0982, 0.2597, 0.1510, 0.0810, 0.1752, 0.0646],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,454][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0579, 0.0200, 0.0449, 0.0422, 0.2737, 0.1895, 0.0238, 0.3479],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,455][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ station] are: tensor([3.2091e-11, 3.5659e-03, 5.4851e-11, 2.1449e-06, 9.9643e-01, 1.0443e-10,
        1.1198e-08, 2.7141e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,455][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0845, 0.1115, 0.1024, 0.1216, 0.1103, 0.0976, 0.1181, 0.1528, 0.1011],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,455][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4066, 0.1882, 0.0704, 0.0999, 0.0459, 0.0522, 0.0824, 0.0243, 0.0301],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,456][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7236, 0.0466, 0.0184, 0.0116, 0.0139, 0.0349, 0.0025, 0.1369, 0.0116],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,456][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0011, 0.1873, 0.0106, 0.1166, 0.6414, 0.0026, 0.0144, 0.0194, 0.0066],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,460][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4784, 0.0291, 0.0611, 0.0952, 0.0651, 0.0219, 0.0563, 0.0927, 0.1002],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,463][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([8.4049e-07, 4.2328e-03, 2.3547e-04, 8.8047e-02, 9.0423e-01, 6.5342e-05,
        1.9091e-03, 7.4075e-04, 5.3538e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,468][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2457, 0.1667, 0.0435, 0.2192, 0.0463, 0.0580, 0.0621, 0.1229, 0.0357],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,468][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0222, 0.0208, 0.4071, 0.1380, 0.0912, 0.0416, 0.1462, 0.0330, 0.0999],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,468][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5598, 0.1213, 0.0309, 0.0391, 0.0771, 0.0271, 0.0240, 0.0856, 0.0352],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,469][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0682, 0.1013, 0.0846, 0.1979, 0.1633, 0.0817, 0.1472, 0.0819, 0.0740],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,469][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0877, 0.3052, 0.0299, 0.1233, 0.1791, 0.0345, 0.0254, 0.0360, 0.1790],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,470][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.3240e-10, 1.5213e-01, 3.2268e-09, 1.6824e-03, 8.4618e-01, 1.2455e-09,
        1.5665e-06, 7.0106e-06, 1.6484e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,470][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.0810, 0.0960, 0.1090, 0.1014, 0.0943, 0.0959, 0.1085, 0.1185, 0.1003,
        0.0951], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,470][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.3441, 0.1670, 0.0795, 0.0815, 0.0509, 0.0614, 0.0846, 0.0343, 0.0484,
        0.0483], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,474][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.1172, 0.1700, 0.0243, 0.0478, 0.0088, 0.0255, 0.0228, 0.4337, 0.0230,
        0.1269], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,478][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([7.6241e-04, 6.3554e-02, 1.0698e-02, 4.9920e-02, 8.5578e-01, 2.0964e-03,
        6.8226e-03, 6.6656e-03, 2.2325e-03, 1.4703e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,482][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.3720, 0.0330, 0.0538, 0.1071, 0.0653, 0.0195, 0.0505, 0.0835, 0.0857,
        0.1296], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,482][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([8.6704e-07, 8.5145e-04, 1.5890e-04, 3.6432e-02, 9.6136e-01, 2.9706e-05,
        6.0197e-04, 2.6060e-04, 3.7615e-05, 2.6903e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,483][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.2489, 0.1325, 0.0597, 0.0811, 0.0517, 0.0678, 0.0812, 0.1117, 0.0647,
        0.1007], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,483][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0235, 0.0309, 0.3633, 0.2091, 0.0806, 0.0355, 0.1075, 0.0266, 0.0737,
        0.0492], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,483][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.4464, 0.1592, 0.0336, 0.0490, 0.0936, 0.0230, 0.0215, 0.0990, 0.0287,
        0.0459], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,484][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.0457, 0.0886, 0.0834, 0.1749, 0.1376, 0.0718, 0.1386, 0.0619, 0.0833,
        0.1140], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,484][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.1119, 0.1109, 0.0121, 0.2064, 0.1270, 0.0427, 0.0186, 0.1000, 0.0300,
        0.2404], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,485][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([6.2769e-13, 3.9251e-05, 4.1503e-10, 9.0873e-08, 9.9996e-01, 1.7937e-11,
        1.7909e-08, 1.2755e-08, 6.1634e-09, 3.6454e-12], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,488][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0714, 0.0861, 0.0991, 0.0994, 0.0846, 0.0895, 0.1034, 0.1155, 0.0943,
        0.0941, 0.0627], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,493][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.4409, 0.1091, 0.0549, 0.0727, 0.0347, 0.0541, 0.0883, 0.0245, 0.0486,
        0.0499, 0.0224], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,496][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.2937, 0.1502, 0.0398, 0.0099, 0.0027, 0.1409, 0.0360, 0.2383, 0.0527,
        0.0261, 0.0097], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,497][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0017, 0.4431, 0.0089, 0.1340, 0.3189, 0.0010, 0.0041, 0.0079, 0.0032,
        0.0040, 0.0732], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,497][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.3755, 0.0259, 0.0502, 0.0900, 0.0608, 0.0174, 0.0472, 0.0797, 0.0824,
        0.1132, 0.0577], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,498][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([8.1966e-04, 4.8979e-02, 3.8227e-04, 4.4978e-01, 4.1461e-01, 2.4824e-05,
        1.7322e-03, 1.6468e-03, 1.5718e-03, 1.1519e-02, 6.8926e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,498][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1484, 0.1324, 0.0402, 0.1289, 0.0405, 0.0530, 0.0557, 0.1005, 0.0478,
        0.1985, 0.0542], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,498][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0199, 0.0288, 0.2971, 0.1049, 0.1089, 0.0555, 0.1600, 0.0461, 0.0978,
        0.0438, 0.0372], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,499][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.5070, 0.1023, 0.0228, 0.0404, 0.0783, 0.0189, 0.0181, 0.0855, 0.0258,
        0.0340, 0.0668], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,499][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0454, 0.0754, 0.1069, 0.1565, 0.1031, 0.0751, 0.1489, 0.0513, 0.0861,
        0.1099, 0.0414], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,503][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0810, 0.0428, 0.0136, 0.0636, 0.4098, 0.0165, 0.0164, 0.0508, 0.0296,
        0.0812, 0.1946], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,506][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([3.9190e-07, 3.4789e-02, 1.0360e-10, 4.1213e-05, 9.4260e-01, 1.2970e-10,
        7.4671e-09, 2.2514e-07, 2.1687e-08, 1.0357e-08, 2.2574e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,511][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0659, 0.0839, 0.0816, 0.0871, 0.0819, 0.0793, 0.0871, 0.1150, 0.0853,
        0.0858, 0.0715, 0.0756], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,511][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4130, 0.0952, 0.0452, 0.0770, 0.0353, 0.0400, 0.0690, 0.0290, 0.0347,
        0.0477, 0.0203, 0.0937], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,511][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4610, 0.1032, 0.0309, 0.0044, 0.0063, 0.0949, 0.0162, 0.1650, 0.0350,
        0.0108, 0.0211, 0.0513], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,512][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0029, 0.1828, 0.0073, 0.0985, 0.5440, 0.0013, 0.0047, 0.0072, 0.0033,
        0.0040, 0.1233, 0.0208], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,512][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.4002, 0.0229, 0.0452, 0.0778, 0.0528, 0.0161, 0.0424, 0.0685, 0.0755,
        0.0961, 0.0489, 0.0536], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,513][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([3.1414e-05, 1.0475e-02, 1.0443e-04, 1.3412e-01, 6.9639e-01, 5.2944e-05,
        2.0601e-03, 1.6104e-03, 7.2984e-04, 5.5765e-03, 1.4046e-01, 8.3832e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,513][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1690, 0.1039, 0.0362, 0.1331, 0.0403, 0.0422, 0.0511, 0.0901, 0.0380,
        0.1806, 0.0668, 0.0488], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,514][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0414, 0.0245, 0.2660, 0.0907, 0.0763, 0.0499, 0.1546, 0.0312, 0.0934,
        0.0429, 0.0321, 0.0970], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,517][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4814, 0.1094, 0.0274, 0.0303, 0.0678, 0.0250, 0.0222, 0.0713, 0.0317,
        0.0321, 0.0733, 0.0279], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,521][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0401, 0.0909, 0.0821, 0.1592, 0.1087, 0.0659, 0.0997, 0.0581, 0.0699,
        0.1087, 0.0553, 0.0614], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,525][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0167, 0.1092, 0.0139, 0.2376, 0.1373, 0.0124, 0.0184, 0.0213, 0.0499,
        0.3081, 0.0623, 0.0130], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,525][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.1809e-09, 3.6502e-03, 2.1389e-11, 8.4895e-06, 5.8464e-01, 1.2210e-11,
        2.0073e-09, 1.2335e-07, 6.2206e-09, 1.6957e-09, 4.1160e-01, 1.0100e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,526][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0622, 0.0735, 0.0862, 0.0776, 0.0748, 0.0743, 0.0853, 0.0901, 0.0823,
        0.0707, 0.0575, 0.0779, 0.0878], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,526][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.6024, 0.0358, 0.0169, 0.0329, 0.0158, 0.0181, 0.0348, 0.0129, 0.0160,
        0.0241, 0.0103, 0.0581, 0.1218], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,527][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.1182, 0.2364, 0.0427, 0.0159, 0.0273, 0.0897, 0.0346, 0.1383, 0.0378,
        0.0387, 0.0538, 0.0644, 0.1021], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,527][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0073, 0.1996, 0.0112, 0.1297, 0.5508, 0.0008, 0.0054, 0.0052, 0.0018,
        0.0033, 0.0509, 0.0105, 0.0236], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,528][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.3323, 0.0254, 0.0458, 0.0830, 0.0523, 0.0171, 0.0442, 0.0650, 0.0761,
        0.1041, 0.0542, 0.0513, 0.0493], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,528][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([3.9290e-05, 1.7834e-03, 1.2856e-04, 5.0713e-02, 9.0044e-01, 2.6304e-05,
        5.4985e-04, 2.8591e-04, 5.5276e-05, 6.9827e-04, 2.5019e-02, 2.7954e-03,
        1.7470e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,531][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1733, 0.0944, 0.0363, 0.1049, 0.0452, 0.0415, 0.0517, 0.0910, 0.0467,
        0.1413, 0.0575, 0.0500, 0.0660], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,537][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0597, 0.0303, 0.2392, 0.1383, 0.0953, 0.0499, 0.1221, 0.0378, 0.0708,
        0.0432, 0.0280, 0.0519, 0.0335], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,539][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.5003, 0.1066, 0.0255, 0.0396, 0.0714, 0.0193, 0.0175, 0.0598, 0.0225,
        0.0327, 0.0516, 0.0173, 0.0360], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,540][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0362, 0.0673, 0.0745, 0.1277, 0.0992, 0.0491, 0.1451, 0.0446, 0.0680,
        0.0840, 0.0416, 0.1168, 0.0461], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,540][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0371, 0.0445, 0.0253, 0.0573, 0.0960, 0.0388, 0.0069, 0.0107, 0.0358,
        0.0659, 0.0367, 0.0081, 0.5368], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,541][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([2.5168e-06, 1.0637e-01, 2.4102e-09, 5.9383e-03, 8.8226e-01, 7.5547e-12,
        2.0953e-07, 1.5082e-08, 2.2226e-09, 7.4931e-08, 4.7726e-03, 5.9601e-04,
        5.3276e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,541][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0500, 0.0730, 0.0670, 0.0792, 0.0741, 0.0578, 0.0791, 0.0972, 0.0680,
        0.0755, 0.0588, 0.0708, 0.0942, 0.0553], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,542][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.3626, 0.0455, 0.0268, 0.0503, 0.0223, 0.0221, 0.0422, 0.0200, 0.0235,
        0.0370, 0.0162, 0.0716, 0.1557, 0.1043], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,542][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3997, 0.0419, 0.0350, 0.0070, 0.0127, 0.0713, 0.0062, 0.1213, 0.0296,
        0.0205, 0.0258, 0.0335, 0.0920, 0.1035], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,544][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0049, 0.1719, 0.0081, 0.1003, 0.4511, 0.0010, 0.0055, 0.0080, 0.0040,
        0.0045, 0.1093, 0.0294, 0.0771, 0.0249], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,550][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.4136, 0.0203, 0.0413, 0.0601, 0.0446, 0.0164, 0.0377, 0.0631, 0.0668,
        0.0808, 0.0435, 0.0464, 0.0392, 0.0264], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,552][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.3607e-05, 2.4608e-03, 5.9289e-05, 4.7836e-02, 6.8656e-01, 8.8250e-06,
        7.9073e-04, 7.2293e-04, 4.6202e-04, 2.3134e-03, 9.1494e-02, 1.3510e-02,
        1.4804e-01, 5.7226e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,554][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1894, 0.0823, 0.0301, 0.1183, 0.0272, 0.0303, 0.0367, 0.0702, 0.0301,
        0.1514, 0.0581, 0.0450, 0.0920, 0.0390], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,554][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0933, 0.0198, 0.2030, 0.0616, 0.0689, 0.0582, 0.1295, 0.0280, 0.0820,
        0.0297, 0.0276, 0.0768, 0.0264, 0.0953], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,555][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.4966, 0.0987, 0.0223, 0.0296, 0.0608, 0.0201, 0.0187, 0.0593, 0.0257,
        0.0310, 0.0614, 0.0238, 0.0345, 0.0170], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,555][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0307, 0.0732, 0.0607, 0.1582, 0.0971, 0.0460, 0.1003, 0.0602, 0.0535,
        0.1078, 0.0416, 0.0781, 0.0537, 0.0390], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,556][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0444, 0.0430, 0.0664, 0.0469, 0.2050, 0.0788, 0.0514, 0.0247, 0.0948,
        0.0575, 0.0619, 0.0387, 0.1157, 0.0707], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,556][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.0903e-08, 2.4407e-03, 2.9796e-12, 1.0074e-06, 8.2567e-01, 1.7783e-12,
        8.8915e-10, 5.4357e-08, 3.8750e-10, 4.5849e-10, 1.6688e-01, 7.9803e-05,
        4.2779e-03, 6.5324e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,591][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:07,594][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,596][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,600][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,601][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,601][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,601][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,602][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,602][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,602][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,603][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,603][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,603][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,604][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.2704, 0.7296], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,605][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.2783, 0.7217], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,608][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.4847, 0.5153], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,612][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.2184, 0.7816], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,614][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([9.9952e-01, 4.8466e-04], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,616][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.3688, 0.6312], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,617][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.3074, 0.6926], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,617][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.2679, 0.7321], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,617][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.2024, 0.7976], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,618][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.6611, 0.3389], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,618][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.9888, 0.0112], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,618][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([9.9982e-01, 1.8453e-04], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,619][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0045, 0.9372, 0.0584], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,619][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0118, 0.8910, 0.0972], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,621][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2480, 0.0685, 0.6836], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,626][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0012, 0.9435, 0.0553], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,629][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([9.9732e-01, 9.7763e-04, 1.6986e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,631][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0246, 0.9284, 0.0470], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,631][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1632, 0.4172, 0.4196], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,631][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1375, 0.3613, 0.5012], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,632][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1510, 0.4212, 0.4278], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,632][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1426, 0.7909, 0.0665], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,633][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9226, 0.0551, 0.0223], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,633][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([2.8330e-10, 1.0000e+00, 1.2675e-09], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,633][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.0146, 0.6319, 0.0680, 0.2854], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,634][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.0224, 0.3423, 0.0923, 0.5430], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,637][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0227, 0.0046, 0.0633, 0.9094], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,641][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.0175, 0.5915, 0.1081, 0.2829], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,645][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([9.9465e-01, 1.0004e-03, 9.7461e-04, 3.3756e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,645][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.1113, 0.5033, 0.0429, 0.3425], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,646][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.1094, 0.2934, 0.2976, 0.2996], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,646][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0875, 0.2199, 0.3180, 0.3745], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,647][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0856, 0.2899, 0.2921, 0.3324], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,647][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.2151, 0.4408, 0.0556, 0.2886], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,647][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.9447, 0.0336, 0.0118, 0.0100], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,648][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([2.9315e-04, 9.9967e-01, 3.3099e-06, 3.5029e-05], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,648][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0203, 0.1835, 0.0186, 0.0600, 0.7176], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,651][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0144, 0.2223, 0.0475, 0.1760, 0.5398], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,656][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0162, 0.0110, 0.1161, 0.5360, 0.3207], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,661][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0008, 0.4883, 0.0171, 0.1620, 0.3318], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,662][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.9931, 0.0011, 0.0022, 0.0022, 0.0014], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,662][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0780, 0.4948, 0.0241, 0.1613, 0.2418], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,663][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.0815, 0.2229, 0.2293, 0.2364, 0.2299], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,663][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0646, 0.1618, 0.2310, 0.2692, 0.2735], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,663][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0752, 0.2057, 0.2103, 0.2360, 0.2728], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,664][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1415, 0.5406, 0.0295, 0.1094, 0.1790], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,665][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.9282, 0.0309, 0.0154, 0.0084, 0.0171], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,669][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([8.7514e-06, 9.2232e-01, 1.0431e-08, 3.6737e-05, 7.7634e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,671][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.1201e-04, 1.4364e-01, 4.7553e-03, 2.8529e-02, 8.2164e-01, 1.2281e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,675][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0012, 0.2229, 0.0149, 0.2023, 0.5537, 0.0049], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,675][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0017, 0.0019, 0.0277, 0.6335, 0.3170, 0.0183], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,676][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.3915e-04, 3.0833e-01, 7.5785e-03, 1.6503e-01, 5.1462e-01, 4.2027e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,676][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.9618e-01, 3.2628e-04, 8.8763e-04, 1.1189e-03, 7.5679e-04, 7.3147e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,677][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0026, 0.3872, 0.0068, 0.1201, 0.4800, 0.0034], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,677][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0706, 0.1835, 0.1818, 0.1902, 0.1863, 0.1876], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,677][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0544, 0.1347, 0.1903, 0.2186, 0.2236, 0.1784], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,678][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0551, 0.1644, 0.1688, 0.1910, 0.2259, 0.1949], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,679][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0331, 0.3882, 0.0194, 0.1572, 0.3910, 0.0111], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,684][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9575, 0.0078, 0.0065, 0.0035, 0.0061, 0.0186], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,687][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.9440e-13, 5.0136e-03, 3.5624e-13, 1.8834e-08, 9.9499e-01, 3.1857e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,689][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([3.0358e-04, 1.1879e-01, 8.0035e-03, 6.4291e-02, 8.0121e-01, 2.1920e-03,
        5.2010e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,690][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0012, 0.1685, 0.0181, 0.2171, 0.5820, 0.0040, 0.0091],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,690][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0056, 0.0042, 0.0456, 0.4745, 0.2854, 0.0154, 0.1692],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,690][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([4.5397e-04, 2.1062e-01, 1.0989e-02, 1.3574e-01, 6.3443e-01, 2.8309e-03,
        4.9397e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,691][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([9.9481e-01, 4.5089e-04, 1.0574e-03, 1.7205e-03, 4.5043e-04, 8.3046e-04,
        6.7667e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,691][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0087, 0.3024, 0.0135, 0.1571, 0.5026, 0.0053, 0.0103],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,692][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0553, 0.1542, 0.1546, 0.1639, 0.1603, 0.1608, 0.1508],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,695][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0458, 0.1114, 0.1568, 0.1831, 0.1847, 0.1429, 0.1753],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,701][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0437, 0.1373, 0.1425, 0.1607, 0.1921, 0.1644, 0.1594],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,703][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0335, 0.3289, 0.0225, 0.2053, 0.3802, 0.0084, 0.0212],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,703][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.9360, 0.0185, 0.0076, 0.0052, 0.0072, 0.0169, 0.0087],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,704][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([6.1782e-10, 1.3569e-02, 2.0805e-09, 2.0688e-05, 9.8641e-01, 4.1294e-09,
        1.4926e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,704][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([2.8439e-04, 1.3217e-01, 5.4122e-03, 9.0080e-02, 7.5900e-01, 1.4412e-03,
        5.6355e-03, 5.9722e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,704][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0010, 0.0869, 0.0136, 0.2117, 0.6691, 0.0021, 0.0073, 0.0082],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,705][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0013, 0.0016, 0.0271, 0.2768, 0.3211, 0.0091, 0.1455, 0.2176],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,705][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0005, 0.2933, 0.0067, 0.2690, 0.4176, 0.0011, 0.0066, 0.0051],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,706][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([9.8676e-01, 4.6076e-04, 2.4605e-03, 2.6757e-03, 1.6230e-03, 2.0291e-03,
        1.8664e-03, 2.1283e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,709][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0056, 0.3152, 0.0095, 0.1679, 0.4823, 0.0026, 0.0097, 0.0071],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,713][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0479, 0.1351, 0.1345, 0.1441, 0.1397, 0.1369, 0.1305, 0.1313],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,717][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0393, 0.0981, 0.1380, 0.1601, 0.1589, 0.1225, 0.1501, 0.1329],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,717][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0320, 0.1179, 0.1248, 0.1399, 0.1705, 0.1410, 0.1386, 0.1354],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,718][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0152, 0.3347, 0.0176, 0.1471, 0.4421, 0.0061, 0.0212, 0.0160],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,718][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.7786, 0.0193, 0.0187, 0.0072, 0.0345, 0.0815, 0.0272, 0.0330],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,719][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([3.2091e-11, 3.5659e-03, 5.4851e-11, 2.1449e-06, 9.9643e-01, 1.0443e-10,
        1.1198e-08, 2.7141e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:07,719][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0009, 0.1227, 0.0092, 0.1087, 0.6970, 0.0019, 0.0154, 0.0394, 0.0047],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,719][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0023, 0.2083, 0.0192, 0.2779, 0.4212, 0.0038, 0.0199, 0.0335, 0.0139],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,723][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0007, 0.0027, 0.0226, 0.2895, 0.1860, 0.0135, 0.1289, 0.3244, 0.0316],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,727][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([2.5341e-04, 1.7512e-01, 7.5610e-03, 1.3554e-01, 6.3942e-01, 2.4133e-03,
        1.2858e-02, 2.1152e-02, 5.6879e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,729][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([9.8166e-01, 1.0183e-03, 2.3098e-03, 3.5397e-03, 8.7614e-04, 1.4055e-03,
        1.3212e-03, 1.0516e-03, 6.8173e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,731][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0099, 0.2877, 0.0170, 0.1753, 0.4387, 0.0041, 0.0272, 0.0221, 0.0181],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,731][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0413, 0.1184, 0.1169, 0.1264, 0.1242, 0.1237, 0.1173, 0.1214, 0.1104],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,732][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0341, 0.0862, 0.1222, 0.1447, 0.1430, 0.1089, 0.1365, 0.1185, 0.1060],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,732][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0312, 0.1018, 0.1081, 0.1219, 0.1471, 0.1264, 0.1225, 0.1225, 0.1186],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,732][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0346, 0.3075, 0.0224, 0.2325, 0.3056, 0.0085, 0.0387, 0.0380, 0.0123],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,733][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8551, 0.0288, 0.0082, 0.0057, 0.0094, 0.0176, 0.0108, 0.0042, 0.0602],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,733][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.3240e-10, 1.5213e-01, 3.2268e-09, 1.6824e-03, 8.4618e-01, 1.2455e-09,
        1.5665e-06, 7.0106e-06, 1.6484e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:07,734][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([1.1908e-04, 6.2423e-02, 8.1608e-03, 7.6151e-02, 8.2908e-01, 8.5867e-04,
        7.6605e-03, 1.3321e-02, 1.3319e-03, 8.9353e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,735][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([2.8427e-04, 6.0766e-02, 1.1123e-02, 2.3217e-01, 6.5879e-01, 2.2525e-03,
        8.3225e-03, 1.5491e-02, 5.5131e-03, 5.2865e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,741][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0037, 0.0024, 0.0326, 0.2988, 0.1759, 0.0143, 0.1482, 0.1499, 0.0305,
        0.1437], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,743][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([1.4947e-04, 5.2873e-02, 7.0399e-03, 5.8660e-02, 8.6265e-01, 1.7648e-03,
        6.2828e-03, 7.1336e-03, 2.0067e-03, 1.4408e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,745][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([9.7228e-01, 1.7978e-03, 2.4564e-03, 6.1042e-03, 1.0188e-03, 1.3498e-03,
        9.6548e-04, 5.4603e-04, 6.5968e-03, 6.8831e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,745][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0053, 0.1207, 0.0133, 0.1772, 0.6372, 0.0026, 0.0193, 0.0140, 0.0056,
        0.0047], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,746][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.0336, 0.1060, 0.1063, 0.1130, 0.1129, 0.1112, 0.1060, 0.1081, 0.0986,
        0.1044], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,746][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0301, 0.0788, 0.1125, 0.1324, 0.1305, 0.0992, 0.1245, 0.1079, 0.0959,
        0.0882], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,747][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0228, 0.0900, 0.0976, 0.1088, 0.1354, 0.1109, 0.1097, 0.1059, 0.1024,
        0.1165], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,747][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.0179, 0.2251, 0.0201, 0.2152, 0.4314, 0.0067, 0.0296, 0.0386, 0.0063,
        0.0092], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,750][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.8162, 0.0317, 0.0139, 0.0080, 0.0213, 0.0325, 0.0128, 0.0089, 0.0480,
        0.0069], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,753][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([6.2769e-13, 3.9251e-05, 4.1503e-10, 9.0873e-08, 9.9996e-01, 1.7937e-11,
        1.7909e-08, 1.2755e-08, 6.1634e-09, 3.6454e-12], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:07,758][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0162, 0.1251, 0.0079, 0.0715, 0.6132, 0.0009, 0.0068, 0.0122, 0.0043,
        0.0023, 0.1396], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,759][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0101, 0.1454, 0.0147, 0.2674, 0.4220, 0.0022, 0.0129, 0.0172, 0.0165,
        0.0103, 0.0814], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,759][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0080, 0.0037, 0.0357, 0.1817, 0.2164, 0.0068, 0.0956, 0.1201, 0.0306,
        0.0853, 0.2160], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,760][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0004, 0.3875, 0.0059, 0.1789, 0.3287, 0.0009, 0.0041, 0.0092, 0.0031,
        0.0043, 0.0770], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,760][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([9.7770e-01, 9.4988e-04, 2.6325e-03, 2.7576e-03, 1.6875e-03, 1.1941e-03,
        1.2673e-03, 1.1391e-03, 5.5962e-03, 3.1621e-03, 1.9117e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,760][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0480, 0.4726, 0.0075, 0.1890, 0.1610, 0.0008, 0.0075, 0.0080, 0.0116,
        0.0105, 0.0836], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,761][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0332, 0.0965, 0.0965, 0.1033, 0.0998, 0.0986, 0.0933, 0.0955, 0.0883,
        0.0945, 0.1006], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,761][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0285, 0.0704, 0.0995, 0.1156, 0.1188, 0.0913, 0.1132, 0.1001, 0.0877,
        0.0797, 0.0951], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,765][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0185, 0.0810, 0.0912, 0.0997, 0.1281, 0.1021, 0.1028, 0.0985, 0.0936,
        0.1046, 0.0799], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,770][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0659, 0.3712, 0.0106, 0.1039, 0.3326, 0.0040, 0.0179, 0.0151, 0.0078,
        0.0081, 0.0629], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,773][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.7659, 0.0202, 0.0142, 0.0070, 0.0200, 0.0339, 0.0160, 0.0075, 0.0746,
        0.0079, 0.0329], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,773][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([3.9190e-07, 3.4789e-02, 1.0360e-10, 4.1213e-05, 9.4260e-01, 1.2970e-10,
        7.4671e-09, 2.2514e-07, 2.1687e-08, 1.0357e-08, 2.2574e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:07,773][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.6867e-04, 7.8666e-02, 2.4798e-03, 3.5926e-02, 3.8406e-01, 4.4734e-04,
        3.0366e-03, 1.6453e-02, 1.3795e-03, 1.5627e-03, 4.5971e-01, 1.5614e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,774][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0056, 0.1600, 0.0085, 0.2515, 0.4043, 0.0016, 0.0061, 0.0224, 0.0083,
        0.0141, 0.0813, 0.0363], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,774][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0047, 0.0031, 0.0223, 0.1805, 0.1193, 0.0079, 0.0837, 0.1169, 0.0179,
        0.1240, 0.2161, 0.1036], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,775][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0007, 0.1748, 0.0049, 0.1213, 0.5354, 0.0012, 0.0043, 0.0078, 0.0030,
        0.0039, 0.1234, 0.0194], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,776][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.7947e-01, 9.1233e-04, 1.8395e-03, 2.6185e-03, 1.2411e-03, 1.1742e-03,
        1.1296e-03, 6.6713e-04, 4.8379e-03, 2.4009e-03, 9.5034e-04, 2.7627e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,780][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0268, 0.2586, 0.0055, 0.1413, 0.2743, 0.0018, 0.0137, 0.0164, 0.0126,
        0.0118, 0.2055, 0.0316], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,786][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0297, 0.0873, 0.0875, 0.0943, 0.0911, 0.0902, 0.0850, 0.0878, 0.0799,
        0.0858, 0.0926, 0.0889], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,787][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0270, 0.0657, 0.0916, 0.1060, 0.1060, 0.0815, 0.1018, 0.0902, 0.0804,
        0.0733, 0.0859, 0.0905], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,787][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0207, 0.0767, 0.0817, 0.0907, 0.1116, 0.0924, 0.0914, 0.0893, 0.0864,
        0.0984, 0.0757, 0.0850], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,787][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0548, 0.2667, 0.0109, 0.1376, 0.2650, 0.0041, 0.0199, 0.0207, 0.0074,
        0.0112, 0.1603, 0.0412], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,788][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8103, 0.0313, 0.0088, 0.0072, 0.0088, 0.0197, 0.0110, 0.0046, 0.0585,
        0.0078, 0.0123, 0.0198], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,788][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([3.1809e-09, 3.6502e-03, 2.1389e-11, 8.4895e-06, 5.8464e-01, 1.2210e-11,
        2.0073e-09, 1.2335e-07, 6.2206e-09, 1.6957e-09, 4.1160e-01, 1.0100e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:07,789][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([1.5622e-03, 3.7726e-02, 4.5950e-03, 3.4089e-02, 7.9232e-01, 2.6973e-04,
        2.9845e-03, 5.2912e-03, 4.9294e-04, 4.8633e-04, 9.8942e-02, 5.9124e-03,
        1.5324e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,789][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0119, 0.0850, 0.0112, 0.1903, 0.5292, 0.0010, 0.0055, 0.0076, 0.0039,
        0.0051, 0.0303, 0.0163, 0.1027], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,792][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0036, 0.0012, 0.0239, 0.0945, 0.1593, 0.0069, 0.0912, 0.0591, 0.0189,
        0.0501, 0.2408, 0.1175, 0.1331], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,798][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0019, 0.1920, 0.0075, 0.1539, 0.5382, 0.0008, 0.0051, 0.0056, 0.0016,
        0.0031, 0.0533, 0.0101, 0.0269], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,800][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([9.7675e-01, 1.5303e-03, 2.8209e-03, 2.6147e-03, 8.4104e-04, 1.3642e-03,
        1.1829e-03, 2.5710e-04, 4.5175e-03, 2.2570e-03, 1.2559e-03, 1.8978e-03,
        2.7150e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,801][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0444, 0.1214, 0.0096, 0.1400, 0.4864, 0.0015, 0.0111, 0.0073, 0.0043,
        0.0050, 0.0982, 0.0246, 0.0463], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,801][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0268, 0.0814, 0.0806, 0.0863, 0.0852, 0.0830, 0.0788, 0.0804, 0.0735,
        0.0786, 0.0846, 0.0833, 0.0774], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,802][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0252, 0.0622, 0.0871, 0.1010, 0.1000, 0.0756, 0.0947, 0.0825, 0.0725,
        0.0663, 0.0777, 0.0812, 0.0738], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,802][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0158, 0.0719, 0.0778, 0.0862, 0.1074, 0.0853, 0.0866, 0.0835, 0.0790,
        0.0889, 0.0679, 0.0775, 0.0722], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,802][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0760, 0.1529, 0.0233, 0.1741, 0.2984, 0.0051, 0.0270, 0.0193, 0.0046,
        0.0087, 0.0992, 0.0342, 0.0770], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,806][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.6953, 0.0398, 0.0178, 0.0111, 0.0222, 0.0390, 0.0136, 0.0078, 0.0705,
        0.0086, 0.0239, 0.0184, 0.0322], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,810][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([2.5168e-06, 1.0637e-01, 2.4102e-09, 5.9383e-03, 8.8226e-01, 7.5547e-12,
        2.0953e-07, 1.5082e-08, 2.2226e-09, 7.4931e-08, 4.7726e-03, 5.9601e-04,
        5.3276e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:07,812][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([5.9501e-03, 7.7564e-02, 3.9363e-03, 2.9325e-02, 4.9238e-01, 1.6605e-04,
        5.2833e-03, 1.0511e-02, 1.5968e-03, 1.3929e-03, 2.4140e-01, 2.2544e-02,
        8.3222e-02, 2.4723e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,814][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0090, 0.0791, 0.0063, 0.1159, 0.2855, 0.0006, 0.0061, 0.0156, 0.0067,
        0.0066, 0.0343, 0.0360, 0.3234, 0.0750], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,814][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0043, 0.0017, 0.0106, 0.1445, 0.0603, 0.0047, 0.0678, 0.0611, 0.0182,
        0.1874, 0.1097, 0.0893, 0.1850, 0.0554], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,815][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0012, 0.1641, 0.0046, 0.1210, 0.4503, 0.0007, 0.0048, 0.0078, 0.0033,
        0.0041, 0.1037, 0.0268, 0.0852, 0.0224], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,815][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.8178e-01, 5.0853e-04, 1.6740e-03, 2.0067e-03, 1.0896e-03, 9.7481e-04,
        7.4655e-04, 4.6662e-04, 4.2169e-03, 2.2896e-03, 6.3112e-04, 1.5744e-03,
        1.0919e-03, 9.5037e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,816][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0320, 0.1505, 0.0058, 0.0979, 0.2954, 0.0008, 0.0106, 0.0115, 0.0109,
        0.0086, 0.1488, 0.0460, 0.1388, 0.0426], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,816][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0272, 0.0743, 0.0735, 0.0788, 0.0767, 0.0759, 0.0718, 0.0735, 0.0681,
        0.0722, 0.0781, 0.0766, 0.0734, 0.0798], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,817][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0231, 0.0565, 0.0788, 0.0911, 0.0914, 0.0707, 0.0872, 0.0776, 0.0685,
        0.0626, 0.0737, 0.0774, 0.0692, 0.0720], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,820][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0168, 0.0656, 0.0701, 0.0782, 0.0967, 0.0795, 0.0798, 0.0772, 0.0745,
        0.0846, 0.0643, 0.0729, 0.0686, 0.0713], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,826][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0863, 0.2095, 0.0110, 0.1103, 0.2418, 0.0033, 0.0168, 0.0251, 0.0054,
        0.0103, 0.1089, 0.0329, 0.0870, 0.0514], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,828][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7896, 0.0157, 0.0093, 0.0057, 0.0121, 0.0220, 0.0118, 0.0057, 0.0514,
        0.0069, 0.0148, 0.0206, 0.0095, 0.0250], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,828][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0903e-08, 2.4407e-03, 2.9796e-12, 1.0074e-06, 8.2567e-01, 1.7783e-12,
        8.8915e-10, 5.4357e-08, 3.8750e-10, 4.5849e-10, 1.6688e-01, 7.9803e-05,
        4.2779e-03, 6.5324e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:07,830][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:07,831][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13923],
        [ 2268],
        [ 3928],
        [ 1395],
        [  488],
        [ 1139],
        [ 3603],
        [  621],
        [ 2104],
        [ 1218],
        [  468],
        [ 2871],
        [ 2236],
        [ 1292]], device='cuda:0')
[2024-07-24 10:30:07,832][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[14318],
        [15070],
        [11312],
        [ 6542],
        [ 7086],
        [ 8639],
        [18053],
        [ 5314],
        [ 9363],
        [ 9643],
        [ 5402],
        [10426],
        [13823],
        [ 8561]], device='cuda:0')
[2024-07-24 10:30:07,835][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[21353],
        [22419],
        [18977],
        [17019],
        [16769],
        [17200],
        [17239],
        [16985],
        [16784],
        [16256],
        [16553],
        [16537],
        [16788],
        [16844]], device='cuda:0')
[2024-07-24 10:30:07,837][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[40766],
        [33870],
        [34354],
        [35688],
        [34168],
        [34171],
        [34520],
        [33329],
        [34260],
        [34310],
        [35773],
        [36291],
        [39539],
        [38142]], device='cuda:0')
[2024-07-24 10:30:07,840][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[24324],
        [  521],
        [ 7190],
        [  796],
        [ 1074],
        [ 6694],
        [ 3388],
        [ 1718],
        [ 8417],
        [ 3590],
        [ 3659],
        [ 4167],
        [ 1233],
        [ 3123]], device='cuda:0')
[2024-07-24 10:30:07,843][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 1825],
        [37282],
        [42852],
        [40442],
        [30958],
        [14746],
        [ 8419],
        [22269],
        [ 6292],
        [ 2050],
        [23414],
        [ 5958],
        [ 7648],
        [ 5102]], device='cuda:0')
[2024-07-24 10:30:07,845][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[22919],
        [21831],
        [25018],
        [22717],
        [24394],
        [25199],
        [25924],
        [26298],
        [26894],
        [25990],
        [26526],
        [27212],
        [27512],
        [28092]], device='cuda:0')
[2024-07-24 10:30:07,846][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 2816],
        [33171],
        [33142],
        [22494],
        [14706],
        [12307],
        [12519],
        [12399],
        [12556],
        [12282],
        [17283],
        [14051],
        [12447],
        [12673]], device='cuda:0')
[2024-07-24 10:30:07,846][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[27118],
        [14172],
        [ 9924],
        [ 9159],
        [ 6666],
        [ 8780],
        [ 6466],
        [ 7373],
        [ 7369],
        [ 7846],
        [ 6121],
        [ 6521],
        [ 6948],
        [ 7190]], device='cuda:0')
[2024-07-24 10:30:07,848][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 7923],
        [10009],
        [ 8031],
        [10721],
        [10373],
        [10669],
        [10711],
        [11013],
        [11092],
        [11887],
        [12163],
        [12138],
        [12446],
        [12191]], device='cuda:0')
[2024-07-24 10:30:07,849][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[20838],
        [29232],
        [29541],
        [30052],
        [28616],
        [29552],
        [29572],
        [29898],
        [29733],
        [30197],
        [29706],
        [30141],
        [29867],
        [29963]], device='cuda:0')
[2024-07-24 10:30:07,851][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[11862],
        [14007],
        [12676],
        [12795],
        [12164],
        [12066],
        [11963],
        [12026],
        [11217],
        [10844],
        [10346],
        [10501],
        [10459],
        [10546]], device='cuda:0')
[2024-07-24 10:30:07,854][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[17959],
        [22693],
        [12025],
        [18679],
        [11953],
        [ 6532],
        [11180],
        [ 2999],
        [ 9008],
        [11091],
        [ 7655],
        [12277],
        [10602],
        [ 4118]], device='cuda:0')
[2024-07-24 10:30:07,856][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[21179],
        [21186],
        [42637],
        [42637],
        [41615],
        [ 9490],
        [ 9687],
        [ 9453],
        [13891],
        [ 9378],
        [10285],
        [11229],
        [12515],
        [10093]], device='cuda:0')
[2024-07-24 10:30:07,859][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 5360],
        [17083],
        [ 4860],
        [ 7025],
        [ 3040],
        [14678],
        [ 5362],
        [ 5128],
        [ 6469],
        [14384],
        [ 6416],
        [16086],
        [14472],
        [20847]], device='cuda:0')
[2024-07-24 10:30:07,861][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13497],
        [39157],
        [37634],
        [35809],
        [31079],
        [29425],
        [29650],
        [30446],
        [31429],
        [28879],
        [27117],
        [15656],
        [25961],
        [21879]], device='cuda:0')
[2024-07-24 10:30:07,862][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13896],
        [ 7130],
        [ 6134],
        [ 6614],
        [ 3976],
        [ 4372],
        [ 4291],
        [ 3994],
        [ 4179],
        [ 3983],
        [ 3621],
        [ 3615],
        [ 3227],
        [ 2994]], device='cuda:0')
[2024-07-24 10:30:07,863][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[1827],
        [4136],
        [6953],
        [4503],
        [4976],
        [4765],
        [5047],
        [4095],
        [3553],
        [3756],
        [3803],
        [3671],
        [3690],
        [2962]], device='cuda:0')
[2024-07-24 10:30:07,864][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[27741],
        [16261],
        [15415],
        [15010],
        [16434],
        [16618],
        [16956],
        [15505],
        [16583],
        [18097],
        [16778],
        [17888],
        [16768],
        [16401]], device='cuda:0')
[2024-07-24 10:30:07,865][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[26532],
        [26503],
        [26217],
        [26043],
        [25591],
        [26022],
        [25911],
        [25083],
        [24087],
        [23060],
        [23657],
        [23629],
        [23763],
        [24133]], device='cuda:0')
[2024-07-24 10:30:07,868][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[10823],
        [12335],
        [13808],
        [19135],
        [17352],
        [17398],
        [17467],
        [17663],
        [17822],
        [15970],
        [17955],
        [17587],
        [15505],
        [18103]], device='cuda:0')
[2024-07-24 10:30:07,870][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[7051],
        [4090],
        [3452],
        [3709],
        [3510],
        [3492],
        [3470],
        [3554],
        [3532],
        [3535],
        [3464],
        [3428],
        [3482],
        [3465]], device='cuda:0')
[2024-07-24 10:30:07,873][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[42630],
        [41506],
        [42112],
        [43009],
        [43272],
        [43117],
        [43107],
        [42978],
        [43021],
        [43062],
        [43226],
        [43170],
        [43195],
        [43106]], device='cuda:0')
[2024-07-24 10:30:07,875][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[23317],
        [31983],
        [31354],
        [31116],
        [31226],
        [31464],
        [31392],
        [31482],
        [31347],
        [31358],
        [31055],
        [30717],
        [30739],
        [30669]], device='cuda:0')
[2024-07-24 10:30:07,878][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12347],
        [22583],
        [21513],
        [25630],
        [20162],
        [14526],
        [14834],
        [13747],
        [16425],
        [14102],
        [13739],
        [12856],
        [12595],
        [13071]], device='cuda:0')
[2024-07-24 10:30:07,879][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[9056],
        [9096],
        [8628],
        [8669],
        [7917],
        [9139],
        [8743],
        [5488],
        [6970],
        [6133],
        [5724],
        [6558],
        [4064],
        [6454]], device='cuda:0')
[2024-07-24 10:30:07,880][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[24687],
        [24679],
        [ 9999],
        [10000],
        [10212],
        [11200],
        [11193],
        [11201],
        [11180],
        [11198],
        [11679],
        [22200],
        [11278],
        [15032]], device='cuda:0')
[2024-07-24 10:30:07,881][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[35862],
        [33314],
        [34947],
        [33470],
        [35141],
        [34795],
        [34754],
        [36527],
        [35634],
        [36906],
        [36992],
        [37874],
        [38589],
        [37650]], device='cuda:0')
[2024-07-24 10:30:07,882][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[48887],
        [38329],
        [48177],
        [48707],
        [49630],
        [47597],
        [49445],
        [49667],
        [49546],
        [47578],
        [49372],
        [49157],
        [48084],
        [47022]], device='cuda:0')
[2024-07-24 10:30:07,885][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[4627],
        [4627],
        [4627],
        [4627],
        [4627],
        [4627],
        [4627],
        [4627],
        [4627],
        [4627],
        [4627],
        [4627],
        [4627],
        [4627]], device='cuda:0')
[2024-07-24 10:30:07,923][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:07,923][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,924][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,924][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,925][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,925][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,926][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,928][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,931][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,933][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,934][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,934][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,934][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:07,935][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([9.3317e-06, 9.9999e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,935][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([1.0065e-05, 9.9999e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,935][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.4537, 0.5463], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,936][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.2022, 0.7978], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,936][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.9038, 0.0962], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,936][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.5286, 0.4714], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,937][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.8697, 0.1303], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,937][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.7622, 0.2378], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,937][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.9470, 0.0530], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,938][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.8435, 0.1565], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,938][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.9367, 0.0633], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,938][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.2644, 0.7356], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:07,939][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([7.6839e-05, 9.7830e-01, 2.1621e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,939][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([9.5477e-05, 6.9770e-02, 9.3013e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,939][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2597, 0.4483, 0.2919], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,940][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1094, 0.4730, 0.4176], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,940][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.8019, 0.1514, 0.0467], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,940][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4335, 0.4328, 0.1337], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,941][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0852, 0.7803, 0.1345], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,941][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1223, 0.8034, 0.0744], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,941][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1049, 0.8894, 0.0057], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,942][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7091, 0.1620, 0.1289], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,942][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7035, 0.2296, 0.0669], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,942][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0416, 0.3413, 0.6171], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:07,943][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([3.2058e-04, 8.7755e-01, 5.8047e-02, 6.4087e-02], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,943][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([9.1079e-06, 1.4089e-01, 1.5892e-01, 7.0018e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,943][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.1819, 0.3061, 0.3467, 0.1653], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,944][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0663, 0.2896, 0.2673, 0.3768], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,946][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.8583, 0.0526, 0.0422, 0.0470], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,948][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.3802, 0.3026, 0.1020, 0.2152], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,949][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.3638, 0.4008, 0.1180, 0.1174], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,949][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.3709, 0.5166, 0.0435, 0.0690], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,949][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.2787, 0.2321, 0.4688, 0.0204], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,950][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.6835, 0.1566, 0.0877, 0.0722], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,950][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.6743, 0.1434, 0.0397, 0.1425], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,950][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0281, 0.2099, 0.2790, 0.4830], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:07,951][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ went] are: tensor([4.2057e-05, 7.8322e-01, 7.9891e-02, 2.6212e-02, 1.1063e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,951][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ went] are: tensor([9.4668e-06, 2.7038e-03, 2.4211e-02, 1.1894e-02, 9.6118e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,954][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1670, 0.2758, 0.2273, 0.1595, 0.1705], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,959][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0510, 0.2180, 0.2082, 0.2973, 0.2255], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,962][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.7266, 0.0638, 0.0610, 0.1317, 0.0169], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,963][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1422, 0.2301, 0.1552, 0.2025, 0.2701], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,963][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.1267, 0.1653, 0.0233, 0.0421, 0.6425], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,963][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.1111, 0.3971, 0.0229, 0.0116, 0.4573], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,964][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0720, 0.2400, 0.5800, 0.1035, 0.0045], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,964][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.5382, 0.1415, 0.0858, 0.1113, 0.1232], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,964][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.8501, 0.0740, 0.0258, 0.0135, 0.0366], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,967][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0295, 0.1430, 0.2393, 0.1876, 0.4006], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:07,970][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([1.4290e-04, 1.6710e-01, 1.7909e-01, 4.8486e-02, 3.2677e-01, 2.7841e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,973][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.6100e-06, 6.6817e-04, 3.6345e-03, 1.3829e-03, 7.0002e-02, 9.2431e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,976][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1500, 0.2234, 0.1686, 0.1425, 0.1605, 0.1548], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,976][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0393, 0.1852, 0.1684, 0.2611, 0.2046, 0.1414], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,976][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3699, 0.1454, 0.0735, 0.3544, 0.0408, 0.0161], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,977][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1939, 0.1669, 0.0813, 0.1052, 0.1327, 0.3202], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,977][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0092, 0.0250, 0.0019, 0.0035, 0.8367, 0.1237], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,977][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0215, 0.2683, 0.0094, 0.0108, 0.6714, 0.0186], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,978][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([9.1943e-02, 2.6952e-01, 5.5754e-02, 4.4941e-01, 1.3306e-01, 3.2437e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,978][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.4918, 0.1165, 0.0843, 0.0942, 0.1299, 0.0834], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,981][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.9221, 0.0162, 0.0106, 0.0057, 0.0217, 0.0236], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,986][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0781, 0.1743, 0.1617, 0.1832, 0.2240, 0.1787], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:07,989][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([1.4182e-04, 1.4249e-01, 8.6166e-02, 2.9220e-02, 1.4716e-01, 2.2344e-01,
        3.7138e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,990][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([5.7380e-06, 7.5304e-04, 1.2369e-02, 3.3430e-03, 1.5646e-01, 3.7303e-01,
        4.5405e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,990][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1196, 0.1700, 0.1590, 0.1099, 0.1220, 0.1818, 0.1378],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,991][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0325, 0.1610, 0.1474, 0.2249, 0.1788, 0.1226, 0.1329],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,991][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.5787, 0.1045, 0.0481, 0.1760, 0.0434, 0.0157, 0.0336],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,991][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.2235, 0.1513, 0.0671, 0.0991, 0.0971, 0.2117, 0.1502],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,992][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0294, 0.0599, 0.0103, 0.0282, 0.7806, 0.0750, 0.0166],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:07,995][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0284, 0.4036, 0.0164, 0.0263, 0.4956, 0.0140, 0.0157],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,001][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0776, 0.2749, 0.1385, 0.0877, 0.3412, 0.0788, 0.0014],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,003][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.4459, 0.1027, 0.0756, 0.0800, 0.1255, 0.0780, 0.0922],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,003][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.9105, 0.0156, 0.0118, 0.0059, 0.0209, 0.0212, 0.0140],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,004][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0462, 0.1172, 0.1352, 0.1726, 0.2110, 0.1261, 0.1917],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,004][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ station] are: tensor([1.6518e-04, 2.4468e-01, 1.4940e-01, 3.4086e-02, 2.2608e-01, 1.3380e-01,
        1.6983e-01, 4.1946e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,004][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ station] are: tensor([7.1826e-07, 1.0124e-04, 3.3590e-04, 1.4445e-04, 2.7725e-02, 5.2471e-02,
        1.2339e-02, 9.0688e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,005][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0722, 0.1482, 0.1360, 0.0949, 0.1174, 0.1404, 0.1402, 0.1507],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,005][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0254, 0.1414, 0.1265, 0.1924, 0.1508, 0.1060, 0.1189, 0.1385],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,006][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.5519, 0.0882, 0.0629, 0.1638, 0.0257, 0.0200, 0.0705, 0.0170],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,009][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.1533, 0.1238, 0.0677, 0.0810, 0.0906, 0.2006, 0.1310, 0.1520],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,013][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0148, 0.0549, 0.0073, 0.0151, 0.8049, 0.0653, 0.0148, 0.0229],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,017][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0483, 0.2738, 0.0115, 0.0211, 0.5940, 0.0094, 0.0147, 0.0272],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,017][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0062, 0.0578, 0.0480, 0.0716, 0.1527, 0.2275, 0.4355, 0.0006],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,018][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.3781, 0.1074, 0.0766, 0.0840, 0.1161, 0.0829, 0.0898, 0.0651],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,018][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.8143, 0.0108, 0.0112, 0.0070, 0.0386, 0.0622, 0.0299, 0.0261],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,018][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0476, 0.1039, 0.1169, 0.1292, 0.2033, 0.1229, 0.1543, 0.1219],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,019][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([1.7584e-04, 1.8832e-01, 6.5862e-02, 3.1832e-02, 1.6133e-01, 1.6343e-01,
        3.1489e-01, 4.8908e-02, 2.5262e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,019][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([2.4227e-08, 2.4186e-04, 2.6466e-03, 1.1462e-03, 7.0325e-02, 1.0497e-01,
        6.7449e-02, 5.4236e-01, 2.1086e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,022][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0658, 0.1294, 0.1007, 0.0849, 0.0945, 0.1234, 0.1385, 0.2099, 0.0529],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,028][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0260, 0.1240, 0.1086, 0.1739, 0.1395, 0.0939, 0.1032, 0.1313, 0.0995],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,030][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5238, 0.0938, 0.0301, 0.2106, 0.0374, 0.0110, 0.0584, 0.0246, 0.0102],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,031][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1654, 0.1202, 0.0522, 0.0673, 0.0797, 0.1818, 0.1203, 0.1389, 0.0742],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,031][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1131, 0.0577, 0.0131, 0.0252, 0.5363, 0.0581, 0.0544, 0.0861, 0.0561],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,031][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0693, 0.4300, 0.0185, 0.0292, 0.3113, 0.0153, 0.0271, 0.0513, 0.0480],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,032][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0180, 0.2677, 0.0453, 0.1635, 0.3040, 0.0150, 0.1635, 0.0228, 0.0004],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,032][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3987, 0.0869, 0.0634, 0.0721, 0.1113, 0.0706, 0.0850, 0.0661, 0.0460],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,033][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8487, 0.0224, 0.0130, 0.0113, 0.0208, 0.0233, 0.0170, 0.0119, 0.0317],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,033][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0372, 0.0827, 0.0804, 0.0982, 0.0971, 0.0589, 0.0823, 0.0648, 0.3984],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,034][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([2.5332e-04, 1.0819e-01, 9.6297e-02, 5.1862e-02, 1.9614e-01, 1.6552e-01,
        2.7767e-01, 5.1216e-02, 2.6011e-02, 2.6839e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,036][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([2.0345e-07, 1.5714e-03, 5.5050e-04, 1.9028e-03, 7.0818e-02, 1.0201e-01,
        3.1874e-02, 5.5371e-01, 1.0333e-01, 1.3423e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,042][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0578, 0.1031, 0.1283, 0.0558, 0.0999, 0.1441, 0.1115, 0.1584, 0.0791,
        0.0621], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,044][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0187, 0.1103, 0.0982, 0.1450, 0.1210, 0.0842, 0.0939, 0.1145, 0.0928,
        0.1214], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,045][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.6710, 0.0676, 0.0568, 0.0627, 0.0307, 0.0138, 0.0361, 0.0135, 0.0166,
        0.0313], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,045][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.1751, 0.1111, 0.0398, 0.0637, 0.0738, 0.1591, 0.1126, 0.1233, 0.0651,
        0.0765], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,045][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.0152, 0.0372, 0.0178, 0.0097, 0.7656, 0.0446, 0.0376, 0.0395, 0.0276,
        0.0051], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,046][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0274, 0.2469, 0.0123, 0.0287, 0.6219, 0.0071, 0.0143, 0.0237, 0.0138,
        0.0038], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,046][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0526, 0.0620, 0.1328, 0.0046, 0.4218, 0.0588, 0.1290, 0.0349, 0.1019,
        0.0014], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,049][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.3495, 0.1012, 0.0552, 0.0458, 0.1388, 0.0652, 0.0837, 0.0664, 0.0409,
        0.0533], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,054][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.5810, 0.0520, 0.0221, 0.0386, 0.0700, 0.0861, 0.0421, 0.0189, 0.0656,
        0.0236], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,057][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0304, 0.0908, 0.0651, 0.1073, 0.0890, 0.0612, 0.0750, 0.0582, 0.2527,
        0.1702], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,058][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([2.2951e-04, 1.1787e-01, 8.6000e-02, 3.7371e-02, 1.3991e-01, 1.5248e-01,
        3.2331e-01, 5.5621e-02, 3.5593e-02, 2.9718e-02, 2.1913e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,058][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.9077e-07, 1.0880e-04, 8.2997e-04, 3.2208e-04, 1.2153e-02, 5.7960e-02,
        3.4086e-02, 1.2709e-01, 6.3823e-01, 3.2426e-02, 9.6795e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,059][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0537, 0.1060, 0.0991, 0.0719, 0.0721, 0.1121, 0.1125, 0.1603, 0.0643,
        0.0764, 0.0717], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,059][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0185, 0.0974, 0.0882, 0.1317, 0.1028, 0.0756, 0.0860, 0.1000, 0.0827,
        0.1125, 0.1045], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,060][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.3878, 0.0763, 0.0553, 0.1841, 0.0269, 0.0178, 0.0767, 0.0247, 0.0219,
        0.1128, 0.0157], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,060][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.1873, 0.1006, 0.0342, 0.0471, 0.0504, 0.1377, 0.0844, 0.1084, 0.0505,
        0.0810, 0.1183], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,060][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0664, 0.0388, 0.0040, 0.0178, 0.3460, 0.0304, 0.0147, 0.0434, 0.0169,
        0.0163, 0.4053], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,063][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1926, 0.2507, 0.0073, 0.0110, 0.2396, 0.0062, 0.0077, 0.0234, 0.0150,
        0.0045, 0.2421], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,066][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([4.3175e-02, 3.0488e-01, 5.3744e-02, 2.6524e-01, 5.3172e-02, 4.1765e-02,
        4.6459e-02, 6.0885e-02, 8.9239e-03, 1.2152e-01, 2.3987e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,072][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.3792, 0.0971, 0.0494, 0.0585, 0.0903, 0.0607, 0.0705, 0.0571, 0.0365,
        0.0627, 0.0382], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,072][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.7161, 0.0457, 0.0216, 0.0141, 0.0314, 0.0416, 0.0245, 0.0203, 0.0373,
        0.0073, 0.0401], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,073][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0429, 0.0673, 0.0645, 0.0764, 0.0840, 0.0635, 0.0789, 0.0610, 0.2104,
        0.1371, 0.1139], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,073][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0014, 0.0752, 0.1742, 0.0316, 0.1420, 0.1367, 0.2516, 0.0607, 0.0318,
        0.0220, 0.0200, 0.0529], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,073][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.3328e-08, 1.8049e-04, 2.1255e-03, 4.0682e-04, 4.4082e-02, 8.4044e-02,
        6.3200e-02, 3.4756e-01, 1.6811e-01, 9.4577e-03, 2.0812e-01, 7.2718e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,074][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0569, 0.0928, 0.0967, 0.0635, 0.0705, 0.1013, 0.0923, 0.1488, 0.0591,
        0.0716, 0.0819, 0.0647], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,074][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0176, 0.0895, 0.0805, 0.1248, 0.0970, 0.0674, 0.0730, 0.0950, 0.0748,
        0.1053, 0.1030, 0.0720], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,078][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.4451, 0.0834, 0.0417, 0.1587, 0.0365, 0.0129, 0.0467, 0.0202, 0.0202,
        0.0974, 0.0198, 0.0175], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,083][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1484, 0.0845, 0.0326, 0.0443, 0.0459, 0.1206, 0.0795, 0.1007, 0.0474,
        0.0772, 0.1185, 0.1004], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,088][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0505, 0.0092, 0.0016, 0.0041, 0.2129, 0.0153, 0.0049, 0.0147, 0.0098,
        0.0050, 0.6421, 0.0298], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,088][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0488, 0.1526, 0.0035, 0.0066, 0.1705, 0.0032, 0.0055, 0.0187, 0.0099,
        0.0029, 0.5338, 0.0440], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,088][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0465, 0.0714, 0.2592, 0.0559, 0.1406, 0.0467, 0.0132, 0.1398, 0.0984,
        0.0325, 0.0955, 0.0003], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,089][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3625, 0.0697, 0.0554, 0.0532, 0.0851, 0.0527, 0.0662, 0.0464, 0.0377,
        0.0550, 0.0570, 0.0590], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,089][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.8691, 0.0135, 0.0078, 0.0051, 0.0169, 0.0134, 0.0102, 0.0075, 0.0196,
        0.0033, 0.0213, 0.0123], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,090][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0455, 0.0752, 0.0539, 0.0722, 0.0701, 0.0520, 0.0650, 0.0531, 0.1671,
        0.1111, 0.0897, 0.1452], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,090][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0003, 0.1450, 0.1256, 0.0266, 0.1468, 0.1159, 0.2159, 0.0423, 0.0179,
        0.0153, 0.0164, 0.0579, 0.0741], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,091][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([1.5843e-07, 1.7461e-04, 9.6268e-04, 1.4284e-04, 5.6692e-02, 1.0866e-01,
        3.2417e-02, 3.6640e-01, 9.3587e-02, 6.6522e-03, 8.4667e-02, 3.4147e-02,
        2.1549e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,094][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0507, 0.0981, 0.0902, 0.0562, 0.0734, 0.0898, 0.0903, 0.0989, 0.0627,
        0.0584, 0.0737, 0.0814, 0.0762], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,100][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0166, 0.0843, 0.0747, 0.1124, 0.0909, 0.0639, 0.0706, 0.0825, 0.0694,
        0.0929, 0.0938, 0.0731, 0.0748], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,102][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.3576, 0.0856, 0.0808, 0.1294, 0.0355, 0.0178, 0.0706, 0.0212, 0.0277,
        0.0707, 0.0222, 0.0614, 0.0196], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,102][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.1772, 0.0936, 0.0304, 0.0441, 0.0414, 0.0950, 0.0733, 0.0820, 0.0422,
        0.0593, 0.0960, 0.0859, 0.0796], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,103][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0690, 0.0379, 0.0082, 0.0255, 0.3590, 0.0124, 0.0183, 0.0139, 0.0137,
        0.0092, 0.3138, 0.0773, 0.0418], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,103][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.1584, 0.1188, 0.0062, 0.0097, 0.2660, 0.0029, 0.0061, 0.0094, 0.0067,
        0.0019, 0.2830, 0.0313, 0.0996], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,104][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0113, 0.0285, 0.0854, 0.0252, 0.1237, 0.1090, 0.2679, 0.0022, 0.0554,
        0.0099, 0.0287, 0.2517, 0.0011], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,104][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.2476, 0.0727, 0.0611, 0.0610, 0.0959, 0.0676, 0.0697, 0.0735, 0.0482,
        0.0642, 0.0593, 0.0538, 0.0252], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,104][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.5941, 0.0306, 0.0229, 0.0164, 0.0294, 0.0475, 0.0267, 0.0123, 0.0520,
        0.0139, 0.0785, 0.0610, 0.0145], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,105][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0432, 0.0585, 0.0543, 0.0674, 0.0556, 0.0476, 0.0584, 0.0430, 0.1536,
        0.1135, 0.0860, 0.1087, 0.1104], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,108][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0017, 0.1091, 0.2046, 0.0342, 0.1188, 0.0987, 0.1446, 0.0420, 0.0280,
        0.0189, 0.0141, 0.0436, 0.0787, 0.0631], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,112][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.5068e-06, 1.3161e-04, 1.2252e-03, 2.6382e-04, 1.0683e-02, 8.6302e-02,
        3.2274e-02, 1.6739e-01, 1.0916e-01, 1.2842e-02, 7.7010e-02, 6.1450e-02,
        3.1088e-01, 1.3038e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,116][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0552, 0.0888, 0.0670, 0.0578, 0.0593, 0.0580, 0.0883, 0.1270, 0.0469,
        0.0645, 0.0670, 0.0690, 0.0918, 0.0592], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,116][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0138, 0.0791, 0.0693, 0.1095, 0.0860, 0.0564, 0.0626, 0.0819, 0.0647,
        0.0889, 0.0884, 0.0636, 0.0741, 0.0619], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,117][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2292, 0.0960, 0.0401, 0.2292, 0.0329, 0.0070, 0.0726, 0.0264, 0.0203,
        0.1264, 0.0224, 0.0485, 0.0344, 0.0148], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,117][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1256, 0.0791, 0.0285, 0.0358, 0.0382, 0.0994, 0.0651, 0.0811, 0.0393,
        0.0610, 0.0950, 0.0851, 0.0765, 0.0904], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,118][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0708, 0.0074, 0.0012, 0.0015, 0.1827, 0.0112, 0.0040, 0.0089, 0.0058,
        0.0027, 0.5002, 0.0298, 0.0261, 0.1477], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,118][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1027, 0.0986, 0.0042, 0.0053, 0.1687, 0.0028, 0.0062, 0.0150, 0.0089,
        0.0024, 0.3173, 0.0479, 0.1547, 0.0653], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,119][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([6.2922e-02, 1.4798e-01, 2.4820e-02, 2.4826e-01, 4.9312e-02, 7.4271e-05,
        1.0111e-01, 1.5535e-02, 8.8782e-03, 1.5316e-01, 3.2413e-02, 7.9656e-02,
        7.5675e-02, 2.0296e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,119][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2649, 0.0698, 0.0515, 0.0554, 0.0771, 0.0503, 0.0635, 0.0482, 0.0378,
        0.0587, 0.0539, 0.0592, 0.0541, 0.0557], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,122][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.7499, 0.0260, 0.0139, 0.0102, 0.0308, 0.0260, 0.0173, 0.0125, 0.0312,
        0.0064, 0.0248, 0.0233, 0.0014, 0.0263], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,127][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0533, 0.0656, 0.0488, 0.0571, 0.0557, 0.0521, 0.0531, 0.0494, 0.1269,
        0.0869, 0.0771, 0.0904, 0.0898, 0.0936], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,161][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:08,180][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,182][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,185][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,189][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,191][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,191][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,192][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,192][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,192][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,192][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,193][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,193][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,193][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.5212, 0.4788], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,194][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.8928, 0.1072], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,194][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.2031, 0.7969], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,197][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.3710, 0.6290], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,202][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.4289, 0.5711], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,205][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.2067, 0.7933], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,206][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.8697, 0.1303], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,206][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.7622, 0.2378], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,206][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.1962, 0.8038], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,207][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.6064, 0.3936], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,207][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0248, 0.9752], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,207][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.3383, 0.6617], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,207][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0846, 0.9073, 0.0080], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,208][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8026, 0.0728, 0.1246], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,208][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0019, 0.9943, 0.0038], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,209][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2193, 0.3592, 0.4215], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,214][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0041, 0.9617, 0.0341], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,220][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0730, 0.7326, 0.1944], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,220][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0852, 0.7803, 0.1345], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,220][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1223, 0.8034, 0.0744], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,221][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0047, 0.9566, 0.0387], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,221][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4396, 0.2999, 0.2604], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,221][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0126, 0.4370, 0.5504], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,221][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1293, 0.0434, 0.8273], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,222][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.0089, 0.0188, 0.9564, 0.0159], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,222][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.5572, 0.0065, 0.0221, 0.4141], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,222][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0432, 0.8814, 0.0079, 0.0675], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,224][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.1482, 0.2492, 0.2941, 0.3085], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,230][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.0158, 0.7163, 0.0380, 0.2299], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,234][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.3629, 0.1890, 0.0576, 0.3904], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,234][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.3638, 0.4008, 0.1180, 0.1174], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,235][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.3709, 0.5166, 0.0435, 0.0690], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,235][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.1070, 0.5780, 0.0559, 0.2590], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,235][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.3499, 0.2236, 0.2278, 0.1987], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,236][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.0092, 0.2704, 0.3351, 0.3853], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,236][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.1394, 0.1811, 0.0801, 0.5994], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,236][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.4155, 0.0634, 0.4100, 0.0539, 0.0573], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,237][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.7871, 0.0229, 0.0251, 0.0709, 0.0940], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,237][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0102, 0.8709, 0.0029, 0.0322, 0.0838], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,240][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1187, 0.1912, 0.2207, 0.2336, 0.2357], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,245][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0121, 0.4047, 0.0086, 0.0682, 0.5065], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,248][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.2972, 0.3344, 0.1545, 0.1203, 0.0937], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,249][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.1267, 0.1653, 0.0233, 0.0421, 0.6425], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,249][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.1111, 0.3971, 0.0229, 0.0116, 0.4573], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,249][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0454, 0.4329, 0.0235, 0.2316, 0.2667], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,250][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.2927, 0.1885, 0.1913, 0.1608, 0.1668], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,250][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0058, 0.1948, 0.2415, 0.2724, 0.2855], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,250][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.1084, 0.0560, 0.1196, 0.0467, 0.6693], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,251][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2539, 0.0334, 0.0387, 0.0372, 0.5264, 0.1105], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,251][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3319, 0.0044, 0.0048, 0.0100, 0.0202, 0.6286], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,251][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0151, 0.7575, 0.0029, 0.0654, 0.1560, 0.0032], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,255][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0828, 0.1569, 0.1830, 0.1932, 0.1927, 0.1914], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,260][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0015, 0.3189, 0.0039, 0.0744, 0.5909, 0.0104], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,262][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2276, 0.1108, 0.0466, 0.0422, 0.0628, 0.5100], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,263][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0092, 0.0250, 0.0019, 0.0035, 0.8367, 0.1237], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,263][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0215, 0.2683, 0.0094, 0.0108, 0.6714, 0.0186], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,263][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0840, 0.4047, 0.0116, 0.2862, 0.1845, 0.0290], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,264][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2244, 0.1611, 0.1732, 0.1476, 0.1467, 0.1471], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,264][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0044, 0.1479, 0.1848, 0.2120, 0.2200, 0.2309], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,264][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0952, 0.0284, 0.2265, 0.0298, 0.0642, 0.5559], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,265][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0490, 0.0039, 0.1796, 0.0013, 0.0476, 0.6949, 0.0237],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,265][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.9211, 0.0038, 0.0057, 0.0274, 0.0160, 0.0163, 0.0097],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,266][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0066, 0.7749, 0.0039, 0.0706, 0.1310, 0.0045, 0.0085],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,271][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0748, 0.1284, 0.1483, 0.1574, 0.1594, 0.1584, 0.1734],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,277][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0012, 0.2210, 0.0050, 0.0606, 0.6975, 0.0057, 0.0090],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,277][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.3733, 0.1533, 0.0725, 0.0847, 0.0514, 0.1878, 0.0769],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,277][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0294, 0.0599, 0.0103, 0.0282, 0.7806, 0.0750, 0.0166],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,278][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0284, 0.4036, 0.0164, 0.0263, 0.4956, 0.0140, 0.0157],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,278][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0090, 0.3038, 0.0160, 0.2087, 0.4108, 0.0349, 0.0167],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,278][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1873, 0.1403, 0.1538, 0.1272, 0.1274, 0.1263, 0.1377],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,279][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0043, 0.1212, 0.1494, 0.1708, 0.1780, 0.1855, 0.1908],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,279][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0926, 0.0558, 0.1109, 0.2257, 0.0866, 0.0533, 0.3751],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,279][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.1019, 0.0087, 0.1208, 0.0154, 0.3125, 0.1993, 0.1864, 0.0549],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,281][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.7097, 0.0031, 0.0061, 0.0158, 0.0168, 0.2059, 0.0244, 0.0181],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,287][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0058, 0.7932, 0.0020, 0.0335, 0.1518, 0.0016, 0.0080, 0.0042],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,291][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0555, 0.1089, 0.1264, 0.1328, 0.1368, 0.1335, 0.1490, 0.1572],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,291][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0031, 0.2651, 0.0043, 0.0785, 0.6248, 0.0027, 0.0079, 0.0136],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,292][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.1543, 0.1520, 0.0732, 0.0633, 0.0591, 0.2749, 0.1330, 0.0901],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,292][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.0148, 0.0549, 0.0073, 0.0151, 0.8049, 0.0653, 0.0148, 0.0229],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,292][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0483, 0.2738, 0.0115, 0.0211, 0.5940, 0.0094, 0.0147, 0.0272],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,293][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0033, 0.2371, 0.0086, 0.3272, 0.2986, 0.0495, 0.0342, 0.0414],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,293][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.1872, 0.1300, 0.1448, 0.1108, 0.1090, 0.1128, 0.1201, 0.0853],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,293][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0083, 0.1023, 0.1199, 0.1353, 0.1468, 0.1480, 0.1487, 0.1907],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,294][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.1020, 0.0308, 0.0953, 0.2487, 0.2570, 0.0515, 0.0670, 0.1478],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,297][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0117, 0.0697, 0.0134, 0.0692, 0.3628, 0.1162, 0.0815, 0.2525, 0.0230],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,302][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5218, 0.0167, 0.0266, 0.1589, 0.0518, 0.0436, 0.0775, 0.0138, 0.0893],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,305][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0196, 0.7222, 0.0035, 0.0975, 0.1053, 0.0033, 0.0210, 0.0201, 0.0074],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,306][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0491, 0.0947, 0.1097, 0.1176, 0.1185, 0.1183, 0.1311, 0.1412, 0.1199],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,306][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0046, 0.2965, 0.0068, 0.0976, 0.5068, 0.0047, 0.0227, 0.0450, 0.0153],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,306][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2174, 0.1692, 0.1139, 0.1012, 0.0523, 0.0730, 0.0867, 0.0453, 0.1410],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,307][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1131, 0.0577, 0.0131, 0.0252, 0.5363, 0.0581, 0.0544, 0.0861, 0.0561],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,307][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0693, 0.4300, 0.0185, 0.0292, 0.3113, 0.0153, 0.0271, 0.0513, 0.0480],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,307][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0082, 0.2654, 0.0170, 0.2070, 0.3429, 0.0313, 0.0589, 0.0601, 0.0092],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,308][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1695, 0.1068, 0.1184, 0.1089, 0.1037, 0.1018, 0.1102, 0.0816, 0.0989],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,308][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0027, 0.0828, 0.1019, 0.1184, 0.1235, 0.1276, 0.1315, 0.1931, 0.1185],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,311][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1035, 0.0439, 0.3253, 0.1039, 0.0460, 0.1001, 0.0496, 0.0593, 0.1683],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,316][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.0027, 0.0045, 0.2814, 0.0035, 0.2328, 0.0838, 0.0659, 0.0522, 0.2701,
        0.0030], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,320][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.2955, 0.0097, 0.0208, 0.2156, 0.1133, 0.0586, 0.0869, 0.0194, 0.1343,
        0.0458], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,320][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0112, 0.5886, 0.0055, 0.0850, 0.2674, 0.0029, 0.0147, 0.0135, 0.0039,
        0.0071], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,320][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.0399, 0.0845, 0.0998, 0.1065, 0.1086, 0.1049, 0.1176, 0.1259, 0.1063,
        0.1060], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,321][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.0008, 0.1297, 0.0061, 0.0842, 0.7358, 0.0018, 0.0135, 0.0201, 0.0040,
        0.0040], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,321][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.1831, 0.0900, 0.0321, 0.1377, 0.0886, 0.0594, 0.1273, 0.0631, 0.1924,
        0.0263], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,322][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.0152, 0.0372, 0.0178, 0.0097, 0.7656, 0.0446, 0.0376, 0.0395, 0.0276,
        0.0051], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,322][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0274, 0.2469, 0.0123, 0.0287, 0.6219, 0.0071, 0.0143, 0.0237, 0.0138,
        0.0038], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,322][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0103, 0.1418, 0.0107, 0.1169, 0.5755, 0.0188, 0.0496, 0.0660, 0.0060,
        0.0045], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,324][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.1532, 0.0917, 0.1039, 0.0930, 0.0897, 0.0955, 0.0999, 0.0722, 0.0968,
        0.1041], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,330][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.0021, 0.0717, 0.0894, 0.1056, 0.1112, 0.1155, 0.1187, 0.1716, 0.1057,
        0.1086], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,334][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0816, 0.0712, 0.0453, 0.2746, 0.0766, 0.0430, 0.0739, 0.0390, 0.0574,
        0.2373], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,334][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0308, 0.0648, 0.1497, 0.0359, 0.0476, 0.0700, 0.1924, 0.0398, 0.3039,
        0.0357, 0.0295], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,335][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.4500, 0.0116, 0.0125, 0.0249, 0.0311, 0.3227, 0.0166, 0.0387, 0.0180,
        0.0552, 0.0187], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,335][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0172, 0.7967, 0.0012, 0.0482, 0.0531, 0.0011, 0.0051, 0.0081, 0.0024,
        0.0056, 0.0612], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,336][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0430, 0.0762, 0.0866, 0.0936, 0.0957, 0.0940, 0.1050, 0.1120, 0.0958,
        0.0953, 0.1029], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,336][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0332, 0.3744, 0.0034, 0.0823, 0.2785, 0.0013, 0.0061, 0.0179, 0.0065,
        0.0085, 0.1880], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,336][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.3265, 0.1545, 0.0605, 0.0360, 0.0362, 0.1590, 0.0266, 0.0488, 0.0508,
        0.0608, 0.0403], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,337][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0664, 0.0388, 0.0040, 0.0178, 0.3460, 0.0304, 0.0147, 0.0434, 0.0169,
        0.0163, 0.4053], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,337][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1926, 0.2507, 0.0073, 0.0110, 0.2396, 0.0062, 0.0077, 0.0234, 0.0150,
        0.0045, 0.2421], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,340][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0332, 0.4022, 0.0083, 0.2446, 0.1539, 0.0218, 0.0191, 0.0703, 0.0061,
        0.0168, 0.0238], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,345][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1817, 0.0897, 0.0964, 0.0832, 0.0781, 0.0804, 0.0860, 0.0658, 0.0800,
        0.0866, 0.0721], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,348][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0020, 0.0654, 0.0822, 0.0946, 0.0988, 0.1024, 0.1058, 0.1505, 0.0939,
        0.0946, 0.1097], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,349][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0482, 0.0187, 0.1788, 0.0814, 0.0668, 0.0594, 0.0863, 0.0312, 0.0892,
        0.0788, 0.2611], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,349][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0502, 0.0018, 0.2089, 0.0008, 0.0226, 0.2455, 0.0281, 0.0165, 0.4098,
        0.0007, 0.0140, 0.0011], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,349][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.6858, 0.0106, 0.0196, 0.0483, 0.0276, 0.0528, 0.0197, 0.0155, 0.0268,
        0.0385, 0.0398, 0.0148], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,350][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0582, 0.5986, 0.0018, 0.0498, 0.0592, 0.0017, 0.0077, 0.0083, 0.0043,
        0.0108, 0.1284, 0.0713], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,350][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0398, 0.0687, 0.0786, 0.0842, 0.0852, 0.0842, 0.0930, 0.0994, 0.0861,
        0.0857, 0.0931, 0.1020], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,351][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0100, 0.1843, 0.0017, 0.0473, 0.2463, 0.0012, 0.0064, 0.0183, 0.0058,
        0.0074, 0.3966, 0.0747], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,351][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2251, 0.1031, 0.0640, 0.0410, 0.0240, 0.0804, 0.0378, 0.0493, 0.0840,
        0.0527, 0.1899, 0.0487], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,351][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0505, 0.0092, 0.0016, 0.0041, 0.2129, 0.0153, 0.0049, 0.0147, 0.0098,
        0.0050, 0.6421, 0.0298], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,354][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0488, 0.1526, 0.0035, 0.0066, 0.1705, 0.0032, 0.0055, 0.0187, 0.0099,
        0.0029, 0.5338, 0.0440], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,359][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0991, 0.2417, 0.0079, 0.1389, 0.1373, 0.0091, 0.0200, 0.0481, 0.0080,
        0.0194, 0.2138, 0.0566], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,363][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1518, 0.0794, 0.0975, 0.0838, 0.0725, 0.0782, 0.0823, 0.0584, 0.0747,
        0.0820, 0.0630, 0.0763], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,363][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0021, 0.0607, 0.0744, 0.0856, 0.0894, 0.0921, 0.0947, 0.1370, 0.0842,
        0.0846, 0.0979, 0.0974], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,363][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0686, 0.0498, 0.0712, 0.1393, 0.0650, 0.0377, 0.0860, 0.0899, 0.0335,
        0.1089, 0.0422, 0.2080], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,364][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0332, 0.0227, 0.0991, 0.0265, 0.2560, 0.1055, 0.1035, 0.0360, 0.1873,
        0.0181, 0.0933, 0.0140, 0.0047], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,364][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.6784, 0.0062, 0.0183, 0.0738, 0.0216, 0.0117, 0.0192, 0.0053, 0.0313,
        0.0298, 0.0203, 0.0267, 0.0573], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,365][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0468, 0.6332, 0.0021, 0.0681, 0.1022, 0.0009, 0.0059, 0.0044, 0.0015,
        0.0052, 0.0464, 0.0362, 0.0470], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,365][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0354, 0.0623, 0.0709, 0.0770, 0.0796, 0.0768, 0.0853, 0.0906, 0.0777,
        0.0775, 0.0852, 0.0930, 0.0887], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,365][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0182, 0.1492, 0.0031, 0.0724, 0.4351, 0.0009, 0.0054, 0.0090, 0.0025,
        0.0041, 0.1456, 0.0347, 0.1200], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,366][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.1801, 0.0876, 0.0433, 0.0802, 0.0283, 0.0313, 0.0580, 0.0301, 0.1070,
        0.0338, 0.0841, 0.1192, 0.1169], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,369][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.0690, 0.0379, 0.0082, 0.0255, 0.3590, 0.0124, 0.0183, 0.0139, 0.0137,
        0.0092, 0.3138, 0.0773, 0.0418], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,375][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.1584, 0.1188, 0.0062, 0.0097, 0.2660, 0.0029, 0.0061, 0.0094, 0.0067,
        0.0019, 0.2830, 0.0313, 0.0996], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,377][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0401, 0.1844, 0.0110, 0.2237, 0.2312, 0.0114, 0.0216, 0.0248, 0.0038,
        0.0112, 0.0400, 0.0951, 0.1018], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,377][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.1171, 0.0721, 0.0826, 0.0767, 0.0745, 0.0752, 0.0782, 0.0564, 0.0722,
        0.0758, 0.0673, 0.0790, 0.0728], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,378][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0046, 0.0563, 0.0662, 0.0753, 0.0821, 0.0837, 0.0842, 0.1098, 0.0769,
        0.0804, 0.0915, 0.0907, 0.0984], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,378][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0570, 0.0586, 0.0417, 0.1370, 0.0138, 0.0134, 0.0548, 0.0349, 0.0639,
        0.1201, 0.0344, 0.0460, 0.3245], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,379][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1712, 0.0113, 0.0154, 0.0086, 0.1876, 0.0522, 0.1228, 0.1359, 0.0790,
        0.0075, 0.0580, 0.0213, 0.1075, 0.0217], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,379][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3018, 0.0059, 0.0097, 0.0198, 0.0243, 0.1854, 0.0376, 0.0283, 0.0321,
        0.0519, 0.0792, 0.0693, 0.0773, 0.0774], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,379][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1778, 0.4202, 0.0019, 0.0511, 0.0547, 0.0007, 0.0072, 0.0063, 0.0037,
        0.0087, 0.0754, 0.0499, 0.1059, 0.0364], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,380][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0286, 0.0569, 0.0654, 0.0710, 0.0721, 0.0702, 0.0787, 0.0845, 0.0724,
        0.0720, 0.0791, 0.0869, 0.0841, 0.0781], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,381][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0234, 0.1143, 0.0015, 0.0408, 0.1311, 0.0006, 0.0056, 0.0110, 0.0047,
        0.0066, 0.2522, 0.0951, 0.2187, 0.0946], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,387][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1100, 0.0522, 0.0274, 0.0221, 0.0204, 0.0770, 0.0433, 0.0487, 0.0743,
        0.0449, 0.1823, 0.0936, 0.1024, 0.1013], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,391][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0708, 0.0074, 0.0012, 0.0015, 0.1827, 0.0112, 0.0040, 0.0089, 0.0058,
        0.0027, 0.5002, 0.0298, 0.0261, 0.1477], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,392][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1027, 0.0986, 0.0042, 0.0053, 0.1687, 0.0028, 0.0062, 0.0150, 0.0089,
        0.0024, 0.3173, 0.0479, 0.1547, 0.0653], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,392][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4214, 0.0693, 0.0026, 0.0741, 0.0341, 0.0025, 0.0106, 0.0116, 0.0088,
        0.0137, 0.0792, 0.0613, 0.1527, 0.0581], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,392][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1224, 0.0656, 0.0826, 0.0759, 0.0625, 0.0653, 0.0697, 0.0487, 0.0641,
        0.0727, 0.0565, 0.0661, 0.0686, 0.0793], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,393][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0021, 0.0506, 0.0605, 0.0702, 0.0736, 0.0758, 0.0784, 0.1102, 0.0690,
        0.0710, 0.0808, 0.0811, 0.0964, 0.0803], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,393][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0489, 0.0148, 0.1316, 0.0187, 0.0341, 0.2468, 0.0207, 0.0268, 0.0612,
        0.0171, 0.0431, 0.0263, 0.0169, 0.2930], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,394][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:08,395][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13404],
        [  997],
        [ 8484],
        [ 5786],
        [ 4481],
        [ 4121],
        [ 9835],
        [ 4427],
        [ 8498],
        [ 8041],
        [ 4729],
        [ 9335],
        [ 6403],
        [ 8138]], device='cuda:0')
[2024-07-24 10:30:08,397][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13399],
        [15740],
        [ 5421],
        [ 4208],
        [ 1544],
        [ 2627],
        [ 6924],
        [ 1462],
        [ 3593],
        [ 4271],
        [ 1289],
        [ 4556],
        [ 4931],
        [ 2386]], device='cuda:0')
[2024-07-24 10:30:08,399][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10091],
        [10025],
        [10286],
        [11406],
        [12945],
        [24544],
        [24593],
        [22730],
        [23765],
        [25577],
        [25426],
        [26316],
        [25630],
        [26657]], device='cuda:0')
[2024-07-24 10:30:08,402][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[19950],
        [11013],
        [32715],
        [22107],
        [36655],
        [34744],
        [35523],
        [38103],
        [36638],
        [35286],
        [30613],
        [31878],
        [32466],
        [28519]], device='cuda:0')
[2024-07-24 10:30:08,404][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20005],
        [17648],
        [18359],
        [17880],
        [18241],
        [17271],
        [17385],
        [17176],
        [17104],
        [17207],
        [17455],
        [17836],
        [18759],
        [18628]], device='cuda:0')
[2024-07-24 10:30:08,407][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[12896],
        [ 8166],
        [ 9950],
        [ 8310],
        [ 8606],
        [ 9427],
        [10213],
        [10880],
        [10991],
        [10217],
        [ 9596],
        [ 9389],
        [ 9217],
        [ 9324]], device='cuda:0')
[2024-07-24 10:30:08,409][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6412],
        [ 5210],
        [ 5209],
        [ 5725],
        [ 6578],
        [ 9173],
        [ 7623],
        [ 7655],
        [ 7973],
        [ 6958],
        [ 8946],
        [ 8753],
        [ 9622],
        [10663]], device='cuda:0')
[2024-07-24 10:30:08,410][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[22133],
        [29610],
        [26651],
        [25243],
        [21506],
        [21416],
        [20401],
        [18687],
        [19270],
        [20629],
        [20820],
        [21201],
        [21706],
        [22101]], device='cuda:0')
[2024-07-24 10:30:08,411][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[30974],
        [36848],
        [42536],
        [42775],
        [34286],
        [28762],
        [30255],
        [29700],
        [31479],
        [28697],
        [30661],
        [27571],
        [29158],
        [28256]], device='cuda:0')
[2024-07-24 10:30:08,412][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 5727],
        [23853],
        [42807],
        [39290],
        [39574],
        [37580],
        [39985],
        [37935],
        [40345],
        [37478],
        [32696],
        [27261],
        [28605],
        [27536]], device='cuda:0')
[2024-07-24 10:30:08,413][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[19276],
        [19047],
        [18999],
        [38479],
        [38397],
        [14304],
        [33307],
        [38442],
        [29916],
        [40219],
        [15535],
        [34871],
        [37627],
        [13019]], device='cuda:0')
[2024-07-24 10:30:08,414][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[40376],
        [39587],
        [39555],
        [39288],
        [39206],
        [40114],
        [40899],
        [40466],
        [40988],
        [40851],
        [40804],
        [41519],
        [41294],
        [41706]], device='cuda:0')
[2024-07-24 10:30:08,417][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[10670],
        [17186],
        [36203],
        [37568],
        [27057],
        [18282],
        [19818],
        [28496],
        [25345],
        [39557],
        [34328],
        [23206],
        [38593],
        [31936]], device='cuda:0')
[2024-07-24 10:30:08,419][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[27393],
        [  188],
        [ 1130],
        [  863],
        [  912],
        [  859],
        [ 1032],
        [ 1349],
        [  947],
        [  969],
        [ 1004],
        [ 1189],
        [ 1096],
        [ 1153]], device='cuda:0')
[2024-07-24 10:30:08,422][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[39752],
        [ 1023],
        [24054],
        [24018],
        [18070],
        [18996],
        [24868],
        [22246],
        [31029],
        [36490],
        [27809],
        [29202],
        [20615],
        [29674]], device='cuda:0')
[2024-07-24 10:30:08,424][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[16311],
        [15966],
        [20032],
        [17514],
        [14371],
        [ 8300],
        [11088],
        [10290],
        [11287],
        [12758],
        [14075],
        [13258],
        [11567],
        [11049]], device='cuda:0')
[2024-07-24 10:30:08,427][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12151],
        [10666],
        [12186],
        [25384],
        [14994],
        [28787],
        [12532],
        [17594],
        [22563],
        [29241],
        [26559],
        [17924],
        [17728],
        [29244]], device='cuda:0')
[2024-07-24 10:30:08,428][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 1994],
        [24814],
        [24761],
        [25611],
        [26055],
        [27163],
        [27010],
        [26804],
        [27236],
        [28423],
        [25969],
        [27642],
        [28105],
        [29803]], device='cuda:0')
[2024-07-24 10:30:08,429][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 4146],
        [ 6107],
        [ 7244],
        [ 7777],
        [ 7806],
        [ 8368],
        [ 8503],
        [ 9299],
        [ 9575],
        [ 9793],
        [ 9902],
        [ 9921],
        [10150],
        [10279]], device='cuda:0')
[2024-07-24 10:30:08,429][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15687],
        [16212],
        [28035],
        [22520],
        [24803],
        [23917],
        [22828],
        [23025],
        [22423],
        [20492],
        [16974],
        [ 6808],
        [15294],
        [ 8641]], device='cuda:0')
[2024-07-24 10:30:08,431][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[36235],
        [ 6971],
        [ 6245],
        [ 8180],
        [ 7161],
        [ 8524],
        [ 9906],
        [ 8833],
        [ 8283],
        [ 8105],
        [ 9751],
        [ 7780],
        [ 6476],
        [ 6645]], device='cuda:0')
[2024-07-24 10:30:08,432][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[15226],
        [15051],
        [19167],
        [18294],
        [28248],
        [29556],
        [29690],
        [29168],
        [29598],
        [29871],
        [34873],
        [37453],
        [34067],
        [37850]], device='cuda:0')
[2024-07-24 10:30:08,434][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[33689],
        [30766],
        [21888],
        [22896],
        [18271],
        [18134],
        [18157],
        [17979],
        [18066],
        [17859],
        [23070],
        [25452],
        [23073],
        [23761]], device='cuda:0')
[2024-07-24 10:30:08,437][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33868],
        [15486],
        [12353],
        [ 9464],
        [ 9440],
        [ 8894],
        [ 9253],
        [ 7164],
        [ 8633],
        [10106],
        [ 8664],
        [10524],
        [ 7296],
        [13921]], device='cuda:0')
[2024-07-24 10:30:08,439][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[27829],
        [19796],
        [12026],
        [ 7816],
        [ 5495],
        [ 4526],
        [ 4412],
        [ 4382],
        [ 4545],
        [ 5051],
        [ 4982],
        [ 5390],
        [ 5539],
        [ 5898]], device='cuda:0')
[2024-07-24 10:30:08,442][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[2492],
        [1876],
        [1659],
        [1882],
        [1821],
        [2018],
        [2113],
        [2169],
        [2285],
        [2447],
        [2460],
        [2489],
        [2551],
        [2637]], device='cuda:0')
[2024-07-24 10:30:08,444][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8846],
        [ 7400],
        [28903],
        [15491],
        [39554],
        [21209],
        [21722],
        [15555],
        [29775],
        [15968],
        [25824],
        [16927],
        [ 7534],
        [27289]], device='cuda:0')
[2024-07-24 10:30:08,445][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[34012],
        [38434],
        [34480],
        [36881],
        [32275],
        [34333],
        [35563],
        [36159],
        [32925],
        [34055],
        [31241],
        [33933],
        [35907],
        [30871]], device='cuda:0')
[2024-07-24 10:30:08,446][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[15229],
        [46562],
        [35551],
        [27582],
        [44517],
        [44946],
        [42008],
        [43929],
        [35636],
        [25002],
        [37977],
        [36303],
        [36674],
        [36781]], device='cuda:0')
[2024-07-24 10:30:08,447][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[31880],
        [31880],
        [31880],
        [31880],
        [31880],
        [31880],
        [31880],
        [31880],
        [31880],
        [31880],
        [31880],
        [31880],
        [31880],
        [31880]], device='cuda:0')
[2024-07-24 10:30:08,483][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:08,486][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,489][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,492][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,493][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,493][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,493][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,494][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,494][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,494][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,495][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,495][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,495][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,496][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.6415, 0.3585], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,498][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.4292, 0.5708], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,500][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.3704, 0.6296], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,504][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0602, 0.9398], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,506][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([9.9908e-01, 9.1901e-04], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,508][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.3826, 0.6174], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,508][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0440, 0.9560], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,509][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.1225, 0.8775], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,509][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.5302, 0.4698], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,509][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.2176, 0.7824], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,510][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.0166, 0.9834], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,510][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.2048, 0.7952], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,510][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1071, 0.7541, 0.1388], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,511][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0700, 0.5409, 0.3891], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,511][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2323, 0.3698, 0.3979], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,514][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0252, 0.5088, 0.4659], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,520][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9860, 0.0053, 0.0086], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,524][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0027, 0.9489, 0.0484], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,524][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0215, 0.4861, 0.4924], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,524][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0032, 0.9016, 0.0952], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,525][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([2.4844e-04, 9.9875e-01, 1.0009e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,525][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0017, 0.0346, 0.9636], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,525][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0068, 0.5029, 0.4903], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,526][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([1.8520e-04, 9.9495e-01, 4.8620e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,526][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.3721, 0.1845, 0.0309, 0.4125], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,527][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.0743, 0.3346, 0.2571, 0.3340], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,531][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.1541, 0.2576, 0.2788, 0.3095], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,536][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0189, 0.3427, 0.3127, 0.3257], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,537][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.9793, 0.0045, 0.0070, 0.0092], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,538][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0134, 0.7963, 0.0434, 0.1469], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,538][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.0302, 0.3162, 0.2904, 0.3632], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,538][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0624, 0.3806, 0.0989, 0.4580], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,539][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0065, 0.9669, 0.0026, 0.0240], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,539][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.0042, 0.0112, 0.1503, 0.8343], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,539][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.0051, 0.3375, 0.3514, 0.3061], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,540][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0022, 0.9362, 0.0092, 0.0524], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,540][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.0927, 0.2110, 0.0210, 0.4478, 0.2274], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,541][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0499, 0.2733, 0.1883, 0.2680, 0.2205], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,547][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1290, 0.2010, 0.2192, 0.2500, 0.2008], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,551][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0139, 0.2523, 0.2291, 0.2372, 0.2674], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,551][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.9816, 0.0030, 0.0048, 0.0059, 0.0047], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,552][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.0082, 0.5894, 0.0224, 0.0545, 0.3255], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,552][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0134, 0.1951, 0.1736, 0.1741, 0.4438], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,552][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0323, 0.2227, 0.0719, 0.2851, 0.3880], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,553][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0111, 0.8736, 0.0016, 0.0122, 0.1015], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,553][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ went] are: tensor([5.0637e-04, 1.1583e-02, 2.4840e-01, 1.0199e-01, 6.3752e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,553][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0040, 0.2548, 0.2553, 0.2178, 0.2680], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,557][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0017, 0.8623, 0.0024, 0.0155, 0.1180], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,562][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0388, 0.2195, 0.0216, 0.3143, 0.3519, 0.0539], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,564][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0651, 0.1969, 0.1516, 0.2041, 0.1790, 0.2033], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,565][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1132, 0.1632, 0.1725, 0.2049, 0.1709, 0.1754], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,565][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0109, 0.2027, 0.1817, 0.1929, 0.2144, 0.1974], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,566][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.9829, 0.0019, 0.0030, 0.0042, 0.0032, 0.0048], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,566][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0030, 0.5071, 0.0249, 0.1071, 0.3367, 0.0212], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,566][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0091, 0.1736, 0.1536, 0.1687, 0.2786, 0.2163], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,567][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([4.2338e-04, 3.3387e-01, 4.2746e-02, 2.8188e-01, 3.4076e-01, 3.2172e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,567][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0025, 0.6773, 0.0009, 0.0210, 0.2970, 0.0013], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,567][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.2530e-05, 2.6811e-04, 1.3976e-02, 3.0462e-03, 6.9593e-02, 9.1303e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,570][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0053, 0.1967, 0.1951, 0.1747, 0.2024, 0.2258], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,573][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.5837e-04, 8.5222e-01, 1.4125e-03, 2.6799e-02, 1.1678e-01, 2.5328e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,578][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1481, 0.1539, 0.0144, 0.2417, 0.2157, 0.0404, 0.1858],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,579][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0436, 0.1689, 0.1266, 0.1844, 0.1473, 0.1690, 0.1602],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,579][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0962, 0.1392, 0.1439, 0.1710, 0.1440, 0.1458, 0.1600],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,579][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0084, 0.1691, 0.1505, 0.1588, 0.1786, 0.1631, 0.1715],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,580][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.9784, 0.0017, 0.0030, 0.0040, 0.0030, 0.0049, 0.0051],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,580][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0032, 0.4089, 0.0173, 0.0746, 0.4527, 0.0098, 0.0335],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,580][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0080, 0.1423, 0.1281, 0.1465, 0.2415, 0.1454, 0.1882],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,581][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.1773e-03, 2.7482e-01, 3.4354e-02, 2.3877e-01, 4.4669e-01, 3.2137e-04,
        3.8632e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,582][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([2.3613e-03, 8.4068e-01, 1.0486e-03, 1.8520e-02, 1.3350e-01, 6.6323e-04,
        3.2253e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,586][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([2.1155e-04, 1.1322e-03, 2.4669e-02, 1.3760e-02, 2.1587e-01, 6.1028e-01,
        1.3408e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,590][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0032, 0.1567, 0.1545, 0.1376, 0.1654, 0.1843, 0.1982],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,592][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([2.1882e-04, 8.2236e-01, 1.4200e-03, 1.9716e-02, 1.5034e-01, 1.1764e-03,
        4.7648e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,592][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.0897, 0.1195, 0.0130, 0.2358, 0.1890, 0.0290, 0.2201, 0.1039],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,593][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0236, 0.1548, 0.1125, 0.1625, 0.1292, 0.1567, 0.1452, 0.1155],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,593][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0776, 0.1201, 0.1301, 0.1487, 0.1268, 0.1278, 0.1405, 0.1283],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,593][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0062, 0.1391, 0.1261, 0.1314, 0.1501, 0.1362, 0.1463, 0.1645],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,594][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.9652, 0.0024, 0.0038, 0.0054, 0.0040, 0.0068, 0.0068, 0.0056],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,594][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0054, 0.3300, 0.0164, 0.0720, 0.4882, 0.0075, 0.0284, 0.0521],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,594][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0075, 0.1097, 0.1042, 0.1086, 0.1999, 0.1207, 0.1342, 0.2152],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,595][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ station] are: tensor([8.9986e-04, 1.6554e-01, 2.5730e-02, 2.6629e-01, 5.3332e-01, 3.8514e-04,
        4.8019e-03, 3.0324e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,596][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ station] are: tensor([4.0588e-03, 6.9524e-01, 8.8343e-04, 1.7280e-02, 2.6972e-01, 3.9555e-04,
        5.4450e-03, 6.9716e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,600][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.0031, 0.0016, 0.0154, 0.0212, 0.1227, 0.5426, 0.2187, 0.0748],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,606][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0041, 0.1306, 0.1400, 0.1130, 0.1400, 0.1539, 0.1679, 0.1504],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,606][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ station] are: tensor([6.0583e-04, 8.0253e-01, 1.2964e-03, 2.2983e-02, 1.5547e-01, 6.5156e-04,
        4.8876e-03, 1.1568e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,606][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1801, 0.1098, 0.0052, 0.1658, 0.0525, 0.0102, 0.1274, 0.0979, 0.2510],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,607][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0202, 0.1434, 0.0890, 0.1529, 0.1133, 0.1208, 0.1371, 0.1037, 0.1197],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,607][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0748, 0.1057, 0.1137, 0.1303, 0.1128, 0.1136, 0.1226, 0.1100, 0.1165],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,607][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0053, 0.1232, 0.1105, 0.1176, 0.1324, 0.1198, 0.1272, 0.1485, 0.1156],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,608][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9588, 0.0018, 0.0033, 0.0046, 0.0034, 0.0052, 0.0058, 0.0047, 0.0123],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,608][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0033, 0.4247, 0.0110, 0.0715, 0.2726, 0.0062, 0.0441, 0.1392, 0.0273],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,611][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0056, 0.1165, 0.0995, 0.1067, 0.1757, 0.1170, 0.1101, 0.1695, 0.0994],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,615][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([6.4590e-05, 3.1099e-01, 2.5253e-02, 2.8498e-01, 3.5979e-01, 6.2368e-04,
        8.1655e-03, 1.0089e-02, 4.8230e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,618][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([8.9921e-03, 8.2129e-01, 1.3375e-03, 4.3293e-02, 8.1324e-02, 6.6056e-04,
        9.3713e-03, 3.0748e-02, 2.9814e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,619][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0008, 0.0028, 0.0198, 0.0368, 0.1354, 0.2049, 0.2325, 0.0485, 0.3185],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,620][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0019, 0.1149, 0.1170, 0.0991, 0.1166, 0.1371, 0.1515, 0.1383, 0.1237],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,620][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0011, 0.7900, 0.0020, 0.0440, 0.0966, 0.0013, 0.0126, 0.0457, 0.0068],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,620][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.1050, 0.0716, 0.0081, 0.2111, 0.1094, 0.0122, 0.1296, 0.0801, 0.1449,
        0.1279], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,621][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.0218, 0.1293, 0.0815, 0.1247, 0.0965, 0.1169, 0.1171, 0.0928, 0.1144,
        0.1051], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,621][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0578, 0.0951, 0.1035, 0.1155, 0.1008, 0.1008, 0.1111, 0.1032, 0.1047,
        0.1074], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,621][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0045, 0.1108, 0.0991, 0.1032, 0.1175, 0.1060, 0.1136, 0.1295, 0.1030,
        0.1129], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,622][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.9045, 0.0038, 0.0063, 0.0085, 0.0073, 0.0106, 0.0118, 0.0096, 0.0219,
        0.0157], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,623][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0007, 0.2605, 0.0164, 0.0848, 0.5385, 0.0039, 0.0288, 0.0552, 0.0073,
        0.0040], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,627][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.0096, 0.0973, 0.0814, 0.1088, 0.1565, 0.0956, 0.1304, 0.1502, 0.0800,
        0.0901], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,631][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([3.3002e-04, 2.1951e-01, 5.8673e-02, 2.1502e-01, 4.8367e-01, 9.0688e-04,
        1.3678e-02, 7.6562e-03, 7.1638e-05, 4.8215e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,633][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([2.1546e-03, 7.4088e-01, 2.5739e-03, 3.1352e-02, 1.9839e-01, 5.9098e-04,
        6.0688e-03, 1.5735e-02, 9.5120e-04, 1.3090e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,634][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.0191, 0.0239, 0.0188, 0.1135, 0.2498, 0.0874, 0.0591, 0.0382, 0.3110,
        0.0792], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,634][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.0017, 0.1007, 0.1065, 0.0917, 0.1065, 0.1199, 0.1306, 0.1265, 0.1180,
        0.0978], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,634][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([3.8217e-04, 5.7921e-01, 4.6289e-03, 5.2239e-02, 3.0219e-01, 1.2687e-03,
        1.5789e-02, 3.7926e-02, 3.7695e-03, 2.5926e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,635][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0344, 0.0636, 0.0018, 0.1103, 0.0286, 0.0024, 0.0482, 0.0285, 0.0589,
        0.0704, 0.5529], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,635][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0210, 0.1114, 0.0720, 0.1123, 0.0894, 0.1048, 0.1043, 0.0849, 0.1030,
        0.0975, 0.0994], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,635][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0570, 0.0875, 0.0935, 0.1090, 0.0864, 0.0911, 0.1002, 0.0917, 0.0950,
        0.1001, 0.0884], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,639][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0050, 0.0982, 0.0877, 0.0917, 0.1043, 0.0946, 0.1006, 0.1145, 0.0914,
        0.0994, 0.1126], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,644][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.9520, 0.0017, 0.0032, 0.0041, 0.0029, 0.0046, 0.0050, 0.0041, 0.0113,
        0.0077, 0.0034], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,646][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0122, 0.4385, 0.0073, 0.0526, 0.1871, 0.0035, 0.0184, 0.0512, 0.0137,
        0.0051, 0.2105], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,647][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0049, 0.0763, 0.0713, 0.0814, 0.1515, 0.0948, 0.0960, 0.1477, 0.0767,
        0.0690, 0.1304], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,647][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([5.5244e-04, 3.3429e-01, 3.3517e-02, 2.6728e-01, 3.4491e-01, 6.3047e-04,
        8.6589e-03, 6.7856e-03, 5.7740e-05, 5.5239e-04, 2.7667e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,648][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([4.4582e-02, 7.6834e-01, 4.5470e-04, 1.8633e-02, 6.6245e-02, 2.1980e-04,
        3.6098e-03, 9.1643e-03, 2.2385e-03, 2.3566e-03, 8.4154e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,648][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0007, 0.0185, 0.0064, 0.0107, 0.0847, 0.4071, 0.0250, 0.1344, 0.1070,
        0.0765, 0.1291], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,648][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0018, 0.0935, 0.0959, 0.0811, 0.0961, 0.1094, 0.1208, 0.1130, 0.1026,
        0.0882, 0.0977], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,649][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([6.0524e-03, 8.0298e-01, 9.5549e-04, 2.6461e-02, 6.0154e-02, 5.2490e-04,
        5.6122e-03, 1.2248e-02, 4.7831e-03, 3.3323e-03, 7.6896e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,649][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1003, 0.0198, 0.0006, 0.0191, 0.0083, 0.0014, 0.0129, 0.0123, 0.0291,
        0.0219, 0.2869, 0.4875], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,651][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0248, 0.1034, 0.0658, 0.1091, 0.0821, 0.0870, 0.0904, 0.0735, 0.0893,
        0.0938, 0.0895, 0.0914], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,652][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0558, 0.0782, 0.0808, 0.0963, 0.0812, 0.0826, 0.0921, 0.0828, 0.0849,
        0.0893, 0.0828, 0.0933], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,653][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0040, 0.0897, 0.0790, 0.0835, 0.0943, 0.0852, 0.0903, 0.1050, 0.0825,
        0.0901, 0.1017, 0.0948], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,653][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.9515, 0.0014, 0.0026, 0.0035, 0.0028, 0.0043, 0.0044, 0.0038, 0.0100,
        0.0065, 0.0034, 0.0058], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,658][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0170, 0.3140, 0.0048, 0.0409, 0.1455, 0.0031, 0.0142, 0.0402, 0.0135,
        0.0050, 0.2209, 0.1809], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,662][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0056, 0.0802, 0.0697, 0.0796, 0.1321, 0.0811, 0.1023, 0.1172, 0.0717,
        0.0680, 0.0943, 0.0980], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,662][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.2416e-03, 3.2335e-01, 2.5065e-02, 2.2505e-01, 3.9858e-01, 5.3585e-04,
        7.5155e-03, 8.1026e-03, 9.1641e-05, 8.5278e-04, 7.5872e-03, 2.0314e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,662][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([4.8102e-02, 6.8293e-01, 4.3979e-04, 1.3101e-02, 4.5037e-02, 2.0368e-04,
        2.2457e-03, 7.4671e-03, 1.8275e-03, 1.7910e-03, 1.3735e-01, 5.9506e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,663][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0017, 0.0063, 0.0180, 0.0126, 0.0718, 0.2531, 0.0606, 0.0756, 0.2048,
        0.0440, 0.2022, 0.0492], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,663][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0015, 0.0835, 0.0827, 0.0734, 0.0876, 0.0976, 0.1075, 0.1021, 0.0934,
        0.0791, 0.0896, 0.1022], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,663][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([4.5599e-03, 6.2968e-01, 8.9245e-04, 2.0994e-02, 7.5897e-02, 5.3842e-04,
        4.1274e-03, 1.7290e-02, 5.0466e-03, 3.5887e-03, 1.6875e-01, 6.8632e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,664][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.0676, 0.0169, 0.0007, 0.0257, 0.0150, 0.0010, 0.0148, 0.0096, 0.0138,
        0.0123, 0.1940, 0.3359, 0.2927], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,667][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0234, 0.0935, 0.0542, 0.0976, 0.0748, 0.0840, 0.0795, 0.0670, 0.0791,
        0.0805, 0.0816, 0.0812, 0.1036], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,673][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0448, 0.0710, 0.0781, 0.0904, 0.0779, 0.0758, 0.0825, 0.0751, 0.0788,
        0.0829, 0.0780, 0.0849, 0.0797], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,675][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0035, 0.0797, 0.0715, 0.0746, 0.0856, 0.0769, 0.0831, 0.0934, 0.0750,
        0.0821, 0.0927, 0.0877, 0.0942], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,675][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.9135, 0.0024, 0.0040, 0.0060, 0.0048, 0.0074, 0.0075, 0.0068, 0.0152,
        0.0111, 0.0063, 0.0101, 0.0049], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,676][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.0180, 0.3080, 0.0065, 0.0442, 0.2805, 0.0019, 0.0114, 0.0345, 0.0036,
        0.0023, 0.0775, 0.0690, 0.1427], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,676][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0073, 0.0673, 0.0671, 0.0681, 0.1203, 0.0781, 0.0861, 0.1303, 0.0673,
        0.0544, 0.1000, 0.0688, 0.0847], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,676][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([3.8607e-03, 2.4717e-01, 2.8635e-02, 2.9319e-01, 3.8586e-01, 9.1320e-04,
        9.8884e-03, 1.0781e-02, 1.2373e-04, 1.3454e-03, 4.6954e-03, 2.7646e-03,
        1.0767e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,677][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([9.8605e-02, 7.0145e-01, 6.7286e-04, 2.3998e-02, 4.6548e-02, 1.1512e-04,
        1.9868e-03, 3.9011e-03, 6.2723e-04, 1.3620e-03, 3.4262e-02, 2.8703e-02,
        5.7766e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,677][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([0.0182, 0.0220, 0.0364, 0.0701, 0.1456, 0.0402, 0.0918, 0.0140, 0.1814,
        0.0548, 0.2149, 0.0851, 0.0253], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,678][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0021, 0.0764, 0.0815, 0.0662, 0.0786, 0.0910, 0.0971, 0.0891, 0.0888,
        0.0729, 0.0797, 0.0938, 0.0829], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,679][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([1.1066e-02, 5.9156e-01, 1.7722e-03, 2.1559e-02, 1.4294e-01, 4.5347e-04,
        5.0143e-03, 1.2211e-02, 2.1747e-03, 1.8120e-03, 6.7961e-02, 3.6395e-02,
        1.0508e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,683][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.9736e-02, 1.4805e-02, 2.8169e-04, 1.5010e-02, 4.5142e-03, 4.6977e-04,
        6.6297e-03, 6.0783e-03, 1.5188e-02, 1.5076e-02, 1.5434e-01, 2.7343e-01,
        3.0336e-01, 1.1109e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,687][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0302, 0.0836, 0.0508, 0.0889, 0.0707, 0.0665, 0.0696, 0.0587, 0.0749,
        0.0815, 0.0780, 0.0752, 0.0950, 0.0765], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,689][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0477, 0.0657, 0.0696, 0.0810, 0.0697, 0.0719, 0.0784, 0.0703, 0.0732,
        0.0755, 0.0720, 0.0802, 0.0751, 0.0699], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,689][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0035, 0.0747, 0.0654, 0.0694, 0.0784, 0.0706, 0.0747, 0.0868, 0.0680,
        0.0742, 0.0839, 0.0784, 0.0867, 0.0853], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,689][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8989, 0.0028, 0.0042, 0.0070, 0.0050, 0.0074, 0.0076, 0.0071, 0.0161,
        0.0118, 0.0063, 0.0099, 0.0050, 0.0109], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,690][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0208, 0.1842, 0.0025, 0.0253, 0.0694, 0.0015, 0.0073, 0.0212, 0.0069,
        0.0029, 0.1139, 0.0919, 0.2738, 0.1784], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,690][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0041, 0.0699, 0.0567, 0.0661, 0.1103, 0.0796, 0.0742, 0.1095, 0.0590,
        0.0560, 0.0807, 0.0665, 0.0822, 0.0853], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,691][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([7.7700e-03, 3.7121e-01, 2.2860e-02, 3.3575e-01, 2.3110e-01, 3.5778e-04,
        5.3495e-03, 5.6280e-03, 9.5816e-05, 1.1678e-03, 5.7815e-03, 1.6533e-03,
        7.9847e-03, 3.3017e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,691][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.6217e-01, 3.5377e-01, 4.3441e-04, 1.1556e-02, 5.2456e-02, 1.5141e-04,
        2.2405e-03, 5.2024e-03, 2.0086e-03, 2.1708e-03, 1.1389e-01, 6.3137e-02,
        1.6915e-01, 6.1661e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,694][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0017, 0.0030, 0.0040, 0.0027, 0.0332, 0.2443, 0.0774, 0.0672, 0.1180,
        0.0201, 0.2477, 0.0950, 0.0112, 0.0746], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,700][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0021, 0.0717, 0.0707, 0.0625, 0.0725, 0.0803, 0.0894, 0.0814, 0.0773,
        0.0677, 0.0731, 0.0859, 0.0788, 0.0866], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,702][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.1125e-02, 4.1798e-01, 6.8667e-04, 1.7232e-02, 5.0579e-02, 3.5114e-04,
        3.1597e-03, 1.1150e-02, 4.2366e-03, 2.8481e-03, 8.8643e-02, 5.8545e-02,
        1.9806e-01, 1.3540e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,740][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:08,744][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,746][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,748][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,748][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,749][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,749][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,749][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,750][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,750][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,750][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,752][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,754][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:08,758][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.2803, 0.7197], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,762][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0982, 0.9018], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,762][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.4606, 0.5394], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,763][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.7070, 0.2930], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,763][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.9975, 0.0025], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,763][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.1420, 0.8580], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,763][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.9778, 0.0222], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,764][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.2098, 0.7902], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,764][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.5302, 0.4698], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,764][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0017, 0.9983], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,765][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.9668, 0.0332], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,765][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.2048, 0.7952], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:08,768][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0010, 0.9927, 0.0063], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,772][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.3613e-05, 9.8652e-01, 1.3440e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,776][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1203, 0.7180, 0.1617], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,776][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0615, 0.8548, 0.0837], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,777][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9654, 0.0155, 0.0191], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,777][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([6.4261e-04, 9.7701e-01, 2.2350e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,777][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.9316, 0.0340, 0.0344], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,777][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0023, 0.9653, 0.0324], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,778][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([2.4844e-04, 9.9875e-01, 1.0009e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,778][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0006, 0.5206, 0.4787], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,778][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6845, 0.1300, 0.1855], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,780][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.8520e-04, 9.9495e-01, 4.8620e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:08,785][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.0149, 0.8814, 0.0100, 0.0937], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,788][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([6.5305e-04, 9.5364e-01, 9.7621e-03, 3.5947e-02], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,789][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.1366, 0.4848, 0.1144, 0.2641], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,790][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.1656, 0.6004, 0.0597, 0.1743], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,790][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.9286, 0.0153, 0.0250, 0.0311], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,790][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0031, 0.8693, 0.0250, 0.1027], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,791][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.7904, 0.0442, 0.0190, 0.1464], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,791][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0140, 0.8557, 0.0454, 0.0849], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,791][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0065, 0.9669, 0.0026, 0.0240], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,792][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.0008, 0.3381, 0.2481, 0.4130], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,792][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.5757, 0.1091, 0.1827, 0.1326], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,793][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0022, 0.9362, 0.0092, 0.0524], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:08,799][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.0062, 0.8964, 0.0040, 0.0446, 0.0488], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,803][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0011, 0.6251, 0.0120, 0.0153, 0.3465], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,803][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.2154, 0.3792, 0.0905, 0.2126, 0.1023], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,804][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1428, 0.4491, 0.0426, 0.1016, 0.2639], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,804][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.9796, 0.0040, 0.0041, 0.0044, 0.0078], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,804][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.0035, 0.7634, 0.0160, 0.0503, 0.1669], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,805][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.9154, 0.0164, 0.0110, 0.0325, 0.0247], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,805][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0129, 0.7615, 0.0266, 0.0535, 0.1455], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,805][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0111, 0.8736, 0.0016, 0.0122, 0.1015], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,809][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.0022, 0.1916, 0.3936, 0.0686, 0.3441], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,814][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.6970, 0.0524, 0.0978, 0.0464, 0.1064], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,816][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0017, 0.8623, 0.0024, 0.0155, 0.1180], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:08,817][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0032, 0.8625, 0.0029, 0.0612, 0.0681, 0.0021], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,817][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.9380e-04, 7.3383e-01, 8.8959e-03, 4.3085e-02, 2.0727e-01, 6.3206e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,817][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3482, 0.2527, 0.0809, 0.1591, 0.0818, 0.0772], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,818][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1899, 0.3835, 0.0278, 0.1778, 0.1887, 0.0322], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,818][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.9874, 0.0014, 0.0012, 0.0029, 0.0034, 0.0037], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,818][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0017, 0.7185, 0.0146, 0.0893, 0.1670, 0.0089], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,819][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.9500, 0.0050, 0.0056, 0.0164, 0.0074, 0.0156], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,819][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0103, 0.7248, 0.0187, 0.0928, 0.1329, 0.0205], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,822][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0025, 0.6773, 0.0009, 0.0210, 0.2970, 0.0013], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,825][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.8970e-04, 5.9887e-02, 6.9579e-02, 1.3602e-02, 6.2665e-02, 7.9368e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,830][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.9034, 0.0085, 0.0157, 0.0111, 0.0155, 0.0457], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,831][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.5837e-04, 8.5222e-01, 1.4125e-03, 2.6799e-02, 1.1678e-01, 2.5328e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:08,831][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0062, 0.8070, 0.0045, 0.0607, 0.1026, 0.0024, 0.0165],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,831][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.8689e-04, 6.7259e-01, 6.6234e-03, 3.8616e-02, 2.7271e-01, 2.8693e-03,
        6.3087e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,832][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1744, 0.2958, 0.0792, 0.1943, 0.0982, 0.0680, 0.0902],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,832][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0973, 0.3949, 0.0272, 0.1251, 0.2850, 0.0244, 0.0462],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,832][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.9577, 0.0022, 0.0030, 0.0044, 0.0098, 0.0105, 0.0124],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,833][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0016, 0.6332, 0.0140, 0.0742, 0.2499, 0.0055, 0.0216],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,836][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.8963, 0.0083, 0.0116, 0.0284, 0.0178, 0.0218, 0.0159],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,841][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0050, 0.6993, 0.0166, 0.0556, 0.1852, 0.0143, 0.0240],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,843][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([2.3613e-03, 8.4068e-01, 1.0486e-03, 1.8520e-02, 1.3350e-01, 6.6323e-04,
        3.2253e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,844][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0012, 0.0913, 0.1349, 0.0313, 0.1220, 0.4593, 0.1600],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,844][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.6881, 0.0225, 0.0368, 0.0238, 0.0419, 0.1046, 0.0822],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,845][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.1882e-04, 8.2236e-01, 1.4200e-03, 1.9716e-02, 1.5034e-01, 1.1764e-03,
        4.7648e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:08,845][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.0062, 0.7578, 0.0043, 0.0634, 0.1283, 0.0019, 0.0217, 0.0163],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,845][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([4.2121e-04, 5.2169e-01, 7.1261e-03, 2.6360e-02, 4.1698e-01, 2.3785e-03,
        7.2402e-03, 1.7813e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,846][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.1276, 0.2882, 0.0786, 0.1719, 0.1167, 0.0622, 0.0742, 0.0807],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,846][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0646, 0.4275, 0.0255, 0.1187, 0.2736, 0.0169, 0.0431, 0.0300],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,846][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.9371, 0.0032, 0.0034, 0.0071, 0.0122, 0.0150, 0.0165, 0.0054],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,849][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0029, 0.5545, 0.0130, 0.0768, 0.3038, 0.0039, 0.0189, 0.0263],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,854][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.9148, 0.0062, 0.0096, 0.0223, 0.0128, 0.0170, 0.0139, 0.0034],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,857][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0051, 0.6590, 0.0129, 0.0636, 0.1950, 0.0133, 0.0235, 0.0277],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,858][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([4.0588e-03, 6.9524e-01, 8.8343e-04, 1.7280e-02, 2.6972e-01, 3.9555e-04,
        5.4450e-03, 6.9716e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,858][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.0010, 0.1154, 0.1782, 0.0443, 0.0794, 0.3296, 0.1844, 0.0678],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,858][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.6685, 0.0184, 0.0415, 0.0177, 0.0406, 0.0918, 0.0723, 0.0491],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,859][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([6.0583e-04, 8.0253e-01, 1.2964e-03, 2.2983e-02, 1.5547e-01, 6.5156e-04,
        4.8876e-03, 1.1568e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:08,859][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0199, 0.7010, 0.0052, 0.1001, 0.0605, 0.0021, 0.0348, 0.0567, 0.0198],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,859][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0007, 0.6385, 0.0108, 0.0643, 0.2098, 0.0042, 0.0171, 0.0497, 0.0049],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,860][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1485, 0.2035, 0.0685, 0.1833, 0.0797, 0.0430, 0.0816, 0.1039, 0.0880],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,864][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1095, 0.2843, 0.0251, 0.1532, 0.2514, 0.0233, 0.0690, 0.0589, 0.0253],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,869][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9509, 0.0016, 0.0026, 0.0048, 0.0085, 0.0065, 0.0102, 0.0029, 0.0121],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,871][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0029, 0.5674, 0.0155, 0.0912, 0.1863, 0.0062, 0.0387, 0.0800, 0.0119],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,871][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.8130, 0.0173, 0.0130, 0.0483, 0.0187, 0.0240, 0.0147, 0.0046, 0.0465],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,871][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0093, 0.6164, 0.0148, 0.0979, 0.1351, 0.0142, 0.0330, 0.0606, 0.0186],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,872][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([8.9921e-03, 8.2129e-01, 1.3375e-03, 4.3293e-02, 8.1324e-02, 6.6056e-04,
        9.3713e-03, 3.0748e-02, 2.9814e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,872][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0007, 0.1250, 0.1319, 0.0432, 0.1174, 0.1715, 0.2298, 0.0703, 0.1101],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,872][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5078, 0.0196, 0.0403, 0.0279, 0.0388, 0.1100, 0.1018, 0.0734, 0.0803],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,873][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0011, 0.7900, 0.0020, 0.0440, 0.0966, 0.0013, 0.0126, 0.0457, 0.0068],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:08,873][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.0085, 0.6216, 0.0107, 0.1134, 0.1435, 0.0026, 0.0353, 0.0469, 0.0090,
        0.0085], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,874][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([2.4922e-04, 6.0346e-01, 1.0815e-02, 4.9570e-02, 2.9386e-01, 2.0364e-03,
        1.2465e-02, 2.5155e-02, 1.1898e-03, 1.1974e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,878][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0813, 0.2454, 0.0858, 0.1542, 0.1130, 0.0441, 0.0861, 0.0947, 0.0606,
        0.0347], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,883][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.0481, 0.3352, 0.0352, 0.1491, 0.2764, 0.0165, 0.0537, 0.0455, 0.0168,
        0.0236], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,884][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.7485, 0.0081, 0.0124, 0.0184, 0.0509, 0.0337, 0.0531, 0.0173, 0.0433,
        0.0143], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,885][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0010, 0.4641, 0.0213, 0.1067, 0.3207, 0.0050, 0.0295, 0.0423, 0.0048,
        0.0044], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,885][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.7207, 0.0222, 0.0120, 0.0755, 0.0174, 0.0207, 0.0146, 0.0065, 0.0409,
        0.0696], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,886][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0045, 0.5389, 0.0256, 0.0750, 0.2340, 0.0129, 0.0379, 0.0497, 0.0100,
        0.0114], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,886][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([2.1546e-03, 7.4088e-01, 2.5739e-03, 3.1352e-02, 1.9839e-01, 5.9098e-04,
        6.0688e-03, 1.5735e-02, 9.5120e-04, 1.3090e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,886][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.0003, 0.1092, 0.0984, 0.0682, 0.1773, 0.1321, 0.2441, 0.0537, 0.1014,
        0.0154], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,887][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.3254, 0.0379, 0.0560, 0.0514, 0.0583, 0.1101, 0.1095, 0.1037, 0.0648,
        0.0830], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,888][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([3.8217e-04, 5.7921e-01, 4.6289e-03, 5.2239e-02, 3.0219e-01, 1.2687e-03,
        1.5789e-02, 3.7926e-02, 3.7695e-03, 2.5926e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:08,891][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([1.9148e-02, 7.5228e-01, 1.6644e-03, 5.3156e-02, 2.9704e-02, 6.0509e-04,
        1.1280e-02, 1.3335e-02, 6.1907e-03, 5.6971e-03, 1.0694e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,896][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0022, 0.6245, 0.0046, 0.0205, 0.2297, 0.0021, 0.0092, 0.0298, 0.0047,
        0.0019, 0.0707], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,898][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1971, 0.2059, 0.0501, 0.1248, 0.0600, 0.0466, 0.0660, 0.0699, 0.0804,
        0.0369, 0.0624], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,898][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.3056, 0.2766, 0.0214, 0.0884, 0.1114, 0.0115, 0.0363, 0.0215, 0.0182,
        0.0216, 0.0877], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,898][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.9655, 0.0016, 0.0019, 0.0035, 0.0048, 0.0045, 0.0056, 0.0017, 0.0069,
        0.0023, 0.0017], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,899][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0111, 0.6036, 0.0093, 0.0684, 0.1351, 0.0029, 0.0172, 0.0315, 0.0085,
        0.0056, 0.1069], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,899][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.8666, 0.0083, 0.0067, 0.0231, 0.0101, 0.0124, 0.0077, 0.0019, 0.0229,
        0.0234, 0.0169], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,899][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0238, 0.5546, 0.0103, 0.0503, 0.0903, 0.0110, 0.0208, 0.0296, 0.0153,
        0.0179, 0.1761], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,900][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([4.4582e-02, 7.6834e-01, 4.5470e-04, 1.8633e-02, 6.6245e-02, 2.1980e-04,
        3.6098e-03, 9.1643e-03, 2.2385e-03, 2.3566e-03, 8.4154e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,900][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0014, 0.1675, 0.1179, 0.0169, 0.0956, 0.3125, 0.0714, 0.1336, 0.0390,
        0.0186, 0.0257], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,903][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.6955, 0.0117, 0.0261, 0.0150, 0.0217, 0.0457, 0.0408, 0.0312, 0.0460,
        0.0279, 0.0385], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,906][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([6.0524e-03, 8.0298e-01, 9.5549e-04, 2.6461e-02, 6.0154e-02, 5.2490e-04,
        5.6122e-03, 1.2248e-02, 4.7831e-03, 3.3323e-03, 7.6896e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:08,911][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1123, 0.4472, 0.0022, 0.0425, 0.0354, 0.0010, 0.0125, 0.0213, 0.0142,
        0.0095, 0.1982, 0.1037], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,912][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0074, 0.5786, 0.0055, 0.0333, 0.1811, 0.0021, 0.0073, 0.0303, 0.0043,
        0.0035, 0.0920, 0.0545], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,912][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2085, 0.1734, 0.0536, 0.1099, 0.0603, 0.0394, 0.0593, 0.0651, 0.0731,
        0.0349, 0.0580, 0.0643], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,912][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.3613, 0.1845, 0.0137, 0.0736, 0.1007, 0.0090, 0.0268, 0.0191, 0.0164,
        0.0215, 0.1075, 0.0660], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,913][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([9.6276e-01, 9.0749e-04, 1.4268e-03, 2.2813e-03, 5.2774e-03, 3.8420e-03,
        5.3801e-03, 1.6571e-03, 6.4953e-03, 1.9090e-03, 2.4221e-03, 5.6375e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,913][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0125, 0.4746, 0.0094, 0.0721, 0.1417, 0.0036, 0.0188, 0.0325, 0.0105,
        0.0075, 0.1301, 0.0867], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,914][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.8824, 0.0049, 0.0055, 0.0162, 0.0074, 0.0101, 0.0065, 0.0018, 0.0228,
        0.0176, 0.0116, 0.0134], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,917][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0308, 0.4044, 0.0086, 0.0452, 0.1067, 0.0072, 0.0173, 0.0275, 0.0129,
        0.0172, 0.2229, 0.0992], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,920][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([4.8102e-02, 6.8293e-01, 4.3979e-04, 1.3101e-02, 4.5037e-02, 2.0368e-04,
        2.2457e-03, 7.4671e-03, 1.8275e-03, 1.7910e-03, 1.3735e-01, 5.9506e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,925][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0010, 0.0866, 0.1583, 0.0190, 0.0675, 0.2320, 0.1087, 0.0777, 0.0628,
        0.0151, 0.0941, 0.0771], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,926][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.6396, 0.0084, 0.0194, 0.0130, 0.0220, 0.0558, 0.0467, 0.0380, 0.0430,
        0.0246, 0.0506, 0.0390], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,927][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.5599e-03, 6.2968e-01, 8.9245e-04, 2.0994e-02, 7.5897e-02, 5.3842e-04,
        4.1274e-03, 1.7290e-02, 5.0466e-03, 3.5887e-03, 1.6875e-01, 6.8632e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:08,927][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.0617, 0.3668, 0.0035, 0.0520, 0.0907, 0.0008, 0.0166, 0.0196, 0.0057,
        0.0053, 0.1431, 0.0800, 0.1542], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,928][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0090, 0.4134, 0.0093, 0.0325, 0.3428, 0.0017, 0.0070, 0.0205, 0.0025,
        0.0021, 0.0372, 0.0390, 0.0831], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,928][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0622, 0.2006, 0.0783, 0.1290, 0.1079, 0.0380, 0.0748, 0.0849, 0.0525,
        0.0251, 0.0567, 0.0546, 0.0354], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,928][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.1729, 0.2521, 0.0192, 0.1192, 0.1582, 0.0080, 0.0301, 0.0256, 0.0105,
        0.0193, 0.0641, 0.0590, 0.0617], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,929][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.8343, 0.0042, 0.0065, 0.0111, 0.0222, 0.0148, 0.0203, 0.0084, 0.0198,
        0.0086, 0.0118, 0.0206, 0.0174], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,929][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.0154, 0.4434, 0.0126, 0.0739, 0.2276, 0.0026, 0.0159, 0.0277, 0.0045,
        0.0046, 0.0550, 0.0417, 0.0751], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,932][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.8267, 0.0074, 0.0090, 0.0248, 0.0128, 0.0138, 0.0105, 0.0029, 0.0245,
        0.0231, 0.0159, 0.0149, 0.0137], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,938][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0210, 0.4307, 0.0116, 0.0618, 0.1191, 0.0068, 0.0200, 0.0288, 0.0075,
        0.0131, 0.1022, 0.0707, 0.1068], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,940][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([9.8605e-02, 7.0145e-01, 6.7286e-04, 2.3998e-02, 4.6548e-02, 1.1512e-04,
        1.9868e-03, 3.9011e-03, 6.2723e-04, 1.3620e-03, 3.4262e-02, 2.8703e-02,
        5.7766e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,940][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.0010, 0.0851, 0.1502, 0.0474, 0.0738, 0.0841, 0.1404, 0.0525, 0.0638,
        0.0240, 0.0967, 0.1397, 0.0413], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,941][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.4636, 0.0147, 0.0380, 0.0201, 0.0281, 0.0712, 0.0662, 0.0645, 0.0423,
        0.0395, 0.0665, 0.0631, 0.0223], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,941][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([1.1066e-02, 5.9156e-01, 1.7722e-03, 2.1559e-02, 1.4294e-01, 4.5347e-04,
        5.0143e-03, 1.2211e-02, 2.1747e-03, 1.8120e-03, 6.7961e-02, 3.6395e-02,
        1.0508e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:08,942][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1430, 0.3360, 0.0015, 0.0384, 0.0233, 0.0005, 0.0076, 0.0114, 0.0094,
        0.0079, 0.1019, 0.0605, 0.1747, 0.0840], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,942][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0178, 0.4093, 0.0065, 0.0407, 0.1100, 0.0016, 0.0080, 0.0214, 0.0064,
        0.0052, 0.0627, 0.0706, 0.1381, 0.1015], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,942][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2414, 0.1214, 0.0463, 0.0863, 0.0455, 0.0324, 0.0465, 0.0596, 0.0628,
        0.0331, 0.0505, 0.0540, 0.0563, 0.0638], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,943][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4395, 0.1212, 0.0093, 0.0576, 0.0602, 0.0056, 0.0178, 0.0129, 0.0132,
        0.0174, 0.0578, 0.0478, 0.0726, 0.0670], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,946][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.9585, 0.0013, 0.0014, 0.0031, 0.0048, 0.0032, 0.0042, 0.0016, 0.0052,
        0.0020, 0.0019, 0.0041, 0.0028, 0.0059], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,952][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0185, 0.3261, 0.0086, 0.0653, 0.1049, 0.0030, 0.0161, 0.0260, 0.0092,
        0.0075, 0.0973, 0.0666, 0.1537, 0.0972], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,954][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.8765, 0.0046, 0.0043, 0.0155, 0.0062, 0.0111, 0.0047, 0.0016, 0.0178,
        0.0181, 0.0097, 0.0097, 0.0063, 0.0138], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,954][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0649, 0.3809, 0.0066, 0.0518, 0.0562, 0.0041, 0.0117, 0.0181, 0.0100,
        0.0187, 0.1292, 0.0622, 0.1188, 0.0668], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,954][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.6217e-01, 3.5377e-01, 4.3441e-04, 1.1556e-02, 5.2456e-02, 1.5141e-04,
        2.2405e-03, 5.2024e-03, 2.0086e-03, 2.1708e-03, 1.1389e-01, 6.3137e-02,
        1.6915e-01, 6.1661e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,955][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0004, 0.0334, 0.0572, 0.0110, 0.0431, 0.1806, 0.1082, 0.0446, 0.0705,
        0.0202, 0.1012, 0.1364, 0.0424, 0.1508], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,955][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.5928, 0.0096, 0.0178, 0.0143, 0.0179, 0.0506, 0.0393, 0.0270, 0.0370,
        0.0282, 0.0407, 0.0399, 0.0186, 0.0664], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,956][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.1125e-02, 4.1798e-01, 6.8667e-04, 1.7232e-02, 5.0579e-02, 3.5114e-04,
        3.1597e-03, 1.1150e-02, 4.2366e-03, 2.8481e-03, 8.8643e-02, 5.8545e-02,
        1.9806e-01, 1.3540e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:08,957][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:08,958][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10216],
        [ 6339],
        [ 3435],
        [ 4480],
        [ 2222],
        [ 1230],
        [ 3401],
        [  903],
        [ 3096],
        [ 2804],
        [ 2008],
        [ 3090],
        [ 2707],
        [ 2620]], device='cuda:0')
[2024-07-24 10:30:08,959][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12377],
        [ 5830],
        [ 7472],
        [ 7279],
        [ 5981],
        [ 5116],
        [10698],
        [ 4209],
        [ 9070],
        [ 7849],
        [ 5963],
        [ 9134],
        [ 6654],
        [ 8081]], device='cuda:0')
[2024-07-24 10:30:08,961][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[18728],
        [39605],
        [44438],
        [45680],
        [46296],
        [45690],
        [45335],
        [46026],
        [46971],
        [47202],
        [46437],
        [44093],
        [44298],
        [44448]], device='cuda:0')
[2024-07-24 10:30:08,964][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[14085],
        [10624],
        [ 9037],
        [10445],
        [10825],
        [10119],
        [ 9563],
        [ 9473],
        [ 9098],
        [ 9280],
        [ 9734],
        [ 9905],
        [10184],
        [10367]], device='cuda:0')
[2024-07-24 10:30:08,966][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[1048],
        [1477],
        [2238],
        [2233],
        [2124],
        [2165],
        [2333],
        [2142],
        [2383],
        [2310],
        [2368],
        [2426],
        [2498],
        [2498]], device='cuda:0')
[2024-07-24 10:30:08,969][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 6181],
        [ 9287],
        [11556],
        [11267],
        [12172],
        [12359],
        [12768],
        [12369],
        [12439],
        [11639],
        [11590],
        [11569],
        [11324],
        [11299]], device='cuda:0')
[2024-07-24 10:30:08,971][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[19806],
        [19951],
        [21167],
        [22172],
        [21936],
        [21666],
        [21921],
        [23208],
        [23293],
        [28065],
        [24109],
        [24018],
        [27295],
        [27996]], device='cuda:0')
[2024-07-24 10:30:08,972][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[5045],
        [6662],
        [7461],
        [7424],
        [5262],
        [5199],
        [4621],
        [4486],
        [5269],
        [4312],
        [5687],
        [5735],
        [5380],
        [6037]], device='cuda:0')
[2024-07-24 10:30:08,973][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[5277],
        [8692],
        [6377],
        [7581],
        [5687],
        [5491],
        [5478],
        [4892],
        [4951],
        [5363],
        [5158],
        [5102],
        [5169],
        [5046]], device='cuda:0')
[2024-07-24 10:30:08,974][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 5521],
        [38740],
        [38532],
        [33117],
        [28419],
        [30418],
        [28876],
        [26697],
        [29747],
        [27527],
        [30170],
        [29601],
        [28595],
        [31432]], device='cuda:0')
[2024-07-24 10:30:08,975][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15308],
        [32363],
        [38383],
        [38312],
        [37229],
        [34511],
        [36863],
        [34814],
        [37094],
        [35739],
        [36669],
        [35731],
        [36177],
        [31646]], device='cuda:0')
[2024-07-24 10:30:08,976][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22773],
        [50131],
        [13492],
        [34976],
        [10959],
        [ 4303],
        [ 5031],
        [ 4849],
        [ 7965],
        [16123],
        [ 8030],
        [ 9037],
        [16306],
        [ 8970]], device='cuda:0')
[2024-07-24 10:30:08,978][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 724],
        [3701],
        [1671],
        [2113],
        [1903],
        [1657],
        [1536],
        [1615],
        [1447],
        [1633],
        [1605],
        [1536],
        [1635],
        [1564]], device='cuda:0')
[2024-07-24 10:30:08,981][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[39977],
        [28903],
        [27150],
        [27031],
        [27782],
        [27762],
        [27933],
        [28007],
        [27843],
        [28792],
        [26952],
        [25653],
        [26447],
        [21857]], device='cuda:0')
[2024-07-24 10:30:08,983][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[41275],
        [47466],
        [45487],
        [44952],
        [46688],
        [45753],
        [45848],
        [45986],
        [44213],
        [43160],
        [45614],
        [46094],
        [46089],
        [44968]], device='cuda:0')
[2024-07-24 10:30:08,986][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 9939],
        [14968],
        [18388],
        [18410],
        [18704],
        [18892],
        [19277],
        [19670],
        [19599],
        [20482],
        [18948],
        [19857],
        [22307],
        [19427]], device='cuda:0')
[2024-07-24 10:30:08,988][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 5670],
        [22786],
        [22726],
        [22475],
        [16315],
        [18354],
        [17311],
        [14819],
        [17012],
        [16342],
        [16169],
        [16397],
        [14650],
        [16376]], device='cuda:0')
[2024-07-24 10:30:08,989][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 9387],
        [15768],
        [15638],
        [13497],
        [14574],
        [14405],
        [14931],
        [14852],
        [13088],
        [14215],
        [13039],
        [12443],
        [14062],
        [11112]], device='cuda:0')
[2024-07-24 10:30:08,990][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11201],
        [ 9420],
        [10295],
        [11012],
        [ 6297],
        [ 7058],
        [ 5635],
        [ 5689],
        [ 4799],
        [ 5126],
        [ 5039],
        [ 3943],
        [ 4880],
        [ 3668]], device='cuda:0')
[2024-07-24 10:30:08,991][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[11518],
        [11386],
        [10724],
        [11163],
        [11385],
        [11592],
        [11921],
        [12233],
        [11907],
        [13092],
        [11694],
        [11805],
        [11760],
        [11857]], device='cuda:0')
[2024-07-24 10:30:08,992][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 6577],
        [47289],
        [47773],
        [47867],
        [47136],
        [47179],
        [46582],
        [46251],
        [47104],
        [46090],
        [47426],
        [47174],
        [47210],
        [47699]], device='cuda:0')
[2024-07-24 10:30:08,993][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[34050],
        [34291],
        [27571],
        [28241],
        [32712],
        [32520],
        [29489],
        [29954],
        [28214],
        [32878],
        [34182],
        [33757],
        [30828],
        [33417]], device='cuda:0')
[2024-07-24 10:30:08,995][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[33343],
        [34043],
        [32616],
        [31320],
        [31388],
        [30545],
        [30926],
        [30859],
        [30192],
        [30565],
        [26788],
        [23859],
        [25441],
        [23817]], device='cuda:0')
[2024-07-24 10:30:08,998][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[18746],
        [24465],
        [30524],
        [30475],
        [31078],
        [32813],
        [31333],
        [32380],
        [30252],
        [31577],
        [29951],
        [30293],
        [30751],
        [32186]], device='cuda:0')
[2024-07-24 10:30:09,000][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[17894],
        [ 5597],
        [10258],
        [ 6878],
        [ 8126],
        [11015],
        [ 9906],
        [10122],
        [ 8566],
        [ 7525],
        [ 8938],
        [ 7605],
        [ 6252],
        [ 5777]], device='cuda:0')
[2024-07-24 10:30:09,003][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7339],
        [ 9778],
        [16782],
        [15911],
        [12889],
        [11111],
        [11964],
        [12090],
        [12097],
        [12448],
        [11433],
        [11851],
        [12489],
        [12832]], device='cuda:0')
[2024-07-24 10:30:09,005][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5951],
        [20273],
        [20489],
        [19363],
        [21920],
        [21670],
        [22273],
        [22198],
        [20384],
        [22495],
        [19817],
        [16885],
        [19316],
        [18527]], device='cuda:0')
[2024-07-24 10:30:09,006][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[44350],
        [25778],
        [23427],
        [25860],
        [27367],
        [26815],
        [28326],
        [28230],
        [30029],
        [29327],
        [29999],
        [32087],
        [31364],
        [32523]], device='cuda:0')
[2024-07-24 10:30:09,007][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32783],
        [13753],
        [10458],
        [10991],
        [10015],
        [ 7227],
        [ 8951],
        [ 9881],
        [11437],
        [11791],
        [ 9476],
        [ 9840],
        [11239],
        [11554]], device='cuda:0')
[2024-07-24 10:30:09,008][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9049],
        [9049],
        [9049],
        [9049],
        [9049],
        [9049],
        [9049],
        [9049],
        [9049],
        [9049],
        [9049],
        [9049],
        [9049],
        [9049]], device='cuda:0')
[2024-07-24 10:30:09,046][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:09,047][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,047][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,047][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,048][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,048][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,048][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,049][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,049][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,049][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,049][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,050][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,050][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,050][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.8988, 0.1012], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,051][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.9985, 0.0015], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,051][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.7122, 0.2878], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,051][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.4728, 0.5272], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,052][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0064, 0.9936], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,053][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.9773, 0.0227], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,055][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.4732, 0.5268], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,056][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([9.9996e-01, 4.4602e-05], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,056][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0045, 0.9955], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,057][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.9990, 0.0010], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,057][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.9984, 0.0016], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,057][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.9967, 0.0033], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,058][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([1.3007e-02, 9.8651e-01, 4.7983e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,058][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.9818, 0.0028, 0.0154], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,058][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3373, 0.4246, 0.2381], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,059][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0054, 0.9904, 0.0042], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,059][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([6.4828e-05, 9.9947e-01, 4.6197e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,059][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7457, 0.2284, 0.0258], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,060][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3420, 0.3391, 0.3189], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,060][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([9.9954e-01, 1.2574e-04, 3.3489e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,060][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0052, 0.7784, 0.2164], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,061][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9508, 0.0470, 0.0023], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,063][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9964, 0.0012, 0.0024], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,068][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.7394, 0.0861, 0.1745], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,070][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.1204, 0.8766, 0.0017, 0.0012], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,070][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.9657, 0.0035, 0.0171, 0.0137], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,071][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.3123, 0.4444, 0.1748, 0.0685], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,071][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0131, 0.9671, 0.0074, 0.0124], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,071][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([1.6146e-04, 9.9663e-01, 1.1107e-03, 2.1000e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,072][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.4642, 0.4186, 0.0403, 0.0769], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,072][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.3076, 0.2485, 0.2259, 0.2180], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,072][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([9.9713e-01, 4.2267e-04, 1.0606e-03, 1.3839e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,073][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0033, 0.6276, 0.2017, 0.1674], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,073][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([9.8239e-01, 1.4394e-02, 8.8911e-04, 2.3222e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,076][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.9931, 0.0016, 0.0024, 0.0029], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,082][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.8770, 0.0302, 0.0351, 0.0577], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,084][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ went] are: tensor([5.5182e-01, 4.3836e-01, 2.8634e-04, 4.6379e-04, 9.0723e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,084][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.9636, 0.0025, 0.0133, 0.0106, 0.0099], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,085][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.6417, 0.1112, 0.1688, 0.0288, 0.0495], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,085][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0201, 0.9244, 0.0037, 0.0067, 0.0451], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,085][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ went] are: tensor([4.2823e-04, 9.8858e-01, 6.4576e-04, 1.0758e-03, 9.2694e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,086][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.6055, 0.2994, 0.0168, 0.0381, 0.0402], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,086][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.2449, 0.2100, 0.1911, 0.1829, 0.1711], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,086][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ went] are: tensor([9.9937e-01, 6.3797e-05, 1.6892e-04, 3.0771e-04, 9.4516e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,087][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0022, 0.4622, 0.1948, 0.1278, 0.2130], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,087][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ went] are: tensor([9.9333e-01, 4.3307e-03, 1.9250e-04, 7.3520e-04, 1.4109e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,088][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ went] are: tensor([9.9483e-01, 8.9360e-04, 1.4525e-03, 1.7154e-03, 1.1128e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,092][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.6482, 0.0883, 0.0976, 0.0846, 0.0812], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,096][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.8257e-02, 9.4067e-01, 2.2715e-04, 6.2014e-04, 3.0122e-02, 9.8812e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,098][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.9581, 0.0021, 0.0124, 0.0096, 0.0087, 0.0090], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,099][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2678, 0.1425, 0.1432, 0.0286, 0.0436, 0.3742], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,099][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0346, 0.8965, 0.0025, 0.0120, 0.0525, 0.0019], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,099][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([2.7902e-04, 9.8956e-01, 4.7950e-04, 1.6221e-03, 7.7465e-03, 3.1034e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,100][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.8972, 0.0413, 0.0083, 0.0179, 0.0276, 0.0078], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,100][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2195, 0.1786, 0.1632, 0.1545, 0.1472, 0.1370], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,100][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([9.9975e-01, 1.9431e-05, 6.0786e-05, 1.0943e-04, 3.3271e-05, 3.0931e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,101][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0031, 0.4507, 0.1318, 0.1497, 0.1796, 0.0851], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,101][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.8228e-01, 1.1367e-02, 4.5515e-04, 1.7493e-03, 3.7891e-03, 3.5847e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,102][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.9465e-01, 7.4239e-04, 1.2092e-03, 1.2625e-03, 8.4690e-04, 1.2919e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,105][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9126e-01, 2.2021e-03, 2.2613e-03, 1.7521e-03, 1.7053e-03, 8.1908e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,108][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([2.0869e-02, 9.5073e-01, 2.4852e-04, 4.9951e-04, 2.7221e-02, 6.8217e-05,
        3.6249e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,113][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.9449, 0.0023, 0.0123, 0.0100, 0.0090, 0.0091, 0.0124],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,113][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.3414, 0.1377, 0.0900, 0.0242, 0.0396, 0.2495, 0.1175],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,113][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0117, 0.8989, 0.0028, 0.0093, 0.0737, 0.0009, 0.0027],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,114][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([1.8669e-04, 9.8596e-01, 4.4324e-04, 1.3031e-03, 1.1405e-02, 2.0576e-04,
        4.9819e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,114][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.8105, 0.0858, 0.0140, 0.0297, 0.0410, 0.0091, 0.0099],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,114][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1659, 0.1578, 0.1449, 0.1398, 0.1337, 0.1223, 0.1356],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,115][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([9.9972e-01, 1.9297e-05, 6.0335e-05, 1.0400e-04, 3.2080e-05, 2.9862e-05,
        3.5629e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,115][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0021, 0.3821, 0.1281, 0.1131, 0.1692, 0.0726, 0.1328],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,115][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.7264e-01, 1.7745e-02, 5.9458e-04, 2.2492e-03, 5.4528e-03, 4.3163e-04,
        8.8232e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,116][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.9143e-01, 9.2213e-04, 1.5552e-03, 1.6787e-03, 1.1669e-03, 1.6459e-03,
        1.6017e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,119][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.9408, 0.0114, 0.0134, 0.0109, 0.0091, 0.0061, 0.0083],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,123][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ station] are: tensor([2.4719e-01, 6.8707e-01, 6.8885e-04, 9.5174e-04, 6.3028e-02, 7.9355e-05,
        8.4019e-04, 1.4842e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,127][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.9404, 0.0020, 0.0114, 0.0092, 0.0082, 0.0085, 0.0116, 0.0087],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,127][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.3431, 0.1007, 0.1056, 0.0176, 0.0319, 0.2022, 0.1031, 0.0958],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,127][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ station] are: tensor([1.8121e-02, 8.7387e-01, 2.6857e-03, 8.9875e-03, 8.6689e-02, 4.9560e-04,
        2.3113e-03, 6.8356e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,128][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ station] are: tensor([2.3168e-04, 9.8268e-01, 4.7352e-04, 1.2755e-03, 1.3260e-02, 1.5653e-04,
        5.3908e-04, 1.3844e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,128][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.7710, 0.0975, 0.0154, 0.0286, 0.0453, 0.0109, 0.0120, 0.0193],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,128][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.1466, 0.1393, 0.1281, 0.1225, 0.1178, 0.1095, 0.1214, 0.1149],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,129][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ station] are: tensor([9.9950e-01, 3.2641e-05, 9.2951e-05, 1.5503e-04, 4.9030e-05, 5.4800e-05,
        6.0072e-05, 5.3839e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,129][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0020, 0.3764, 0.0916, 0.1072, 0.1425, 0.0571, 0.1255, 0.0978],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,129][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ station] are: tensor([9.8613e-01, 8.6254e-03, 3.1794e-04, 1.1430e-03, 2.5661e-03, 1.7272e-04,
        4.1074e-04, 6.3106e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,133][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.9829, 0.0013, 0.0026, 0.0028, 0.0020, 0.0027, 0.0026, 0.0030],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,137][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.9363, 0.0139, 0.0111, 0.0121, 0.0093, 0.0035, 0.0072, 0.0066],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,141][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([3.4032e-02, 8.9607e-01, 6.6762e-04, 2.4507e-03, 6.1487e-02, 2.1496e-04,
        2.6567e-03, 2.1930e-03, 2.2414e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,141][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.9260, 0.0022, 0.0119, 0.0097, 0.0086, 0.0087, 0.0118, 0.0085, 0.0127],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,142][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4327, 0.1038, 0.0784, 0.0210, 0.0250, 0.1468, 0.0891, 0.0624, 0.0408],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,142][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0139, 0.8031, 0.0052, 0.0221, 0.1014, 0.0020, 0.0105, 0.0400, 0.0018],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,142][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([6.9750e-04, 9.4424e-01, 1.7872e-03, 5.6446e-03, 2.7067e-02, 1.1486e-03,
        4.4019e-03, 1.4427e-02, 5.8572e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,143][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.6904, 0.0830, 0.0196, 0.0481, 0.0451, 0.0163, 0.0204, 0.0430, 0.0342],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,143][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1290, 0.1251, 0.1176, 0.1114, 0.1064, 0.0984, 0.1087, 0.1039, 0.0996],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,143][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([9.9777e-01, 1.2295e-04, 3.2256e-04, 5.2898e-04, 1.7331e-04, 1.7765e-04,
        2.1733e-04, 1.8468e-04, 5.0116e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,144][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0038, 0.3592, 0.0849, 0.1043, 0.1220, 0.0642, 0.1224, 0.1145, 0.0248],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,145][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.6675e-01, 1.8569e-02, 8.9884e-04, 3.0863e-03, 5.4230e-03, 5.3014e-04,
        1.3720e-03, 2.2205e-03, 1.1481e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,147][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.9072e-01, 7.2880e-04, 1.0757e-03, 1.2221e-03, 8.9133e-04, 1.3459e-03,
        1.3066e-03, 1.2068e-03, 1.5000e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,153][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.7494, 0.0178, 0.0380, 0.0272, 0.0226, 0.0167, 0.0267, 0.0180, 0.0837],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,155][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([4.2884e-03, 8.8621e-01, 1.6468e-03, 1.3637e-03, 1.0146e-01, 3.5612e-04,
        3.9249e-03, 5.8341e-04, 1.3965e-04, 3.0841e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,156][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.9069, 0.0025, 0.0127, 0.0105, 0.0094, 0.0097, 0.0129, 0.0095, 0.0141,
        0.0117], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,156][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.3303, 0.1353, 0.0679, 0.0209, 0.0367, 0.1577, 0.0987, 0.0742, 0.0381,
        0.0402], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,156][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([2.8229e-03, 8.4392e-01, 4.7278e-03, 1.1501e-02, 1.0584e-01, 1.4835e-03,
        6.8634e-03, 2.1167e-02, 5.4881e-04, 1.1345e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,157][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([1.6103e-04, 9.5466e-01, 2.0352e-03, 3.8861e-03, 2.9163e-02, 6.4596e-04,
        2.5774e-03, 6.3317e-03, 1.9516e-04, 3.4545e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,157][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.3336, 0.2390, 0.0347, 0.0591, 0.0876, 0.0329, 0.0380, 0.1005, 0.0365,
        0.0382], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,157][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.1121, 0.1151, 0.1062, 0.1012, 0.0981, 0.0903, 0.1006, 0.0960, 0.0904,
        0.0900], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,158][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([9.9446e-01, 2.9878e-04, 7.0240e-04, 9.8620e-04, 3.7220e-04, 3.9251e-04,
        4.4330e-04, 4.3121e-04, 9.8371e-04, 9.2974e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,158][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0020, 0.3506, 0.1021, 0.0997, 0.1372, 0.0535, 0.1148, 0.0971, 0.0203,
        0.0226], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,159][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([9.7619e-01, 1.1953e-02, 6.6245e-04, 2.0630e-03, 3.9403e-03, 3.6458e-04,
        8.8714e-04, 1.5060e-03, 8.2301e-04, 1.6122e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,165][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.9783, 0.0020, 0.0022, 0.0029, 0.0019, 0.0027, 0.0026, 0.0027, 0.0027,
        0.0019], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,169][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.7491, 0.0200, 0.0298, 0.0265, 0.0407, 0.0145, 0.0168, 0.0206, 0.0520,
        0.0300], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,170][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([5.0759e-01, 4.6886e-01, 2.0079e-04, 9.9934e-04, 1.9370e-02, 2.8259e-05,
        3.6738e-04, 3.3826e-04, 7.7679e-05, 2.1479e-05, 2.1437e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,170][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.9238, 0.0017, 0.0103, 0.0080, 0.0073, 0.0074, 0.0101, 0.0072, 0.0113,
        0.0090, 0.0038], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,170][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.4536, 0.0454, 0.0670, 0.0179, 0.0179, 0.1509, 0.0620, 0.0808, 0.0376,
        0.0308, 0.0361], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,171][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([5.1066e-02, 8.4891e-01, 2.4246e-03, 1.3819e-02, 4.8017e-02, 6.1590e-04,
        3.0951e-03, 1.0408e-02, 9.9980e-04, 1.4452e-03, 1.9202e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,171][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([2.9020e-03, 9.6789e-01, 9.1183e-04, 2.7202e-03, 1.3205e-02, 2.7013e-04,
        1.1174e-03, 3.4451e-03, 2.1615e-04, 3.4262e-04, 6.9793e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,171][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.8171, 0.0668, 0.0080, 0.0246, 0.0198, 0.0048, 0.0067, 0.0106, 0.0130,
        0.0151, 0.0136], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,172][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.1186, 0.1035, 0.0964, 0.0918, 0.0868, 0.0800, 0.0896, 0.0851, 0.0824,
        0.0816, 0.0842], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,172][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([9.9962e-01, 1.2738e-05, 4.2318e-05, 7.4931e-05, 2.0176e-05, 2.1196e-05,
        2.4036e-05, 2.1547e-05, 7.3183e-05, 7.1072e-05, 1.4145e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,176][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0020, 0.3355, 0.0916, 0.0960, 0.1203, 0.0533, 0.1118, 0.0995, 0.0217,
        0.0252, 0.0431], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,179][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([9.9217e-01, 3.9193e-03, 1.3112e-04, 6.5503e-04, 9.3566e-04, 7.4473e-05,
        2.0162e-04, 3.6700e-04, 2.6290e-04, 5.6206e-04, 7.2248e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,183][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.9826, 0.0012, 0.0018, 0.0019, 0.0014, 0.0020, 0.0019, 0.0020, 0.0023,
        0.0012, 0.0019], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,184][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([9.8165e-01, 3.1836e-03, 2.1451e-03, 1.8255e-03, 1.4423e-03, 8.2443e-04,
        1.2382e-03, 1.2941e-03, 2.3899e-03, 2.7816e-03, 1.2236e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,184][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([2.2459e-01, 7.3726e-01, 2.1065e-04, 1.2529e-03, 2.8106e-02, 3.8495e-05,
        3.9047e-04, 4.2932e-04, 9.7772e-05, 2.0588e-05, 5.7439e-03, 1.8584e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,185][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.9143, 0.0019, 0.0106, 0.0083, 0.0074, 0.0078, 0.0106, 0.0076, 0.0116,
        0.0092, 0.0040, 0.0066], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,185][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1750, 0.1008, 0.0866, 0.0237, 0.0276, 0.1707, 0.0800, 0.0724, 0.0430,
        0.0322, 0.0844, 0.1036], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,185][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0715, 0.7688, 0.0030, 0.0165, 0.0680, 0.0009, 0.0039, 0.0179, 0.0014,
        0.0022, 0.0287, 0.0171], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,186][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([3.4303e-03, 9.5522e-01, 9.4279e-04, 3.7665e-03, 1.5947e-02, 3.5085e-04,
        1.2883e-03, 4.3954e-03, 3.1864e-04, 5.2089e-04, 9.2830e-03, 4.5403e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,186][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.8907, 0.0259, 0.0054, 0.0125, 0.0121, 0.0034, 0.0042, 0.0072, 0.0092,
        0.0089, 0.0137, 0.0066], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,187][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1092, 0.0950, 0.0882, 0.0835, 0.0808, 0.0741, 0.0824, 0.0790, 0.0755,
        0.0749, 0.0782, 0.0792], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,190][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([9.9934e-01, 2.5196e-05, 7.4281e-05, 1.1835e-04, 3.5359e-05, 3.7154e-05,
        4.1761e-05, 3.6467e-05, 1.1889e-04, 1.0599e-04, 2.6748e-05, 4.3601e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,195][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0036, 0.3025, 0.0755, 0.0926, 0.1129, 0.0543, 0.1061, 0.1048, 0.0220,
        0.0273, 0.0537, 0.0448], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,197][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.9068e-01, 4.1661e-03, 1.6336e-04, 7.0929e-04, 1.1292e-03, 9.2526e-05,
        2.3373e-04, 4.2781e-04, 2.8398e-04, 6.0502e-04, 8.7351e-04, 6.3630e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,198][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9001e-01, 5.5817e-04, 8.4025e-04, 1.0802e-03, 7.0906e-04, 1.0226e-03,
        1.0149e-03, 9.0519e-04, 1.2479e-03, 6.1608e-04, 9.7536e-04, 1.0175e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,198][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.9564, 0.0046, 0.0052, 0.0032, 0.0027, 0.0023, 0.0031, 0.0023, 0.0084,
        0.0055, 0.0028, 0.0035], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,199][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([7.4846e-01, 2.1919e-01, 4.2608e-04, 1.0311e-03, 2.8128e-02, 2.7920e-05,
        5.2890e-04, 1.4771e-04, 3.5411e-05, 1.7954e-05, 1.0754e-03, 6.8235e-04,
        2.4258e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,199][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.9258, 0.0014, 0.0087, 0.0070, 0.0062, 0.0064, 0.0089, 0.0063, 0.0097,
        0.0078, 0.0032, 0.0054, 0.0032], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,199][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.3665, 0.0349, 0.0437, 0.0126, 0.0176, 0.1218, 0.0715, 0.0499, 0.0370,
        0.0315, 0.0618, 0.1044, 0.0470], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,200][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([5.5292e-02, 7.7564e-01, 4.1148e-03, 1.8882e-02, 8.5185e-02, 5.0483e-04,
        3.4298e-03, 1.0584e-02, 5.7816e-04, 1.5715e-03, 1.4141e-02, 8.4705e-03,
        2.1606e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,200][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([1.8541e-03, 9.4111e-01, 1.9571e-03, 5.7260e-03, 2.7658e-02, 4.3738e-04,
        2.0467e-03, 4.5057e-03, 2.3113e-04, 4.7726e-04, 5.5972e-03, 4.1359e-03,
        4.2633e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,204][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.6483, 0.0882, 0.0153, 0.0372, 0.0486, 0.0107, 0.0126, 0.0280, 0.0172,
        0.0195, 0.0339, 0.0194, 0.0211], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,209][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.1016, 0.0904, 0.0821, 0.0784, 0.0753, 0.0690, 0.0766, 0.0733, 0.0695,
        0.0691, 0.0717, 0.0733, 0.0696], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,211][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([9.9863e-01, 5.5301e-05, 1.3494e-04, 2.0089e-04, 7.0320e-05, 7.5389e-05,
        8.1452e-05, 7.6082e-05, 2.0956e-04, 1.9891e-04, 5.3722e-05, 9.3225e-05,
        1.1887e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,212][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0020, 0.3104, 0.0883, 0.0967, 0.1285, 0.0435, 0.1112, 0.0852, 0.0171,
        0.0226, 0.0362, 0.0337, 0.0246], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,212][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([9.9160e-01, 2.8971e-03, 1.6859e-04, 6.2902e-04, 9.2392e-04, 8.3293e-05,
        2.0971e-04, 3.6044e-04, 2.3688e-04, 4.8155e-04, 5.7763e-04, 5.4251e-04,
        1.2940e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,213][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([9.8532e-01, 7.8321e-04, 1.2185e-03, 1.5868e-03, 1.0943e-03, 1.2864e-03,
        1.3672e-03, 1.3361e-03, 1.5855e-03, 9.2603e-04, 1.3770e-03, 1.1900e-03,
        9.2884e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,213][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.9548, 0.0044, 0.0037, 0.0046, 0.0029, 0.0010, 0.0024, 0.0016, 0.0050,
        0.0102, 0.0024, 0.0046, 0.0024], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,214][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([6.8057e-01, 2.8898e-01, 1.2609e-04, 8.6613e-04, 1.5430e-02, 1.8560e-05,
        1.8934e-04, 2.5972e-04, 6.5644e-05, 1.4545e-05, 2.6965e-03, 9.9217e-04,
        1.0032e-03, 8.7896e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,214][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.9285, 0.0012, 0.0086, 0.0064, 0.0058, 0.0059, 0.0083, 0.0059, 0.0092,
        0.0070, 0.0028, 0.0050, 0.0029, 0.0025], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,214][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0711, 0.0503, 0.0533, 0.0142, 0.0159, 0.1313, 0.0601, 0.0511, 0.0386,
        0.0241, 0.0715, 0.0941, 0.0465, 0.2777], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,218][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.4115, 0.3639, 0.0031, 0.0198, 0.0571, 0.0008, 0.0037, 0.0135, 0.0022,
        0.0034, 0.0266, 0.0188, 0.0464, 0.0291], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,221][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.3184e-02, 9.0088e-01, 1.8091e-03, 7.0887e-03, 2.1027e-02, 4.5605e-04,
        2.0882e-03, 7.4990e-03, 7.1394e-04, 1.2167e-03, 1.2455e-02, 8.4075e-03,
        8.9220e-03, 1.4250e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,226][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.8214, 0.0321, 0.0070, 0.0164, 0.0182, 0.0050, 0.0057, 0.0102, 0.0119,
        0.0117, 0.0168, 0.0095, 0.0103, 0.0238], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,226][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0973, 0.0851, 0.0774, 0.0726, 0.0702, 0.0643, 0.0719, 0.0688, 0.0654,
        0.0647, 0.0675, 0.0681, 0.0650, 0.0616], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,226][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([9.9870e-01, 4.7089e-05, 1.2322e-04, 1.8409e-04, 5.7824e-05, 6.2051e-05,
        7.3700e-05, 6.0628e-05, 1.8899e-04, 1.6965e-04, 4.5502e-05, 7.6676e-05,
        9.7452e-05, 1.0896e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,227][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0028, 0.2703, 0.0789, 0.0922, 0.1079, 0.0476, 0.1030, 0.0893, 0.0218,
        0.0272, 0.0445, 0.0426, 0.0310, 0.0408], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,227][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.9125e-01, 2.9188e-03, 1.4356e-04, 5.3625e-04, 8.6380e-04, 6.5317e-05,
        1.7652e-04, 3.0508e-04, 2.1048e-04, 4.1124e-04, 5.5586e-04, 4.3841e-04,
        1.2127e-03, 9.1454e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,228][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.8951e-01, 4.9226e-04, 7.6543e-04, 9.9756e-04, 6.8006e-04, 9.5621e-04,
        9.4760e-04, 8.1123e-04, 1.1133e-03, 5.3871e-04, 8.8081e-04, 9.2727e-04,
        5.0248e-04, 8.7612e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,228][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([9.9181e-01, 7.8062e-04, 8.3447e-04, 5.1795e-04, 5.1470e-04, 2.8717e-04,
        5.5145e-04, 4.0927e-04, 1.5022e-03, 8.4090e-04, 4.3271e-04, 7.1619e-04,
        3.7757e-04, 4.2221e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,256][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:09,256][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,257][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,257][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,257][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,258][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,258][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,259][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,259][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,259][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,260][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,260][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,260][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,261][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.0174, 0.9826], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,261][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0569, 0.9431], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,261][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([1.4006e-05, 9.9999e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,262][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.2392, 0.7608], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,262][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0064, 0.9936], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,262][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.9773, 0.0227], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,263][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.7854, 0.2146], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,263][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.2185, 0.7815], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,263][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.0948, 0.9052], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,264][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0091, 0.9909], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,264][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([8.0584e-06, 9.9999e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,264][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.9672, 0.0328], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,265][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([2.9248e-05, 9.9993e-01, 4.3707e-05], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,265][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0218, 0.9011, 0.0771], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,265][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([3.7974e-05, 8.9581e-01, 1.0415e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,266][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0048, 0.9901, 0.0052], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,266][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([6.4828e-05, 9.9947e-01, 4.6197e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,266][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7457, 0.2284, 0.0258], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,267][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4594, 0.4057, 0.1349], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,267][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0521, 0.8008, 0.1472], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,267][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([2.3763e-04, 9.9933e-01, 4.3649e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,268][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([5.4688e-05, 9.9937e-01, 5.7828e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,268][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.4341e-05, 9.6579e-01, 3.4195e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,268][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4646, 0.3391, 0.1964], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,269][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([2.0156e-04, 9.9904e-01, 1.8411e-04, 5.7418e-04], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,269][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.0190, 0.7414, 0.0890, 0.1506], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,270][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([4.3409e-05, 8.5150e-01, 9.8455e-02, 5.0000e-02], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,273][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.0107, 0.9707, 0.0083, 0.0103], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,275][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([1.6146e-04, 9.9663e-01, 1.1107e-03, 2.1000e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,279][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.4642, 0.4186, 0.0403, 0.0769], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,281][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.3477, 0.2886, 0.1326, 0.2310], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,281][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0323, 0.6594, 0.1832, 0.1251], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,282][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([6.8746e-04, 9.9722e-01, 6.5457e-04, 1.4409e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,282][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([2.0645e-04, 9.9687e-01, 1.3638e-03, 1.5585e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,282][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([4.1672e-05, 9.0277e-01, 4.1064e-02, 5.6123e-02], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,283][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.2337, 0.3078, 0.1822, 0.2763], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,283][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([5.3333e-04, 9.9467e-01, 5.5140e-05, 3.8854e-04, 4.3547e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,283][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0297, 0.6693, 0.0836, 0.0878, 0.1296], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,284][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([7.9929e-05, 6.1046e-01, 1.3071e-01, 4.1113e-02, 2.1764e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,284][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0115, 0.9390, 0.0039, 0.0051, 0.0405], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,284][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([4.2823e-04, 9.8858e-01, 6.4576e-04, 1.0758e-03, 9.2694e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,286][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.6055, 0.2994, 0.0168, 0.0381, 0.0402], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,288][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.5453, 0.1864, 0.0711, 0.1284, 0.0688], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,293][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.0688, 0.5595, 0.1019, 0.1290, 0.1408], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,295][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([9.7603e-04, 9.8756e-01, 4.5343e-04, 1.0449e-03, 9.9610e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,297][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([2.8550e-04, 9.8313e-01, 8.1705e-04, 1.0085e-03, 1.4757e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,297][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([1.1535e-04, 8.0773e-01, 5.9059e-02, 3.4885e-02, 9.8215e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,298][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.4140, 0.1565, 0.1328, 0.1466, 0.1501], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,298][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.7460e-05, 9.9645e-01, 1.7795e-05, 1.9864e-04, 3.2635e-03, 1.8662e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,298][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0938, 0.4527, 0.0668, 0.0960, 0.1171, 0.1736], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,299][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.9064e-05, 1.3955e-01, 3.0153e-02, 1.5077e-02, 4.5793e-02, 7.6940e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,299][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0082, 0.9373, 0.0027, 0.0083, 0.0413, 0.0023], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,299][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([2.7902e-04, 9.8956e-01, 4.7950e-04, 1.6221e-03, 7.7465e-03, 3.1034e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,300][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.8972, 0.0413, 0.0083, 0.0179, 0.0276, 0.0078], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,300][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7066, 0.1043, 0.0352, 0.0937, 0.0372, 0.0230], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,300][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1730, 0.3061, 0.0963, 0.1546, 0.1117, 0.1583], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,301][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.3757e-04, 9.8667e-01, 2.0696e-04, 1.5135e-03, 1.1020e-02, 3.4940e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,303][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.1086e-05, 9.8836e-01, 3.5029e-04, 1.0093e-03, 9.8457e-03, 3.6806e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,304][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.8033e-05, 8.0742e-01, 2.4750e-02, 2.2603e-02, 5.0644e-02, 9.4542e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,308][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7561, 0.0344, 0.0310, 0.0701, 0.0318, 0.0767], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,310][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([4.1809e-05, 9.9519e-01, 2.2806e-05, 1.9573e-04, 4.4902e-03, 1.1859e-05,
        4.8488e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,313][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0899, 0.4405, 0.0585, 0.0801, 0.1015, 0.1639, 0.0656],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,313][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([8.7793e-05, 1.1242e-01, 3.1491e-02, 1.7037e-02, 5.8099e-02, 6.0659e-01,
        1.7428e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,314][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0085, 0.9125, 0.0034, 0.0072, 0.0633, 0.0019, 0.0032],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,314][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.8669e-04, 9.8596e-01, 4.4324e-04, 1.3031e-03, 1.1405e-02, 2.0576e-04,
        4.9819e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,314][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.8105, 0.0858, 0.0140, 0.0297, 0.0410, 0.0091, 0.0099],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,315][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.5716, 0.1252, 0.0509, 0.1021, 0.0556, 0.0406, 0.0540],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,315][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1272, 0.2671, 0.0858, 0.1319, 0.1169, 0.1547, 0.1163],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,315][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.9989e-04, 9.8540e-01, 2.4537e-04, 9.9748e-04, 1.2466e-02, 1.8565e-04,
        5.0383e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,315][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([6.6283e-05, 9.8659e-01, 3.2174e-04, 7.6815e-04, 1.1429e-02, 2.1216e-04,
        6.1019e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,316][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.0717e-04, 6.2277e-01, 3.9451e-02, 3.4680e-02, 6.7583e-02, 1.0706e-01,
        1.2835e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,317][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.5913, 0.0439, 0.0441, 0.0828, 0.0543, 0.0966, 0.0871],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,318][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([4.1238e-05, 9.9441e-01, 1.9412e-05, 1.4668e-04, 5.2071e-03, 4.9555e-06,
        3.7683e-05, 1.3236e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,321][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0315, 0.3151, 0.0471, 0.0780, 0.0745, 0.2044, 0.0847, 0.1646],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,324][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([3.8346e-05, 9.7552e-02, 3.8162e-02, 1.5270e-02, 5.4271e-02, 4.6517e-01,
        1.6041e-01, 1.6913e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,327][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0100, 0.9048, 0.0032, 0.0071, 0.0658, 0.0010, 0.0025, 0.0056],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,329][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([2.3168e-04, 9.8268e-01, 4.7352e-04, 1.2755e-03, 1.3260e-02, 1.5653e-04,
        5.3908e-04, 1.3844e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,329][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.7710, 0.0975, 0.0154, 0.0286, 0.0453, 0.0109, 0.0120, 0.0193],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,330][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.4893, 0.1191, 0.0530, 0.1221, 0.0600, 0.0412, 0.0601, 0.0552],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,330][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0476, 0.3075, 0.0697, 0.0970, 0.0883, 0.1784, 0.1126, 0.0988],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,330][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([5.0252e-04, 9.7185e-01, 3.4878e-04, 1.2837e-03, 2.2873e-02, 1.8635e-04,
        9.3580e-04, 2.0187e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,330][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([8.6729e-05, 9.8237e-01, 3.6619e-04, 8.2845e-04, 1.3922e-02, 1.4408e-04,
        6.3095e-04, 1.6544e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,331][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([2.1305e-05, 6.4866e-01, 3.0569e-02, 2.6023e-02, 5.2215e-02, 7.2135e-02,
        9.1238e-02, 7.9143e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,331][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.4748, 0.0448, 0.0683, 0.1136, 0.0610, 0.0849, 0.0871, 0.0655],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,331][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([2.6281e-04, 9.8449e-01, 1.2270e-04, 1.2716e-03, 9.3107e-03, 5.4400e-05,
        5.2753e-04, 3.8879e-03, 7.2111e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,332][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0670, 0.3672, 0.0650, 0.0898, 0.1009, 0.1222, 0.0571, 0.0880, 0.0429],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,333][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.8272e-05, 1.1092e-01, 3.1363e-02, 1.2292e-02, 5.2583e-02, 4.5090e-01,
        1.8998e-01, 1.1054e-01, 4.1411e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,335][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0143, 0.8167, 0.0067, 0.0192, 0.0940, 0.0038, 0.0112, 0.0315, 0.0026],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,337][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([6.9750e-04, 9.4424e-01, 1.7872e-03, 5.6446e-03, 2.7067e-02, 1.1486e-03,
        4.4019e-03, 1.4427e-02, 5.8572e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,341][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6904, 0.0830, 0.0196, 0.0481, 0.0451, 0.0163, 0.0204, 0.0430, 0.0342],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,345][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3987, 0.1295, 0.0533, 0.1153, 0.0617, 0.0427, 0.0579, 0.0701, 0.0708],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,345][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0461, 0.2345, 0.0751, 0.1093, 0.0875, 0.1358, 0.1260, 0.1096, 0.0762],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,345][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([8.6742e-04, 9.5204e-01, 8.7001e-04, 4.1677e-03, 2.5747e-02, 6.4127e-04,
        3.5032e-03, 1.1796e-02, 3.6269e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,346][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.8566e-04, 9.6679e-01, 7.7546e-04, 3.5633e-03, 1.5521e-02, 4.9555e-04,
        2.6681e-03, 9.6637e-03, 3.3587e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,346][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([2.4961e-05, 6.1531e-01, 3.2015e-02, 2.9055e-02, 5.3880e-02, 6.5266e-02,
        1.1578e-01, 7.5302e-02, 1.3374e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,346][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1986, 0.0605, 0.0589, 0.0983, 0.0702, 0.1160, 0.1403, 0.1227, 0.1345],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,347][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([3.5333e-05, 9.7972e-01, 2.0411e-04, 7.0519e-04, 1.7470e-02, 5.1449e-05,
        3.8668e-04, 1.3720e-03, 2.3615e-05, 3.2001e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,347][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.0171, 0.3000, 0.0569, 0.0898, 0.1054, 0.1411, 0.0651, 0.1236, 0.0384,
        0.0625], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,347][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([7.4725e-06, 1.8000e-01, 2.5516e-02, 1.1896e-02, 6.0105e-02, 4.2393e-01,
        1.4956e-01, 1.1015e-01, 2.5934e-02, 1.2909e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,348][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.0033, 0.8605, 0.0061, 0.0109, 0.0908, 0.0024, 0.0074, 0.0162, 0.0009,
        0.0014], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,349][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([1.6103e-04, 9.5466e-01, 2.0352e-03, 3.8861e-03, 2.9163e-02, 6.4596e-04,
        2.5774e-03, 6.3317e-03, 1.9516e-04, 3.4545e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,351][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.3336, 0.2390, 0.0347, 0.0591, 0.0876, 0.0329, 0.0380, 0.1005, 0.0365,
        0.0382], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,354][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.2543, 0.1162, 0.0667, 0.1145, 0.0873, 0.0535, 0.0757, 0.0903, 0.0657,
        0.0757], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,358][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0170, 0.2646, 0.0826, 0.0777, 0.0860, 0.1251, 0.1020, 0.1291, 0.0570,
        0.0589], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,361][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([1.3328e-04, 9.6469e-01, 7.8220e-04, 2.0099e-03, 2.4348e-02, 3.7659e-04,
        2.0286e-03, 5.3163e-03, 1.0108e-04, 2.0942e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,361][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([5.9767e-05, 9.6192e-01, 9.8225e-04, 2.1744e-03, 2.4199e-02, 4.2336e-04,
        2.1504e-03, 7.6916e-03, 1.6133e-04, 2.3341e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,361][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([1.6271e-05, 6.6619e-01, 2.8329e-02, 3.0721e-02, 5.4639e-02, 3.9961e-02,
        1.0688e-01, 5.3360e-02, 1.1265e-02, 8.6329e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,362][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.1285, 0.1014, 0.0708, 0.1176, 0.1060, 0.0813, 0.0966, 0.0914, 0.0807,
        0.1256], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,362][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([2.1292e-03, 9.8664e-01, 5.9486e-05, 9.9274e-04, 6.5214e-03, 1.4490e-05,
        1.5136e-04, 9.9244e-04, 5.9464e-05, 7.5216e-05, 2.3630e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,362][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0282, 0.3102, 0.0462, 0.0524, 0.0791, 0.1482, 0.0527, 0.0880, 0.0319,
        0.0447, 0.1183], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,363][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([3.2166e-05, 1.0073e-01, 2.4993e-02, 1.0312e-02, 3.7249e-02, 4.7489e-01,
        1.0057e-01, 1.5034e-01, 2.9760e-02, 1.6241e-02, 5.4875e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,363][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0308, 0.8769, 0.0032, 0.0109, 0.0461, 0.0013, 0.0035, 0.0088, 0.0013,
        0.0016, 0.0153], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,363][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([2.9020e-03, 9.6789e-01, 9.1183e-04, 2.7202e-03, 1.3205e-02, 2.7013e-04,
        1.1174e-03, 3.4451e-03, 2.1615e-04, 3.4262e-04, 6.9793e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,364][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.8171, 0.0668, 0.0080, 0.0246, 0.0198, 0.0048, 0.0067, 0.0106, 0.0130,
        0.0151, 0.0136], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,367][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.5354, 0.0726, 0.0314, 0.0806, 0.0335, 0.0243, 0.0367, 0.0378, 0.0479,
        0.0651, 0.0347], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,370][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1435, 0.1908, 0.0680, 0.0887, 0.0658, 0.1158, 0.0755, 0.0699, 0.0691,
        0.0630, 0.0500], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,372][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([2.2654e-03, 9.7389e-01, 2.9467e-04, 1.9022e-03, 9.9768e-03, 2.3160e-04,
        8.9705e-04, 3.0487e-03, 1.8887e-04, 3.3322e-04, 6.9690e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,374][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([6.8685e-04, 9.7534e-01, 4.7614e-04, 2.0206e-03, 1.0858e-02, 1.7977e-04,
        1.0052e-03, 3.3306e-03, 2.3907e-04, 2.4953e-04, 5.6167e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,376][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([6.9616e-05, 6.8671e-01, 2.9613e-02, 1.3454e-02, 2.8934e-02, 5.7217e-02,
        6.8396e-02, 7.7894e-02, 1.2452e-02, 8.9128e-03, 1.6347e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,377][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.3502, 0.0508, 0.0444, 0.0591, 0.0383, 0.0713, 0.0680, 0.0681, 0.0770,
        0.1045, 0.0681], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,377][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.6389e-03, 9.8179e-01, 5.9219e-05, 1.0969e-03, 7.7665e-03, 1.5290e-05,
        1.4793e-04, 9.8732e-04, 6.8444e-05, 7.7296e-05, 3.9269e-03, 1.4222e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,378][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1199, 0.2019, 0.0496, 0.0707, 0.0785, 0.1009, 0.0431, 0.0846, 0.0341,
        0.0492, 0.1352, 0.0323], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,378][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.6951e-05, 8.5780e-02, 2.4697e-02, 9.3322e-03, 3.6471e-02, 3.9550e-01,
        1.0951e-01, 1.1974e-01, 2.9590e-02, 1.3153e-02, 9.8515e-02, 7.7684e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,378][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0474, 0.8125, 0.0039, 0.0125, 0.0627, 0.0018, 0.0044, 0.0140, 0.0017,
        0.0022, 0.0225, 0.0144], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,379][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([3.4303e-03, 9.5522e-01, 9.4279e-04, 3.7665e-03, 1.5947e-02, 3.5085e-04,
        1.2883e-03, 4.3954e-03, 3.1864e-04, 5.2089e-04, 9.2830e-03, 4.5403e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,379][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.8907, 0.0259, 0.0054, 0.0125, 0.0121, 0.0034, 0.0042, 0.0072, 0.0092,
        0.0089, 0.0137, 0.0066], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,379][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6118, 0.0617, 0.0258, 0.0570, 0.0271, 0.0184, 0.0276, 0.0278, 0.0417,
        0.0464, 0.0322, 0.0224], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,381][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1058, 0.1931, 0.0660, 0.0896, 0.0651, 0.0921, 0.0754, 0.0654, 0.0588,
        0.0553, 0.0687, 0.0647], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,383][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([5.0326e-03, 9.3264e-01, 4.4748e-04, 3.2319e-03, 2.1613e-02, 2.9097e-04,
        1.2603e-03, 6.0247e-03, 2.8849e-04, 5.9516e-04, 2.3474e-02, 5.1059e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,385][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.7731e-04, 9.5830e-01, 5.5023e-04, 2.1710e-03, 1.5738e-02, 3.0240e-04,
        1.3077e-03, 4.6464e-03, 3.1036e-04, 3.2993e-04, 9.8251e-03, 5.6377e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,387][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([7.5714e-05, 4.7144e-01, 3.2153e-02, 1.7206e-02, 3.9596e-02, 7.3287e-02,
        9.4997e-02, 1.0262e-01, 1.6063e-02, 9.6669e-03, 5.3736e-02, 8.9161e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,391][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.4054, 0.0325, 0.0268, 0.0472, 0.0257, 0.0539, 0.0590, 0.0489, 0.0719,
        0.1095, 0.0779, 0.0413], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,393][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([2.8429e-03, 9.6993e-01, 1.9899e-04, 1.6836e-03, 1.8026e-02, 1.9767e-05,
        2.4393e-04, 8.5869e-04, 3.3657e-05, 5.7407e-05, 1.6283e-03, 9.7290e-04,
        3.5029e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,393][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0487, 0.1861, 0.0741, 0.0499, 0.1173, 0.1194, 0.0680, 0.0717, 0.0307,
        0.0321, 0.1236, 0.0469, 0.0313], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,393][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([1.3372e-05, 8.4225e-02, 2.6714e-02, 9.4742e-03, 3.9327e-02, 3.5063e-01,
        1.1543e-01, 7.6514e-02, 2.6987e-02, 1.1767e-02, 9.4612e-02, 1.2390e-01,
        4.0407e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,394][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0404, 0.8088, 0.0054, 0.0137, 0.0778, 0.0013, 0.0044, 0.0099, 0.0009,
        0.0016, 0.0137, 0.0084, 0.0138], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,394][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([1.8541e-03, 9.4111e-01, 1.9571e-03, 5.7260e-03, 2.7658e-02, 4.3738e-04,
        2.0467e-03, 4.5057e-03, 2.3113e-04, 4.7726e-04, 5.5972e-03, 4.1359e-03,
        4.2633e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,394][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.6483, 0.0882, 0.0153, 0.0372, 0.0486, 0.0107, 0.0126, 0.0280, 0.0172,
        0.0195, 0.0339, 0.0194, 0.0211], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,395][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.3553, 0.0949, 0.0458, 0.0888, 0.0480, 0.0342, 0.0473, 0.0529, 0.0474,
        0.0581, 0.0494, 0.0361, 0.0417], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,395][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0671, 0.1756, 0.0590, 0.0633, 0.0708, 0.0985, 0.0768, 0.0752, 0.0458,
        0.0516, 0.0691, 0.0886, 0.0587], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,395][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([6.5420e-03, 9.1942e-01, 1.0423e-03, 5.1449e-03, 3.0663e-02, 3.1019e-04,
        2.0102e-03, 5.8713e-03, 2.3313e-04, 6.7456e-04, 1.2445e-02, 5.2801e-03,
        1.0363e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,396][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([1.2812e-03, 9.3849e-01, 1.2566e-03, 4.0280e-03, 3.0949e-02, 2.8512e-04,
        1.8935e-03, 5.2577e-03, 2.1475e-04, 3.5449e-04, 6.2469e-03, 5.3326e-03,
        4.4070e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,398][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([4.1970e-05, 4.7330e-01, 3.0968e-02, 2.2981e-02, 4.5181e-02, 4.5775e-02,
        8.9230e-02, 5.1501e-02, 1.1898e-02, 9.8350e-03, 3.5577e-02, 1.5077e-01,
        3.2946e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,401][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.1915, 0.0497, 0.0512, 0.0858, 0.0462, 0.0543, 0.0684, 0.0587, 0.0715,
        0.1194, 0.0779, 0.0595, 0.0657], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,403][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.7499e-02, 9.3835e-01, 1.2805e-04, 2.2768e-03, 1.3663e-02, 2.6255e-05,
        2.6419e-04, 1.4337e-03, 1.5212e-04, 1.6440e-04, 5.7735e-03, 2.3473e-03,
        1.2341e-02, 5.5753e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,407][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0615, 0.2289, 0.0482, 0.0704, 0.0826, 0.0927, 0.0385, 0.0674, 0.0301,
        0.0417, 0.1335, 0.0317, 0.0258, 0.0470], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,409][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([8.4318e-06, 4.4634e-02, 1.3673e-02, 5.2905e-03, 2.1722e-02, 3.5648e-01,
        9.1068e-02, 8.5931e-02, 2.2226e-02, 9.2895e-03, 8.2016e-02, 9.6833e-02,
        3.2589e-02, 1.3824e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,411][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0922, 0.6793, 0.0050, 0.0185, 0.0732, 0.0020, 0.0052, 0.0143, 0.0022,
        0.0032, 0.0231, 0.0172, 0.0299, 0.0345], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,411][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([1.3184e-02, 9.0088e-01, 1.8091e-03, 7.0887e-03, 2.1027e-02, 4.5605e-04,
        2.0882e-03, 7.4990e-03, 7.1394e-04, 1.2167e-03, 1.2455e-02, 8.4075e-03,
        8.9220e-03, 1.4250e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,411][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.8214, 0.0321, 0.0070, 0.0164, 0.0182, 0.0050, 0.0057, 0.0102, 0.0119,
        0.0117, 0.0168, 0.0095, 0.0103, 0.0238], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,412][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5617, 0.0626, 0.0261, 0.0648, 0.0273, 0.0164, 0.0234, 0.0289, 0.0385,
        0.0460, 0.0289, 0.0194, 0.0330, 0.0231], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,412][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0737, 0.1589, 0.0605, 0.0806, 0.0575, 0.0841, 0.0727, 0.0566, 0.0518,
        0.0488, 0.0547, 0.0657, 0.0508, 0.0837], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,413][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.0335e-02, 8.9864e-01, 5.4379e-04, 4.7507e-03, 2.0540e-02, 2.9030e-04,
        1.4123e-03, 5.7565e-03, 3.8899e-04, 9.2265e-04, 1.8992e-02, 6.3179e-03,
        1.9238e-02, 1.1869e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,413][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.6169e-03, 9.1737e-01, 9.3831e-04, 3.7762e-03, 2.1491e-02, 3.7739e-04,
        1.9470e-03, 6.6082e-03, 5.3118e-04, 5.5940e-04, 1.1769e-02, 8.1477e-03,
        8.6106e-03, 1.5262e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,413][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.0641e-05, 3.9807e-01, 2.2429e-02, 1.5267e-02, 3.8153e-02, 5.7360e-02,
        9.8785e-02, 6.4650e-02, 1.4218e-02, 1.0072e-02, 5.5725e-02, 1.3027e-01,
        3.8099e-02, 5.6868e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,415][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.2819, 0.0243, 0.0275, 0.0482, 0.0253, 0.0529, 0.0596, 0.0572, 0.0747,
        0.0952, 0.0790, 0.0518, 0.0631, 0.0594], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,416][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:09,418][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[8590],
        [5006],
        [ 399],
        [ 619],
        [ 195],
        [  30],
        [ 202],
        [  48],
        [ 290],
        [ 143],
        [ 220],
        [ 226],
        [ 182],
        [ 233]], device='cuda:0')
[2024-07-24 10:30:09,420][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9605],
        [13552],
        [ 2751],
        [ 4552],
        [ 2717],
        [ 1348],
        [ 3162],
        [  896],
        [ 3527],
        [ 2696],
        [ 2721],
        [ 2791],
        [ 2544],
        [ 2550]], device='cuda:0')
[2024-07-24 10:30:09,422][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[39635],
        [41213],
        [36397],
        [37175],
        [40906],
        [36308],
        [36269],
        [37636],
        [36031],
        [35511],
        [40341],
        [37665],
        [41648],
        [41447]], device='cuda:0')
[2024-07-24 10:30:09,424][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[13529],
        [13542],
        [13607],
        [13798],
        [13907],
        [14006],
        [14286],
        [14376],
        [14630],
        [15018],
        [14742],
        [14932],
        [14789],
        [14778]], device='cuda:0')
[2024-07-24 10:30:09,427][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[10209],
        [41218],
        [39451],
        [40722],
        [24351],
        [20824],
        [21740],
        [18842],
        [20360],
        [22142],
        [16716],
        [20860],
        [17658],
        [18625]], device='cuda:0')
[2024-07-24 10:30:09,430][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[8549],
        [ 246],
        [ 369],
        [ 370],
        [ 439],
        [ 457],
        [ 519],
        [ 569],
        [ 845],
        [ 731],
        [ 552],
        [ 771],
        [ 740],
        [1633]], device='cuda:0')
[2024-07-24 10:30:09,430][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[16918],
        [32945],
        [32961],
        [32961],
        [32963],
        [32958],
        [32969],
        [32957],
        [32816],
        [32910],
        [32967],
        [32963],
        [32946],
        [32893]], device='cuda:0')
[2024-07-24 10:30:09,431][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[28578],
        [32118],
        [47425],
        [49337],
        [48582],
        [35587],
        [40595],
        [40751],
        [38520],
        [43366],
        [39329],
        [32883],
        [38786],
        [32858]], device='cuda:0')
[2024-07-24 10:30:09,432][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[  185],
        [  687],
        [ 1984],
        [ 2984],
        [ 7005],
        [10433],
        [15515],
        [18241],
        [19927],
        [21612],
        [22674],
        [24356],
        [25556],
        [25715]], device='cuda:0')
[2024-07-24 10:30:09,433][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[46373],
        [46378],
        [46389],
        [46476],
        [46397],
        [46382],
        [46381],
        [46382],
        [46422],
        [46486],
        [46382],
        [46381],
        [46401],
        [46397]], device='cuda:0')
[2024-07-24 10:30:09,434][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[1068],
        [9245],
        [6679],
        [6704],
        [5766],
        [5718],
        [4752],
        [4000],
        [3615],
        [3747],
        [3512],
        [3189],
        [3383],
        [2946]], device='cuda:0')
[2024-07-24 10:30:09,435][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[44161],
        [44168],
        [44134],
        [44257],
        [44241],
        [44349],
        [44427],
        [44320],
        [44472],
        [44424],
        [44239],
        [44274],
        [44284],
        [44291]], device='cuda:0')
[2024-07-24 10:30:09,438][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[8135],
        [8212],
        [8236],
        [8255],
        [8210],
        [8243],
        [8305],
        [8459],
        [8317],
        [8524],
        [8450],
        [8318],
        [8397],
        [8343]], device='cuda:0')
[2024-07-24 10:30:09,439][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[12976],
        [13152],
        [14731],
        [20785],
        [19194],
        [12980],
        [13817],
        [13637],
        [16571],
        [19586],
        [13526],
        [14452],
        [15680],
        [13138]], device='cuda:0')
[2024-07-24 10:30:09,441][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21942],
        [ 6854],
        [ 4379],
        [ 2321],
        [  929],
        [ 1648],
        [  573],
        [  884],
        [  564],
        [ 1065],
        [ 1853],
        [ 1817],
        [ 1021],
        [  984]], device='cuda:0')
[2024-07-24 10:30:09,444][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 1202],
        [26193],
        [26567],
        [26559],
        [26581],
        [26591],
        [26593],
        [26595],
        [26526],
        [26625],
        [26526],
        [26528],
        [26532],
        [26118]], device='cuda:0')
[2024-07-24 10:30:09,446][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[13315],
        [ 9445],
        [10294],
        [11026],
        [11173],
        [14232],
        [14866],
        [15900],
        [14679],
        [15496],
        [15339],
        [14693],
        [15028],
        [14645]], device='cuda:0')
[2024-07-24 10:30:09,449][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[18084],
        [11103],
        [11545],
        [11541],
        [11730],
        [ 4714],
        [ 3976],
        [ 3434],
        [ 3674],
        [ 3867],
        [ 3726],
        [ 3833],
        [ 3723],
        [ 3825]], device='cuda:0')
[2024-07-24 10:30:09,450][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 3706],
        [10353],
        [10876],
        [10741],
        [11382],
        [11334],
        [11688],
        [11665],
        [11755],
        [11928],
        [11116],
        [11113],
        [11709],
        [10813]], device='cuda:0')
[2024-07-24 10:30:09,451][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[17735],
        [ 3394],
        [ 3390],
        [ 3364],
        [ 3358],
        [ 3355],
        [ 3348],
        [ 3348],
        [ 3195],
        [ 3241],
        [ 3310],
        [ 3252],
        [ 3171],
        [ 3010]], device='cuda:0')
[2024-07-24 10:30:09,452][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12164],
        [12228],
        [18614],
        [20517],
        [20352],
        [14669],
        [16378],
        [17659],
        [20011],
        [21985],
        [16850],
        [15779],
        [20178],
        [18102]], device='cuda:0')
[2024-07-24 10:30:09,453][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[33811],
        [44696],
        [46537],
        [45945],
        [46606],
        [45789],
        [45733],
        [45914],
        [46006],
        [45686],
        [45274],
        [44880],
        [45788],
        [45211]], device='cuda:0')
[2024-07-24 10:30:09,454][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[6089],
        [9171],
        [9348],
        [8915],
        [8262],
        [7274],
        [6354],
        [6599],
        [5346],
        [5387],
        [4344],
        [3990],
        [2924],
        [2825]], device='cuda:0')
[2024-07-24 10:30:09,456][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[44108],
        [26376],
        [26492],
        [26464],
        [26423],
        [26418],
        [26422],
        [26348],
        [26142],
        [26278],
        [26536],
        [26785],
        [26566],
        [26973]], device='cuda:0')
[2024-07-24 10:30:09,457][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24643],
        [17066],
        [17005],
        [17067],
        [17412],
        [17286],
        [17327],
        [17413],
        [17694],
        [17860],
        [17543],
        [17932],
        [18406],
        [18820]], device='cuda:0')
[2024-07-24 10:30:09,460][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[19508],
        [24277],
        [24870],
        [24848],
        [27926],
        [27334],
        [30291],
        [28521],
        [29052],
        [28591],
        [27981],
        [28194],
        [27552],
        [28298]], device='cuda:0')
[2024-07-24 10:30:09,462][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[30315],
        [30139],
        [22070],
        [17304],
        [19120],
        [23055],
        [20666],
        [20049],
        [20747],
        [16801],
        [14683],
        [11631],
        [11579],
        [11371]], device='cuda:0')
[2024-07-24 10:30:09,465][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[40307],
        [34126],
        [31818],
        [32220],
        [30803],
        [32937],
        [32932],
        [32900],
        [33281],
        [33571],
        [36635],
        [38215],
        [38052],
        [38887]], device='cuda:0')
[2024-07-24 10:30:09,467][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[22446],
        [43790],
        [39492],
        [37481],
        [44310],
        [39581],
        [43445],
        [41354],
        [40883],
        [31926],
        [39913],
        [40401],
        [37667],
        [40126]], device='cuda:0')
[2024-07-24 10:30:09,468][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[10209],
        [10209],
        [10209],
        [10209],
        [10209],
        [10209],
        [10209],
        [10209],
        [10209],
        [10209],
        [10209],
        [10209],
        [10209],
        [10209]], device='cuda:0')
[2024-07-24 10:30:09,497][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:09,498][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,499][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,499][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,500][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,501][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,501][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,502][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,504][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,505][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,506][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,507][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,507][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,508][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.6169, 0.3831], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,509][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.0068, 0.9932], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,509][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.4028, 0.5972], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,510][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.3367, 0.6633], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,511][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.0756, 0.9244], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,511][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.5188, 0.4812], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,512][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0939, 0.9061], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,513][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.0055, 0.9945], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,514][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.1308, 0.8692], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,514][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.8505, 0.1495], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,517][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.6409, 0.3591], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,520][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,524][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3027, 0.3260, 0.3713], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,525][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([5.8156e-06, 8.1871e-01, 1.8128e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,526][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2319, 0.3850, 0.3831], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,526][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0560, 0.8679, 0.0761], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,527][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0433, 0.6382, 0.3185], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,529][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8782, 0.0814, 0.0404], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,532][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1228, 0.4361, 0.4412], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,536][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0016, 0.5734, 0.4250], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,540][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0278, 0.6084, 0.3638], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,541][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9308, 0.0609, 0.0083], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,542][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3436, 0.2322, 0.4242], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,542][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0214, 0.8762, 0.1024], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,544][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.2371, 0.3220, 0.2266, 0.2143], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,546][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([8.2233e-05, 3.0541e-01, 6.6064e-01, 3.3873e-02], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,549][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.1658, 0.2829, 0.2822, 0.2692], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,553][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0295, 0.7809, 0.1212, 0.0683], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,556][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.0244, 0.4423, 0.2427, 0.2905], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,556][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.5236, 0.1833, 0.1285, 0.1646], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,557][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.0677, 0.3073, 0.3131, 0.3119], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,558][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0014, 0.4312, 0.3546, 0.2127], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,559][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0261, 0.4361, 0.2828, 0.2549], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,561][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.9402, 0.0494, 0.0071, 0.0033], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,564][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.3762, 0.1494, 0.2749, 0.1995], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,567][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0522, 0.7012, 0.1023, 0.1442], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,572][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.1895, 0.1916, 0.2187, 0.1461, 0.2541], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,572][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ went] are: tensor([4.8461e-05, 4.7966e-02, 9.1473e-01, 1.2764e-02, 2.4493e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,573][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1346, 0.2183, 0.2173, 0.2082, 0.2216], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,574][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.0424, 0.7308, 0.0628, 0.0337, 0.1303], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,576][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.0330, 0.3118, 0.1540, 0.1596, 0.3416], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,578][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.3145, 0.1860, 0.1900, 0.1809, 0.1286], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,582][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ went] are: tensor([0.0655, 0.2110, 0.2457, 0.2237, 0.2542], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,587][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0020, 0.3585, 0.2290, 0.1564, 0.2541], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,588][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0379, 0.2759, 0.1723, 0.1547, 0.3591], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,588][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.9427, 0.0427, 0.0050, 0.0028, 0.0067], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,589][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.2080, 0.1409, 0.2454, 0.1722, 0.2336], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,590][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0113, 0.8076, 0.0462, 0.0899, 0.0450], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,592][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2395, 0.1501, 0.1391, 0.1111, 0.1965, 0.1637], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,594][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.3001e-05, 2.4249e-01, 9.0732e-02, 5.2159e-02, 6.0851e-01, 6.0570e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,598][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1166, 0.1798, 0.1813, 0.1751, 0.1859, 0.1613], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,601][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0944, 0.6732, 0.0410, 0.0452, 0.1220, 0.0242], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,603][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0221, 0.2467, 0.1314, 0.1465, 0.2682, 0.1852], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,604][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6742, 0.0961, 0.0332, 0.0601, 0.0343, 0.1021], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,605][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0177, 0.1701, 0.1942, 0.2137, 0.2266, 0.1778], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,605][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0046, 0.2301, 0.1696, 0.1230, 0.2142, 0.2584], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,608][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0232, 0.2275, 0.1626, 0.1607, 0.2969, 0.1291], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,611][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.9381, 0.0429, 0.0047, 0.0039, 0.0063, 0.0041], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,614][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1397, 0.1225, 0.1937, 0.1550, 0.1836, 0.2055], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,618][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0758, 0.4974, 0.0959, 0.0938, 0.0811, 0.1561], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:09,619][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2122, 0.1321, 0.1115, 0.0898, 0.1757, 0.1417, 0.1370],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,620][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.7293e-05, 6.0419e-02, 4.4244e-01, 9.7396e-03, 1.9014e-01, 2.8932e-01,
        7.9181e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,621][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0967, 0.1557, 0.1556, 0.1498, 0.1605, 0.1376, 0.1440],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,622][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0739, 0.7103, 0.0417, 0.0295, 0.0969, 0.0201, 0.0275],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,625][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0214, 0.2071, 0.1004, 0.1086, 0.2226, 0.1478, 0.1922],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,629][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.4898, 0.1147, 0.0574, 0.0820, 0.0565, 0.1292, 0.0704],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,632][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0155, 0.1471, 0.1645, 0.1718, 0.1800, 0.1549, 0.1662],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,634][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0029, 0.2033, 0.1486, 0.0948, 0.1689, 0.2100, 0.1715],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,635][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0157, 0.1909, 0.1392, 0.1393, 0.2604, 0.0946, 0.1600],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,636][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.9557, 0.0322, 0.0028, 0.0018, 0.0039, 0.0022, 0.0014],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,637][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1405, 0.0976, 0.1695, 0.1189, 0.1462, 0.1744, 0.1529],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,639][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1463, 0.3204, 0.0926, 0.0687, 0.0786, 0.1611, 0.1323],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:09,642][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1573, 0.1190, 0.1037, 0.0904, 0.1686, 0.1229, 0.1171, 0.1210],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,645][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ station] are: tensor([1.1476e-05, 5.5393e-02, 4.4265e-01, 1.6587e-02, 3.7170e-01, 2.5697e-02,
        6.9694e-02, 1.8266e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,648][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0833, 0.1337, 0.1351, 0.1296, 0.1406, 0.1187, 0.1259, 0.1332],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,650][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.0295, 0.7641, 0.0275, 0.0208, 0.0820, 0.0198, 0.0258, 0.0305],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,650][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0227, 0.1715, 0.0793, 0.0862, 0.1912, 0.1112, 0.1537, 0.1842],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,651][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.3855, 0.1091, 0.0544, 0.0880, 0.0608, 0.1106, 0.0700, 0.1216],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,652][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0353, 0.1346, 0.1359, 0.1356, 0.1488, 0.1299, 0.1410, 0.1389],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,654][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0023, 0.1729, 0.1340, 0.0841, 0.1345, 0.1847, 0.1419, 0.1455],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,657][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0135, 0.1681, 0.1272, 0.1071, 0.2196, 0.0871, 0.1530, 0.1245],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,661][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ station] are: tensor([0.9554, 0.0313, 0.0030, 0.0016, 0.0041, 0.0019, 0.0013, 0.0014],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,665][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.1574, 0.0735, 0.1370, 0.1017, 0.1258, 0.1472, 0.1261, 0.1314],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,666][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.1483, 0.3177, 0.0688, 0.0468, 0.0667, 0.1004, 0.0843, 0.1671],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:09,667][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1321, 0.0879, 0.1105, 0.0785, 0.1302, 0.1099, 0.1197, 0.0999, 0.1313],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,668][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8754e-07, 1.3419e-01, 2.9973e-02, 1.3128e-02, 4.6935e-01, 3.9576e-02,
        1.0032e-01, 2.1270e-01, 7.6113e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,670][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0763, 0.1183, 0.1205, 0.1159, 0.1251, 0.1070, 0.1124, 0.1187, 0.1057],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,672][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0323, 0.5827, 0.0528, 0.0474, 0.1236, 0.0276, 0.0461, 0.0695, 0.0181],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,676][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0100, 0.1373, 0.0745, 0.0895, 0.1658, 0.1086, 0.1501, 0.1949, 0.0693],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,681][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8217, 0.0356, 0.0086, 0.0167, 0.0095, 0.0364, 0.0183, 0.0300, 0.0231],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,681][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0217, 0.1182, 0.1196, 0.1296, 0.1378, 0.1115, 0.1268, 0.1282, 0.1067],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,682][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0014, 0.1578, 0.0944, 0.0684, 0.1167, 0.1413, 0.1480, 0.1505, 0.1215],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,683][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0130, 0.1490, 0.0953, 0.1300, 0.2005, 0.0711, 0.1391, 0.1252, 0.0768],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,684][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.7140e-01, 2.0233e-02, 1.4550e-03, 1.1624e-03, 2.1590e-03, 1.2335e-03,
        8.6491e-04, 1.1452e-03, 3.4881e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,686][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1032, 0.0783, 0.1188, 0.0991, 0.1249, 0.1300, 0.1155, 0.1159, 0.1141],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,688][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0320, 0.1185, 0.0413, 0.0237, 0.0244, 0.0947, 0.0924, 0.2094, 0.3636],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:09,692][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.0705, 0.1091, 0.0915, 0.0751, 0.1303, 0.1098, 0.1055, 0.1055, 0.1168,
        0.0860], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,695][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([9.2248e-06, 1.0664e-01, 1.1713e-01, 8.6079e-03, 2.4542e-01, 4.2410e-02,
        3.8358e-02, 4.2663e-01, 1.2390e-02, 2.4115e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,697][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0660, 0.1080, 0.1097, 0.1049, 0.1129, 0.0960, 0.1011, 0.1069, 0.0942,
        0.1001], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,698][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0087, 0.5509, 0.0569, 0.0335, 0.1475, 0.0339, 0.0597, 0.0779, 0.0152,
        0.0158], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,699][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.0072, 0.1197, 0.0678, 0.0835, 0.1735, 0.0929, 0.1398, 0.1821, 0.0543,
        0.0793], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,699][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.4346, 0.0991, 0.0462, 0.0569, 0.0413, 0.0891, 0.0528, 0.0807, 0.0539,
        0.0454], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,702][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([0.0205, 0.1113, 0.1110, 0.1052, 0.1191, 0.1054, 0.1139, 0.1095, 0.1021,
        0.1022], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,705][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0007, 0.1466, 0.0978, 0.0622, 0.1027, 0.1422, 0.1324, 0.1334, 0.1084,
        0.0737], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,708][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0058, 0.1359, 0.1110, 0.0967, 0.2105, 0.0680, 0.1344, 0.1065, 0.0592,
        0.0720], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,711][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([9.6041e-01, 2.7156e-02, 2.5946e-03, 1.2683e-03, 3.5510e-03, 1.5732e-03,
        1.1956e-03, 1.5107e-03, 3.6202e-04, 3.8263e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,712][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.1345, 0.0627, 0.1084, 0.0822, 0.1140, 0.1208, 0.1030, 0.0885, 0.0950,
        0.0909], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,713][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0288, 0.1155, 0.0197, 0.0173, 0.0180, 0.0829, 0.0827, 0.2197, 0.2592,
        0.1562], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:09,714][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1613, 0.0826, 0.0616, 0.0571, 0.1003, 0.0862, 0.0785, 0.0841, 0.1117,
        0.0771, 0.0995], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,715][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.2478e-05, 8.9253e-02, 2.1653e-01, 1.2532e-02, 1.0586e-01, 3.0790e-02,
        7.9635e-02, 4.3752e-01, 1.5153e-02, 7.1453e-03, 5.5681e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,717][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0637, 0.0975, 0.0987, 0.0960, 0.1022, 0.0878, 0.0926, 0.0979, 0.0865,
        0.0921, 0.0850], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,720][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0831, 0.5710, 0.0426, 0.0373, 0.0991, 0.0247, 0.0364, 0.0439, 0.0170,
        0.0174, 0.0275], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,724][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0188, 0.1269, 0.0595, 0.0677, 0.1360, 0.0842, 0.1127, 0.1407, 0.0523,
        0.0629, 0.1382], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,728][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.3760, 0.0964, 0.0309, 0.0567, 0.0340, 0.0711, 0.0501, 0.0878, 0.0501,
        0.0514, 0.0955], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,729][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0209, 0.0958, 0.0999, 0.0963, 0.1066, 0.0956, 0.1001, 0.1038, 0.0911,
        0.0934, 0.0964], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,730][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0042, 0.1242, 0.0796, 0.0598, 0.0942, 0.1142, 0.0912, 0.1008, 0.0926,
        0.0681, 0.1711], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,731][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0178, 0.1189, 0.0750, 0.0865, 0.1627, 0.0640, 0.1072, 0.1006, 0.0609,
        0.0773, 0.1289], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,732][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([9.7111e-01, 1.9127e-02, 1.6292e-03, 1.1516e-03, 2.1496e-03, 1.3665e-03,
        8.3495e-04, 9.0119e-04, 3.5874e-04, 3.7938e-04, 9.9384e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,735][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1108, 0.0649, 0.0970, 0.0791, 0.0944, 0.1060, 0.0919, 0.0874, 0.0939,
        0.0832, 0.0912], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,739][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0892, 0.2047, 0.0279, 0.0228, 0.0227, 0.0764, 0.0630, 0.1374, 0.1720,
        0.1359, 0.0481], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:09,743][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1822, 0.0723, 0.0624, 0.0480, 0.0937, 0.0764, 0.0726, 0.0707, 0.0865,
        0.0596, 0.0802, 0.0953], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,744][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([3.2860e-06, 6.3931e-03, 3.4252e-01, 4.0130e-03, 3.7133e-02, 1.2885e-01,
        3.4816e-02, 3.8460e-01, 4.0383e-02, 2.5384e-03, 1.7721e-02, 1.0336e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,745][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0592, 0.0896, 0.0907, 0.0879, 0.0941, 0.0800, 0.0847, 0.0896, 0.0791,
        0.0842, 0.0782, 0.0827], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,746][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1326, 0.4761, 0.0424, 0.0374, 0.1205, 0.0196, 0.0325, 0.0447, 0.0161,
        0.0169, 0.0341, 0.0272], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,748][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0163, 0.1104, 0.0534, 0.0585, 0.1172, 0.0773, 0.1010, 0.1235, 0.0483,
        0.0553, 0.1230, 0.1158], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,751][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.5916, 0.0515, 0.0140, 0.0267, 0.0156, 0.0445, 0.0266, 0.0450, 0.0302,
        0.0287, 0.0682, 0.0574], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,755][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0148, 0.0788, 0.0907, 0.0889, 0.0980, 0.0877, 0.0916, 0.0963, 0.0863,
        0.0863, 0.0897, 0.0910], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,759][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0036, 0.1094, 0.0605, 0.0480, 0.0801, 0.0908, 0.0735, 0.0852, 0.0762,
        0.0566, 0.1478, 0.1685], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,760][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0183, 0.1132, 0.0699, 0.0848, 0.1448, 0.0550, 0.0953, 0.0886, 0.0533,
        0.0699, 0.1125, 0.0943], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,761][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.8392e-01, 1.1702e-02, 7.2540e-04, 4.0303e-04, 9.9856e-04, 5.8626e-04,
        3.4828e-04, 3.7973e-04, 1.4565e-04, 1.2514e-04, 4.6606e-04, 1.9550e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,762][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1020, 0.0596, 0.0921, 0.0683, 0.0876, 0.0976, 0.0856, 0.0770, 0.0861,
        0.0699, 0.0780, 0.0963], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,764][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1129, 0.0890, 0.0389, 0.0183, 0.0255, 0.0669, 0.0566, 0.1233, 0.2436,
        0.0957, 0.0465, 0.0829], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:09,767][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1261, 0.0772, 0.0532, 0.0490, 0.0952, 0.0736, 0.0679, 0.0707, 0.0872,
        0.0618, 0.0849, 0.0851, 0.0680], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,770][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([2.4474e-05, 6.5012e-02, 1.4238e-01, 1.7852e-02, 4.6742e-01, 3.2897e-02,
        3.4753e-02, 8.8393e-02, 1.5184e-02, 4.1294e-03, 7.4625e-02, 4.7226e-02,
        1.0099e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,773][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0526, 0.0834, 0.0842, 0.0813, 0.0871, 0.0739, 0.0782, 0.0827, 0.0729,
        0.0778, 0.0716, 0.0765, 0.0777], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,775][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0343, 0.5565, 0.0502, 0.0319, 0.1242, 0.0168, 0.0400, 0.0511, 0.0116,
        0.0130, 0.0217, 0.0267, 0.0221], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,776][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0119, 0.0957, 0.0457, 0.0542, 0.1192, 0.0647, 0.0941, 0.1180, 0.0379,
        0.0522, 0.1135, 0.1027, 0.0901], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,777][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.3601, 0.0945, 0.0381, 0.0493, 0.0381, 0.0599, 0.0456, 0.0666, 0.0368,
        0.0345, 0.0690, 0.0650, 0.0425], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,777][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([0.0229, 0.0799, 0.0805, 0.0791, 0.0891, 0.0825, 0.0861, 0.0847, 0.0773,
        0.0774, 0.0838, 0.0870, 0.0695], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,779][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0028, 0.1000, 0.0510, 0.0403, 0.0649, 0.0756, 0.0619, 0.0762, 0.0575,
        0.0462, 0.1268, 0.1468, 0.1502], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,782][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0124, 0.1069, 0.0690, 0.0681, 0.1393, 0.0514, 0.0914, 0.0815, 0.0443,
        0.0569, 0.1000, 0.0862, 0.0924], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,784][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([9.8032e-01, 1.5185e-02, 7.7976e-04, 3.6471e-04, 1.1240e-03, 5.5699e-04,
        3.2798e-04, 4.1968e-04, 9.5428e-05, 1.0257e-04, 3.7527e-04, 1.4991e-04,
        1.9487e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,788][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.1806, 0.0475, 0.0760, 0.0573, 0.0820, 0.0814, 0.0675, 0.0660, 0.0727,
        0.0599, 0.0707, 0.0752, 0.0632], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,791][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0918, 0.1430, 0.0232, 0.0149, 0.0182, 0.0534, 0.0580, 0.1304, 0.1555,
        0.0876, 0.0365, 0.0916, 0.0959], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:09,792][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1746, 0.0707, 0.0423, 0.0421, 0.0819, 0.0665, 0.0567, 0.0647, 0.0810,
        0.0527, 0.0772, 0.0698, 0.0556, 0.0642], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,792][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.2018e-06, 5.9458e-02, 1.6914e-02, 6.7135e-03, 1.1123e-01, 8.2936e-04,
        1.9381e-01, 2.8238e-01, 6.6256e-03, 4.4544e-03, 1.0670e-01, 1.4971e-01,
        6.0642e-02, 5.3604e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,794][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0509, 0.0762, 0.0772, 0.0754, 0.0801, 0.0683, 0.0722, 0.0764, 0.0680,
        0.0722, 0.0670, 0.0709, 0.0713, 0.0738], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,797][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1135, 0.4559, 0.0448, 0.0395, 0.1098, 0.0201, 0.0290, 0.0435, 0.0140,
        0.0154, 0.0288, 0.0249, 0.0191, 0.0416], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,801][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0181, 0.0944, 0.0424, 0.0455, 0.0918, 0.0637, 0.0816, 0.0977, 0.0381,
        0.0422, 0.0972, 0.0935, 0.0755, 0.1183], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,806][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.5516, 0.0415, 0.0119, 0.0220, 0.0125, 0.0347, 0.0237, 0.0365, 0.0278,
        0.0267, 0.0529, 0.0482, 0.0376, 0.0723], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,807][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0092, 0.0686, 0.0745, 0.0801, 0.0859, 0.0703, 0.0800, 0.0867, 0.0703,
        0.0767, 0.0724, 0.0796, 0.0678, 0.0778], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,807][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0042, 0.0790, 0.0398, 0.0352, 0.0600, 0.0642, 0.0532, 0.0633, 0.0570,
        0.0427, 0.1091, 0.1230, 0.1316, 0.1378], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,808][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0142, 0.0972, 0.0556, 0.0720, 0.1234, 0.0449, 0.0798, 0.0749, 0.0444,
        0.0583, 0.0910, 0.0776, 0.0903, 0.0764], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,810][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.8937e-01, 7.9054e-03, 3.7773e-04, 2.7414e-04, 5.7493e-04, 3.4463e-04,
        1.8875e-04, 2.2045e-04, 8.1236e-05, 7.5807e-05, 2.6555e-04, 1.0220e-04,
        1.2396e-04, 9.2501e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,813][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0923, 0.0505, 0.0751, 0.0588, 0.0745, 0.0778, 0.0710, 0.0663, 0.0725,
        0.0610, 0.0695, 0.0799, 0.0670, 0.0837], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,817][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1286, 0.1309, 0.0295, 0.0155, 0.0208, 0.0483, 0.0462, 0.0955, 0.1408,
        0.0833, 0.0344, 0.0613, 0.0597, 0.1054], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:09,904][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:09,909][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,909][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,910][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,911][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,911][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,912][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,913][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,913][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,914][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,915][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,915][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,916][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:09,917][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([9.9994e-01, 5.6974e-05], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,917][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0010, 0.9990], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,918][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.9394, 0.0606], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,919][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.3367, 0.6633], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,922][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.0021, 0.9979], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,924][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.0843, 0.9157], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,924][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.8200, 0.1800], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,925][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0024, 0.9976], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,926][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.8089, 0.1911], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,927][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.7183, 0.2817], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,929][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.1523, 0.8477], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,932][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.0180, 0.9820], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:09,935][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.9299, 0.0019, 0.0683], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,938][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3058e-04, 9.7163e-01, 2.8138e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,939][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2198, 0.6256, 0.1545], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,940][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0560, 0.8679, 0.0761], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,941][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([1.1547e-06, 9.9998e-01, 1.4836e-05], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,942][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([7.6698e-05, 9.9988e-01, 4.3529e-05], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,942][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4089, 0.4864, 0.1047], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,944][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.2815e-06, 1.0000e+00, 1.0326e-06], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,946][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0356, 0.9543, 0.0102], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,950][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2188, 0.7377, 0.0435], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,953][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0259, 0.9479, 0.0262], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,955][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([1.8585e-04, 9.9810e-01, 1.7134e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:09,956][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.8424, 0.0063, 0.1233, 0.0280], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,957][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([1.1227e-04, 9.6893e-01, 2.2152e-02, 8.8096e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,958][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.1758, 0.4433, 0.1366, 0.2444], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,958][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.0295, 0.7809, 0.1212, 0.0683], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,960][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([2.9731e-06, 9.9990e-01, 6.1154e-05, 3.3809e-05], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,962][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([2.1595e-04, 9.9939e-01, 1.6924e-04, 2.2569e-04], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,965][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.1757, 0.4584, 0.1653, 0.2006], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,967][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([2.5259e-06, 9.9999e-01, 4.3286e-06, 3.7410e-06], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,971][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0284, 0.9390, 0.0141, 0.0185], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,972][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.1194, 0.7555, 0.0745, 0.0506], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,973][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.0108, 0.9290, 0.0319, 0.0282], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,973][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([1.6994e-04, 9.9560e-01, 3.5071e-03, 7.1988e-04], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:09,974][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.9452, 0.0011, 0.0386, 0.0089, 0.0062], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,975][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([7.9800e-04, 9.0679e-01, 3.1088e-02, 1.4289e-02, 4.7036e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,978][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.2611, 0.2717, 0.0810, 0.1415, 0.2447], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,982][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.0424, 0.7308, 0.0628, 0.0337, 0.1303], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,985][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([6.2729e-06, 9.9948e-01, 2.4108e-05, 9.5473e-06, 4.7656e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,987][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([1.3345e-04, 9.9913e-01, 3.8954e-05, 5.4420e-05, 6.4475e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,987][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([0.4598, 0.2244, 0.0604, 0.1001, 0.1554], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,988][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([6.6189e-06, 9.9996e-01, 1.0469e-06, 1.1763e-06, 2.6283e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,989][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0379, 0.9083, 0.0083, 0.0095, 0.0361], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,991][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.1961, 0.6438, 0.0394, 0.0326, 0.0882], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,993][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0280, 0.8436, 0.0228, 0.0217, 0.0840], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,996][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([1.1886e-04, 9.9299e-01, 1.2644e-03, 2.5510e-04, 5.3763e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:09,998][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([9.6442e-01, 1.7445e-04, 2.1080e-02, 4.0671e-03, 2.5978e-03, 7.6631e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,002][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0025, 0.8754, 0.0223, 0.0163, 0.0461, 0.0374], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,003][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.5148, 0.0799, 0.0632, 0.1130, 0.1948, 0.0344], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,004][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0944, 0.6732, 0.0410, 0.0452, 0.1220, 0.0242], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,004][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.3825e-07, 9.9986e-01, 2.9276e-06, 3.4275e-06, 1.2668e-04, 4.0839e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,005][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.3085e-05, 9.9946e-01, 1.3639e-05, 3.8495e-05, 4.6237e-04, 1.6777e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,007][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.7420, 0.0793, 0.0206, 0.0632, 0.0535, 0.0415], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,009][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([3.7026e-07, 9.9999e-01, 1.2316e-07, 4.1039e-07, 7.6323e-06, 5.9958e-08],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,013][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0437, 0.8999, 0.0072, 0.0145, 0.0310, 0.0038], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,017][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.5269, 0.3364, 0.0228, 0.0364, 0.0594, 0.0181], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,018][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0594, 0.8259, 0.0176, 0.0284, 0.0624, 0.0063], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,019][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([6.0838e-04, 9.8548e-01, 1.9368e-03, 8.3483e-04, 9.0497e-03, 2.0865e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,020][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([8.8969e-01, 5.0817e-04, 2.2839e-02, 5.1977e-03, 4.1850e-03, 9.6715e-03,
        6.7908e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,020][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0049, 0.7684, 0.0436, 0.0269, 0.0610, 0.0576, 0.0376],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,022][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3164, 0.1443, 0.0648, 0.1147, 0.2555, 0.0380, 0.0663],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,025][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0739, 0.7103, 0.0417, 0.0295, 0.0969, 0.0201, 0.0275],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,027][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.8685e-07, 9.9986e-01, 2.7180e-06, 1.6542e-06, 1.2860e-04, 1.9030e-06,
        2.8896e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,030][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.3718e-05, 9.9900e-01, 2.2261e-05, 3.6420e-05, 8.8624e-04, 1.2798e-05,
        2.3650e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,034][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.6523, 0.0853, 0.0323, 0.0683, 0.0727, 0.0508, 0.0383],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,034][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.9601e-07, 9.9999e-01, 1.8255e-07, 2.4592e-07, 1.3611e-05, 4.8795e-08,
        1.2428e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,035][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0179, 0.9330, 0.0055, 0.0085, 0.0300, 0.0025, 0.0026],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,036][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3706, 0.4685, 0.0253, 0.0285, 0.0720, 0.0187, 0.0164],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,037][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0322, 0.8629, 0.0160, 0.0188, 0.0592, 0.0040, 0.0069],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,040][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.5221e-04, 9.8941e-01, 1.1562e-03, 3.3919e-04, 6.7823e-03, 1.0651e-03,
        1.0962e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,040][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.7943, 0.0012, 0.0441, 0.0098, 0.0105, 0.0164, 0.1224, 0.0013],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,041][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0017, 0.7882, 0.0341, 0.0199, 0.0508, 0.0464, 0.0296, 0.0293],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,044][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2376, 0.1590, 0.0611, 0.0923, 0.2506, 0.0297, 0.0665, 0.1033],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,048][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0295, 0.7641, 0.0275, 0.0208, 0.0820, 0.0198, 0.0258, 0.0305],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,050][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([3.9053e-07, 9.9970e-01, 4.7693e-06, 2.5216e-06, 2.7761e-04, 1.0562e-06,
        2.8474e-06, 1.1580e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,051][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([2.1637e-05, 9.9892e-01, 1.8118e-05, 2.4657e-05, 9.3904e-04, 4.5321e-06,
        1.3298e-05, 5.5827e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,052][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([0.3926, 0.1526, 0.0738, 0.1084, 0.1363, 0.0607, 0.0432, 0.0325],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,053][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([2.3472e-07, 9.9998e-01, 1.9050e-07, 1.8520e-07, 1.9184e-05, 1.6229e-08,
        7.2538e-08, 3.8892e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,055][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0102, 0.9436, 0.0041, 0.0050, 0.0258, 0.0021, 0.0026, 0.0065],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,057][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([0.2955, 0.5243, 0.0275, 0.0275, 0.0837, 0.0139, 0.0146, 0.0129],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,062][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([0.0136, 0.8840, 0.0129, 0.0135, 0.0606, 0.0025, 0.0049, 0.0081],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,064][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([1.7695e-05, 9.9479e-01, 4.4202e-04, 8.9021e-05, 3.2073e-03, 3.6799e-04,
        4.9323e-04, 5.9210e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,066][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6613, 0.0011, 0.0597, 0.0137, 0.0095, 0.0289, 0.2055, 0.0034, 0.0170],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,067][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([6.8248e-04, 7.5696e-01, 2.8541e-02, 1.5081e-02, 4.6600e-02, 4.9138e-02,
        4.2822e-02, 5.0553e-02, 9.6238e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,068][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1890, 0.1152, 0.0761, 0.1150, 0.2275, 0.0393, 0.0753, 0.1115, 0.0511],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,069][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0323, 0.5827, 0.0528, 0.0474, 0.1236, 0.0276, 0.0461, 0.0695, 0.0181],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,070][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([2.1496e-06, 9.9835e-01, 3.3964e-05, 3.6524e-05, 9.3235e-04, 2.7168e-05,
        9.9813e-05, 5.1656e-04, 4.1698e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,072][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([2.1840e-04, 9.9083e-01, 1.8280e-04, 5.3131e-04, 4.0552e-03, 1.3128e-04,
        4.9590e-04, 3.4915e-03, 6.1810e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,075][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1362, 0.2110, 0.0521, 0.0945, 0.1262, 0.1031, 0.1033, 0.0912, 0.0824],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,078][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([3.0239e-06, 9.9982e-01, 3.0013e-06, 6.5314e-06, 9.3013e-05, 1.1097e-06,
        6.9234e-06, 6.5295e-05, 3.7959e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,082][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0516, 0.7689, 0.0152, 0.0382, 0.0619, 0.0067, 0.0118, 0.0393, 0.0064],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,083][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2737, 0.4108, 0.0392, 0.0513, 0.0947, 0.0294, 0.0351, 0.0436, 0.0222],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,083][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0259, 0.7363, 0.0265, 0.0401, 0.0990, 0.0084, 0.0193, 0.0388, 0.0056],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,084][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([3.6461e-04, 9.5993e-01, 3.6996e-03, 1.4789e-03, 1.4592e-02, 3.4908e-03,
        6.4519e-03, 9.4361e-03, 5.5719e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,086][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.4415, 0.0049, 0.0931, 0.0211, 0.0178, 0.0534, 0.3302, 0.0067, 0.0183,
        0.0131], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,088][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([1.2323e-04, 8.7387e-01, 1.5532e-02, 6.9838e-03, 2.2975e-02, 2.3654e-02,
        2.4353e-02, 2.3478e-02, 4.3784e-03, 4.6475e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,093][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0982, 0.1530, 0.0693, 0.1041, 0.2272, 0.0352, 0.0688, 0.1379, 0.0370,
        0.0693], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,096][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.0087, 0.5509, 0.0569, 0.0335, 0.1475, 0.0339, 0.0597, 0.0779, 0.0152,
        0.0158], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,098][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([3.1297e-07, 9.9865e-01, 3.0690e-05, 1.6484e-05, 9.9541e-04, 1.4781e-05,
        5.3910e-05, 2.3296e-04, 9.0295e-07, 8.9513e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,098][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([3.3000e-05, 9.9467e-01, 1.4407e-04, 2.1277e-04, 3.1964e-03, 6.1469e-05,
        2.3608e-04, 1.4061e-03, 1.2312e-05, 2.6596e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,099][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([0.0497, 0.2698, 0.0651, 0.0839, 0.1236, 0.0907, 0.1017, 0.0944, 0.0699,
        0.0511], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,100][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([1.6655e-07, 9.9990e-01, 2.3939e-06, 1.6490e-06, 7.9872e-05, 4.8655e-07,
        2.8869e-06, 1.7361e-05, 4.9601e-08, 6.8954e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,102][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0099, 0.8600, 0.0116, 0.0145, 0.0561, 0.0056, 0.0104, 0.0257, 0.0024,
        0.0038], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,105][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.1075, 0.5064, 0.0535, 0.0399, 0.1373, 0.0318, 0.0414, 0.0481, 0.0163,
        0.0178], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,109][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.0055, 0.8138, 0.0215, 0.0221, 0.0783, 0.0062, 0.0141, 0.0312, 0.0027,
        0.0046], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,112][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([7.4595e-05, 9.6718e-01, 2.9934e-03, 6.3988e-04, 1.5154e-02, 2.1211e-03,
        4.4244e-03, 7.0587e-03, 1.7572e-04, 1.7985e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,114][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.8321, 0.0008, 0.0284, 0.0079, 0.0047, 0.0163, 0.0928, 0.0012, 0.0082,
        0.0052, 0.0025], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,114][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0037, 0.7741, 0.0301, 0.0190, 0.0418, 0.0321, 0.0320, 0.0333, 0.0104,
        0.0113, 0.0123], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,115][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.3024, 0.0783, 0.0510, 0.1067, 0.1745, 0.0255, 0.0500, 0.0728, 0.0395,
        0.0627, 0.0367], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,116][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0831, 0.5710, 0.0426, 0.0373, 0.0991, 0.0247, 0.0364, 0.0439, 0.0170,
        0.0174, 0.0275], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,117][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([9.2714e-06, 9.9921e-01, 1.4585e-05, 2.2141e-05, 5.3759e-04, 4.7217e-06,
        1.6445e-05, 8.1490e-05, 1.3062e-06, 9.6349e-07, 9.8680e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,120][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([2.6019e-04, 9.9752e-01, 4.6428e-05, 1.5301e-04, 1.2698e-03, 1.6504e-05,
        5.6008e-05, 3.0315e-04, 1.1983e-05, 1.8911e-05, 3.4292e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,123][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.6563, 0.0407, 0.0224, 0.0592, 0.0445, 0.0267, 0.0253, 0.0215, 0.0435,
        0.0323, 0.0276], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,125][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.1987e-05, 9.9995e-01, 7.1552e-07, 1.7926e-06, 2.5897e-05, 7.8397e-08,
        3.8453e-07, 3.1734e-06, 5.8162e-08, 5.9420e-08, 3.2046e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,129][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0874, 0.7515, 0.0115, 0.0263, 0.0554, 0.0047, 0.0062, 0.0211, 0.0041,
        0.0058, 0.0260], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,130][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.5649, 0.2126, 0.0254, 0.0367, 0.0594, 0.0165, 0.0157, 0.0145, 0.0124,
        0.0155, 0.0264], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,131][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0614, 0.7418, 0.0220, 0.0345, 0.0775, 0.0051, 0.0107, 0.0176, 0.0041,
        0.0065, 0.0188], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,132][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([4.8638e-04, 9.7519e-01, 2.2096e-03, 8.4490e-04, 1.0980e-02, 1.7358e-03,
        2.4144e-03, 3.4290e-03, 2.5942e-04, 2.1766e-04, 2.2354e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,133][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([7.9132e-01, 1.8938e-04, 1.5825e-02, 3.6672e-03, 2.2425e-03, 6.8242e-03,
        4.7389e-02, 5.1908e-04, 3.7279e-03, 2.5540e-03, 9.5798e-04, 1.2478e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,136][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0081, 0.5472, 0.0423, 0.0317, 0.0656, 0.0583, 0.0554, 0.0654, 0.0185,
        0.0233, 0.0322, 0.0520], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,140][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4019, 0.0622, 0.0443, 0.0775, 0.1620, 0.0188, 0.0384, 0.0582, 0.0296,
        0.0457, 0.0295, 0.0318], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,145][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1326, 0.4761, 0.0424, 0.0374, 0.1205, 0.0196, 0.0325, 0.0447, 0.0161,
        0.0169, 0.0341, 0.0272], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,146][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.0004e-05, 9.9907e-01, 1.4254e-05, 1.7766e-05, 6.0665e-04, 5.2882e-06,
        1.5852e-05, 8.2071e-05, 1.4711e-06, 8.1139e-07, 1.2835e-04, 4.3856e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,147][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([3.0345e-04, 9.9668e-01, 4.2896e-05, 1.6806e-04, 1.5618e-03, 2.0528e-05,
        5.6707e-05, 3.9184e-04, 1.4022e-05, 2.1485e-05, 5.6187e-04, 1.8214e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,147][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6949, 0.0306, 0.0154, 0.0335, 0.0364, 0.0256, 0.0225, 0.0190, 0.0397,
        0.0264, 0.0296, 0.0264], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,149][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.4617e-05, 9.9994e-01, 5.7224e-07, 1.9726e-06, 2.7712e-05, 5.8895e-08,
        3.4331e-07, 4.0118e-06, 6.5611e-08, 6.7312e-08, 3.9684e-06, 2.5397e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,152][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1550, 0.6863, 0.0104, 0.0235, 0.0546, 0.0042, 0.0052, 0.0167, 0.0041,
        0.0052, 0.0274, 0.0076], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,156][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.6542, 0.1732, 0.0186, 0.0232, 0.0479, 0.0102, 0.0109, 0.0095, 0.0097,
        0.0100, 0.0213, 0.0113], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,161][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1093, 0.6597, 0.0238, 0.0344, 0.0884, 0.0063, 0.0123, 0.0212, 0.0052,
        0.0073, 0.0226, 0.0094], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,161][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.0948e-03, 9.6381e-01, 2.7208e-03, 1.0556e-03, 1.3419e-02, 2.3546e-03,
        2.9675e-03, 4.2604e-03, 3.2598e-04, 2.7842e-04, 3.0043e-03, 4.7105e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,162][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.5116, 0.0016, 0.0363, 0.0087, 0.0076, 0.0184, 0.1400, 0.0017, 0.0066,
        0.0053, 0.0025, 0.2579, 0.0018], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,163][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0014, 0.6815, 0.0290, 0.0170, 0.0455, 0.0290, 0.0389, 0.0334, 0.0084,
        0.0102, 0.0182, 0.0667, 0.0207], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,165][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.1672, 0.1398, 0.0468, 0.0860, 0.1868, 0.0212, 0.0426, 0.0864, 0.0290,
        0.0552, 0.0352, 0.0476, 0.0562], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,168][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0343, 0.5565, 0.0502, 0.0319, 0.1242, 0.0168, 0.0400, 0.0511, 0.0116,
        0.0130, 0.0217, 0.0267, 0.0221], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,170][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([9.8011e-06, 9.9739e-01, 4.7220e-05, 3.4371e-05, 2.0321e-03, 8.3078e-06,
        3.7531e-05, 1.8968e-04, 1.1249e-06, 1.0463e-06, 1.5944e-04, 5.0196e-05,
        4.3118e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,173][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([3.6527e-04, 9.9391e-01, 1.3939e-04, 2.6921e-04, 3.7477e-03, 2.3784e-05,
        1.1716e-04, 5.9256e-04, 9.7373e-06, 2.2357e-05, 3.6187e-04, 2.0603e-04,
        2.3124e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,177][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([0.3546, 0.0972, 0.0460, 0.0630, 0.0849, 0.0423, 0.0502, 0.0383, 0.0489,
        0.0401, 0.0507, 0.0555, 0.0284], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,177][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([1.6981e-05, 9.9984e-01, 2.3728e-06, 4.2911e-06, 1.2145e-04, 1.0604e-07,
        1.0751e-06, 7.9699e-06, 4.6083e-08, 1.0422e-07, 3.4704e-06, 3.1509e-06,
        3.9949e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,178][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0525, 0.7914, 0.0118, 0.0194, 0.0559, 0.0039, 0.0069, 0.0211, 0.0024,
        0.0042, 0.0149, 0.0065, 0.0093], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,179][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([0.4002, 0.3409, 0.0292, 0.0269, 0.0775, 0.0138, 0.0156, 0.0177, 0.0088,
        0.0110, 0.0238, 0.0133, 0.0213], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,181][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([0.0253, 0.7847, 0.0235, 0.0232, 0.0847, 0.0035, 0.0092, 0.0159, 0.0022,
        0.0034, 0.0120, 0.0057, 0.0066], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,183][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([2.0459e-04, 9.6775e-01, 2.9053e-03, 5.8822e-04, 1.4058e-02, 1.5918e-03,
        3.2697e-03, 3.5039e-03, 1.4066e-04, 1.1757e-04, 1.5920e-03, 3.1142e-03,
        1.1686e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,186][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([7.2494e-01, 2.4537e-04, 2.2463e-02, 5.1390e-03, 3.4770e-03, 1.0175e-02,
        6.2714e-02, 6.6900e-04, 5.9825e-03, 3.3191e-03, 1.4749e-03, 1.3877e-01,
        8.3056e-04, 1.9794e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,190][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0054, 0.5987, 0.0225, 0.0155, 0.0430, 0.0396, 0.0383, 0.0464, 0.0120,
        0.0129, 0.0282, 0.0567, 0.0263, 0.0546], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,192][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3208, 0.0498, 0.0439, 0.0852, 0.1524, 0.0212, 0.0425, 0.0546, 0.0336,
        0.0479, 0.0353, 0.0379, 0.0325, 0.0425], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,193][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1135, 0.4559, 0.0448, 0.0395, 0.1098, 0.0201, 0.0290, 0.0435, 0.0140,
        0.0154, 0.0288, 0.0249, 0.0191, 0.0416], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,194][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([4.4358e-05, 9.9837e-01, 2.2838e-05, 4.0372e-05, 7.5820e-04, 8.3876e-06,
        2.4075e-05, 1.2160e-04, 2.7343e-06, 1.7489e-06, 1.8940e-04, 6.7818e-05,
        7.3486e-05, 2.7382e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,195][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.2474e-03, 9.9220e-01, 9.3591e-05, 3.8608e-04, 2.6628e-03, 3.3311e-05,
        1.0605e-04, 5.7111e-04, 3.2705e-05, 4.9007e-05, 8.4491e-04, 3.1653e-04,
        6.2329e-04, 8.3652e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,197][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5517, 0.0381, 0.0178, 0.0433, 0.0372, 0.0319, 0.0294, 0.0229, 0.0449,
        0.0330, 0.0383, 0.0379, 0.0202, 0.0536], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,199][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.8091e-04, 9.9949e-01, 2.5900e-06, 1.2546e-05, 1.1089e-04, 2.3601e-07,
        1.4279e-06, 1.2263e-05, 3.9652e-07, 4.5783e-07, 1.2649e-05, 9.0822e-06,
        2.1675e-05, 4.4955e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,203][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1353, 0.7127, 0.0103, 0.0256, 0.0481, 0.0027, 0.0037, 0.0115, 0.0030,
        0.0041, 0.0132, 0.0051, 0.0088, 0.0158], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,206][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.6406, 0.1638, 0.0170, 0.0272, 0.0450, 0.0097, 0.0097, 0.0090, 0.0093,
        0.0099, 0.0191, 0.0100, 0.0142, 0.0155], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,208][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1427, 0.6146, 0.0253, 0.0373, 0.0804, 0.0058, 0.0104, 0.0162, 0.0049,
        0.0071, 0.0195, 0.0078, 0.0103, 0.0175], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,209][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.4607e-03, 9.5997e-01, 2.6796e-03, 9.9673e-04, 1.3318e-02, 1.7525e-03,
        2.1218e-03, 3.1273e-03, 2.6076e-04, 2.2102e-04, 2.3395e-03, 3.3924e-03,
        1.6500e-03, 6.7107e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,213][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:10,216][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[6963],
        [9192],
        [ 277],
        [  70],
        [   8],
        [  11],
        [  13],
        [   9],
        [  41],
        [  10],
        [   8],
        [  16],
        [  14],
        [  19]], device='cuda:0')
[2024-07-24 10:30:10,218][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 9316],
        [11342],
        [  218],
        [  440],
        [  122],
        [   19],
        [   87],
        [   20],
        [  149],
        [   75],
        [  105],
        [  111],
        [   53],
        [   72]], device='cuda:0')
[2024-07-24 10:30:10,221][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[20532],
        [30018],
        [28199],
        [28410],
        [25107],
        [25799],
        [26738],
        [26120],
        [27146],
        [27315],
        [28005],
        [28522],
        [28990],
        [29073]], device='cuda:0')
[2024-07-24 10:30:10,224][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[15671],
        [50221],
        [50119],
        [28224],
        [ 6210],
        [30948],
        [ 5209],
        [ 7674],
        [19186],
        [14465],
        [11168],
        [ 3524],
        [ 9024],
        [ 7454]], device='cuda:0')
[2024-07-24 10:30:10,226][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[20616],
        [36511],
        [35760],
        [37118],
        [36412],
        [36214],
        [34812],
        [34843],
        [34021],
        [34212],
        [34300],
        [33633],
        [33925],
        [33765]], device='cuda:0')
[2024-07-24 10:30:10,228][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[36520],
        [48007],
        [48088],
        [48159],
        [47842],
        [47715],
        [47671],
        [47603],
        [47209],
        [46953],
        [47232],
        [46931],
        [47142],
        [46825]], device='cuda:0')
[2024-07-24 10:30:10,229][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[35687],
        [25296],
        [25349],
        [24695],
        [26611],
        [25773],
        [24827],
        [24550],
        [23915],
        [23828],
        [23622],
        [23495],
        [23619],
        [22661]], device='cuda:0')
[2024-07-24 10:30:10,231][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 4181],
        [ 6043],
        [ 4619],
        [ 7088],
        [ 7881],
        [ 6601],
        [ 7730],
        [ 8804],
        [ 5933],
        [ 9239],
        [10283],
        [ 8825],
        [10134],
        [ 9273]], device='cuda:0')
[2024-07-24 10:30:10,233][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12821],
        [ 4467],
        [ 6961],
        [ 5438],
        [ 7717],
        [ 7403],
        [ 6864],
        [ 8228],
        [ 8325],
        [ 7443],
        [ 7751],
        [ 7820],
        [ 8311],
        [ 8705]], device='cuda:0')
[2024-07-24 10:30:10,236][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[13680],
        [18271],
        [17490],
        [18395],
        [20666],
        [21327],
        [20685],
        [21066],
        [21417],
        [21592],
        [21149],
        [21147],
        [22089],
        [21910]], device='cuda:0')
[2024-07-24 10:30:10,239][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 6960],
        [42304],
        [33167],
        [28000],
        [23298],
        [21329],
        [19459],
        [17019],
        [16089],
        [15737],
        [16043],
        [16083],
        [15451],
        [14978]], device='cuda:0')
[2024-07-24 10:30:10,241][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[29799],
        [33567],
        [32151],
        [31838],
        [31774],
        [31799],
        [31331],
        [31389],
        [30889],
        [31266],
        [30934],
        [30455],
        [30563],
        [30227]], device='cuda:0')
[2024-07-24 10:30:10,244][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11576],
        [15665],
        [ 3076],
        [ 4389],
        [ 3531],
        [ 3252],
        [ 3369],
        [ 2385],
        [ 2539],
        [ 3238],
        [ 3543],
        [ 3390],
        [ 3782],
        [ 3639]], device='cuda:0')
[2024-07-24 10:30:10,245][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[17225],
        [ 8248],
        [ 6979],
        [ 6062],
        [ 6804],
        [ 5179],
        [ 4809],
        [ 5045],
        [ 3448],
        [ 3661],
        [ 3944],
        [ 3684],
        [ 4068],
        [ 3774]], device='cuda:0')
[2024-07-24 10:30:10,246][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[7775],
        [ 306],
        [1208],
        [ 195],
        [ 168],
        [1446],
        [ 956],
        [1452],
        [1124],
        [ 612],
        [ 723],
        [1522],
        [1082],
        [2381]], device='cuda:0')
[2024-07-24 10:30:10,248][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[25085],
        [25075],
        [19621],
        [10662],
        [19671],
        [21555],
        [15965],
        [ 9196],
        [ 3827],
        [  791],
        [11189],
        [ 9334],
        [ 1751],
        [ 6195]], device='cuda:0')
[2024-07-24 10:30:10,251][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12252],
        [23470],
        [23674],
        [23440],
        [23513],
        [23048],
        [22386],
        [22753],
        [22670],
        [23065],
        [22589],
        [20895],
        [22092],
        [21307]], device='cuda:0')
[2024-07-24 10:30:10,254][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 7970],
        [ 8468],
        [ 4448],
        [ 3033],
        [ 3061],
        [ 4506],
        [ 5649],
        [ 7469],
        [ 8935],
        [ 9443],
        [ 9711],
        [10122],
        [ 9648],
        [11333]], device='cuda:0')
[2024-07-24 10:30:10,256][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24870],
        [24550],
        [26783],
        [27874],
        [26693],
        [26365],
        [26103],
        [25862],
        [26585],
        [26661],
        [26035],
        [25908],
        [26515],
        [26820]], device='cuda:0')
[2024-07-24 10:30:10,259][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22485],
        [34804],
        [34811],
        [34810],
        [34810],
        [34809],
        [34809],
        [34808],
        [34811],
        [34810],
        [34813],
        [34813],
        [34819],
        [34813]], device='cuda:0')
[2024-07-24 10:30:10,261][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[40044],
        [15073],
        [14712],
        [14712],
        [14712],
        [14711],
        [14713],
        [14713],
        [14778],
        [14737],
        [14719],
        [14727],
        [14734],
        [14741]], device='cuda:0')
[2024-07-24 10:30:10,263][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[32280],
        [ 5936],
        [ 4592],
        [ 4523],
        [ 5013],
        [15362],
        [15223],
        [ 8470],
        [ 9031],
        [ 8120],
        [22751],
        [27245],
        [12177],
        [21163]], device='cuda:0')
[2024-07-24 10:30:10,264][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 5122],
        [19908],
        [19925],
        [19925],
        [19925],
        [19925],
        [19925],
        [19925],
        [19926],
        [19925],
        [19925],
        [19925],
        [19924],
        [19922]], device='cuda:0')
[2024-07-24 10:30:10,266][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14136],
        [ 5475],
        [11411],
        [11298],
        [11739],
        [11632],
        [11710],
        [11735],
        [12369],
        [12247],
        [12340],
        [12308],
        [12306],
        [11926]], device='cuda:0')
[2024-07-24 10:30:10,268][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[13519],
        [21740],
        [ 9028],
        [ 8621],
        [ 9445],
        [15855],
        [11668],
        [10464],
        [10922],
        [ 9306],
        [19989],
        [22913],
        [14742],
        [23029]], device='cuda:0')
[2024-07-24 10:30:10,271][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 1815],
        [22853],
        [23363],
        [23361],
        [23059],
        [22892],
        [23011],
        [22958],
        [21437],
        [22084],
        [21469],
        [20452],
        [22044],
        [20155]], device='cuda:0')
[2024-07-24 10:30:10,274][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12729],
        [19822],
        [19859],
        [19911],
        [19919],
        [20035],
        [19990],
        [19910],
        [20745],
        [20518],
        [20290],
        [20536],
        [20465],
        [20582]], device='cuda:0')
[2024-07-24 10:30:10,276][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[38164],
        [37664],
        [41125],
        [42306],
        [41845],
        [36157],
        [37724],
        [39626],
        [39567],
        [41422],
        [31659],
        [30631],
        [38511],
        [32395]], device='cuda:0')
[2024-07-24 10:30:10,279][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[40561],
        [46498],
        [47282],
        [48873],
        [46333],
        [42918],
        [42692],
        [43120],
        [43406],
        [44361],
        [42598],
        [39892],
        [41826],
        [38083]], device='cuda:0')
[2024-07-24 10:30:10,280][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[25440],
        [25440],
        [25440],
        [25440],
        [25440],
        [25440],
        [25440],
        [25440],
        [25440],
        [25440],
        [25440],
        [25440],
        [25440],
        [25440]], device='cuda:0')
[2024-07-24 10:30:10,374][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:10,375][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,376][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,377][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,377][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,378][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,379][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,382][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,384][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,388][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,390][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,391][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,392][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,393][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.3940, 0.6060], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,393][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([0.0039, 0.9961], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,395][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.6903, 0.3097], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,399][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.0302, 0.9698], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,402][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.5726, 0.4274], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,406][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.9987, 0.0013], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,408][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([8.8835e-04, 9.9911e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,409][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.9011, 0.0989], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,410][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.3420, 0.6580], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,410][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([1.5200e-04, 9.9985e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,411][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([7.9275e-05, 9.9992e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,414][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0207, 0.9793], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,417][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3191, 0.6230, 0.0579], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,419][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([4.1885e-04, 5.7140e-01, 4.2818e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,423][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1715, 0.7306, 0.0978], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,424][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([3.9474e-09, 1.0000e+00, 3.6181e-08], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,425][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4932, 0.2958, 0.2110], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,426][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.8830, 0.0648, 0.0522], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,426][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([6.6933e-05, 9.6495e-01, 3.4987e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,428][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0786, 0.9167, 0.0046], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,431][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2175, 0.4158, 0.3667], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,433][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.0278e-06, 1.6488e-01, 8.3512e-01], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,435][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([1.0228e-09, 1.0000e+00, 2.3705e-08], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,439][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0033, 0.9618, 0.0349], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,440][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.1449, 0.6977, 0.1171, 0.0404], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,441][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([1.7109e-04, 3.4736e-01, 2.7900e-01, 3.7347e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,442][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.1245, 0.6238, 0.1594, 0.0922], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,442][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([2.2506e-08, 1.0000e+00, 1.2909e-06, 7.5086e-08], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,444][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.1438, 0.3625, 0.2499, 0.2438], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,448][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.5498, 0.2194, 0.1089, 0.1219], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,450][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([1.0274e-04, 8.5369e-01, 7.0697e-02, 7.5514e-02], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,453][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0451, 0.9300, 0.0134, 0.0114], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,455][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.1473, 0.3209, 0.2859, 0.2458], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,456][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([4.1170e-07, 9.6561e-02, 8.5871e-01, 4.4724e-02], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,457][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([3.9502e-09, 1.0000e+00, 3.0203e-07, 3.5506e-08], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,457][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0031, 0.6952, 0.1932, 0.1085], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,458][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.4687, 0.3771, 0.0403, 0.0129, 0.1010], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,460][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.0004, 0.4060, 0.1972, 0.1848, 0.2116], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,464][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.1953, 0.5257, 0.0898, 0.0625, 0.1266], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,466][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ went] are: tensor([9.7275e-08, 9.9999e-01, 5.3150e-08, 2.8689e-09, 5.1426e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,469][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.2099, 0.2089, 0.1594, 0.1671, 0.2546], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,471][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.7814, 0.0394, 0.0415, 0.0446, 0.0931], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,472][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ went] are: tensor([1.2649e-04, 7.9845e-01, 3.3071e-02, 5.2638e-02, 1.1571e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,473][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2780, 0.6383, 0.0226, 0.0094, 0.0517], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,473][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.1219, 0.2495, 0.2177, 0.1905, 0.2204], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,475][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ went] are: tensor([2.1398e-06, 1.2872e-01, 5.4602e-01, 1.8328e-02, 3.0692e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,477][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ went] are: tensor([4.6601e-09, 1.0000e+00, 2.6254e-08, 3.5587e-09, 1.3946e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,480][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0024, 0.3322, 0.1191, 0.0947, 0.4516], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,484][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.4077, 0.2978, 0.0459, 0.0277, 0.2084, 0.0126], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,486][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0026, 0.2888, 0.1313, 0.1396, 0.2298, 0.2079], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,487][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2723, 0.3984, 0.0802, 0.0628, 0.1261, 0.0602], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,488][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.8379e-10, 9.9999e-01, 1.7093e-08, 4.1088e-09, 6.9513e-06, 4.3215e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,489][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3053, 0.1522, 0.1193, 0.1248, 0.1930, 0.1054], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,490][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.9008, 0.0116, 0.0174, 0.0268, 0.0369, 0.0065], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,492][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.6961e-04, 6.2753e-01, 2.9663e-02, 6.0996e-02, 1.3162e-01, 1.5003e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,496][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1288, 0.7911, 0.0068, 0.0172, 0.0539, 0.0021], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,500][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.1042, 0.2055, 0.1828, 0.1610, 0.1864, 0.1600], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,502][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.1234e-05, 1.1543e-01, 3.3312e-01, 4.4346e-02, 3.2969e-01, 1.7741e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,503][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([2.3163e-11, 1.0000e+00, 5.2256e-10, 1.4179e-10, 8.7469e-08, 4.8570e-10],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,503][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0121, 0.3423, 0.0714, 0.0779, 0.2906, 0.2057], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,504][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.4164, 0.3245, 0.0444, 0.0237, 0.1693, 0.0080, 0.0137],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,507][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0022, 0.1998, 0.0999, 0.0987, 0.2033, 0.1261, 0.2700],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,510][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1467, 0.5074, 0.0748, 0.0513, 0.1155, 0.0531, 0.0511],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,512][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([9.9358e-11, 9.9999e-01, 1.1736e-08, 5.3159e-10, 1.2679e-05, 6.4905e-10,
        1.1739e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,516][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2662, 0.1909, 0.1100, 0.0887, 0.1844, 0.0701, 0.0897],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,517][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.8652, 0.0228, 0.0232, 0.0291, 0.0452, 0.0069, 0.0076],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,518][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([1.7983e-04, 6.2040e-01, 2.6774e-02, 5.8450e-02, 1.1869e-01, 1.1698e-01,
        5.8526e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,519][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([1.6556e-01, 7.8873e-01, 7.2579e-03, 4.4583e-03, 3.1344e-02, 6.6374e-04,
        1.9842e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,520][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0883, 0.1759, 0.1586, 0.1379, 0.1616, 0.1351, 0.1427],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,521][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([6.6825e-06, 1.0191e-01, 2.7953e-01, 3.0438e-02, 2.6613e-01, 1.1584e-01,
        2.0613e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,523][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([2.5875e-11, 1.0000e+00, 1.3530e-09, 1.1725e-10, 2.6642e-07, 4.2359e-10,
        6.8375e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,526][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0180, 0.2112, 0.0906, 0.0621, 0.3106, 0.2306, 0.0771],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,529][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.2623, 0.3264, 0.0266, 0.0103, 0.1207, 0.0154, 0.0159, 0.2223],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,533][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ station] are: tensor([0.0009, 0.1810, 0.0882, 0.1122, 0.1548, 0.1084, 0.2145, 0.1401],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,534][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1905, 0.3996, 0.0755, 0.0422, 0.1099, 0.0581, 0.0602, 0.0640],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,535][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ station] are: tensor([1.6298e-10, 9.9998e-01, 1.1623e-08, 1.1383e-10, 2.1794e-05, 5.7474e-11,
        2.4613e-10, 3.7909e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,536][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.1922, 0.2257, 0.0881, 0.0904, 0.1613, 0.0574, 0.0917, 0.0932],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,538][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.6781, 0.0595, 0.0456, 0.0502, 0.1159, 0.0136, 0.0136, 0.0235],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,540][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ station] are: tensor([1.7905e-04, 5.0563e-01, 3.3299e-02, 5.2972e-02, 1.2784e-01, 1.4802e-01,
        7.4769e-02, 5.7293e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,542][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ station] are: tensor([1.3275e-02, 9.4322e-01, 3.5222e-03, 1.9432e-03, 2.5484e-02, 9.1979e-04,
        2.5420e-03, 9.0902e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,546][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0716, 0.1575, 0.1422, 0.1219, 0.1416, 0.1203, 0.1286, 0.1162],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,548][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ station] are: tensor([5.9732e-06, 8.7209e-02, 3.4257e-01, 5.1079e-02, 2.0289e-01, 1.0639e-01,
        1.7759e-01, 3.2277e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,549][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ station] are: tensor([1.9207e-11, 1.0000e+00, 5.5109e-10, 3.4140e-11, 2.0724e-07, 5.0456e-11,
        1.5031e-10, 1.0469e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,550][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0016, 0.1458, 0.0529, 0.0616, 0.2775, 0.2515, 0.1549, 0.0541],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,551][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1201, 0.3072, 0.0391, 0.0364, 0.1606, 0.0128, 0.0208, 0.3006, 0.0024],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,553][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0015, 0.1550, 0.0651, 0.1160, 0.1553, 0.0746, 0.2280, 0.1487, 0.0559],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,556][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1190, 0.3829, 0.0779, 0.0622, 0.1260, 0.0592, 0.0592, 0.0857, 0.0279],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,558][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([9.0705e-10, 9.9971e-01, 2.2364e-07, 6.0800e-08, 1.1981e-04, 5.0866e-08,
        9.6961e-07, 1.6683e-04, 1.6913e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,562][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0481, 0.2110, 0.1076, 0.1021, 0.1595, 0.0692, 0.0868, 0.1174, 0.0983],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,564][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5258, 0.0774, 0.0548, 0.0782, 0.1217, 0.0275, 0.0330, 0.0616, 0.0201],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,565][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([5.7337e-05, 5.8540e-01, 2.4791e-02, 4.6064e-02, 9.8502e-02, 1.1500e-01,
        6.8659e-02, 4.7554e-02, 1.3974e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,566][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0623, 0.7746, 0.0060, 0.0130, 0.0494, 0.0012, 0.0138, 0.0787, 0.0011],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,567][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0684, 0.1374, 0.1260, 0.1096, 0.1288, 0.1091, 0.1160, 0.1056, 0.0992],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,568][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([8.8726e-07, 1.2354e-01, 3.0637e-01, 3.3026e-02, 2.5113e-01, 8.0596e-02,
        1.7479e-01, 2.4036e-02, 6.5045e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,570][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([4.6143e-10, 9.9999e-01, 3.4156e-08, 9.1043e-09, 3.0473e-06, 2.3162e-08,
        1.0318e-07, 2.0704e-06, 5.3547e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,574][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0027, 0.4905, 0.0237, 0.0441, 0.1962, 0.1114, 0.0635, 0.0572, 0.0107],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,578][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.0514, 0.3411, 0.0500, 0.0166, 0.1370, 0.0242, 0.0272, 0.3471, 0.0022,
        0.0033], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,580][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.0006, 0.1245, 0.0469, 0.0823, 0.1520, 0.0701, 0.2012, 0.1677, 0.0455,
        0.1091], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,580][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0843, 0.3663, 0.0764, 0.0447, 0.1241, 0.0782, 0.0737, 0.0897, 0.0311,
        0.0315], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,581][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([8.7287e-11, 9.9903e-01, 2.4233e-06, 2.6264e-08, 8.7847e-04, 9.5184e-08,
        1.6354e-06, 8.5650e-05, 1.7825e-10, 5.7071e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,582][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.0531, 0.1376, 0.0658, 0.0735, 0.1300, 0.0661, 0.0983, 0.1640, 0.0913,
        0.1201], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,584][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.3005, 0.1618, 0.0727, 0.0828, 0.1700, 0.0377, 0.0436, 0.0875, 0.0191,
        0.0243], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,586][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([4.4952e-05, 4.6992e-01, 3.5825e-02, 3.6064e-02, 1.4838e-01, 1.3600e-01,
        8.4420e-02, 5.4072e-02, 1.6058e-02, 1.9216e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,589][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([7.9954e-03, 8.3091e-01, 1.0670e-02, 7.2527e-03, 4.7601e-02, 1.8344e-03,
        1.9083e-02, 7.1060e-02, 8.0954e-04, 2.7795e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,593][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0578, 0.1267, 0.1178, 0.0995, 0.1173, 0.0996, 0.1076, 0.0956, 0.0895,
        0.0886], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,595][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([2.5947e-07, 6.8549e-02, 4.0838e-01, 4.6241e-02, 2.5222e-01, 6.4031e-02,
        1.2988e-01, 1.8523e-02, 7.1833e-03, 5.0009e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,596][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([3.1426e-11, 1.0000e+00, 3.5004e-08, 2.2261e-09, 3.3184e-06, 1.1991e-08,
        5.1041e-08, 7.4241e-07, 7.5380e-11, 6.1920e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,597][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0014, 0.1681, 0.0647, 0.0454, 0.2843, 0.1222, 0.1188, 0.1053, 0.0589,
        0.0307], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,598][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1695, 0.2174, 0.0651, 0.0281, 0.2002, 0.0187, 0.0261, 0.2238, 0.0038,
        0.0031, 0.0441], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,600][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0033, 0.1271, 0.0544, 0.0666, 0.1116, 0.0825, 0.1696, 0.1185, 0.0531,
        0.0719, 0.1414], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,603][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1966, 0.3964, 0.0453, 0.0395, 0.0866, 0.0489, 0.0429, 0.0585, 0.0189,
        0.0199, 0.0465], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,606][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([2.8652e-08, 9.9999e-01, 3.0849e-08, 9.0947e-09, 1.0271e-05, 7.5566e-10,
        4.3101e-09, 1.8186e-07, 4.6023e-11, 5.1298e-12, 4.7926e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,609][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1145, 0.1113, 0.0624, 0.0780, 0.1389, 0.0598, 0.0751, 0.1174, 0.0805,
        0.1129, 0.0492], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,611][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.7290, 0.0242, 0.0312, 0.0463, 0.0805, 0.0141, 0.0136, 0.0238, 0.0107,
        0.0100, 0.0166], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,612][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.5117e-04, 5.3071e-01, 2.4163e-02, 4.8315e-02, 9.5039e-02, 9.9582e-02,
        5.5037e-02, 5.4989e-02, 1.2710e-02, 2.1782e-02, 5.7520e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,612][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0506, 0.8152, 0.0085, 0.0152, 0.0424, 0.0025, 0.0138, 0.0282, 0.0017,
        0.0075, 0.0145], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,613][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0584, 0.1160, 0.1028, 0.0896, 0.1047, 0.0885, 0.0948, 0.0864, 0.0811,
        0.0802, 0.0975], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,615][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.9755e-06, 9.7978e-02, 3.1402e-01, 1.9873e-02, 2.1164e-01, 1.0927e-01,
        1.6817e-01, 3.2074e-02, 1.2195e-02, 5.0938e-03, 2.9683e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,617][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([6.1626e-09, 1.0000e+00, 1.1560e-08, 2.6602e-09, 1.1880e-06, 1.2156e-09,
        3.8122e-09, 4.5613e-08, 7.0771e-11, 2.6541e-11, 3.6538e-08],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,620][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0047, 0.1440, 0.0549, 0.0525, 0.1848, 0.1341, 0.1125, 0.0920, 0.0565,
        0.0502, 0.1136], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:10,624][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5965, 0.1073, 0.0213, 0.0139, 0.1012, 0.0068, 0.0092, 0.1099, 0.0016,
        0.0015, 0.0208, 0.0100], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,626][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0058, 0.1111, 0.0524, 0.0568, 0.1164, 0.0739, 0.1478, 0.1030, 0.0409,
        0.0487, 0.1237, 0.1195], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,627][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2371, 0.2607, 0.0620, 0.0475, 0.1056, 0.0488, 0.0469, 0.0598, 0.0225,
        0.0211, 0.0459, 0.0421], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,628][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([4.2964e-08, 9.9999e-01, 1.2884e-08, 4.0196e-09, 4.3798e-06, 4.4888e-10,
        1.2353e-09, 1.3622e-07, 3.1495e-11, 2.6658e-12, 9.7273e-07, 1.0023e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,630][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1062, 0.0673, 0.0794, 0.0661, 0.1420, 0.0458, 0.0793, 0.1192, 0.0866,
        0.0720, 0.0533, 0.0829], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,633][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9211, 0.0062, 0.0104, 0.0189, 0.0191, 0.0028, 0.0032, 0.0050, 0.0032,
        0.0037, 0.0041, 0.0022], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,635][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.7946e-04, 4.3165e-01, 2.7921e-02, 4.1024e-02, 1.0983e-01, 1.0606e-01,
        6.2711e-02, 5.8924e-02, 1.3234e-02, 1.9644e-02, 7.4839e-02, 5.3975e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,637][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([1.9952e-01, 7.2565e-01, 6.5691e-03, 1.1008e-02, 1.9366e-02, 7.2028e-04,
        2.7179e-03, 2.0890e-02, 7.1844e-04, 3.8574e-03, 6.5753e-03, 2.4055e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,641][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0534, 0.1048, 0.0940, 0.0823, 0.0962, 0.0811, 0.0861, 0.0782, 0.0738,
        0.0729, 0.0892, 0.0880], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,642][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([4.9222e-06, 8.1790e-02, 2.6933e-01, 2.7884e-02, 2.0083e-01, 9.7822e-02,
        1.6386e-01, 3.1229e-02, 1.2552e-02, 5.9851e-03, 2.6152e-02, 8.2567e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,643][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.8927e-10, 1.0000e+00, 2.3893e-09, 7.0329e-10, 3.8102e-07, 4.2529e-10,
        1.1908e-09, 1.5721e-08, 2.0937e-11, 7.4516e-12, 1.9391e-08, 1.6543e-08],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,644][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0105, 0.1507, 0.0510, 0.0529, 0.1091, 0.1492, 0.0768, 0.1963, 0.0473,
        0.0446, 0.0621, 0.0495], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:10,646][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1413, 0.2853, 0.0661, 0.0165, 0.1706, 0.0175, 0.0314, 0.1929, 0.0030,
        0.0022, 0.0351, 0.0201, 0.0180], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,649][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([0.0014, 0.0959, 0.0398, 0.0680, 0.0935, 0.0431, 0.1211, 0.0800, 0.0296,
        0.0484, 0.1068, 0.1174, 0.1551], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,653][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.1001, 0.4071, 0.0558, 0.0322, 0.1064, 0.0474, 0.0476, 0.0588, 0.0171,
        0.0170, 0.0466, 0.0405, 0.0234], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,656][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([9.3936e-09, 9.9994e-01, 6.4476e-08, 4.5015e-09, 5.6738e-05, 2.1355e-10,
        5.7251e-09, 5.8347e-07, 1.7896e-12, 1.0893e-12, 1.6999e-07, 5.8953e-08,
        2.8856e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,657][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.1425, 0.1106, 0.0580, 0.0537, 0.0893, 0.0499, 0.0881, 0.0651, 0.0721,
        0.0743, 0.0396, 0.1155, 0.0414], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,658][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([0.6535, 0.0476, 0.0404, 0.0511, 0.0844, 0.0104, 0.0138, 0.0328, 0.0091,
        0.0103, 0.0189, 0.0087, 0.0190], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,659][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([6.6206e-05, 4.7924e-01, 2.5447e-02, 4.0378e-02, 1.0161e-01, 7.9431e-02,
        5.5475e-02, 4.6541e-02, 9.7965e-03, 1.7461e-02, 6.3466e-02, 4.6628e-02,
        3.4464e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,661][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([1.5684e-02, 9.0112e-01, 5.7923e-03, 3.6528e-03, 4.0464e-02, 1.4714e-03,
        6.3864e-03, 1.5509e-02, 2.8785e-04, 5.2034e-04, 5.5975e-03, 3.0060e-03,
        5.0570e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,664][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0477, 0.0976, 0.0876, 0.0751, 0.0880, 0.0764, 0.0811, 0.0719, 0.0678,
        0.0678, 0.0816, 0.0827, 0.0746], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,666][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([5.9003e-07, 7.5463e-02, 3.4876e-01, 1.7304e-02, 2.6970e-01, 6.0540e-02,
        1.0156e-01, 2.0965e-02, 4.5229e-03, 1.7489e-03, 2.3775e-02, 6.6990e-02,
        8.6690e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,668][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([2.5810e-09, 1.0000e+00, 2.9928e-08, 4.7412e-09, 3.5385e-06, 1.5075e-09,
        1.2294e-08, 1.5751e-07, 3.8544e-11, 4.2069e-11, 2.8866e-08, 3.8421e-08,
        1.0908e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,672][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0016, 0.0596, 0.0324, 0.0350, 0.1660, 0.1016, 0.1127, 0.0281, 0.0365,
        0.0292, 0.1134, 0.2664, 0.0174], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:10,673][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([7.9854e-01, 6.6825e-02, 8.4756e-03, 8.4018e-03, 3.6861e-02, 2.7525e-03,
        2.3718e-03, 4.0574e-02, 7.9667e-04, 8.2517e-04, 8.5113e-03, 2.8913e-03,
        4.8881e-03, 1.7289e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,674][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0062, 0.1116, 0.0350, 0.0513, 0.0886, 0.0560, 0.1020, 0.0656, 0.0292,
        0.0419, 0.0991, 0.0908, 0.1077, 0.1148], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,675][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.3075, 0.2039, 0.0504, 0.0425, 0.0917, 0.0380, 0.0360, 0.0480, 0.0185,
        0.0167, 0.0397, 0.0333, 0.0211, 0.0528], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,676][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([4.4400e-07, 9.9999e-01, 1.0124e-08, 8.2783e-09, 3.8256e-06, 2.4729e-10,
        9.0087e-10, 6.6441e-08, 3.6812e-11, 4.0338e-12, 4.3089e-07, 7.6655e-08,
        1.1425e-07, 2.7636e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,679][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1290, 0.1089, 0.0624, 0.0637, 0.0971, 0.0544, 0.0596, 0.0843, 0.0768,
        0.0647, 0.0443, 0.0568, 0.0588, 0.0392], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,683][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.9205, 0.0072, 0.0094, 0.0160, 0.0179, 0.0030, 0.0028, 0.0040, 0.0029,
        0.0033, 0.0036, 0.0018, 0.0034, 0.0042], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,686][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.6987e-05, 4.1521e-01, 2.4050e-02, 3.7979e-02, 9.9809e-02, 9.7090e-02,
        5.6002e-02, 4.4904e-02, 1.1582e-02, 1.6695e-02, 6.2021e-02, 5.0918e-02,
        3.3208e-02, 5.0438e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,688][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2136, 0.6706, 0.0056, 0.0091, 0.0370, 0.0011, 0.0049, 0.0239, 0.0008,
        0.0029, 0.0163, 0.0064, 0.0021, 0.0058], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,689][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0487, 0.0888, 0.0798, 0.0697, 0.0812, 0.0698, 0.0731, 0.0659, 0.0631,
        0.0623, 0.0754, 0.0745, 0.0686, 0.0790], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,690][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([3.3046e-06, 6.7276e-02, 1.6868e-01, 2.2342e-02, 1.9258e-01, 7.2559e-02,
        1.0773e-01, 2.0741e-02, 6.9046e-03, 3.7517e-03, 2.2934e-02, 6.9687e-02,
        1.0145e-02, 2.3466e-01], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,691][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([3.3232e-08, 1.0000e+00, 1.3252e-08, 5.8879e-09, 1.3558e-06, 1.6668e-09,
        5.6056e-09, 5.6681e-08, 1.7373e-10, 6.2238e-11, 6.1359e-08, 5.7970e-08,
        2.5093e-08, 4.5470e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,694][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0074, 0.1418, 0.0269, 0.0359, 0.1075, 0.0940, 0.0695, 0.0500, 0.0309,
        0.0336, 0.0798, 0.0954, 0.1352, 0.0921], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:10,799][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:10,802][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,802][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,803][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,804][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,804][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,805][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,806][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,807][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,807][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,810][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,812][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,813][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:10,814][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.9542, 0.0458], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,815][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.0054, 0.9946], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,817][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.8028, 0.1972], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,818][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.2292, 0.7708], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,819][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.2815, 0.7185], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,819][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.9987, 0.0013], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,820][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([1.0187e-05, 9.9999e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,822][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.0412, 0.9588], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,826][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.7041, 0.2959], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,828][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([6.8964e-08, 1.0000e+00], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,830][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([1.7937e-04, 9.9982e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,833][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.1011, 0.8989], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:10,834][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2837, 0.6568, 0.0595], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,834][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.5364e-04, 9.8831e-01, 1.0735e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,835][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0881, 0.8725, 0.0394], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,836][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.4361e-06, 1.0000e+00, 2.0821e-07], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,839][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0519, 0.7434, 0.2047], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,843][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8830, 0.0648, 0.0522], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,846][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.3679e-05, 9.9712e-01, 2.8622e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,848][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([4.0904e-04, 9.9897e-01, 6.2277e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,849][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0400, 0.9138, 0.0463], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,849][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.0008e-07, 9.9882e-01, 1.1754e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,850][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([1.8595e-08, 1.0000e+00, 1.9417e-07], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,851][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0102, 0.9199, 0.0699], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:10,853][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.1798, 0.6636, 0.0741, 0.0825], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,855][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([6.3300e-04, 9.6498e-01, 1.2510e-02, 2.1874e-02], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,859][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0848, 0.7696, 0.0953, 0.0503], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,861][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([1.2335e-05, 9.9998e-01, 4.3687e-06, 2.2490e-06], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,863][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.0156, 0.6465, 0.1553, 0.1827], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,864][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.5498, 0.2194, 0.1089, 0.1219], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,865][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([1.0665e-05, 9.8935e-01, 7.6903e-03, 2.9539e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,866][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([5.2896e-04, 9.9676e-01, 1.9914e-03, 7.1745e-04], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,869][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0203, 0.8898, 0.0605, 0.0295], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,871][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([2.6121e-07, 9.9780e-01, 1.8124e-03, 3.8886e-04], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,873][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([5.6439e-08, 1.0000e+00, 1.5664e-06, 2.5047e-07], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,876][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0025, 0.9207, 0.0429, 0.0339], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:10,881][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.4139, 0.3894, 0.0465, 0.0501, 0.1001], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,881][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.0016, 0.9591, 0.0082, 0.0165, 0.0146], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,882][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.1302, 0.7148, 0.0434, 0.0272, 0.0844], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,883][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([2.3246e-05, 9.9997e-01, 6.5728e-07, 4.2144e-07, 7.9606e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,884][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.0348, 0.4457, 0.1432, 0.1863, 0.1900], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,886][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.7814, 0.0394, 0.0415, 0.0446, 0.0931], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,888][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([1.2765e-05, 9.8903e-01, 2.3072e-03, 1.3707e-03, 7.2807e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,890][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([9.3921e-04, 9.9458e-01, 7.2783e-04, 2.5595e-04, 3.4955e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,894][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0770, 0.7612, 0.0485, 0.0343, 0.0789], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,896][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([4.3370e-07, 9.9646e-01, 1.4885e-03, 2.2181e-04, 1.8290e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,897][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([6.5606e-08, 9.9999e-01, 2.1981e-07, 4.0521e-08, 5.4130e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,898][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0086, 0.5491, 0.1055, 0.0955, 0.2414], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:10,899][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.6890, 0.1363, 0.0290, 0.0518, 0.0831, 0.0108], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,900][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0087, 0.8637, 0.0175, 0.0493, 0.0407, 0.0202], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,903][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3067, 0.5134, 0.0381, 0.0326, 0.0896, 0.0196], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,905][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([5.4796e-08, 1.0000e+00, 1.2584e-08, 1.8186e-08, 3.9331e-07, 5.0680e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,910][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2333, 0.2025, 0.1126, 0.2072, 0.1843, 0.0601], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,912][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9008, 0.0116, 0.0174, 0.0268, 0.0369, 0.0065], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,913][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([3.5238e-05, 9.7314e-01, 2.9020e-03, 2.5465e-03, 1.0395e-02, 1.0982e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,913][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([1.0905e-03, 9.9446e-01, 4.9011e-04, 3.3196e-04, 3.3884e-03, 2.4409e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,914][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1376, 0.5800, 0.0490, 0.0443, 0.1449, 0.0441], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,915][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([5.0249e-07, 9.8885e-01, 1.4078e-03, 4.1316e-04, 2.6662e-03, 6.6618e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,916][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.8647e-09, 1.0000e+00, 1.0281e-08, 3.3989e-09, 5.9588e-07, 6.2409e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,919][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0663, 0.1368, 0.1564, 0.1695, 0.2613, 0.2096], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:10,923][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4849, 0.2756, 0.0415, 0.0620, 0.1095, 0.0131, 0.0134],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,927][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0063, 0.8735, 0.0160, 0.0355, 0.0364, 0.0130, 0.0193],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,928][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1393, 0.6952, 0.0336, 0.0236, 0.0790, 0.0163, 0.0131],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,929][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([9.8118e-08, 1.0000e+00, 3.1368e-08, 1.8118e-08, 1.2279e-06, 5.7152e-09,
        8.5228e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,930][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1750, 0.2871, 0.1152, 0.1622, 0.1525, 0.0446, 0.0634],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,931][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.8652, 0.0228, 0.0232, 0.0291, 0.0452, 0.0069, 0.0076],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,932][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([2.7077e-05, 9.7488e-01, 2.8768e-03, 2.1661e-03, 9.3429e-03, 6.4206e-03,
        4.2864e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,934][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([3.2516e-04, 9.9634e-01, 3.3887e-04, 1.1925e-04, 2.6245e-03, 1.3325e-04,
        1.1907e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,938][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0508, 0.6829, 0.0490, 0.0317, 0.1293, 0.0377, 0.0186],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,941][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([6.6744e-07, 9.8537e-01, 1.4727e-03, 4.0962e-04, 2.6070e-03, 5.2663e-03,
        4.8702e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,943][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.5808e-09, 1.0000e+00, 2.0456e-08, 2.6378e-09, 1.3359e-06, 5.4289e-09,
        9.6501e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,944][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0514, 0.1900, 0.1160, 0.1203, 0.2068, 0.1902, 0.1254],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:10,945][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.5135, 0.2777, 0.0245, 0.0393, 0.0756, 0.0137, 0.0109, 0.0448],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,946][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([0.0013, 0.9234, 0.0079, 0.0234, 0.0184, 0.0079, 0.0095, 0.0083],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,948][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.2177, 0.5675, 0.0400, 0.0205, 0.0923, 0.0218, 0.0203, 0.0200],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,950][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([1.3265e-07, 1.0000e+00, 2.8077e-08, 8.3768e-09, 1.6376e-06, 1.1894e-09,
        3.3223e-09, 3.8117e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,954][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0420, 0.4985, 0.0692, 0.1112, 0.1239, 0.0355, 0.0530, 0.0667],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,957][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.6781, 0.0595, 0.0456, 0.0502, 0.1159, 0.0136, 0.0136, 0.0235],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,959][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([1.3914e-05, 9.6885e-01, 2.8235e-03, 1.8154e-03, 9.0577e-03, 9.0942e-03,
        4.7726e-03, 3.5769e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,960][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([7.4918e-05, 9.9759e-01, 1.7917e-04, 4.4856e-05, 1.8035e-03, 5.0883e-05,
        5.8984e-05, 1.9555e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,961][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.0445, 0.6985, 0.0474, 0.0276, 0.0963, 0.0352, 0.0157, 0.0347],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,962][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([3.2479e-07, 9.8725e-01, 1.2944e-03, 4.2230e-04, 1.8791e-03, 4.6963e-03,
        3.8300e-03, 6.3087e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,963][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([1.0623e-09, 1.0000e+00, 9.3355e-09, 9.1922e-10, 1.0541e-06, 1.0030e-09,
        2.7071e-09, 1.4747e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,966][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0138, 0.2216, 0.1040, 0.0959, 0.2011, 0.1602, 0.0998, 0.1036],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:10,970][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2793, 0.3123, 0.0473, 0.0867, 0.1178, 0.0227, 0.0256, 0.0910, 0.0174],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,973][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0010, 0.9065, 0.0085, 0.0222, 0.0202, 0.0082, 0.0158, 0.0133, 0.0043],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,975][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1121, 0.5374, 0.0559, 0.0471, 0.1233, 0.0311, 0.0297, 0.0498, 0.0136],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,976][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([2.1684e-06, 9.9993e-01, 9.9794e-07, 1.2162e-06, 2.0331e-05, 3.7820e-07,
        1.6275e-06, 4.4101e-05, 1.6931e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,977][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0231, 0.3499, 0.0876, 0.1305, 0.1164, 0.0469, 0.0652, 0.0977, 0.0827],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,978][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5258, 0.0774, 0.0548, 0.0782, 0.1217, 0.0275, 0.0330, 0.0616, 0.0201],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,979][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([1.3450e-05, 9.6371e-01, 3.2570e-03, 2.3674e-03, 8.8653e-03, 9.1655e-03,
        6.7475e-03, 4.9809e-03, 8.9685e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,981][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([5.2817e-04, 9.7592e-01, 1.5322e-03, 1.0336e-03, 9.9130e-03, 9.5574e-04,
        1.4000e-03, 8.5406e-03, 1.7890e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,984][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0362, 0.5095, 0.0614, 0.0410, 0.1644, 0.0534, 0.0370, 0.0727, 0.0243],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,987][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([1.8663e-07, 9.8868e-01, 1.0273e-03, 3.1081e-04, 1.9136e-03, 3.6824e-03,
        3.6435e-03, 6.0431e-04, 1.4087e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,989][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.9474e-08, 9.9998e-01, 3.4436e-07, 1.1096e-07, 1.1765e-05, 1.6998e-07,
        6.7735e-07, 8.4949e-06, 8.9620e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,991][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0115, 0.2947, 0.0808, 0.0779, 0.1479, 0.1297, 0.0946, 0.1052, 0.0577],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:10,992][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.1546, 0.3830, 0.0477, 0.0652, 0.1234, 0.0357, 0.0330, 0.1178, 0.0165,
        0.0230], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,993][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([4.9070e-04, 9.1293e-01, 6.3649e-03, 1.6091e-02, 1.9076e-02, 7.1152e-03,
        1.3112e-02, 1.5056e-02, 2.8939e-03, 6.8694e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,993][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0583, 0.5471, 0.0547, 0.0290, 0.1276, 0.0521, 0.0442, 0.0566, 0.0153,
        0.0151], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,995][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([2.2749e-07, 9.9996e-01, 1.1899e-06, 3.1378e-07, 2.1850e-05, 2.0324e-07,
        7.9204e-07, 1.4023e-05, 2.1201e-08, 2.5459e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:10,998][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.0078, 0.3632, 0.0651, 0.0887, 0.1105, 0.0472, 0.0621, 0.1111, 0.0627,
        0.0817], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,002][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.3005, 0.1618, 0.0727, 0.0828, 0.1700, 0.0377, 0.0436, 0.0875, 0.0191,
        0.0243], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,005][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([7.1901e-06, 9.3975e-01, 5.3853e-03, 2.2664e-03, 1.8732e-02, 1.4295e-02,
        1.0215e-02, 6.8746e-03, 1.1141e-03, 1.3630e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,006][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([6.4273e-05, 9.8857e-01, 7.3713e-04, 2.4245e-04, 5.7611e-03, 4.4162e-04,
        6.7614e-04, 3.4208e-03, 3.7496e-05, 5.1944e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,007][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0154, 0.5207, 0.0663, 0.0255, 0.1454, 0.0714, 0.0475, 0.0714, 0.0202,
        0.0161], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,008][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([1.3098e-07, 9.8991e-01, 1.1008e-03, 3.2265e-04, 1.9018e-03, 3.1491e-03,
        2.8319e-03, 4.8692e-04, 1.2037e-04, 1.7668e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,009][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([1.8825e-09, 9.9999e-01, 3.0532e-07, 3.0174e-08, 1.0783e-05, 8.1745e-08,
        3.2817e-07, 3.2163e-06, 1.5053e-09, 1.3742e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,011][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0044, 0.4174, 0.0567, 0.0524, 0.1222, 0.1025, 0.0789, 0.0961, 0.0333,
        0.0362], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,013][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.4351, 0.1859, 0.0433, 0.0648, 0.1056, 0.0162, 0.0165, 0.0535, 0.0149,
        0.0137, 0.0504], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,018][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0044, 0.8287, 0.0135, 0.0341, 0.0298, 0.0131, 0.0189, 0.0180, 0.0075,
        0.0132, 0.0187], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,022][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1483, 0.6639, 0.0218, 0.0192, 0.0635, 0.0180, 0.0134, 0.0198, 0.0060,
        0.0060, 0.0203], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,023][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([8.1589e-06, 9.9999e-01, 1.7893e-07, 2.8195e-07, 4.2207e-06, 1.4943e-08,
        5.1116e-08, 9.3940e-07, 1.6396e-08, 1.1587e-08, 7.0267e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,024][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0855, 0.1746, 0.0638, 0.1255, 0.1148, 0.0400, 0.0517, 0.0629, 0.0872,
        0.1212, 0.0727], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,024][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.7290, 0.0242, 0.0312, 0.0463, 0.0805, 0.0141, 0.0136, 0.0238, 0.0107,
        0.0100, 0.0166], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,026][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.4666e-05, 9.7149e-01, 2.0763e-03, 1.6429e-03, 6.7522e-03, 5.3918e-03,
        3.3113e-03, 3.1634e-03, 4.8822e-04, 8.3041e-04, 4.8365e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,028][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([1.1464e-03, 9.9244e-01, 5.7899e-04, 3.1519e-04, 3.7159e-03, 2.3507e-04,
        2.3813e-04, 8.6595e-04, 4.5244e-05, 3.6811e-05, 3.7818e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,031][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0831, 0.5332, 0.0392, 0.0349, 0.1068, 0.0353, 0.0218, 0.0421, 0.0184,
        0.0149, 0.0703], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,034][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([4.2352e-07, 9.8935e-01, 1.1119e-03, 2.1583e-04, 1.6025e-03, 3.5997e-03,
        2.7736e-03, 4.5973e-04, 1.3658e-04, 1.1732e-04, 6.2895e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,036][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([1.7728e-07, 9.9999e-01, 1.4094e-07, 4.0287e-08, 5.5847e-06, 1.5760e-08,
        4.5432e-08, 3.7338e-07, 1.6668e-09, 8.1343e-10, 2.7716e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,038][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0254, 0.0713, 0.0893, 0.1007, 0.1675, 0.1056, 0.0822, 0.1078, 0.0804,
        0.0657, 0.1041], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,039][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.7611, 0.0500, 0.0200, 0.0333, 0.0563, 0.0067, 0.0067, 0.0225, 0.0077,
        0.0068, 0.0230, 0.0060], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,040][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0091, 0.7606, 0.0170, 0.0375, 0.0419, 0.0174, 0.0237, 0.0245, 0.0083,
        0.0132, 0.0243, 0.0224], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,040][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4094, 0.3264, 0.0356, 0.0291, 0.0973, 0.0181, 0.0145, 0.0206, 0.0088,
        0.0071, 0.0216, 0.0115], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,042][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.1151e-05, 9.9998e-01, 1.0645e-07, 1.8184e-07, 2.5455e-06, 1.0238e-08,
        2.4247e-08, 7.5980e-07, 1.2358e-08, 7.6774e-09, 9.4759e-07, 2.7699e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,045][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1650, 0.0764, 0.0808, 0.1173, 0.1016, 0.0268, 0.0503, 0.0618, 0.1019,
        0.0963, 0.0704, 0.0513], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,049][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.9211, 0.0062, 0.0104, 0.0189, 0.0191, 0.0028, 0.0032, 0.0050, 0.0032,
        0.0037, 0.0041, 0.0022], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,052][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.9968e-05, 9.5467e-01, 2.7035e-03, 1.7751e-03, 8.1139e-03, 7.4087e-03,
        4.8438e-03, 3.4736e-03, 6.2720e-04, 8.8599e-04, 6.4610e-03, 9.0065e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,053][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([2.2833e-03, 9.8890e-01, 7.3937e-04, 4.0412e-04, 5.0316e-03, 2.7358e-04,
        2.7767e-04, 1.1752e-03, 6.0496e-05, 4.9244e-05, 5.0145e-04, 3.0670e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,054][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1217, 0.4411, 0.0473, 0.0384, 0.1221, 0.0335, 0.0191, 0.0368, 0.0198,
        0.0147, 0.0714, 0.0340], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,055][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.2041e-07, 9.8375e-01, 1.0303e-03, 2.4023e-04, 1.6888e-03, 3.6798e-03,
        3.2237e-03, 4.9752e-04, 1.3356e-04, 1.1855e-04, 5.7556e-04, 5.0630e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,056][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.3580e-08, 1.0000e+00, 3.7819e-08, 1.3686e-08, 2.1506e-06, 6.2221e-09,
        1.6182e-08, 1.5116e-07, 5.9085e-10, 2.8864e-10, 1.4805e-07, 1.1986e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,058][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0507, 0.0849, 0.0780, 0.0835, 0.1143, 0.1164, 0.0799, 0.0910, 0.0708,
        0.0639, 0.0695, 0.0970], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,061][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.2897, 0.3170, 0.0459, 0.0489, 0.1099, 0.0155, 0.0198, 0.0555, 0.0113,
        0.0102, 0.0445, 0.0151, 0.0166], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,065][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([0.0013, 0.8847, 0.0069, 0.0200, 0.0172, 0.0055, 0.0121, 0.0099, 0.0029,
        0.0056, 0.0107, 0.0148, 0.0083], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,069][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0680, 0.6641, 0.0323, 0.0166, 0.0982, 0.0203, 0.0196, 0.0244, 0.0057,
        0.0054, 0.0230, 0.0138, 0.0085], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,070][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([1.2917e-05, 9.9996e-01, 7.8433e-07, 5.8180e-07, 2.2378e-05, 2.5843e-08,
        1.8016e-07, 4.2259e-06, 1.2559e-08, 1.9805e-08, 1.0777e-06, 6.0837e-07,
        8.0539e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,071][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0321, 0.2275, 0.0537, 0.0807, 0.0801, 0.0312, 0.0536, 0.0670, 0.0651,
        0.0892, 0.0693, 0.0702, 0.0803], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,071][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([0.6535, 0.0476, 0.0404, 0.0511, 0.0844, 0.0104, 0.0138, 0.0328, 0.0091,
        0.0103, 0.0189, 0.0087, 0.0190], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,073][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([6.7971e-06, 9.6920e-01, 1.6107e-03, 9.4297e-04, 5.3520e-03, 4.0976e-03,
        2.7935e-03, 2.2457e-03, 2.9766e-04, 4.6718e-04, 4.4114e-03, 7.0566e-03,
        1.5195e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,074][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([1.5605e-04, 9.9347e-01, 4.8190e-04, 1.3061e-04, 4.0271e-03, 1.3606e-04,
        2.1217e-04, 9.0864e-04, 1.2725e-05, 1.3822e-05, 2.0942e-04, 1.5112e-04,
        9.1219e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,076][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.0181, 0.6192, 0.0363, 0.0169, 0.0729, 0.0409, 0.0193, 0.0386, 0.0104,
        0.0097, 0.0633, 0.0416, 0.0128], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,079][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([2.2570e-07, 9.8904e-01, 8.5237e-04, 1.5108e-04, 1.6848e-03, 1.9276e-03,
        1.6010e-03, 3.2573e-04, 5.8503e-05, 5.3389e-05, 4.9647e-04, 3.5899e-03,
        2.1964e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,081][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([9.1457e-08, 9.9998e-01, 3.2625e-07, 7.1553e-08, 1.4842e-05, 2.0437e-08,
        1.2517e-07, 1.1035e-06, 1.0784e-09, 1.2825e-09, 2.3793e-07, 2.9662e-07,
        9.2703e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,085][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0099, 0.1636, 0.0492, 0.0582, 0.1030, 0.0900, 0.0738, 0.0896, 0.0398,
        0.0466, 0.0735, 0.1292, 0.0738], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,086][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.7387, 0.0633, 0.0201, 0.0363, 0.0495, 0.0070, 0.0053, 0.0181, 0.0077,
        0.0068, 0.0207, 0.0048, 0.0067, 0.0150], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,087][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0077, 0.7955, 0.0122, 0.0353, 0.0301, 0.0114, 0.0160, 0.0121, 0.0061,
        0.0110, 0.0162, 0.0176, 0.0113, 0.0176], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,088][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4334, 0.2919, 0.0311, 0.0278, 0.0906, 0.0150, 0.0120, 0.0174, 0.0080,
        0.0062, 0.0218, 0.0103, 0.0086, 0.0258], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,089][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([7.6658e-05, 9.9990e-01, 3.2005e-07, 8.0211e-07, 7.5649e-06, 2.7535e-08,
        7.5650e-08, 1.5416e-06, 4.8071e-08, 3.2670e-08, 2.0090e-06, 8.0745e-07,
        1.7698e-06, 4.9129e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,092][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.1365, 0.1146, 0.0594, 0.1087, 0.0814, 0.0312, 0.0424, 0.0521, 0.0860,
        0.0943, 0.0637, 0.0421, 0.0583, 0.0290], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,096][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.9205, 0.0072, 0.0094, 0.0160, 0.0179, 0.0030, 0.0028, 0.0040, 0.0029,
        0.0033, 0.0036, 0.0018, 0.0034, 0.0042], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,099][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([4.9781e-05, 9.0851e-01, 3.1842e-03, 3.0201e-03, 1.1127e-02, 1.0910e-02,
        6.3011e-03, 4.8652e-03, 9.6795e-04, 1.6526e-03, 1.1734e-02, 1.4213e-02,
        3.8354e-03, 1.9627e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,101][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([4.8415e-03, 9.8029e-01, 1.0974e-03, 6.8821e-04, 7.5619e-03, 3.6892e-04,
        3.8511e-04, 1.4718e-03, 8.2015e-05, 6.8548e-05, 7.9969e-04, 4.4367e-04,
        3.4487e-04, 1.5563e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,102][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1657, 0.3578, 0.0434, 0.0381, 0.1244, 0.0308, 0.0164, 0.0297, 0.0191,
        0.0133, 0.0679, 0.0281, 0.0130, 0.0524], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,102][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([4.2240e-07, 9.7764e-01, 9.9179e-04, 2.9538e-04, 2.2457e-03, 3.9604e-03,
        3.1295e-03, 5.0524e-04, 1.3187e-04, 1.3788e-04, 7.8346e-04, 6.5002e-03,
        4.0036e-04, 3.2813e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,103][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([1.0693e-06, 9.9999e-01, 1.9581e-07, 9.9248e-08, 8.1349e-06, 2.4770e-08,
        7.2901e-08, 5.5080e-07, 4.3551e-09, 2.0961e-09, 4.8953e-07, 4.3914e-07,
        2.1228e-07, 2.5225e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,105][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0434, 0.0521, 0.0615, 0.0686, 0.0902, 0.0959, 0.0599, 0.0669, 0.0662,
        0.0512, 0.0587, 0.0951, 0.0809, 0.1093], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,109][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:11,111][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9480],
        [38479],
        [ 3143],
        [  835],
        [  447],
        [  167],
        [  157],
        [   58],
        [  268],
        [  137],
        [   87],
        [   43],
        [   90],
        [   60]], device='cuda:0')
[2024-07-24 10:30:11,114][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 7928],
        [16091],
        [  344],
        [  179],
        [  123],
        [   91],
        [  135],
        [   37],
        [  151],
        [   88],
        [   86],
        [   54],
        [   79],
        [   76]], device='cuda:0')
[2024-07-24 10:30:11,116][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 6646],
        [22737],
        [20587],
        [19846],
        [19337],
        [19598],
        [19352],
        [21350],
        [21665],
        [21545],
        [20188],
        [17119],
        [20166],
        [12439]], device='cuda:0')
[2024-07-24 10:30:11,119][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[7959],
        [2678],
        [1174],
        [2808],
        [2247],
        [3198],
        [2812],
        [3127],
        [3192],
        [4095],
        [4237],
        [4090],
        [4290],
        [4255]], device='cuda:0')
[2024-07-24 10:30:11,120][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4644],
        [49533],
        [49966],
        [49793],
        [49527],
        [48693],
        [49134],
        [47963],
        [47223],
        [46470],
        [48239],
        [43714],
        [47693],
        [40709]], device='cuda:0')
[2024-07-24 10:30:11,122][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[29021],
        [44323],
        [44384],
        [44384],
        [44384],
        [44384],
        [44384],
        [44383],
        [44385],
        [44385],
        [44384],
        [44384],
        [44383],
        [44384]], device='cuda:0')
[2024-07-24 10:30:11,123][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13754],
        [30052],
        [34814],
        [37254],
        [37992],
        [34742],
        [33956],
        [34200],
        [33952],
        [33114],
        [32856],
        [32573],
        [31598],
        [31901]], device='cuda:0')
[2024-07-24 10:30:11,126][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[44458],
        [44286],
        [29196],
        [ 5511],
        [28516],
        [39997],
        [37268],
        [26484],
        [25077],
        [16969],
        [34997],
        [42481],
        [29636],
        [42748]], device='cuda:0')
[2024-07-24 10:30:11,129][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[46524],
        [50248],
        [50247],
        [50240],
        [50237],
        [50176],
        [50168],
        [50052],
        [50144],
        [49976],
        [50115],
        [49906],
        [50034],
        [49876]], device='cuda:0')
[2024-07-24 10:30:11,131][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 121],
        [ 110],
        [3287],
        [3366],
        [2025],
        [2523],
        [2627],
        [3135],
        [2425],
        [2567],
        [2652],
        [2549],
        [2900],
        [2245]], device='cuda:0')
[2024-07-24 10:30:11,134][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[38962],
        [50070],
        [49593],
        [49076],
        [48269],
        [48062],
        [47027],
        [47161],
        [46722],
        [46758],
        [46920],
        [46768],
        [46608],
        [46721]], device='cuda:0')
[2024-07-24 10:30:11,136][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[12364],
        [50257],
        [33321],
        [23839],
        [21126],
        [ 9368],
        [ 5198],
        [ 5357],
        [ 8335],
        [ 6165],
        [ 5706],
        [ 3613],
        [ 5744],
        [ 1297]], device='cuda:0')
[2024-07-24 10:30:11,138][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 3161],
        [22709],
        [22709],
        [22709],
        [22709],
        [22709],
        [22709],
        [22709],
        [22709],
        [22709],
        [22709],
        [22709],
        [22709],
        [22709]], device='cuda:0')
[2024-07-24 10:30:11,139][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[21680],
        [50224],
        [50223],
        [50204],
        [47930],
        [49517],
        [47012],
        [44588],
        [50084],
        [44326],
        [44625],
        [45678],
        [38030],
        [45274]], device='cuda:0')
[2024-07-24 10:30:11,141][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21241],
        [ 2786],
        [ 3574],
        [ 4349],
        [ 3190],
        [ 1888],
        [ 2024],
        [ 3191],
        [ 2196],
        [ 5752],
        [ 2309],
        [ 1640],
        [ 3605],
        [ 2154]], device='cuda:0')
[2024-07-24 10:30:11,143][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[12242],
        [ 4548],
        [18442],
        [17904],
        [15498],
        [ 7684],
        [13763],
        [14471],
        [16388],
        [17880],
        [14766],
        [ 6629],
        [17647],
        [ 7539]], device='cuda:0')
[2024-07-24 10:30:11,146][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[8314],
        [5725],
        [5744],
        [5841],
        [5803],
        [6107],
        [6081],
        [6004],
        [6094],
        [6105],
        [6502],
        [6999],
        [6287],
        [6779]], device='cuda:0')
[2024-07-24 10:30:11,149][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[13110],
        [19456],
        [32751],
        [31884],
        [32685],
        [31824],
        [32906],
        [32760],
        [33053],
        [33655],
        [32849],
        [30685],
        [33476],
        [30400]], device='cuda:0')
[2024-07-24 10:30:11,151][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1128],
        [1899],
        [5775],
        [5775],
        [5775],
        [5775],
        [5775],
        [5775],
        [5775],
        [5775],
        [5775],
        [5775],
        [5775],
        [5774]], device='cuda:0')
[2024-07-24 10:30:11,154][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[10206],
        [ 5165],
        [ 4639],
        [ 4603],
        [ 5448],
        [ 6099],
        [ 5657],
        [ 5262],
        [ 5468],
        [ 5647],
        [ 7174],
        [ 7712],
        [ 6927],
        [ 7549]], device='cuda:0')
[2024-07-24 10:30:11,155][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[6555],
        [6514],
        [3703],
        [6833],
        [ 950],
        [1539],
        [ 988],
        [1847],
        [3524],
        [6276],
        [ 518],
        [1931],
        [1445],
        [1848]], device='cuda:0')
[2024-07-24 10:30:11,156][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[2346],
        [9438],
        [9454],
        [9468],
        [9426],
        [9456],
        [9470],
        [9476],
        [9465],
        [9480],
        [9434],
        [9440],
        [9436],
        [9349]], device='cuda:0')
[2024-07-24 10:30:11,158][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[7629],
        [1275],
        [1267],
        [1269],
        [1278],
        [1278],
        [1274],
        [1272],
        [1340],
        [1303],
        [1286],
        [1293],
        [1286],
        [1321]], device='cuda:0')
[2024-07-24 10:30:11,161][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[5071],
        [2642],
        [4785],
        [4947],
        [5208],
        [6111],
        [5922],
        [5874],
        [7755],
        [7755],
        [7104],
        [8084],
        [7006],
        [8860]], device='cuda:0')
[2024-07-24 10:30:11,163][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39591],
        [17513],
        [17521],
        [17527],
        [17555],
        [17573],
        [17576],
        [17565],
        [17563],
        [17563],
        [17551],
        [17538],
        [17551],
        [17541]], device='cuda:0')
[2024-07-24 10:30:11,166][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[11656],
        [21996],
        [21998],
        [21998],
        [21998],
        [21998],
        [21998],
        [21998],
        [21998],
        [21998],
        [21998],
        [21998],
        [21998],
        [21998]], device='cuda:0')
[2024-07-24 10:30:11,169][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[3557],
        [ 146],
        [ 157],
        [ 153],
        [ 315],
        [ 690],
        [ 670],
        [ 770],
        [ 682],
        [ 497],
        [1371],
        [1226],
        [1012],
        [1394]], device='cuda:0')
[2024-07-24 10:30:11,171][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[49208],
        [50171],
        [49474],
        [49385],
        [49711],
        [49571],
        [49435],
        [49661],
        [49389],
        [49000],
        [49587],
        [49599],
        [49534],
        [49536]], device='cuda:0')
[2024-07-24 10:30:11,173][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[35210],
        [49009],
        [48401],
        [48061],
        [48799],
        [49605],
        [49305],
        [48720],
        [49322],
        [47608],
        [49160],
        [49548],
        [48218],
        [49382]], device='cuda:0')
[2024-07-24 10:30:11,174][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19448],
        [19448],
        [19448],
        [19448],
        [19448],
        [19448],
        [19448],
        [19448],
        [19448],
        [19448],
        [19448],
        [19448],
        [19448],
        [19448]], device='cuda:0')
[2024-07-24 10:30:11,288][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:11,291][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,294][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,296][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,298][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,299][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,300][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,300][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,301][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,302][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,305][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,307][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,310][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,314][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.0091, 0.9909], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,315][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([2.4764e-04, 9.9975e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,315][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.9223, 0.0777], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,316][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.8915, 0.1085], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,317][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([0.8608, 0.1392], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,318][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([8.7999e-05, 9.9991e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,321][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0302, 0.9698], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,325][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.1183, 0.8817], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,328][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0233, 0.9767], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,330][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([0.9885, 0.0115], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,331][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([0.2992, 0.7008], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,331][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.0949, 0.9051], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,332][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([3.6518e-04, 9.8772e-01, 1.1915e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,333][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.3044e-05, 9.8703e-01, 1.2961e-02], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,335][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1577, 0.4435, 0.3987], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,338][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3049, 0.4319, 0.2632], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,341][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1309, 0.8010, 0.0680], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,344][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.2938e-09, 1.0000e+00, 5.8380e-09], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,345][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0013, 0.9207, 0.0781], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,346][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0469, 0.4772, 0.4759], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,347][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0023, 0.8488, 0.1489], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,348][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0099, 0.9878, 0.0023], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,350][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0647, 0.4585, 0.4768], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,352][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0487, 0.8627, 0.0885], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,354][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([1.4159e-04, 9.8104e-01, 1.4841e-02, 3.9804e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,357][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([5.1584e-06, 9.8155e-01, 7.8777e-03, 1.0565e-02], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,358][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0226, 0.6282, 0.2847, 0.0645], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,359][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0782, 0.4582, 0.1969, 0.2667], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,360][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.0458, 0.8328, 0.0770, 0.0443], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,361][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([4.1201e-09, 1.0000e+00, 7.8283e-08, 4.9987e-09], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,361][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([1.6571e-04, 9.5486e-01, 3.4979e-02, 9.9987e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,363][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0602, 0.3430, 0.3970, 0.1998], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,365][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([2.2676e-04, 4.4515e-01, 2.1574e-01, 3.3889e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,369][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.0053, 0.9875, 0.0028, 0.0044], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,371][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.0106, 0.0429, 0.9421, 0.0044], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,372][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0055, 0.9026, 0.0547, 0.0373], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,373][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ went] are: tensor([2.3197e-04, 9.5752e-01, 1.2473e-02, 2.5522e-03, 2.7221e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,374][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ went] are: tensor([1.8593e-05, 9.7217e-01, 5.3530e-03, 9.0449e-03, 1.3417e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,376][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0946, 0.3680, 0.1868, 0.0653, 0.2853], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,378][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ went] are: tensor([0.1250, 0.3098, 0.1412, 0.2132, 0.2108], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,382][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ went] are: tensor([0.1265, 0.6941, 0.0592, 0.0374, 0.0827], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,384][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ went] are: tensor([1.1997e-08, 1.0000e+00, 1.0144e-08, 4.9467e-10, 2.8162e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,385][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ went] are: tensor([6.4532e-04, 8.7301e-01, 4.2644e-02, 1.3232e-02, 7.0466e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,386][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.0335, 0.2685, 0.2761, 0.1243, 0.2977], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,386][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0008, 0.3155, 0.0440, 0.0609, 0.5788], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,388][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.2787, 0.6091, 0.0010, 0.0026, 0.1086], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,391][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ went] are: tensor([0.0156, 0.0364, 0.9390, 0.0043, 0.0046], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,395][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.0450, 0.6127, 0.0755, 0.0493, 0.2175], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,397][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0010, 0.8277, 0.0363, 0.0088, 0.0900, 0.0361], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,398][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([3.3122e-04, 7.3376e-01, 2.1854e-02, 5.1638e-02, 2.8468e-02, 1.6395e-01],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,399][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2095, 0.0525, 0.1199, 0.0510, 0.1710, 0.3962], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,399][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3068, 0.1383, 0.0920, 0.1599, 0.1363, 0.1667], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,401][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.2454, 0.4935, 0.0802, 0.0373, 0.0854, 0.0583], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,403][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.8989e-10, 1.0000e+00, 1.9585e-10, 2.3409e-11, 1.1662e-08, 4.2996e-11],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,406][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0029, 0.6162, 0.0448, 0.0155, 0.0788, 0.2418], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,410][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0262, 0.1923, 0.2292, 0.1388, 0.2262, 0.1873], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,411][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0399, 0.5688, 0.0200, 0.0226, 0.1847, 0.1640], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,412][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([6.2900e-04, 8.4168e-01, 5.1272e-04, 2.4941e-03, 1.5464e-01, 4.1432e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,413][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0649, 0.5159, 0.2367, 0.0334, 0.0357, 0.1135], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,415][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1946, 0.4971, 0.0313, 0.0604, 0.1864, 0.0302], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,417][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([3.4937e-04, 8.9678e-01, 1.7373e-02, 5.3167e-03, 4.2652e-02, 1.6084e-02,
        2.1441e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,419][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.6424e-04, 7.4555e-01, 1.9208e-02, 3.9844e-02, 2.0272e-02, 9.1051e-02,
        8.3913e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,423][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1342, 0.0725, 0.1110, 0.0566, 0.2030, 0.2819, 0.1408],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,424][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.2145, 0.1356, 0.0887, 0.1565, 0.1601, 0.1397, 0.1048],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,424][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1070, 0.6752, 0.0581, 0.0193, 0.0849, 0.0369, 0.0187],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,425][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.0704e-10, 1.0000e+00, 2.1869e-10, 8.7572e-12, 2.0908e-08, 2.5305e-11,
        7.7708e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,427][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0011, 0.6863, 0.0325, 0.0190, 0.0754, 0.1319, 0.0538],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,430][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0228, 0.1672, 0.1889, 0.0975, 0.1981, 0.1533, 0.1722],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,434][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0218, 0.4906, 0.0202, 0.0289, 0.2243, 0.1475, 0.0668],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,436][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([1.3047e-02, 8.0361e-01, 7.3245e-04, 2.3989e-03, 1.7934e-01, 1.2115e-05,
        8.6033e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,437][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0707, 0.3566, 0.3159, 0.0318, 0.0288, 0.1077, 0.0885],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,438][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0503, 0.6832, 0.0373, 0.0327, 0.1396, 0.0325, 0.0243],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,438][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ station] are: tensor([5.0491e-04, 8.4982e-01, 2.1623e-02, 5.5882e-03, 5.1918e-02, 2.3696e-02,
        2.6068e-02, 2.0785e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,440][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ station] are: tensor([1.2799e-04, 6.7734e-01, 2.4898e-02, 3.6766e-02, 1.9540e-02, 1.0713e-01,
        9.8365e-02, 3.5840e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,442][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.0600, 0.0916, 0.1162, 0.0452, 0.1888, 0.2182, 0.1133, 0.1668],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,446][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ station] are: tensor([0.1433, 0.1621, 0.0775, 0.1447, 0.1538, 0.1137, 0.1014, 0.1036],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,449][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ station] are: tensor([0.0746, 0.7448, 0.0557, 0.0135, 0.0701, 0.0222, 0.0126, 0.0064],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,450][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ station] are: tensor([7.5921e-11, 1.0000e+00, 9.5724e-11, 2.0934e-12, 1.6513e-08, 3.5569e-12,
        1.7885e-11, 4.9077e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,451][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ station] are: tensor([0.0012, 0.4699, 0.0450, 0.0226, 0.1329, 0.2067, 0.0788, 0.0429],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,452][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0199, 0.1558, 0.1686, 0.0944, 0.1799, 0.1277, 0.1446, 0.1091],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,453][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ station] are: tensor([0.0064, 0.5000, 0.0203, 0.0216, 0.2208, 0.1028, 0.0501, 0.0780],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,455][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ station] are: tensor([5.6833e-02, 7.3349e-01, 8.7786e-04, 2.5669e-03, 1.9904e-01, 6.3924e-06,
        5.4047e-04, 6.6407e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,459][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ station] are: tensor([0.0276, 0.1392, 0.5584, 0.0120, 0.0122, 0.1203, 0.1288, 0.0015],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,462][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.0313, 0.6863, 0.0327, 0.0280, 0.1485, 0.0206, 0.0131, 0.0394],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,463][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0010, 0.8055, 0.0286, 0.0102, 0.0578, 0.0222, 0.0375, 0.0298, 0.0075],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,464][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.4411e-04, 7.5045e-01, 1.3564e-02, 2.8248e-02, 1.7029e-02, 5.2897e-02,
        6.0914e-02, 5.7676e-02, 1.9078e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,465][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0430, 0.1156, 0.0755, 0.0429, 0.1353, 0.1920, 0.1126, 0.1805, 0.1027],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,467][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2381, 0.0789, 0.0674, 0.1273, 0.1278, 0.0672, 0.0751, 0.0939, 0.1244],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,469][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0800, 0.4703, 0.0810, 0.0384, 0.1278, 0.0659, 0.0550, 0.0491, 0.0326],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,472][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([4.0566e-10, 1.0000e+00, 5.1315e-09, 5.0310e-10, 2.6827e-07, 1.9956e-09,
        1.6033e-08, 7.8145e-07, 4.7529e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,476][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0014, 0.5977, 0.0420, 0.0213, 0.0785, 0.1217, 0.0631, 0.0337, 0.0406],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,476][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0115, 0.1225, 0.1545, 0.0996, 0.1685, 0.1045, 0.1332, 0.1021, 0.1037],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,477][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0010, 0.3391, 0.0183, 0.0182, 0.2340, 0.1810, 0.0723, 0.1295, 0.0066],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,478][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([1.1239e-03, 8.1795e-01, 9.2364e-04, 5.7618e-03, 1.3036e-01, 3.5268e-05,
        3.4472e-03, 4.0348e-02, 5.0599e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,480][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0546, 0.2298, 0.2921, 0.0274, 0.0226, 0.1031, 0.1013, 0.0060, 0.1631],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,482][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0063, 0.6998, 0.0278, 0.0226, 0.0870, 0.0324, 0.0224, 0.0880, 0.0138],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,485][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([2.7750e-04, 8.0129e-01, 2.3710e-02, 5.6263e-03, 5.0191e-02, 2.7776e-02,
        4.6053e-02, 3.4163e-02, 6.8278e-03, 4.0817e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,487][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([3.8180e-05, 7.3640e-01, 1.1848e-02, 1.3526e-02, 1.5480e-02, 7.1798e-02,
        7.7879e-02, 4.2281e-02, 1.7140e-02, 1.3612e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,489][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0107, 0.1584, 0.0817, 0.0236, 0.1546, 0.1983, 0.0826, 0.1789, 0.0665,
        0.0445], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,490][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0621, 0.1437, 0.0809, 0.0871, 0.1771, 0.0843, 0.0947, 0.1154, 0.0970,
        0.0577], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,490][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([0.0300, 0.6366, 0.0767, 0.0216, 0.1051, 0.0375, 0.0377, 0.0288, 0.0167,
        0.0091], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,491][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([6.3840e-11, 1.0000e+00, 4.8145e-09, 1.5988e-10, 2.7862e-07, 1.1881e-09,
        7.9688e-09, 3.7587e-07, 1.0086e-11, 1.0077e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,492][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([2.7128e-04, 6.1425e-01, 2.5704e-02, 1.0613e-02, 6.5674e-02, 1.4945e-01,
        6.8840e-02, 2.4824e-02, 2.7358e-02, 1.3011e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,494][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0107, 0.1051, 0.1531, 0.0712, 0.1721, 0.1021, 0.1299, 0.0964, 0.1011,
        0.0584], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,496][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([0.0009, 0.4067, 0.0238, 0.0177, 0.3045, 0.0882, 0.0619, 0.0733, 0.0029,
        0.0200], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,499][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([8.0790e-04, 7.4617e-01, 1.6859e-03, 3.2826e-03, 2.1676e-01, 2.6194e-05,
        2.7337e-03, 2.8415e-02, 2.1541e-05, 1.0291e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,501][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([7.3110e-03, 2.5081e-02, 6.8599e-01, 2.2742e-03, 3.2300e-03, 5.2554e-02,
        4.6259e-02, 3.3468e-04, 1.7553e-01, 1.4326e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,503][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.0020, 0.7569, 0.0181, 0.0118, 0.0586, 0.0391, 0.0216, 0.0690, 0.0096,
        0.0133], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,504][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([1.7282e-04, 9.3461e-01, 8.2628e-03, 2.1939e-03, 1.5534e-02, 8.2689e-03,
        1.1212e-02, 7.4420e-03, 2.1377e-03, 9.1265e-04, 9.2551e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,504][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([2.3733e-04, 7.5190e-01, 7.6297e-03, 1.4259e-02, 1.2301e-02, 6.9387e-02,
        4.5393e-02, 6.6697e-02, 1.2877e-02, 1.1357e-02, 7.9616e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,505][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0548, 0.0611, 0.0529, 0.0334, 0.1179, 0.1025, 0.0614, 0.1915, 0.0732,
        0.0625, 0.1888], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,507][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1298, 0.1101, 0.0687, 0.1104, 0.1162, 0.0635, 0.0582, 0.1005, 0.0936,
        0.0586, 0.0905], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,511][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1008, 0.5052, 0.0731, 0.0299, 0.0900, 0.0593, 0.0298, 0.0188, 0.0247,
        0.0175, 0.0510], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,513][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([1.1822e-08, 1.0000e+00, 2.8576e-09, 3.1244e-10, 1.4641e-07, 2.6030e-10,
        1.3938e-09, 3.5166e-08, 1.1946e-11, 5.9242e-12, 4.9400e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,515][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([5.6861e-04, 7.0759e-01, 1.6572e-02, 1.1771e-02, 4.4278e-02, 7.8497e-02,
        3.3546e-02, 3.2553e-02, 1.9941e-02, 1.1364e-02, 4.3322e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,516][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0136, 0.1031, 0.1262, 0.0685, 0.1314, 0.0942, 0.1126, 0.0883, 0.0900,
        0.0579, 0.1142], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,517][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0041, 0.2825, 0.0221, 0.0304, 0.2302, 0.0847, 0.0478, 0.0742, 0.0066,
        0.0326, 0.1848], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,518][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.1544e-01, 7.8554e-01, 3.6659e-04, 5.3954e-03, 7.8371e-02, 5.9280e-06,
        5.0904e-04, 9.6654e-03, 3.3708e-05, 2.3157e-04, 4.4366e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,520][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0145, 0.0489, 0.5075, 0.0081, 0.0099, 0.0897, 0.1001, 0.0019, 0.1970,
        0.0056, 0.0168], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,523][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0566, 0.4768, 0.0378, 0.0417, 0.1549, 0.0198, 0.0105, 0.0984, 0.0170,
        0.0215, 0.0652], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,527][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0028, 0.6146, 0.0294, 0.0095, 0.0585, 0.0262, 0.0369, 0.0260, 0.0098,
        0.0038, 0.0332, 0.1493], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,529][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0005, 0.4304, 0.0186, 0.0270, 0.0209, 0.1094, 0.0826, 0.0904, 0.0314,
        0.0222, 0.0216, 0.1450], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,530][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1374, 0.0256, 0.0389, 0.0243, 0.0724, 0.1100, 0.0523, 0.1223, 0.0678,
        0.0534, 0.1795, 0.1159], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,531][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.3481, 0.0239, 0.0427, 0.0652, 0.0693, 0.0486, 0.0349, 0.0836, 0.0862,
        0.0503, 0.0963, 0.0508], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,532][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.4224, 0.2383, 0.0767, 0.0246, 0.0918, 0.0426, 0.0177, 0.0095, 0.0180,
        0.0090, 0.0287, 0.0208], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,533][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([6.9690e-09, 1.0000e+00, 8.9036e-10, 9.1036e-11, 5.7241e-08, 8.6889e-11,
        3.3720e-10, 8.8251e-09, 3.3612e-12, 1.2393e-12, 2.2908e-09, 2.5626e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,536][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0057, 0.3572, 0.0314, 0.0200, 0.0768, 0.1184, 0.0469, 0.0416, 0.0433,
        0.0240, 0.1074, 0.1274], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,540][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0158, 0.1012, 0.1143, 0.0557, 0.1133, 0.0909, 0.1019, 0.0745, 0.0798,
        0.0493, 0.0885, 0.1148], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,542][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0137, 0.3250, 0.0119, 0.0165, 0.1659, 0.0875, 0.0516, 0.0732, 0.0047,
        0.0189, 0.1414, 0.0897], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,543][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([5.0614e-01, 4.0528e-01, 2.1228e-04, 4.0046e-03, 5.9729e-02, 3.1323e-06,
        2.7541e-04, 7.5338e-03, 3.4915e-05, 2.7834e-04, 6.5562e-03, 9.9503e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,544][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0349, 0.1569, 0.3037, 0.0188, 0.0159, 0.0893, 0.0825, 0.0078, 0.1657,
        0.0135, 0.0281, 0.0828], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,545][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3435, 0.2103, 0.0258, 0.0486, 0.1317, 0.0125, 0.0089, 0.0853, 0.0298,
        0.0294, 0.0590, 0.0153], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,546][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([2.3195e-04, 8.7412e-01, 7.6267e-03, 2.3553e-03, 2.2843e-02, 6.1073e-03,
        1.1002e-02, 1.1948e-02, 1.7920e-03, 1.2102e-03, 1.0888e-02, 4.3866e-02,
        6.0126e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,548][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([1.4537e-04, 7.0777e-01, 7.2732e-03, 1.3689e-02, 1.3884e-02, 3.2546e-02,
        4.0879e-02, 3.7704e-02, 9.3496e-03, 1.0677e-02, 1.0696e-02, 8.1459e-02,
        3.3924e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,551][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0212, 0.1186, 0.0527, 0.0191, 0.1067, 0.0839, 0.0507, 0.0871, 0.0451,
        0.0289, 0.1404, 0.1425, 0.1031], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,555][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([0.0771, 0.1235, 0.0539, 0.1077, 0.0851, 0.0430, 0.0475, 0.0738, 0.0552,
        0.0585, 0.0632, 0.0706, 0.1408], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,556][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([0.0620, 0.5730, 0.0643, 0.0200, 0.1129, 0.0315, 0.0247, 0.0219, 0.0112,
        0.0078, 0.0268, 0.0268, 0.0171], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,557][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([1.2697e-09, 1.0000e+00, 1.8664e-09, 1.0879e-10, 2.1469e-07, 1.1455e-10,
        9.6004e-10, 4.6920e-08, 1.7850e-12, 1.8903e-12, 2.2081e-09, 3.6236e-09,
        4.3686e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,558][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([5.7093e-04, 6.8922e-01, 1.5007e-02, 1.1401e-02, 4.1679e-02, 4.5212e-02,
        1.8531e-02, 1.6767e-02, 1.1475e-02, 9.0855e-03, 3.6308e-02, 6.5524e-02,
        3.9217e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,560][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0154, 0.0989, 0.1116, 0.0541, 0.1167, 0.0760, 0.0932, 0.0650, 0.0647,
        0.0436, 0.0863, 0.1118, 0.0625], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,562][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([0.0017, 0.3541, 0.0141, 0.0110, 0.1776, 0.0674, 0.0427, 0.0711, 0.0029,
        0.0157, 0.1219, 0.0986, 0.0214], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,565][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([6.7717e-01, 2.3449e-01, 4.0118e-04, 4.0606e-03, 4.5250e-02, 2.3887e-06,
        2.1153e-04, 4.2026e-03, 2.1922e-05, 1.3873e-04, 1.9598e-03, 3.2246e-03,
        2.8858e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,569][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([0.0169, 0.0621, 0.4387, 0.0048, 0.0053, 0.0860, 0.0818, 0.0008, 0.2033,
        0.0028, 0.0165, 0.0797, 0.0013], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,570][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([0.0102, 0.6629, 0.0272, 0.0235, 0.0962, 0.0142, 0.0100, 0.0506, 0.0082,
        0.0100, 0.0436, 0.0244, 0.0191], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,570][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0113, 0.2678, 0.0365, 0.0148, 0.0529, 0.0244, 0.0284, 0.0196, 0.0139,
        0.0059, 0.0415, 0.1270, 0.0326, 0.3235], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,571][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0033, 0.1704, 0.0184, 0.0357, 0.0170, 0.0668, 0.0390, 0.0479, 0.0354,
        0.0270, 0.0204, 0.1034, 0.0744, 0.3409], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,573][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1671, 0.0099, 0.0258, 0.0196, 0.0424, 0.0633, 0.0273, 0.0509, 0.0550,
        0.0405, 0.1179, 0.0698, 0.0834, 0.2270], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,576][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.4694, 0.0114, 0.0210, 0.0440, 0.0337, 0.0189, 0.0148, 0.0283, 0.0533,
        0.0287, 0.0471, 0.0298, 0.0916, 0.1080], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,580][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.5468, 0.1390, 0.0513, 0.0242, 0.0627, 0.0276, 0.0107, 0.0059, 0.0147,
        0.0085, 0.0243, 0.0152, 0.0134, 0.0557], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,582][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.6314e-07, 1.0000e+00, 3.9179e-09, 9.5349e-10, 2.2320e-07, 1.6068e-10,
        8.2785e-10, 1.7223e-08, 1.5872e-11, 8.3776e-12, 5.0897e-09, 4.7254e-09,
        1.3836e-09, 4.1243e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,583][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0159, 0.1970, 0.0263, 0.0208, 0.0530, 0.0730, 0.0247, 0.0291, 0.0381,
        0.0214, 0.0764, 0.0791, 0.0886, 0.2566], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,584][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0160, 0.0941, 0.0962, 0.0541, 0.0943, 0.0777, 0.0823, 0.0587, 0.0648,
        0.0411, 0.0722, 0.0905, 0.0523, 0.1057], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,585][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0365, 0.3041, 0.0070, 0.0102, 0.1065, 0.0615, 0.0274, 0.0649, 0.0034,
        0.0159, 0.1436, 0.0644, 0.0248, 0.1297], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,586][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.0589e-01, 1.0109e-01, 1.3383e-04, 2.4013e-03, 1.9733e-02, 2.2556e-06,
        1.6645e-04, 2.0501e-03, 3.5231e-05, 2.3410e-04, 2.9869e-03, 4.7378e-03,
        3.6439e-02, 2.4090e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,589][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0573, 0.3485, 0.1195, 0.0250, 0.0248, 0.0665, 0.0620, 0.0090, 0.1087,
        0.0201, 0.0270, 0.0670, 0.0143, 0.0503], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,593][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.3573, 0.1898, 0.0260, 0.0552, 0.1097, 0.0136, 0.0087, 0.0547, 0.0333,
        0.0345, 0.0416, 0.0135, 0.0310, 0.0310], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,711][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:11,714][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,717][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,719][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,719][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,720][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,721][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,722][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,723][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,725][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,728][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,730][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,734][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:11,735][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.0010, 0.9990], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,735][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([9.7511e-07, 1.0000e+00], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,736][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.0653, 0.9347], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,737][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.7606, 0.2394], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,738][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([0.8608, 0.1392], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,740][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([8.7999e-05, 9.9991e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,743][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,747][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.9944, 0.0056], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,748][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([0.2259, 0.7741], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,748][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([2.3149e-05, 9.9998e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,749][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([0.0726, 0.9274], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,750][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([0.0949, 0.9051], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:11,751][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([8.8262e-05, 9.9650e-01, 3.4127e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,752][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.7724e-06, 9.9838e-01, 1.6168e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,755][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0158, 0.8467, 0.1375], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,758][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1349, 0.6748, 0.1903], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,761][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1309, 0.8010, 0.0680], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,762][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.2938e-09, 1.0000e+00, 5.8380e-09], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,763][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([1.9321e-04, 9.9059e-01, 9.2202e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,763][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6974, 0.1790, 0.1236], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,765][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0804, 0.8008, 0.1188], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,767][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([1.7676e-11, 1.0000e+00, 2.9411e-10], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,771][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0077, 0.9907, 0.0016], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,774][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0487, 0.8627, 0.0885], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:11,775][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([1.5522e-04, 9.8882e-01, 8.2304e-03, 2.7932e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,775][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([2.9730e-06, 9.9678e-01, 2.2725e-03, 9.4274e-04], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,776][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0067, 0.8047, 0.1265, 0.0621], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,777][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.1027, 0.5270, 0.2254, 0.1448], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,779][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.0458, 0.8328, 0.0770, 0.0443], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,780][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([4.1201e-09, 1.0000e+00, 7.8283e-08, 4.9987e-09], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,783][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([1.8507e-04, 9.8188e-01, 1.3998e-02, 3.9394e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,787][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.4149, 0.1855, 0.1234, 0.2761], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,787][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0179, 0.8105, 0.0826, 0.0891], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,788][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([7.8219e-11, 1.0000e+00, 5.5675e-09, 3.3336e-10], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,789][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.0079, 0.9594, 0.0044, 0.0283], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,790][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0055, 0.9026, 0.0547, 0.0373], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:11,791][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([1.4348e-04, 9.7914e-01, 4.8552e-03, 1.3767e-03, 1.4487e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,793][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([5.7754e-06, 9.9241e-01, 1.1873e-03, 5.4915e-04, 5.8506e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,796][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([0.0173, 0.7150, 0.0688, 0.0551, 0.1437], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,800][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([0.1394, 0.3247, 0.1438, 0.1015, 0.2907], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,801][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([0.1265, 0.6941, 0.0592, 0.0374, 0.0827], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,801][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([1.1997e-08, 1.0000e+00, 1.0144e-08, 4.9467e-10, 2.8162e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,802][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([1.8678e-04, 9.7711e-01, 7.1310e-03, 1.9013e-03, 1.3668e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,803][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.6857, 0.0581, 0.0574, 0.1115, 0.0873], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,805][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0739, 0.5699, 0.0697, 0.1106, 0.1759], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,807][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([2.0856e-10, 1.0000e+00, 4.5012e-10, 2.0518e-11, 2.1392e-08],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,811][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.0054, 0.9687, 0.0011, 0.0110, 0.0137], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,813][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([0.0450, 0.6127, 0.0755, 0.0493, 0.2175], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:11,814][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.0105e-04, 9.7571e-01, 4.0476e-03, 1.2380e-03, 1.6351e-02, 2.5545e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,815][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([7.1341e-06, 9.9084e-01, 1.2609e-03, 6.1682e-04, 4.4158e-03, 2.8644e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,816][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0467, 0.3402, 0.0840, 0.0980, 0.1695, 0.2616], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,817][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1996, 0.2831, 0.1210, 0.0796, 0.2573, 0.0594], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,820][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2454, 0.4935, 0.0802, 0.0373, 0.0854, 0.0583], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,822][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.8989e-10, 1.0000e+00, 1.9585e-10, 2.3409e-11, 1.1662e-08, 4.2996e-11],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,824][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.1051e-04, 9.8592e-01, 2.5105e-03, 7.7912e-04, 6.9886e-03, 3.6874e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,827][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.7430, 0.0109, 0.0347, 0.1120, 0.0389, 0.0604], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,827][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4900, 0.1738, 0.0537, 0.1117, 0.1196, 0.0512], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,828][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.7476e-14, 1.0000e+00, 7.5894e-13, 4.4468e-14, 6.1922e-11, 1.5739e-13],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,829][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([2.4180e-02, 9.5013e-01, 5.8497e-04, 1.2539e-02, 1.2280e-02, 2.8773e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,830][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1946, 0.4971, 0.0313, 0.0604, 0.1864, 0.0302], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:11,831][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([4.6634e-05, 9.8122e-01, 2.8720e-03, 8.7089e-04, 1.1134e-02, 1.3114e-03,
        2.5441e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,833][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([4.0608e-06, 9.9045e-01, 1.3383e-03, 5.4728e-04, 3.6899e-03, 1.9820e-03,
        1.9844e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,836][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0240, 0.3569, 0.0886, 0.0758, 0.1918, 0.1917, 0.0711],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,840][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1137, 0.3010, 0.1187, 0.0645, 0.2957, 0.0597, 0.0466],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,841][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1070, 0.6752, 0.0581, 0.0193, 0.0849, 0.0369, 0.0187],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,842][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.0704e-10, 1.0000e+00, 2.1869e-10, 8.7572e-12, 2.0908e-08, 2.5305e-11,
        7.7708e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,842][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.6111e-05, 9.7746e-01, 3.7705e-03, 1.1457e-03, 1.1395e-02, 3.6934e-03,
        2.4399e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,844][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.5910, 0.0272, 0.0513, 0.1143, 0.0734, 0.0822, 0.0607],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,847][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.3154, 0.2201, 0.0727, 0.1390, 0.1440, 0.0641, 0.0446],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,849][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([5.8994e-14, 1.0000e+00, 2.3921e-12, 5.2712e-14, 3.1691e-10, 2.4309e-13,
        6.6765e-13], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,851][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([1.1786e-02, 9.6161e-01, 7.1223e-04, 1.2129e-02, 1.2976e-02, 2.5204e-04,
        5.3555e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,854][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0503, 0.6832, 0.0373, 0.0327, 0.1396, 0.0325, 0.0243],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:11,854][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([4.3196e-05, 9.7999e-01, 2.9082e-03, 7.3270e-04, 1.0429e-02, 1.6703e-03,
        2.4417e-03, 1.7889e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,855][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([1.4654e-06, 9.9191e-01, 8.5975e-04, 3.2188e-04, 2.2095e-03, 1.7410e-03,
        1.3024e-03, 1.6579e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,856][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([0.0066, 0.4846, 0.0722, 0.0484, 0.1341, 0.1436, 0.0465, 0.0639],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,858][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([0.0649, 0.4017, 0.1032, 0.0513, 0.2533, 0.0519, 0.0344, 0.0393],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,861][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([0.0746, 0.7448, 0.0557, 0.0135, 0.0701, 0.0222, 0.0126, 0.0064],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,863][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([7.5921e-11, 1.0000e+00, 9.5724e-11, 2.0934e-12, 1.6513e-08, 3.5569e-12,
        1.7885e-11, 4.9077e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,865][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([1.4509e-04, 9.5804e-01, 5.6853e-03, 1.8435e-03, 1.8282e-02, 6.0522e-03,
        3.7712e-03, 6.1758e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,867][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.5197, 0.0470, 0.0483, 0.1670, 0.0843, 0.0568, 0.0422, 0.0346],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,868][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([0.2053, 0.3591, 0.0739, 0.1230, 0.1257, 0.0398, 0.0326, 0.0407],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,868][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([9.0887e-14, 1.0000e+00, 1.4378e-12, 1.6019e-14, 3.4635e-10, 2.1411e-14,
        1.0401e-13, 1.8691e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,869][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([4.9273e-03, 9.7416e-01, 5.7876e-04, 7.8187e-03, 1.0210e-02, 2.3904e-04,
        4.1102e-04, 1.6593e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,871][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([0.0313, 0.6863, 0.0327, 0.0280, 0.1485, 0.0206, 0.0131, 0.0394],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:11,873][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([7.3558e-05, 9.5974e-01, 5.5819e-03, 1.9456e-03, 1.6836e-02, 3.0886e-03,
        6.6077e-03, 5.6175e-03, 5.0918e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,875][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.6126e-06, 9.8948e-01, 8.6760e-04, 4.1715e-04, 2.6311e-03, 1.9433e-03,
        1.8249e-03, 2.7023e-03, 1.3394e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,878][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0055, 0.4738, 0.0515, 0.0423, 0.1124, 0.1396, 0.0534, 0.0929, 0.0285],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,880][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0696, 0.3160, 0.0982, 0.0647, 0.2352, 0.0499, 0.0516, 0.0908, 0.0241],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,881][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0800, 0.4703, 0.0810, 0.0384, 0.1278, 0.0659, 0.0550, 0.0491, 0.0326],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,882][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([4.0566e-10, 1.0000e+00, 5.1315e-09, 5.0310e-10, 2.6827e-07, 1.9956e-09,
        1.6033e-08, 7.8145e-07, 4.7529e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,883][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([6.5214e-05, 9.6218e-01, 5.2139e-03, 1.8566e-03, 1.2943e-02, 5.9846e-03,
        4.2365e-03, 6.7520e-03, 7.6998e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,885][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1783, 0.0863, 0.0516, 0.1631, 0.0943, 0.0958, 0.1039, 0.0908, 0.1359],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,887][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0668, 0.4097, 0.0605, 0.0817, 0.1108, 0.0899, 0.0553, 0.0740, 0.0511],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,890][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([5.9182e-13, 1.0000e+00, 1.3291e-10, 1.1116e-11, 8.0225e-09, 2.9360e-11,
        2.5645e-10, 7.9273e-08, 3.7524e-13], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,892][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([4.5839e-03, 9.6319e-01, 9.0631e-04, 1.3783e-02, 1.2633e-02, 3.7868e-04,
        7.8361e-04, 3.4977e-03, 2.4035e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,894][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0063, 0.6998, 0.0278, 0.0226, 0.0870, 0.0324, 0.0224, 0.0880, 0.0138],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:11,894][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([5.4677e-05, 9.5388e-01, 6.3640e-03, 1.5953e-03, 1.8146e-02, 4.0334e-03,
        7.7061e-03, 7.1440e-03, 5.3519e-04, 5.4342e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,895][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([1.5783e-06, 9.8224e-01, 1.4320e-03, 4.7110e-04, 4.1467e-03, 3.9998e-03,
        3.2078e-03, 4.0400e-03, 2.1258e-04, 2.4389e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,896][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0024, 0.4456, 0.0610, 0.0301, 0.1263, 0.1371, 0.0436, 0.0962, 0.0240,
        0.0339], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,898][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([0.0403, 0.3066, 0.1104, 0.0399, 0.2798, 0.0514, 0.0512, 0.0850, 0.0181,
        0.0172], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,901][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([0.0300, 0.6366, 0.0767, 0.0216, 0.1051, 0.0375, 0.0377, 0.0288, 0.0167,
        0.0091], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,903][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([6.3840e-11, 1.0000e+00, 4.8145e-09, 1.5988e-10, 2.7862e-07, 1.1881e-09,
        7.9688e-09, 3.7587e-07, 1.0086e-11, 1.0077e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,905][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([7.3536e-05, 9.4349e-01, 6.4038e-03, 1.8459e-03, 1.9231e-02, 1.0461e-02,
        6.1390e-03, 9.9876e-03, 9.4958e-04, 1.4181e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,907][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.1429, 0.0630, 0.0567, 0.1281, 0.1219, 0.0775, 0.0808, 0.0850, 0.1159,
        0.1281], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,908][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0311, 0.5322, 0.0549, 0.0644, 0.1174, 0.0456, 0.0419, 0.0383, 0.0270,
        0.0473], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,908][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([5.6386e-14, 1.0000e+00, 9.8634e-11, 1.8417e-12, 7.8772e-09, 1.6973e-11,
        1.3019e-10, 3.4480e-08, 4.0973e-14, 5.6988e-14], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,909][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([5.0419e-03, 9.4798e-01, 1.4666e-03, 1.2892e-02, 2.1682e-02, 7.7990e-04,
        1.2653e-03, 6.7138e-03, 3.1299e-04, 1.8609e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,911][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.0020, 0.7569, 0.0181, 0.0118, 0.0586, 0.0391, 0.0216, 0.0690, 0.0096,
        0.0133], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:11,913][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([2.2239e-05, 9.8711e-01, 1.8879e-03, 5.2495e-04, 5.2963e-03, 9.3044e-04,
        1.5702e-03, 9.6073e-04, 1.2982e-04, 8.2981e-05, 1.4880e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,915][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.3975e-06, 9.9182e-01, 5.5349e-04, 1.9847e-04, 2.0717e-03, 1.5427e-03,
        9.7927e-04, 2.1962e-03, 7.0370e-05, 7.3328e-05, 4.9410e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,919][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0126, 0.3380, 0.0465, 0.0584, 0.1228, 0.0945, 0.0310, 0.0895, 0.0293,
        0.0615, 0.1160], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,920][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0992, 0.2138, 0.1160, 0.0775, 0.2675, 0.0377, 0.0331, 0.0635, 0.0198,
        0.0215, 0.0503], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,921][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.1008, 0.5052, 0.0731, 0.0299, 0.0900, 0.0593, 0.0298, 0.0188, 0.0247,
        0.0175, 0.0510], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,922][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.1822e-08, 1.0000e+00, 2.8576e-09, 3.1244e-10, 1.4641e-07, 2.6030e-10,
        1.3938e-09, 3.5166e-08, 1.1946e-11, 5.9242e-12, 4.9400e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,923][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([4.9197e-05, 9.7515e-01, 2.3528e-03, 9.0542e-04, 7.8060e-03, 3.4049e-03,
        1.8646e-03, 3.9634e-03, 4.0546e-04, 5.7216e-04, 3.5293e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,925][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.3656, 0.0155, 0.0298, 0.0873, 0.0462, 0.0421, 0.0379, 0.0268, 0.0993,
        0.0958, 0.1537], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,927][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.1423, 0.3481, 0.0449, 0.0962, 0.1018, 0.0314, 0.0213, 0.0310, 0.0295,
        0.0649, 0.0886], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,929][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([5.4070e-12, 1.0000e+00, 1.3943e-11, 1.7214e-12, 1.4048e-09, 8.8787e-13,
        3.4916e-12, 9.1562e-10, 2.2425e-14, 1.2783e-14, 9.5467e-11],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,931][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([5.2059e-03, 9.6550e-01, 6.1103e-04, 7.6149e-03, 9.0374e-03, 1.9793e-04,
        3.4319e-04, 1.5965e-03, 1.1854e-04, 6.4594e-04, 9.1320e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,933][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0566, 0.4768, 0.0378, 0.0417, 0.1549, 0.0198, 0.0105, 0.0984, 0.0170,
        0.0215, 0.0652], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:11,934][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([1.4411e-04, 9.5661e-01, 4.2174e-03, 1.3707e-03, 1.6261e-02, 2.1534e-03,
        3.9255e-03, 2.4757e-03, 3.3723e-04, 1.7762e-04, 3.4796e-03, 8.8518e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,935][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.8465e-06, 9.8447e-01, 9.9757e-04, 3.5933e-04, 3.3134e-03, 2.3023e-03,
        1.5399e-03, 2.4307e-03, 1.2254e-04, 1.1080e-04, 8.3550e-04, 3.5116e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,936][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0265, 0.2828, 0.0431, 0.0502, 0.1050, 0.1204, 0.0338, 0.0676, 0.0266,
        0.0505, 0.1147, 0.0789], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,938][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2384, 0.0988, 0.1141, 0.0551, 0.2589, 0.0432, 0.0284, 0.0497, 0.0194,
        0.0152, 0.0481, 0.0305], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,940][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4224, 0.2383, 0.0767, 0.0246, 0.0918, 0.0426, 0.0177, 0.0095, 0.0180,
        0.0090, 0.0287, 0.0208], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,943][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([6.9690e-09, 1.0000e+00, 8.9036e-10, 9.1036e-11, 5.7241e-08, 8.6889e-11,
        3.3720e-10, 8.8251e-09, 3.3612e-12, 1.2393e-12, 2.2908e-09, 2.5626e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,945][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.5522e-04, 9.5674e-01, 4.0564e-03, 1.3612e-03, 1.4071e-02, 4.5200e-03,
        2.3235e-03, 4.3410e-03, 5.7702e-04, 7.5104e-04, 5.4477e-03, 5.5542e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,947][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.6064, 0.0058, 0.0228, 0.0526, 0.0272, 0.0340, 0.0237, 0.0125, 0.0785,
        0.0556, 0.0517, 0.0294], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,947][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3955, 0.1390, 0.0342, 0.0877, 0.0884, 0.0252, 0.0173, 0.0260, 0.0254,
        0.0520, 0.0733, 0.0360], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,948][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([7.5543e-12, 1.0000e+00, 8.9219e-12, 9.6602e-13, 8.3677e-10, 3.8040e-13,
        1.3013e-12, 4.5625e-10, 1.3553e-14, 6.5566e-15, 7.7806e-11, 3.8595e-11],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,949][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([2.6880e-02, 9.2224e-01, 5.5609e-04, 1.3809e-02, 1.2865e-02, 2.2170e-04,
        4.1821e-04, 2.4852e-03, 1.5598e-04, 1.1102e-03, 1.6709e-02, 2.5492e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,951][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3435, 0.2103, 0.0258, 0.0486, 0.1317, 0.0125, 0.0089, 0.0853, 0.0298,
        0.0294, 0.0590, 0.0153], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:11,953][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([1.3150e-05, 9.8491e-01, 1.2172e-03, 3.0153e-04, 5.5221e-03, 5.9735e-04,
        1.2995e-03, 1.1984e-03, 6.4138e-05, 6.3881e-05, 1.2496e-03, 3.3589e-03,
        2.0438e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,955][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([1.8388e-06, 9.8850e-01, 6.0826e-04, 2.1234e-04, 2.1315e-03, 1.2860e-03,
        9.6836e-04, 1.9487e-03, 6.2653e-05, 8.0807e-05, 7.2274e-04, 3.1915e-03,
        2.8099e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,959][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([0.0041, 0.4863, 0.0439, 0.0265, 0.0966, 0.0678, 0.0252, 0.0422, 0.0151,
        0.0201, 0.0732, 0.0794, 0.0196], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,960][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([0.0382, 0.4466, 0.0830, 0.0464, 0.1768, 0.0287, 0.0276, 0.0440, 0.0091,
        0.0123, 0.0297, 0.0350, 0.0225], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,961][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([0.0620, 0.5730, 0.0643, 0.0200, 0.1129, 0.0315, 0.0247, 0.0219, 0.0112,
        0.0078, 0.0268, 0.0268, 0.0171], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,962][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([1.2697e-09, 1.0000e+00, 1.8664e-09, 1.0879e-10, 2.1469e-07, 1.1455e-10,
        9.6004e-10, 4.6920e-08, 1.7850e-12, 1.8903e-12, 2.2081e-09, 3.6236e-09,
        4.3686e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,963][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([3.5382e-05, 9.7294e-01, 2.5753e-03, 6.9915e-04, 7.6385e-03, 2.6984e-03,
        1.3835e-03, 2.7941e-03, 2.3351e-04, 3.6299e-04, 3.0133e-03, 4.5810e-03,
        1.0431e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,966][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.2336, 0.0421, 0.0347, 0.0983, 0.0663, 0.0362, 0.0372, 0.0306, 0.0681,
        0.0924, 0.1178, 0.0644, 0.0784], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,969][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([0.1134, 0.3296, 0.0498, 0.0847, 0.0962, 0.0270, 0.0233, 0.0333, 0.0269,
        0.0548, 0.0779, 0.0657, 0.0174], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,971][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([9.5852e-12, 1.0000e+00, 1.1473e-10, 5.5684e-12, 1.4128e-08, 1.8825e-12,
        2.5439e-11, 9.5058e-09, 2.7284e-14, 4.1921e-14, 2.2402e-10, 1.8810e-10,
        4.2511e-11], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,973][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([5.5631e-03, 9.5611e-01, 5.1002e-04, 7.2691e-03, 9.1969e-03, 1.6400e-04,
        3.4053e-04, 2.2156e-03, 9.7686e-05, 6.7998e-04, 1.4483e-02, 2.9853e-03,
        3.8427e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,974][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([0.0102, 0.6629, 0.0272, 0.0235, 0.0962, 0.0142, 0.0100, 0.0506, 0.0082,
        0.0100, 0.0436, 0.0244, 0.0191], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:11,975][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.5102e-04, 9.3873e-01, 5.3886e-03, 1.9228e-03, 1.6915e-02, 2.9268e-03,
        3.8001e-03, 2.2642e-03, 4.3775e-04, 2.6464e-04, 5.2208e-03, 9.1565e-03,
        7.4392e-04, 1.1975e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,976][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.0262e-05, 9.7236e-01, 1.5063e-03, 6.6445e-04, 4.8551e-03, 2.6712e-03,
        1.7896e-03, 3.0320e-03, 2.0443e-04, 2.0603e-04, 1.5462e-03, 5.2540e-03,
        5.7498e-04, 5.3246e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,978][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0319, 0.1434, 0.0423, 0.0511, 0.0854, 0.1089, 0.0284, 0.0498, 0.0283,
        0.0529, 0.1106, 0.0672, 0.0292, 0.1707], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,980][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.2763, 0.1187, 0.0973, 0.0682, 0.1940, 0.0325, 0.0210, 0.0326, 0.0176,
        0.0153, 0.0446, 0.0222, 0.0170, 0.0427], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,984][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.5468, 0.1390, 0.0513, 0.0242, 0.0627, 0.0276, 0.0107, 0.0059, 0.0147,
        0.0085, 0.0243, 0.0152, 0.0134, 0.0557], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,986][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.6314e-07, 1.0000e+00, 3.9179e-09, 9.5349e-10, 2.2320e-07, 1.6068e-10,
        8.2785e-10, 1.7223e-08, 1.5872e-11, 8.3776e-12, 5.0897e-09, 4.7254e-09,
        1.3836e-09, 4.1243e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,987][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([3.4869e-04, 9.4867e-01, 3.8496e-03, 1.4538e-03, 1.2531e-02, 4.4844e-03,
        1.8173e-03, 3.4087e-03, 5.9446e-04, 7.6386e-04, 5.3425e-03, 4.8235e-03,
        1.5421e-03, 1.0366e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,988][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.6129, 0.0089, 0.0191, 0.0589, 0.0203, 0.0278, 0.0169, 0.0078, 0.0603,
        0.0521, 0.0373, 0.0196, 0.0202, 0.0377], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,989][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.4497, 0.0657, 0.0290, 0.0662, 0.0671, 0.0213, 0.0146, 0.0239, 0.0274,
        0.0505, 0.0719, 0.0355, 0.0161, 0.0612], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,990][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.2112e-10, 1.0000e+00, 4.2219e-11, 5.6731e-12, 2.5967e-09, 9.5853e-13,
        3.8079e-12, 6.5208e-10, 7.4320e-14, 3.1483e-14, 1.6441e-10, 1.0956e-10,
        2.0326e-11, 1.7915e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,992][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([3.7032e-02, 9.0778e-01, 5.4027e-04, 1.4830e-02, 1.2101e-02, 2.1393e-04,
        3.0595e-04, 1.9464e-03, 1.5950e-04, 1.1947e-03, 2.0205e-02, 2.4007e-03,
        3.8174e-04, 9.0588e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,996][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.3573, 0.1898, 0.0260, 0.0552, 0.1097, 0.0136, 0.0087, 0.0547, 0.0333,
        0.0345, 0.0416, 0.0135, 0.0310, 0.0310], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:11,999][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:12,001][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13476],
        [ 1324],
        [  216],
        [  509],
        [  204],
        [    1],
        [    6],
        [   12],
        [   18],
        [  182],
        [   15],
        [    1],
        [   70],
        [    1]], device='cuda:0')
[2024-07-24 10:30:12,003][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10788],
        [  749],
        [    6],
        [   12],
        [    4],
        [    1],
        [    1],
        [    2],
        [    2],
        [   18],
        [    1],
        [    1],
        [   11],
        [    1]], device='cuda:0')
[2024-07-24 10:30:12,004][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 3416],
        [50255],
        [50255],
        [50255],
        [50253],
        [50249],
        [50252],
        [50250],
        [50249],
        [50249],
        [50252],
        [50220],
        [50251],
        [48376]], device='cuda:0')
[2024-07-24 10:30:12,005][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[23892],
        [49972],
        [49970],
        [49966],
        [49965],
        [49766],
        [49773],
        [49620],
        [49726],
        [49717],
        [49719],
        [48069],
        [49633],
        [39040]], device='cuda:0')
[2024-07-24 10:30:12,008][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[23519],
        [50246],
        [50256],
        [50256],
        [50256],
        [42363],
        [43930],
        [46039],
        [46840],
        [48846],
        [45292],
        [38756],
        [47367],
        [33264]], device='cuda:0')
[2024-07-24 10:30:12,010][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 5360],
        [25508],
        [39176],
        [33675],
        [29817],
        [23932],
        [24070],
        [24947],
        [19548],
        [23771],
        [21020],
        [15312],
        [22193],
        [15547]], device='cuda:0')
[2024-07-24 10:30:12,013][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17288],
        [ 9812],
        [ 8998],
        [ 8742],
        [ 8595],
        [ 6915],
        [ 7965],
        [ 8386],
        [ 5529],
        [ 6954],
        [ 5995],
        [ 4689],
        [ 6727],
        [ 3469]], device='cuda:0')
[2024-07-24 10:30:12,016][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[14392],
        [28686],
        [28686],
        [28686],
        [28686],
        [28686],
        [28686],
        [28686],
        [28686],
        [28686],
        [28686],
        [28686],
        [28686],
        [28686]], device='cuda:0')
[2024-07-24 10:30:12,017][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 7746],
        [50215],
        [50209],
        [50211],
        [50208],
        [50154],
        [50181],
        [50019],
        [50140],
        [50155],
        [50185],
        [49553],
        [50179],
        [45014]], device='cuda:0')
[2024-07-24 10:30:12,018][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[49285],
        [    1],
        [    3],
        [   21],
        [   76],
        [  390],
        [  848],
        [ 1240],
        [ 2253],
        [ 3075],
        [ 3335],
        [ 3938],
        [ 3665],
        [ 4335]], device='cuda:0')
[2024-07-24 10:30:12,020][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[32383],
        [10662],
        [10613],
        [14967],
        [17214],
        [12167],
        [13055],
        [13432],
        [14025],
        [14465],
        [15104],
        [14730],
        [14638],
        [14147]], device='cuda:0')
[2024-07-24 10:30:12,022][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[31347],
        [32419],
        [48912],
        [48896],
        [49085],
        [48860],
        [48843],
        [48854],
        [48823],
        [48770],
        [48951],
        [49064],
        [48302],
        [43676]], device='cuda:0')
[2024-07-24 10:30:12,025][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[24793],
        [    7],
        [   29],
        [ 6936],
        [ 7361],
        [   16],
        [   61],
        [ 2202],
        [  433],
        [ 7255],
        [ 5467],
        [ 1242],
        [ 4599],
        [   46]], device='cuda:0')
[2024-07-24 10:30:12,028][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[23602],
        [39991],
        [39896],
        [39870],
        [39936],
        [39488],
        [39619],
        [39337],
        [38466],
        [38737],
        [37707],
        [35159],
        [39086],
        [35691]], device='cuda:0')
[2024-07-24 10:30:12,030][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[31871],
        [ 4399],
        [ 5013],
        [ 6421],
        [ 8264],
        [ 1114],
        [ 6072],
        [ 3934],
        [ 2751],
        [ 7660],
        [ 3901],
        [ 5998],
        [ 6262],
        [ 1163]], device='cuda:0')
[2024-07-24 10:30:12,032][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[39109],
        [32870],
        [32858],
        [32835],
        [32835],
        [32829],
        [32839],
        [32833],
        [32811],
        [32799],
        [32843],
        [32797],
        [32840],
        [32735]], device='cuda:0')
[2024-07-24 10:30:12,033][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[43100],
        [24531],
        [24529],
        [24531],
        [24616],
        [24597],
        [24598],
        [24599],
        [24628],
        [24671],
        [24615],
        [24665],
        [24640],
        [24732]], device='cuda:0')
[2024-07-24 10:30:12,034][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[44682],
        [ 8291],
        [ 7672],
        [ 7508],
        [ 7452],
        [ 8083],
        [ 7528],
        [ 7202],
        [ 6923],
        [ 6890],
        [ 5291],
        [ 5058],
        [ 6021],
        [ 5875]], device='cuda:0')
[2024-07-24 10:30:12,037][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[18454],
        [15412],
        [15632],
        [15968],
        [17466],
        [17220],
        [17103],
        [15928],
        [16119],
        [16392],
        [17165],
        [18886],
        [15573],
        [18203]], device='cuda:0')
[2024-07-24 10:30:12,040][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[18712],
        [39239],
        [48867],
        [48949],
        [48905],
        [48711],
        [48828],
        [48882],
        [48363],
        [48740],
        [48358],
        [47512],
        [48588],
        [44675]], device='cuda:0')
[2024-07-24 10:30:12,042][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[19606],
        [18653],
        [18652],
        [18652],
        [18652],
        [18652],
        [18652],
        [18652],
        [18652],
        [18652],
        [18652],
        [18652],
        [18652],
        [18652]], device='cuda:0')
[2024-07-24 10:30:12,045][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[30615],
        [11999],
        [11984],
        [11951],
        [11987],
        [12019],
        [12025],
        [12031],
        [12031],
        [12054],
        [12033],
        [12050],
        [12043],
        [12106]], device='cuda:0')
[2024-07-24 10:30:12,046][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[16603],
        [16996],
        [31848],
        [30611],
        [23733],
        [19905],
        [22475],
        [24376],
        [28089],
        [28818],
        [28299],
        [24125],
        [29530],
        [23917]], device='cuda:0')
[2024-07-24 10:30:12,047][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[22276],
        [21744],
        [21547],
        [20975],
        [18398],
        [16396],
        [15789],
        [16761],
        [16395],
        [17643],
        [16842],
        [15325],
        [16718],
        [14750]], device='cuda:0')
[2024-07-24 10:30:12,049][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[37843],
        [38431],
        [38431],
        [38431],
        [38431],
        [38431],
        [38431],
        [38431],
        [38431],
        [38431],
        [38431],
        [38431],
        [38431],
        [38431]], device='cuda:0')
[2024-07-24 10:30:12,052][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[41560],
        [26197],
        [26088],
        [26205],
        [26043],
        [26090],
        [26051],
        [26043],
        [26000],
        [25863],
        [25919],
        [25820],
        [25803],
        [25789]], device='cuda:0')
[2024-07-24 10:30:12,054][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[14089],
        [29090],
        [29364],
        [28969],
        [27838],
        [27477],
        [28056],
        [27481],
        [26920],
        [27189],
        [25212],
        [21632],
        [26730],
        [21901]], device='cuda:0')
[2024-07-24 10:30:12,057][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 5092],
        [17642],
        [ 8849],
        [ 9006],
        [10576],
        [11904],
        [11270],
        [11123],
        [11055],
        [10309],
        [11543],
        [14574],
        [11008],
        [16253]], device='cuda:0')
[2024-07-24 10:30:12,060][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[10289],
        [21218],
        [15133],
        [12155],
        [15716],
        [17063],
        [13276],
        [12838],
        [13266],
        [ 9429],
        [13536],
        [14209],
        [12392],
        [19822]], device='cuda:0')
[2024-07-24 10:30:12,061][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[28888],
        [28888],
        [28888],
        [28888],
        [28888],
        [28888],
        [28888],
        [28888],
        [28888],
        [28888],
        [28888],
        [28888],
        [28888],
        [28888]], device='cuda:0')
[2024-07-24 10:30:12,183][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:12,184][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,184][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,185][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,186][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,188][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,191][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,194][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,196][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,197][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,197][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,198][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,199][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,202][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Rebecca] are: tensor([0.1762, 0.8238], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,204][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Rebecca] are: tensor([9.9920e-01, 8.0444e-04], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,207][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Rebecca] are: tensor([0.0307, 0.9693], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,209][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Rebecca] are: tensor([0.6331, 0.3669], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,209][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Rebecca] are: tensor([3.1536e-04, 9.9968e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,210][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Rebecca] are: tensor([0.4887, 0.5113], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,211][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Rebecca] are: tensor([0.0015, 0.9985], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,212][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Rebecca] are: tensor([0.8183, 0.1817], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,214][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Rebecca] are: tensor([0.0063, 0.9937], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,215][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Rebecca] are: tensor([9.9921e-01, 7.8559e-04], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,217][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Rebecca] are: tensor([1.0000e+00, 2.8311e-06], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,221][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Rebecca] are: tensor([0.6290, 0.3710], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,222][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.5093, 0.4660, 0.0247], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,223][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.9276, 0.0654, 0.0070], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,224][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1141, 0.7883, 0.0977], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,224][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.6957e-02, 9.8257e-01, 4.7328e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,226][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([2.3400e-05, 9.9779e-01, 2.1819e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,228][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0299, 0.9336, 0.0365], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,230][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([5.2852e-04, 9.9932e-01, 1.5169e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,234][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3057, 0.5396, 0.1547], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,235][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0444, 0.5700, 0.3856], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,236][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.9861, 0.0051, 0.0088], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,237][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9751, 0.0157, 0.0092], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,237][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3721, 0.0503, 0.5776], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,239][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.8145, 0.1282, 0.0270, 0.0302], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,242][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([0.8469, 0.0703, 0.0101, 0.0728], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,246][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0230, 0.7921, 0.0506, 0.1342], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,248][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([0.0072, 0.9894, 0.0010, 0.0024], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,249][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([2.2689e-05, 9.9665e-01, 2.8868e-03, 4.4507e-04], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,249][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0455, 0.8769, 0.0429, 0.0347], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,250][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([2.5900e-03, 9.9501e-01, 4.2065e-04, 1.9798e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,252][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.3610, 0.2359, 0.2226, 0.1805], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,253][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([8.0351e-04, 1.7694e-02, 8.4004e-01, 1.4146e-01], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,256][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.5297, 0.1082, 0.0878, 0.2743], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,260][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.9154, 0.0451, 0.0156, 0.0239], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,261][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.3092, 0.0255, 0.3962, 0.2691], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,262][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ went] are: tensor([0.7892, 0.1674, 0.0063, 0.0064, 0.0306], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,263][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ went] are: tensor([0.9258, 0.0246, 0.0037, 0.0350, 0.0109], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,264][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ went] are: tensor([0.0729, 0.3945, 0.0348, 0.1597, 0.3380], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,266][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ went] are: tensor([5.2507e-02, 9.3068e-01, 8.3054e-04, 3.5147e-03, 1.2466e-02],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,267][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ went] are: tensor([2.2427e-05, 9.8927e-01, 1.0252e-03, 2.1864e-04, 9.4658e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,271][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ went] are: tensor([0.1080, 0.4463, 0.0237, 0.0239, 0.3981], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,273][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ went] are: tensor([5.3023e-04, 9.9788e-01, 4.1574e-05, 2.0829e-04, 1.3381e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,274][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ went] are: tensor([0.2659, 0.2878, 0.0933, 0.0919, 0.2610], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,275][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ went] are: tensor([0.0037, 0.1484, 0.3165, 0.2230, 0.3084], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,276][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ went] are: tensor([0.9557, 0.0049, 0.0038, 0.0193, 0.0163], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,277][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ went] are: tensor([9.9560e-01, 2.0621e-03, 6.5923e-04, 1.0170e-03, 6.6125e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,280][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ went] are: tensor([0.1001, 0.0189, 0.5218, 0.3058, 0.0533], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,284][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.6389, 0.2708, 0.0086, 0.0076, 0.0471, 0.0270], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,286][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.6430e-01, 8.6282e-03, 1.1381e-03, 2.1890e-02, 3.8652e-03, 1.8298e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,287][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1481, 0.3679, 0.0193, 0.1159, 0.2838, 0.0651], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,287][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.9503e-02, 9.4763e-01, 3.7383e-04, 3.0346e-03, 9.4417e-03, 1.9763e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,288][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([5.8079e-06, 9.9008e-01, 7.5194e-04, 1.1524e-04, 4.9569e-03, 4.0911e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,289][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2995, 0.4482, 0.0158, 0.0202, 0.2072, 0.0092], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,290][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([1.4193e-04, 9.9945e-01, 7.6752e-06, 8.6098e-05, 3.0782e-04, 5.8690e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,292][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.3535, 0.3938, 0.0536, 0.0786, 0.1074, 0.0131], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,293][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([4.4167e-06, 1.0616e-04, 7.4428e-01, 2.6031e-02, 2.2917e-01, 4.1624e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,296][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.9218e-01, 9.4309e-04, 4.5065e-04, 4.7700e-03, 1.6328e-03, 2.8387e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,298][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.9829e-01, 3.5493e-04, 2.9056e-04, 7.5685e-04, 2.8069e-04, 2.5285e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,300][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1966, 0.0143, 0.3410, 0.2456, 0.0397, 0.1628], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,301][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.6103, 0.2772, 0.0128, 0.0087, 0.0566, 0.0253, 0.0091],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,302][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([9.2980e-01, 2.5137e-02, 2.2699e-03, 3.4115e-02, 8.2898e-03, 2.3032e-04,
        1.5976e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,302][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1036, 0.3934, 0.0204, 0.1092, 0.2972, 0.0426, 0.0335],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,304][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([2.6146e-02, 9.6559e-01, 2.4747e-04, 1.8749e-03, 5.9753e-03, 1.6557e-05,
        1.5213e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,306][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([4.5236e-06, 9.9037e-01, 6.9015e-04, 8.5113e-05, 5.8448e-03, 2.1933e-03,
        8.1217e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,309][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0742, 0.6026, 0.0220, 0.0186, 0.2675, 0.0104, 0.0048],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,311][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([1.6492e-04, 9.9886e-01, 2.1339e-05, 1.5775e-04, 7.7254e-04, 6.5535e-06,
        1.4885e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,313][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1667, 0.3396, 0.1044, 0.1078, 0.2425, 0.0221, 0.0169],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,314][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([6.6801e-06, 4.8373e-04, 6.6904e-01, 2.3054e-02, 3.0440e-01, 8.8523e-04,
        2.1271e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,314][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([9.7467e-01, 2.3005e-03, 1.5913e-03, 1.3488e-02, 7.7114e-03, 5.6101e-05,
        1.7885e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,315][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([9.9025e-01, 3.6404e-03, 2.3516e-03, 1.6898e-03, 1.8691e-03, 1.6594e-04,
        3.5265e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,317][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1510, 0.0128, 0.2616, 0.1801, 0.0366, 0.1223, 0.2356],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,320][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ station] are: tensor([0.1419, 0.7552, 0.0124, 0.0042, 0.0686, 0.0115, 0.0041, 0.0022],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,322][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ station] are: tensor([9.5396e-01, 2.0671e-02, 1.8978e-03, 1.7292e-02, 5.8088e-03, 1.0738e-04,
        7.1291e-05, 1.8867e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,326][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ station] are: tensor([0.1633, 0.2872, 0.0236, 0.1109, 0.2295, 0.0457, 0.0260, 0.1138],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,326][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ station] are: tensor([2.4012e-01, 7.4073e-01, 3.6163e-04, 2.9632e-03, 1.3021e-02, 1.3226e-05,
        1.2754e-04, 2.6672e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,327][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ station] are: tensor([4.0618e-06, 9.9459e-01, 4.8328e-04, 5.6888e-05, 3.4260e-03, 9.1149e-04,
        3.3661e-04, 1.8785e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,328][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ station] are: tensor([0.0459, 0.7418, 0.0120, 0.0131, 0.1724, 0.0045, 0.0017, 0.0085],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,329][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ station] are: tensor([5.6815e-05, 9.9934e-01, 1.2649e-05, 8.4092e-05, 4.7477e-04, 6.8598e-06,
        1.2881e-05, 1.1969e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,331][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ station] are: tensor([0.0830, 0.6597, 0.0542, 0.0446, 0.1182, 0.0076, 0.0058, 0.0269],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,333][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ station] are: tensor([5.5050e-08, 3.2869e-05, 6.7992e-01, 4.6505e-03, 3.1512e-01, 4.2311e-05,
        2.3008e-04, 9.7053e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,335][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ station] are: tensor([9.8203e-01, 1.9428e-03, 1.2202e-03, 9.9493e-03, 4.3639e-03, 3.0059e-05,
        7.6892e-05, 3.8802e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,337][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ station] are: tensor([9.8779e-01, 7.0564e-03, 1.7343e-03, 1.3226e-03, 1.9258e-03, 1.3508e-04,
        3.0608e-05, 1.0241e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,339][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ station] are: tensor([0.1018, 0.0045, 0.2822, 0.2230, 0.0173, 0.1224, 0.2148, 0.0341],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,340][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3490, 0.4239, 0.0218, 0.0229, 0.0851, 0.0309, 0.0261, 0.0263, 0.0141],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,341][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([8.8062e-01, 3.2233e-02, 5.0716e-03, 6.5037e-02, 1.3699e-02, 3.3282e-04,
        3.1635e-04, 1.1668e-03, 1.5182e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,342][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1324, 0.1655, 0.0235, 0.1405, 0.2296, 0.0372, 0.0373, 0.1440, 0.0901],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,343][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([1.7807e-01, 7.8513e-01, 6.5128e-04, 1.0193e-02, 1.5377e-02, 5.3910e-05,
        6.8981e-04, 9.3820e-03, 4.5851e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,345][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([3.5702e-06, 9.8485e-01, 1.1480e-03, 1.5315e-04, 6.6414e-03, 4.0303e-03,
        2.0061e-03, 1.0934e-03, 7.7920e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,348][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0129, 0.7104, 0.0131, 0.0125, 0.1965, 0.0107, 0.0061, 0.0354, 0.0024],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,350][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([3.5004e-04, 9.9549e-01, 1.0867e-04, 8.7583e-04, 2.8256e-03, 5.4624e-05,
        1.3782e-04, 1.2397e-04, 3.2816e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,352][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1246, 0.2446, 0.1090, 0.0954, 0.1730, 0.0253, 0.0252, 0.1875, 0.0154],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,353][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0044, 0.0061, 0.3504, 0.2285, 0.1916, 0.0109, 0.0225, 0.0068, 0.1789],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,354][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([9.1695e-01, 7.4659e-03, 4.4740e-03, 4.6277e-02, 1.9594e-02, 9.8284e-05,
        3.9504e-04, 2.7382e-03, 2.0068e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,355][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([8.5819e-01, 5.0092e-02, 1.7879e-02, 3.4688e-02, 2.5793e-02, 4.6211e-03,
        2.3425e-03, 7.1740e-04, 5.6739e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,357][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0734, 0.0029, 0.0556, 0.0944, 0.0123, 0.0210, 0.0315, 0.0107, 0.6983],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,359][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Amy] are: tensor([0.3365, 0.3242, 0.0388, 0.0233, 0.1578, 0.0341, 0.0329, 0.0272, 0.0149,
        0.0103], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,362][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Amy] are: tensor([8.2211e-01, 7.9700e-02, 6.9171e-03, 5.9179e-02, 2.2575e-02, 4.3342e-04,
        4.1645e-04, 2.1954e-03, 1.2928e-03, 5.1852e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,365][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Amy] are: tensor([0.0404, 0.3967, 0.0188, 0.0644, 0.1302, 0.0410, 0.0335, 0.1638, 0.0548,
        0.0565], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,366][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Amy] are: tensor([5.4751e-02, 9.1172e-01, 7.5895e-04, 4.9842e-03, 1.4206e-02, 4.8721e-05,
        6.3264e-04, 1.0741e-02, 2.4538e-04, 1.9096e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,367][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Amy] are: tensor([7.8110e-06, 9.8109e-01, 2.1947e-03, 2.3837e-04, 9.7725e-03, 3.7231e-03,
        1.8704e-03, 9.3249e-04, 8.8947e-05, 8.0341e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,368][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Amy] are: tensor([0.0254, 0.5613, 0.0196, 0.0111, 0.2995, 0.0194, 0.0088, 0.0491, 0.0032,
        0.0027], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,369][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Amy] are: tensor([3.2206e-04, 9.9611e-01, 7.1520e-05, 5.5719e-04, 2.5644e-03, 5.0851e-05,
        9.9701e-05, 1.4376e-04, 2.0023e-05, 6.0039e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,372][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Amy] are: tensor([0.0879, 0.3092, 0.1107, 0.0646, 0.2183, 0.0166, 0.0141, 0.1593, 0.0084,
        0.0109], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,374][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Amy] are: tensor([1.6499e-05, 1.3621e-04, 6.9536e-01, 2.4529e-02, 2.4785e-01, 6.2131e-04,
        2.7762e-03, 5.1144e-04, 2.6204e-02, 1.9947e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,378][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Amy] are: tensor([0.6347, 0.0625, 0.0290, 0.1193, 0.1055, 0.0013, 0.0037, 0.0176, 0.0101,
        0.0163], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,379][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Amy] are: tensor([0.7810, 0.1450, 0.0155, 0.0147, 0.0271, 0.0067, 0.0031, 0.0010, 0.0038,
        0.0023], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,380][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Amy] are: tensor([0.2243, 0.0012, 0.0520, 0.0564, 0.0139, 0.0124, 0.0171, 0.0206, 0.5558,
        0.0464], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,381][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.6076, 0.2417, 0.0104, 0.0104, 0.0578, 0.0122, 0.0055, 0.0033, 0.0052,
        0.0029, 0.0429], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,382][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([8.7171e-01, 5.1052e-02, 3.6360e-03, 5.1665e-02, 1.2089e-02, 3.7230e-04,
        2.0677e-04, 6.4487e-04, 1.1602e-03, 4.3493e-03, 3.1123e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,384][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0580, 0.2228, 0.0169, 0.0768, 0.2146, 0.0434, 0.0317, 0.1421, 0.0856,
        0.0478, 0.0604], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,385][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([3.6567e-01, 5.9712e-01, 6.9281e-04, 8.6347e-03, 1.5083e-02, 3.6132e-05,
        4.3179e-04, 4.6342e-03, 3.6910e-04, 3.0083e-03, 4.3235e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,388][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([3.9073e-06, 9.9119e-01, 4.2528e-04, 8.9453e-05, 4.1689e-03, 1.3117e-03,
        5.1987e-04, 2.7954e-04, 2.8817e-05, 3.4842e-05, 1.9505e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,392][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0834, 0.6662, 0.0119, 0.0151, 0.1966, 0.0053, 0.0020, 0.0103, 0.0016,
        0.0019, 0.0057], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,392][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.7632e-04, 9.9868e-01, 1.6126e-05, 2.0990e-04, 7.6637e-04, 5.2386e-06,
        1.1132e-05, 1.2674e-05, 4.6048e-06, 1.0558e-05, 1.0870e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,393][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1147, 0.4471, 0.0913, 0.0647, 0.1341, 0.0159, 0.0105, 0.0587, 0.0120,
        0.0070, 0.0439], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,394][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([1.6011e-07, 3.7751e-05, 7.5850e-01, 8.4286e-03, 2.2406e-01, 1.1864e-04,
        4.8815e-04, 1.7921e-05, 8.0464e-03, 3.0136e-04, 5.0964e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,395][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([9.1281e-01, 1.1643e-02, 2.7978e-03, 3.6621e-02, 1.8180e-02, 1.6072e-04,
        4.0212e-04, 3.1418e-03, 2.3096e-03, 9.4700e-03, 2.4668e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,396][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([9.9693e-01, 9.1250e-04, 8.1086e-04, 6.5000e-04, 5.4227e-04, 3.6967e-05,
        1.1110e-05, 6.1976e-07, 9.0472e-05, 1.2396e-05, 4.2176e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,399][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0761, 0.0009, 0.0768, 0.1262, 0.0107, 0.0098, 0.0264, 0.0076, 0.5293,
        0.0759, 0.0605], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,403][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.6316, 0.1930, 0.0134, 0.0072, 0.0522, 0.0275, 0.0093, 0.0042, 0.0063,
        0.0030, 0.0482, 0.0041], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,405][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([9.8010e-01, 4.7045e-03, 6.9578e-04, 1.0565e-02, 2.3900e-03, 6.4319e-05,
        3.3750e-05, 9.6675e-05, 2.5454e-04, 6.2775e-04, 4.3207e-04, 3.2593e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,406][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2564, 0.1105, 0.0123, 0.0678, 0.1565, 0.0337, 0.0222, 0.0917, 0.0750,
        0.0442, 0.0698, 0.0599], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,407][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([8.6393e-01, 1.2179e-01, 2.0929e-04, 4.6120e-03, 5.7971e-03, 4.6532e-06,
        6.2411e-05, 8.5278e-04, 9.5820e-05, 9.3742e-04, 1.4726e-03, 2.3390e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,408][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([5.1606e-06, 9.9250e-01, 3.6430e-04, 5.5674e-05, 2.5209e-03, 1.1428e-03,
        4.6934e-04, 1.7362e-04, 1.9411e-05, 1.7083e-05, 8.6085e-04, 1.8727e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,409][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1706, 0.5821, 0.0190, 0.0157, 0.1808, 0.0071, 0.0028, 0.0118, 0.0020,
        0.0014, 0.0045, 0.0022], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,410][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([2.7032e-04, 9.9893e-01, 1.0903e-05, 1.1860e-04, 5.7363e-04, 4.6110e-06,
        9.1227e-06, 8.3521e-06, 2.6272e-06, 4.6263e-06, 5.2949e-05, 1.2332e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,414][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3949, 0.2709, 0.0709, 0.0641, 0.0948, 0.0114, 0.0069, 0.0466, 0.0101,
        0.0049, 0.0202, 0.0041], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,416][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.7575e-06, 1.0106e-05, 7.8258e-01, 1.5805e-02, 1.7498e-01, 1.9149e-04,
        5.6080e-04, 2.2442e-05, 2.4914e-02, 7.8939e-04, 1.1455e-05, 1.3168e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,418][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([9.9357e-01, 2.5251e-04, 2.5940e-04, 3.5687e-03, 1.3549e-03, 7.6332e-06,
        1.9598e-05, 1.4617e-04, 1.9112e-04, 5.3360e-04, 8.8448e-05, 8.8284e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,419][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.9918e-01, 1.9022e-04, 2.1156e-04, 2.6720e-04, 1.1222e-04, 9.1311e-06,
        1.1697e-06, 4.8896e-08, 2.4012e-05, 4.3636e-06, 8.3520e-07, 2.6112e-07],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,420][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.2132, 0.0010, 0.0652, 0.0526, 0.0071, 0.0107, 0.0193, 0.0042, 0.3689,
        0.0493, 0.0727, 0.1357], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,421][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ necklace] are: tensor([0.1627, 0.4168, 0.0398, 0.0123, 0.1704, 0.0470, 0.0280, 0.0140, 0.0106,
        0.0058, 0.0786, 0.0122, 0.0017], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,422][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ necklace] are: tensor([9.0736e-01, 4.7317e-02, 2.9526e-03, 3.0435e-02, 7.9945e-03, 1.2210e-04,
        1.0679e-04, 3.3647e-04, 4.0371e-04, 1.4737e-03, 1.0090e-03, 1.7422e-04,
        3.1912e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,425][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ necklace] are: tensor([0.0393, 0.3620, 0.0096, 0.0586, 0.1077, 0.0168, 0.0137, 0.1238, 0.0284,
        0.0430, 0.0469, 0.0585, 0.0919], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,427][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ necklace] are: tensor([6.1718e-01, 3.4898e-01, 6.6532e-04, 6.3285e-03, 1.1665e-02, 2.4872e-05,
        2.4561e-04, 3.6841e-03, 1.8737e-04, 1.9002e-03, 3.2300e-03, 1.0144e-03,
        4.8972e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,429][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ necklace] are: tensor([2.5923e-06, 9.9311e-01, 4.0751e-04, 4.9370e-05, 2.8271e-03, 5.4491e-04,
        3.6841e-04, 2.7987e-04, 9.2919e-06, 1.2130e-05, 8.1459e-04, 1.5239e-03,
        4.7615e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,432][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ necklace] are: tensor([1.7840e-02, 7.8742e-01, 1.7177e-02, 8.2284e-03, 1.4208e-01, 4.5251e-03,
        2.5077e-03, 1.2859e-02, 8.5040e-04, 5.8024e-04, 3.5582e-03, 2.1632e-03,
        2.0206e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,432][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ necklace] are: tensor([2.9807e-05, 9.9926e-01, 1.2074e-05, 5.7993e-05, 5.3981e-04, 4.7208e-06,
        9.4265e-06, 1.1860e-05, 1.1779e-06, 2.7745e-06, 4.4453e-05, 2.0819e-05,
        8.9082e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,433][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ necklace] are: tensor([0.0568, 0.5271, 0.0905, 0.0457, 0.1412, 0.0140, 0.0099, 0.0649, 0.0061,
        0.0044, 0.0257, 0.0101, 0.0036], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,434][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ necklace] are: tensor([6.0544e-09, 3.4220e-06, 7.1614e-01, 2.0912e-03, 2.7876e-01, 1.8605e-05,
        1.8332e-04, 1.0664e-05, 2.6992e-03, 5.6969e-05, 4.3190e-07, 2.6300e-05,
        1.5623e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,435][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ necklace] are: tensor([9.6531e-01, 3.7203e-03, 1.8996e-03, 1.4557e-02, 1.0764e-02, 3.8158e-05,
        1.0977e-04, 1.2198e-03, 4.8178e-04, 1.2726e-03, 3.9153e-04, 9.7881e-05,
        1.3683e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,436][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ necklace] are: tensor([9.8005e-01, 9.7806e-03, 2.7786e-03, 2.5828e-03, 4.0983e-03, 2.2314e-04,
        1.0919e-04, 1.1583e-05, 1.9923e-04, 9.6487e-05, 3.1055e-05, 3.3551e-05,
        2.0512e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,438][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ necklace] are: tensor([6.1189e-02, 3.9511e-04, 3.7273e-02, 7.1553e-02, 2.9118e-03, 4.6159e-03,
        1.0865e-02, 2.6497e-03, 6.6975e-01, 5.6260e-02, 2.3511e-02, 5.5074e-02,
        3.9470e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,441][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([4.6742e-01, 3.4743e-01, 1.9273e-02, 9.8594e-03, 6.5392e-02, 2.0303e-02,
        7.7157e-03, 3.1672e-03, 6.0281e-03, 2.8380e-03, 3.6705e-02, 3.3976e-03,
        2.6260e-04, 1.0205e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,443][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([9.7773e-01, 4.2710e-03, 7.4933e-04, 1.2758e-02, 2.2466e-03, 8.8821e-05,
        4.4020e-05, 1.1275e-04, 3.3806e-04, 8.3301e-04, 5.0718e-04, 4.1232e-05,
        1.2355e-04, 1.5803e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,446][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1178, 0.1115, 0.0110, 0.0460, 0.1095, 0.0237, 0.0141, 0.0628, 0.0495,
        0.0253, 0.0399, 0.0494, 0.0889, 0.2506], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,446][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([9.2120e-01, 6.2501e-02, 2.5692e-04, 3.9473e-03, 4.5479e-03, 5.5916e-06,
        7.3645e-05, 8.0169e-04, 1.5478e-04, 9.3114e-04, 1.3536e-03, 2.7875e-04,
        2.5546e-03, 1.3957e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,447][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([9.7021e-06, 9.8763e-01, 5.7589e-04, 9.1171e-05, 3.3821e-03, 1.2993e-03,
        4.9121e-04, 1.7281e-04, 2.6616e-05, 1.8203e-05, 1.1533e-03, 1.8668e-03,
        4.0817e-05, 3.2381e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,448][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.6878e-01, 6.1366e-01, 1.5312e-02, 1.4379e-02, 1.5187e-01, 6.0163e-03,
        1.8310e-03, 1.0631e-02, 1.9128e-03, 1.3239e-03, 3.5552e-03, 1.7080e-03,
        1.6331e-04, 8.8590e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,450][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.7295e-04, 9.9921e-01, 7.7809e-06, 9.1687e-05, 3.4958e-04, 4.3651e-06,
        5.6110e-06, 5.2731e-06, 2.1762e-06, 3.0366e-06, 3.5286e-05, 8.4075e-06,
        4.0232e-07, 4.6012e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,452][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.6067, 0.2091, 0.0350, 0.0432, 0.0519, 0.0043, 0.0023, 0.0220, 0.0039,
        0.0030, 0.0095, 0.0015, 0.0009, 0.0068], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,455][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.4543e-09, 2.1709e-07, 8.5540e-01, 1.1879e-03, 1.3971e-01, 6.5019e-06,
        4.4248e-05, 8.3393e-07, 3.6134e-03, 2.7260e-05, 8.3981e-08, 1.0667e-05,
        2.2955e-08, 4.3125e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,457][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.9665e-01, 1.2640e-04, 1.5986e-04, 2.0037e-03, 5.6285e-04, 4.3389e-06,
        7.2745e-06, 6.6194e-05, 1.2957e-04, 2.1594e-04, 4.2199e-05, 4.8961e-06,
        1.3724e-05, 1.4782e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,459][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.9898e-01, 2.1736e-04, 1.1045e-04, 5.9578e-04, 6.5989e-05, 3.8574e-06,
        4.5042e-07, 3.9960e-08, 1.8680e-05, 5.9911e-06, 6.3098e-07, 1.5745e-07,
        1.3915e-08, 3.3466e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,460][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0760, 0.0009, 0.0401, 0.0323, 0.0039, 0.0099, 0.0130, 0.0028, 0.5571,
        0.0467, 0.0496, 0.0995, 0.0069, 0.0612], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,587][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:30:12,589][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,592][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,593][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,593][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,594][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,595][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,595][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,596][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,597][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,598][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,598][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,599][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [After] are: tensor([1.], device='cuda:0') for source tokens [After]
[2024-07-24 10:30:12,600][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Rebecca] are: tensor([0.1762, 0.8238], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,600][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Rebecca] are: tensor([0.9608, 0.0392], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,601][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Rebecca] are: tensor([0.0456, 0.9544], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,602][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Rebecca] are: tensor([0.4970, 0.5030], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,602][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Rebecca] are: tensor([3.1536e-04, 9.9968e-01], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,605][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Rebecca] are: tensor([0.4887, 0.5113], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,607][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Rebecca] are: tensor([0.0015, 0.9985], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,608][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Rebecca] are: tensor([0.8183, 0.1817], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,608][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Rebecca] are: tensor([2.3246e-06, 1.0000e+00], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,609][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Rebecca] are: tensor([0.0189, 0.9811], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,610][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Rebecca] are: tensor([1.0000e+00, 3.6408e-06], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,611][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Rebecca] are: tensor([9.9972e-01, 2.7797e-04], device='cuda:0') for source tokens [After Rebecca]
[2024-07-24 10:30:12,614][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5093, 0.4660, 0.0247], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,618][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2219, 0.7737, 0.0044], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,620][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([5.0737e-04, 9.9895e-01, 5.3897e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,621][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.7312e-06, 9.9999e-01, 1.0850e-06], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,621][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([2.3400e-05, 9.9779e-01, 2.1819e-03], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,622][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0299, 0.9336, 0.0365], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,623][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([5.2852e-04, 9.9932e-01, 1.5169e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,625][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3057, 0.5396, 0.1547], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,627][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0012, 0.9972, 0.0016], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,631][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0655, 0.9261, 0.0084], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,633][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9079, 0.0586, 0.0335], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,634][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([8.7834e-02, 9.1182e-01, 3.4300e-04], device='cuda:0') for source tokens [After Rebecca and]
[2024-07-24 10:30:12,635][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.8145, 0.1282, 0.0270, 0.0302], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,636][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([0.4346, 0.5234, 0.0058, 0.0362], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,636][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([0.0040, 0.9913, 0.0021, 0.0026], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,638][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([1.9495e-05, 9.9996e-01, 1.6582e-05, 1.2710e-06], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,640][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([2.2689e-05, 9.9665e-01, 2.8868e-03, 4.4507e-04], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,642][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0455, 0.8769, 0.0429, 0.0347], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,645][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([2.5900e-03, 9.9501e-01, 4.2065e-04, 1.9798e-03], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,647][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.3610, 0.2359, 0.2226, 0.1805], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,648][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([0.0063, 0.9601, 0.0138, 0.0198], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,648][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([0.0568, 0.8882, 0.0167, 0.0384], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,649][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.7572, 0.1202, 0.0376, 0.0850], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,651][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([0.1966, 0.8008, 0.0013, 0.0013], device='cuda:0') for source tokens [After Rebecca and Amy]
[2024-07-24 10:30:12,654][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ went] are: tensor([0.7892, 0.1674, 0.0063, 0.0064, 0.0306], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,657][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ went] are: tensor([0.4035, 0.5535, 0.0027, 0.0238, 0.0165], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,660][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ went] are: tensor([7.4871e-04, 9.9565e-01, 2.4294e-04, 3.5772e-04, 3.0053e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,661][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ went] are: tensor([2.6082e-05, 9.9991e-01, 2.2055e-06, 1.0361e-07, 5.6831e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,662][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ went] are: tensor([2.2427e-05, 9.8927e-01, 1.0252e-03, 2.1864e-04, 9.4658e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,662][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ went] are: tensor([0.1080, 0.4463, 0.0237, 0.0239, 0.3981], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,663][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ went] are: tensor([5.3023e-04, 9.9788e-01, 4.1574e-05, 2.0829e-04, 1.3381e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,665][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ went] are: tensor([0.2659, 0.2878, 0.0933, 0.0919, 0.2610], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,668][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ went] are: tensor([0.0016, 0.9899, 0.0014, 0.0034, 0.0038], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,672][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ went] are: tensor([0.2206, 0.7207, 0.0043, 0.0132, 0.0412], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,674][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ went] are: tensor([0.9720, 0.0110, 0.0035, 0.0072, 0.0063], device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,674][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ went] are: tensor([5.6525e-01, 4.3165e-01, 2.4551e-04, 2.1088e-04, 2.6480e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went]
[2024-07-24 10:30:12,675][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.6389, 0.2708, 0.0086, 0.0076, 0.0471, 0.0270], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,676][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([3.3234e-01, 6.3699e-01, 1.1801e-03, 2.0321e-02, 9.0420e-03, 1.2602e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,677][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.6916e-04, 9.9840e-01, 6.3398e-05, 7.6337e-05, 1.1884e-03, 1.0451e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,680][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.1129e-06, 9.9997e-01, 8.5982e-07, 4.2380e-08, 2.9344e-05, 2.3756e-08],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,682][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([5.8079e-06, 9.9008e-01, 7.5194e-04, 1.1524e-04, 4.9569e-03, 4.0911e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,686][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2995, 0.4482, 0.0158, 0.0202, 0.2072, 0.0092], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,687][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([1.4193e-04, 9.9945e-01, 7.6752e-06, 8.6098e-05, 3.0782e-04, 5.8690e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,688][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.3535, 0.3938, 0.0536, 0.0786, 0.1074, 0.0131], device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,688][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([4.1166e-04, 9.7914e-01, 2.8504e-03, 8.9930e-03, 5.8112e-03, 2.7929e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,689][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.5982e-01, 8.2607e-01, 9.3711e-04, 4.3239e-03, 8.3425e-03, 5.0960e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,690][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.8199e-01, 3.8739e-03, 2.0909e-03, 7.3495e-03, 4.1664e-03, 5.2970e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,691][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([3.1479e-01, 6.8132e-01, 2.0103e-04, 4.1890e-04, 3.2625e-03, 1.1103e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to]
[2024-07-24 10:30:12,694][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.6103, 0.2772, 0.0128, 0.0087, 0.0566, 0.0253, 0.0091],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,696][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.4260e-01, 8.2657e-01, 1.5693e-03, 1.6927e-02, 1.2120e-02, 9.8266e-05,
        1.1692e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,699][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([4.4602e-05, 9.9849e-01, 6.9705e-05, 4.9395e-05, 1.2462e-03, 5.0325e-05,
        5.2286e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,701][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([6.7830e-08, 9.9999e-01, 1.0867e-07, 2.4371e-09, 5.8451e-06, 4.0706e-09,
        5.0775e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,701][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([4.5236e-06, 9.9037e-01, 6.9015e-04, 8.5113e-05, 5.8448e-03, 2.1933e-03,
        8.1217e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,702][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0742, 0.6026, 0.0220, 0.0186, 0.2675, 0.0104, 0.0048],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,703][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.6492e-04, 9.9886e-01, 2.1339e-05, 1.5775e-04, 7.7254e-04, 6.5535e-06,
        1.4885e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,705][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1667, 0.3396, 0.1044, 0.1078, 0.2425, 0.0221, 0.0169],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,707][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([7.0024e-04, 9.8250e-01, 2.5984e-03, 4.3058e-03, 6.9811e-03, 1.9866e-03,
        9.2881e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,709][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([1.0329e-01, 8.6328e-01, 2.3428e-03, 8.1263e-03, 2.1432e-02, 5.1283e-04,
        1.0192e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,711][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([9.0182e-01, 4.0250e-02, 1.4279e-02, 1.4822e-02, 2.5415e-02, 2.8188e-03,
        5.9692e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,714][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([4.2131e-02, 9.5597e-01, 8.5223e-05, 6.9640e-05, 1.7306e-03, 4.1192e-06,
        6.9934e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the]
[2024-07-24 10:30:12,714][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ station] are: tensor([0.1419, 0.7552, 0.0124, 0.0042, 0.0686, 0.0115, 0.0041, 0.0022],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,715][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ station] are: tensor([6.6984e-02, 9.1497e-01, 1.3122e-03, 6.1479e-03, 1.0384e-02, 4.5593e-05,
        5.0835e-05, 1.0813e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,716][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ station] are: tensor([1.4984e-05, 9.9907e-01, 3.4230e-05, 3.0561e-05, 7.7147e-04, 3.2012e-05,
        2.5002e-05, 1.8828e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,717][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ station] are: tensor([6.2301e-09, 1.0000e+00, 1.5821e-08, 1.4411e-10, 2.7125e-06, 3.2766e-10,
        5.0421e-10, 2.9363e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,719][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ station] are: tensor([4.0618e-06, 9.9459e-01, 4.8328e-04, 5.6888e-05, 3.4260e-03, 9.1149e-04,
        3.3661e-04, 1.8785e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,722][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ station] are: tensor([0.0459, 0.7418, 0.0120, 0.0131, 0.1724, 0.0045, 0.0017, 0.0085],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,724][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ station] are: tensor([5.6815e-05, 9.9934e-01, 1.2649e-05, 8.4092e-05, 4.7477e-04, 6.8598e-06,
        1.2881e-05, 1.1969e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,727][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ station] are: tensor([0.0830, 0.6597, 0.0542, 0.0446, 0.1182, 0.0076, 0.0058, 0.0269],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,728][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ station] are: tensor([2.7772e-05, 9.9209e-01, 9.6357e-04, 1.1599e-03, 4.7815e-03, 4.6685e-04,
        3.1945e-04, 1.9009e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,729][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ station] are: tensor([5.1824e-02, 9.2800e-01, 1.7370e-03, 4.9113e-03, 1.2170e-02, 3.1646e-04,
        5.5073e-04, 4.9057e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,729][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ station] are: tensor([8.2569e-01, 1.1040e-01, 1.2198e-02, 1.7637e-02, 3.1378e-02, 2.1880e-03,
        4.1852e-04, 9.6322e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,731][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ station] are: tensor([2.2098e-02, 9.7646e-01, 4.7722e-05, 2.1571e-05, 1.3682e-03, 1.2561e-06,
        1.6982e-06, 5.9181e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station]
[2024-07-24 10:30:12,733][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3490, 0.4239, 0.0218, 0.0229, 0.0851, 0.0309, 0.0261, 0.0263, 0.0141],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,736][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.4502e-01, 7.7659e-01, 5.0396e-03, 4.5538e-02, 2.4297e-02, 2.3148e-04,
        4.3989e-04, 2.1219e-03, 7.2542e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,738][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.2842e-04, 9.9484e-01, 3.3454e-04, 2.7757e-04, 3.1114e-03, 3.2101e-04,
        4.4649e-04, 4.9060e-04, 5.1913e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,740][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([4.5657e-07, 9.9986e-01, 2.2022e-06, 2.0256e-07, 7.6833e-05, 3.6289e-07,
        1.3325e-06, 5.9125e-05, 8.5623e-09], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,741][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([3.5702e-06, 9.8485e-01, 1.1480e-03, 1.5315e-04, 6.6414e-03, 4.0303e-03,
        2.0061e-03, 1.0934e-03, 7.7920e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,742][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0129, 0.7104, 0.0131, 0.0125, 0.1965, 0.0107, 0.0061, 0.0354, 0.0024],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,743][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([3.5004e-04, 9.9549e-01, 1.0867e-04, 8.7583e-04, 2.8256e-03, 5.4624e-05,
        1.3782e-04, 1.2397e-04, 3.2816e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,745][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1246, 0.2446, 0.1090, 0.0954, 0.1730, 0.0253, 0.0252, 0.1875, 0.0154],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,748][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0019, 0.9108, 0.0078, 0.0225, 0.0177, 0.0078, 0.0115, 0.0153, 0.0047],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,750][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.5232e-02, 9.3735e-01, 2.8008e-03, 9.7949e-03, 2.0067e-02, 6.7635e-04,
        1.5710e-03, 1.8251e-03, 6.8291e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,754][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5536, 0.1671, 0.0397, 0.0953, 0.0811, 0.0184, 0.0101, 0.0089, 0.0259],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,755][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([5.4512e-02, 9.3583e-01, 5.3198e-04, 7.2579e-04, 6.8353e-03, 4.8686e-05,
        1.3831e-04, 1.3635e-03, 1.7018e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station,]
[2024-07-24 10:30:12,755][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Amy] are: tensor([0.3365, 0.3242, 0.0388, 0.0233, 0.1578, 0.0341, 0.0329, 0.0272, 0.0149,
        0.0103], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,756][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Amy] are: tensor([1.1046e-01, 8.6068e-01, 2.2503e-03, 1.1496e-02, 1.3093e-02, 8.6529e-05,
        1.4883e-04, 1.1720e-03, 1.6025e-04, 4.4581e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,758][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Amy] are: tensor([1.8383e-04, 9.9604e-01, 2.0903e-04, 1.2292e-04, 2.3742e-03, 2.7974e-04,
        2.9643e-04, 4.4019e-04, 2.8669e-05, 2.6930e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,759][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Amy] are: tensor([3.4488e-08, 9.9996e-01, 6.1196e-07, 1.1368e-08, 3.1488e-05, 5.5213e-08,
        2.6160e-07, 8.1461e-06, 4.2948e-10, 2.0149e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,761][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Amy] are: tensor([7.8110e-06, 9.8109e-01, 2.1947e-03, 2.3837e-04, 9.7725e-03, 3.7231e-03,
        1.8704e-03, 9.3249e-04, 8.8947e-05, 8.0341e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,765][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Amy] are: tensor([0.0254, 0.5613, 0.0196, 0.0111, 0.2995, 0.0194, 0.0088, 0.0491, 0.0032,
        0.0027], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,767][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Amy] are: tensor([3.2206e-04, 9.9611e-01, 7.1520e-05, 5.5719e-04, 2.5644e-03, 5.0851e-05,
        9.9701e-05, 1.4376e-04, 2.0023e-05, 6.0039e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,768][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Amy] are: tensor([0.0879, 0.3092, 0.1107, 0.0646, 0.2183, 0.0166, 0.0141, 0.1593, 0.0084,
        0.0109], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,769][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Amy] are: tensor([1.6968e-04, 8.3291e-01, 1.8844e-02, 1.5938e-02, 4.4834e-02, 1.1631e-02,
        2.7021e-02, 4.3425e-02, 2.6315e-03, 2.6009e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,770][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Amy] are: tensor([2.4166e-02, 9.3346e-01, 4.3485e-03, 7.1329e-03, 2.3150e-02, 1.3134e-03,
        2.3792e-03, 2.3257e-03, 8.7571e-04, 8.5098e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,772][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Amy] are: tensor([0.4826, 0.2989, 0.0261, 0.0463, 0.0833, 0.0174, 0.0080, 0.0090, 0.0162,
        0.0121], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,774][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Amy] are: tensor([1.6326e-02, 9.8012e-01, 1.5914e-04, 1.6217e-04, 2.7156e-03, 1.0105e-05,
        2.0560e-05, 4.7446e-04, 2.3799e-06, 5.3242e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy]
[2024-07-24 10:30:12,778][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.6076, 0.2417, 0.0104, 0.0104, 0.0578, 0.0122, 0.0055, 0.0033, 0.0052,
        0.0029, 0.0429], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,781][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.5428e-01, 8.0763e-01, 1.6557e-03, 2.1031e-02, 1.3070e-02, 8.6688e-05,
        8.5862e-05, 2.6197e-04, 2.2910e-04, 5.7369e-04, 1.0953e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,781][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([6.4633e-05, 9.9783e-01, 9.4381e-05, 1.2646e-04, 1.4922e-03, 1.1499e-04,
        8.6553e-05, 6.4207e-05, 1.9228e-05, 1.5368e-05, 9.1085e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,782][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([2.2456e-06, 9.9996e-01, 7.3584e-07, 3.1819e-08, 3.3068e-05, 3.1614e-08,
        3.9477e-08, 3.7171e-07, 4.7791e-10, 7.3994e-11, 1.3458e-08],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,783][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([3.9073e-06, 9.9119e-01, 4.2528e-04, 8.9453e-05, 4.1689e-03, 1.3117e-03,
        5.1987e-04, 2.7954e-04, 2.8817e-05, 3.4842e-05, 1.9505e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,784][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0834, 0.6662, 0.0119, 0.0151, 0.1966, 0.0053, 0.0020, 0.0103, 0.0016,
        0.0019, 0.0057], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,785][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([1.7632e-04, 9.9868e-01, 1.6126e-05, 2.0990e-04, 7.6637e-04, 5.2386e-06,
        1.1132e-05, 1.2674e-05, 4.6048e-06, 1.0558e-05, 1.0870e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,788][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.1147, 0.4471, 0.0913, 0.0647, 0.1341, 0.0159, 0.0105, 0.0587, 0.0120,
        0.0070, 0.0439], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,790][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.9825e-04, 9.7704e-01, 2.4386e-03, 6.3292e-03, 5.5883e-03, 2.3444e-03,
        1.3238e-03, 5.4324e-04, 6.5829e-04, 7.3190e-04, 2.7990e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,793][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([3.7358e-02, 9.3614e-01, 1.2034e-03, 5.1371e-03, 1.3107e-02, 3.3676e-04,
        5.3834e-04, 6.1777e-04, 4.0591e-04, 7.7301e-04, 4.3797e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,794][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([9.6554e-01, 1.0244e-02, 5.5482e-03, 7.2270e-03, 7.8069e-03, 7.3116e-04,
        1.9410e-04, 5.4588e-05, 2.1165e-03, 3.3292e-04, 2.0169e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,795][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([5.0496e-01, 4.9325e-01, 9.5464e-05, 1.9279e-04, 1.4240e-03, 2.7130e-06,
        4.7708e-06, 2.3677e-05, 1.4529e-06, 1.5620e-06, 4.4913e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave]
[2024-07-24 10:30:12,796][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.6316, 0.1930, 0.0134, 0.0072, 0.0522, 0.0275, 0.0093, 0.0042, 0.0063,
        0.0030, 0.0482, 0.0041], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,797][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.4170e-01, 5.2928e-01, 1.4169e-03, 1.5375e-02, 1.0619e-02, 7.4339e-05,
        7.7392e-05, 2.0700e-04, 2.6318e-04, 3.2255e-04, 6.1980e-04, 4.7789e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,798][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([7.8435e-05, 9.9885e-01, 4.1642e-05, 3.5063e-05, 7.9603e-04, 5.0684e-05,
        3.8872e-05, 3.2011e-05, 6.8279e-06, 3.2067e-06, 3.8011e-05, 2.6603e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,800][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.1807e-06, 9.9998e-01, 2.6201e-07, 9.8943e-09, 1.3541e-05, 6.7793e-09,
        7.9133e-09, 7.4325e-08, 1.1652e-10, 1.0431e-11, 4.1799e-09, 1.3633e-09],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,803][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([5.1606e-06, 9.9250e-01, 3.6430e-04, 5.5674e-05, 2.5209e-03, 1.1428e-03,
        4.6934e-04, 1.7362e-04, 1.9411e-05, 1.7083e-05, 8.6085e-04, 1.8727e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,806][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1706, 0.5821, 0.0190, 0.0157, 0.1808, 0.0071, 0.0028, 0.0118, 0.0020,
        0.0014, 0.0045, 0.0022], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,808][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([2.7032e-04, 9.9893e-01, 1.0903e-05, 1.1860e-04, 5.7363e-04, 4.6110e-06,
        9.1227e-06, 8.3521e-06, 2.6272e-06, 4.6263e-06, 5.2949e-05, 1.2332e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,809][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.3949, 0.2709, 0.0709, 0.0641, 0.0948, 0.0114, 0.0069, 0.0466, 0.0101,
        0.0049, 0.0202, 0.0041], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,810][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([7.6194e-04, 9.0382e-01, 1.1179e-02, 2.7492e-02, 2.4143e-02, 7.9900e-03,
        4.6776e-03, 2.1501e-03, 3.5691e-03, 2.8527e-03, 8.8543e-03, 2.5067e-03],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,811][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.5339e-01, 7.1491e-01, 1.7025e-03, 6.7500e-03, 1.8109e-02, 3.0577e-04,
        4.9060e-04, 5.9909e-04, 4.3533e-04, 5.4643e-04, 2.5440e-03, 2.2172e-04],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,812][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.8983e-01, 2.2460e-03, 1.6260e-03, 3.0772e-03, 2.0456e-03, 2.3523e-04,
        3.1769e-05, 7.4330e-06, 6.9769e-04, 1.3289e-04, 5.3556e-05, 1.2251e-05],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,814][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.7410e-01, 7.2350e-01, 1.6740e-04, 2.3539e-04, 1.8819e-03, 7.1399e-06,
        9.7255e-06, 3.9740e-05, 3.4174e-06, 1.4410e-06, 4.4678e-05, 3.2842e-06],
       device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a]
[2024-07-24 10:30:12,817][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ necklace] are: tensor([0.1627, 0.4168, 0.0398, 0.0123, 0.1704, 0.0470, 0.0280, 0.0140, 0.0106,
        0.0058, 0.0786, 0.0122, 0.0017], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,820][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ necklace] are: tensor([4.6186e-02, 9.4287e-01, 7.1994e-04, 4.7070e-03, 5.0882e-03, 1.5666e-05,
        2.7369e-05, 9.0667e-05, 3.0702e-05, 7.2237e-05, 1.5464e-04, 2.4638e-05,
        9.8320e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,821][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ necklace] are: tensor([2.4852e-05, 9.9906e-01, 2.8859e-05, 2.9159e-05, 7.0746e-04, 2.6257e-05,
        2.6059e-05, 3.8492e-05, 2.2305e-06, 3.1347e-06, 2.4623e-05, 2.4395e-05,
        8.4480e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,822][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ necklace] are: tensor([6.3316e-08, 9.9997e-01, 2.6938e-07, 5.0985e-09, 2.7943e-05, 1.0558e-08,
        4.4993e-08, 1.0092e-06, 4.5945e-11, 2.5646e-11, 8.6546e-09, 9.5962e-09,
        1.7522e-10], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,823][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ necklace] are: tensor([2.5923e-06, 9.9311e-01, 4.0751e-04, 4.9370e-05, 2.8271e-03, 5.4491e-04,
        3.6841e-04, 2.7987e-04, 9.2919e-06, 1.2130e-05, 8.1459e-04, 1.5239e-03,
        4.7615e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,824][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ necklace] are: tensor([1.7840e-02, 7.8742e-01, 1.7177e-02, 8.2284e-03, 1.4208e-01, 4.5251e-03,
        2.5077e-03, 1.2859e-02, 8.5040e-04, 5.8024e-04, 3.5582e-03, 2.1632e-03,
        2.0206e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,825][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ necklace] are: tensor([2.9807e-05, 9.9926e-01, 1.2074e-05, 5.7993e-05, 5.3981e-04, 4.7208e-06,
        9.4265e-06, 1.1860e-05, 1.1779e-06, 2.7745e-06, 4.4453e-05, 2.0819e-05,
        8.9082e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,828][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ necklace] are: tensor([0.0568, 0.5271, 0.0905, 0.0457, 0.1412, 0.0140, 0.0099, 0.0649, 0.0061,
        0.0044, 0.0257, 0.0101, 0.0036], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,831][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ necklace] are: tensor([1.1619e-04, 9.4851e-01, 4.5984e-03, 7.1528e-03, 1.8271e-02, 2.9211e-03,
        4.0623e-03, 5.0247e-03, 6.8399e-04, 8.0377e-04, 4.1881e-03, 2.2005e-03,
        1.4697e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,833][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ necklace] are: tensor([7.8708e-02, 8.8503e-01, 2.3695e-03, 5.9024e-03, 2.2030e-02, 3.8911e-04,
        7.3074e-04, 1.0033e-03, 3.2306e-04, 3.6327e-04, 2.5611e-03, 5.0270e-04,
        8.3756e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,835][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ necklace] are: tensor([8.3221e-01, 8.1728e-02, 1.2639e-02, 2.5041e-02, 3.8300e-02, 2.0850e-03,
        8.5597e-04, 5.7469e-04, 3.2061e-03, 1.8757e-03, 8.6818e-04, 5.0630e-04,
        1.0648e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,836][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ necklace] are: tensor([1.8752e-01, 8.0813e-01, 1.5858e-04, 2.5468e-04, 3.7590e-03, 1.7387e-06,
        5.5142e-06, 1.0787e-04, 7.2681e-07, 1.6997e-06, 5.1986e-05, 3.8302e-06,
        3.5344e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace]
[2024-07-24 10:30:12,837][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([4.6742e-01, 3.4743e-01, 1.9273e-02, 9.8594e-03, 6.5392e-02, 2.0303e-02,
        7.7157e-03, 3.1672e-03, 6.0281e-03, 2.8380e-03, 3.6705e-02, 3.3976e-03,
        2.6260e-04, 1.0205e-02], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,838][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([5.8234e-01, 3.9959e-01, 8.1853e-04, 1.1096e-02, 5.2273e-03, 4.4717e-05,
        3.8698e-05, 1.1068e-04, 1.2449e-04, 2.0859e-04, 2.9106e-04, 2.2497e-05,
        1.4897e-05, 6.7751e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,839][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.0478e-04, 9.9864e-01, 4.5793e-05, 5.9001e-05, 7.3761e-04, 4.5121e-05,
        2.4882e-05, 2.1578e-05, 6.5370e-06, 4.0734e-06, 4.9064e-05, 1.7030e-05,
        1.0577e-06, 3.9511e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,841][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([3.4959e-06, 9.9998e-01, 2.8720e-07, 1.6769e-08, 1.7565e-05, 6.0660e-09,
        5.1662e-09, 6.0152e-08, 1.1051e-10, 1.4659e-11, 4.1691e-09, 1.3278e-09,
        4.4936e-11, 3.6695e-08], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,843][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.7021e-06, 9.8763e-01, 5.7589e-04, 9.1171e-05, 3.3821e-03, 1.2993e-03,
        4.9121e-04, 1.7281e-04, 2.6616e-05, 1.8203e-05, 1.1533e-03, 1.8668e-03,
        4.0817e-05, 3.2381e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,846][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.6878e-01, 6.1366e-01, 1.5312e-02, 1.4379e-02, 1.5187e-01, 6.0163e-03,
        1.8310e-03, 1.0631e-02, 1.9128e-03, 1.3239e-03, 3.5552e-03, 1.7080e-03,
        1.6331e-04, 8.8590e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,848][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.7295e-04, 9.9921e-01, 7.7809e-06, 9.1687e-05, 3.4958e-04, 4.3651e-06,
        5.6110e-06, 5.2731e-06, 2.1762e-06, 3.0366e-06, 3.5286e-05, 8.4075e-06,
        4.0232e-07, 4.6012e-06], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,849][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.6067, 0.2091, 0.0350, 0.0432, 0.0519, 0.0043, 0.0023, 0.0220, 0.0039,
        0.0030, 0.0095, 0.0015, 0.0009, 0.0068], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,850][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([4.7405e-05, 9.1461e-01, 8.4150e-03, 1.7041e-02, 2.0968e-02, 8.4405e-03,
        5.4075e-03, 1.9796e-03, 2.3614e-03, 1.3366e-03, 8.9149e-03, 5.5545e-03,
        1.8886e-03, 3.0294e-03], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,851][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.6482e-01, 8.1490e-01, 1.3043e-03, 4.6055e-03, 9.3975e-03, 2.6144e-04,
        3.2507e-04, 4.7657e-04, 2.7993e-04, 3.4482e-04, 2.3319e-03, 2.2662e-04,
        7.1664e-05, 6.5590e-04], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,852][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([9.9120e-01, 1.4979e-03, 7.0156e-04, 4.9104e-03, 8.9261e-04, 8.3104e-05,
        1.1145e-05, 3.6696e-06, 4.5487e-04, 1.3904e-04, 3.1094e-05, 6.6035e-06,
        1.3961e-06, 6.3267e-05], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,855][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([8.5329e-01, 1.4571e-01, 4.1347e-05, 1.3924e-04, 8.0014e-04, 5.9342e-07,
        7.5381e-07, 4.5828e-06, 5.0113e-07, 4.0394e-07, 7.3061e-06, 2.5569e-07,
        4.4004e-07, 5.8351e-07], device='cuda:0') for source tokens [After Rebecca and Amy went to the station, Amy gave a necklace to]
[2024-07-24 10:30:12,858][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:30:12,861][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[16797],
        [  326],
        [    3],
        [   26],
        [   14],
        [    2],
        [    5],
        [    8],
        [    1],
        [   63],
        [    5],
        [    3],
        [   25],
        [    1]], device='cuda:0')
[2024-07-24 10:30:12,864][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15215],
        [   61],
        [    2],
        [    5],
        [    3],
        [    1],
        [    1],
        [    8],
        [    1],
        [   40],
        [    4],
        [    3],
        [   25],
        [    3]], device='cuda:0')
[2024-07-24 10:30:12,865][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11006],
        [ 1430],
        [ 2149],
        [ 5328],
        [ 4689],
        [ 4047],
        [ 4169],
        [ 1992],
        [ 3901],
        [ 5765],
        [ 4672],
        [ 5783],
        [ 5378],
        [ 4093]], device='cuda:0')
[2024-07-24 10:30:12,866][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 1984],
        [ 2042],
        [30099],
        [48226],
        [16957],
        [ 5607],
        [16745],
        [ 8901],
        [34624],
        [48615],
        [40930],
        [ 3368],
        [31014],
        [ 3539]], device='cuda:0')
[2024-07-24 10:30:12,868][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 2154],
        [50249],
        [50244],
        [50238],
        [49757],
        [49761],
        [49765],
        [48935],
        [42331],
        [49652],
        [46328],
        [35805],
        [49315],
        [26298]], device='cuda:0')
[2024-07-24 10:30:12,871][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[12038],
        [41291],
        [43858],
        [43870],
        [43784],
        [43822],
        [43844],
        [43387],
        [43474],
        [43731],
        [42980],
        [33249],
        [41203],
        [26173]], device='cuda:0')
[2024-07-24 10:30:12,873][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[28860],
        [ 6657],
        [ 6671],
        [ 6678],
        [ 6700],
        [ 6705],
        [ 6704],
        [ 6685],
        [ 6737],
        [ 6751],
        [ 6702],
        [ 6699],
        [ 6696],
        [ 6716]], device='cuda:0')
[2024-07-24 10:30:12,876][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[39634],
        [15012],
        [13010],
        [13138],
        [19015],
        [17603],
        [16392],
        [14581],
        [15042],
        [17208],
        [15237],
        [15962],
        [14233],
        [15473]], device='cuda:0')
[2024-07-24 10:30:12,878][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[12850],
        [50044],
        [50044],
        [50044],
        [50043],
        [50044],
        [50043],
        [50043],
        [50043],
        [50043],
        [50043],
        [50043],
        [50043],
        [50043]], device='cuda:0')
[2024-07-24 10:30:12,880][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[49080],
        [32309],
        [ 8859],
        [24664],
        [20351],
        [13422],
        [17066],
        [ 6893],
        [20310],
        [17030],
        [11800],
        [20214],
        [ 9718],
        [27019]], device='cuda:0')
[2024-07-24 10:30:12,881][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[14935],
        [13954],
        [13811],
        [11129],
        [14129],
        [14236],
        [15101],
        [15665],
        [14951],
        [14898],
        [14330],
        [13735],
        [15296],
        [11277]], device='cuda:0')
[2024-07-24 10:30:12,883][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 4054],
        [ 4136],
        [ 4578],
        [14283],
        [ 3909],
        [ 4011],
        [ 3870],
        [ 3952],
        [ 3777],
        [ 9630],
        [ 4281],
        [ 3944],
        [ 3938],
        [ 3997]], device='cuda:0')
[2024-07-24 10:30:12,885][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[42820],
        [42818],
        [33615],
        [ 6979],
        [41816],
        [42594],
        [40931],
        [39299],
        [ 3946],
        [   29],
        [42329],
        [42711],
        [37381],
        [42684]], device='cuda:0')
[2024-07-24 10:30:12,888][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[34513],
        [ 3372],
        [12334],
        [ 9276],
        [ 8460],
        [ 8314],
        [ 8726],
        [ 8435],
        [ 8510],
        [ 9164],
        [ 8333],
        [10119],
        [ 8779],
        [ 9411]], device='cuda:0')
[2024-07-24 10:30:12,891][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21149],
        [24081],
        [19039],
        [16560],
        [25566],
        [17980],
        [17431],
        [18988],
        [13815],
        [16302],
        [19174],
        [19827],
        [16969],
        [15997]], device='cuda:0')
[2024-07-24 10:30:12,893][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21597],
        [25103],
        [24211],
        [22452],
        [22800],
        [23733],
        [23820],
        [24981],
        [24535],
        [24329],
        [23794],
        [23786],
        [24677],
        [24260]], device='cuda:0')
[2024-07-24 10:30:12,895][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[22129],
        [17423],
        [29474],
        [27595],
        [27762],
        [28556],
        [29613],
        [30022],
        [29162],
        [29753],
        [29495],
        [27608],
        [30155],
        [26032]], device='cuda:0')
[2024-07-24 10:30:12,896][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[36767],
        [27681],
        [27536],
        [27563],
        [27538],
        [27532],
        [27531],
        [27533],
        [27545],
        [27546],
        [27537],
        [27533],
        [27533],
        [27535]], device='cuda:0')
[2024-07-24 10:30:12,898][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17335],
        [27882],
        [27897],
        [27897],
        [27897],
        [27897],
        [27897],
        [27897],
        [27897],
        [27897],
        [27897],
        [27897],
        [27897],
        [27897]], device='cuda:0')
[2024-07-24 10:30:12,900][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12957],
        [20808],
        [20771],
        [20745],
        [20608],
        [20649],
        [20648],
        [20729],
        [20570],
        [20487],
        [20701],
        [20715],
        [20730],
        [20627]], device='cuda:0')
[2024-07-24 10:30:12,903][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 9034],
        [ 8999],
        [ 8786],
        [ 8800],
        [10062],
        [ 9615],
        [ 9218],
        [ 8732],
        [ 8858],
        [ 9575],
        [ 8858],
        [ 9164],
        [ 8725],
        [ 9032]], device='cuda:0')
[2024-07-24 10:30:12,906][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[28487],
        [26079],
        [26081],
        [26117],
        [26087],
        [26080],
        [26083],
        [26084],
        [26111],
        [26102],
        [26087],
        [26084],
        [26082],
        [26083]], device='cuda:0')
[2024-07-24 10:30:12,908][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34118],
        [39291],
        [35604],
        [37890],
        [34601],
        [35841],
        [33985],
        [34400],
        [33486],
        [33254],
        [34136],
        [36206],
        [33793],
        [37913]], device='cuda:0')
[2024-07-24 10:30:12,909][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[27602],
        [30298],
        [30276],
        [30194],
        [30265],
        [30285],
        [30279],
        [30290],
        [30262],
        [30239],
        [30293],
        [30269],
        [30281],
        [30294]], device='cuda:0')
[2024-07-24 10:30:12,911][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[21086],
        [25971],
        [25963],
        [26173],
        [26645],
        [25962],
        [26300],
        [26157],
        [26362],
        [26430],
        [26254],
        [26125],
        [26363],
        [26018]], device='cuda:0')
[2024-07-24 10:30:12,912][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[11712],
        [11712],
        [16530],
        [27095],
        [12521],
        [12087],
        [15123],
        [22671],
        [32561],
        [39158],
        [12500],
        [11889],
        [19659],
        [11887]], device='cuda:0')
[2024-07-24 10:30:12,914][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[9085],
        [9029],
        [5421],
        [5343],
        [4722],
        [5218],
        [5456],
        [5464],
        [5461],
        [5473],
        [4871],
        [5256],
        [5350],
        [3112]], device='cuda:0')
[2024-07-24 10:30:12,916][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[20869],
        [21618],
        [19517],
        [15257],
        [21540],
        [21410],
        [20073],
        [16813],
        [14571],
        [12960],
        [21883],
        [21855],
        [18218],
        [22302]], device='cuda:0')
[2024-07-24 10:30:12,919][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26366],
        [19661],
        [17713],
        [24077],
        [16544],
        [23570],
        [22597],
        [23514],
        [29292],
        [26821],
        [22377],
        [23266],
        [26072],
        [24922]], device='cuda:0')
[2024-07-24 10:30:12,921][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[15492],
        [15492],
        [15492],
        [15492],
        [15492],
        [15492],
        [15492],
        [15492],
        [15492],
        [15492],
        [15492],
        [15492],
        [15492],
        [15492]], device='cuda:0')
