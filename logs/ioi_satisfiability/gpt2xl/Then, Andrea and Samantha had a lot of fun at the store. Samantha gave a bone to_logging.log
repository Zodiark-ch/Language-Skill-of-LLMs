[2024-07-24 10:27:13,972][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to
[2024-07-24 10:27:13,972][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Andrea
[2024-07-24 10:27:13,972][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:27:13,972][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:27:13,972][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:27:13,972][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,972][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:27:13,972][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:13,972][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,973][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:27:13,974][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:27:13,975][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,976][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit24']
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,977][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19']
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit27']
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:27:13,978][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit12', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit12', 'circuit13', 'circuit14']
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit27']
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:27:13,979][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:27:13,980][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit14', 'circuit16', 'circuit18']
[2024-07-24 10:27:13,981][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit5', 'circuit7']
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,982][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit23']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit22', 'circuit25']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit18', 'circuit27']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit24']
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:27:13,983][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,984][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit21', 'circuit24', 'circuit26']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit24']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit7', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,985][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit12', 'circuit13']
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20']
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,986][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1']
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,987][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit22']
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,988][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit20']
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18']
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15']
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,989][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit28']
[2024-07-24 10:27:13,990][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit21', 'circuit24']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit21', 'circuit23']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit26']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:27:13,991][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit26']
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15']
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16']
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:27:13,992][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,993][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,994][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit3', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,995][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit15', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit27']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,996][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit3', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit24', 'circuit26']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit22', 'circuit27']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit25']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit12']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit27']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:13,997][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit3', 'circuit5', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit21', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit16', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,998][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit5', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit9', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit4', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit18']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:27:13,999][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,000][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit21']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit9', 'circuit13', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,001][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit27']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:27:14,002][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit7', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit17', 'circuit18', 'circuit26']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit12', 'circuit13', 'circuit23']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit28']
[2024-07-24 10:27:14,003][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit26']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit22']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,004][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit17', 'circuit21', 'circuit22']
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit28']
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,005][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit20', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,006][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit3', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit26']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,007][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit12']
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13']
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,008][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit20', 'circuit24']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit23']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit26', 'circuit28']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit22', 'circuit23']
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:27:14,009][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit9', 'circuit10', 'circuit11', 'circuit27']
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23']
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,010][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20', 'circuit24']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit13']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,011][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,012][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit7', 'circuit11', 'circuit13']
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:27:14,013][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit24']
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit26']
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15']
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,014][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16']
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit15', 'circuit16', 'circuit22', 'circuit23']
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,015][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit19', 'circuit20']
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,016][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit10', 'circuit11', 'circuit13', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit15', 'circuit21', 'circuit25']
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,017][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:27:14,018][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,019][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,020][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,021][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,022][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,023][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit17', 'circuit21', 'circuit22']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit14', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit22']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:27:14,024][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit1']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit12', 'circuit25', 'circuit27']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit25', 'circuit27']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,025][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit24']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit6', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit25']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,026][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,027][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit22']
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,028][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,029][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,030][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,031][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,032][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,033][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit3', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,034][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit23', 'circuit25']
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,035][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,036][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,037][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,038][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,039][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit20']
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit24', 'circuit27']
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,040][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,041][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,042][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,043][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,045][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,046][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit4', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,047][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14', 'circuit23', 'circuit25']
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit19', 'circuit27']
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit16', 'circuit18', 'circuit25']
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit21']
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,048][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,049][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,050][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,051][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22']
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,052][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit13', 'circuit16']
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,053][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,054][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,055][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:27:14,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:27:14,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:14,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit18', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit15', 'circuit23', 'circuit25']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit14']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit7', 'circuit10', 'circuit13', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit13', 'circuit17', 'circuit19', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,062][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,063][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,064][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit25']
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,065][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit18', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit21']
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit26']
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,066][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16', 'circuit20', 'circuit24']
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit24']
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit19']
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit14', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit24']
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit14']
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit18', 'circuit20']
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit21', 'circuit25']
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:27:14,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit18']
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0']
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit25']
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit8', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,070][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,071][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,072][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit20', 'circuit21']
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,073][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,074][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,077][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,077][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,077][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,077][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:14,077][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:27:15,667][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:15,668][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,669][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,669][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,670][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,671][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,672][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,672][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,674][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,674][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,675][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,676][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,677][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:15,678][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,679][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,682][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,686][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,690][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,692][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,693][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,694][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,695][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,695][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,697][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,701][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:15,704][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.4096, 0.3942, 0.1962], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,706][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([1.2645e-04, 7.8448e-05, 9.9980e-01], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,710][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.5869, 0.2458, 0.1673], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,713][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([4.8618e-03, 4.6131e-05, 9.9509e-01], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,714][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.0421, 0.0102, 0.9477], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,714][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([9.7174e-03, 6.8027e-06, 9.9028e-01], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,715][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.4021, 0.3087, 0.2892], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,716][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.5582, 0.3174, 0.1244], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,720][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.5194, 0.3499, 0.1306], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,724][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.6572, 0.3224, 0.0205], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,727][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.5236, 0.2190, 0.2573], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,731][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.4392, 0.3816, 0.1792], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:15,732][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6610, 0.0749, 0.2057, 0.0584], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,733][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([2.3017e-03, 3.9234e-02, 8.1863e-04, 9.5765e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,734][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2353, 0.1761, 0.0466, 0.5420], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,734][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1113, 0.3804, 0.0429, 0.4654], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,737][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3385, 0.1534, 0.2304, 0.2777], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,740][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1223, 0.1958, 0.0133, 0.6687], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,743][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.6231, 0.0298, 0.3245, 0.0226], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,747][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2391, 0.1819, 0.3053, 0.2738], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,750][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0676, 0.4735, 0.0149, 0.4440], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,750][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4279, 0.2390, 0.1111, 0.2220], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,751][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4137, 0.3081, 0.0749, 0.2033], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,752][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4308, 0.1882, 0.1351, 0.2459], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:15,753][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.2207, 0.3076, 0.1125, 0.2737, 0.0856], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,754][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([4.4943e-05, 2.8345e-05, 8.3632e-05, 9.1364e-05, 9.9975e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,757][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.4033, 0.2553, 0.0485, 0.1309, 0.1621], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,759][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([1.3587e-03, 1.6234e-05, 8.9551e-03, 6.2416e-05, 9.8961e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,763][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0214, 0.0051, 0.2061, 0.0039, 0.7634], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,766][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([1.0226e-02, 2.0678e-07, 2.4745e-04, 1.0245e-07, 9.8953e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,768][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.3152, 0.2578, 0.1869, 0.1163, 0.1238], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,769][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.2195, 0.1771, 0.0938, 0.3809, 0.1287], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,769][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.4233, 0.2102, 0.0595, 0.2124, 0.0946], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,770][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.3911, 0.2352, 0.1643, 0.1939, 0.0155], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,772][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.2692, 0.2094, 0.1038, 0.1456, 0.2720], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,775][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.1465, 0.2862, 0.1148, 0.2728, 0.1798], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:15,779][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3776, 0.0332, 0.1267, 0.0330, 0.1386, 0.2909], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,781][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2175e-04, 1.6732e-03, 1.1890e-03, 2.8580e-03, 5.5910e-04, 9.9340e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,786][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4847, 0.1236, 0.0596, 0.1462, 0.0410, 0.1448], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,786][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.9410e-03, 5.4305e-03, 4.4877e-04, 1.1491e-02, 1.6112e-03, 9.7608e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,787][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2316, 0.0659, 0.0282, 0.1192, 0.0633, 0.4918], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,788][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9815e-02, 1.8580e-03, 4.9519e-04, 1.2917e-03, 4.3657e-05, 9.5650e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,789][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2900, 0.0217, 0.2461, 0.0203, 0.3928, 0.0291], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,791][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1348, 0.1050, 0.1131, 0.2437, 0.1004, 0.3030], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,793][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0945, 0.2654, 0.0328, 0.3486, 0.0430, 0.2157], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,797][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3074, 0.1853, 0.1011, 0.1910, 0.0860, 0.1291], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,802][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2481, 0.1913, 0.0831, 0.1401, 0.0331, 0.3043], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,804][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4076, 0.1361, 0.1064, 0.1698, 0.0943, 0.0858], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:15,805][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4302, 0.0496, 0.2258, 0.0375, 0.1620, 0.0617, 0.0332],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,805][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5636e-04, 4.3037e-03, 5.9795e-04, 4.3017e-03, 4.7025e-04, 4.6871e-04,
        9.8900e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,806][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3026, 0.1877, 0.0591, 0.2213, 0.0572, 0.1253, 0.0468],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,808][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0294, 0.0180, 0.0084, 0.0332, 0.0129, 0.1794, 0.7188],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,811][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1418, 0.0312, 0.0706, 0.0439, 0.0548, 0.4433, 0.2145],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,815][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0559, 0.1297, 0.0039, 0.0970, 0.0021, 0.0448, 0.6666],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,820][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2669, 0.0089, 0.2462, 0.0076, 0.4225, 0.0393, 0.0087],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,822][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0981, 0.0590, 0.0549, 0.1318, 0.1309, 0.2211, 0.3043],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,823][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0241, 0.1312, 0.0078, 0.1949, 0.0072, 0.1424, 0.4924],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,823][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2664, 0.1706, 0.0700, 0.1731, 0.0761, 0.1074, 0.1365],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,824][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2262, 0.1928, 0.0627, 0.1635, 0.0451, 0.0837, 0.2261],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,826][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3142, 0.1259, 0.1214, 0.1353, 0.1179, 0.0812, 0.1042],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:15,829][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.3515, 0.0778, 0.0903, 0.0821, 0.1432, 0.0733, 0.0869, 0.0949],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,831][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([2.6501e-04, 1.0296e-03, 4.6497e-04, 1.2104e-03, 1.3019e-04, 1.3691e-03,
        5.0388e-04, 9.9503e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,835][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2839, 0.1097, 0.0587, 0.1962, 0.0937, 0.1458, 0.0757, 0.0363],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,838][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([1.0773e-03, 1.2863e-04, 1.4084e-05, 2.5223e-04, 2.3858e-04, 2.0045e-03,
        1.6743e-03, 9.9461e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,840][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0459, 0.0142, 0.0093, 0.0158, 0.0283, 0.0606, 0.0714, 0.7544],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,841][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([3.2519e-03, 1.1956e-04, 4.0515e-05, 1.7791e-05, 5.3349e-06, 9.6468e-06,
        5.2876e-06, 9.9655e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,841][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.2618, 0.0566, 0.2050, 0.0330, 0.1700, 0.0374, 0.0489, 0.1874],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,842][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0913, 0.0492, 0.0417, 0.0969, 0.0641, 0.1572, 0.2905, 0.2091],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,844][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1244, 0.1511, 0.0508, 0.1397, 0.0265, 0.1140, 0.3384, 0.0552],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,847][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.2294, 0.1455, 0.0963, 0.1408, 0.1134, 0.0945, 0.1213, 0.0587],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,851][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.2127, 0.1528, 0.0497, 0.1263, 0.0253, 0.0852, 0.0850, 0.2630],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,855][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.4368, 0.0837, 0.1104, 0.0866, 0.0794, 0.0591, 0.0436, 0.1004],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:15,858][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.3380, 0.0531, 0.1692, 0.0382, 0.1239, 0.0697, 0.0464, 0.1318, 0.0296],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,858][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ of] are: tensor([8.9865e-04, 1.5859e-02, 1.5713e-04, 2.1563e-02, 1.8229e-05, 6.7597e-04,
        3.8734e-04, 9.5693e-05, 9.6034e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,859][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.3047, 0.1443, 0.0535, 0.1342, 0.0376, 0.0776, 0.0615, 0.0855, 0.1010],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,860][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0052, 0.0030, 0.0017, 0.0070, 0.0039, 0.0454, 0.0610, 0.3732, 0.4996],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,862][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1570, 0.0214, 0.0347, 0.0255, 0.0599, 0.1129, 0.0731, 0.3387, 0.1769],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,865][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0226, 0.0912, 0.0023, 0.1070, 0.0012, 0.0656, 0.2355, 0.0072, 0.4674],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,869][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1782, 0.0152, 0.1763, 0.0134, 0.3810, 0.0347, 0.0140, 0.1777, 0.0095],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,873][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0552, 0.0267, 0.0191, 0.0559, 0.0422, 0.1106, 0.1871, 0.2777, 0.2253],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,876][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0230, 0.1178, 0.0080, 0.1841, 0.0103, 0.1240, 0.3544, 0.0216, 0.1568],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,876][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.2050, 0.1339, 0.0618, 0.1371, 0.0614, 0.0859, 0.1118, 0.0800, 0.1231],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,877][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1709, 0.1584, 0.0440, 0.1498, 0.0224, 0.0774, 0.0920, 0.0598, 0.2253],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,878][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.2348, 0.1021, 0.1231, 0.1204, 0.1387, 0.0702, 0.0758, 0.0901, 0.0450],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:15,880][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.1683, 0.0679, 0.3409, 0.0623, 0.1110, 0.0237, 0.0595, 0.0661, 0.0367,
        0.0637], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,882][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([1.4100e-04, 4.5758e-05, 3.4915e-04, 3.7542e-05, 2.3278e-04, 2.0440e-05,
        1.1355e-03, 8.8549e-04, 1.7993e-05, 9.9713e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,886][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1879, 0.0652, 0.0916, 0.1041, 0.1095, 0.0946, 0.0868, 0.0700, 0.0960,
        0.0942], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,889][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([4.4575e-04, 8.2961e-06, 9.6069e-06, 8.7104e-06, 1.4603e-04, 2.8327e-04,
        2.2892e-04, 1.8481e-03, 2.9445e-04, 9.9673e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,892][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0122, 0.0021, 0.0018, 0.0024, 0.0104, 0.0102, 0.0107, 0.0138, 0.0095,
        0.9268], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,894][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([4.2287e-03, 2.8179e-05, 1.3027e-05, 3.7848e-06, 4.1827e-06, 4.2787e-07,
        1.7981e-06, 1.4493e-04, 2.7550e-07, 9.9557e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,895][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1495, 0.0317, 0.2453, 0.0247, 0.2678, 0.0208, 0.0225, 0.0986, 0.0269,
        0.1121], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,896][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0941, 0.0235, 0.0174, 0.0505, 0.0157, 0.0698, 0.1394, 0.1962, 0.2637,
        0.1298], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,896][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1202, 0.1110, 0.1096, 0.1648, 0.0254, 0.0972, 0.1818, 0.0596, 0.0958,
        0.0345], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,898][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1880, 0.1148, 0.0937, 0.1097, 0.0817, 0.0825, 0.0946, 0.0766, 0.1013,
        0.0571], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,901][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1332, 0.1038, 0.0523, 0.1008, 0.0390, 0.0570, 0.0838, 0.0874, 0.0724,
        0.2701], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,905][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.2974, 0.1481, 0.0970, 0.1104, 0.0582, 0.0673, 0.0622, 0.0438, 0.0518,
        0.0637], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:15,910][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2376, 0.0336, 0.0977, 0.0310, 0.1362, 0.0436, 0.0486, 0.1284, 0.0303,
        0.1901, 0.0229], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,912][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ at] are: tensor([7.4917e-04, 1.5256e-03, 1.4653e-04, 3.7668e-03, 1.0304e-04, 1.5081e-04,
        1.4849e-03, 3.0395e-05, 4.3048e-03, 3.3114e-05, 9.8770e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,913][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1980, 0.1022, 0.0312, 0.1208, 0.0500, 0.0800, 0.0448, 0.0632, 0.1170,
        0.0797, 0.1132], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,914][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ at] are: tensor([1.0224e-03, 3.5278e-04, 3.7558e-05, 6.9247e-04, 1.3797e-04, 4.8617e-03,
        7.4773e-03, 3.9671e-03, 3.0006e-02, 1.3053e-01, 8.2092e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,914][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0618, 0.0063, 0.0112, 0.0095, 0.0092, 0.0580, 0.0342, 0.0467, 0.0706,
        0.3775, 0.3150], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,916][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ at] are: tensor([5.4687e-02, 2.3155e-02, 1.6722e-03, 9.6792e-03, 8.2506e-04, 3.6403e-02,
        1.6092e-02, 1.2100e-03, 3.8695e-03, 9.3844e-04, 8.5147e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,919][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1496, 0.0114, 0.1673, 0.0112, 0.2763, 0.0366, 0.0144, 0.1588, 0.0110,
        0.1456, 0.0178], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,923][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0369, 0.0125, 0.0063, 0.0283, 0.0159, 0.0471, 0.0827, 0.1106, 0.1274,
        0.1945, 0.3379], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,927][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0241, 0.1166, 0.0075, 0.2114, 0.0054, 0.1124, 0.1979, 0.0246, 0.1670,
        0.0262, 0.1070], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,930][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1528, 0.1066, 0.0480, 0.1154, 0.0440, 0.0798, 0.0922, 0.0710, 0.1112,
        0.0741, 0.1048], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,930][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1445, 0.1118, 0.0395, 0.1151, 0.0339, 0.0839, 0.0970, 0.0349, 0.0929,
        0.0305, 0.2160], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,931][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.2435, 0.0835, 0.0883, 0.0866, 0.0843, 0.0517, 0.0451, 0.0815, 0.0454,
        0.0790, 0.1111], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:15,932][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.3575, 0.0303, 0.1358, 0.0196, 0.1390, 0.0396, 0.0173, 0.0771, 0.0174,
        0.1266, 0.0186, 0.0212], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,933][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ the] are: tensor([2.9757e-03, 1.8214e-02, 2.3186e-04, 3.9249e-02, 1.3414e-04, 2.7156e-04,
        3.3105e-02, 8.6453e-05, 6.8765e-02, 7.4403e-05, 4.1123e-02, 7.9577e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,936][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1806, 0.0884, 0.0378, 0.0986, 0.0398, 0.0918, 0.0286, 0.0679, 0.1100,
        0.0611, 0.1664, 0.0291], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,939][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ the] are: tensor([1.0775e-02, 1.6536e-03, 5.9400e-04, 1.8832e-03, 9.2999e-04, 7.3255e-03,
        1.8900e-02, 1.2119e-02, 6.1563e-02, 5.5877e-02, 1.8263e-01, 6.4575e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,943][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1109, 0.0123, 0.0270, 0.0163, 0.0094, 0.0776, 0.0332, 0.0500, 0.0977,
        0.1406, 0.2305, 0.1944], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,947][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0667, 0.1045, 0.0068, 0.0855, 0.0027, 0.0639, 0.2097, 0.0509, 0.0550,
        0.0114, 0.0586, 0.2841], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,948][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1463, 0.0024, 0.1643, 0.0023, 0.3811, 0.0141, 0.0027, 0.1233, 0.0020,
        0.1545, 0.0053, 0.0016], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,949][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0381, 0.0089, 0.0099, 0.0177, 0.0174, 0.0230, 0.0367, 0.0575, 0.0947,
        0.0972, 0.2939, 0.3051], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,950][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0084, 0.0712, 0.0046, 0.1146, 0.0060, 0.0746, 0.2403, 0.0078, 0.0763,
        0.0134, 0.0510, 0.3317], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,951][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1684, 0.0951, 0.0509, 0.0986, 0.0489, 0.0691, 0.0788, 0.0644, 0.0916,
        0.0497, 0.0928, 0.0915], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,954][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.1746, 0.1069, 0.0449, 0.1065, 0.0435, 0.0544, 0.1117, 0.0415, 0.0640,
        0.0301, 0.0736, 0.1483], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,958][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.1822, 0.0733, 0.0966, 0.0769, 0.1130, 0.0475, 0.0795, 0.0700, 0.0291,
        0.0728, 0.0724, 0.0865], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:15,961][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.1528, 0.0679, 0.1166, 0.0614, 0.2466, 0.0434, 0.0641, 0.0384, 0.0529,
        0.0275, 0.0476, 0.0635, 0.0172], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,963][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ store] are: tensor([9.8325e-04, 2.2841e-03, 2.7317e-04, 1.7927e-03, 8.4319e-04, 1.1721e-03,
        3.9979e-04, 3.1113e-03, 5.1556e-04, 1.2990e-03, 5.9053e-04, 9.8863e-04,
        9.8575e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,965][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1481, 0.0508, 0.1554, 0.0444, 0.1040, 0.0769, 0.0449, 0.0519, 0.0660,
        0.0888, 0.0684, 0.0506, 0.0497], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,966][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ store] are: tensor([2.6441e-04, 6.7580e-07, 3.6899e-06, 1.7833e-06, 1.5574e-06, 9.9486e-06,
        1.4848e-05, 9.9431e-04, 1.7502e-04, 3.6773e-03, 4.1685e-04, 3.5972e-04,
        9.9408e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,967][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0335, 0.0021, 0.0017, 0.0035, 0.0035, 0.0026, 0.0021, 0.0211, 0.0145,
        0.0291, 0.0311, 0.0256, 0.8298], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,968][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ store] are: tensor([1.1152e-02, 3.7609e-05, 1.8802e-05, 6.5195e-06, 1.9410e-05, 3.0193e-05,
        3.1775e-06, 1.7094e-04, 2.1964e-06, 2.0903e-05, 2.1613e-06, 1.7159e-06,
        9.8853e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,970][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.1927, 0.0395, 0.1202, 0.0248, 0.1951, 0.0154, 0.0173, 0.0454, 0.0171,
        0.1785, 0.0123, 0.0163, 0.1255], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,973][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0380, 0.0066, 0.0028, 0.0189, 0.0047, 0.0246, 0.0395, 0.0701, 0.0831,
        0.1364, 0.2090, 0.2716, 0.0947], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,977][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.1299, 0.0875, 0.0267, 0.1021, 0.0755, 0.0662, 0.0566, 0.0576, 0.0702,
        0.0909, 0.0975, 0.0905, 0.0488], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,981][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.1701, 0.0891, 0.0778, 0.0838, 0.0821, 0.0577, 0.0751, 0.0523, 0.0707,
        0.0734, 0.0701, 0.0817, 0.0162], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,983][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.1160, 0.0808, 0.0446, 0.0842, 0.0364, 0.0577, 0.0696, 0.0522, 0.0612,
        0.0303, 0.0572, 0.0650, 0.2448], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,984][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.2433, 0.0896, 0.0787, 0.0612, 0.0571, 0.0421, 0.0284, 0.0803, 0.0600,
        0.0747, 0.0942, 0.0257, 0.0647], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:15,985][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.4126, 0.0129, 0.0606, 0.0107, 0.1412, 0.0449, 0.0202, 0.0728, 0.0083,
        0.1004, 0.0156, 0.0343, 0.0562, 0.0093], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:15,986][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.9667e-03, 2.9770e-02, 2.1665e-04, 5.5114e-03, 5.3068e-04, 1.1793e-04,
        2.6020e-04, 2.2070e-04, 2.5129e-03, 7.6653e-05, 1.1372e-03, 2.5234e-04,
        4.5391e-05, 9.5638e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:15,988][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.3460, 0.0442, 0.0418, 0.0378, 0.0199, 0.1936, 0.0175, 0.0467, 0.0833,
        0.0369, 0.0515, 0.0215, 0.0146, 0.0448], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:15,991][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0134, 0.0016, 0.0008, 0.0015, 0.0012, 0.0048, 0.0052, 0.0210, 0.0202,
        0.0214, 0.0693, 0.1881, 0.1391, 0.5124], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:15,995][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0275, 0.0093, 0.0049, 0.0177, 0.0052, 0.0192, 0.0164, 0.0405, 0.0541,
        0.0613, 0.1252, 0.1071, 0.2135, 0.2984], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:15,999][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1025, 0.1630, 0.0250, 0.1045, 0.0200, 0.0722, 0.0785, 0.0328, 0.0516,
        0.0109, 0.0544, 0.0632, 0.0114, 0.2099], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,001][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.2154, 0.0055, 0.1167, 0.0041, 0.2426, 0.0113, 0.0055, 0.0837, 0.0034,
        0.1767, 0.0072, 0.0036, 0.1216, 0.0027], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,002][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0177, 0.0043, 0.0074, 0.0079, 0.0084, 0.0119, 0.0181, 0.0297, 0.0309,
        0.0656, 0.0922, 0.1425, 0.1673, 0.3959], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,003][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0144, 0.1270, 0.0030, 0.1012, 0.0060, 0.0226, 0.0846, 0.0064, 0.0607,
        0.0048, 0.0401, 0.1369, 0.0071, 0.3852], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,004][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.1445, 0.0808, 0.0546, 0.0839, 0.0463, 0.0641, 0.0646, 0.0609, 0.0676,
        0.0604, 0.0708, 0.0729, 0.0396, 0.0889], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,006][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1080, 0.0911, 0.0378, 0.0981, 0.0437, 0.0742, 0.0607, 0.0638, 0.0761,
        0.0534, 0.0751, 0.0610, 0.0287, 0.1282], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,008][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2069, 0.0721, 0.0841, 0.0685, 0.0750, 0.0483, 0.0418, 0.0668, 0.0341,
        0.0608, 0.0721, 0.0324, 0.0474, 0.0897], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,012][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.1046, 0.1132, 0.0506, 0.1079, 0.0438, 0.0111, 0.0538, 0.0201, 0.0717,
        0.0235, 0.0638, 0.0927, 0.0689, 0.1289, 0.0455], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,015][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([1.4961e-05, 4.2577e-06, 1.3227e-05, 1.7795e-05, 4.8046e-01, 6.4672e-06,
        2.7744e-05, 2.8884e-06, 1.3968e-06, 4.6432e-06, 9.4757e-06, 6.0464e-06,
        1.0968e-06, 1.1830e-06, 5.1943e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,019][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.1696, 0.0922, 0.0255, 0.0609, 0.1020, 0.0810, 0.0683, 0.0202, 0.0630,
        0.0282, 0.0545, 0.0678, 0.0094, 0.0551, 0.1024], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,020][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([8.9737e-05, 1.0026e-07, 4.0978e-05, 1.5664e-07, 6.8957e-03, 1.1123e-06,
        5.5578e-07, 1.1607e-06, 1.1935e-06, 2.4122e-05, 4.2385e-06, 4.2955e-06,
        7.0508e-06, 8.7775e-06, 9.9292e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,021][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([3.4359e-03, 5.0184e-04, 1.6341e-02, 2.9785e-04, 5.4693e-02, 4.3225e-04,
        4.0143e-04, 1.0055e-03, 1.0741e-03, 1.5392e-03, 1.4915e-03, 2.4166e-03,
        1.2870e-02, 9.3563e-03, 8.9414e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,022][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([2.3237e-03, 3.0941e-08, 8.1121e-05, 1.7562e-08, 5.8542e-01, 2.3655e-08,
        1.4999e-08, 5.4455e-08, 3.7546e-09, 9.8983e-08, 8.3061e-09, 6.5548e-09,
        7.3798e-08, 2.9111e-09, 4.1218e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,024][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.1618, 0.1159, 0.1138, 0.0594, 0.0886, 0.0214, 0.0868, 0.0204, 0.0321,
        0.0241, 0.0177, 0.0985, 0.0278, 0.0450, 0.0866], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,026][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0487, 0.0131, 0.0064, 0.0223, 0.0069, 0.0235, 0.0321, 0.0200, 0.0469,
        0.0313, 0.0980, 0.1584, 0.0756, 0.3280, 0.0890], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,030][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.1877, 0.0802, 0.0275, 0.0962, 0.0559, 0.0329, 0.0448, 0.0288, 0.0642,
        0.0549, 0.0602, 0.0527, 0.0692, 0.0839, 0.0610], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,035][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.1585, 0.0962, 0.0855, 0.0842, 0.0077, 0.0546, 0.0596, 0.0606, 0.0668,
        0.0507, 0.0569, 0.0693, 0.0546, 0.0876, 0.0071], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,037][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0779, 0.0616, 0.0532, 0.0631, 0.2557, 0.0346, 0.0428, 0.0159, 0.0390,
        0.0189, 0.0353, 0.0400, 0.0098, 0.0428, 0.2095], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,038][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0390, 0.0783, 0.0385, 0.0651, 0.0578, 0.0639, 0.0958, 0.0345, 0.0321,
        0.0624, 0.0786, 0.0754, 0.0358, 0.1560, 0.0866], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,039][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1752, 0.0172, 0.0523, 0.0207, 0.1136, 0.0859, 0.0164, 0.0418, 0.0202,
        0.0335, 0.0165, 0.0153, 0.0328, 0.0138, 0.1557, 0.1891],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,040][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([3.7470e-04, 5.8173e-04, 4.2451e-04, 1.2650e-03, 5.8211e-04, 6.5316e-03,
        1.4106e-04, 3.2810e-04, 7.6502e-04, 1.2319e-04, 3.5758e-04, 1.7559e-04,
        5.8528e-04, 5.0827e-05, 4.5461e-04, 9.8726e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,042][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1699, 0.0426, 0.0637, 0.0513, 0.0200, 0.0764, 0.0441, 0.0575, 0.0733,
        0.0644, 0.0723, 0.0543, 0.0427, 0.0721, 0.0194, 0.0761],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,044][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([8.5744e-04, 4.5938e-06, 9.5285e-07, 3.9909e-06, 4.2257e-06, 4.5503e-05,
        1.1782e-05, 3.8576e-05, 4.7080e-05, 2.9182e-04, 1.4093e-04, 2.0620e-04,
        2.0621e-03, 6.5111e-04, 1.0325e-03, 9.9460e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,048][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0833, 0.0065, 0.0132, 0.0065, 0.0072, 0.0107, 0.0075, 0.0102, 0.0190,
        0.0227, 0.0395, 0.0215, 0.0284, 0.0430, 0.0682, 0.6127],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,051][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([3.9536e-02, 2.1612e-05, 4.9793e-05, 2.1873e-05, 3.0548e-05, 1.8039e-03,
        1.2768e-05, 7.0413e-06, 5.9636e-06, 5.3260e-05, 1.5033e-05, 7.0798e-06,
        6.4643e-05, 1.0706e-06, 1.0802e-05, 9.5836e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,055][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0800, 0.0100, 0.0928, 0.0098, 0.1785, 0.0119, 0.0143, 0.0644, 0.0074,
        0.1235, 0.0086, 0.0111, 0.0787, 0.0103, 0.2742, 0.0245],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,056][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0194, 0.0043, 0.0092, 0.0064, 0.0048, 0.0064, 0.0123, 0.0143, 0.0158,
        0.0250, 0.0579, 0.0798, 0.0738, 0.3192, 0.1191, 0.2322],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,057][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0713, 0.0704, 0.0183, 0.0892, 0.0228, 0.0386, 0.1015, 0.0349, 0.0786,
        0.0632, 0.0732, 0.1231, 0.0533, 0.0956, 0.0311, 0.0348],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,057][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.1158, 0.0635, 0.0511, 0.0674, 0.0307, 0.0627, 0.0563, 0.0563, 0.0622,
        0.0765, 0.0563, 0.0606, 0.0509, 0.0913, 0.0364, 0.0619],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,060][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0781, 0.0550, 0.0410, 0.0621, 0.0385, 0.1034, 0.0506, 0.0302, 0.0533,
        0.0334, 0.0550, 0.0486, 0.0311, 0.0654, 0.0392, 0.2155],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,063][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.2174, 0.0767, 0.0551, 0.0917, 0.0442, 0.0403, 0.0368, 0.0464, 0.0389,
        0.0450, 0.0681, 0.0330, 0.0277, 0.0826, 0.0419, 0.0542],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,066][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2149, 0.0170, 0.1000, 0.0131, 0.0807, 0.0274, 0.0118, 0.0523, 0.0111,
        0.0904, 0.0110, 0.0208, 0.0810, 0.0155, 0.1231, 0.1118, 0.0181],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,069][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([4.3930e-04, 1.1436e-03, 1.4272e-04, 1.2521e-03, 1.8364e-04, 1.3496e-04,
        4.3330e-01, 1.8446e-04, 1.1690e-03, 9.9728e-04, 3.4123e-03, 1.4676e-02,
        5.5866e-05, 2.8413e-04, 1.3519e-04, 1.1750e-04, 5.4237e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,073][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1013, 0.0518, 0.0237, 0.0790, 0.0247, 0.0475, 0.0161, 0.0600, 0.0795,
        0.0448, 0.1206, 0.0187, 0.0283, 0.1678, 0.0283, 0.0898, 0.0181],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,074][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.5945e-03, 2.7315e-04, 7.1642e-05, 1.7487e-04, 7.8145e-05, 3.7612e-04,
        1.3098e-03, 5.5454e-04, 1.7469e-03, 1.7553e-03, 4.7715e-03, 1.9503e-02,
        9.7766e-03, 2.8949e-02, 1.1644e-02, 1.3225e-01, 7.8318e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,075][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0234, 0.0028, 0.0042, 0.0030, 0.0023, 0.0195, 0.0077, 0.0072, 0.0117,
        0.0271, 0.0256, 0.0195, 0.0307, 0.0227, 0.0259, 0.5673, 0.1996],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,075][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.6615e-02, 5.2937e-02, 1.6682e-03, 4.6453e-02, 9.3218e-04, 2.4860e-02,
        4.1671e-01, 3.8525e-03, 2.4939e-02, 4.2895e-03, 3.1539e-02, 1.0146e-01,
        2.2507e-03, 1.3200e-02, 3.6041e-04, 3.8649e-03, 2.5407e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,077][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0803, 0.0019, 0.0800, 0.0018, 0.1691, 0.0118, 0.0020, 0.0767, 0.0020,
        0.0971, 0.0040, 0.0016, 0.1067, 0.0017, 0.3072, 0.0532, 0.0031],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,080][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0141, 0.0026, 0.0021, 0.0040, 0.0035, 0.0036, 0.0041, 0.0075, 0.0097,
        0.0121, 0.0305, 0.0357, 0.0325, 0.2028, 0.0939, 0.2786, 0.2627],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,084][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0069, 0.0340, 0.0023, 0.0596, 0.0025, 0.0463, 0.1371, 0.0065, 0.0439,
        0.0112, 0.0356, 0.1963, 0.0085, 0.1004, 0.0040, 0.0235, 0.2811],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,089][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1077, 0.0659, 0.0329, 0.0725, 0.0397, 0.0487, 0.0567, 0.0478, 0.0670,
        0.0421, 0.0662, 0.0682, 0.0331, 0.0716, 0.0462, 0.0613, 0.0722],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,091][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0740, 0.0575, 0.0297, 0.0679, 0.0332, 0.0450, 0.1258, 0.0338, 0.0539,
        0.0386, 0.0694, 0.0812, 0.0285, 0.0548, 0.0327, 0.0359, 0.1381],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,092][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1661, 0.0623, 0.0698, 0.0595, 0.0619, 0.0404, 0.0456, 0.0527, 0.0261,
        0.0511, 0.0519, 0.0337, 0.0423, 0.0672, 0.0615, 0.0631, 0.0447],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,093][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.1099, 0.0643, 0.0548, 0.0703, 0.0328, 0.0275, 0.0393, 0.0462, 0.0605,
        0.0587, 0.0401, 0.0398, 0.0141, 0.0345, 0.0343, 0.0462, 0.0443, 0.1823],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,094][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([7.1459e-05, 5.9163e-05, 9.0129e-04, 4.5736e-05, 1.2833e-05, 2.3660e-05,
        5.3249e-05, 8.3573e-05, 7.2006e-05, 1.5781e-04, 4.5170e-05, 1.2666e-05,
        3.0526e-06, 2.7359e-05, 6.1646e-06, 1.2491e-05, 3.2863e-05, 9.9838e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,097][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.1125, 0.0466, 0.0490, 0.0530, 0.0197, 0.0432, 0.0714, 0.0628, 0.0527,
        0.0437, 0.0482, 0.0856, 0.0461, 0.0470, 0.0183, 0.0641, 0.0780, 0.0581],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,100][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([1.2750e-03, 6.3989e-07, 6.2620e-06, 8.5495e-07, 7.5481e-06, 3.8642e-06,
        2.8841e-06, 1.0340e-04, 7.9588e-06, 1.2214e-04, 4.9076e-05, 3.3661e-05,
        2.3334e-03, 1.0157e-04, 1.1880e-03, 4.1492e-03, 1.3563e-03, 9.8926e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,102][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([1.1403e-02, 1.0489e-03, 1.3461e-03, 6.6336e-04, 1.7129e-03, 5.0707e-04,
        7.1643e-04, 1.3456e-03, 2.0491e-03, 5.5053e-03, 3.2737e-03, 1.7506e-03,
        4.8050e-03, 4.3265e-03, 1.0640e-02, 5.1780e-03, 8.4297e-03, 9.3530e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,104][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([8.9177e-03, 6.1030e-06, 2.6166e-04, 1.3552e-06, 1.6804e-05, 5.3777e-07,
        5.0838e-07, 2.2967e-05, 2.1898e-07, 9.4061e-06, 3.0668e-07, 1.8320e-07,
        2.9675e-08, 1.0952e-07, 5.4429e-06, 8.9393e-08, 1.5547e-07, 9.9076e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,108][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0957, 0.0493, 0.0760, 0.0398, 0.0847, 0.0188, 0.0383, 0.0266, 0.0227,
        0.0738, 0.0184, 0.0452, 0.0784, 0.0287, 0.0918, 0.0378, 0.0438, 0.1300],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,109][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0273, 0.0056, 0.0016, 0.0102, 0.0013, 0.0073, 0.0099, 0.0100, 0.0199,
        0.0116, 0.0407, 0.0417, 0.0117, 0.1646, 0.0168, 0.2049, 0.3152, 0.0995],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,110][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.1307, 0.0549, 0.0288, 0.0605, 0.0097, 0.0370, 0.0733, 0.0229, 0.0408,
        0.0397, 0.0632, 0.0667, 0.0154, 0.0468, 0.0091, 0.0404, 0.0838, 0.1763],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,111][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0976, 0.0618, 0.0602, 0.0627, 0.0500, 0.0458, 0.0480, 0.0437, 0.0579,
        0.0715, 0.0491, 0.0472, 0.0594, 0.0717, 0.0594, 0.0466, 0.0603, 0.0070],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,113][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0981, 0.0590, 0.0452, 0.0605, 0.0254, 0.0441, 0.0452, 0.0397, 0.0550,
        0.0369, 0.0360, 0.0406, 0.0126, 0.0582, 0.0245, 0.0250, 0.0465, 0.2476],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,116][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.1184, 0.0571, 0.0504, 0.0444, 0.0483, 0.0486, 0.0324, 0.0691, 0.0637,
        0.0717, 0.0665, 0.0214, 0.0422, 0.0658, 0.0516, 0.0740, 0.0344, 0.0401],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,120][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1958, 0.0172, 0.0597, 0.0144, 0.0810, 0.0478, 0.0152, 0.0491, 0.0158,
        0.0543, 0.0146, 0.0229, 0.0554, 0.0158, 0.1247, 0.1280, 0.0248, 0.0497,
        0.0138], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,122][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.0630e-03, 8.9823e-03, 3.7421e-04, 2.6116e-02, 5.8047e-05, 2.3089e-04,
        1.0624e-03, 3.7205e-05, 2.5753e-02, 1.8236e-04, 1.4917e-02, 1.4069e-03,
        6.7676e-05, 6.9801e-03, 4.3202e-05, 6.6493e-04, 9.9137e-04, 1.7513e-05,
        9.0805e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,126][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1051, 0.0429, 0.0244, 0.0624, 0.0141, 0.0384, 0.0159, 0.0459, 0.0674,
        0.0356, 0.0919, 0.0189, 0.0219, 0.1889, 0.0149, 0.0540, 0.0177, 0.0134,
        0.1264], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,127][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.1800e-03, 6.2231e-05, 1.1604e-05, 2.9840e-05, 2.7237e-05, 7.1207e-05,
        9.9280e-05, 2.9611e-05, 3.8678e-04, 2.5971e-04, 5.8756e-04, 2.3874e-03,
        6.5766e-04, 4.3242e-03, 3.6878e-03, 2.4704e-01, 7.0210e-02, 3.2698e-02,
        6.3625e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,128][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0224, 0.0012, 0.0030, 0.0018, 0.0016, 0.0120, 0.0032, 0.0050, 0.0044,
        0.0287, 0.0112, 0.0084, 0.0112, 0.0137, 0.0185, 0.4027, 0.0904, 0.0616,
        0.2989], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,129][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0297, 0.0435, 0.0017, 0.0586, 0.0022, 0.0250, 0.1855, 0.0075, 0.0394,
        0.0096, 0.0167, 0.1355, 0.0015, 0.0165, 0.0010, 0.0049, 0.1147, 0.0006,
        0.3057], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,131][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0704, 0.0031, 0.0425, 0.0027, 0.1124, 0.0095, 0.0025, 0.0302, 0.0038,
        0.0860, 0.0137, 0.0022, 0.0476, 0.0038, 0.2175, 0.0456, 0.0042, 0.0545,
        0.2479], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,134][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0157, 0.0023, 0.0016, 0.0031, 0.0037, 0.0028, 0.0033, 0.0046, 0.0041,
        0.0120, 0.0119, 0.0197, 0.0212, 0.0982, 0.0702, 0.1299, 0.1710, 0.1281,
        0.2969], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,138][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0054, 0.0389, 0.0020, 0.0698, 0.0027, 0.0316, 0.0855, 0.0057, 0.0497,
        0.0059, 0.0339, 0.1528, 0.0064, 0.1179, 0.0043, 0.0175, 0.1684, 0.0087,
        0.1927], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,142][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0927, 0.0551, 0.0370, 0.0623, 0.0283, 0.0424, 0.0529, 0.0420, 0.0564,
        0.0448, 0.0565, 0.0606, 0.0297, 0.0636, 0.0325, 0.0557, 0.0679, 0.0349,
        0.0848], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,144][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0713, 0.0545, 0.0261, 0.0701, 0.0270, 0.0549, 0.0632, 0.0346, 0.0625,
        0.0399, 0.0630, 0.0631, 0.0262, 0.0674, 0.0278, 0.0551, 0.0702, 0.0248,
        0.0982], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,145][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1507, 0.0581, 0.0620, 0.0587, 0.0629, 0.0432, 0.0380, 0.0462, 0.0273,
        0.0452, 0.0547, 0.0272, 0.0352, 0.0583, 0.0602, 0.0603, 0.0353, 0.0217,
        0.0547], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,152][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:16,152][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,153][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,154][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,155][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,155][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,156][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,157][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,157][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,158][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,159][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,160][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,161][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,161][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,162][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,165][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,169][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,172][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,176][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,177][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,177][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,178][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,179][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,181][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,183][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,187][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.4096, 0.3942, 0.1962], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,190][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([1.2645e-04, 7.8448e-05, 9.9980e-01], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,194][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.5869, 0.2458, 0.1673], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,194][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([4.8618e-03, 4.6131e-05, 9.9509e-01], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,195][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.0421, 0.0102, 0.9477], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,196][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([9.7174e-03, 6.8027e-06, 9.9028e-01], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,196][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.4021, 0.3087, 0.2892], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,197][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.5582, 0.3174, 0.1244], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,198][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.5194, 0.3499, 0.1306], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,200][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.6572, 0.3224, 0.0205], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,202][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.5236, 0.2190, 0.2573], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,205][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.4392, 0.3816, 0.1792], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,209][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6610, 0.0749, 0.2057, 0.0584], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,211][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([2.3017e-03, 3.9234e-02, 8.1863e-04, 9.5765e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,214][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2353, 0.1761, 0.0466, 0.5420], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,214][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1113, 0.3804, 0.0429, 0.4654], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,215][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3385, 0.1534, 0.2304, 0.2777], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,216][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1223, 0.1958, 0.0133, 0.6687], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,217][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6231, 0.0298, 0.3245, 0.0226], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,220][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2391, 0.1819, 0.3053, 0.2738], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,222][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0676, 0.4735, 0.0149, 0.4440], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,227][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4279, 0.2390, 0.1111, 0.2220], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,230][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4137, 0.3081, 0.0749, 0.2033], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,232][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4308, 0.1882, 0.1351, 0.2459], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,232][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.2207, 0.3076, 0.1125, 0.2737, 0.0856], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,233][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([4.4943e-05, 2.8345e-05, 8.3632e-05, 9.1364e-05, 9.9975e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,234][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.4033, 0.2553, 0.0485, 0.1309, 0.1621], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,235][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([1.3587e-03, 1.6234e-05, 8.9551e-03, 6.2416e-05, 9.8961e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,236][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0214, 0.0051, 0.2061, 0.0039, 0.7634], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,238][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([1.0226e-02, 2.0678e-07, 2.4745e-04, 1.0245e-07, 9.8953e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,241][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.3152, 0.2578, 0.1869, 0.1163, 0.1238], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,245][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.2195, 0.1771, 0.0938, 0.3809, 0.1287], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,249][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.4233, 0.2102, 0.0595, 0.2124, 0.0946], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,252][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.3911, 0.2352, 0.1643, 0.1939, 0.0155], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,253][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.2692, 0.2094, 0.1038, 0.1456, 0.2720], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,253][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.1465, 0.2862, 0.1148, 0.2728, 0.1798], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,254][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3776, 0.0332, 0.1267, 0.0330, 0.1386, 0.2909], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,255][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2175e-04, 1.6732e-03, 1.1890e-03, 2.8580e-03, 5.5910e-04, 9.9340e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,258][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4847, 0.1236, 0.0596, 0.1462, 0.0410, 0.1448], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,259][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([4.9410e-03, 5.4305e-03, 4.4877e-04, 1.1491e-02, 1.6112e-03, 9.7608e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,263][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2316, 0.0659, 0.0282, 0.1192, 0.0633, 0.4918], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,265][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9815e-02, 1.8580e-03, 4.9519e-04, 1.2917e-03, 4.3657e-05, 9.5650e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,269][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2900, 0.0217, 0.2461, 0.0203, 0.3928, 0.0291], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,270][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1348, 0.1050, 0.1131, 0.2437, 0.1004, 0.3030], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,271][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0945, 0.2654, 0.0328, 0.3486, 0.0430, 0.2157], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,272][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3074, 0.1853, 0.1011, 0.1910, 0.0860, 0.1291], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,273][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2481, 0.1913, 0.0831, 0.1401, 0.0331, 0.3043], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,276][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4076, 0.1361, 0.1064, 0.1698, 0.0943, 0.0858], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,280][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4302, 0.0496, 0.2258, 0.0375, 0.1620, 0.0617, 0.0332],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,282][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5636e-04, 4.3037e-03, 5.9795e-04, 4.3017e-03, 4.7025e-04, 4.6871e-04,
        9.8900e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,285][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3026, 0.1877, 0.0591, 0.2213, 0.0572, 0.1253, 0.0468],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,287][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0294, 0.0180, 0.0084, 0.0332, 0.0129, 0.1794, 0.7188],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,288][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1418, 0.0312, 0.0706, 0.0439, 0.0548, 0.4433, 0.2145],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,289][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0559, 0.1297, 0.0039, 0.0970, 0.0021, 0.0448, 0.6666],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,290][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2669, 0.0089, 0.2462, 0.0076, 0.4225, 0.0393, 0.0087],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,292][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0981, 0.0590, 0.0549, 0.1318, 0.1309, 0.2211, 0.3043],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,294][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0241, 0.1312, 0.0078, 0.1949, 0.0072, 0.1424, 0.4924],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,298][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2664, 0.1706, 0.0700, 0.1731, 0.0761, 0.1074, 0.1365],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,301][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2262, 0.1928, 0.0627, 0.1635, 0.0451, 0.0837, 0.2261],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,305][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3142, 0.1259, 0.1214, 0.1353, 0.1179, 0.0812, 0.1042],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,306][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.3515, 0.0778, 0.0903, 0.0821, 0.1432, 0.0733, 0.0869, 0.0949],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,307][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([2.6501e-04, 1.0296e-03, 4.6497e-04, 1.2104e-03, 1.3019e-04, 1.3691e-03,
        5.0388e-04, 9.9503e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,308][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2839, 0.1097, 0.0587, 0.1962, 0.0937, 0.1458, 0.0757, 0.0363],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,309][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([1.0773e-03, 1.2863e-04, 1.4084e-05, 2.5223e-04, 2.3858e-04, 2.0045e-03,
        1.6743e-03, 9.9461e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,312][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0459, 0.0142, 0.0093, 0.0158, 0.0283, 0.0606, 0.0714, 0.7544],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,314][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([3.2519e-03, 1.1956e-04, 4.0515e-05, 1.7791e-05, 5.3349e-06, 9.6468e-06,
        5.2876e-06, 9.9655e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,318][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.2618, 0.0566, 0.2050, 0.0330, 0.1700, 0.0374, 0.0489, 0.1874],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,322][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0913, 0.0492, 0.0417, 0.0969, 0.0641, 0.1572, 0.2905, 0.2091],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,323][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.1244, 0.1511, 0.0508, 0.1397, 0.0265, 0.1140, 0.3384, 0.0552],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,324][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.2294, 0.1455, 0.0963, 0.1408, 0.1134, 0.0945, 0.1213, 0.0587],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,325][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.2127, 0.1528, 0.0497, 0.1263, 0.0253, 0.0852, 0.0850, 0.2630],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,326][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.4368, 0.0837, 0.1104, 0.0866, 0.0794, 0.0591, 0.0436, 0.1004],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,327][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3380, 0.0531, 0.1692, 0.0382, 0.1239, 0.0697, 0.0464, 0.1318, 0.0296],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,329][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([8.9865e-04, 1.5859e-02, 1.5713e-04, 2.1563e-02, 1.8229e-05, 6.7597e-04,
        3.8734e-04, 9.5693e-05, 9.6034e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,334][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3047, 0.1443, 0.0535, 0.1342, 0.0376, 0.0776, 0.0615, 0.0855, 0.1010],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,337][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0052, 0.0030, 0.0017, 0.0070, 0.0039, 0.0454, 0.0610, 0.3732, 0.4996],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,341][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1570, 0.0214, 0.0347, 0.0255, 0.0599, 0.1129, 0.0731, 0.3387, 0.1769],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,342][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0226, 0.0912, 0.0023, 0.1070, 0.0012, 0.0656, 0.2355, 0.0072, 0.4674],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,343][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1782, 0.0152, 0.1763, 0.0134, 0.3810, 0.0347, 0.0140, 0.1777, 0.0095],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,343][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0552, 0.0267, 0.0191, 0.0559, 0.0422, 0.1106, 0.1871, 0.2777, 0.2253],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,346][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0230, 0.1178, 0.0080, 0.1841, 0.0103, 0.1240, 0.3544, 0.0216, 0.1568],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,349][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.2050, 0.1339, 0.0618, 0.1371, 0.0614, 0.0859, 0.1118, 0.0800, 0.1231],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,352][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.1709, 0.1584, 0.0440, 0.1498, 0.0224, 0.0774, 0.0920, 0.0598, 0.2253],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,356][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.2348, 0.1021, 0.1231, 0.1204, 0.1387, 0.0702, 0.0758, 0.0901, 0.0450],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,359][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.1683, 0.0679, 0.3409, 0.0623, 0.1110, 0.0237, 0.0595, 0.0661, 0.0367,
        0.0637], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,360][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([1.4100e-04, 4.5758e-05, 3.4915e-04, 3.7542e-05, 2.3278e-04, 2.0440e-05,
        1.1355e-03, 8.8549e-04, 1.7993e-05, 9.9713e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,360][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1879, 0.0652, 0.0916, 0.1041, 0.1095, 0.0946, 0.0868, 0.0700, 0.0960,
        0.0942], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,361][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([4.4575e-04, 8.2961e-06, 9.6069e-06, 8.7104e-06, 1.4603e-04, 2.8327e-04,
        2.2892e-04, 1.8481e-03, 2.9445e-04, 9.9673e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,363][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0122, 0.0021, 0.0018, 0.0024, 0.0104, 0.0102, 0.0107, 0.0138, 0.0095,
        0.9268], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,365][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([4.2287e-03, 2.8179e-05, 1.3027e-05, 3.7848e-06, 4.1827e-06, 4.2787e-07,
        1.7981e-06, 1.4493e-04, 2.7550e-07, 9.9557e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,369][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1495, 0.0317, 0.2453, 0.0247, 0.2678, 0.0208, 0.0225, 0.0986, 0.0269,
        0.1121], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,373][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0941, 0.0235, 0.0174, 0.0505, 0.0157, 0.0698, 0.1394, 0.1962, 0.2637,
        0.1298], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,377][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1202, 0.1110, 0.1096, 0.1648, 0.0254, 0.0972, 0.1818, 0.0596, 0.0958,
        0.0345], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,378][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1880, 0.1148, 0.0937, 0.1097, 0.0817, 0.0825, 0.0946, 0.0766, 0.1013,
        0.0571], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,379][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1332, 0.1038, 0.0523, 0.1008, 0.0390, 0.0570, 0.0838, 0.0874, 0.0724,
        0.2701], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,379][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.2974, 0.1481, 0.0970, 0.1104, 0.0582, 0.0673, 0.0622, 0.0438, 0.0518,
        0.0637], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,382][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2376, 0.0336, 0.0977, 0.0310, 0.1362, 0.0436, 0.0486, 0.1284, 0.0303,
        0.1901, 0.0229], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,383][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([7.4917e-04, 1.5256e-03, 1.4653e-04, 3.7668e-03, 1.0304e-04, 1.5081e-04,
        1.4849e-03, 3.0395e-05, 4.3048e-03, 3.3114e-05, 9.8770e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,388][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1980, 0.1022, 0.0312, 0.1208, 0.0500, 0.0800, 0.0448, 0.0632, 0.1170,
        0.0797, 0.1132], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,390][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.0224e-03, 3.5278e-04, 3.7558e-05, 6.9247e-04, 1.3797e-04, 4.8617e-03,
        7.4773e-03, 3.9671e-03, 3.0006e-02, 1.3053e-01, 8.2092e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,394][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0618, 0.0063, 0.0112, 0.0095, 0.0092, 0.0580, 0.0342, 0.0467, 0.0706,
        0.3775, 0.3150], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,395][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([5.4687e-02, 2.3155e-02, 1.6722e-03, 9.6792e-03, 8.2506e-04, 3.6403e-02,
        1.6092e-02, 1.2100e-03, 3.8695e-03, 9.3844e-04, 8.5147e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,396][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.1496, 0.0114, 0.1673, 0.0112, 0.2763, 0.0366, 0.0144, 0.1588, 0.0110,
        0.1456, 0.0178], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,397][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0369, 0.0125, 0.0063, 0.0283, 0.0159, 0.0471, 0.0827, 0.1106, 0.1274,
        0.1945, 0.3379], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,399][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0241, 0.1166, 0.0075, 0.2114, 0.0054, 0.1124, 0.1979, 0.0246, 0.1670,
        0.0262, 0.1070], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,402][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.1528, 0.1066, 0.0480, 0.1154, 0.0440, 0.0798, 0.0922, 0.0710, 0.1112,
        0.0741, 0.1048], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,406][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1445, 0.1118, 0.0395, 0.1151, 0.0339, 0.0839, 0.0970, 0.0349, 0.0929,
        0.0305, 0.2160], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,410][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.2435, 0.0835, 0.0883, 0.0866, 0.0843, 0.0517, 0.0451, 0.0815, 0.0454,
        0.0790, 0.1111], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,412][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3575, 0.0303, 0.1358, 0.0196, 0.1390, 0.0396, 0.0173, 0.0771, 0.0174,
        0.1266, 0.0186, 0.0212], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,413][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([2.9757e-03, 1.8214e-02, 2.3186e-04, 3.9249e-02, 1.3414e-04, 2.7156e-04,
        3.3105e-02, 8.6453e-05, 6.8765e-02, 7.4403e-05, 4.1123e-02, 7.9577e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,414][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1806, 0.0884, 0.0378, 0.0986, 0.0398, 0.0918, 0.0286, 0.0679, 0.1100,
        0.0611, 0.1664, 0.0291], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,415][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([1.0775e-02, 1.6536e-03, 5.9400e-04, 1.8832e-03, 9.2999e-04, 7.3255e-03,
        1.8900e-02, 1.2119e-02, 6.1563e-02, 5.5877e-02, 1.8263e-01, 6.4575e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,418][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1109, 0.0123, 0.0270, 0.0163, 0.0094, 0.0776, 0.0332, 0.0500, 0.0977,
        0.1406, 0.2305, 0.1944], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,422][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0667, 0.1045, 0.0068, 0.0855, 0.0027, 0.0639, 0.2097, 0.0509, 0.0550,
        0.0114, 0.0586, 0.2841], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,426][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.1463, 0.0024, 0.1643, 0.0023, 0.3811, 0.0141, 0.0027, 0.1233, 0.0020,
        0.1545, 0.0053, 0.0016], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,430][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0381, 0.0089, 0.0099, 0.0177, 0.0174, 0.0230, 0.0367, 0.0575, 0.0947,
        0.0972, 0.2939, 0.3051], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,431][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0084, 0.0712, 0.0046, 0.1146, 0.0060, 0.0746, 0.2403, 0.0078, 0.0763,
        0.0134, 0.0510, 0.3317], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,431][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.1684, 0.0951, 0.0509, 0.0986, 0.0489, 0.0691, 0.0788, 0.0644, 0.0916,
        0.0497, 0.0928, 0.0915], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,432][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.1746, 0.1069, 0.0449, 0.1065, 0.0435, 0.0544, 0.1117, 0.0415, 0.0640,
        0.0301, 0.0736, 0.1483], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,434][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1822, 0.0733, 0.0966, 0.0769, 0.1130, 0.0475, 0.0795, 0.0700, 0.0291,
        0.0728, 0.0724, 0.0865], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:16,437][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.1528, 0.0679, 0.1166, 0.0614, 0.2466, 0.0434, 0.0641, 0.0384, 0.0529,
        0.0275, 0.0476, 0.0635, 0.0172], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,439][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([9.8325e-04, 2.2841e-03, 2.7317e-04, 1.7927e-03, 8.4319e-04, 1.1721e-03,
        3.9979e-04, 3.1113e-03, 5.1556e-04, 1.2990e-03, 5.9053e-04, 9.8863e-04,
        9.8575e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,443][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1481, 0.0508, 0.1554, 0.0444, 0.1040, 0.0769, 0.0449, 0.0519, 0.0660,
        0.0888, 0.0684, 0.0506, 0.0497], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,446][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([2.6441e-04, 6.7580e-07, 3.6899e-06, 1.7833e-06, 1.5574e-06, 9.9486e-06,
        1.4848e-05, 9.9431e-04, 1.7502e-04, 3.6773e-03, 4.1685e-04, 3.5972e-04,
        9.9408e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,448][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0335, 0.0021, 0.0017, 0.0035, 0.0035, 0.0026, 0.0021, 0.0211, 0.0145,
        0.0291, 0.0311, 0.0256, 0.8298], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,449][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([1.1152e-02, 3.7609e-05, 1.8802e-05, 6.5195e-06, 1.9410e-05, 3.0193e-05,
        3.1775e-06, 1.7094e-04, 2.1964e-06, 2.0903e-05, 2.1613e-06, 1.7159e-06,
        9.8853e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,450][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.1927, 0.0395, 0.1202, 0.0248, 0.1951, 0.0154, 0.0173, 0.0454, 0.0171,
        0.1785, 0.0123, 0.0163, 0.1255], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,452][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0380, 0.0066, 0.0028, 0.0189, 0.0047, 0.0246, 0.0395, 0.0701, 0.0831,
        0.1364, 0.2090, 0.2716, 0.0947], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,455][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.1299, 0.0875, 0.0267, 0.1021, 0.0755, 0.0662, 0.0566, 0.0576, 0.0702,
        0.0909, 0.0975, 0.0905, 0.0488], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,459][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.1701, 0.0891, 0.0778, 0.0838, 0.0821, 0.0577, 0.0751, 0.0523, 0.0707,
        0.0734, 0.0701, 0.0817, 0.0162], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,463][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.1160, 0.0808, 0.0446, 0.0842, 0.0364, 0.0577, 0.0696, 0.0522, 0.0612,
        0.0303, 0.0572, 0.0650, 0.2448], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,465][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.2433, 0.0896, 0.0787, 0.0612, 0.0571, 0.0421, 0.0284, 0.0803, 0.0600,
        0.0747, 0.0942, 0.0257, 0.0647], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:16,466][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.4126, 0.0129, 0.0606, 0.0107, 0.1412, 0.0449, 0.0202, 0.0728, 0.0083,
        0.1004, 0.0156, 0.0343, 0.0562, 0.0093], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,467][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.9667e-03, 2.9770e-02, 2.1665e-04, 5.5114e-03, 5.3068e-04, 1.1793e-04,
        2.6020e-04, 2.2070e-04, 2.5129e-03, 7.6653e-05, 1.1372e-03, 2.5234e-04,
        4.5391e-05, 9.5638e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,468][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3460, 0.0442, 0.0418, 0.0378, 0.0199, 0.1936, 0.0175, 0.0467, 0.0833,
        0.0369, 0.0515, 0.0215, 0.0146, 0.0448], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,470][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0134, 0.0016, 0.0008, 0.0015, 0.0012, 0.0048, 0.0052, 0.0210, 0.0202,
        0.0214, 0.0693, 0.1881, 0.1391, 0.5124], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,473][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0275, 0.0093, 0.0049, 0.0177, 0.0052, 0.0192, 0.0164, 0.0405, 0.0541,
        0.0613, 0.1252, 0.1071, 0.2135, 0.2984], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,477][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.1025, 0.1630, 0.0250, 0.1045, 0.0200, 0.0722, 0.0785, 0.0328, 0.0516,
        0.0109, 0.0544, 0.0632, 0.0114, 0.2099], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,481][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2154, 0.0055, 0.1167, 0.0041, 0.2426, 0.0113, 0.0055, 0.0837, 0.0034,
        0.1767, 0.0072, 0.0036, 0.1216, 0.0027], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,483][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0177, 0.0043, 0.0074, 0.0079, 0.0084, 0.0119, 0.0181, 0.0297, 0.0309,
        0.0656, 0.0922, 0.1425, 0.1673, 0.3959], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,484][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0144, 0.1270, 0.0030, 0.1012, 0.0060, 0.0226, 0.0846, 0.0064, 0.0607,
        0.0048, 0.0401, 0.1369, 0.0071, 0.3852], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,485][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.1445, 0.0808, 0.0546, 0.0839, 0.0463, 0.0641, 0.0646, 0.0609, 0.0676,
        0.0604, 0.0708, 0.0729, 0.0396, 0.0889], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,487][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1080, 0.0911, 0.0378, 0.0981, 0.0437, 0.0742, 0.0607, 0.0638, 0.0761,
        0.0534, 0.0751, 0.0610, 0.0287, 0.1282], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,490][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.2069, 0.0721, 0.0841, 0.0685, 0.0750, 0.0483, 0.0418, 0.0668, 0.0341,
        0.0608, 0.0721, 0.0324, 0.0474, 0.0897], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:16,494][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.1046, 0.1132, 0.0506, 0.1079, 0.0438, 0.0111, 0.0538, 0.0201, 0.0717,
        0.0235, 0.0638, 0.0927, 0.0689, 0.1289, 0.0455], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,497][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([1.4961e-05, 4.2577e-06, 1.3227e-05, 1.7795e-05, 4.8046e-01, 6.4672e-06,
        2.7744e-05, 2.8884e-06, 1.3968e-06, 4.6432e-06, 9.4757e-06, 6.0464e-06,
        1.0968e-06, 1.1830e-06, 5.1943e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,501][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.1696, 0.0922, 0.0255, 0.0609, 0.1020, 0.0810, 0.0683, 0.0202, 0.0630,
        0.0282, 0.0545, 0.0678, 0.0094, 0.0551, 0.1024], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,502][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([8.9737e-05, 1.0026e-07, 4.0978e-05, 1.5664e-07, 6.8957e-03, 1.1123e-06,
        5.5578e-07, 1.1607e-06, 1.1935e-06, 2.4122e-05, 4.2385e-06, 4.2955e-06,
        7.0508e-06, 8.7775e-06, 9.9292e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,503][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([3.4359e-03, 5.0184e-04, 1.6341e-02, 2.9785e-04, 5.4693e-02, 4.3225e-04,
        4.0143e-04, 1.0055e-03, 1.0741e-03, 1.5392e-03, 1.4915e-03, 2.4166e-03,
        1.2870e-02, 9.3563e-03, 8.9414e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,504][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([2.3237e-03, 3.0941e-08, 8.1121e-05, 1.7562e-08, 5.8542e-01, 2.3655e-08,
        1.4999e-08, 5.4455e-08, 3.7546e-09, 9.8983e-08, 8.3061e-09, 6.5548e-09,
        7.3798e-08, 2.9111e-09, 4.1218e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,506][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.1618, 0.1159, 0.1138, 0.0594, 0.0886, 0.0214, 0.0868, 0.0204, 0.0321,
        0.0241, 0.0177, 0.0985, 0.0278, 0.0450, 0.0866], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,508][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0487, 0.0131, 0.0064, 0.0223, 0.0069, 0.0235, 0.0321, 0.0200, 0.0469,
        0.0313, 0.0980, 0.1584, 0.0756, 0.3280, 0.0890], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,512][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.1877, 0.0802, 0.0275, 0.0962, 0.0559, 0.0329, 0.0448, 0.0288, 0.0642,
        0.0549, 0.0602, 0.0527, 0.0692, 0.0839, 0.0610], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,517][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.1585, 0.0962, 0.0855, 0.0842, 0.0077, 0.0546, 0.0596, 0.0606, 0.0668,
        0.0507, 0.0569, 0.0693, 0.0546, 0.0876, 0.0071], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,519][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0779, 0.0616, 0.0532, 0.0631, 0.2557, 0.0346, 0.0428, 0.0159, 0.0390,
        0.0189, 0.0353, 0.0400, 0.0098, 0.0428, 0.2095], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,520][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0390, 0.0783, 0.0385, 0.0651, 0.0578, 0.0639, 0.0958, 0.0345, 0.0321,
        0.0624, 0.0786, 0.0754, 0.0358, 0.1560, 0.0866], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:16,521][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1752, 0.0172, 0.0523, 0.0207, 0.1136, 0.0859, 0.0164, 0.0418, 0.0202,
        0.0335, 0.0165, 0.0153, 0.0328, 0.0138, 0.1557, 0.1891],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,523][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([3.7470e-04, 5.8173e-04, 4.2451e-04, 1.2650e-03, 5.8211e-04, 6.5316e-03,
        1.4106e-04, 3.2810e-04, 7.6502e-04, 1.2319e-04, 3.5758e-04, 1.7559e-04,
        5.8528e-04, 5.0827e-05, 4.5461e-04, 9.8726e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,525][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.1699, 0.0426, 0.0637, 0.0513, 0.0200, 0.0764, 0.0441, 0.0575, 0.0733,
        0.0644, 0.0723, 0.0543, 0.0427, 0.0721, 0.0194, 0.0761],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,528][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([8.5744e-04, 4.5938e-06, 9.5285e-07, 3.9909e-06, 4.2257e-06, 4.5503e-05,
        1.1782e-05, 3.8576e-05, 4.7080e-05, 2.9182e-04, 1.4093e-04, 2.0620e-04,
        2.0621e-03, 6.5111e-04, 1.0325e-03, 9.9460e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,532][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0833, 0.0065, 0.0132, 0.0065, 0.0072, 0.0107, 0.0075, 0.0102, 0.0190,
        0.0227, 0.0395, 0.0215, 0.0284, 0.0430, 0.0682, 0.6127],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,535][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([3.9536e-02, 2.1612e-05, 4.9793e-05, 2.1873e-05, 3.0548e-05, 1.8039e-03,
        1.2768e-05, 7.0413e-06, 5.9636e-06, 5.3260e-05, 1.5033e-05, 7.0798e-06,
        6.4643e-05, 1.0706e-06, 1.0802e-05, 9.5836e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,536][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0800, 0.0100, 0.0928, 0.0098, 0.1785, 0.0119, 0.0143, 0.0644, 0.0074,
        0.1235, 0.0086, 0.0111, 0.0787, 0.0103, 0.2742, 0.0245],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,537][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0194, 0.0043, 0.0092, 0.0064, 0.0048, 0.0064, 0.0123, 0.0143, 0.0158,
        0.0250, 0.0579, 0.0798, 0.0738, 0.3192, 0.1191, 0.2322],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,538][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0713, 0.0704, 0.0183, 0.0892, 0.0228, 0.0386, 0.1015, 0.0349, 0.0786,
        0.0632, 0.0732, 0.1231, 0.0533, 0.0956, 0.0311, 0.0348],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,539][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.1158, 0.0635, 0.0511, 0.0674, 0.0307, 0.0627, 0.0563, 0.0563, 0.0622,
        0.0765, 0.0563, 0.0606, 0.0509, 0.0913, 0.0364, 0.0619],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,541][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0781, 0.0550, 0.0410, 0.0621, 0.0385, 0.1034, 0.0506, 0.0302, 0.0533,
        0.0334, 0.0550, 0.0486, 0.0311, 0.0654, 0.0392, 0.2155],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,544][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.2174, 0.0767, 0.0551, 0.0917, 0.0442, 0.0403, 0.0368, 0.0464, 0.0389,
        0.0450, 0.0681, 0.0330, 0.0277, 0.0826, 0.0419, 0.0542],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:16,548][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2149, 0.0170, 0.1000, 0.0131, 0.0807, 0.0274, 0.0118, 0.0523, 0.0111,
        0.0904, 0.0110, 0.0208, 0.0810, 0.0155, 0.1231, 0.1118, 0.0181],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,550][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([4.3930e-04, 1.1436e-03, 1.4272e-04, 1.2521e-03, 1.8364e-04, 1.3496e-04,
        4.3330e-01, 1.8446e-04, 1.1690e-03, 9.9728e-04, 3.4123e-03, 1.4676e-02,
        5.5866e-05, 2.8413e-04, 1.3519e-04, 1.1750e-04, 5.4237e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,554][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1013, 0.0518, 0.0237, 0.0790, 0.0247, 0.0475, 0.0161, 0.0600, 0.0795,
        0.0448, 0.1206, 0.0187, 0.0283, 0.1678, 0.0283, 0.0898, 0.0181],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,555][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.5945e-03, 2.7315e-04, 7.1642e-05, 1.7487e-04, 7.8145e-05, 3.7612e-04,
        1.3098e-03, 5.5454e-04, 1.7469e-03, 1.7553e-03, 4.7715e-03, 1.9503e-02,
        9.7766e-03, 2.8949e-02, 1.1644e-02, 1.3225e-01, 7.8318e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,556][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0234, 0.0028, 0.0042, 0.0030, 0.0023, 0.0195, 0.0077, 0.0072, 0.0117,
        0.0271, 0.0256, 0.0195, 0.0307, 0.0227, 0.0259, 0.5673, 0.1996],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,557][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.6615e-02, 5.2937e-02, 1.6682e-03, 4.6453e-02, 9.3218e-04, 2.4860e-02,
        4.1671e-01, 3.8525e-03, 2.4939e-02, 4.2895e-03, 3.1539e-02, 1.0146e-01,
        2.2507e-03, 1.3200e-02, 3.6041e-04, 3.8649e-03, 2.5407e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,560][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0803, 0.0019, 0.0800, 0.0018, 0.1691, 0.0118, 0.0020, 0.0767, 0.0020,
        0.0971, 0.0040, 0.0016, 0.1067, 0.0017, 0.3072, 0.0532, 0.0031],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,564][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0141, 0.0026, 0.0021, 0.0040, 0.0035, 0.0036, 0.0041, 0.0075, 0.0097,
        0.0121, 0.0305, 0.0357, 0.0325, 0.2028, 0.0939, 0.2786, 0.2627],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,568][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0069, 0.0340, 0.0023, 0.0596, 0.0025, 0.0463, 0.1371, 0.0065, 0.0439,
        0.0112, 0.0356, 0.1963, 0.0085, 0.1004, 0.0040, 0.0235, 0.2811],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,572][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1077, 0.0659, 0.0329, 0.0725, 0.0397, 0.0487, 0.0567, 0.0478, 0.0670,
        0.0421, 0.0662, 0.0682, 0.0331, 0.0716, 0.0462, 0.0613, 0.0722],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,573][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0740, 0.0575, 0.0297, 0.0679, 0.0332, 0.0450, 0.1258, 0.0338, 0.0539,
        0.0386, 0.0694, 0.0812, 0.0285, 0.0548, 0.0327, 0.0359, 0.1381],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,574][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1661, 0.0623, 0.0698, 0.0595, 0.0619, 0.0404, 0.0456, 0.0527, 0.0261,
        0.0511, 0.0519, 0.0337, 0.0423, 0.0672, 0.0615, 0.0631, 0.0447],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:16,575][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.1099, 0.0643, 0.0548, 0.0703, 0.0328, 0.0275, 0.0393, 0.0462, 0.0605,
        0.0587, 0.0401, 0.0398, 0.0141, 0.0345, 0.0343, 0.0462, 0.0443, 0.1823],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,576][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([7.1459e-05, 5.9163e-05, 9.0129e-04, 4.5736e-05, 1.2833e-05, 2.3660e-05,
        5.3249e-05, 8.3573e-05, 7.2006e-05, 1.5781e-04, 4.5170e-05, 1.2666e-05,
        3.0526e-06, 2.7359e-05, 6.1646e-06, 1.2491e-05, 3.2863e-05, 9.9838e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,579][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.1125, 0.0466, 0.0490, 0.0530, 0.0197, 0.0432, 0.0714, 0.0628, 0.0527,
        0.0437, 0.0482, 0.0856, 0.0461, 0.0470, 0.0183, 0.0641, 0.0780, 0.0581],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,581][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([1.2750e-03, 6.3989e-07, 6.2620e-06, 8.5495e-07, 7.5481e-06, 3.8642e-06,
        2.8841e-06, 1.0340e-04, 7.9588e-06, 1.2214e-04, 4.9076e-05, 3.3661e-05,
        2.3334e-03, 1.0157e-04, 1.1880e-03, 4.1492e-03, 1.3563e-03, 9.8926e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,583][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([1.1403e-02, 1.0489e-03, 1.3461e-03, 6.6336e-04, 1.7129e-03, 5.0707e-04,
        7.1643e-04, 1.3456e-03, 2.0491e-03, 5.5053e-03, 3.2737e-03, 1.7506e-03,
        4.8050e-03, 4.3265e-03, 1.0640e-02, 5.1780e-03, 8.4297e-03, 9.3530e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,586][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([8.9177e-03, 6.1030e-06, 2.6166e-04, 1.3552e-06, 1.6804e-05, 5.3777e-07,
        5.0838e-07, 2.2967e-05, 2.1898e-07, 9.4061e-06, 3.0668e-07, 1.8320e-07,
        2.9675e-08, 1.0952e-07, 5.4429e-06, 8.9393e-08, 1.5547e-07, 9.9076e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,590][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0957, 0.0493, 0.0760, 0.0398, 0.0847, 0.0188, 0.0383, 0.0266, 0.0227,
        0.0738, 0.0184, 0.0452, 0.0784, 0.0287, 0.0918, 0.0378, 0.0438, 0.1300],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,591][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0273, 0.0056, 0.0016, 0.0102, 0.0013, 0.0073, 0.0099, 0.0100, 0.0199,
        0.0116, 0.0407, 0.0417, 0.0117, 0.1646, 0.0168, 0.2049, 0.3152, 0.0995],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,592][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.1307, 0.0549, 0.0288, 0.0605, 0.0097, 0.0370, 0.0733, 0.0229, 0.0408,
        0.0397, 0.0632, 0.0667, 0.0154, 0.0468, 0.0091, 0.0404, 0.0838, 0.1763],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,594][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.0976, 0.0618, 0.0602, 0.0627, 0.0500, 0.0458, 0.0480, 0.0437, 0.0579,
        0.0715, 0.0491, 0.0472, 0.0594, 0.0717, 0.0594, 0.0466, 0.0603, 0.0070],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,596][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0981, 0.0590, 0.0452, 0.0605, 0.0254, 0.0441, 0.0452, 0.0397, 0.0550,
        0.0369, 0.0360, 0.0406, 0.0126, 0.0582, 0.0245, 0.0250, 0.0465, 0.2476],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,600][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.1184, 0.0571, 0.0504, 0.0444, 0.0483, 0.0486, 0.0324, 0.0691, 0.0637,
        0.0717, 0.0665, 0.0214, 0.0422, 0.0658, 0.0516, 0.0740, 0.0344, 0.0401],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:16,605][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1958, 0.0172, 0.0597, 0.0144, 0.0810, 0.0478, 0.0152, 0.0491, 0.0158,
        0.0543, 0.0146, 0.0229, 0.0554, 0.0158, 0.1247, 0.1280, 0.0248, 0.0497,
        0.0138], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,607][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.0630e-03, 8.9823e-03, 3.7421e-04, 2.6116e-02, 5.8047e-05, 2.3089e-04,
        1.0624e-03, 3.7205e-05, 2.5753e-02, 1.8236e-04, 1.4917e-02, 1.4069e-03,
        6.7676e-05, 6.9801e-03, 4.3202e-05, 6.6493e-04, 9.9137e-04, 1.7513e-05,
        9.0805e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,608][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1051, 0.0429, 0.0244, 0.0624, 0.0141, 0.0384, 0.0159, 0.0459, 0.0674,
        0.0356, 0.0919, 0.0189, 0.0219, 0.1889, 0.0149, 0.0540, 0.0177, 0.0134,
        0.1264], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,609][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.1800e-03, 6.2231e-05, 1.1604e-05, 2.9840e-05, 2.7237e-05, 7.1207e-05,
        9.9280e-05, 2.9611e-05, 3.8678e-04, 2.5971e-04, 5.8756e-04, 2.3874e-03,
        6.5766e-04, 4.3242e-03, 3.6878e-03, 2.4704e-01, 7.0210e-02, 3.2698e-02,
        6.3625e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,610][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0224, 0.0012, 0.0030, 0.0018, 0.0016, 0.0120, 0.0032, 0.0050, 0.0044,
        0.0287, 0.0112, 0.0084, 0.0112, 0.0137, 0.0185, 0.4027, 0.0904, 0.0616,
        0.2989], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,612][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0297, 0.0435, 0.0017, 0.0586, 0.0022, 0.0250, 0.1855, 0.0075, 0.0394,
        0.0096, 0.0167, 0.1355, 0.0015, 0.0165, 0.0010, 0.0049, 0.1147, 0.0006,
        0.3057], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,614][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0704, 0.0031, 0.0425, 0.0027, 0.1124, 0.0095, 0.0025, 0.0302, 0.0038,
        0.0860, 0.0137, 0.0022, 0.0476, 0.0038, 0.2175, 0.0456, 0.0042, 0.0545,
        0.2479], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,618][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0157, 0.0023, 0.0016, 0.0031, 0.0037, 0.0028, 0.0033, 0.0046, 0.0041,
        0.0120, 0.0119, 0.0197, 0.0212, 0.0982, 0.0702, 0.1299, 0.1710, 0.1281,
        0.2969], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,623][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0054, 0.0389, 0.0020, 0.0698, 0.0027, 0.0316, 0.0855, 0.0057, 0.0497,
        0.0059, 0.0339, 0.1528, 0.0064, 0.1179, 0.0043, 0.0175, 0.1684, 0.0087,
        0.1927], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,625][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0927, 0.0551, 0.0370, 0.0623, 0.0283, 0.0424, 0.0529, 0.0420, 0.0564,
        0.0448, 0.0565, 0.0606, 0.0297, 0.0636, 0.0325, 0.0557, 0.0679, 0.0349,
        0.0848], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,626][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0713, 0.0545, 0.0261, 0.0701, 0.0270, 0.0549, 0.0632, 0.0346, 0.0625,
        0.0399, 0.0630, 0.0631, 0.0262, 0.0674, 0.0278, 0.0551, 0.0702, 0.0248,
        0.0982], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,627][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1507, 0.0581, 0.0620, 0.0587, 0.0629, 0.0432, 0.0380, 0.0462, 0.0273,
        0.0452, 0.0547, 0.0272, 0.0352, 0.0583, 0.0602, 0.0603, 0.0353, 0.0217,
        0.0547], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:16,630][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:16,632][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[39726],
        [35983],
        [    1],
        [32706],
        [ 3107],
        [24064],
        [36906],
        [ 8511],
        [23741],
        [18597],
        [41530],
        [29561],
        [29205],
        [23029],
        [ 3855],
        [21041],
        [35060],
        [39774],
        [29260]], device='cuda:0')
[2024-07-24 10:27:16,635][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[44332],
        [42618],
        [    1],
        [45234],
        [ 3382],
        [48154],
        [39552],
        [43940],
        [43817],
        [47827],
        [38435],
        [33836],
        [46789],
        [40932],
        [ 1306],
        [43807],
        [27716],
        [38714],
        [36913]], device='cuda:0')
[2024-07-24 10:27:16,638][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[10737],
        [ 8680],
        [   45],
        [  656],
        [   42],
        [  478],
        [   30],
        [   98],
        [   74],
        [    7],
        [  194],
        [  135],
        [   27],
        [  396],
        [  139],
        [  203],
        [  120],
        [  222],
        [  165]], device='cuda:0')
[2024-07-24 10:27:16,640][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18219],
        [12840],
        [29841],
        [38109],
        [29816],
        [41661],
        [47098],
        [10322],
        [35619],
        [24049],
        [46304],
        [47729],
        [17639],
        [18130],
        [29340],
        [39164],
        [46928],
        [42162],
        [40232]], device='cuda:0')
[2024-07-24 10:27:16,643][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[11266],
        [10917],
        [10168],
        [32287],
        [17062],
        [20659],
        [23869],
        [24144],
        [21228],
        [22493],
        [22321],
        [21422],
        [20329],
        [21916],
        [20921],
        [23099],
        [27522],
        [18849],
        [26157]], device='cuda:0')
[2024-07-24 10:27:16,646][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[26198],
        [30442],
        [  727],
        [27140],
        [ 5196],
        [ 1779],
        [ 4449],
        [ 1681],
        [ 4819],
        [  439],
        [ 6441],
        [ 3750],
        [18473],
        [24510],
        [ 5312],
        [ 9381],
        [ 6961],
        [13988],
        [10631]], device='cuda:0')
[2024-07-24 10:27:16,647][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[28804],
        [28245],
        [   24],
        [ 2629],
        [ 2237],
        [17969],
        [14379],
        [12961],
        [ 9501],
        [ 9260],
        [ 9097],
        [ 9605],
        [43569],
        [ 7408],
        [ 5360],
        [11651],
        [14240],
        [47587],
        [ 9981]], device='cuda:0')
[2024-07-24 10:27:16,649][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[43294],
        [44272],
        [15359],
        [43670],
        [48520],
        [43323],
        [34903],
        [33186],
        [40668],
        [39037],
        [43253],
        [38526],
        [38100],
        [42816],
        [48474],
        [42344],
        [32880],
        [43831],
        [37222]], device='cuda:0')
[2024-07-24 10:27:16,650][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[36662],
        [36418],
        [ 1526],
        [  771],
        [ 2482],
        [   74],
        [   86],
        [ 1349],
        [  534],
        [   28],
        [  228],
        [  224],
        [  465],
        [ 1020],
        [ 4821],
        [  511],
        [ 1336],
        [ 3936],
        [ 3370]], device='cuda:0')
[2024-07-24 10:27:16,653][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 8524],
        [ 7411],
        [ 4149],
        [ 9748],
        [16692],
        [21608],
        [23202],
        [23234],
        [26148],
        [24013],
        [19182],
        [15951],
        [18148],
        [22480],
        [22942],
        [28079],
        [26012],
        [22622],
        [31955]], device='cuda:0')
[2024-07-24 10:27:16,656][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11929],
        [31202],
        [15034],
        [37597],
        [19264],
        [36203],
        [41086],
        [35516],
        [39379],
        [28990],
        [35616],
        [36440],
        [17551],
        [27241],
        [13065],
        [21890],
        [35564],
        [26325],
        [33894]], device='cuda:0')
[2024-07-24 10:27:16,659][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[40667],
        [42960],
        [43200],
        [42846],
        [42845],
        [41456],
        [40717],
        [40575],
        [40971],
        [40251],
        [40059],
        [39737],
        [38992],
        [38739],
        [38955],
        [36448],
        [36995],
        [34964],
        [36288]], device='cuda:0')
[2024-07-24 10:27:16,661][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[12933],
        [13437],
        [16476],
        [14260],
        [14723],
        [13768],
        [21214],
        [13961],
        [13661],
        [25056],
        [15603],
        [22463],
        [23936],
        [14247],
        [19932],
        [13350],
        [25109],
        [24613],
        [17355]], device='cuda:0')
[2024-07-24 10:27:16,664][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[34509],
        [39324],
        [38178],
        [38530],
        [34055],
        [34889],
        [34633],
        [33556],
        [31493],
        [34918],
        [30881],
        [31989],
        [30065],
        [30816],
        [27849],
        [29681],
        [25073],
        [22393],
        [24217]], device='cuda:0')
[2024-07-24 10:27:16,667][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[48329],
        [29137],
        [    8],
        [41192],
        [ 5025],
        [36769],
        [42226],
        [16097],
        [26222],
        [29813],
        [31261],
        [36145],
        [30614],
        [24056],
        [ 4301],
        [42728],
        [41048],
        [43790],
        [35738]], device='cuda:0')
[2024-07-24 10:27:16,668][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[25916],
        [24927],
        [13983],
        [18027],
        [18090],
        [15516],
        [16881],
        [18150],
        [15649],
        [11856],
        [15223],
        [15692],
        [16832],
        [18087],
        [16364],
        [20825],
        [18529],
        [13912],
        [19157]], device='cuda:0')
[2024-07-24 10:27:16,670][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[24088],
        [41856],
        [37046],
        [24874],
        [20155],
        [30755],
        [18848],
        [44910],
        [17649],
        [44407],
        [20606],
        [18766],
        [38309],
        [38692],
        [24383],
        [46470],
        [24931],
        [38544],
        [23562]], device='cuda:0')
[2024-07-24 10:27:16,672][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[42886],
        [22804],
        [28627],
        [17642],
        [25846],
        [33661],
        [24879],
        [30628],
        [27245],
        [34282],
        [27482],
        [27232],
        [35659],
        [35386],
        [31932],
        [34065],
        [28852],
        [34490],
        [23585]], device='cuda:0')
[2024-07-24 10:27:16,674][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[21802],
        [24824],
        [26231],
        [29263],
        [34861],
        [22822],
        [22245],
        [26658],
        [27543],
        [35678],
        [34484],
        [25304],
        [22429],
        [28172],
        [40716],
        [34402],
        [34340],
        [32707],
        [37588]], device='cuda:0')
[2024-07-24 10:27:16,677][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 9310],
        [ 9582],
        [36064],
        [18476],
        [30928],
        [13664],
        [14238],
        [22672],
        [17003],
        [28573],
        [21907],
        [18114],
        [24969],
        [22527],
        [26953],
        [13601],
        [10504],
        [15405],
        [12774]], device='cuda:0')
[2024-07-24 10:27:16,680][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[15096],
        [39653],
        [33612],
        [42113],
        [31721],
        [30854],
        [41273],
        [27563],
        [40525],
        [15244],
        [38415],
        [39753],
        [37543],
        [41030],
        [29984],
        [29851],
        [40805],
        [24393],
        [40248]], device='cuda:0')
[2024-07-24 10:27:16,682][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[40871],
        [41264],
        [24364],
        [10634],
        [36849],
        [ 8094],
        [ 7332],
        [10446],
        [ 6396],
        [ 4428],
        [ 4924],
        [ 5043],
        [10479],
        [ 8092],
        [46530],
        [11846],
        [12307],
        [27505],
        [18423]], device='cuda:0')
[2024-07-24 10:27:16,685][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[44495],
        [44202],
        [45327],
        [45782],
        [40699],
        [38595],
        [36149],
        [36879],
        [39818],
        [42511],
        [42647],
        [41667],
        [41926],
        [45038],
        [42285],
        [41183],
        [35959],
        [33542],
        [33927]], device='cuda:0')
[2024-07-24 10:27:16,688][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[28268],
        [ 9058],
        [14376],
        [12754],
        [18276],
        [15607],
        [ 8308],
        [10305],
        [ 8898],
        [11792],
        [10078],
        [ 9672],
        [13189],
        [ 6387],
        [13576],
        [10156],
        [ 7689],
        [12355],
        [ 7683]], device='cuda:0')
[2024-07-24 10:27:16,689][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[22585],
        [17551],
        [17435],
        [18899],
        [20658],
        [24308],
        [23049],
        [26120],
        [22542],
        [24803],
        [22265],
        [22784],
        [25002],
        [22242],
        [22071],
        [24457],
        [24480],
        [26596],
        [24136]], device='cuda:0')
[2024-07-24 10:27:16,691][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[44098],
        [48477],
        [46607],
        [48843],
        [46680],
        [47573],
        [47742],
        [48013],
        [48564],
        [46502],
        [48019],
        [47842],
        [47269],
        [48628],
        [44796],
        [46952],
        [47511],
        [47521],
        [48227]], device='cuda:0')
[2024-07-24 10:27:16,692][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7991],
        [13543],
        [44273],
        [36318],
        [43360],
        [40114],
        [44009],
        [36092],
        [46704],
        [45974],
        [47763],
        [47139],
        [47520],
        [46597],
        [45609],
        [46240],
        [47026],
        [47189],
        [46710]], device='cuda:0')
[2024-07-24 10:27:16,695][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 5134],
        [ 4502],
        [ 6192],
        [ 7465],
        [ 5752],
        [ 9551],
        [10987],
        [ 7080],
        [ 9695],
        [ 8163],
        [ 9911],
        [ 9917],
        [ 6422],
        [ 6568],
        [ 6354],
        [ 6666],
        [ 8167],
        [ 5919],
        [ 6745]], device='cuda:0')
[2024-07-24 10:27:16,698][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 1375],
        [15802],
        [50232],
        [ 5955],
        [41758],
        [ 9938],
        [ 5299],
        [28366],
        [17928],
        [15429],
        [14769],
        [ 9180],
        [15806],
        [21089],
        [42994],
        [ 5429],
        [ 6173],
        [ 4698],
        [10231]], device='cuda:0')
[2024-07-24 10:27:16,700][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974],
        [26974]], device='cuda:0')
[2024-07-24 10:27:16,727][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:16,730][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,730][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,731][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,732][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,733][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,733][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,734][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,735][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,735][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,738][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,740][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,741][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:16,742][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2052, 0.7948], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,743][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6513, 0.3487], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,745][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6206, 0.3794], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,748][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4937, 0.5063], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,752][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.5982, 0.4018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,756][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4108, 0.5892], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,758][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9879, 0.0121], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,759][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9779, 0.0221], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,760][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9013, 0.0987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,761][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0083, 0.9917], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,762][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2400, 0.7600], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,765][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4448, 0.5552], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:16,769][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.1157, 0.6146, 0.2696], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,773][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([0.1210, 0.3568, 0.5221], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,776][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.4259, 0.2915, 0.2826], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,777][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.3034, 0.2604, 0.4362], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,777][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.6843, 0.2690, 0.0467], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,778][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([0.1918, 0.5529, 0.2553], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,779][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.2118, 0.0558, 0.7324], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,781][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.6509, 0.1095, 0.2396], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,784][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.7384, 0.2545, 0.0071], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,787][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.0142, 0.7042, 0.2815], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,791][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.1422, 0.3912, 0.4666], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,795][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.0988, 0.0273, 0.8739], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:16,796][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0644, 0.2997, 0.1603, 0.4757], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,797][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0459, 0.1666, 0.7758, 0.0117], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,798][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3298, 0.2103, 0.2270, 0.2330], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,799][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1492, 0.1006, 0.6232, 0.1269], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,801][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3907, 0.2595, 0.0565, 0.2932], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,803][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1164, 0.7722, 0.0165, 0.0949], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,807][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3919, 0.0665, 0.3675, 0.1742], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,811][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5432, 0.0556, 0.1946, 0.2067], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,814][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5211, 0.1145, 0.0148, 0.3496], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,815][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0039, 0.4910, 0.1569, 0.3482], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,815][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1004, 0.2845, 0.3716, 0.2435], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,816][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1580, 0.4023, 0.0284, 0.4113], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:16,817][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0377, 0.2498, 0.1087, 0.4195, 0.1843], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,819][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0414, 0.2907, 0.4297, 0.2124, 0.0257], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,822][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.2704, 0.1816, 0.1735, 0.1888, 0.1856], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,826][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.1850, 0.1361, 0.3107, 0.1380, 0.2302], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,830][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.5083, 0.1683, 0.0248, 0.2778, 0.0208], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,832][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.0058, 0.0082, 0.9745, 0.0013, 0.0103], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,833][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.3769, 0.2918, 0.0686, 0.1152, 0.1475], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,834][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.5276, 0.0815, 0.1474, 0.1556, 0.0879], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,835][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.5080, 0.2186, 0.0099, 0.2357, 0.0278], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,836][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0082, 0.3179, 0.1371, 0.3193, 0.2174], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,839][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0794, 0.2210, 0.2662, 0.1857, 0.2478], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,843][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0147, 0.0019, 0.0020, 0.0014, 0.9800], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:16,847][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0428, 0.1864, 0.0869, 0.2965, 0.1460, 0.2414], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,850][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0369, 0.1715, 0.3857, 0.1803, 0.1930, 0.0326], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,851][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2167, 0.1506, 0.1545, 0.1570, 0.1716, 0.1496], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,852][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0979, 0.0748, 0.3324, 0.0875, 0.2679, 0.1395], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,852][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.3064, 0.2183, 0.0308, 0.2181, 0.0510, 0.1754], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,854][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0426, 0.6500, 0.0203, 0.0095, 0.2012, 0.0765], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,857][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2186, 0.0716, 0.2017, 0.2880, 0.0651, 0.1549], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,861][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.4048, 0.0408, 0.1274, 0.1135, 0.1279, 0.1856], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,865][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3621, 0.2091, 0.0263, 0.2332, 0.0428, 0.1266], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,868][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0034, 0.2687, 0.1194, 0.2735, 0.1950, 0.1400], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,869][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0585, 0.1806, 0.2279, 0.1506, 0.2152, 0.1672], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,870][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0081, 0.0338, 0.0054, 0.0128, 0.0026, 0.9372], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:16,870][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0335, 0.1345, 0.0657, 0.2072, 0.1097, 0.1715, 0.2780],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,872][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0733, 0.1374, 0.4442, 0.0865, 0.0695, 0.1758, 0.0132],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,875][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1976, 0.1285, 0.1318, 0.1384, 0.1443, 0.1252, 0.1343],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,879][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1023, 0.0656, 0.3110, 0.0713, 0.2214, 0.1117, 0.1166],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,883][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2501, 0.1920, 0.0283, 0.1870, 0.0504, 0.1364, 0.1557],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,886][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1389, 0.4722, 0.1134, 0.0204, 0.1216, 0.0956, 0.0379],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,886][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1050, 0.0864, 0.1714, 0.2551, 0.2421, 0.0397, 0.1003],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,887][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3595, 0.0459, 0.1081, 0.0954, 0.1078, 0.1434, 0.1400],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,888][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3287, 0.1070, 0.0201, 0.1707, 0.0308, 0.0695, 0.2732],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,890][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0013, 0.1855, 0.0740, 0.1836, 0.1347, 0.1033, 0.3176],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,893][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0537, 0.1527, 0.1993, 0.1304, 0.1904, 0.1434, 0.1301],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,897][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0113, 0.0150, 0.0084, 0.0030, 0.0243, 0.1047, 0.8331],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:16,901][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0186, 0.1058, 0.0492, 0.1787, 0.0880, 0.1405, 0.2448, 0.1745],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,904][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0614, 0.2297, 0.1373, 0.1361, 0.0647, 0.2770, 0.0586, 0.0353],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,904][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1864, 0.1164, 0.1149, 0.1191, 0.1225, 0.1093, 0.1118, 0.1197],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,905][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0915, 0.0639, 0.2779, 0.0709, 0.2110, 0.0989, 0.0900, 0.0959],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,906][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.2673, 0.1028, 0.0164, 0.1826, 0.0205, 0.1639, 0.2103, 0.0362],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,907][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0919, 0.6591, 0.0355, 0.0262, 0.0033, 0.0334, 0.0599, 0.0907],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,909][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.1403, 0.0738, 0.0570, 0.2330, 0.0547, 0.0809, 0.2947, 0.0655],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,911][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.4585, 0.0399, 0.0613, 0.0723, 0.0776, 0.1270, 0.1120, 0.0514],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,915][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.2288, 0.0831, 0.0134, 0.2378, 0.0253, 0.0899, 0.3020, 0.0197],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,919][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0017, 0.1983, 0.0743, 0.1687, 0.1254, 0.1029, 0.2932, 0.0355],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,922][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0469, 0.1317, 0.1724, 0.1110, 0.1654, 0.1212, 0.1112, 0.1402],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,923][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([1.3264e-01, 1.8247e-01, 4.2734e-04, 1.5073e-01, 1.5838e-04, 3.7829e-03,
        2.5503e-03, 5.2724e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:16,924][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0247, 0.0906, 0.0449, 0.1355, 0.0738, 0.1117, 0.1822, 0.1366, 0.1999],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,925][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0168, 0.0419, 0.4967, 0.0449, 0.0758, 0.1043, 0.1312, 0.0878, 0.0005],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,926][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1580, 0.1010, 0.1057, 0.1069, 0.1178, 0.1016, 0.1032, 0.1084, 0.0973],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,929][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0704, 0.0475, 0.3262, 0.0542, 0.2201, 0.0907, 0.0760, 0.0896, 0.0253],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,933][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.2039, 0.1336, 0.0172, 0.1629, 0.0239, 0.1344, 0.1711, 0.0270, 0.1260],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,936][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ of] are: tensor([5.2124e-04, 2.0721e-04, 1.0648e-05, 6.6394e-05, 2.2080e-04, 1.5388e-04,
        2.0153e-03, 1.8928e-04, 9.9662e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,940][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0690, 0.0833, 0.0298, 0.2095, 0.0030, 0.0279, 0.1874, 0.2101, 0.1800],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,941][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.3030, 0.0514, 0.0859, 0.0825, 0.0675, 0.1020, 0.1049, 0.0737, 0.1291],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,942][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.2965, 0.0662, 0.0165, 0.1877, 0.0275, 0.0460, 0.2633, 0.0408, 0.0554],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,943][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0013, 0.1860, 0.0660, 0.1524, 0.1124, 0.0905, 0.2726, 0.0350, 0.0839],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,945][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0415, 0.1188, 0.1590, 0.1007, 0.1511, 0.1123, 0.0984, 0.1298, 0.0884],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,947][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0775, 0.2782, 0.0334, 0.1388, 0.0162, 0.1339, 0.0714, 0.1001, 0.1506],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:16,952][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0090, 0.0712, 0.0305, 0.1360, 0.0585, 0.1038, 0.1928, 0.1312, 0.2057,
        0.0613], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,956][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0457, 0.1608, 0.2314, 0.1732, 0.0354, 0.0991, 0.0291, 0.1693, 0.0524,
        0.0038], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,958][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1495, 0.0963, 0.0919, 0.0993, 0.1001, 0.0894, 0.0917, 0.0934, 0.0887,
        0.0997], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,959][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0813, 0.0545, 0.2356, 0.0663, 0.1816, 0.0937, 0.0856, 0.0877, 0.0309,
        0.0827], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,960][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.2774, 0.1257, 0.0223, 0.1269, 0.0436, 0.1047, 0.0998, 0.0422, 0.1081,
        0.0493], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,961][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.1062, 0.2934, 0.0242, 0.0428, 0.0241, 0.0533, 0.1415, 0.1111, 0.0772,
        0.1260], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,963][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0847, 0.0271, 0.0810, 0.0807, 0.1957, 0.0637, 0.0841, 0.2768, 0.0385,
        0.0677], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,965][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.2692, 0.0488, 0.0547, 0.0763, 0.0498, 0.1811, 0.0938, 0.1075, 0.0867,
        0.0322], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,969][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.2426, 0.0878, 0.0253, 0.2560, 0.0494, 0.0724, 0.1833, 0.0273, 0.0446,
        0.0111], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,974][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0024, 0.1604, 0.0749, 0.1772, 0.1275, 0.0936, 0.2212, 0.0341, 0.0850,
        0.0236], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,976][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0380, 0.1073, 0.1355, 0.0900, 0.1270, 0.0982, 0.0888, 0.1110, 0.0766,
        0.1275], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,977][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([5.0952e-03, 5.6506e-03, 6.7208e-04, 4.8188e-03, 1.3268e-03, 2.0015e-02,
        1.3205e-02, 1.0346e-02, 2.3643e-02, 9.1523e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:16,978][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0170, 0.0761, 0.0365, 0.1180, 0.0613, 0.0926, 0.1582, 0.1143, 0.1722,
        0.0630, 0.0909], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,979][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0601, 0.1455, 0.2006, 0.0869, 0.1517, 0.1632, 0.0806, 0.0568, 0.0115,
        0.0398, 0.0033], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,981][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1346, 0.0830, 0.0887, 0.0882, 0.0959, 0.0810, 0.0844, 0.0892, 0.0781,
        0.0947, 0.0823], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,983][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0763, 0.0495, 0.2446, 0.0549, 0.1715, 0.0805, 0.0733, 0.0805, 0.0245,
        0.0824, 0.0621], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,987][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.1694, 0.1466, 0.0261, 0.1124, 0.0486, 0.0913, 0.0940, 0.0423, 0.1114,
        0.0517, 0.1060], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,990][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ at] are: tensor([5.0022e-04, 1.0695e-03, 4.8081e-05, 1.2106e-04, 1.1937e-04, 1.0934e-04,
        2.1008e-03, 4.8582e-04, 1.5687e-03, 5.3486e-04, 9.9334e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,994][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0192, 0.0204, 0.0504, 0.0935, 0.1910, 0.0192, 0.0298, 0.0061, 0.1084,
        0.4444, 0.0176], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,995][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.2045, 0.0266, 0.0786, 0.0711, 0.0852, 0.1429, 0.0672, 0.0558, 0.0776,
        0.1003, 0.0901], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,996][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.2858, 0.1151, 0.0195, 0.1424, 0.0288, 0.0528, 0.2279, 0.0334, 0.0504,
        0.0173, 0.0266], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,997][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0014, 0.1695, 0.0578, 0.1326, 0.1018, 0.0791, 0.2227, 0.0326, 0.0760,
        0.0215, 0.1050], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:16,999][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0342, 0.0950, 0.1253, 0.0808, 0.1178, 0.0883, 0.0783, 0.1041, 0.0689,
        0.1190, 0.0884], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,001][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0133, 0.1724, 0.0103, 0.0634, 0.0022, 0.1662, 0.0268, 0.0299, 0.0321,
        0.0032, 0.4803], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,005][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0150, 0.0652, 0.0318, 0.1028, 0.0538, 0.0823, 0.1370, 0.1008, 0.1496,
        0.0570, 0.0794, 0.1252], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,010][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0605, 0.0801, 0.1347, 0.0885, 0.0368, 0.2161, 0.0353, 0.1024, 0.0580,
        0.0268, 0.1564, 0.0045], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,012][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1186, 0.0762, 0.0804, 0.0813, 0.0883, 0.0757, 0.0798, 0.0848, 0.0729,
        0.0898, 0.0743, 0.0778], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,013][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0679, 0.0387, 0.2502, 0.0480, 0.1732, 0.0725, 0.0726, 0.0805, 0.0194,
        0.0797, 0.0491, 0.0482], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,014][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.1382, 0.1328, 0.0201, 0.1051, 0.0336, 0.0781, 0.0931, 0.0364, 0.0937,
        0.0451, 0.1036, 0.1203], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,015][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0364, 0.3129, 0.0173, 0.0034, 0.0970, 0.0225, 0.0217, 0.0497, 0.1982,
        0.0117, 0.2180, 0.0111], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,017][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0283, 0.0147, 0.1413, 0.2001, 0.0869, 0.0274, 0.0434, 0.0417, 0.1176,
        0.1219, 0.1502, 0.0264], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,019][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.1498, 0.0160, 0.0687, 0.0510, 0.0595, 0.0870, 0.0666, 0.0502, 0.0674,
        0.1064, 0.0870, 0.1904], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,024][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.1697, 0.0689, 0.0132, 0.0993, 0.0157, 0.0249, 0.1408, 0.0227, 0.0325,
        0.0114, 0.0151, 0.3857], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,028][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0007, 0.1302, 0.0398, 0.0973, 0.0754, 0.0587, 0.1912, 0.0230, 0.0542,
        0.0148, 0.0777, 0.2370], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,030][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0315, 0.0870, 0.1152, 0.0741, 0.1105, 0.0825, 0.0741, 0.0959, 0.0634,
        0.1105, 0.0802, 0.0749], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,031][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0030, 0.0139, 0.0155, 0.0046, 0.0115, 0.0729, 0.0508, 0.0232, 0.0175,
        0.0450, 0.0211, 0.7212], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,032][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0068, 0.0530, 0.0232, 0.1000, 0.0441, 0.0777, 0.1438, 0.0984, 0.1544,
        0.0467, 0.0759, 0.1243, 0.0516], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,033][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0201, 0.0825, 0.2220, 0.0506, 0.0257, 0.0708, 0.1037, 0.1023, 0.0073,
        0.0065, 0.2367, 0.0660, 0.0058], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,035][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1195, 0.0741, 0.0737, 0.0764, 0.0799, 0.0704, 0.0717, 0.0732, 0.0674,
        0.0792, 0.0683, 0.0690, 0.0772], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,037][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0586, 0.0429, 0.2271, 0.0517, 0.1694, 0.0710, 0.0640, 0.0714, 0.0198,
        0.0765, 0.0526, 0.0398, 0.0550], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,042][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.1567, 0.0855, 0.0081, 0.1039, 0.0100, 0.1031, 0.1026, 0.0212, 0.0833,
        0.0348, 0.1191, 0.1352, 0.0364], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,046][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0247, 0.1307, 0.0026, 0.0125, 0.0011, 0.0172, 0.0708, 0.0136, 0.0844,
        0.0071, 0.3568, 0.0990, 0.1794], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,048][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0253, 0.0320, 0.0305, 0.1459, 0.0301, 0.0343, 0.0303, 0.0233, 0.0828,
        0.0035, 0.0374, 0.0135, 0.5112], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,049][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.1548, 0.0244, 0.1080, 0.0515, 0.0443, 0.1484, 0.0844, 0.0384, 0.0525,
        0.0639, 0.0872, 0.1157, 0.0266], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,050][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.1391, 0.0446, 0.0055, 0.1155, 0.0109, 0.0482, 0.0701, 0.0176, 0.0372,
        0.0070, 0.0104, 0.4903, 0.0035], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,051][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0013, 0.0885, 0.0372, 0.0886, 0.0682, 0.0483, 0.1236, 0.0190, 0.0475,
        0.0132, 0.0653, 0.1470, 0.2524], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,053][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0286, 0.0819, 0.1033, 0.0685, 0.0968, 0.0749, 0.0679, 0.0845, 0.0582,
        0.0982, 0.0728, 0.0674, 0.0970], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,055][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ store] are: tensor([7.0646e-04, 2.5993e-02, 1.8350e-04, 5.3194e-02, 7.1649e-05, 9.8230e-03,
        1.1680e-02, 4.6253e-03, 1.0157e-01, 5.5570e-04, 1.0492e-01, 8.5124e-03,
        6.7816e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,059][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0104, 0.0521, 0.0260, 0.0867, 0.0453, 0.0727, 0.1232, 0.0880, 0.1322,
        0.0485, 0.0721, 0.1104, 0.0525, 0.0799], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,064][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1387, 0.0936, 0.2044, 0.0381, 0.1159, 0.0841, 0.0318, 0.0721, 0.0107,
        0.0842, 0.0553, 0.0167, 0.0489, 0.0054], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,066][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1024, 0.0642, 0.0699, 0.0695, 0.0770, 0.0650, 0.0681, 0.0715, 0.0628,
        0.0762, 0.0630, 0.0652, 0.0747, 0.0704], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,067][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0544, 0.0348, 0.2645, 0.0466, 0.1723, 0.0672, 0.0618, 0.0650, 0.0173,
        0.0755, 0.0454, 0.0329, 0.0542, 0.0078], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,068][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.1685, 0.0861, 0.0116, 0.0937, 0.0104, 0.0882, 0.1026, 0.0176, 0.0592,
        0.0420, 0.1092, 0.1135, 0.0274, 0.0701], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,069][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1145, 0.0847, 0.1040, 0.0133, 0.1847, 0.0677, 0.0410, 0.0399, 0.0511,
        0.0374, 0.1021, 0.0581, 0.0289, 0.0725], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,071][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0239, 0.0054, 0.2661, 0.0465, 0.2746, 0.0194, 0.0079, 0.0137, 0.0599,
        0.0418, 0.0369, 0.0066, 0.1145, 0.0828], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,075][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.1319, 0.0109, 0.0722, 0.0410, 0.0563, 0.0697, 0.0339, 0.0591, 0.0509,
        0.1126, 0.0555, 0.0850, 0.1256, 0.0954], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,078][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.1372, 0.1587, 0.0122, 0.1719, 0.0157, 0.0227, 0.0826, 0.0264, 0.0265,
        0.0103, 0.0076, 0.2217, 0.0051, 0.1013], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,082][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0005, 0.0692, 0.0248, 0.0607, 0.0432, 0.0321, 0.0908, 0.0125, 0.0298,
        0.0087, 0.0404, 0.1008, 0.1775, 0.3093], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,084][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0261, 0.0748, 0.0986, 0.0635, 0.0928, 0.0698, 0.0623, 0.0809, 0.0544,
        0.0941, 0.0699, 0.0623, 0.0956, 0.0549], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,085][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0540, 0.1241, 0.0564, 0.0547, 0.0367, 0.1243, 0.0304, 0.1069, 0.0166,
        0.0314, 0.0303, 0.0850, 0.0686, 0.1806], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,086][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0065, 0.0504, 0.0203, 0.0868, 0.0354, 0.0661, 0.1268, 0.0929, 0.1440,
        0.0411, 0.0702, 0.1151, 0.0458, 0.0801, 0.0185], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,087][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0157, 0.0954, 0.1814, 0.0641, 0.0106, 0.1598, 0.0431, 0.0729, 0.0215,
        0.0096, 0.1476, 0.0379, 0.0365, 0.0943, 0.0095], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,089][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0995, 0.0654, 0.0627, 0.0676, 0.0669, 0.0615, 0.0612, 0.0634, 0.0584,
        0.0683, 0.0596, 0.0601, 0.0662, 0.0663, 0.0728], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,092][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0765, 0.0489, 0.1521, 0.0562, 0.1065, 0.0770, 0.0679, 0.0659, 0.0272,
        0.0660, 0.0559, 0.0493, 0.0556, 0.0156, 0.0794], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,096][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.1538, 0.0588, 0.0062, 0.0950, 0.0047, 0.1124, 0.1164, 0.0135, 0.0572,
        0.0378, 0.1153, 0.1354, 0.0183, 0.0710, 0.0041], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,098][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([5.7929e-04, 2.6429e-03, 9.7053e-01, 6.5038e-04, 6.0289e-03, 2.7613e-04,
        3.0842e-04, 1.5660e-04, 9.1732e-05, 1.2701e-04, 9.8968e-04, 4.4993e-04,
        1.1214e-04, 2.1819e-03, 1.4872e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,102][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0296, 0.0430, 0.0123, 0.0138, 0.0126, 0.0463, 0.0909, 0.0142, 0.0292,
        0.0186, 0.0360, 0.1235, 0.0052, 0.5232, 0.0016], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,103][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0683, 0.0209, 0.0365, 0.0303, 0.0251, 0.1118, 0.0406, 0.0738, 0.0300,
        0.0503, 0.0421, 0.1003, 0.0733, 0.2730, 0.0237], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,104][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.0719, 0.0507, 0.0011, 0.0253, 0.0037, 0.0603, 0.1443, 0.0034, 0.0153,
        0.0016, 0.0031, 0.5281, 0.0016, 0.0812, 0.0083], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,105][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0008, 0.0441, 0.0225, 0.0603, 0.0412, 0.0273, 0.0605, 0.0088, 0.0246,
        0.0064, 0.0322, 0.0605, 0.1113, 0.3237, 0.1758], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,107][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0259, 0.0719, 0.0879, 0.0606, 0.0816, 0.0647, 0.0591, 0.0717, 0.0509,
        0.0832, 0.0637, 0.0597, 0.0844, 0.0517, 0.0831], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,109][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([6.9259e-05, 2.1695e-05, 1.0323e-03, 5.4458e-06, 1.1336e-01, 2.8267e-04,
        3.1418e-04, 2.4642e-05, 6.0127e-05, 3.9214e-04, 2.4696e-05, 3.2508e-04,
        5.6892e-06, 9.0957e-04, 8.8318e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,114][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0077, 0.0490, 0.0218, 0.0838, 0.0389, 0.0657, 0.1187, 0.0865, 0.1288,
        0.0430, 0.0678, 0.1057, 0.0474, 0.0769, 0.0215, 0.0371],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,118][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0125, 0.0350, 0.4274, 0.0425, 0.0508, 0.0358, 0.0316, 0.1224, 0.0036,
        0.0114, 0.0281, 0.0801, 0.0289, 0.0418, 0.0413, 0.0068],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,120][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0912, 0.0591, 0.0590, 0.0613, 0.0653, 0.0556, 0.0563, 0.0590, 0.0541,
        0.0622, 0.0546, 0.0544, 0.0637, 0.0602, 0.0699, 0.0742],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,121][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0587, 0.0368, 0.1502, 0.0472, 0.1134, 0.0706, 0.0594, 0.0605, 0.0244,
        0.0624, 0.0566, 0.0390, 0.0531, 0.0116, 0.0811, 0.0750],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,122][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.1034, 0.1001, 0.0122, 0.0870, 0.0228, 0.0595, 0.0620, 0.0229, 0.0769,
        0.0262, 0.0758, 0.0787, 0.0483, 0.1265, 0.0266, 0.0712],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,123][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0478, 0.0802, 0.0064, 0.0097, 0.0187, 0.1623, 0.0613, 0.0116, 0.0767,
        0.0087, 0.0796, 0.0389, 0.2519, 0.0669, 0.0154, 0.0637],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,125][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0111, 0.0073, 0.0260, 0.0350, 0.0150, 0.0100, 0.0163, 0.0156, 0.0396,
        0.0304, 0.0412, 0.0128, 0.6578, 0.0426, 0.0132, 0.0263],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,128][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0848, 0.0232, 0.0480, 0.0441, 0.0432, 0.0537, 0.0378, 0.0497, 0.0522,
        0.0961, 0.0577, 0.0758, 0.1202, 0.1406, 0.0340, 0.0388],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,132][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1078, 0.0554, 0.0047, 0.0809, 0.0082, 0.0364, 0.1071, 0.0094, 0.0176,
        0.0041, 0.0065, 0.4320, 0.0032, 0.0873, 0.0136, 0.0257],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,136][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0007, 0.0452, 0.0222, 0.0583, 0.0404, 0.0262, 0.0591, 0.0095, 0.0244,
        0.0066, 0.0312, 0.0623, 0.1196, 0.2654, 0.1571, 0.0718],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,138][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0218, 0.0640, 0.0830, 0.0540, 0.0780, 0.0594, 0.0524, 0.0685, 0.0465,
        0.0787, 0.0593, 0.0527, 0.0816, 0.0466, 0.0790, 0.0745],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,139][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([4.8519e-05, 1.0186e-03, 1.3139e-04, 7.6029e-04, 2.6522e-04, 2.3651e-02,
        3.0121e-03, 1.1367e-03, 4.8625e-03, 4.5257e-03, 3.2547e-03, 2.2163e-03,
        2.3140e-04, 4.2671e-02, 6.1199e-04, 9.1160e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,140][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0106, 0.0488, 0.0230, 0.0756, 0.0388, 0.0616, 0.1017, 0.0776, 0.1128,
        0.0420, 0.0601, 0.0935, 0.0459, 0.0706, 0.0233, 0.0366, 0.0774],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,142][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0368, 0.0551, 0.1869, 0.0323, 0.0315, 0.0692, 0.0038, 0.0579, 0.0517,
        0.0178, 0.1191, 0.0747, 0.0500, 0.0820, 0.0277, 0.1009, 0.0026],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,145][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0829, 0.0533, 0.0550, 0.0568, 0.0601, 0.0517, 0.0551, 0.0582, 0.0510,
        0.0615, 0.0510, 0.0528, 0.0602, 0.0569, 0.0651, 0.0685, 0.0598],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,149][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0538, 0.0319, 0.1672, 0.0373, 0.1173, 0.0593, 0.0615, 0.0637, 0.0178,
        0.0585, 0.0432, 0.0387, 0.0479, 0.0095, 0.0817, 0.0673, 0.0436],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,153][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0895, 0.1002, 0.0107, 0.0750, 0.0202, 0.0510, 0.0578, 0.0274, 0.0729,
        0.0233, 0.0632, 0.0787, 0.0483, 0.1200, 0.0245, 0.0679, 0.0695],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,156][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0247, 0.1025, 0.0621, 0.0031, 0.0679, 0.0628, 0.0131, 0.0193, 0.1195,
        0.0214, 0.1704, 0.0244, 0.0255, 0.0333, 0.0637, 0.1789, 0.0075],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,157][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0247, 0.0203, 0.0512, 0.0794, 0.0823, 0.0100, 0.0179, 0.0905, 0.0965,
        0.1100, 0.0670, 0.0158, 0.2367, 0.0428, 0.0201, 0.0204, 0.0143],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,158][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1014, 0.0173, 0.0335, 0.0306, 0.0353, 0.0439, 0.0381, 0.0516, 0.0486,
        0.0604, 0.0517, 0.0840, 0.1122, 0.1487, 0.0206, 0.0587, 0.0635],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,158][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1278, 0.0573, 0.0097, 0.0778, 0.0130, 0.0184, 0.1318, 0.0130, 0.0185,
        0.0072, 0.0093, 0.2892, 0.0077, 0.0965, 0.0179, 0.0176, 0.0875],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,161][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0003, 0.0412, 0.0150, 0.0393, 0.0305, 0.0207, 0.0628, 0.0078, 0.0197,
        0.0051, 0.0276, 0.0756, 0.1208, 0.2314, 0.1514, 0.0660, 0.0848],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,164][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0216, 0.0593, 0.0784, 0.0508, 0.0747, 0.0561, 0.0507, 0.0659, 0.0434,
        0.0749, 0.0545, 0.0503, 0.0754, 0.0436, 0.0763, 0.0714, 0.0527],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,166][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.3549e-04, 5.4213e-04, 1.0230e-03, 8.8837e-05, 3.1182e-03, 1.5095e-02,
        6.9449e-02, 1.9525e-03, 9.4296e-04, 1.3062e-02, 2.0118e-03, 1.5857e-02,
        1.4524e-03, 1.1900e-02, 7.2187e-02, 2.5229e-02, 7.6585e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,170][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0045, 0.0399, 0.0172, 0.0748, 0.0320, 0.0574, 0.1078, 0.0769, 0.1162,
        0.0350, 0.0565, 0.0946, 0.0400, 0.0660, 0.0166, 0.0311, 0.0779, 0.0556],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,174][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0146, 0.0389, 0.1696, 0.0435, 0.0332, 0.1037, 0.0937, 0.0895, 0.0150,
        0.0276, 0.0415, 0.0315, 0.0463, 0.0364, 0.0301, 0.0799, 0.0937, 0.0116],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,175][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0836, 0.0534, 0.0524, 0.0536, 0.0557, 0.0496, 0.0502, 0.0517, 0.0472,
        0.0559, 0.0482, 0.0479, 0.0555, 0.0539, 0.0605, 0.0657, 0.0539, 0.0611],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,176][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0537, 0.0323, 0.1659, 0.0408, 0.1250, 0.0605, 0.0491, 0.0547, 0.0184,
        0.0540, 0.0433, 0.0292, 0.0416, 0.0100, 0.0824, 0.0677, 0.0335, 0.0381],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,177][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.1237, 0.0867, 0.0135, 0.0724, 0.0194, 0.0571, 0.0573, 0.0191, 0.0615,
        0.0229, 0.0550, 0.0747, 0.0371, 0.1175, 0.0228, 0.0700, 0.0662, 0.0232],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,179][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0169, 0.1162, 0.0262, 0.0122, 0.0903, 0.0099, 0.0915, 0.0547, 0.0602,
        0.0092, 0.0032, 0.0457, 0.0060, 0.0342, 0.0420, 0.0109, 0.0633, 0.3074],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,182][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0954, 0.0107, 0.0249, 0.1082, 0.0195, 0.1196, 0.0847, 0.0384, 0.0346,
        0.0052, 0.0558, 0.0354, 0.0416, 0.0425, 0.0056, 0.1615, 0.0808, 0.0356],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,186][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.1311, 0.0275, 0.0243, 0.0301, 0.0302, 0.0238, 0.0498, 0.0412, 0.0535,
        0.1127, 0.0406, 0.0749, 0.1013, 0.1199, 0.0234, 0.0275, 0.0722, 0.0160],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,190][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0811, 0.0386, 0.0036, 0.0413, 0.0065, 0.0419, 0.1147, 0.0043, 0.0054,
        0.0019, 0.0024, 0.4684, 0.0016, 0.0638, 0.0110, 0.0292, 0.0816, 0.0027],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,192][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0006, 0.0305, 0.0175, 0.0506, 0.0372, 0.0202, 0.0447, 0.0068, 0.0183,
        0.0048, 0.0240, 0.0496, 0.0990, 0.2426, 0.1473, 0.0600, 0.0547, 0.0918],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,193][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0215, 0.0575, 0.0727, 0.0484, 0.0677, 0.0526, 0.0474, 0.0590, 0.0419,
        0.0691, 0.0509, 0.0473, 0.0689, 0.0415, 0.0689, 0.0665, 0.0485, 0.0696],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,194][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([2.6076e-04, 4.0995e-03, 1.9238e-04, 3.8096e-03, 8.5368e-04, 2.9990e-03,
        6.6613e-04, 4.9250e-03, 5.9045e-03, 1.0713e-03, 2.6028e-03, 1.1809e-03,
        1.0859e-04, 1.7155e-02, 1.0687e-04, 1.7053e-03, 8.4595e-04, 9.5151e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,195][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0084, 0.0411, 0.0198, 0.0647, 0.0336, 0.0529, 0.0895, 0.0705, 0.0976,
        0.0369, 0.0536, 0.0821, 0.0405, 0.0619, 0.0201, 0.0322, 0.0694, 0.0544,
        0.0709], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,197][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0577, 0.0540, 0.2216, 0.0919, 0.0323, 0.1416, 0.0492, 0.0867, 0.0044,
        0.0158, 0.0246, 0.0384, 0.0232, 0.0068, 0.0240, 0.0393, 0.0347, 0.0532,
        0.0007], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,200][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0725, 0.0467, 0.0498, 0.0493, 0.0548, 0.0470, 0.0486, 0.0512, 0.0452,
        0.0537, 0.0458, 0.0467, 0.0538, 0.0503, 0.0589, 0.0635, 0.0527, 0.0581,
        0.0513], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,204][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0424, 0.0247, 0.1843, 0.0308, 0.1371, 0.0572, 0.0462, 0.0517, 0.0139,
        0.0554, 0.0382, 0.0268, 0.0425, 0.0065, 0.0870, 0.0648, 0.0306, 0.0357,
        0.0241], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,208][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1036, 0.0920, 0.0109, 0.0665, 0.0177, 0.0519, 0.0559, 0.0183, 0.0600,
        0.0224, 0.0605, 0.0692, 0.0390, 0.0886, 0.0188, 0.0700, 0.0632, 0.0153,
        0.0763], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,210][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.2330e-04, 1.3366e-04, 4.4175e-03, 6.6212e-05, 3.1030e-03, 4.4027e-04,
        7.6115e-04, 1.3822e-05, 9.6386e-04, 8.5968e-05, 2.0172e-03, 9.4007e-04,
        9.1970e-05, 4.0862e-04, 1.0738e-03, 3.8380e-04, 8.7978e-04, 2.1918e-03,
        9.8160e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,211][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0228, 0.0107, 0.0153, 0.1360, 0.0493, 0.0133, 0.0515, 0.0454, 0.1032,
        0.0473, 0.0880, 0.0155, 0.1021, 0.0433, 0.0217, 0.1195, 0.0491, 0.0356,
        0.0305], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,212][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0944, 0.0169, 0.0290, 0.0276, 0.0268, 0.0339, 0.0334, 0.0284, 0.0428,
        0.0463, 0.0428, 0.0643, 0.0831, 0.1209, 0.0155, 0.0476, 0.0507, 0.1196,
        0.0761], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,213][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0986, 0.0752, 0.0106, 0.0796, 0.0126, 0.0210, 0.1255, 0.0117, 0.0187,
        0.0061, 0.0085, 0.3037, 0.0057, 0.0849, 0.0175, 0.0163, 0.0831, 0.0068,
        0.0138], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,215][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0002, 0.0529, 0.0144, 0.0313, 0.0231, 0.0195, 0.0642, 0.0083, 0.0197,
        0.0053, 0.0264, 0.0716, 0.1051, 0.1862, 0.1206, 0.0542, 0.0814, 0.0863,
        0.0294], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,217][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0187, 0.0529, 0.0698, 0.0446, 0.0669, 0.0497, 0.0444, 0.0572, 0.0388,
        0.0660, 0.0498, 0.0443, 0.0667, 0.0387, 0.0680, 0.0635, 0.0463, 0.0687,
        0.0449], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,221][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0156, 0.0471, 0.0094, 0.0190, 0.0065, 0.0860, 0.0345, 0.0123, 0.0146,
        0.0170, 0.0315, 0.0523, 0.0113, 0.2161, 0.0263, 0.0226, 0.1163, 0.0039,
        0.2577], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,250][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:17,253][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,256][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,259][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,262][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,263][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,264][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,264][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,265][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,266][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,267][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,270][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,272][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,276][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3019, 0.6981], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,279][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8449, 0.1551], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,281][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6274, 0.3726], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,282][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6670, 0.3330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,283][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8778, 0.1222], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,283][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([2.5707e-06, 1.0000e+00], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,284][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9989, 0.0011], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,286][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5468, 0.4532], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,289][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9780, 0.0220], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,293][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0049, 0.9951], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,295][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([1.5707e-04, 9.9984e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,299][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3379, 0.6621], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,300][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.2070, 0.5551, 0.2379], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,300][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([0.7543, 0.1726, 0.0731], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,301][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.4323, 0.2891, 0.2786], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,302][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.5424, 0.2703, 0.1873], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,304][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.6017, 0.2325, 0.1658], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,306][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([1.6048e-02, 9.8395e-01, 7.6686e-07], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,308][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([9.9592e-01, 3.1997e-04, 3.7575e-03], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,311][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.0187, 0.1130, 0.8682], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,315][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.9057, 0.0477, 0.0466], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,319][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.0031, 0.8549, 0.1420], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,320][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.0006, 0.5921, 0.4072], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,320][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.0620, 0.0242, 0.9138], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,321][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1218, 0.3017, 0.1622, 0.4142], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,322][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.6318, 0.1037, 0.0480, 0.2165], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,324][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3357, 0.2094, 0.2244, 0.2306], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,327][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.4547, 0.2187, 0.1636, 0.1630], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,331][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4358, 0.1137, 0.2178, 0.2328], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,333][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.9934e-04, 9.9960e-01, 1.5273e-08, 1.7784e-09], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,335][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([9.9596e-01, 3.5892e-04, 2.9771e-03, 7.0510e-04], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,337][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0899, 0.1633, 0.6619, 0.0850], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,338][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9634, 0.0168, 0.0153, 0.0045], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,339][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0017, 0.8317, 0.1183, 0.0483], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,339][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0014, 0.3119, 0.3290, 0.3577], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,341][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0806, 0.4428, 0.0733, 0.4033], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,344][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.0934, 0.2657, 0.1128, 0.3771, 0.1509], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,348][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.4995, 0.1168, 0.0465, 0.3182, 0.0190], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,352][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.2747, 0.1815, 0.1723, 0.1880, 0.1835], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,355][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.3953, 0.1883, 0.1337, 0.1360, 0.1467], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,356][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.3420, 0.1817, 0.1178, 0.2204, 0.1382], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,356][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([7.4185e-02, 9.2580e-01, 1.0704e-05, 8.7954e-08, 1.9187e-06],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,357][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.8927, 0.0029, 0.0258, 0.0112, 0.0675], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,359][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0138, 0.0384, 0.6297, 0.0356, 0.2824], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,362][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.6908, 0.0359, 0.0761, 0.0089, 0.1883], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,366][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.0022, 0.8010, 0.0610, 0.0236, 0.1122], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,370][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0007, 0.2583, 0.2132, 0.2708, 0.2570], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,372][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([7.9413e-03, 1.1723e-03, 1.8596e-03, 6.2277e-04, 9.8840e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,373][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0801, 0.1957, 0.0936, 0.2742, 0.1298, 0.2266], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,374][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.5020, 0.0879, 0.0384, 0.1913, 0.0134, 0.1670], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,375][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.2214, 0.1507, 0.1534, 0.1562, 0.1697, 0.1487], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,375][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3296, 0.1652, 0.1225, 0.1222, 0.1350, 0.1255], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,378][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2942, 0.1117, 0.1216, 0.1515, 0.1419, 0.1791], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,379][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([2.9110e-04, 9.9971e-01, 1.0920e-07, 8.1963e-09, 8.6942e-08, 3.6475e-07],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,382][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([8.9288e-01, 3.4454e-03, 4.3564e-02, 8.9597e-03, 5.0376e-02, 7.7964e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,386][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0147, 0.0337, 0.2876, 0.0389, 0.4216, 0.2036], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,389][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.6618, 0.0862, 0.0560, 0.0163, 0.0815, 0.0981], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,391][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0013, 0.6738, 0.0881, 0.0275, 0.2048, 0.0044], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,391][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0010, 0.1418, 0.1691, 0.1898, 0.2221, 0.2763], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,392][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0014, 0.0107, 0.0059, 0.0035, 0.0022, 0.9763], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,393][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0650, 0.1451, 0.0731, 0.1984, 0.0978, 0.1641, 0.2566],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,395][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.4283, 0.0667, 0.0308, 0.1371, 0.0104, 0.1249, 0.2018],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,399][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2016, 0.1287, 0.1311, 0.1379, 0.1430, 0.1247, 0.1330],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,402][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2947, 0.1471, 0.1090, 0.1080, 0.1207, 0.1111, 0.1094],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,406][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2442, 0.0944, 0.1018, 0.1424, 0.1181, 0.1415, 0.1577],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,408][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.7722e-03, 9.9723e-01, 6.8774e-08, 1.7940e-09, 3.6723e-08, 7.0698e-08,
        2.6441e-08], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,409][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6191, 0.0162, 0.1526, 0.0400, 0.1600, 0.0030, 0.0092],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,410][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0229, 0.0139, 0.2844, 0.0147, 0.3856, 0.2439, 0.0345],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,410][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.9673, 0.0090, 0.0087, 0.0027, 0.0055, 0.0058, 0.0010],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,412][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0009, 0.6711, 0.0648, 0.0239, 0.2029, 0.0034, 0.0329],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,415][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0012, 0.1029, 0.1404, 0.1489, 0.1861, 0.2121, 0.2084],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,417][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.5320e-04, 3.9089e-03, 7.6631e-03, 7.6995e-04, 1.3133e-02, 1.1706e-01,
        8.5651e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,421][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0412, 0.1173, 0.0549, 0.1736, 0.0802, 0.1385, 0.2344, 0.1599],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,424][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.3117, 0.0575, 0.0259, 0.1505, 0.0097, 0.1455, 0.2792, 0.0201],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,426][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.1903, 0.1165, 0.1144, 0.1187, 0.1215, 0.1088, 0.1107, 0.1191],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,427][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.2658, 0.1330, 0.0973, 0.0990, 0.1065, 0.1044, 0.1031, 0.0908],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,428][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.2359, 0.0885, 0.0847, 0.1277, 0.1073, 0.1213, 0.1422, 0.0925],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,429][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([6.0492e-04, 9.9798e-01, 8.9450e-06, 5.6367e-06, 3.8198e-06, 5.2832e-05,
        7.4742e-05, 1.2642e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,431][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.7495, 0.0140, 0.1224, 0.0300, 0.0645, 0.0015, 0.0080, 0.0102],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,434][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0164, 0.0094, 0.0784, 0.0075, 0.1294, 0.1558, 0.0176, 0.5854],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,437][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.3664, 0.0900, 0.0553, 0.0201, 0.1154, 0.0654, 0.0277, 0.2598],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,441][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0007, 0.7143, 0.0553, 0.0205, 0.1645, 0.0038, 0.0390, 0.0019],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,444][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0009, 0.0925, 0.1185, 0.1291, 0.1669, 0.1870, 0.1743, 0.1307],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,444][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([6.4752e-02, 1.1645e-01, 7.7012e-04, 8.7279e-02, 2.2668e-04, 8.2675e-03,
        5.7834e-03, 7.1647e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,445][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0462, 0.1014, 0.0513, 0.1364, 0.0703, 0.1129, 0.1758, 0.1311, 0.1745],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,446][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.3834, 0.0601, 0.0273, 0.1161, 0.0090, 0.1014, 0.1697, 0.0156, 0.1174],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,448][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.1612, 0.1014, 0.1053, 0.1067, 0.1169, 0.1014, 0.1024, 0.1080, 0.0967],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,451][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.2468, 0.1228, 0.0908, 0.0893, 0.1004, 0.0923, 0.0907, 0.0833, 0.0837],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,455][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.1864, 0.0838, 0.0905, 0.1168, 0.1158, 0.1167, 0.1238, 0.0546, 0.1116],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,457][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([2.6074e-03, 9.9738e-01, 2.9651e-08, 8.3325e-09, 7.3672e-08, 1.7306e-07,
        1.2480e-07, 1.2466e-05, 6.2282e-07], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,461][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.5522, 0.0337, 0.2028, 0.0596, 0.0880, 0.0027, 0.0102, 0.0155, 0.0353],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,462][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0271, 0.0499, 0.1782, 0.0456, 0.2042, 0.1087, 0.0545, 0.2410, 0.0908],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,463][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.7924, 0.0202, 0.0251, 0.0040, 0.0174, 0.0221, 0.0028, 0.0812, 0.0347],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,464][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([4.9859e-04, 6.9685e-01, 6.0705e-02, 2.0429e-02, 1.7302e-01, 3.4228e-03,
        4.0754e-02, 1.9695e-03, 2.3437e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,466][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0021, 0.0653, 0.1044, 0.1073, 0.1473, 0.1696, 0.1422, 0.1099, 0.1520],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,468][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0146, 0.1265, 0.0558, 0.0577, 0.0174, 0.2754, 0.1605, 0.1018, 0.1903],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:17,472][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0255, 0.0865, 0.0364, 0.1394, 0.0560, 0.1075, 0.1938, 0.1232, 0.1813,
        0.0503], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,477][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.2090, 0.0446, 0.0184, 0.1237, 0.0077, 0.1206, 0.2519, 0.0184, 0.2002,
        0.0056], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,479][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1525, 0.0966, 0.0917, 0.0991, 0.0995, 0.0892, 0.0911, 0.0931, 0.0881,
        0.0991], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,480][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.2370, 0.1150, 0.0825, 0.0831, 0.0914, 0.0864, 0.0847, 0.0776, 0.0780,
        0.0644], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,481][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.2034, 0.0872, 0.0585, 0.1176, 0.0734, 0.0953, 0.1027, 0.0686, 0.1081,
        0.0852], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,482][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([8.6610e-03, 9.9133e-01, 6.9324e-08, 4.1612e-09, 7.7880e-08, 1.0130e-07,
        6.0016e-08, 9.6588e-06, 1.3916e-07, 8.3221e-09], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,483][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.7639, 0.0231, 0.0643, 0.0168, 0.0587, 0.0013, 0.0049, 0.0072, 0.0165,
        0.0432], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,486][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0058, 0.0101, 0.1448, 0.0102, 0.1890, 0.1760, 0.0170, 0.4074, 0.0216,
        0.0181], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,490][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.1620, 0.0174, 0.0587, 0.0033, 0.1223, 0.0175, 0.0032, 0.1817, 0.0175,
        0.4164], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,492][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([5.4843e-04, 7.0983e-01, 5.7509e-02, 1.9509e-02, 1.5587e-01, 4.0057e-03,
        4.5883e-02, 2.5861e-03, 2.6861e-03, 1.5711e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,497][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0014, 0.0588, 0.0869, 0.0921, 0.1224, 0.1332, 0.1211, 0.0943, 0.1157,
        0.1741], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,497][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.5205e-03, 2.1149e-03, 7.1341e-04, 1.6492e-03, 1.1840e-03, 1.8557e-02,
        1.1107e-02, 7.1990e-03, 1.3085e-02, 9.4287e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:17,498][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0371, 0.0890, 0.0445, 0.1226, 0.0601, 0.0964, 0.1572, 0.1121, 0.1528,
        0.0556, 0.0725], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,499][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.3319, 0.0525, 0.0251, 0.1077, 0.0084, 0.0927, 0.1612, 0.0145, 0.1140,
        0.0053, 0.0865], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,501][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.1375, 0.0833, 0.0886, 0.0881, 0.0954, 0.0809, 0.0838, 0.0890, 0.0776,
        0.0941, 0.0817], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,504][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.2202, 0.1068, 0.0789, 0.0769, 0.0872, 0.0808, 0.0787, 0.0725, 0.0724,
        0.0596, 0.0659], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,508][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1518, 0.0645, 0.0623, 0.0927, 0.0778, 0.0927, 0.0966, 0.0587, 0.0919,
        0.0777, 0.1335], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,510][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([2.1478e-03, 9.9781e-01, 7.1734e-08, 1.6083e-08, 1.6581e-07, 4.0046e-07,
        3.3287e-07, 3.4696e-05, 6.5505e-07, 2.9355e-08, 2.2201e-06],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,514][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.5153, 0.0562, 0.0841, 0.0304, 0.0664, 0.0019, 0.0078, 0.0106, 0.0333,
        0.0921, 0.1019], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,515][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0060, 0.0071, 0.1152, 0.0059, 0.2233, 0.1209, 0.0153, 0.3852, 0.0127,
        0.0923, 0.0161], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,516][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.2992, 0.0034, 0.0081, 0.0006, 0.0078, 0.0031, 0.0006, 0.0497, 0.0134,
        0.0576, 0.5566], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,517][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([3.9221e-04, 7.0230e-01, 5.4947e-02, 1.9193e-02, 1.5773e-01, 3.8828e-03,
        4.8178e-02, 2.2058e-03, 2.8114e-03, 1.6089e-03, 6.7535e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,519][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0019, 0.0415, 0.0699, 0.0732, 0.0998, 0.1126, 0.0975, 0.0783, 0.0989,
        0.1405, 0.1860], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,522][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0021, 0.0645, 0.0128, 0.0225, 0.0018, 0.2288, 0.0472, 0.0221, 0.0323,
        0.0043, 0.5617], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:17,523][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0327, 0.0785, 0.0393, 0.1118, 0.0538, 0.0899, 0.1434, 0.1026, 0.1401,
        0.0508, 0.0651, 0.0921], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,527][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.3103, 0.0468, 0.0228, 0.0932, 0.0077, 0.0820, 0.1381, 0.0131, 0.1000,
        0.0048, 0.0774, 0.1036], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,530][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.1210, 0.0766, 0.0804, 0.0814, 0.0879, 0.0757, 0.0794, 0.0848, 0.0725,
        0.0894, 0.0738, 0.0771], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,534][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.2065, 0.1005, 0.0750, 0.0726, 0.0825, 0.0748, 0.0733, 0.0687, 0.0671,
        0.0561, 0.0618, 0.0610], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,535][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.1279, 0.0592, 0.0575, 0.0810, 0.0701, 0.0746, 0.0882, 0.0585, 0.0748,
        0.0727, 0.1102, 0.1253], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,536][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([3.8910e-03, 9.9607e-01, 9.2978e-08, 8.9632e-09, 2.1000e-07, 2.6127e-07,
        7.6811e-08, 4.2260e-05, 3.0922e-07, 1.7969e-08, 5.8758e-07, 1.3136e-07],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,537][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2839, 0.0361, 0.1297, 0.0594, 0.1268, 0.0041, 0.0083, 0.0201, 0.0398,
        0.1095, 0.1144, 0.0680], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,539][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0037, 0.0028, 0.0816, 0.0029, 0.1127, 0.1008, 0.0112, 0.5139, 0.0074,
        0.1355, 0.0159, 0.0115], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,540][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([3.7901e-01, 3.7371e-03, 4.9134e-03, 9.3626e-04, 3.5533e-03, 2.7316e-03,
        5.5739e-04, 1.8150e-02, 5.8687e-03, 2.1424e-02, 5.5876e-01, 3.5985e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,543][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.5931e-04, 6.2809e-01, 5.5421e-02, 2.3369e-02, 2.0633e-01, 3.2247e-03,
        4.3332e-02, 1.9678e-03, 1.7240e-03, 1.2739e-03, 5.4369e-03, 2.9472e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,547][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0019, 0.0314, 0.0575, 0.0612, 0.0825, 0.0944, 0.0895, 0.0618, 0.0813,
        0.1239, 0.1537, 0.1610], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,549][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.6796e-04, 2.6087e-03, 9.4744e-03, 8.5092e-04, 3.8669e-03, 6.2282e-02,
        4.1703e-02, 7.8907e-03, 1.0304e-02, 2.7696e-02, 1.5789e-02, 8.1737e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:17,552][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0204, 0.0695, 0.0306, 0.1126, 0.0462, 0.0877, 0.1553, 0.0992, 0.1453,
        0.0414, 0.0614, 0.0885, 0.0417], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,553][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.1663, 0.0327, 0.0138, 0.0903, 0.0054, 0.0876, 0.1866, 0.0130, 0.1406,
        0.0040, 0.1049, 0.1508, 0.0041], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,553][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1219, 0.0745, 0.0737, 0.0765, 0.0796, 0.0704, 0.0714, 0.0731, 0.0671,
        0.0789, 0.0679, 0.0683, 0.0767], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,555][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.2030, 0.0957, 0.0681, 0.0690, 0.0746, 0.0721, 0.0699, 0.0649, 0.0650,
        0.0535, 0.0591, 0.0580, 0.0471], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,558][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.1392, 0.0617, 0.0554, 0.0811, 0.0673, 0.0755, 0.0712, 0.0457, 0.0671,
        0.0655, 0.0932, 0.0957, 0.0814], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,560][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([5.3239e-03, 9.9461e-01, 1.7693e-07, 4.0317e-08, 3.4292e-07, 1.1153e-06,
        6.0781e-07, 5.6604e-05, 1.4029e-06, 7.9588e-08, 2.8575e-06, 9.7743e-07,
        7.9297e-07], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,564][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.4390, 0.0266, 0.0551, 0.0270, 0.0631, 0.0026, 0.0056, 0.0117, 0.0238,
        0.0535, 0.0647, 0.0446, 0.1827], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,567][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0013, 0.0086, 0.3157, 0.0125, 0.1443, 0.3178, 0.0136, 0.0574, 0.0130,
        0.0831, 0.0227, 0.0086, 0.0015], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,569][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0631, 0.0073, 0.0157, 0.0010, 0.0270, 0.0089, 0.0031, 0.0506, 0.0042,
        0.1057, 0.5401, 0.0011, 0.1721], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,570][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([3.0265e-04, 4.8438e-01, 3.1705e-02, 1.0129e-02, 8.5328e-02, 2.2196e-03,
        3.0688e-02, 1.4773e-03, 1.6210e-03, 1.0686e-03, 5.1145e-03, 2.8774e-02,
        3.1720e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,571][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0011, 0.0316, 0.0496, 0.0579, 0.0694, 0.0831, 0.0786, 0.0573, 0.0706,
        0.1110, 0.1379, 0.1289, 0.1228], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,572][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([2.9761e-04, 1.5307e-02, 3.3234e-04, 2.5530e-02, 9.7026e-05, 1.3531e-02,
        1.3945e-02, 4.5321e-03, 6.8457e-02, 7.7975e-04, 9.4390e-02, 1.0803e-02,
        7.5200e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:17,575][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0245, 0.0658, 0.0336, 0.0993, 0.0481, 0.0816, 0.1333, 0.0923, 0.1270,
        0.0453, 0.0596, 0.0834, 0.0449, 0.0615], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,579][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.3077, 0.0424, 0.0186, 0.0861, 0.0059, 0.0722, 0.1265, 0.0107, 0.0908,
        0.0037, 0.0684, 0.0948, 0.0035, 0.0688], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,583][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1045, 0.0646, 0.0699, 0.0697, 0.0767, 0.0651, 0.0678, 0.0715, 0.0626,
        0.0760, 0.0627, 0.0646, 0.0743, 0.0699], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,586][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1945, 0.0916, 0.0664, 0.0647, 0.0729, 0.0675, 0.0652, 0.0610, 0.0604,
        0.0499, 0.0555, 0.0543, 0.0445, 0.0517], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,587][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.1072, 0.0500, 0.0599, 0.0575, 0.0704, 0.0594, 0.0583, 0.0518, 0.0546,
        0.0599, 0.0771, 0.0776, 0.0854, 0.1309], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,588][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([5.1354e-03, 9.9481e-01, 2.3251e-07, 1.8146e-08, 3.9785e-07, 7.3181e-07,
        1.6813e-07, 5.1038e-05, 4.3132e-07, 3.9985e-08, 1.0048e-06, 2.0400e-07,
        2.3703e-07, 7.4075e-08], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,589][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.6028, 0.0068, 0.0165, 0.0093, 0.0556, 0.0029, 0.0046, 0.0082, 0.0107,
        0.0150, 0.0265, 0.0241, 0.0756, 0.1414], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,591][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0130, 0.0183, 0.1676, 0.0332, 0.1822, 0.0716, 0.0502, 0.1175, 0.0601,
        0.0938, 0.0890, 0.0430, 0.0305, 0.0299], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,593][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([2.5252e-01, 3.9222e-03, 1.6656e-02, 4.2647e-04, 1.4785e-02, 1.0871e-02,
        1.1602e-03, 6.0151e-02, 3.8225e-03, 1.2448e-01, 4.0532e-01, 3.3663e-04,
        1.0322e-01, 2.3296e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,595][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([2.7133e-04, 2.2582e-01, 4.9437e-02, 9.4555e-03, 1.3416e-01, 8.0135e-04,
        4.0412e-03, 8.6816e-04, 3.7336e-04, 3.9869e-04, 1.1298e-03, 2.2384e-03,
        1.3960e-01, 4.3141e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,599][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0024, 0.0235, 0.0409, 0.0448, 0.0591, 0.0685, 0.0583, 0.0443, 0.0604,
        0.0873, 0.1080, 0.1010, 0.1094, 0.1921], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,603][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0096, 0.0460, 0.0897, 0.0157, 0.0298, 0.1752, 0.0408, 0.0776, 0.0142,
        0.0457, 0.0346, 0.1686, 0.0596, 0.1929], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:17,605][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.0217, 0.0688, 0.0269, 0.1042, 0.0375, 0.0795, 0.1425, 0.0954, 0.1379,
        0.0364, 0.0578, 0.0827, 0.0366, 0.0589, 0.0132], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,606][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.1110, 0.0274, 0.0106, 0.0794, 0.0044, 0.0807, 0.1709, 0.0119, 0.1401,
        0.0036, 0.1027, 0.1514, 0.0039, 0.1000, 0.0022], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,607][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.1011, 0.0658, 0.0628, 0.0678, 0.0668, 0.0617, 0.0610, 0.0635, 0.0583,
        0.0681, 0.0594, 0.0597, 0.0659, 0.0659, 0.0720], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,609][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.1879, 0.0893, 0.0585, 0.0622, 0.0648, 0.0645, 0.0632, 0.0576, 0.0579,
        0.0478, 0.0529, 0.0530, 0.0419, 0.0496, 0.0488], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,611][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.1066, 0.0801, 0.0389, 0.0777, 0.0459, 0.0765, 0.0716, 0.0365, 0.0545,
        0.0435, 0.0711, 0.0788, 0.0431, 0.1350, 0.0402], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,613][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([5.0309e-03, 9.9481e-01, 2.1240e-05, 8.3582e-07, 4.2352e-06, 5.8570e-06,
        1.1296e-06, 1.0075e-04, 1.6695e-06, 6.1690e-07, 5.4135e-06, 8.1316e-07,
        1.7005e-06, 7.0764e-07, 1.0978e-05], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,618][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.3408, 0.0041, 0.0244, 0.0111, 0.0564, 0.0034, 0.0045, 0.0103, 0.0106,
        0.0205, 0.0292, 0.0252, 0.0862, 0.2126, 0.1608], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,622][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0029, 0.0091, 0.1459, 0.0081, 0.0670, 0.1586, 0.0279, 0.2824, 0.0111,
        0.0889, 0.0165, 0.0336, 0.0364, 0.0475, 0.0641], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,623][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([3.7792e-02, 3.5076e-03, 6.6069e-03, 9.5833e-04, 1.7148e-02, 1.5597e-03,
        2.7291e-04, 6.9871e-02, 1.1185e-02, 1.9608e-01, 3.6900e-01, 2.3783e-04,
        2.5692e-01, 5.1814e-03, 2.3676e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,624][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([2.2756e-04, 2.1228e-01, 3.0697e-02, 5.2348e-03, 8.5778e-02, 8.1566e-04,
        6.8970e-03, 7.6170e-04, 4.2723e-04, 4.5162e-04, 1.8169e-03, 5.5479e-03,
        1.7257e-01, 3.5707e-01, 1.1942e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,625][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0011, 0.0267, 0.0391, 0.0452, 0.0552, 0.0695, 0.0591, 0.0410, 0.0545,
        0.0786, 0.1028, 0.0970, 0.0874, 0.1554, 0.0874], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,626][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([9.2483e-06, 6.9124e-06, 3.8825e-04, 1.7029e-06, 4.4444e-02, 2.5661e-04,
        2.2067e-04, 1.4693e-05, 3.3116e-05, 2.3564e-04, 1.9684e-05, 2.2407e-04,
        3.1623e-06, 5.2625e-04, 9.5362e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:17,629][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0219, 0.0648, 0.0294, 0.0973, 0.0426, 0.0751, 0.1300, 0.0913, 0.1240,
        0.0401, 0.0571, 0.0791, 0.0408, 0.0586, 0.0171, 0.0308],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,632][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1809, 0.0345, 0.0144, 0.0870, 0.0054, 0.0756, 0.1537, 0.0115, 0.1153,
        0.0037, 0.0864, 0.1250, 0.0038, 0.0881, 0.0028, 0.0119],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,636][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0932, 0.0595, 0.0591, 0.0614, 0.0652, 0.0557, 0.0561, 0.0591, 0.0540,
        0.0620, 0.0544, 0.0540, 0.0634, 0.0598, 0.0693, 0.0738],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,640][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1647, 0.0811, 0.0605, 0.0598, 0.0657, 0.0605, 0.0590, 0.0555, 0.0548,
        0.0463, 0.0512, 0.0495, 0.0417, 0.0479, 0.0498, 0.0520],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,641][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0904, 0.0578, 0.0424, 0.0714, 0.0531, 0.0565, 0.0573, 0.0277, 0.0559,
        0.0387, 0.0717, 0.0701, 0.0537, 0.1366, 0.0463, 0.0703],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,642][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.2200e-02, 9.8777e-01, 9.0575e-08, 7.1600e-09, 2.0072e-07, 4.5051e-07,
        1.0228e-07, 2.0936e-05, 3.0163e-07, 1.5709e-08, 6.4030e-07, 1.7842e-07,
        2.5573e-07, 5.4804e-08, 2.7463e-06, 3.0336e-08], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,643][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.3020, 0.0026, 0.0148, 0.0048, 0.0281, 0.0010, 0.0031, 0.0046, 0.0077,
        0.0136, 0.0233, 0.0253, 0.0992, 0.2114, 0.2206, 0.0380],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,645][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0017, 0.0048, 0.0455, 0.0049, 0.1079, 0.1017, 0.0026, 0.2711, 0.0170,
        0.2200, 0.0236, 0.0052, 0.0517, 0.0137, 0.1117, 0.0169],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,647][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.0564e-01, 3.6573e-03, 2.3229e-03, 7.7106e-04, 3.7660e-03, 2.9433e-03,
        3.8699e-04, 2.7065e-02, 8.5214e-03, 3.9848e-02, 6.8044e-01, 4.2079e-04,
        8.1030e-02, 2.8491e-03, 4.8388e-03, 3.5501e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,649][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.5834e-04, 2.2287e-01, 3.7156e-02, 6.4455e-03, 1.0318e-01, 7.1489e-04,
        5.7039e-03, 6.8419e-04, 4.6172e-04, 4.1131e-04, 1.5436e-03, 3.5904e-03,
        1.3820e-01, 3.5355e-01, 1.1704e-01, 8.1909e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,652][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0010, 0.0178, 0.0336, 0.0364, 0.0489, 0.0561, 0.0464, 0.0331, 0.0477,
        0.0684, 0.0897, 0.0804, 0.0869, 0.1478, 0.0841, 0.1218],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,654][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([7.8120e-06, 2.4977e-04, 1.3563e-04, 1.3503e-04, 2.2512e-04, 1.5916e-02,
        2.0720e-03, 5.6353e-04, 1.7556e-03, 4.3495e-03, 1.5057e-03, 1.8574e-03,
        1.5577e-04, 2.0118e-02, 2.3847e-03, 9.4857e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:17,658][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0260, 0.0636, 0.0306, 0.0896, 0.0420, 0.0720, 0.1137, 0.0833, 0.1120,
        0.0397, 0.0523, 0.0723, 0.0396, 0.0558, 0.0186, 0.0313, 0.0574],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,659][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2573, 0.0394, 0.0179, 0.0796, 0.0061, 0.0698, 0.1152, 0.0107, 0.0847,
        0.0037, 0.0651, 0.0879, 0.0036, 0.0651, 0.0031, 0.0110, 0.0797],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,660][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0846, 0.0538, 0.0552, 0.0570, 0.0601, 0.0519, 0.0550, 0.0584, 0.0509,
        0.0615, 0.0509, 0.0524, 0.0600, 0.0566, 0.0646, 0.0682, 0.0591],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,661][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1561, 0.0773, 0.0574, 0.0565, 0.0626, 0.0573, 0.0569, 0.0531, 0.0521,
        0.0439, 0.0486, 0.0476, 0.0393, 0.0452, 0.0483, 0.0497, 0.0480],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,663][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0848, 0.0500, 0.0363, 0.0599, 0.0411, 0.0494, 0.0588, 0.0343, 0.0502,
        0.0442, 0.0644, 0.0754, 0.0576, 0.1197, 0.0390, 0.0662, 0.0688],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,665][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([5.9188e-03, 9.9402e-01, 2.0629e-07, 1.4111e-08, 2.8363e-07, 6.7890e-07,
        1.0914e-07, 5.2867e-05, 4.3356e-07, 4.7016e-08, 1.0794e-06, 2.5167e-07,
        3.6805e-07, 8.4838e-08, 3.4159e-06, 6.9516e-08, 1.4331e-07],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,669][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0556, 0.0053, 0.0397, 0.0140, 0.0315, 0.0011, 0.0022, 0.0058, 0.0092,
        0.0245, 0.0264, 0.0160, 0.1125, 0.4019, 0.1929, 0.0415, 0.0199],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,672][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0049, 0.0036, 0.0683, 0.0037, 0.0913, 0.0530, 0.0089, 0.5061, 0.0106,
        0.0758, 0.0128, 0.0095, 0.0141, 0.0154, 0.0891, 0.0235, 0.0094],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,675][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([3.4870e-01, 4.0940e-03, 3.3696e-03, 9.9813e-04, 2.6692e-03, 2.5203e-03,
        3.6417e-04, 1.9119e-02, 1.0020e-02, 1.9801e-02, 5.2597e-01, 3.8039e-04,
        3.5309e-02, 1.5968e-03, 2.9256e-03, 2.1389e-02, 7.6751e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,676][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.0957e-04, 1.9498e-01, 3.0415e-02, 7.7101e-03, 1.2062e-01, 6.4250e-04,
        6.2999e-03, 5.1307e-04, 3.4349e-04, 3.3814e-04, 1.4268e-03, 3.9957e-03,
        1.4995e-01, 3.5563e-01, 1.0511e-01, 7.6584e-03, 1.4152e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,677][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0017, 0.0138, 0.0289, 0.0300, 0.0422, 0.0488, 0.0480, 0.0304, 0.0402,
        0.0586, 0.0761, 0.0743, 0.0720, 0.1298, 0.0732, 0.1166, 0.1152],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,678][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([7.3307e-06, 5.7140e-05, 4.4732e-04, 9.2159e-06, 7.0329e-04, 6.9960e-03,
        2.9690e-02, 3.6243e-04, 2.9469e-04, 4.4226e-03, 8.3585e-04, 1.0838e-02,
        3.8189e-04, 4.5177e-03, 7.9873e-02, 1.9577e-02, 8.4099e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:17,679][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0162, 0.0581, 0.0244, 0.0936, 0.0359, 0.0710, 0.1282, 0.0827, 0.1196,
        0.0322, 0.0495, 0.0718, 0.0336, 0.0505, 0.0123, 0.0258, 0.0559, 0.0387],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,681][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.1116, 0.0240, 0.0103, 0.0691, 0.0045, 0.0700, 0.1500, 0.0107, 0.1146,
        0.0034, 0.0842, 0.1244, 0.0036, 0.0806, 0.0023, 0.0117, 0.1205, 0.0045],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,684][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.0851, 0.0538, 0.0526, 0.0538, 0.0557, 0.0499, 0.0501, 0.0519, 0.0472,
        0.0558, 0.0481, 0.0477, 0.0553, 0.0537, 0.0600, 0.0654, 0.0533, 0.0606],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,688][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.1651, 0.0765, 0.0514, 0.0530, 0.0582, 0.0555, 0.0539, 0.0507, 0.0503,
        0.0411, 0.0462, 0.0456, 0.0359, 0.0430, 0.0429, 0.0483, 0.0459, 0.0364],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,692][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.1011, 0.0524, 0.0439, 0.0575, 0.0455, 0.0469, 0.0472, 0.0246, 0.0474,
        0.0409, 0.0589, 0.0573, 0.0438, 0.1155, 0.0448, 0.0642, 0.0586, 0.0495],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,694][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([1.5977e-02, 9.8366e-01, 9.8147e-07, 1.6688e-07, 2.4841e-06, 3.7722e-06,
        1.3695e-06, 2.9781e-04, 3.4494e-06, 4.9935e-07, 5.5215e-06, 2.9039e-06,
        3.1800e-06, 1.1026e-06, 2.7208e-05, 7.3868e-07, 2.3976e-06, 6.2184e-06],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,695][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0623, 0.0076, 0.0621, 0.0233, 0.0347, 0.0016, 0.0027, 0.0060, 0.0079,
        0.0195, 0.0232, 0.0142, 0.0816, 0.3759, 0.1712, 0.0454, 0.0187, 0.0421],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,696][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0028, 0.0070, 0.0488, 0.0059, 0.2142, 0.0246, 0.0509, 0.1170, 0.0123,
        0.1091, 0.0138, 0.0453, 0.0471, 0.0139, 0.2205, 0.0099, 0.0544, 0.0027],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,697][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.0621, 0.0057, 0.0149, 0.0010, 0.0259, 0.0035, 0.0007, 0.0492, 0.0036,
        0.0860, 0.3178, 0.0005, 0.1774, 0.0059, 0.0361, 0.1932, 0.0020, 0.0144],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,698][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([2.7591e-04, 2.0929e-01, 2.2889e-02, 5.9614e-03, 8.2505e-02, 7.1224e-04,
        7.7856e-03, 6.6501e-04, 4.6489e-04, 4.2860e-04, 1.9632e-03, 7.1506e-03,
        1.8726e-01, 3.2379e-01, 1.0158e-01, 9.4224e-03, 1.9573e-02, 1.8278e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,701][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0019, 0.0117, 0.0253, 0.0251, 0.0367, 0.0404, 0.0384, 0.0252, 0.0389,
        0.0551, 0.0686, 0.0666, 0.0691, 0.1292, 0.0658, 0.1048, 0.0951, 0.1022],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,703][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([8.9733e-05, 1.3694e-03, 1.8748e-04, 8.0596e-04, 5.9247e-04, 1.9122e-03,
        2.7097e-04, 2.4459e-03, 1.6743e-03, 8.5599e-04, 1.0393e-03, 5.4870e-04,
        5.5269e-05, 6.2371e-03, 2.0593e-04, 1.6463e-03, 5.4209e-04, 9.7952e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:17,708][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0217, 0.0546, 0.0271, 0.0781, 0.0369, 0.0635, 0.1039, 0.0769, 0.1008,
        0.0362, 0.0490, 0.0676, 0.0367, 0.0511, 0.0166, 0.0288, 0.0544, 0.0418,
        0.0544], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,712][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.2502, 0.0375, 0.0167, 0.0736, 0.0056, 0.0646, 0.1084, 0.0101, 0.0785,
        0.0036, 0.0606, 0.0822, 0.0035, 0.0613, 0.0030, 0.0104, 0.0750, 0.0041,
        0.0512], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,713][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0740, 0.0472, 0.0500, 0.0495, 0.0548, 0.0472, 0.0486, 0.0514, 0.0452,
        0.0536, 0.0457, 0.0465, 0.0537, 0.0501, 0.0585, 0.0633, 0.0522, 0.0577,
        0.0509], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,714][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1418, 0.0693, 0.0534, 0.0523, 0.0582, 0.0533, 0.0519, 0.0506, 0.0479,
        0.0409, 0.0446, 0.0443, 0.0351, 0.0406, 0.0463, 0.0457, 0.0443, 0.0365,
        0.0427], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,715][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0828, 0.0428, 0.0356, 0.0486, 0.0420, 0.0470, 0.0491, 0.0249, 0.0434,
        0.0310, 0.0583, 0.0601, 0.0480, 0.0963, 0.0379, 0.0673, 0.0580, 0.0484,
        0.0785], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,716][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.4280e-03, 9.9544e-01, 1.1397e-06, 1.0852e-07, 1.4176e-06, 3.1624e-06,
        9.7146e-07, 7.3686e-05, 2.2029e-06, 2.7956e-07, 5.5523e-06, 1.8243e-06,
        1.8333e-06, 6.5521e-07, 1.3648e-05, 3.9140e-07, 1.1460e-06, 1.5961e-06,
        1.8360e-05], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,719][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0246, 0.0075, 0.0308, 0.0103, 0.0180, 0.0006, 0.0016, 0.0025, 0.0077,
        0.0263, 0.0230, 0.0158, 0.0866, 0.3654, 0.2007, 0.0387, 0.0191, 0.0517,
        0.0689], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,723][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0059, 0.0143, 0.0628, 0.0103, 0.0887, 0.0969, 0.0109, 0.2134, 0.0293,
        0.0788, 0.0196, 0.0089, 0.0173, 0.0377, 0.0855, 0.0599, 0.0112, 0.1403,
        0.0081], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,725][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.1258e-01, 2.1759e-03, 3.6473e-03, 3.0872e-04, 4.0892e-03, 3.5903e-03,
        4.4445e-04, 2.1747e-02, 4.7140e-03, 3.5688e-02, 5.8379e-01, 2.7859e-04,
        6.2511e-02, 1.0753e-03, 5.2114e-03, 3.1750e-02, 1.1401e-03, 9.9866e-03,
        1.5268e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,728][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.4066e-04, 3.3996e-01, 1.8624e-02, 3.6300e-03, 3.4986e-02, 1.0152e-03,
        1.8905e-02, 6.7055e-04, 1.1384e-03, 6.6092e-04, 3.0920e-03, 1.5067e-02,
        1.3719e-01, 2.6443e-01, 8.8688e-02, 7.6683e-03, 4.1732e-02, 1.9859e-02,
        2.5335e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,731][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0021, 0.0101, 0.0223, 0.0229, 0.0346, 0.0392, 0.0334, 0.0211, 0.0323,
        0.0432, 0.0601, 0.0546, 0.0525, 0.1011, 0.0587, 0.0944, 0.0819, 0.0887,
        0.1468], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,731][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0013, 0.0094, 0.0086, 0.0032, 0.0032, 0.0698, 0.0298, 0.0049, 0.0074,
        0.0130, 0.0216, 0.0682, 0.0057, 0.1402, 0.0707, 0.0300, 0.2739, 0.0031,
        0.2358], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:17,735][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:17,738][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15603],
        [11263],
        [   18],
        [10909],
        [ 8679],
        [18559],
        [31183],
        [10657],
        [13431],
        [21665],
        [34780],
        [26444],
        [37169],
        [18957],
        [18802],
        [33850],
        [34405],
        [28613],
        [26741]], device='cuda:0')
[2024-07-24 10:27:17,741][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[37153],
        [38731],
        [    2],
        [34957],
        [ 3995],
        [28510],
        [40675],
        [15038],
        [30705],
        [29755],
        [44648],
        [33118],
        [32943],
        [31285],
        [ 5658],
        [21808],
        [37242],
        [38288],
        [35459]], device='cuda:0')
[2024-07-24 10:27:17,743][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[7415],
        [7462],
        [8383],
        [9474],
        [9746],
        [9853],
        [9734],
        [9552],
        [9560],
        [9621],
        [9546],
        [9415],
        [9390],
        [9541],
        [9540],
        [9582],
        [9667],
        [9707],
        [9732]], device='cuda:0')
[2024-07-24 10:27:17,746][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30302],
        [22207],
        [15129],
        [17779],
        [15013],
        [15489],
        [19085],
        [21435],
        [24945],
        [21354],
        [21651],
        [26898],
        [29932],
        [21974],
        [22469],
        [22119],
        [22251],
        [29420],
        [25682]], device='cuda:0')
[2024-07-24 10:27:17,749][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[41242],
        [42436],
        [44252],
        [44280],
        [44719],
        [44797],
        [44883],
        [45079],
        [44984],
        [45177],
        [45411],
        [45473],
        [45351],
        [45365],
        [45526],
        [45645],
        [45721],
        [46021],
        [46068]], device='cuda:0')
[2024-07-24 10:27:17,751][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[45468],
        [41142],
        [38611],
        [35991],
        [36743],
        [34787],
        [33711],
        [34513],
        [33866],
        [33919],
        [33508],
        [32656],
        [32557],
        [32482],
        [33150],
        [32868],
        [32080],
        [31716],
        [31559]], device='cuda:0')
[2024-07-24 10:27:17,753][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13125],
        [14678],
        [15003],
        [11873],
        [11217],
        [10727],
        [10777],
        [ 9843],
        [ 9176],
        [10444],
        [10345],
        [10594],
        [ 9941],
        [11034],
        [10629],
        [11018],
        [10534],
        [10736],
        [10377]], device='cuda:0')
[2024-07-24 10:27:17,754][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 5790],
        [22201],
        [39274],
        [28751],
        [42966],
        [34385],
        [38229],
        [26025],
        [ 3969],
        [23958],
        [14587],
        [17649],
        [23505],
        [35181],
        [42813],
        [28515],
        [20196],
        [ 4752],
        [ 3860]], device='cuda:0')
[2024-07-24 10:27:17,756][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[18644],
        [19276],
        [ 1726],
        [ 7143],
        [27888],
        [13787],
        [16097],
        [27684],
        [38320],
        [10032],
        [14445],
        [21149],
        [47684],
        [10705],
        [27201],
        [46456],
        [41841],
        [30522],
        [40750]], device='cuda:0')
[2024-07-24 10:27:17,759][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[15703],
        [15686],
        [ 1171],
        [ 5847],
        [ 5314],
        [ 4790],
        [ 8821],
        [10227],
        [ 7574],
        [ 8437],
        [ 5306],
        [ 8060],
        [ 6261],
        [ 4345],
        [ 5056],
        [ 4709],
        [ 6402],
        [ 7561],
        [ 7281]], device='cuda:0')
[2024-07-24 10:27:17,762][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 3020],
        [ 2820],
        [ 3347],
        [ 5945],
        [ 5662],
        [ 9381],
        [ 6250],
        [ 7297],
        [ 7935],
        [10139],
        [ 8764],
        [13241],
        [14692],
        [12658],
        [15015],
        [14959],
        [12685],
        [14587],
        [13623]], device='cuda:0')
[2024-07-24 10:27:17,764][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[4246],
        [2566],
        [3484],
        [4122],
        [4564],
        [5058],
        [6478],
        [6276],
        [6438],
        [6386],
        [6658],
        [7738],
        [7208],
        [6250],
        [6210],
        [6465],
        [6841],
        [6684],
        [6944]], device='cuda:0')
[2024-07-24 10:27:17,767][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[3724],
        [5894],
        [6606],
        [6585],
        [5940],
        [6019],
        [5821],
        [5653],
        [5456],
        [5211],
        [5182],
        [5065],
        [5040],
        [5104],
        [5049],
        [5115],
        [5066],
        [4959],
        [4930]], device='cuda:0')
[2024-07-24 10:27:17,770][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14699],
        [35290],
        [46516],
        [42170],
        [47285],
        [48311],
        [48292],
        [47356],
        [46705],
        [48364],
        [47382],
        [47781],
        [48923],
        [47674],
        [49047],
        [48845],
        [48779],
        [49457],
        [47960]], device='cuda:0')
[2024-07-24 10:27:17,772][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[12725],
        [ 1516],
        [ 1507],
        [ 4128],
        [ 8247],
        [ 5022],
        [ 9584],
        [13956],
        [ 4697],
        [16847],
        [10630],
        [ 6806],
        [16941],
        [ 8842],
        [24624],
        [21690],
        [14944],
        [ 9153],
        [ 5893]], device='cuda:0')
[2024-07-24 10:27:17,774][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[23612],
        [32299],
        [33063],
        [34724],
        [36052],
        [36791],
        [36540],
        [36923],
        [36844],
        [37128],
        [36993],
        [36759],
        [36963],
        [36707],
        [36617],
        [36586],
        [36254],
        [36372],
        [36096]], device='cuda:0')
[2024-07-24 10:27:17,775][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12472],
        [13368],
        [14265],
        [15797],
        [17078],
        [16497],
        [15388],
        [15365],
        [15224],
        [14860],
        [15238],
        [15071],
        [14741],
        [14943],
        [14640],
        [14791],
        [14652],
        [14290],
        [14711]], device='cuda:0')
[2024-07-24 10:27:17,777][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[22296],
        [21791],
        [19230],
        [18944],
        [18166],
        [17838],
        [18075],
        [18063],
        [17944],
        [17946],
        [17675],
        [17570],
        [17498],
        [17578],
        [17294],
        [16879],
        [16951],
        [16635],
        [16544]], device='cuda:0')
[2024-07-24 10:27:17,780][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[15007],
        [19130],
        [18990],
        [18697],
        [16816],
        [15711],
        [14845],
        [14277],
        [13640],
        [13295],
        [12681],
        [12245],
        [12176],
        [11813],
        [11540],
        [11225],
        [10916],
        [10888],
        [10471]], device='cuda:0')
[2024-07-24 10:27:17,782][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[21304],
        [21835],
        [18322],
        [24003],
        [22969],
        [21289],
        [24753],
        [23157],
        [25941],
        [24663],
        [24835],
        [25262],
        [23149],
        [22866],
        [24452],
        [23806],
        [23169],
        [23042],
        [22994]], device='cuda:0')
[2024-07-24 10:27:17,785][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[40934],
        [25199],
        [25294],
        [25204],
        [25710],
        [25199],
        [25215],
        [25212],
        [25213],
        [25252],
        [25210],
        [25221],
        [25228],
        [25227],
        [25226],
        [25276],
        [25234],
        [25301],
        [25222]], device='cuda:0')
[2024-07-24 10:27:17,788][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[34348],
        [34340],
        [34209],
        [34210],
        [30601],
        [30575],
        [20875],
        [25454],
        [18625],
        [26380],
        [18169],
        [13785],
        [12248],
        [18084],
        [14716],
        [14668],
        [15102],
        [15033],
        [14891]], device='cuda:0')
[2024-07-24 10:27:17,790][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 8370],
        [11420],
        [21478],
        [20627],
        [27596],
        [38125],
        [37116],
        [24265],
        [24245],
        [27581],
        [29682],
        [26346],
        [32276],
        [23494],
        [26057],
        [31785],
        [26635],
        [30377],
        [27209]], device='cuda:0')
[2024-07-24 10:27:17,793][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 2899],
        [ 2957],
        [ 2983],
        [ 2960],
        [ 2864],
        [ 3200],
        [ 2901],
        [ 8617],
        [ 3926],
        [27021],
        [ 7893],
        [ 5486],
        [16911],
        [12010],
        [24298],
        [12303],
        [ 6271],
        [22995],
        [ 9714]], device='cuda:0')
[2024-07-24 10:27:17,794][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[23193],
        [34477],
        [33354],
        [33512],
        [33525],
        [32882],
        [32699],
        [32809],
        [32690],
        [32671],
        [32546],
        [32092],
        [34134],
        [41680],
        [42183],
        [41864],
        [42062],
        [41875],
        [39545]], device='cuda:0')
[2024-07-24 10:27:17,796][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15551],
        [16159],
        [10554],
        [ 6790],
        [ 6923],
        [ 5931],
        [ 6482],
        [ 6539],
        [ 7159],
        [ 8501],
        [ 8142],
        [ 9114],
        [ 9453],
        [11044],
        [10258],
        [ 9539],
        [ 9773],
        [ 9990],
        [ 8920]], device='cuda:0')
[2024-07-24 10:27:17,798][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[17969],
        [11903],
        [22167],
        [13118],
        [26630],
        [12863],
        [12708],
        [16359],
        [13832],
        [23485],
        [14205],
        [13180],
        [19293],
        [14596],
        [25030],
        [13909],
        [13203],
        [21705],
        [13976]], device='cuda:0')
[2024-07-24 10:27:17,800][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[18216],
        [20162],
        [18390],
        [19326],
        [15889],
        [17538],
        [19786],
        [17001],
        [21154],
        [13250],
        [18623],
        [20520],
        [19206],
        [17945],
        [16205],
        [18550],
        [19726],
        [17415],
        [21158]], device='cuda:0')
[2024-07-24 10:27:17,803][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[12614],
        [48616],
        [49675],
        [44084],
        [42537],
        [42817],
        [39155],
        [32955],
        [44505],
        [25062],
        [36604],
        [41631],
        [21722],
        [36106],
        [16223],
        [19949],
        [31246],
        [27840],
        [41643]], device='cuda:0')
[2024-07-24 10:27:17,806][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025],
        [29025]], device='cuda:0')
[2024-07-24 10:27:17,843][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:17,844][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,844][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,845][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,846][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,846][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,847][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,848][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,849][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,849][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,850][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,850][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,851][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:17,852][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1818, 0.8182], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,853][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7240, 0.2760], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,853][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2766, 0.7234], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,855][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3788, 0.6212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,858][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0670, 0.9330], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,862][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7793, 0.2207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,865][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3308, 0.6692], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,868][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6650, 0.3350], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,869][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9041, 0.0959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,869][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4994, 0.5006], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,870][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1401, 0.8599], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,872][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8381, 0.1619], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:17,874][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.1413, 0.0377, 0.8210], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,878][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([0.4581, 0.2995, 0.2424], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,882][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.1137, 0.5748, 0.3115], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,885][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.0654, 0.1783, 0.7563], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,886][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.0012, 0.2953, 0.7035], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,887][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([0.0802, 0.8732, 0.0466], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,887][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.1062, 0.2672, 0.6266], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,888][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.3960, 0.1768, 0.4272], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,890][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.5453, 0.4402, 0.0145], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,893][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.2528, 0.3837, 0.3635], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,897][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.0093, 0.1877, 0.8030], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,901][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.7783, 0.1175, 0.1043], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:17,903][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1106, 0.0884, 0.6650, 0.1360], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,904][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3122, 0.1668, 0.2023, 0.3187], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,905][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0361, 0.1382, 0.6301, 0.1956], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,906][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0509, 0.1080, 0.5874, 0.2538], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,906][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0016, 0.1239, 0.3076, 0.5669], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,908][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2491, 0.5376, 0.2052, 0.0080], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,911][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1230, 0.2500, 0.4429, 0.1841], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,915][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2803, 0.0764, 0.1721, 0.4712], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,919][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4373, 0.3569, 0.1496, 0.0561], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,921][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1423, 0.2481, 0.4354, 0.1742], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,922][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0158, 0.1097, 0.7100, 0.1645], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,923][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.6476, 0.1216, 0.0933, 0.1376], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:17,924][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0315, 0.0098, 0.4087, 0.0527, 0.4973], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,925][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.3021, 0.1643, 0.1787, 0.1747, 0.1802], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,927][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0305, 0.1249, 0.4654, 0.2774, 0.1018], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,930][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0237, 0.0670, 0.4302, 0.1712, 0.3080], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,932][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([1.3806e-04, 1.4918e-02, 3.2750e-01, 2.2521e-01, 4.3223e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,936][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.1579, 0.6054, 0.1059, 0.1236, 0.0072], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,940][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0510, 0.1172, 0.3032, 0.0977, 0.4310], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,941][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.2051, 0.0633, 0.1449, 0.3797, 0.2069], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,941][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.4116, 0.2342, 0.0712, 0.2623, 0.0207], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,942][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.1254, 0.2123, 0.3271, 0.1900, 0.1452], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,943][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0033, 0.1090, 0.3902, 0.1093, 0.3882], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,945][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.6032, 0.0790, 0.0699, 0.1024, 0.1454], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:17,948][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0585, 0.0110, 0.1731, 0.0509, 0.6428, 0.0636], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,952][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.2782, 0.0934, 0.1439, 0.1997, 0.1580, 0.1268], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,956][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0195, 0.1148, 0.2316, 0.3169, 0.2010, 0.1162], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,958][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0492, 0.0735, 0.2865, 0.1811, 0.2812, 0.1285], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,959][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([3.8404e-05, 1.1036e-02, 1.3171e-02, 2.0985e-01, 1.1099e-01, 6.5492e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,960][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0508, 0.5181, 0.1005, 0.1157, 0.2126, 0.0023], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,960][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0583, 0.1258, 0.2486, 0.0888, 0.3326, 0.1459], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,960][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1438, 0.0430, 0.0977, 0.2742, 0.1364, 0.3049], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,961][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1650, 0.5388, 0.0789, 0.0865, 0.1005, 0.0303], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,962][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1019, 0.1560, 0.2715, 0.1348, 0.2147, 0.1211], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,965][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0052, 0.0677, 0.3326, 0.0684, 0.3877, 0.1384], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,969][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.5091, 0.0854, 0.0828, 0.1136, 0.1478, 0.0613], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:17,973][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0687, 0.0239, 0.1964, 0.0843, 0.4229, 0.1302, 0.0737],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,976][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1922, 0.0833, 0.1172, 0.1696, 0.1144, 0.0901, 0.2332],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,976][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0252, 0.0731, 0.1482, 0.2624, 0.0662, 0.3972, 0.0277],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,976][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0245, 0.0478, 0.2185, 0.1471, 0.2328, 0.1309, 0.1984],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,977][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([2.6747e-05, 2.7490e-03, 1.8912e-02, 3.8832e-02, 3.6078e-01, 3.5915e-01,
        2.1955e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,977][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0733, 0.5273, 0.2018, 0.0662, 0.0802, 0.0495, 0.0016],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,977][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0592, 0.1186, 0.2024, 0.0939, 0.2865, 0.1425, 0.0969],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,978][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1177, 0.0282, 0.0573, 0.1772, 0.0730, 0.1785, 0.3682],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,978][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1025, 0.0929, 0.0594, 0.1441, 0.0366, 0.5589, 0.0056],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,978][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0993, 0.1469, 0.2180, 0.1129, 0.1654, 0.1570, 0.1003],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,980][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0059, 0.0565, 0.2741, 0.0799, 0.2927, 0.1490, 0.1418],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,983][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.4874, 0.0805, 0.0761, 0.1032, 0.1411, 0.0538, 0.0581],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:17,987][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0254, 0.0044, 0.1551, 0.0398, 0.5298, 0.0630, 0.0626, 0.1200],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,991][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.1509, 0.0555, 0.0688, 0.1135, 0.0618, 0.0699, 0.2186, 0.2610],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,994][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0080, 0.0504, 0.1321, 0.1359, 0.1161, 0.2378, 0.1668, 0.1531],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,994][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0089, 0.0241, 0.1646, 0.0840, 0.1943, 0.1351, 0.2257, 0.1632],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,994][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([1.5300e-05, 9.4331e-04, 5.7097e-03, 1.9226e-02, 1.6075e-01, 3.0702e-01,
        1.8986e-01, 3.1647e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,994][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([1.7658e-02, 5.3983e-01, 2.2332e-01, 1.1775e-01, 7.2993e-02, 2.0395e-02,
        7.7253e-03, 3.3362e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,995][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0392, 0.0776, 0.1846, 0.0651, 0.2390, 0.1155, 0.0726, 0.2063],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,995][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0733, 0.0227, 0.0463, 0.1334, 0.0608, 0.1382, 0.2882, 0.2372],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,995][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0325, 0.1883, 0.0235, 0.0808, 0.0140, 0.6471, 0.0115, 0.0023],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,996][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0703, 0.1239, 0.1706, 0.1099, 0.1317, 0.1609, 0.1256, 0.1072],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,996][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0017, 0.0473, 0.2206, 0.0551, 0.2147, 0.1187, 0.1002, 0.2416],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,996][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.4841, 0.0648, 0.0596, 0.0899, 0.1180, 0.0533, 0.0540, 0.0764],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:17,998][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0766, 0.0107, 0.1535, 0.0367, 0.4738, 0.0620, 0.0453, 0.0952, 0.0462],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,001][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.1190, 0.0433, 0.0794, 0.1465, 0.0612, 0.0413, 0.2406, 0.1450, 0.1237],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,005][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0060, 0.0170, 0.1139, 0.0608, 0.0621, 0.1167, 0.0475, 0.5627, 0.0133],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,009][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0138, 0.0256, 0.1382, 0.0787, 0.1755, 0.0965, 0.1948, 0.1962, 0.0807],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,012][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ of] are: tensor([3.7762e-07, 1.5129e-05, 4.6652e-04, 4.0097e-04, 1.8584e-02, 2.6926e-03,
        4.6518e-03, 9.1319e-01, 5.9994e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,012][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0514, 0.2281, 0.5336, 0.0590, 0.0757, 0.0160, 0.0305, 0.0045, 0.0011],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,012][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0421, 0.0848, 0.1481, 0.0709, 0.2002, 0.1056, 0.0808, 0.1923, 0.0751],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,013][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0633, 0.0134, 0.0239, 0.0844, 0.0302, 0.0827, 0.1795, 0.1321, 0.3904],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,013][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0308, 0.0581, 0.2087, 0.1105, 0.0224, 0.5299, 0.0186, 0.0182, 0.0030],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,013][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0735, 0.0978, 0.1608, 0.0788, 0.1457, 0.1263, 0.0962, 0.1488, 0.0720],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,014][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0031, 0.0463, 0.2079, 0.0624, 0.2086, 0.1116, 0.1136, 0.1615, 0.0849],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,014][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.4068, 0.0699, 0.0647, 0.0886, 0.1233, 0.0478, 0.0516, 0.0738, 0.0734],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,014][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0203, 0.0033, 0.1139, 0.0340, 0.2726, 0.0603, 0.1346, 0.0910, 0.2247,
        0.0454], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,015][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.1292, 0.0530, 0.0873, 0.0963, 0.0693, 0.0603, 0.1465, 0.2123, 0.0690,
        0.0768], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,015][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0077, 0.0229, 0.0630, 0.0749, 0.0447, 0.2201, 0.0650, 0.2297, 0.2068,
        0.0652], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,017][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0078, 0.0175, 0.1146, 0.0544, 0.1035, 0.0734, 0.1627, 0.2475, 0.1039,
        0.1146], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,019][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([5.3388e-07, 3.2985e-05, 2.8895e-04, 5.2813e-04, 4.0394e-03, 2.1258e-02,
        1.2138e-02, 4.6182e-01, 1.1589e-01, 3.8400e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,022][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.1407, 0.4515, 0.1472, 0.0825, 0.0860, 0.0070, 0.0287, 0.0284, 0.0226,
        0.0055], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,026][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0289, 0.0626, 0.1472, 0.0422, 0.2168, 0.0859, 0.0492, 0.1757, 0.0493,
        0.1423], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,030][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0463, 0.0118, 0.0205, 0.0655, 0.0266, 0.0624, 0.1409, 0.1064, 0.3207,
        0.1988], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,030][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([3.0414e-02, 1.9939e-02, 7.2410e-03, 1.7699e-02, 1.3303e-02, 8.4814e-01,
        1.0059e-02, 2.0963e-02, 3.1563e-02, 6.7521e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,031][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0536, 0.0924, 0.1508, 0.0718, 0.1284, 0.1028, 0.0942, 0.1291, 0.0898,
        0.0872], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,031][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0009, 0.0347, 0.1462, 0.0408, 0.1778, 0.0943, 0.0752, 0.2092, 0.0518,
        0.1691], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,031][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.3753, 0.0656, 0.0607, 0.0789, 0.1096, 0.0484, 0.0506, 0.0716, 0.0692,
        0.0700], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,032][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0519, 0.0079, 0.1336, 0.0258, 0.4185, 0.0715, 0.0461, 0.0697, 0.0421,
        0.0976, 0.0351], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,032][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0915, 0.0480, 0.0808, 0.1369, 0.0746, 0.0462, 0.2101, 0.1330, 0.0859,
        0.0557, 0.0372], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,033][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0085, 0.0392, 0.0709, 0.0838, 0.0555, 0.1623, 0.0759, 0.2262, 0.1350,
        0.1212, 0.0215], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,033][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0100, 0.0174, 0.1025, 0.0530, 0.1223, 0.0759, 0.1377, 0.1731, 0.1010,
        0.1434, 0.0636], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,034][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ at] are: tensor([3.8549e-07, 5.3094e-06, 5.7617e-05, 8.8234e-05, 1.3158e-03, 8.4880e-04,
        1.4242e-03, 7.9929e-03, 2.1612e-02, 8.7406e-01, 9.2593e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,037][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.1002, 0.2989, 0.1587, 0.0635, 0.1239, 0.0313, 0.0840, 0.0831, 0.0289,
        0.0251, 0.0024], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,039][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0343, 0.0678, 0.1198, 0.0524, 0.1773, 0.0888, 0.0543, 0.1805, 0.0521,
        0.1271, 0.0457], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,044][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0471, 0.0092, 0.0157, 0.0493, 0.0196, 0.0485, 0.1017, 0.0798, 0.2060,
        0.1328, 0.2903], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,048][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0245, 0.0170, 0.0141, 0.0232, 0.0061, 0.6833, 0.0543, 0.1258, 0.0400,
        0.0079, 0.0038], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,048][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0584, 0.0826, 0.1289, 0.0598, 0.0980, 0.0950, 0.0818, 0.1255, 0.0639,
        0.1423, 0.0638], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,049][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0014, 0.0241, 0.1647, 0.0342, 0.1628, 0.0782, 0.0708, 0.1776, 0.0457,
        0.1408, 0.0997], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,049][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.3258, 0.0708, 0.0593, 0.0789, 0.0996, 0.0440, 0.0479, 0.0653, 0.0666,
        0.0653, 0.0766], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,049][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0641, 0.0055, 0.0839, 0.0284, 0.2102, 0.0584, 0.0498, 0.1116, 0.0750,
        0.0716, 0.0875, 0.1539], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,050][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0941, 0.0382, 0.0661, 0.1091, 0.0562, 0.0481, 0.1499, 0.1321, 0.0945,
        0.0581, 0.0378, 0.1158], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,050][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0065, 0.0229, 0.0574, 0.0819, 0.0350, 0.1657, 0.0339, 0.2346, 0.1543,
        0.1145, 0.0779, 0.0155], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,050][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0096, 0.0165, 0.0831, 0.0530, 0.0813, 0.0540, 0.1123, 0.1533, 0.0720,
        0.1442, 0.1029, 0.1176], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,051][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ the] are: tensor([6.0714e-07, 1.2020e-05, 1.5630e-04, 1.2738e-04, 1.6843e-03, 9.5975e-04,
        1.1647e-03, 3.2502e-02, 1.3867e-02, 4.5082e-01, 3.0896e-01, 1.8974e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,051][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0869, 0.3041, 0.3081, 0.0753, 0.0684, 0.0284, 0.0295, 0.0492, 0.0093,
        0.0240, 0.0095, 0.0072], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,051][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0337, 0.0652, 0.1052, 0.0529, 0.1531, 0.0887, 0.0532, 0.1602, 0.0590,
        0.1236, 0.0510, 0.0542], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,053][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0340, 0.0071, 0.0125, 0.0403, 0.0152, 0.0383, 0.0807, 0.0622, 0.1638,
        0.0983, 0.2223, 0.2254], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,056][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0199, 0.0312, 0.0123, 0.0823, 0.0092, 0.2664, 0.0123, 0.0543, 0.1009,
        0.0519, 0.3584, 0.0009], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,060][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0688, 0.0826, 0.1146, 0.0584, 0.0807, 0.0858, 0.0525, 0.1115, 0.0598,
        0.1144, 0.0886, 0.0824], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,064][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0019, 0.0299, 0.1367, 0.0401, 0.1273, 0.0868, 0.0738, 0.1454, 0.0498,
        0.1330, 0.0940, 0.0812], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,067][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.2804, 0.0565, 0.0543, 0.0775, 0.1078, 0.0379, 0.0429, 0.0583, 0.0646,
        0.0658, 0.0750, 0.0788], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,067][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0054, 0.0017, 0.0421, 0.0140, 0.2719, 0.0368, 0.0559, 0.0376, 0.1001,
        0.0813, 0.1276, 0.1849, 0.0405], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,067][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.1148, 0.0449, 0.0695, 0.0937, 0.0413, 0.0457, 0.1386, 0.1426, 0.0607,
        0.0524, 0.0456, 0.1221, 0.0280], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,068][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0042, 0.0183, 0.0408, 0.0492, 0.0326, 0.0595, 0.0848, 0.2166, 0.1352,
        0.1736, 0.0405, 0.0646, 0.0801], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,068][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0034, 0.0091, 0.0624, 0.0305, 0.0590, 0.0518, 0.0862, 0.1258, 0.0765,
        0.1019, 0.0743, 0.1318, 0.1873], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,068][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ store] are: tensor([9.5451e-08, 4.7472e-06, 4.1353e-05, 6.9529e-05, 3.3969e-04, 3.5790e-04,
        1.0873e-03, 1.2081e-02, 1.0772e-02, 8.8350e-02, 1.1310e-01, 2.9061e-01,
        4.8319e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,069][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0471, 0.1699, 0.1180, 0.0331, 0.3206, 0.0105, 0.0729, 0.0067, 0.0210,
        0.0198, 0.0212, 0.1577, 0.0015], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,069][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0228, 0.0479, 0.1084, 0.0350, 0.1555, 0.0729, 0.0411, 0.1391, 0.0412,
        0.1082, 0.0390, 0.0432, 0.1459], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,070][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0354, 0.0061, 0.0103, 0.0331, 0.0132, 0.0311, 0.0679, 0.0525, 0.1420,
        0.0891, 0.1931, 0.1949, 0.1314], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,071][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ store] are: tensor([3.1696e-02, 4.8247e-02, 7.1152e-03, 4.4306e-02, 2.2052e-03, 2.4620e-02,
        4.6792e-02, 3.5155e-02, 1.2159e-01, 1.7961e-02, 5.8895e-01, 3.1162e-02,
        2.0524e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,073][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0366, 0.0595, 0.1069, 0.0505, 0.0806, 0.0651, 0.0660, 0.0864, 0.0526,
        0.1008, 0.0870, 0.1060, 0.1019], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,076][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0005, 0.0339, 0.1072, 0.0345, 0.1048, 0.0656, 0.0580, 0.1375, 0.0388,
        0.1433, 0.0792, 0.0690, 0.1275], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,080][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.2634, 0.0569, 0.0492, 0.0616, 0.0891, 0.0395, 0.0404, 0.0570, 0.0563,
        0.0571, 0.0640, 0.0681, 0.0973], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,085][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0736, 0.0044, 0.0857, 0.0202, 0.2061, 0.0576, 0.0453, 0.0675, 0.0493,
        0.0454, 0.0624, 0.1390, 0.1150, 0.0285], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,085][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0650, 0.0330, 0.0589, 0.1136, 0.0466, 0.0313, 0.1826, 0.0934, 0.0872,
        0.0423, 0.0377, 0.1327, 0.0221, 0.0534], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,085][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0031, 0.0086, 0.0609, 0.0311, 0.0381, 0.1146, 0.0540, 0.2551, 0.0460,
        0.1087, 0.0401, 0.0274, 0.2029, 0.0095], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,086][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0060, 0.0115, 0.0612, 0.0345, 0.0674, 0.0499, 0.0673, 0.0919, 0.0584,
        0.0969, 0.0676, 0.1031, 0.2632, 0.0211], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,086][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [.] are: tensor([5.4671e-07, 6.5400e-06, 1.8032e-04, 1.5731e-04, 5.9909e-04, 8.4421e-04,
        1.8596e-03, 1.3763e-02, 9.3838e-03, 8.4245e-02, 4.5463e-02, 2.6164e-01,
        2.4136e-01, 3.4050e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,087][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.1684, 0.1845, 0.1193, 0.0628, 0.0421, 0.0548, 0.0971, 0.0583, 0.0275,
        0.0084, 0.0580, 0.1008, 0.0107, 0.0073], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,087][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0249, 0.0523, 0.1009, 0.0404, 0.1262, 0.0629, 0.0465, 0.1089, 0.0484,
        0.0919, 0.0432, 0.0472, 0.1300, 0.0763], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,087][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0200, 0.0048, 0.0094, 0.0284, 0.0114, 0.0287, 0.0572, 0.0454, 0.1172,
        0.0746, 0.1569, 0.1617, 0.1139, 0.1703], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,088][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0647, 0.0224, 0.0523, 0.0371, 0.0481, 0.1526, 0.0622, 0.0813, 0.0705,
        0.0306, 0.3390, 0.0284, 0.0090, 0.0018], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,088][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0484, 0.0542, 0.0843, 0.0462, 0.0599, 0.0660, 0.0502, 0.0902, 0.0497,
        0.0844, 0.0739, 0.0834, 0.1452, 0.0641], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,090][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0019, 0.0228, 0.1161, 0.0322, 0.1242, 0.0626, 0.0673, 0.1244, 0.0456,
        0.1014, 0.0728, 0.0697, 0.1230, 0.0359], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,092][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.2175, 0.0559, 0.0451, 0.0641, 0.0795, 0.0352, 0.0376, 0.0512, 0.0522,
        0.0520, 0.0615, 0.0664, 0.0942, 0.0876], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,097][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0095, 0.0016, 0.0702, 0.0092, 0.0850, 0.0300, 0.0456, 0.0491, 0.0417,
        0.0301, 0.0591, 0.1723, 0.0523, 0.0356, 0.3086], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,101][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0850, 0.0475, 0.0511, 0.0509, 0.0484, 0.1005, 0.0967, 0.1688, 0.0504,
        0.0643, 0.0302, 0.0917, 0.0324, 0.0519, 0.0300], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,103][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0052, 0.0203, 0.0763, 0.0470, 0.0170, 0.1003, 0.0345, 0.2144, 0.1334,
        0.1063, 0.0136, 0.0441, 0.1498, 0.0261, 0.0116], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,104][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0026, 0.0075, 0.0520, 0.0194, 0.0347, 0.0290, 0.0711, 0.0919, 0.0489,
        0.0886, 0.0635, 0.1069, 0.3096, 0.0148, 0.0596], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,104][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([2.3172e-07, 2.1158e-06, 4.2750e-05, 2.4918e-05, 4.0915e-05, 5.3016e-05,
        4.4384e-04, 1.1445e-04, 1.5753e-03, 4.1353e-03, 2.5319e-02, 6.9666e-02,
        8.6039e-02, 2.5325e-01, 5.5929e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,104][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.1123, 0.1703, 0.0503, 0.0289, 0.0041, 0.0192, 0.0833, 0.0526, 0.0204,
        0.0707, 0.0316, 0.1582, 0.1528, 0.0411, 0.0041], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,105][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0154, 0.0363, 0.0929, 0.0305, 0.1301, 0.0640, 0.0318, 0.1151, 0.0311,
        0.0830, 0.0297, 0.0304, 0.1419, 0.0516, 0.1163], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,105][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0234, 0.0058, 0.0087, 0.0265, 0.0104, 0.0245, 0.0538, 0.0383, 0.1063,
        0.0642, 0.1376, 0.1413, 0.0951, 0.1426, 0.1216], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,105][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.1213, 0.0543, 0.0158, 0.0723, 0.0052, 0.2434, 0.0119, 0.0464, 0.1964,
        0.0365, 0.1042, 0.0175, 0.0622, 0.0086, 0.0041], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,107][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0323, 0.0522, 0.0782, 0.0426, 0.0298, 0.0659, 0.0525, 0.0703, 0.0512,
        0.0932, 0.0826, 0.0919, 0.1495, 0.0673, 0.0404], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,109][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0007, 0.0279, 0.1010, 0.0277, 0.0954, 0.0706, 0.0476, 0.1127, 0.0251,
        0.1094, 0.0504, 0.0553, 0.1333, 0.0291, 0.1138], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,112][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.2012, 0.0346, 0.0285, 0.0515, 0.0613, 0.0289, 0.0318, 0.0374, 0.0459,
        0.0458, 0.0546, 0.0571, 0.0820, 0.0786, 0.1608], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,116][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0089, 0.0012, 0.0390, 0.0081, 0.1819, 0.0240, 0.0218, 0.0170, 0.0245,
        0.0264, 0.0310, 0.0715, 0.0769, 0.0151, 0.4426, 0.0102],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,121][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1077, 0.0518, 0.0553, 0.0806, 0.0400, 0.0683, 0.0875, 0.1372, 0.0613,
        0.0600, 0.0335, 0.0804, 0.0309, 0.0479, 0.0258, 0.0317],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,121][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0053, 0.0225, 0.0625, 0.0634, 0.0333, 0.0925, 0.0361, 0.1539, 0.0834,
        0.0795, 0.0384, 0.0447, 0.1987, 0.0318, 0.0249, 0.0289],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,122][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0049, 0.0089, 0.0484, 0.0239, 0.0499, 0.0269, 0.0635, 0.1178, 0.0527,
        0.1006, 0.0547, 0.0986, 0.2106, 0.0208, 0.0858, 0.0319],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,122][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([6.7352e-08, 8.2868e-07, 4.3049e-06, 1.0262e-05, 2.0143e-05, 1.7408e-05,
        1.1239e-04, 4.6240e-04, 6.5090e-04, 2.6984e-03, 3.6025e-03, 1.0457e-02,
        1.4991e-02, 7.3095e-02, 2.6570e-01, 6.2818e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,122][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0528, 0.2538, 0.0449, 0.0501, 0.0831, 0.0030, 0.0559, 0.0142, 0.0152,
        0.0430, 0.0261, 0.1772, 0.0475, 0.0381, 0.0947, 0.0004],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,123][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0191, 0.0394, 0.0887, 0.0289, 0.1160, 0.0581, 0.0315, 0.1049, 0.0308,
        0.0835, 0.0295, 0.0326, 0.1133, 0.0523, 0.1071, 0.0642],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,123][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0280, 0.0044, 0.0068, 0.0213, 0.0082, 0.0194, 0.0435, 0.0317, 0.0896,
        0.0530, 0.1183, 0.1178, 0.0786, 0.1198, 0.0953, 0.1642],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,123][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0767, 0.1480, 0.0260, 0.0842, 0.0228, 0.0579, 0.0602, 0.1552, 0.1248,
        0.0358, 0.0672, 0.0662, 0.0139, 0.0350, 0.0206, 0.0054],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,124][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0317, 0.0491, 0.0773, 0.0369, 0.0562, 0.0502, 0.0521, 0.0614, 0.0435,
        0.0602, 0.0812, 0.0771, 0.1351, 0.0727, 0.0768, 0.0386],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,126][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0007, 0.0187, 0.0878, 0.0225, 0.0921, 0.0447, 0.0391, 0.0858, 0.0262,
        0.1071, 0.0520, 0.0427, 0.1282, 0.0240, 0.1149, 0.1136],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,128][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.1554, 0.0354, 0.0377, 0.0471, 0.0747, 0.0248, 0.0273, 0.0383, 0.0404,
        0.0417, 0.0462, 0.0469, 0.0792, 0.0634, 0.1680, 0.0734],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,132][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0563, 0.0031, 0.0464, 0.0184, 0.1158, 0.0286, 0.0268, 0.0517, 0.0422,
        0.0300, 0.0524, 0.0938, 0.0982, 0.0241, 0.2406, 0.0249, 0.0466],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,136][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0927, 0.0369, 0.0529, 0.0816, 0.0507, 0.0407, 0.1063, 0.1197, 0.0602,
        0.0547, 0.0303, 0.0799, 0.0243, 0.0432, 0.0359, 0.0243, 0.0659],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,139][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0071, 0.0184, 0.0387, 0.0700, 0.0176, 0.1180, 0.0087, 0.1643, 0.1144,
        0.0701, 0.0506, 0.0302, 0.1692, 0.0214, 0.0142, 0.0809, 0.0064],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,139][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0052, 0.0093, 0.0444, 0.0300, 0.0441, 0.0267, 0.0403, 0.0796, 0.0441,
        0.0889, 0.0534, 0.0950, 0.2100, 0.0209, 0.0756, 0.0696, 0.0630],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,140][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([2.9506e-08, 1.7786e-07, 7.5234e-07, 1.3694e-06, 1.1770e-05, 6.8785e-06,
        4.8303e-06, 1.8513e-04, 8.1873e-05, 5.6904e-04, 1.0402e-03, 1.1978e-03,
        2.2724e-03, 1.0961e-02, 9.8444e-02, 6.3431e-01, 2.5091e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,140][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0852, 0.2791, 0.1640, 0.0299, 0.0830, 0.0299, 0.0015, 0.0089, 0.0102,
        0.0225, 0.0081, 0.0700, 0.0435, 0.0700, 0.0782, 0.0143, 0.0018],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,140][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0200, 0.0418, 0.0740, 0.0330, 0.1026, 0.0522, 0.0336, 0.1024, 0.0350,
        0.0788, 0.0321, 0.0350, 0.1082, 0.0530, 0.0960, 0.0673, 0.0350],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,141][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0202, 0.0037, 0.0056, 0.0193, 0.0064, 0.0170, 0.0379, 0.0269, 0.0755,
        0.0400, 0.0965, 0.0988, 0.0588, 0.0987, 0.0637, 0.1250, 0.2063],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,141][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.0572e-02, 9.2422e-03, 5.6436e-03, 1.6397e-02, 3.5607e-03, 6.2392e-02,
        5.1135e-04, 6.2386e-03, 2.6850e-02, 1.8962e-02, 6.0802e-02, 2.8406e-03,
        3.2477e-02, 2.1296e-03, 3.2300e-03, 7.3782e-01, 3.3419e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,142][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0435, 0.0543, 0.0750, 0.0384, 0.0490, 0.0535, 0.0315, 0.0724, 0.0394,
        0.0660, 0.0591, 0.0569, 0.1154, 0.0646, 0.0684, 0.0667, 0.0459],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,142][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0012, 0.0178, 0.0801, 0.0237, 0.0779, 0.0443, 0.0408, 0.1102, 0.0301,
        0.0802, 0.0599, 0.0462, 0.1069, 0.0280, 0.0987, 0.1001, 0.0539],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,144][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1509, 0.0342, 0.0318, 0.0477, 0.0620, 0.0230, 0.0252, 0.0347, 0.0381,
        0.0379, 0.0445, 0.0460, 0.0736, 0.0642, 0.1492, 0.0697, 0.0673],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,146][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0039, 0.0016, 0.0190, 0.0111, 0.1378, 0.0242, 0.0340, 0.0125, 0.0480,
        0.0281, 0.0721, 0.0998, 0.0503, 0.0372, 0.2723, 0.0471, 0.0861, 0.0149],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,149][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0903, 0.0438, 0.0483, 0.0738, 0.0311, 0.0629, 0.1083, 0.1131, 0.0581,
        0.0443, 0.0277, 0.0883, 0.0223, 0.0522, 0.0203, 0.0246, 0.0579, 0.0324],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,153][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0029, 0.0078, 0.0436, 0.0292, 0.0267, 0.0774, 0.0512, 0.2330, 0.0643,
        0.0632, 0.0462, 0.0278, 0.1899, 0.0133, 0.0174, 0.0553, 0.0370, 0.0137],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,157][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0020, 0.0059, 0.0444, 0.0181, 0.0392, 0.0269, 0.0555, 0.0724, 0.0383,
        0.0693, 0.0399, 0.0667, 0.2182, 0.0136, 0.0651, 0.0702, 0.0910, 0.0634],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,157][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([1.0269e-08, 8.0183e-08, 6.4842e-07, 7.4156e-07, 9.9360e-06, 6.0480e-06,
        5.5917e-06, 2.6928e-05, 6.2940e-05, 5.0223e-04, 4.1683e-04, 1.1192e-03,
        4.0587e-03, 7.3784e-03, 1.2890e-01, 2.0854e-01, 5.2447e-01, 1.2450e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,158][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0749, 0.0883, 0.0393, 0.0219, 0.0270, 0.0176, 0.0705, 0.1454, 0.0453,
        0.0882, 0.0350, 0.0842, 0.1388, 0.0169, 0.0220, 0.0139, 0.0707, 0.0003],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,158][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0138, 0.0329, 0.0707, 0.0252, 0.1035, 0.0524, 0.0299, 0.0904, 0.0294,
        0.0746, 0.0256, 0.0297, 0.1085, 0.0479, 0.0934, 0.0712, 0.0313, 0.0695],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,159][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0183, 0.0029, 0.0041, 0.0148, 0.0050, 0.0128, 0.0302, 0.0205, 0.0656,
        0.0346, 0.0823, 0.0847, 0.0515, 0.0874, 0.0647, 0.1137, 0.1894, 0.1176],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,159][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0769, 0.0482, 0.0271, 0.0439, 0.0076, 0.1469, 0.0151, 0.0401, 0.0635,
        0.0399, 0.0348, 0.0138, 0.1929, 0.0140, 0.0061, 0.2155, 0.0125, 0.0013],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,159][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0236, 0.0417, 0.0626, 0.0339, 0.0526, 0.0558, 0.0410, 0.0642, 0.0344,
        0.0644, 0.0530, 0.0678, 0.0992, 0.0549, 0.0697, 0.0728, 0.0592, 0.0492],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,160][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0006, 0.0255, 0.0672, 0.0273, 0.0690, 0.0435, 0.0359, 0.0898, 0.0294,
        0.0845, 0.0537, 0.0393, 0.1024, 0.0338, 0.0833, 0.0853, 0.0461, 0.0835],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,161][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.1437, 0.0281, 0.0237, 0.0406, 0.0512, 0.0213, 0.0229, 0.0297, 0.0337,
        0.0329, 0.0390, 0.0403, 0.0627, 0.0565, 0.1304, 0.0613, 0.0601, 0.1217],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,164][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0732, 0.0060, 0.0300, 0.0185, 0.0648, 0.0433, 0.0353, 0.0441, 0.0412,
        0.0300, 0.0531, 0.0980, 0.1051, 0.0259, 0.1466, 0.0411, 0.0639, 0.0491,
        0.0309], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,168][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0679, 0.0299, 0.0498, 0.0787, 0.0462, 0.0310, 0.1217, 0.0793, 0.0626,
        0.0433, 0.0241, 0.0946, 0.0197, 0.0372, 0.0326, 0.0252, 0.0733, 0.0436,
        0.0394], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,172][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0041, 0.0123, 0.0366, 0.0401, 0.0284, 0.1110, 0.0384, 0.1694, 0.0611,
        0.1081, 0.0307, 0.0318, 0.1398, 0.0123, 0.0204, 0.0854, 0.0286, 0.0378,
        0.0037], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,175][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0037, 0.0066, 0.0361, 0.0225, 0.0336, 0.0247, 0.0506, 0.0766, 0.0411,
        0.0612, 0.0368, 0.0698, 0.1729, 0.0169, 0.0584, 0.0765, 0.0826, 0.1121,
        0.0172], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,175][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([5.1691e-09, 2.0246e-08, 1.4607e-07, 1.1643e-07, 1.5223e-06, 4.1242e-06,
        1.0117e-06, 7.9955e-06, 1.1613e-05, 3.4768e-04, 9.1007e-05, 1.4191e-04,
        3.7801e-04, 8.0041e-04, 1.8362e-02, 2.9113e-01, 6.9696e-02, 3.6287e-01,
        2.5615e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,176][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1094, 0.2280, 0.1249, 0.0474, 0.0549, 0.0441, 0.0189, 0.0838, 0.0306,
        0.0127, 0.0193, 0.0730, 0.0299, 0.0079, 0.0401, 0.0443, 0.0222, 0.0080,
        0.0006], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,176][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0200, 0.0370, 0.0678, 0.0328, 0.0871, 0.0478, 0.0337, 0.0860, 0.0321,
        0.0733, 0.0295, 0.0344, 0.0968, 0.0514, 0.0825, 0.0586, 0.0353, 0.0684,
        0.0258], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,176][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0176, 0.0032, 0.0044, 0.0150, 0.0050, 0.0131, 0.0281, 0.0200, 0.0552,
        0.0298, 0.0704, 0.0714, 0.0423, 0.0739, 0.0470, 0.0911, 0.1451, 0.0833,
        0.1842], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,177][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([2.2947e-03, 4.8335e-03, 5.2650e-03, 3.7002e-03, 1.3489e-03, 4.2026e-02,
        1.5972e-03, 1.0005e-03, 3.7598e-03, 5.4918e-04, 4.6792e-03, 1.1583e-03,
        2.1617e-03, 6.7079e-04, 1.1437e-03, 9.2229e-01, 1.0812e-03, 4.2162e-04,
        1.4916e-05], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,177][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0392, 0.0427, 0.0619, 0.0300, 0.0464, 0.0433, 0.0376, 0.0689, 0.0309,
        0.0615, 0.0382, 0.0579, 0.1077, 0.0463, 0.0641, 0.0576, 0.0552, 0.0887,
        0.0218], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,178][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0012, 0.0182, 0.0767, 0.0247, 0.0722, 0.0518, 0.0386, 0.0707, 0.0264,
        0.0662, 0.0508, 0.0441, 0.0831, 0.0239, 0.0896, 0.1059, 0.0519, 0.0661,
        0.0379], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,179][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1243, 0.0291, 0.0253, 0.0409, 0.0492, 0.0192, 0.0221, 0.0268, 0.0323,
        0.0309, 0.0377, 0.0390, 0.0596, 0.0550, 0.1157, 0.0559, 0.0565, 0.1096,
        0.0710], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,195][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:18,195][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,196][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,196][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,197][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,197][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,197][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,197][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,198][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,198][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,198][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,199][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,199][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,199][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4543, 0.5457], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,200][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9880, 0.0120], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,200][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,200][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1144, 0.8856], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,201][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.6116, 0.3884], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,201][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9969, 0.0031], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,201][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6793, 0.3207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,202][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2637, 0.7363], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,202][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1159, 0.8841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,202][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9532, 0.0468], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,203][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.5896, 0.4104], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,203][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1980, 0.8020], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,203][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.2399, 0.4190, 0.3410], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,204][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([0.9416, 0.0245, 0.0339], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,204][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([5.9837e-06, 1.6769e-01, 8.3231e-01], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,204][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.0456, 0.4180, 0.5364], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,205][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.1638, 0.7946, 0.0416], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,205][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.6552, 0.0009, 0.3439], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,205][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.0895, 0.1472, 0.7632], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,206][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.1513, 0.4485, 0.4002], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,206][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.0087, 0.4044, 0.5869], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,208][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.9686, 0.0141, 0.0173], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,212][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.0550, 0.0491, 0.8959], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,215][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.1586, 0.5482, 0.2933], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,215][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1661, 0.2552, 0.3943, 0.1845], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,216][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.9506, 0.0135, 0.0193, 0.0165], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,216][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([5.6200e-07, 6.0415e-03, 6.1636e-01, 3.7760e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,216][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0394, 0.2213, 0.3071, 0.4322], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,217][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0886, 0.6629, 0.0948, 0.1537], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,217][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([9.8227e-01, 1.5808e-05, 1.7299e-02, 4.1254e-04], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,217][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0630, 0.0753, 0.3969, 0.4648], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,218][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0932, 0.2520, 0.2302, 0.4246], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,218][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0019, 0.1054, 0.3983, 0.4943], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,218][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.9685, 0.0025, 0.0033, 0.0258], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,220][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0192, 0.0183, 0.3721, 0.5904], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,222][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1214, 0.4270, 0.1366, 0.3150], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,226][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.1137, 0.2190, 0.3064, 0.2363, 0.1246], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,230][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.8260, 0.0299, 0.0403, 0.0446, 0.0593], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,233][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([1.4217e-07, 8.9219e-04, 7.2013e-02, 2.4392e-01, 6.8317e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,233][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.0128, 0.1053, 0.1360, 0.2191, 0.5268], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,234][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.1313, 0.3149, 0.2903, 0.2349, 0.0287], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,234][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([4.4988e-01, 6.5876e-05, 6.1802e-02, 2.6973e-03, 4.8555e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,234][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.0210, 0.0477, 0.1332, 0.3460, 0.4521], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,234][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0694, 0.2036, 0.1775, 0.3388, 0.2106], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,235][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([3.6009e-04, 1.7692e-02, 9.2264e-02, 2.9896e-01, 5.9073e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,235][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.9366, 0.0017, 0.0022, 0.0162, 0.0434], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,235][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0114, 0.0112, 0.1970, 0.3042, 0.4762], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,236][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0995, 0.2665, 0.1214, 0.2892, 0.2235], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,236][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1059, 0.1837, 0.2410, 0.1563, 0.2419, 0.0712], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,238][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.4400, 0.0519, 0.0788, 0.0963, 0.1056, 0.2273], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,240][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([5.7813e-09, 5.8684e-05, 5.8842e-03, 3.8078e-02, 8.2643e-01, 1.2955e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,243][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0149, 0.0788, 0.1066, 0.1512, 0.3812, 0.2673], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,247][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1639, 0.2041, 0.0871, 0.3986, 0.0307, 0.1156], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,249][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([5.5185e-01, 1.9647e-05, 3.4873e-02, 1.1282e-03, 3.4267e-01, 6.9463e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,251][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0214, 0.0409, 0.1196, 0.2265, 0.3659, 0.2257], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,251][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0513, 0.1431, 0.1319, 0.2462, 0.1618, 0.2657], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,252][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([1.4147e-04, 1.4256e-02, 3.3892e-02, 1.5343e-01, 3.5035e-01, 4.4793e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,252][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([8.7644e-01, 6.5394e-04, 9.9625e-04, 9.0224e-03, 4.1059e-02, 7.1829e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,252][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0062, 0.0062, 0.1260, 0.2004, 0.3255, 0.3357], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,253][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0913, 0.2679, 0.0797, 0.1811, 0.1623, 0.2177], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,253][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1012, 0.1581, 0.1777, 0.1884, 0.1870, 0.0885, 0.0992],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,253][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.3729, 0.0355, 0.0597, 0.0641, 0.0771, 0.1757, 0.2150],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,254][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([7.2153e-09, 1.5452e-05, 1.1530e-03, 1.4247e-02, 1.8258e-01, 5.8912e-01,
        2.1289e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,254][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0129, 0.0573, 0.0760, 0.1073, 0.2791, 0.2047, 0.2627],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,255][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1134, 0.1865, 0.1159, 0.3015, 0.0337, 0.1853, 0.0637],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,256][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([9.0844e-01, 2.9340e-06, 7.3620e-03, 1.2792e-04, 6.8308e-02, 1.1411e-02,
        4.3500e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,260][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0147, 0.0217, 0.0822, 0.1333, 0.2462, 0.1578, 0.3440],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,263][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0411, 0.1141, 0.1036, 0.1928, 0.1249, 0.2071, 0.2163],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,265][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([5.0658e-05, 2.3426e-03, 1.5238e-02, 4.4363e-02, 2.0463e-01, 5.7063e-01,
        1.6274e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,267][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.7922e-01, 9.9776e-05, 1.1570e-04, 1.0193e-03, 5.5591e-03, 1.0279e-02,
        1.0371e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,269][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0045, 0.0047, 0.0895, 0.1398, 0.2252, 0.2287, 0.3075],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,270][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0828, 0.1872, 0.0552, 0.1535, 0.1138, 0.1625, 0.2450],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,270][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0864, 0.1295, 0.1759, 0.1451, 0.1356, 0.0804, 0.0809, 0.1662],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,270][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.4459, 0.0381, 0.0490, 0.0538, 0.0610, 0.1006, 0.1290, 0.1227],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,271][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([5.3909e-09, 9.1509e-06, 9.7350e-04, 3.1757e-03, 1.2851e-01, 7.0357e-02,
        6.6591e-01, 1.3107e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,271][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.0084, 0.0447, 0.0555, 0.0807, 0.1833, 0.1453, 0.1806, 0.3015],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,271][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0341, 0.1342, 0.0760, 0.1892, 0.0653, 0.1309, 0.2330, 0.1374],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,272][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([4.8502e-01, 2.3468e-05, 2.5275e-02, 9.0309e-04, 2.0495e-01, 4.0527e-02,
        2.1606e-02, 2.2169e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,272][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0121, 0.0199, 0.0587, 0.1181, 0.1332, 0.1210, 0.3099, 0.2269],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,272][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0345, 0.0943, 0.0823, 0.1530, 0.0977, 0.1638, 0.1731, 0.2014],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,272][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([3.8313e-05, 1.5202e-03, 7.0185e-03, 2.9023e-02, 9.7902e-02, 5.4679e-01,
        1.8183e-01, 1.3587e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,274][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([7.7927e-01, 1.3345e-04, 9.3822e-05, 7.6377e-04, 3.3122e-03, 5.0984e-03,
        4.9238e-02, 1.6209e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,276][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0037, 0.0039, 0.0690, 0.1081, 0.1720, 0.1756, 0.2360, 0.2317],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,279][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0678, 0.1680, 0.0408, 0.1218, 0.0818, 0.1263, 0.1950, 0.1984],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,283][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0781, 0.1170, 0.1867, 0.0930, 0.1448, 0.0495, 0.0701, 0.1615, 0.0994],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,287][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.3947, 0.0276, 0.0375, 0.0339, 0.0475, 0.0848, 0.1046, 0.1059, 0.1635],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,288][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([2.4563e-09, 1.8089e-07, 3.1134e-05, 1.4964e-04, 9.9836e-03, 5.5875e-03,
        4.7547e-02, 3.7837e-01, 5.5833e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,288][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0085, 0.0315, 0.0408, 0.0572, 0.1427, 0.1084, 0.1339, 0.2538, 0.2232],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,288][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0027, 0.0127, 0.0266, 0.0224, 0.0415, 0.0060, 0.0157, 0.8696, 0.0028],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,289][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([9.2593e-01, 9.1460e-07, 2.4963e-03, 3.5139e-05, 2.3520e-02, 3.4984e-03,
        1.3264e-03, 3.8310e-02, 4.8806e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,289][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0111, 0.0115, 0.0314, 0.0617, 0.0811, 0.0711, 0.1912, 0.1598, 0.3811],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,289][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0272, 0.0729, 0.0654, 0.1226, 0.0790, 0.1306, 0.1384, 0.1636, 0.2003],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,290][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([4.8460e-05, 7.1695e-04, 4.7084e-03, 1.1586e-02, 3.5213e-02, 1.8409e-01,
        1.0622e-01, 1.4928e-01, 5.0814e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,290][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([5.6036e-01, 2.2201e-05, 1.7530e-05, 1.5576e-04, 8.3271e-04, 1.3540e-03,
        1.3793e-02, 7.0910e-02, 3.5256e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,291][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0031, 0.0032, 0.0572, 0.0882, 0.1393, 0.1425, 0.1893, 0.1851, 0.1920],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,294][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0682, 0.1263, 0.0318, 0.1050, 0.0648, 0.1004, 0.1625, 0.1435, 0.1975],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,298][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0680, 0.1097, 0.1152, 0.0976, 0.1212, 0.0617, 0.0580, 0.1306, 0.1406,
        0.0974], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,301][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.3230, 0.0342, 0.0373, 0.0456, 0.0460, 0.0779, 0.1026, 0.0965, 0.1485,
        0.0885], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,303][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([4.9223e-11, 1.0293e-08, 8.3878e-07, 4.7433e-06, 2.3073e-04, 9.3881e-04,
        4.0440e-03, 4.6663e-03, 4.3073e-01, 5.5939e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,305][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0039, 0.0245, 0.0290, 0.0423, 0.0923, 0.0766, 0.0930, 0.1624, 0.1369,
        0.3392], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,305][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0092, 0.0578, 0.0085, 0.0400, 0.0101, 0.3797, 0.0805, 0.3778, 0.0304,
        0.0061], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,306][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([2.8841e-02, 1.8938e-06, 3.5384e-03, 1.2071e-04, 3.6907e-02, 7.6751e-03,
        4.1308e-03, 4.7734e-02, 1.3518e-02, 8.5753e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,306][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0053, 0.0085, 0.0158, 0.0376, 0.0513, 0.0412, 0.1142, 0.1153, 0.2468,
        0.3640], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,306][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0244, 0.0663, 0.0567, 0.1065, 0.0673, 0.1132, 0.1204, 0.1400, 0.1722,
        0.1330], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,307][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([4.9335e-06, 1.3788e-04, 9.3105e-04, 1.9192e-03, 2.3686e-02, 1.9188e-01,
        4.9768e-02, 6.0430e-02, 3.9313e-01, 2.7812e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,307][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([2.4135e-01, 1.1783e-05, 7.9856e-06, 6.0782e-05, 2.9116e-04, 4.2525e-04,
        4.2426e-03, 2.1417e-02, 1.1289e-01, 6.1930e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,307][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0026, 0.0027, 0.0463, 0.0714, 0.1131, 0.1142, 0.1528, 0.1504, 0.1568,
        0.1898], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,308][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0709, 0.1183, 0.0301, 0.0833, 0.0647, 0.0822, 0.1280, 0.1551, 0.1501,
        0.1172], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,309][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0526, 0.0952, 0.1209, 0.0835, 0.1372, 0.0500, 0.0612, 0.1125, 0.0973,
        0.0921, 0.0974], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,312][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.6839, 0.0145, 0.0143, 0.0152, 0.0184, 0.0313, 0.0386, 0.0412, 0.0641,
        0.0419, 0.0366], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,314][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([6.0519e-11, 1.3598e-09, 8.7809e-08, 7.4099e-07, 1.9800e-05, 2.7761e-05,
        2.4918e-04, 1.4514e-04, 4.1024e-02, 4.8563e-01, 4.7290e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,318][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0044, 0.0182, 0.0226, 0.0313, 0.0747, 0.0590, 0.0695, 0.1358, 0.1120,
        0.3043, 0.1683], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,321][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0273, 0.1561, 0.0902, 0.1737, 0.0332, 0.0393, 0.0896, 0.2681, 0.0773,
        0.0247, 0.0205], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,323][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.7299e-01, 3.3141e-07, 1.3807e-03, 1.7847e-05, 1.4263e-02, 1.9048e-03,
        7.7514e-04, 1.9590e-02, 3.3744e-03, 6.5507e-01, 1.3063e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,323][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0070, 0.0062, 0.0138, 0.0285, 0.0433, 0.0422, 0.0818, 0.0820, 0.1507,
        0.2275, 0.3169], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,324][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0210, 0.0552, 0.0490, 0.0915, 0.0585, 0.0972, 0.1028, 0.1193, 0.1470,
        0.1149, 0.1437], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,324][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([9.1802e-06, 6.8555e-05, 2.5461e-04, 1.0385e-03, 4.2231e-03, 1.2650e-02,
        2.0189e-02, 3.1105e-02, 1.5916e-01, 2.9813e-01, 4.7318e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,324][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([2.8684e-01, 5.5653e-06, 3.1681e-06, 2.0573e-05, 9.5381e-05, 1.3192e-04,
        1.0078e-03, 5.5292e-03, 2.1944e-02, 1.8975e-01, 4.9467e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,325][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0020, 0.0021, 0.0387, 0.0593, 0.0952, 0.0967, 0.1289, 0.1260, 0.1304,
        0.1585, 0.1621], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,325][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0594, 0.0872, 0.0223, 0.0667, 0.0462, 0.0697, 0.1046, 0.1152, 0.1209,
        0.0893, 0.2185], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,325][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0499, 0.0787, 0.0976, 0.0813, 0.0924, 0.0436, 0.0488, 0.1176, 0.1044,
        0.0960, 0.1415, 0.0481], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,326][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.7243, 0.0112, 0.0112, 0.0109, 0.0142, 0.0234, 0.0279, 0.0316, 0.0481,
        0.0331, 0.0273, 0.0368], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,326][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([1.9828e-12, 4.8507e-11, 4.3392e-09, 3.6446e-08, 1.3522e-06, 1.2304e-06,
        3.2586e-06, 1.0872e-05, 3.0444e-03, 3.3304e-02, 9.1350e-01, 5.0130e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,327][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0035, 0.0132, 0.0167, 0.0226, 0.0586, 0.0443, 0.0511, 0.1117, 0.0881,
        0.2656, 0.1386, 0.1860], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,328][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0597, 0.1201, 0.1645, 0.1678, 0.0500, 0.0645, 0.0801, 0.1239, 0.0359,
        0.0353, 0.0554, 0.0428], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,330][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([3.7342e-01, 2.3863e-07, 9.2038e-04, 9.1618e-06, 8.5861e-03, 1.0046e-03,
        3.7562e-04, 1.2098e-02, 1.7383e-03, 4.0783e-01, 7.0886e-02, 1.2314e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,333][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.0038, 0.0033, 0.0099, 0.0180, 0.0300, 0.0263, 0.0456, 0.0517, 0.1205,
        0.1567, 0.2308, 0.3033], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,337][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0183, 0.0492, 0.0437, 0.0818, 0.0520, 0.0875, 0.0917, 0.1073, 0.1319,
        0.1033, 0.1283, 0.1052], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,340][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([2.2847e-06, 1.8202e-05, 8.3295e-05, 2.0030e-04, 1.1767e-03, 2.8012e-03,
        2.9212e-03, 6.8226e-03, 2.8256e-02, 2.0893e-01, 4.9209e-01, 2.5669e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,342][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([2.3681e-01, 3.8051e-06, 1.8651e-06, 9.0787e-06, 4.2500e-05, 4.9302e-05,
        2.7865e-04, 1.8169e-03, 6.1928e-03, 5.3098e-02, 1.3974e-01, 5.6196e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,342][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0017, 0.0019, 0.0327, 0.0499, 0.0807, 0.0810, 0.1083, 0.1062, 0.1097,
        0.1338, 0.1366, 0.1575], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,343][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0583, 0.0767, 0.0209, 0.0551, 0.0419, 0.0587, 0.0842, 0.0954, 0.0952,
        0.0757, 0.1719, 0.1659], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,343][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0515, 0.0745, 0.1059, 0.0715, 0.0986, 0.0367, 0.0479, 0.0997, 0.0877,
        0.0948, 0.1180, 0.0501, 0.0631], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,343][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.2813, 0.0316, 0.0289, 0.0341, 0.0320, 0.0547, 0.0705, 0.0681, 0.1051,
        0.0585, 0.0638, 0.0803, 0.0913], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,344][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([6.5035e-13, 3.1360e-11, 1.0323e-09, 1.1741e-08, 3.7674e-07, 1.1354e-07,
        5.4896e-06, 8.5048e-06, 7.9629e-04, 5.1365e-02, 7.7819e-02, 5.4270e-01,
        3.2730e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,344][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0021, 0.0135, 0.0153, 0.0220, 0.0495, 0.0399, 0.0456, 0.0881, 0.0676,
        0.1872, 0.0995, 0.1366, 0.2330], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,344][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0109, 0.1467, 0.0343, 0.1583, 0.0048, 0.0548, 0.1209, 0.1107, 0.0813,
        0.0224, 0.0445, 0.2040, 0.0063], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,345][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([8.6976e-03, 5.4831e-08, 2.3789e-04, 3.7189e-06, 2.6231e-03, 4.0947e-04,
        1.9147e-04, 3.6940e-03, 7.8152e-04, 1.1027e-01, 2.7783e-02, 4.8917e-02,
        7.9639e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,346][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0028, 0.0032, 0.0072, 0.0140, 0.0196, 0.0178, 0.0401, 0.0352, 0.0847,
        0.1149, 0.1888, 0.2552, 0.2163], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,349][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0171, 0.0469, 0.0397, 0.0748, 0.0468, 0.0798, 0.0844, 0.0975, 0.1207,
        0.0922, 0.1161, 0.0950, 0.0891], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,351][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([7.4632e-07, 8.9178e-06, 3.4274e-05, 6.9876e-05, 4.7251e-04, 9.7207e-04,
        1.5159e-03, 2.4228e-03, 1.7897e-02, 7.7714e-02, 4.4715e-01, 3.3813e-01,
        1.1361e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,354][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([8.8507e-02, 7.0875e-07, 3.9719e-07, 2.0485e-06, 9.8656e-06, 1.1476e-05,
        8.1478e-05, 6.1989e-04, 1.9862e-03, 1.9281e-02, 6.0943e-02, 3.1034e-01,
        5.1821e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,358][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0016, 0.0018, 0.0282, 0.0430, 0.0689, 0.0690, 0.0928, 0.0908, 0.0950,
        0.1152, 0.1179, 0.1360, 0.1399], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,360][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0556, 0.0686, 0.0165, 0.0526, 0.0337, 0.0496, 0.0781, 0.0770, 0.0849,
        0.0630, 0.1645, 0.1514, 0.1046], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,360][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0431, 0.0602, 0.1059, 0.0580, 0.0723, 0.0369, 0.0530, 0.0947, 0.0757,
        0.0847, 0.1064, 0.0537, 0.0845, 0.0710], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,361][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.6155, 0.0091, 0.0096, 0.0106, 0.0129, 0.0257, 0.0295, 0.0302, 0.0440,
        0.0312, 0.0253, 0.0326, 0.0542, 0.0696], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,361][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([2.1346e-12, 1.1432e-11, 4.0288e-09, 9.6226e-09, 6.2176e-07, 3.6671e-07,
        4.4383e-06, 5.8335e-06, 1.4276e-04, 1.1373e-02, 1.8312e-02, 6.9065e-02,
        4.7390e-01, 4.2720e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,361][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0026, 0.0101, 0.0117, 0.0167, 0.0377, 0.0318, 0.0352, 0.0744, 0.0560,
        0.1625, 0.0870, 0.1170, 0.2144, 0.1428], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,362][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0141, 0.0488, 0.1018, 0.0651, 0.0774, 0.0495, 0.1379, 0.1970, 0.0391,
        0.0230, 0.0353, 0.1341, 0.0614, 0.0156], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,362][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.3023e-01, 1.3077e-08, 9.3328e-05, 6.3164e-07, 1.0773e-03, 1.0924e-04,
        3.7790e-05, 1.8649e-03, 1.9202e-04, 7.6740e-02, 1.0053e-02, 1.9501e-02,
        6.4487e-01, 1.1523e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,362][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0018, 0.0016, 0.0089, 0.0142, 0.0233, 0.0171, 0.0327, 0.0292, 0.0667,
        0.1417, 0.1437, 0.1753, 0.1883, 0.1554], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,364][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0157, 0.0410, 0.0360, 0.0670, 0.0426, 0.0701, 0.0739, 0.0868, 0.1056,
        0.0833, 0.1032, 0.0845, 0.0810, 0.1094], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,366][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([1.8016e-06, 1.6646e-05, 5.8119e-05, 1.9114e-04, 4.1835e-04, 1.6735e-03,
        1.3955e-03, 3.0878e-03, 1.2745e-02, 3.6703e-02, 9.6636e-02, 2.1367e-01,
        1.8961e-01, 4.4379e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,368][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([9.3638e-02, 1.0032e-07, 4.5349e-08, 2.7395e-07, 1.5599e-06, 2.0205e-06,
        1.7119e-05, 1.7610e-04, 5.7101e-04, 8.0113e-03, 2.6816e-02, 1.6955e-01,
        4.2466e-01, 2.7655e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,371][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0013, 0.0014, 0.0247, 0.0377, 0.0614, 0.0618, 0.0823, 0.0809, 0.0834,
        0.1015, 0.1036, 0.1195, 0.1233, 0.1175], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,375][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0490, 0.0570, 0.0189, 0.0430, 0.0361, 0.0419, 0.0655, 0.0799, 0.0664,
        0.0619, 0.1157, 0.1174, 0.1080, 0.1393], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,378][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.0311, 0.0651, 0.0874, 0.0661, 0.0347, 0.0447, 0.0396, 0.0859, 0.0901,
        0.0671, 0.1227, 0.0506, 0.0891, 0.0920, 0.0337], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,378][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.3725, 0.0185, 0.0172, 0.0199, 0.0209, 0.0355, 0.0428, 0.0442, 0.0656,
        0.0395, 0.0387, 0.0488, 0.0636, 0.0833, 0.0891], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,379][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([5.2283e-13, 6.8720e-12, 5.5583e-10, 1.1748e-09, 7.7963e-09, 2.6158e-08,
        1.0094e-07, 2.0658e-07, 1.5574e-05, 5.2664e-04, 3.6176e-04, 5.3412e-03,
        1.4257e-02, 1.0196e-01, 8.7754e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,379][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.0009, 0.0062, 0.0068, 0.0110, 0.0254, 0.0216, 0.0254, 0.0571, 0.0416,
        0.1345, 0.0683, 0.0944, 0.1833, 0.1205, 0.2031], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,379][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0362, 0.1024, 0.0703, 0.0746, 0.0072, 0.0657, 0.1882, 0.0223, 0.0938,
        0.0102, 0.0384, 0.2185, 0.0165, 0.0499, 0.0058], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,380][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([9.7202e-03, 6.6584e-09, 3.0980e-05, 4.0761e-07, 4.0517e-04, 5.5796e-05,
        2.3395e-05, 6.1761e-04, 1.0084e-04, 1.7033e-02, 3.1742e-03, 5.6468e-03,
        1.2811e-01, 2.6554e-02, 8.0852e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,380][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.0005, 0.0011, 0.0034, 0.0086, 0.0118, 0.0111, 0.0206, 0.0194, 0.0528,
        0.0864, 0.1025, 0.1189, 0.1575, 0.1447, 0.2605], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,380][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0139, 0.0404, 0.0342, 0.0643, 0.0397, 0.0697, 0.0732, 0.0829, 0.1042,
        0.0780, 0.0983, 0.0801, 0.0740, 0.1013, 0.0457], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,381][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([4.7698e-07, 1.7595e-06, 8.6731e-06, 2.5701e-05, 5.1997e-05, 1.9791e-04,
        3.2887e-04, 3.3913e-04, 3.1709e-03, 1.1025e-02, 2.8375e-02, 5.3881e-02,
        7.9183e-02, 2.2707e-01, 5.9634e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,381][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([2.1635e-01, 3.0060e-07, 9.9777e-08, 4.2707e-07, 1.5425e-06, 2.5395e-06,
        1.5892e-05, 1.5830e-04, 4.1034e-04, 5.8102e-03, 1.5984e-02, 8.5933e-02,
        1.9649e-01, 9.6847e-02, 3.8200e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,383][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0014, 0.0016, 0.0225, 0.0335, 0.0524, 0.0518, 0.0693, 0.0674, 0.0715,
        0.0863, 0.0883, 0.1013, 0.1046, 0.0985, 0.1497], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,386][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0289, 0.0407, 0.0135, 0.0324, 0.0225, 0.0368, 0.0546, 0.0478, 0.0569,
        0.0428, 0.1165, 0.1056, 0.0785, 0.1390, 0.1834], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,390][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0367, 0.0636, 0.0727, 0.0556, 0.0680, 0.0335, 0.0375, 0.0775, 0.0749,
        0.0731, 0.0934, 0.0443, 0.0972, 0.0834, 0.0653, 0.0233],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,394][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.2207, 0.0197, 0.0200, 0.0243, 0.0234, 0.0391, 0.0499, 0.0496, 0.0718,
        0.0442, 0.0454, 0.0577, 0.0675, 0.0905, 0.0848, 0.0914],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,396][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([4.2067e-14, 2.3146e-13, 1.8465e-11, 7.5070e-11, 1.3854e-09, 8.4458e-10,
        7.2748e-09, 8.4542e-09, 7.7717e-07, 1.8237e-05, 1.0136e-04, 2.7824e-04,
        3.5413e-03, 1.7149e-02, 4.4960e-01, 5.2931e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,397][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0014, 0.0069, 0.0080, 0.0113, 0.0261, 0.0204, 0.0232, 0.0510, 0.0365,
        0.1146, 0.0572, 0.0779, 0.1524, 0.0987, 0.1811, 0.1332],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,397][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0269, 0.1092, 0.0395, 0.1364, 0.0087, 0.0603, 0.0714, 0.0312, 0.1034,
        0.0221, 0.0621, 0.1271, 0.0278, 0.1653, 0.0068, 0.0019],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,397][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([1.2154e-03, 1.7718e-09, 1.1926e-05, 1.4049e-07, 1.5109e-04, 1.8500e-05,
        8.1848e-06, 1.9573e-04, 3.6277e-05, 6.7098e-03, 1.4146e-03, 2.6321e-03,
        5.9904e-02, 1.5233e-02, 4.5131e-01, 4.6116e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,398][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0009, 0.0008, 0.0036, 0.0060, 0.0089, 0.0071, 0.0153, 0.0129, 0.0393,
        0.0613, 0.0897, 0.0926, 0.1190, 0.1171, 0.1968, 0.2287],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,398][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0127, 0.0358, 0.0313, 0.0582, 0.0374, 0.0627, 0.0660, 0.0772, 0.0938,
        0.0741, 0.0911, 0.0749, 0.0715, 0.0958, 0.0449, 0.0725],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,399][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([3.8738e-07, 1.6182e-06, 3.3016e-06, 1.3647e-05, 3.1985e-05, 3.9578e-05,
        1.1360e-04, 1.1670e-04, 1.1408e-03, 2.6003e-03, 6.2455e-03, 1.9392e-02,
        1.4328e-02, 1.9387e-01, 4.2671e-01, 3.3540e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,399][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.6651e-01, 2.8811e-07, 1.0738e-07, 4.0114e-07, 2.0380e-06, 1.9868e-06,
        1.2451e-05, 1.1739e-04, 2.7757e-04, 3.5509e-03, 1.0199e-02, 5.3155e-02,
        1.2134e-01, 6.1084e-02, 3.2516e-01, 2.5858e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,399][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0012, 0.0014, 0.0193, 0.0291, 0.0460, 0.0455, 0.0614, 0.0591, 0.0636,
        0.0757, 0.0783, 0.0900, 0.0923, 0.0894, 0.1332, 0.1147],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,401][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0394, 0.0588, 0.0122, 0.0363, 0.0213, 0.0344, 0.0536, 0.0436, 0.0555,
        0.0376, 0.1032, 0.0858, 0.0593, 0.1170, 0.1213, 0.1207],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,405][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0332, 0.0523, 0.0592, 0.0637, 0.0580, 0.0283, 0.0329, 0.0930, 0.0838,
        0.0682, 0.1016, 0.0439, 0.0814, 0.0812, 0.0595, 0.0286, 0.0310],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,408][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.4669, 0.0092, 0.0089, 0.0093, 0.0108, 0.0186, 0.0222, 0.0247, 0.0372,
        0.0245, 0.0212, 0.0283, 0.0457, 0.0580, 0.0718, 0.0693, 0.0734],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,410][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.1239e-15, 2.5947e-14, 1.4965e-12, 8.5644e-12, 2.2918e-10, 2.0123e-10,
        7.5096e-11, 2.0706e-09, 2.7574e-07, 4.0545e-06, 5.5552e-05, 2.6299e-05,
        1.5767e-04, 4.5932e-04, 3.6813e-02, 5.6906e-01, 3.9342e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,414][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0017, 0.0062, 0.0069, 0.0093, 0.0227, 0.0173, 0.0182, 0.0449, 0.0304,
        0.1033, 0.0484, 0.0635, 0.1385, 0.0829, 0.1670, 0.1234, 0.1155],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,417][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0535, 0.1032, 0.0532, 0.1790, 0.0151, 0.0971, 0.0351, 0.1716, 0.0350,
        0.0141, 0.0356, 0.0846, 0.0155, 0.0646, 0.0110, 0.0097, 0.0221],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,417][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.0006e-02, 1.5740e-09, 1.3008e-05, 6.1313e-08, 1.4108e-04, 1.0416e-05,
        2.9825e-06, 1.8692e-04, 1.3965e-05, 7.7004e-03, 7.5765e-04, 1.3015e-03,
        5.6883e-02, 7.9023e-03, 3.9506e-01, 4.4097e-01, 6.9043e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,417][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0005, 0.0007, 0.0025, 0.0040, 0.0073, 0.0040, 0.0092, 0.0082, 0.0256,
        0.0340, 0.0485, 0.0584, 0.0601, 0.0696, 0.1482, 0.1789, 0.3402],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,418][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0122, 0.0335, 0.0297, 0.0548, 0.0352, 0.0593, 0.0616, 0.0725, 0.0876,
        0.0695, 0.0846, 0.0695, 0.0676, 0.0894, 0.0423, 0.0686, 0.0619],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,418][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.4355e-08, 7.5897e-08, 3.7539e-07, 9.0065e-07, 4.0470e-06, 5.5750e-06,
        1.7884e-06, 7.0778e-06, 7.8331e-05, 3.7358e-04, 1.0384e-03, 1.2833e-03,
        2.4159e-03, 8.4188e-03, 4.0137e-02, 8.3170e-01, 1.1454e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,419][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.9478e-01, 4.9620e-07, 1.3361e-07, 4.1444e-07, 2.0667e-06, 1.8528e-06,
        7.9378e-06, 7.6286e-05, 1.7745e-04, 2.0513e-03, 5.0018e-03, 2.3553e-02,
        5.6037e-02, 2.4697e-02, 1.4226e-01, 1.1918e-01, 3.3217e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,419][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0010, 0.0012, 0.0172, 0.0256, 0.0409, 0.0403, 0.0542, 0.0530, 0.0558,
        0.0672, 0.0688, 0.0792, 0.0819, 0.0780, 0.1178, 0.1014, 0.1164],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,421][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0422, 0.0445, 0.0110, 0.0283, 0.0197, 0.0271, 0.0374, 0.0427, 0.0430,
        0.0292, 0.0760, 0.0683, 0.0547, 0.0901, 0.1071, 0.1090, 0.1697],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,423][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0334, 0.0475, 0.0684, 0.0502, 0.0743, 0.0314, 0.0347, 0.0610, 0.0673,
        0.0657, 0.0747, 0.0374, 0.0764, 0.0744, 0.0738, 0.0371, 0.0330, 0.0595],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,428][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.1529, 0.0203, 0.0192, 0.0229, 0.0204, 0.0355, 0.0476, 0.0441, 0.0694,
        0.0375, 0.0421, 0.0534, 0.0602, 0.0768, 0.0681, 0.0770, 0.0977, 0.0550],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,430][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([8.0202e-16, 3.7698e-15, 1.8190e-13, 7.8303e-13, 3.8564e-11, 1.1585e-11,
        1.1612e-10, 2.7441e-10, 8.1171e-09, 5.5281e-07, 1.5024e-06, 3.2291e-06,
        5.3393e-05, 1.6083e-04, 8.3409e-03, 2.4010e-02, 6.0255e-01, 3.6488e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,434][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.0009, 0.0057, 0.0060, 0.0086, 0.0195, 0.0160, 0.0171, 0.0382, 0.0254,
        0.0817, 0.0386, 0.0516, 0.1043, 0.0639, 0.1119, 0.0890, 0.0882, 0.2335],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,435][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0083, 0.0780, 0.0470, 0.1090, 0.0292, 0.1052, 0.1206, 0.0581, 0.0631,
        0.0275, 0.0336, 0.0816, 0.0433, 0.0751, 0.0210, 0.0069, 0.0873, 0.0054],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,435][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([5.2131e-05, 4.4599e-11, 5.5630e-07, 5.3085e-09, 9.2006e-06, 1.0546e-06,
        4.4216e-07, 1.3652e-05, 2.0345e-06, 5.3498e-04, 1.1007e-04, 2.1542e-04,
        6.0067e-03, 1.2974e-03, 5.3337e-02, 6.7059e-02, 1.3862e-02, 8.5750e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,435][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0005, 0.0005, 0.0013, 0.0026, 0.0029, 0.0026, 0.0088, 0.0054, 0.0199,
        0.0242, 0.0395, 0.0465, 0.0390, 0.0617, 0.0591, 0.1225, 0.3438, 0.2192],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,436][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0114, 0.0330, 0.0278, 0.0531, 0.0327, 0.0566, 0.0594, 0.0691, 0.0845,
        0.0647, 0.0806, 0.0659, 0.0623, 0.0849, 0.0380, 0.0627, 0.0573, 0.0560],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,436][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([1.4240e-08, 7.8446e-08, 5.5785e-07, 8.3036e-07, 2.3817e-06, 3.0804e-06,
        6.5644e-06, 9.2374e-06, 7.8500e-05, 4.2777e-04, 7.5969e-04, 1.2978e-03,
        6.1776e-03, 1.4346e-02, 3.0335e-02, 2.3761e-01, 4.6997e-01, 2.3898e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,437][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([2.3324e-01, 2.4644e-07, 6.5440e-08, 1.7508e-07, 8.2347e-07, 7.4199e-07,
        2.8429e-06, 3.1208e-05, 4.8928e-05, 7.4854e-04, 1.6947e-03, 8.8934e-03,
        1.5935e-02, 5.3308e-03, 3.6920e-02, 3.4424e-02, 1.1282e-01, 5.4991e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,437][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0009, 0.0012, 0.0150, 0.0224, 0.0353, 0.0346, 0.0469, 0.0457, 0.0492,
        0.0587, 0.0607, 0.0694, 0.0719, 0.0692, 0.1032, 0.0892, 0.1029, 0.1236],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,437][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.0409, 0.0361, 0.0080, 0.0265, 0.0154, 0.0218, 0.0346, 0.0330, 0.0370,
        0.0237, 0.0698, 0.0570, 0.0435, 0.0973, 0.0921, 0.0948, 0.1789, 0.0895],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,439][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0341, 0.0493, 0.0589, 0.0499, 0.0446, 0.0279, 0.0323, 0.0726, 0.0596,
        0.0617, 0.0894, 0.0325, 0.0825, 0.0644, 0.0460, 0.0277, 0.0323, 0.0849,
        0.0494], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,442][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.3105, 0.0104, 0.0092, 0.0089, 0.0107, 0.0173, 0.0212, 0.0240, 0.0362,
        0.0248, 0.0217, 0.0287, 0.0463, 0.0534, 0.0718, 0.0655, 0.0704, 0.0636,
        0.1053], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,444][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.7027e-15, 7.1164e-16, 2.7502e-14, 1.3637e-13, 3.5355e-12, 6.2492e-12,
        1.7732e-11, 4.0716e-11, 1.8236e-09, 1.8138e-07, 1.5237e-07, 6.4747e-07,
        2.4087e-06, 5.8475e-06, 7.1333e-04, 1.3098e-02, 8.4368e-02, 3.3875e-01,
        5.6307e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,448][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0014, 0.0048, 0.0054, 0.0071, 0.0165, 0.0130, 0.0138, 0.0323, 0.0218,
        0.0706, 0.0341, 0.0447, 0.0935, 0.0553, 0.1109, 0.0825, 0.0799, 0.2245,
        0.0881], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,452][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0189, 0.0435, 0.0367, 0.0809, 0.0297, 0.1740, 0.0563, 0.0386, 0.1031,
        0.0226, 0.0548, 0.0708, 0.0230, 0.0683, 0.0241, 0.0663, 0.0415, 0.0170,
        0.0300], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,453][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.3445e-03, 2.1983e-11, 4.0202e-07, 1.1511e-09, 5.3446e-06, 3.2563e-07,
        8.8088e-08, 8.4210e-06, 4.5036e-07, 4.6249e-04, 3.5163e-05, 6.8685e-05,
        4.0217e-03, 4.7021e-04, 3.1282e-02, 3.6248e-02, 5.2967e-03, 8.8161e-01,
        3.8148e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,453][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0006, 0.0005, 0.0011, 0.0021, 0.0027, 0.0025, 0.0055, 0.0042, 0.0103,
        0.0133, 0.0212, 0.0316, 0.0259, 0.0477, 0.0482, 0.0807, 0.1888, 0.1340,
        0.3789], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,454][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0111, 0.0293, 0.0258, 0.0480, 0.0306, 0.0512, 0.0537, 0.0634, 0.0769,
        0.0610, 0.0756, 0.0617, 0.0593, 0.0801, 0.0377, 0.0600, 0.0544, 0.0530,
        0.0673], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,454][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.5925e-08, 4.5699e-08, 1.2990e-07, 2.1970e-07, 1.1693e-06, 2.7894e-06,
        2.1477e-06, 2.2796e-06, 1.9355e-05, 6.0181e-05, 2.0270e-04, 3.7071e-04,
        4.1885e-04, 3.0381e-03, 8.7071e-03, 4.1023e-01, 1.2160e-01, 1.9842e-01,
        2.5693e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,454][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.9760e-01, 4.9755e-07, 1.2894e-07, 2.9547e-07, 1.2943e-06, 9.8701e-07,
        3.4708e-06, 2.8934e-05, 4.6078e-05, 5.4986e-04, 1.1207e-03, 5.3916e-03,
        9.9807e-03, 3.4470e-03, 2.1338e-02, 1.9067e-02, 5.8996e-02, 3.8782e-01,
        1.9461e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,455][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0008, 0.0010, 0.0139, 0.0205, 0.0326, 0.0323, 0.0431, 0.0418, 0.0444,
        0.0532, 0.0543, 0.0625, 0.0644, 0.0618, 0.0924, 0.0796, 0.0911, 0.1094,
        0.1010], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,455][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0450, 0.0386, 0.0087, 0.0232, 0.0151, 0.0224, 0.0288, 0.0259, 0.0298,
        0.0203, 0.0518, 0.0505, 0.0394, 0.0727, 0.0722, 0.0787, 0.1197, 0.0748,
        0.1826], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,456][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:18,458][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12066],
        [21145],
        [  200],
        [10661],
        [ 4004],
        [ 9629],
        [15114],
        [ 4574],
        [12122],
        [11710],
        [29227],
        [16037],
        [17246],
        [10528],
        [ 6024],
        [ 5332],
        [15250],
        [11944],
        [ 9408]], device='cuda:0')
[2024-07-24 10:27:18,459][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15592],
        [12502],
        [   61],
        [14957],
        [ 8818],
        [21683],
        [33058],
        [ 8639],
        [10718],
        [23004],
        [37824],
        [27732],
        [32940],
        [23870],
        [20021],
        [28603],
        [34025],
        [29651],
        [24552]], device='cuda:0')
[2024-07-24 10:27:18,462][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 6972],
        [11725],
        [ 9140],
        [11108],
        [20155],
        [23250],
        [16442],
        [18180],
        [17014],
        [11136],
        [12467],
        [ 8417],
        [ 9190],
        [ 7922],
        [14926],
        [23405],
        [13065],
        [14957],
        [ 8947]], device='cuda:0')
[2024-07-24 10:27:18,463][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[29052],
        [26869],
        [15410],
        [13331],
        [11090],
        [11306],
        [10670],
        [10788],
        [10120],
        [ 8907],
        [ 8477],
        [ 8804],
        [ 8893],
        [ 8267],
        [ 8161],
        [ 8375],
        [ 8247],
        [ 8718],
        [ 8413]], device='cuda:0')
[2024-07-24 10:27:18,465][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[19278],
        [17069],
        [15870],
        [18162],
        [18537],
        [20292],
        [24882],
        [15989],
        [12420],
        [19458],
        [18804],
        [22629],
        [18743],
        [19754],
        [19614],
        [21315],
        [22981],
        [19044],
        [19936]], device='cuda:0')
[2024-07-24 10:27:18,468][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[3903],
        [3542],
        [7901],
        [5379],
        [5163],
        [4594],
        [3183],
        [2801],
        [2391],
        [2603],
        [2790],
        [2203],
        [1737],
        [1775],
        [1719],
        [1921],
        [1850],
        [2050],
        [2286]], device='cuda:0')
[2024-07-24 10:27:18,470][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[37234],
        [21546],
        [30202],
        [25441],
        [30408],
        [22250],
        [27902],
        [24498],
        [21768],
        [33007],
        [40640],
        [38879],
        [40236],
        [37840],
        [39244],
        [30229],
        [26050],
        [26774],
        [15614]], device='cuda:0')
[2024-07-24 10:27:18,473][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[40283],
        [30963],
        [ 4199],
        [16184],
        [ 7311],
        [12294],
        [12675],
        [11694],
        [34522],
        [15967],
        [25660],
        [26624],
        [32542],
        [27215],
        [25923],
        [24492],
        [23631],
        [30926],
        [25012]], device='cuda:0')
[2024-07-24 10:27:18,476][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24471],
        [22373],
        [18817],
        [19175],
        [16641],
        [18970],
        [18857],
        [20637],
        [20872],
        [21962],
        [21918],
        [21949],
        [21939],
        [21319],
        [20846],
        [21756],
        [21713],
        [21379],
        [21143]], device='cuda:0')
[2024-07-24 10:27:18,477][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[39343],
        [40632],
        [39384],
        [41832],
        [41355],
        [40997],
        [41366],
        [41626],
        [41817],
        [42567],
        [42264],
        [42072],
        [42169],
        [41967],
        [41452],
        [41251],
        [40870],
        [40975],
        [40735]], device='cuda:0')
[2024-07-24 10:27:18,478][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[35046],
        [36242],
        [40539],
        [41331],
        [42118],
        [42655],
        [29340],
        [27270],
        [28999],
        [19848],
        [23118],
        [44170],
        [47577],
        [46116],
        [42060],
        [44469],
        [25570],
        [37640],
        [21089]], device='cuda:0')
[2024-07-24 10:27:18,479][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[5226],
        [3386],
        [2402],
        [1976],
        [1996],
        [2081],
        [2024],
        [2014],
        [2100],
        [2271],
        [2395],
        [2203],
        [2189],
        [2280],
        [2258],
        [2252],
        [2384],
        [2515],
        [2743]], device='cuda:0')
[2024-07-24 10:27:18,480][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[25609],
        [37490],
        [11113],
        [14399],
        [11430],
        [ 7688],
        [ 7973],
        [ 7248],
        [10233],
        [ 5805],
        [ 7737],
        [ 7352],
        [ 6555],
        [ 7613],
        [ 6135],
        [ 4727],
        [ 5688],
        [ 5528],
        [ 5833]], device='cuda:0')
[2024-07-24 10:27:18,481][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[37134],
        [37881],
        [37396],
        [36515],
        [34660],
        [33383],
        [32343],
        [31103],
        [29652],
        [28051],
        [26719],
        [25451],
        [24170],
        [23461],
        [22064],
        [21536],
        [20887],
        [19591],
        [19968]], device='cuda:0')
[2024-07-24 10:27:18,484][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[10825],
        [17521],
        [ 7795],
        [12570],
        [ 7265],
        [11833],
        [10601],
        [ 7485],
        [20002],
        [ 5001],
        [19345],
        [ 5749],
        [ 2984],
        [ 6356],
        [ 5943],
        [ 5640],
        [ 8648],
        [10426],
        [13418]], device='cuda:0')
[2024-07-24 10:27:18,485][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[8555],
        [7245],
        [6336],
        [5665],
        [5246],
        [5382],
        [5566],
        [5770],
        [5853],
        [6065],
        [5822],
        [5833],
        [5963],
        [6018],
        [5893],
        [5605],
        [5582],
        [5502],
        [5723]], device='cuda:0')
[2024-07-24 10:27:18,487][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[4302],
        [4467],
        [4483],
        [4488],
        [4536],
        [6466],
        [6703],
        [6209],
        [6294],
        [6238],
        [4887],
        [4753],
        [5960],
        [4781],
        [5240],
        [5440],
        [4777],
        [5425],
        [5205]], device='cuda:0')
[2024-07-24 10:27:18,490][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 4745],
        [ 8114],
        [11673],
        [10434],
        [ 8374],
        [ 8756],
        [ 9484],
        [ 8206],
        [ 9633],
        [ 9824],
        [11708],
        [12247],
        [ 4890],
        [ 4989],
        [12060],
        [ 9556],
        [14562],
        [ 6341],
        [ 7858]], device='cuda:0')
[2024-07-24 10:27:18,493][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1706],
        [1897],
        [1604],
        [1952],
        [1463],
        [1740],
        [2029],
        [2248],
        [2584],
        [2441],
        [2670],
        [2771],
        [2480],
        [2445],
        [1946],
        [1949],
        [1989],
        [1800],
        [1800]], device='cuda:0')
[2024-07-24 10:27:18,495][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20348],
        [17830],
        [18564],
        [19602],
        [24558],
        [18214],
        [20255],
        [29249],
        [22056],
        [28097],
        [32847],
        [31274],
        [27091],
        [35797],
        [24467],
        [24298],
        [29782],
        [28210],
        [27086]], device='cuda:0')
[2024-07-24 10:27:18,498][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8727],
        [ 8735],
        [ 9867],
        [ 8768],
        [10542],
        [ 9880],
        [ 8832],
        [ 9273],
        [ 8735],
        [10454],
        [10045],
        [ 9768],
        [11702],
        [10957],
        [20336],
        [15016],
        [14214],
        [11822],
        [11803]], device='cuda:0')
[2024-07-24 10:27:18,499][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[12266],
        [11046],
        [ 5068],
        [ 4237],
        [ 2446],
        [ 3293],
        [ 2296],
        [ 1981],
        [ 1542],
        [ 1175],
        [ 1023],
        [  860],
        [  816],
        [ 1002],
        [ 1208],
        [ 2735],
        [ 2082],
        [ 1594],
        [ 1235]], device='cuda:0')
[2024-07-24 10:27:18,500][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[4003],
        [3649],
        [4396],
        [4751],
        [5090],
        [5630],
        [5842],
        [6305],
        [6777],
        [7116],
        [7376],
        [7557],
        [7816],
        [8067],
        [8021],
        [8182],
        [8204],
        [8310],
        [8345]], device='cuda:0')
[2024-07-24 10:27:18,501][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[14234],
        [14258],
        [16061],
        [16082],
        [11166],
        [ 6023],
        [ 6660],
        [ 8142],
        [18816],
        [14411],
        [10746],
        [12148],
        [13534],
        [13843],
        [11131],
        [ 9071],
        [11415],
        [13814],
        [ 9923]], device='cuda:0')
[2024-07-24 10:27:18,502][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14599],
        [14389],
        [14616],
        [14777],
        [14992],
        [15427],
        [14490],
        [15663],
        [14073],
        [16062],
        [17345],
        [15311],
        [17630],
        [17777],
        [15371],
        [17010],
        [14190],
        [16321],
        [15331]], device='cuda:0')
[2024-07-24 10:27:18,504][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[14044],
        [13769],
        [15387],
        [14790],
        [13332],
        [12470],
        [12523],
        [12050],
        [11665],
        [11487],
        [11178],
        [11123],
        [11058],
        [10745],
        [10321],
        [10141],
        [10185],
        [10005],
        [ 9711]], device='cuda:0')
[2024-07-24 10:27:18,506][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[21263],
        [23961],
        [37115],
        [29744],
        [34856],
        [33632],
        [27308],
        [28156],
        [25600],
        [27391],
        [26052],
        [24821],
        [26053],
        [26361],
        [29336],
        [29789],
        [26291],
        [26474],
        [23633]], device='cuda:0')
[2024-07-24 10:27:18,507][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[36015],
        [34710],
        [30313],
        [31562],
        [33245],
        [33913],
        [33712],
        [33395],
        [34286],
        [34466],
        [33576],
        [32402],
        [32882],
        [34189],
        [31100],
        [31544],
        [31191],
        [32811],
        [34690]], device='cuda:0')
[2024-07-24 10:27:18,510][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[36066],
        [40669],
        [45680],
        [44554],
        [46318],
        [45818],
        [45543],
        [46058],
        [42535],
        [47455],
        [44461],
        [46420],
        [45888],
        [46359],
        [45556],
        [45230],
        [47718],
        [44569],
        [46456]], device='cuda:0')
[2024-07-24 10:27:18,512][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510],
        [23510]], device='cuda:0')
[2024-07-24 10:27:18,536][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:18,537][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,537][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,538][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,538][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,538][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,539][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,539][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,539][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,540][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,540][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,540][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,541][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,541][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([9.9963e-01, 3.7168e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,541][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8208, 0.1792], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,542][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2615, 0.7385], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,542][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0545, 0.9455], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,542][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([9.9966e-01, 3.4048e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,543][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4888, 0.5112], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,543][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6171, 0.3829], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,543][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.7942, 0.2058], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,544][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8706, 0.1294], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,544][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.8771, 0.1229], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,544][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9585, 0.0415], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,545][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4761, 0.5239], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,545][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([9.9855e-01, 7.3636e-04, 7.1488e-04], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,545][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([0.6351, 0.0875, 0.2773], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,546][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.1842, 0.5439, 0.2719], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,546][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.0187, 0.8202, 0.1611], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,546][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([9.9985e-01, 1.0913e-04, 3.7256e-05], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,547][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([0.2990, 0.3217, 0.3793], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,551][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.4525, 0.2914, 0.2561], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,557][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.7014, 0.1479, 0.1507], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,557][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.8936, 0.0439, 0.0624], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,558][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.0658, 0.9150, 0.0192], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,558][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.8220, 0.0428, 0.1352], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,558][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.5688, 0.1145, 0.3167], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,558][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([9.9738e-01, 5.8477e-04, 5.4950e-04, 1.4840e-03], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,559][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5964, 0.0587, 0.2076, 0.1372], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,559][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1162, 0.3619, 0.2317, 0.2901], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,559][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0150, 0.4496, 0.2775, 0.2579], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,560][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([9.9944e-01, 2.1813e-04, 1.2080e-04, 2.2510e-04], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,563][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2223, 0.2351, 0.2814, 0.2612], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,569][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3499, 0.2243, 0.2030, 0.2227], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,573][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6846, 0.1227, 0.1340, 0.0587], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,573][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9011, 0.0253, 0.0477, 0.0259], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,573][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5376, 0.3687, 0.0391, 0.0545], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,574][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.8401, 0.0314, 0.1045, 0.0241], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,574][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2059, 0.0307, 0.2324, 0.5309], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,574][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([9.9837e-01, 3.2007e-04, 2.7597e-04, 8.4694e-04, 1.8720e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,574][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.4306, 0.0481, 0.1726, 0.1238, 0.2248], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,575][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0916, 0.3309, 0.1610, 0.2801, 0.1365], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,575][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0124, 0.4088, 0.1818, 0.3088, 0.0882], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,575][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([9.9807e-01, 6.7709e-04, 3.2418e-04, 5.7608e-04, 3.5200e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,576][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.1751, 0.1895, 0.2203, 0.2090, 0.2061], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,579][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.2931, 0.1875, 0.1636, 0.1851, 0.1707], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,585][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.6279, 0.1143, 0.1162, 0.0568, 0.0848], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,589][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.7933, 0.0385, 0.0733, 0.0456, 0.0493], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,589][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0265, 0.7933, 0.0197, 0.1487, 0.0117], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,589][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.7146, 0.0286, 0.1112, 0.0274, 0.1183], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,590][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.3212, 0.0171, 0.1386, 0.2308, 0.2922], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,590][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([9.9402e-01, 5.9369e-04, 6.5685e-04, 1.5847e-03, 3.3966e-04, 2.8100e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,590][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.3942, 0.0412, 0.1376, 0.0957, 0.1747, 0.1565], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,590][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0819, 0.2299, 0.1631, 0.2229, 0.1613, 0.1408], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,591][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0093, 0.2855, 0.1997, 0.2475, 0.1518, 0.1063], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,591][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([9.9846e-01, 4.3929e-04, 2.0005e-04, 3.2197e-04, 2.1335e-04, 3.6374e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,594][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1438, 0.1523, 0.1822, 0.1682, 0.1710, 0.1823], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,599][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2447, 0.1512, 0.1370, 0.1526, 0.1469, 0.1676], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,604][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.5627, 0.1118, 0.1257, 0.0614, 0.0924, 0.0459], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,605][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.8606, 0.0213, 0.0434, 0.0230, 0.0299, 0.0219], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,605][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.4041, 0.4285, 0.0072, 0.0131, 0.0098, 0.1374], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,605][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.6299, 0.0350, 0.1159, 0.0268, 0.1316, 0.0608], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,606][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1694, 0.0098, 0.0488, 0.2026, 0.2369, 0.3325], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,606][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.9353e-01, 5.3075e-04, 5.1368e-04, 1.3285e-03, 3.0075e-04, 2.1080e-03,
        1.6918e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,606][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3725, 0.0345, 0.1140, 0.0760, 0.1424, 0.1313, 0.1293],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,607][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0675, 0.2059, 0.1278, 0.1917, 0.1108, 0.1423, 0.1541],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,607][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0110, 0.2933, 0.1576, 0.1451, 0.1544, 0.1627, 0.0759],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,607][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([9.9665e-01, 7.6672e-04, 3.6410e-04, 5.3508e-04, 3.9544e-04, 6.6049e-04,
        6.2930e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,610][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1221, 0.1294, 0.1511, 0.1405, 0.1443, 0.1527, 0.1598],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,615][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2026, 0.1325, 0.1195, 0.1333, 0.1292, 0.1467, 0.1361],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,620][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.5475, 0.1045, 0.1161, 0.0536, 0.0887, 0.0411, 0.0486],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,621][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.8758, 0.0145, 0.0285, 0.0136, 0.0201, 0.0141, 0.0334],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,621][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.4184, 0.0697, 0.0029, 0.0218, 0.0056, 0.4809, 0.0008],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,621][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6196, 0.0271, 0.1017, 0.0268, 0.1054, 0.0525, 0.0669],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,622][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3200, 0.0038, 0.0380, 0.0748, 0.1847, 0.1651, 0.2136],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,622][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([9.9766e-01, 2.3898e-04, 1.8148e-04, 4.4542e-04, 9.3972e-05, 5.6426e-04,
        3.6527e-04, 4.5311e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,622][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.3240, 0.0275, 0.0905, 0.0605, 0.1097, 0.1015, 0.1016, 0.1848],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,623][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0718, 0.1707, 0.1116, 0.1651, 0.0941, 0.1093, 0.1931, 0.0842],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,623][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0116, 0.2612, 0.1166, 0.1638, 0.1111, 0.0946, 0.1767, 0.0643],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,624][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([9.9204e-01, 2.0865e-03, 6.2074e-04, 9.7127e-04, 7.4344e-04, 1.2924e-03,
        1.3412e-03, 9.0097e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,630][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.1025, 0.1089, 0.1288, 0.1236, 0.1238, 0.1346, 0.1446, 0.1331],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,635][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.1897, 0.1186, 0.1020, 0.1152, 0.1072, 0.1262, 0.1171, 0.1240],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,636][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.5004, 0.0961, 0.1027, 0.0496, 0.0795, 0.0375, 0.0440, 0.0902],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,637][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.7176, 0.0259, 0.0502, 0.0263, 0.0348, 0.0233, 0.0624, 0.0594],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,637][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0602, 0.6535, 0.0726, 0.0649, 0.0252, 0.0348, 0.0842, 0.0047],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,637][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.4431, 0.0342, 0.1010, 0.0289, 0.0932, 0.0499, 0.0646, 0.1851],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,638][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([2.9353e-01, 1.0302e-04, 2.2000e-03, 3.3136e-03, 8.3550e-03, 5.2084e-03,
        4.6942e-02, 6.4035e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,638][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ of] are: tensor([9.9531e-01, 2.9848e-04, 2.5079e-04, 5.8747e-04, 1.7075e-04, 8.8704e-04,
        5.1503e-04, 5.8316e-04, 1.3975e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,638][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.3003, 0.0194, 0.0747, 0.0465, 0.0952, 0.0837, 0.0836, 0.1617, 0.1349],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,639][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0478, 0.1507, 0.1021, 0.1500, 0.0817, 0.1008, 0.1686, 0.0979, 0.1004],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,639][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0051, 0.1596, 0.1283, 0.1068, 0.1138, 0.1024, 0.0825, 0.2510, 0.0505],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,640][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ of] are: tensor([9.8910e-01, 1.5202e-03, 9.2277e-04, 1.4041e-03, 1.2240e-03, 1.3821e-03,
        1.4807e-03, 9.5403e-04, 2.0085e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,644][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0920, 0.0983, 0.1181, 0.1087, 0.1133, 0.1164, 0.1261, 0.1176, 0.1094],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,649][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.1554, 0.1043, 0.0928, 0.1034, 0.0990, 0.1134, 0.1044, 0.1134, 0.1140],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,652][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.4865, 0.0900, 0.1034, 0.0460, 0.0766, 0.0381, 0.0425, 0.0938, 0.0230],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,653][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.7802, 0.0119, 0.0320, 0.0157, 0.0255, 0.0181, 0.0473, 0.0537, 0.0157],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,653][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.1408, 0.3364, 0.1078, 0.1663, 0.0049, 0.0500, 0.0769, 0.0526, 0.0643],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,653][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.5493, 0.0213, 0.0721, 0.0200, 0.0926, 0.0331, 0.0589, 0.1279, 0.0248],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,654][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ of] are: tensor([2.3029e-02, 4.7357e-05, 1.0944e-03, 1.4218e-03, 1.0916e-02, 4.4384e-03,
        1.5714e-02, 8.8653e-01, 5.6811e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,654][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([9.9734e-01, 9.5167e-05, 8.5379e-05, 2.2826e-04, 5.2657e-05, 3.7636e-04,
        2.5138e-04, 2.8143e-04, 6.4290e-04, 6.4573e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,654][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.2616, 0.0195, 0.0651, 0.0407, 0.0780, 0.0721, 0.0722, 0.1272, 0.1111,
        0.1524], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,655][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0512, 0.1410, 0.0832, 0.1345, 0.0698, 0.0842, 0.1659, 0.0894, 0.1177,
        0.0633], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,658][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0087, 0.2025, 0.1371, 0.1449, 0.0815, 0.1245, 0.0900, 0.1016, 0.0853,
        0.0240], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,660][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([9.9162e-01, 1.4269e-03, 5.0481e-04, 8.9181e-04, 6.9943e-04, 9.7775e-04,
        1.0014e-03, 1.0963e-03, 1.4700e-03, 3.1030e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,666][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0818, 0.0903, 0.1069, 0.0994, 0.1024, 0.1098, 0.1169, 0.1073, 0.1026,
        0.0825], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,668][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.1513, 0.0977, 0.0814, 0.0923, 0.0834, 0.1025, 0.0943, 0.0992, 0.1017,
        0.0961], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,668][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.5449, 0.0831, 0.0780, 0.0382, 0.0587, 0.0294, 0.0323, 0.0648, 0.0176,
        0.0529], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,669][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.7033, 0.0224, 0.0444, 0.0214, 0.0286, 0.0173, 0.0465, 0.0481, 0.0167,
        0.0512], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,669][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([2.5346e-02, 5.2913e-01, 2.5990e-03, 1.4676e-02, 2.5698e-03, 7.7191e-02,
        3.8815e-02, 3.3710e-03, 3.0598e-01, 3.2822e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,669][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.5054, 0.0209, 0.0820, 0.0213, 0.0750, 0.0304, 0.0529, 0.1431, 0.0205,
        0.0485], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,670][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([2.5035e-02, 2.2394e-05, 4.3876e-04, 5.5786e-04, 3.7798e-03, 9.1557e-04,
        2.2307e-02, 7.3220e-01, 1.1145e-01, 1.0329e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,670][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ at] are: tensor([9.7913e-01, 5.5210e-04, 4.9902e-04, 1.3839e-03, 3.1888e-04, 2.1191e-03,
        1.4204e-03, 1.2091e-03, 3.0096e-03, 2.0893e-03, 8.2679e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,670][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.3227, 0.0200, 0.0566, 0.0339, 0.0582, 0.0566, 0.0538, 0.0948, 0.0770,
        0.0949, 0.1315], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,674][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0464, 0.1248, 0.0732, 0.1239, 0.0678, 0.0857, 0.1469, 0.0732, 0.1026,
        0.0741, 0.0813], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,679][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0049, 0.1861, 0.0969, 0.1199, 0.0891, 0.1103, 0.0824, 0.0880, 0.1083,
        0.0465, 0.0677], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,682][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ at] are: tensor([9.8510e-01, 2.5214e-03, 9.0235e-04, 1.5776e-03, 1.4236e-03, 1.8186e-03,
        1.7481e-03, 1.3430e-03, 2.3842e-03, 6.3241e-04, 5.5045e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,684][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0761, 0.0804, 0.0979, 0.0902, 0.0945, 0.0996, 0.1098, 0.0995, 0.0934,
        0.0790, 0.0795], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,684][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.1450, 0.0816, 0.0748, 0.0804, 0.0782, 0.0868, 0.0803, 0.0857, 0.0866,
        0.0849, 0.1156], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,684][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.4537, 0.0863, 0.0865, 0.0399, 0.0662, 0.0305, 0.0366, 0.0775, 0.0208,
        0.0664, 0.0356], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,685][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.8649, 0.0099, 0.0170, 0.0074, 0.0109, 0.0078, 0.0220, 0.0220, 0.0083,
        0.0220, 0.0079], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,685][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0429, 0.5349, 0.0112, 0.0201, 0.0014, 0.2044, 0.0651, 0.0090, 0.0335,
        0.0030, 0.0745], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,685][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.6556, 0.0108, 0.0498, 0.0090, 0.0547, 0.0178, 0.0301, 0.1087, 0.0097,
        0.0415, 0.0123], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,686][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ at] are: tensor([1.2342e-01, 6.7625e-05, 1.0890e-03, 1.1015e-03, 3.5460e-03, 2.4317e-03,
        7.2780e-03, 2.8214e-01, 8.9363e-02, 7.9648e-02, 4.0991e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:18,686][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ the] are: tensor([9.4925e-01, 7.9853e-04, 7.1659e-04, 1.8788e-03, 4.8230e-04, 3.1993e-03,
        2.2172e-03, 1.8177e-03, 5.2434e-03, 3.5505e-03, 1.2642e-02, 1.8208e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,689][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.2540, 0.0182, 0.0525, 0.0325, 0.0576, 0.0557, 0.0528, 0.0946, 0.0787,
        0.0942, 0.1256, 0.0835], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,695][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0399, 0.1120, 0.0670, 0.1036, 0.0634, 0.0754, 0.1002, 0.0676, 0.0954,
        0.0672, 0.0922, 0.1161], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,699][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0060, 0.1834, 0.0746, 0.0953, 0.1097, 0.1001, 0.0503, 0.1082, 0.0665,
        0.0455, 0.0848, 0.0756], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,699][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.9562, 0.0063, 0.0027, 0.0041, 0.0035, 0.0048, 0.0045, 0.0030, 0.0065,
        0.0019, 0.0017, 0.0047], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,700][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0701, 0.0754, 0.0899, 0.0833, 0.0854, 0.0900, 0.0972, 0.0905, 0.0860,
        0.0721, 0.0747, 0.0855], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,700][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.1264, 0.0728, 0.0667, 0.0723, 0.0701, 0.0770, 0.0712, 0.0768, 0.0771,
        0.0765, 0.1035, 0.1096], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,701][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.4636, 0.0816, 0.0795, 0.0362, 0.0608, 0.0277, 0.0327, 0.0703, 0.0192,
        0.0595, 0.0316, 0.0372], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,701][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.8215, 0.0104, 0.0200, 0.0081, 0.0130, 0.0087, 0.0256, 0.0300, 0.0112,
        0.0332, 0.0083, 0.0099], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,701][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.1776, 0.0622, 0.0063, 0.0144, 0.0013, 0.1228, 0.0004, 0.0047, 0.3389,
        0.0250, 0.2455, 0.0009], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,702][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.7453, 0.0066, 0.0364, 0.0045, 0.0369, 0.0101, 0.0189, 0.0914, 0.0045,
        0.0270, 0.0051, 0.0131], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,702][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ the] are: tensor([1.8398e-01, 8.8038e-06, 3.4160e-04, 1.5266e-04, 9.9137e-04, 5.3705e-04,
        1.7218e-03, 2.6951e-02, 1.2168e-02, 1.1484e-02, 2.0543e-01, 5.5623e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:18,703][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ store] are: tensor([9.9163e-01, 1.3497e-04, 1.0456e-04, 3.2330e-04, 5.7052e-05, 4.5881e-04,
        3.1809e-04, 3.2986e-04, 9.1529e-04, 5.5622e-04, 2.0276e-03, 2.9530e-03,
        1.8784e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,708][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.2431, 0.0170, 0.0475, 0.0284, 0.0473, 0.0476, 0.0452, 0.0767, 0.0639,
        0.0818, 0.1033, 0.0681, 0.1301], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,713][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0340, 0.0996, 0.0622, 0.0927, 0.0507, 0.0585, 0.1161, 0.0540, 0.0848,
        0.0497, 0.0922, 0.1377, 0.0677], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,715][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0048, 0.1490, 0.0922, 0.1165, 0.0554, 0.0779, 0.0973, 0.0539, 0.0843,
        0.0214, 0.0932, 0.1074, 0.0467], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,716][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.9193, 0.0079, 0.0041, 0.0066, 0.0049, 0.0076, 0.0069, 0.0068, 0.0114,
        0.0032, 0.0025, 0.0067, 0.0122], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,716][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0618, 0.0688, 0.0821, 0.0783, 0.0782, 0.0874, 0.0935, 0.0839, 0.0808,
        0.0651, 0.0710, 0.0827, 0.0664], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,716][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.1213, 0.0676, 0.0597, 0.0650, 0.0605, 0.0702, 0.0651, 0.0677, 0.0690,
        0.0656, 0.0930, 0.0982, 0.0970], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,717][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.4398, 0.0752, 0.0650, 0.0329, 0.0486, 0.0237, 0.0294, 0.0563, 0.0172,
        0.0457, 0.0327, 0.0384, 0.0950], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,717][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.7169, 0.0203, 0.0306, 0.0134, 0.0199, 0.0135, 0.0355, 0.0379, 0.0139,
        0.0391, 0.0132, 0.0174, 0.0285], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,717][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ store] are: tensor([4.4267e-04, 2.1304e-01, 6.5981e-04, 3.6680e-03, 3.5817e-05, 2.7587e-04,
        8.8342e-03, 2.7971e-03, 1.4951e-01, 1.4057e-04, 6.1297e-01, 7.0763e-03,
        5.5197e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,718][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.3167, 0.0192, 0.0571, 0.0152, 0.0593, 0.0290, 0.0400, 0.1421, 0.0134,
        0.0435, 0.0160, 0.0231, 0.2253], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,719][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ store] are: tensor([5.3789e-02, 8.6181e-07, 1.4229e-05, 1.4591e-05, 5.4769e-05, 7.2200e-05,
        1.5074e-04, 3.7412e-03, 2.4694e-03, 1.2935e-03, 8.7674e-02, 2.9777e-01,
        5.5296e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:18,723][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [.] are: tensor([9.7208e-01, 4.2285e-04, 2.9980e-04, 9.8011e-04, 1.7623e-04, 1.5363e-03,
        1.0367e-03, 9.1929e-04, 2.9754e-03, 1.1712e-03, 6.1627e-03, 1.0104e-02,
        3.6816e-04, 1.7699e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,728][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.2339, 0.0130, 0.0404, 0.0231, 0.0449, 0.0420, 0.0406, 0.0738, 0.0621,
        0.0759, 0.1037, 0.0665, 0.1203, 0.0596], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,731][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0310, 0.0924, 0.0569, 0.0852, 0.0493, 0.0574, 0.1020, 0.0606, 0.0693,
        0.0583, 0.0794, 0.1220, 0.0783, 0.0582], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,732][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0041, 0.0935, 0.0668, 0.0592, 0.0707, 0.0781, 0.0667, 0.1080, 0.0554,
        0.0618, 0.0493, 0.0971, 0.1517, 0.0376], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,732][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.9518, 0.0048, 0.0020, 0.0035, 0.0027, 0.0038, 0.0037, 0.0028, 0.0055,
        0.0012, 0.0013, 0.0039, 0.0060, 0.0069], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,732][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0610, 0.0645, 0.0782, 0.0724, 0.0752, 0.0788, 0.0876, 0.0785, 0.0747,
        0.0609, 0.0633, 0.0750, 0.0624, 0.0674], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,733][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.1026, 0.0592, 0.0543, 0.0591, 0.0577, 0.0642, 0.0586, 0.0640, 0.0646,
        0.0650, 0.0869, 0.0921, 0.0947, 0.0770], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,733][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.3966, 0.0666, 0.0698, 0.0317, 0.0507, 0.0247, 0.0313, 0.0646, 0.0180,
        0.0511, 0.0295, 0.0350, 0.0888, 0.0416], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,733][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.7877, 0.0111, 0.0207, 0.0076, 0.0140, 0.0086, 0.0238, 0.0314, 0.0101,
        0.0356, 0.0081, 0.0106, 0.0192, 0.0114], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,734][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0613, 0.1433, 0.0155, 0.0443, 0.0105, 0.0045, 0.0599, 0.1130, 0.0352,
        0.0047, 0.2070, 0.1640, 0.1267, 0.0101], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,734][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.3368, 0.0156, 0.0524, 0.0115, 0.0601, 0.0253, 0.0317, 0.1195, 0.0085,
        0.0422, 0.0134, 0.0202, 0.2053, 0.0574], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,735][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [.] are: tensor([9.2671e-04, 1.6522e-07, 7.4623e-06, 7.0372e-06, 3.2831e-05, 1.6771e-05,
        5.2707e-05, 1.6182e-03, 4.6160e-04, 1.3479e-03, 1.7907e-02, 1.1285e-01,
        8.4839e-01, 1.6376e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:18,738][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([9.8950e-01, 1.9089e-04, 1.4293e-04, 4.5962e-04, 9.7211e-05, 6.8804e-04,
        4.4591e-04, 3.9205e-04, 1.1816e-03, 5.5280e-04, 2.1401e-03, 3.1771e-03,
        2.0117e-04, 5.8738e-04, 2.4281e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,744][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.1827, 0.0132, 0.0364, 0.0236, 0.0398, 0.0397, 0.0382, 0.0656, 0.0566,
        0.0732, 0.0962, 0.0626, 0.1087, 0.0633, 0.1001], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,748][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0261, 0.0990, 0.0436, 0.0835, 0.0361, 0.0550, 0.0998, 0.0572, 0.0750,
        0.0440, 0.0781, 0.1226, 0.0765, 0.0689, 0.0346], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,748][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0043, 0.1334, 0.0527, 0.0946, 0.0271, 0.0622, 0.0689, 0.0715, 0.0909,
        0.0222, 0.0739, 0.1067, 0.1069, 0.0631, 0.0215], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,749][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.8623, 0.0083, 0.0048, 0.0069, 0.0055, 0.0078, 0.0083, 0.0078, 0.0141,
        0.0048, 0.0043, 0.0098, 0.0115, 0.0161, 0.0276], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,749][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.0544, 0.0606, 0.0710, 0.0676, 0.0668, 0.0781, 0.0800, 0.0751, 0.0733,
        0.0576, 0.0643, 0.0710, 0.0604, 0.0670, 0.0529], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,749][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.1055, 0.0549, 0.0489, 0.0547, 0.0503, 0.0589, 0.0551, 0.0582, 0.0597,
        0.0579, 0.0806, 0.0854, 0.0853, 0.0718, 0.0726], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,750][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.4048, 0.0627, 0.0611, 0.0278, 0.0442, 0.0199, 0.0244, 0.0520, 0.0145,
        0.0464, 0.0259, 0.0301, 0.0854, 0.0353, 0.0653], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,750][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.6489, 0.0206, 0.0335, 0.0153, 0.0207, 0.0135, 0.0343, 0.0429, 0.0187,
        0.0529, 0.0153, 0.0170, 0.0269, 0.0166, 0.0230], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,750][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0054, 0.2891, 0.0092, 0.0534, 0.0029, 0.0040, 0.2177, 0.0074, 0.1664,
        0.0004, 0.0023, 0.1879, 0.0010, 0.0497, 0.0031], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,754][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.4143, 0.0083, 0.0432, 0.0065, 0.0486, 0.0147, 0.0189, 0.0975, 0.0059,
        0.0292, 0.0097, 0.0129, 0.1606, 0.0303, 0.0995], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,758][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([3.5124e-02, 4.0702e-07, 1.3872e-05, 1.1093e-05, 3.1434e-05, 2.4214e-05,
        7.9168e-05, 4.9031e-04, 3.8839e-04, 5.7125e-04, 1.7006e-02, 1.3711e-01,
        6.8932e-01, 2.8480e-02, 9.1351e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:18,760][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([9.8094e-01, 2.0565e-04, 1.8862e-04, 5.8639e-04, 1.0414e-04, 1.0560e-03,
        6.1337e-04, 4.9472e-04, 1.6930e-03, 8.4829e-04, 4.0696e-03, 6.2494e-03,
        2.5488e-04, 9.8503e-04, 2.8537e-04, 1.4217e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,764][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1635, 0.0146, 0.0379, 0.0236, 0.0394, 0.0388, 0.0368, 0.0642, 0.0527,
        0.0625, 0.0832, 0.0572, 0.1045, 0.0547, 0.0922, 0.0743],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,764][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0235, 0.0809, 0.0507, 0.0748, 0.0412, 0.0461, 0.1011, 0.0509, 0.0724,
        0.0462, 0.0801, 0.1282, 0.0576, 0.0681, 0.0430, 0.0352],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,765][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0044, 0.1234, 0.0658, 0.1071, 0.0499, 0.0521, 0.0527, 0.0561, 0.0903,
        0.0350, 0.0998, 0.0706, 0.0739, 0.0581, 0.0412, 0.0195],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,765][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.8882, 0.0049, 0.0029, 0.0043, 0.0036, 0.0058, 0.0056, 0.0048, 0.0071,
        0.0030, 0.0024, 0.0068, 0.0084, 0.0103, 0.0227, 0.0190],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,765][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0527, 0.0577, 0.0705, 0.0650, 0.0657, 0.0713, 0.0765, 0.0699, 0.0680,
        0.0536, 0.0587, 0.0679, 0.0582, 0.0630, 0.0507, 0.0505],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,766][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0991, 0.0487, 0.0449, 0.0494, 0.0469, 0.0534, 0.0491, 0.0530, 0.0536,
        0.0524, 0.0752, 0.0800, 0.0811, 0.0660, 0.0695, 0.0778],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,766][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.3593, 0.0619, 0.0606, 0.0300, 0.0446, 0.0223, 0.0275, 0.0525, 0.0168,
        0.0423, 0.0279, 0.0331, 0.0783, 0.0397, 0.0669, 0.0362],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,767][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.6743, 0.0176, 0.0287, 0.0128, 0.0201, 0.0133, 0.0315, 0.0382, 0.0150,
        0.0431, 0.0124, 0.0157, 0.0270, 0.0182, 0.0218, 0.0105],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,768][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([1.6055e-02, 2.7544e-01, 2.1458e-03, 6.4241e-03, 8.4127e-05, 1.1780e-01,
        3.0850e-02, 2.1695e-02, 8.2191e-02, 4.2250e-04, 6.0159e-02, 1.7678e-01,
        3.2763e-03, 2.0012e-01, 1.2657e-04, 6.4259e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,772][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.3442, 0.0107, 0.0453, 0.0088, 0.0459, 0.0184, 0.0209, 0.0971, 0.0062,
        0.0274, 0.0083, 0.0124, 0.1367, 0.0319, 0.0949, 0.0911],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,775][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.1739e-01, 4.1662e-07, 9.0717e-06, 9.3827e-06, 1.3759e-05, 1.4721e-05,
        4.3252e-05, 4.2399e-04, 4.8995e-04, 7.1964e-05, 7.2528e-03, 2.1146e-02,
        6.3697e-02, 1.0568e-02, 2.1290e-02, 7.5758e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:18,778][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([9.5342e-01, 5.1977e-04, 4.3625e-04, 1.2214e-03, 2.7342e-04, 1.9355e-03,
        1.3872e-03, 1.2803e-03, 4.3128e-03, 2.5320e-03, 9.5941e-03, 1.3408e-02,
        7.5206e-04, 2.5670e-03, 7.5614e-04, 3.3336e-03, 2.2716e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,781][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1463, 0.0121, 0.0341, 0.0214, 0.0383, 0.0362, 0.0343, 0.0613, 0.0508,
        0.0594, 0.0799, 0.0550, 0.0979, 0.0523, 0.0923, 0.0716, 0.0567],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,781][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0254, 0.0866, 0.0457, 0.0809, 0.0394, 0.0546, 0.0627, 0.0407, 0.0699,
        0.0478, 0.0736, 0.1029, 0.0731, 0.0633, 0.0360, 0.0459, 0.0515],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,781][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0049, 0.1330, 0.0566, 0.0636, 0.0607, 0.0682, 0.0324, 0.0963, 0.0428,
        0.0283, 0.0605, 0.0600, 0.1349, 0.0447, 0.0485, 0.0410, 0.0235],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,782][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8237, 0.0089, 0.0045, 0.0063, 0.0054, 0.0074, 0.0078, 0.0069, 0.0095,
        0.0041, 0.0035, 0.0088, 0.0108, 0.0124, 0.0307, 0.0296, 0.0198],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,782][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0514, 0.0552, 0.0648, 0.0613, 0.0631, 0.0664, 0.0717, 0.0686, 0.0634,
        0.0521, 0.0553, 0.0636, 0.0561, 0.0592, 0.0495, 0.0487, 0.0495],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,783][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0853, 0.0448, 0.0418, 0.0464, 0.0448, 0.0503, 0.0459, 0.0506, 0.0515,
        0.0514, 0.0707, 0.0749, 0.0771, 0.0620, 0.0655, 0.0725, 0.0643],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,783][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3635, 0.0571, 0.0602, 0.0278, 0.0452, 0.0213, 0.0257, 0.0524, 0.0151,
        0.0422, 0.0242, 0.0286, 0.0740, 0.0348, 0.0642, 0.0318, 0.0318],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,786][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.7275, 0.0140, 0.0237, 0.0092, 0.0174, 0.0105, 0.0237, 0.0321, 0.0111,
        0.0362, 0.0092, 0.0110, 0.0222, 0.0131, 0.0195, 0.0085, 0.0110],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,790][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([5.7996e-03, 2.7874e-03, 8.2159e-05, 6.7381e-04, 7.0931e-05, 1.2913e-02,
        2.6350e-05, 3.4752e-04, 9.3894e-03, 9.0980e-04, 3.0804e-02, 8.1300e-05,
        3.1349e-03, 6.3589e-04, 1.4400e-04, 9.3214e-01, 6.2656e-05],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,795][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3163, 0.0091, 0.0392, 0.0073, 0.0349, 0.0155, 0.0190, 0.0861, 0.0049,
        0.0208, 0.0056, 0.0084, 0.1347, 0.0315, 0.0725, 0.0764, 0.1177],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,797][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([4.6786e-02, 6.6915e-08, 3.4738e-06, 1.3947e-06, 7.0562e-06, 3.5891e-06,
        3.7838e-06, 2.5390e-04, 1.3581e-04, 8.1352e-05, 2.0984e-03, 1.5364e-02,
        5.4201e-02, 4.6957e-03, 1.5369e-02, 6.0354e-01, 2.5746e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:18,797][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([9.8262e-01, 2.9739e-04, 1.9783e-04, 6.2097e-04, 1.2089e-04, 9.4476e-04,
        6.2968e-04, 5.6337e-04, 1.7018e-03, 9.2709e-04, 3.0773e-03, 4.3387e-03,
        3.1326e-04, 9.8598e-04, 2.6726e-04, 1.0582e-03, 8.3856e-04, 4.9357e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,797][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.1097, 0.0116, 0.0321, 0.0213, 0.0366, 0.0354, 0.0337, 0.0576, 0.0514,
        0.0631, 0.0781, 0.0526, 0.0908, 0.0544, 0.0865, 0.0692, 0.0551, 0.0607],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,798][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0197, 0.0745, 0.0409, 0.0700, 0.0334, 0.0459, 0.0916, 0.0460, 0.0624,
        0.0355, 0.0649, 0.1045, 0.0612, 0.0519, 0.0320, 0.0423, 0.0922, 0.0311],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,798][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0022, 0.0898, 0.0555, 0.0684, 0.0565, 0.0588, 0.0602, 0.0518, 0.0801,
        0.0321, 0.0627, 0.0753, 0.1005, 0.0428, 0.0468, 0.0462, 0.0430, 0.0271],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,799][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.8289, 0.0075, 0.0033, 0.0052, 0.0051, 0.0072, 0.0068, 0.0060, 0.0091,
        0.0036, 0.0029, 0.0063, 0.0090, 0.0125, 0.0276, 0.0283, 0.0165, 0.0144],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,799][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0465, 0.0504, 0.0608, 0.0583, 0.0599, 0.0652, 0.0702, 0.0644, 0.0605,
        0.0493, 0.0526, 0.0618, 0.0501, 0.0564, 0.0467, 0.0486, 0.0487, 0.0496],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,799][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0878, 0.0446, 0.0393, 0.0436, 0.0400, 0.0475, 0.0438, 0.0460, 0.0469,
        0.0442, 0.0656, 0.0695, 0.0688, 0.0572, 0.0593, 0.0683, 0.0624, 0.0652],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,803][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.3308, 0.0576, 0.0519, 0.0262, 0.0398, 0.0198, 0.0236, 0.0442, 0.0142,
        0.0365, 0.0254, 0.0289, 0.0709, 0.0341, 0.0598, 0.0358, 0.0343, 0.0662],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,807][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.5931, 0.0232, 0.0358, 0.0145, 0.0242, 0.0148, 0.0335, 0.0418, 0.0150,
        0.0470, 0.0118, 0.0138, 0.0282, 0.0164, 0.0242, 0.0128, 0.0178, 0.0322],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,811][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([1.1359e-02, 2.2624e-01, 4.5001e-03, 2.9997e-02, 5.6104e-03, 9.5333e-03,
        9.3834e-02, 2.3229e-03, 5.1407e-02, 1.2229e-04, 3.0912e-01, 7.7145e-02,
        1.4337e-02, 2.6942e-02, 5.4340e-03, 2.1789e-02, 1.0980e-01, 5.0994e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,813][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.1922, 0.0097, 0.0330, 0.0077, 0.0312, 0.0154, 0.0195, 0.0760, 0.0061,
        0.0210, 0.0074, 0.0099, 0.1162, 0.0327, 0.0688, 0.0678, 0.0992, 0.1861],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,813][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([1.4593e-02, 3.0187e-09, 1.8850e-07, 1.1860e-07, 8.0235e-07, 2.3856e-07,
        9.2978e-07, 5.3120e-05, 2.4413e-05, 2.4144e-05, 9.4549e-04, 3.3867e-03,
        2.1255e-02, 8.8223e-04, 3.6734e-03, 3.9392e-01, 1.5172e-01, 4.0951e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:18,814][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([8.8896e-01, 1.5585e-03, 1.2746e-03, 3.2400e-03, 8.4412e-04, 4.7081e-03,
        3.4135e-03, 2.9981e-03, 8.6213e-03, 4.7816e-03, 1.6366e-02, 2.2117e-02,
        1.7784e-03, 5.5068e-03, 1.9999e-03, 7.2232e-03, 5.1126e-03, 2.1779e-03,
        1.7323e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,814][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1602, 0.0109, 0.0285, 0.0176, 0.0295, 0.0298, 0.0287, 0.0486, 0.0404,
        0.0466, 0.0690, 0.0480, 0.0838, 0.0439, 0.0772, 0.0627, 0.0481, 0.0538,
        0.0726], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,815][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0198, 0.0693, 0.0440, 0.0664, 0.0391, 0.0460, 0.0754, 0.0434, 0.0532,
        0.0457, 0.0562, 0.0959, 0.0642, 0.0499, 0.0389, 0.0451, 0.0709, 0.0435,
        0.0332], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,815][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0038, 0.0951, 0.0577, 0.0542, 0.0425, 0.0696, 0.0531, 0.0622, 0.0472,
        0.0423, 0.0365, 0.0746, 0.1240, 0.0517, 0.0347, 0.0420, 0.0389, 0.0565,
        0.0135], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,815][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.8071, 0.0076, 0.0045, 0.0056, 0.0055, 0.0081, 0.0079, 0.0055, 0.0082,
        0.0037, 0.0030, 0.0076, 0.0106, 0.0114, 0.0274, 0.0270, 0.0167, 0.0183,
        0.0143], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,819][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0473, 0.0503, 0.0593, 0.0556, 0.0573, 0.0608, 0.0667, 0.0615, 0.0574,
        0.0467, 0.0482, 0.0574, 0.0490, 0.0530, 0.0444, 0.0445, 0.0450, 0.0494,
        0.0463], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,825][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0821, 0.0398, 0.0375, 0.0406, 0.0395, 0.0439, 0.0400, 0.0434, 0.0439,
        0.0427, 0.0616, 0.0650, 0.0648, 0.0539, 0.0573, 0.0617, 0.0549, 0.0625,
        0.0650], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,829][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2918, 0.0546, 0.0556, 0.0260, 0.0441, 0.0201, 0.0243, 0.0491, 0.0141,
        0.0418, 0.0223, 0.0273, 0.0718, 0.0334, 0.0601, 0.0308, 0.0311, 0.0676,
        0.0342], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,829][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.7249, 0.0144, 0.0223, 0.0081, 0.0135, 0.0084, 0.0206, 0.0259, 0.0094,
        0.0282, 0.0081, 0.0098, 0.0207, 0.0123, 0.0159, 0.0080, 0.0116, 0.0231,
        0.0147], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,830][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([2.0533e-03, 4.3260e-03, 1.4562e-04, 2.7237e-04, 2.8213e-04, 9.8988e-04,
        6.8312e-04, 5.6738e-05, 2.8086e-04, 4.8482e-05, 7.5708e-04, 2.5134e-03,
        1.9717e-03, 2.7935e-03, 7.6494e-04, 9.7943e-01, 2.3804e-03, 1.1409e-04,
        1.3445e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,830][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2139, 0.0073, 0.0272, 0.0058, 0.0247, 0.0114, 0.0164, 0.0648, 0.0051,
        0.0186, 0.0057, 0.0085, 0.1044, 0.0249, 0.0532, 0.0557, 0.0875, 0.1707,
        0.0941], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,831][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.3101e-02, 1.9064e-08, 6.9364e-07, 3.0868e-07, 8.4513e-07, 6.3543e-07,
        2.3519e-06, 4.8398e-05, 2.3469e-05, 2.8434e-05, 3.6685e-04, 3.0321e-03,
        7.8180e-03, 5.1237e-04, 1.0862e-03, 1.5916e-01, 8.3390e-02, 5.8131e-01,
        1.5012e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:18,860][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:18,860][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,861][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,861][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,861][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,862][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,862][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,862][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,863][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,863][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,863][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,864][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,864][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:18,864][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7630, 0.2370], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,865][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2810, 0.7190], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,865][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0640, 0.9360], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,865][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0372, 0.9628], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,866][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0712, 0.9288], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,866][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9227, 0.0773], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,866][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2182, 0.7818], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,868][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0086, 0.9914], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,871][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1184, 0.8816], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,876][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5428, 0.4572], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,880][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0793, 0.9207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,881][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4761, 0.5239], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:18,881][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.7314, 0.1556, 0.1130], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,881][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([8.4897e-04, 1.5444e-02, 9.8371e-01], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,881][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.2095, 0.0998, 0.6907], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,882][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.0941, 0.0354, 0.8705], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,882][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.0274, 0.4288, 0.5438], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,882][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.1469, 0.0302, 0.8229], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,883][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.1763, 0.0622, 0.7616], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,883][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.0055, 0.2773, 0.7173], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,883][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.3023, 0.1304, 0.5673], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,886][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.3519, 0.0716, 0.5765], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,891][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.0842, 0.6271, 0.2888], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,897][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.5688, 0.1145, 0.3167], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:18,897][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.5756, 0.1586, 0.0954, 0.1704], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,897][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0340, 0.0027, 0.7680, 0.1953], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,898][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0122, 0.0098, 0.5433, 0.4347], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,898][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0053, 0.0018, 0.5509, 0.4420], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,898][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0176, 0.2401, 0.4173, 0.3250], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,899][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2994, 0.0247, 0.5063, 0.1695], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,899][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0515, 0.0068, 0.5655, 0.3761], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,899][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0027, 0.0642, 0.2920, 0.6411], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,900][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0362, 0.0074, 0.2465, 0.7099], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,905][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1086, 0.0423, 0.4115, 0.4375], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,911][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0579, 0.4631, 0.1392, 0.3399], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,913][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2059, 0.0307, 0.2324, 0.5309], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:18,913][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.7106, 0.1133, 0.0304, 0.0948, 0.0509], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,914][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([4.9529e-05, 1.7561e-05, 6.9508e-04, 3.9731e-04, 9.9884e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,914][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.0843, 0.0036, 0.0843, 0.3158, 0.5120], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,914][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.0163, 0.0008, 0.0873, 0.0714, 0.8242], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,914][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0087, 0.1615, 0.2876, 0.2398, 0.3024], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,915][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.1110, 0.0133, 0.4177, 0.0771, 0.3809], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,915][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.1044, 0.0085, 0.2557, 0.2731, 0.3583], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,915][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0012, 0.0458, 0.1385, 0.4336, 0.3808], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,916][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.0889, 0.0027, 0.1186, 0.4662, 0.3235], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,917][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.1372, 0.0111, 0.1482, 0.1574, 0.5461], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,922][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0419, 0.3221, 0.1403, 0.2962, 0.1995], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,927][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.3212, 0.0171, 0.1386, 0.2308, 0.2922], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:18,929][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.5445, 0.1253, 0.0457, 0.1192, 0.0342, 0.1312], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,930][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([2.6080e-06, 3.5737e-06, 2.3583e-04, 5.2410e-04, 9.9905e-01, 1.7904e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,930][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([8.5508e-03, 6.6881e-04, 3.8432e-02, 8.0642e-02, 7.3286e-01, 1.3885e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,930][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([4.1132e-03, 9.6524e-05, 2.7063e-02, 6.4536e-02, 7.2262e-01, 1.8157e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,931][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0104, 0.1448, 0.2475, 0.1944, 0.2704, 0.1325], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,931][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1989, 0.0127, 0.2076, 0.0867, 0.2500, 0.2442], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,931][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0161, 0.0012, 0.0894, 0.1048, 0.5983, 0.1903], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,932][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0007, 0.0221, 0.1106, 0.2634, 0.4314, 0.1718], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,932][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0407, 0.0024, 0.0249, 0.4303, 0.2143, 0.2874], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,932][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.1034, 0.0256, 0.0363, 0.1567, 0.3613, 0.3165], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,934][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0348, 0.3010, 0.1060, 0.2857, 0.0954, 0.1772], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,940][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1694, 0.0098, 0.0488, 0.2026, 0.2369, 0.3325], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:18,944][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4730, 0.1007, 0.0512, 0.0989, 0.0445, 0.0762, 0.1555],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,948][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.7661e-05, 2.6633e-06, 1.0248e-04, 3.8656e-04, 9.8298e-01, 6.6715e-04,
        1.5846e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,948][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([2.3143e-02, 2.0047e-04, 2.1696e-02, 4.9735e-02, 2.2600e-01, 3.1525e-01,
        3.6397e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,949][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.3371e-02, 4.1542e-05, 9.4096e-03, 1.3166e-02, 2.6508e-01, 2.3952e-01,
        4.5940e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,949][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0075, 0.1146, 0.1890, 0.1473, 0.2337, 0.1120, 0.1960],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,949][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0986, 0.0118, 0.2143, 0.0569, 0.2816, 0.2063, 0.1305],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,950][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0780, 0.0007, 0.0582, 0.0575, 0.3919, 0.1772, 0.2365],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,950][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0008, 0.0191, 0.0940, 0.2099, 0.3275, 0.1649, 0.1836],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,950][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0692, 0.0006, 0.0128, 0.1196, 0.1242, 0.1657, 0.5079],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,950][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0962, 0.0032, 0.0407, 0.0784, 0.3058, 0.2325, 0.2432],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,954][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0300, 0.2380, 0.1304, 0.1962, 0.1093, 0.1924, 0.1035],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,960][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3200, 0.0038, 0.0380, 0.0748, 0.1847, 0.1651, 0.2136],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:18,964][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.4520, 0.0981, 0.0322, 0.0960, 0.0291, 0.0736, 0.1191, 0.1000],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,964][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([1.2444e-05, 5.2484e-05, 8.7375e-05, 2.3878e-03, 8.9233e-01, 4.3413e-04,
        8.8919e-02, 1.5781e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,964][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([9.4504e-02, 4.8387e-06, 1.1246e-03, 9.4932e-04, 1.1206e-02, 1.0479e-02,
        9.6154e-02, 7.8558e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,965][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([1.2379e-02, 5.7692e-08, 1.8499e-05, 4.5383e-05, 1.6645e-03, 4.5843e-04,
        7.0193e-03, 9.7842e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,965][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0049, 0.0856, 0.1305, 0.1180, 0.1942, 0.0885, 0.1601, 0.2183],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,965][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.1544, 0.0073, 0.0783, 0.0466, 0.1482, 0.1751, 0.1515, 0.2386],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,966][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([2.2548e-01, 4.4789e-05, 5.6081e-03, 3.8185e-03, 5.4931e-02, 9.7725e-03,
        3.0862e-02, 6.6948e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,966][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0008, 0.0126, 0.0493, 0.1533, 0.2241, 0.1249, 0.1371, 0.2979],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,966][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([1.2667e-01, 9.5517e-06, 4.5587e-04, 2.6097e-03, 5.1031e-03, 7.8254e-03,
        1.9982e-02, 8.3734e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,967][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([3.1672e-01, 3.5311e-04, 3.4361e-02, 1.0767e-02, 5.6038e-02, 2.4010e-02,
        7.5190e-02, 4.8256e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,967][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0341, 0.2690, 0.0714, 0.1636, 0.0766, 0.2202, 0.0512, 0.1139],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,968][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([2.9353e-01, 1.0302e-04, 2.2000e-03, 3.3136e-03, 8.3550e-03, 5.2084e-03,
        4.6942e-02, 6.4035e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:18,972][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.3889, 0.0945, 0.0447, 0.0939, 0.0320, 0.0726, 0.1119, 0.0587, 0.1027],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,975][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([1.3487e-03, 1.8688e-05, 2.0311e-04, 1.0410e-03, 8.6791e-01, 2.1702e-03,
        1.8610e-02, 8.0142e-02, 2.8561e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,979][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([3.2333e-03, 1.1712e-06, 1.6064e-04, 2.2398e-04, 1.6405e-03, 1.1794e-03,
        2.0186e-02, 9.2620e-01, 4.7175e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,981][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([1.4321e-05, 1.0528e-09, 5.5193e-07, 5.0047e-07, 3.1691e-05, 6.0684e-06,
        7.3449e-05, 9.9880e-01, 1.0706e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,981][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0045, 0.0790, 0.1386, 0.0993, 0.1590, 0.0674, 0.1209, 0.1662, 0.1652],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,982][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0565, 0.0035, 0.0657, 0.0448, 0.0973, 0.1363, 0.1435, 0.3138, 0.1387],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,982][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([1.2799e-02, 8.8666e-06, 9.3103e-04, 7.0047e-04, 5.9554e-03, 1.7370e-03,
        1.1786e-02, 8.9167e-01, 7.4413e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,982][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0003, 0.0097, 0.0420, 0.1266, 0.1784, 0.0999, 0.1314, 0.3184, 0.0932],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,983][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([1.8134e-02, 1.3834e-05, 1.1006e-03, 2.0756e-03, 5.1279e-03, 4.9924e-03,
        2.6154e-02, 7.0323e-01, 2.3917e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,983][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([5.3187e-02, 3.9463e-04, 7.1187e-03, 9.6311e-03, 2.1525e-02, 1.5848e-02,
        5.1103e-02, 6.0378e-01, 2.3742e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,983][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0179, 0.2123, 0.0805, 0.1820, 0.0677, 0.1351, 0.0667, 0.0577, 0.1802],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,983][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([2.3029e-02, 4.7357e-05, 1.0944e-03, 1.4218e-03, 1.0916e-02, 4.4384e-03,
        1.5714e-02, 8.8653e-01, 5.6811e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:18,984][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.5014, 0.0903, 0.0216, 0.0807, 0.0170, 0.0475, 0.0921, 0.0452, 0.0885,
        0.0156], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,985][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([5.3056e-05, 1.3012e-05, 8.7261e-07, 1.5451e-04, 3.4408e-03, 5.4160e-06,
        9.1315e-04, 2.8241e-04, 1.2166e-03, 9.9392e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,987][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([3.6564e-03, 1.8820e-07, 1.6087e-05, 5.1651e-05, 6.4989e-04, 7.0301e-04,
        9.4499e-03, 6.4864e-01, 2.3745e-01, 9.9383e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,991][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([1.0780e-03, 9.3523e-09, 2.8848e-06, 8.4876e-06, 1.8780e-04, 1.9571e-04,
        3.6483e-04, 7.8662e-01, 2.6667e-02, 1.8488e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,996][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0012, 0.0398, 0.0633, 0.0594, 0.0961, 0.0391, 0.0888, 0.1226, 0.1470,
        0.3427], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,998][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0402, 0.0027, 0.0286, 0.0356, 0.0457, 0.1016, 0.1188, 0.2059, 0.0956,
        0.3254], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,998][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([2.3875e-02, 5.6000e-06, 4.5925e-04, 5.6724e-04, 6.0783e-03, 2.8669e-03,
        6.6993e-03, 4.7439e-01, 1.2199e-01, 3.6306e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,998][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0004, 0.0078, 0.0286, 0.1180, 0.1756, 0.0867, 0.1186, 0.2899, 0.0860,
        0.0884], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,999][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([1.8795e-02, 1.5487e-06, 1.0736e-04, 5.0789e-04, 2.6240e-03, 1.6238e-03,
        4.1822e-03, 5.1837e-01, 2.7726e-01, 1.7652e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,999][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([3.2102e-02, 8.2058e-05, 6.9677e-04, 1.7294e-03, 1.1344e-02, 1.7824e-02,
        2.5078e-02, 5.9592e-01, 1.6364e-01, 1.5158e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:18,999][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0211, 0.1944, 0.0586, 0.1714, 0.0627, 0.1476, 0.0560, 0.0657, 0.1228,
        0.0996], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,000][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([2.5035e-02, 2.2394e-05, 4.3876e-04, 5.5786e-04, 3.7798e-03, 9.1557e-04,
        2.2307e-02, 7.3220e-01, 1.1145e-01, 1.0329e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,000][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.3786, 0.0910, 0.0284, 0.0857, 0.0204, 0.0583, 0.0900, 0.0451, 0.0937,
        0.0132, 0.0956], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,000][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([9.7761e-05, 1.6936e-07, 1.7807e-07, 2.3448e-06, 2.7982e-04, 5.2389e-07,
        3.7366e-06, 2.0956e-06, 1.3225e-05, 2.7477e-03, 9.9685e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,001][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([2.7288e-02, 9.3688e-07, 1.1331e-04, 7.3460e-05, 4.8841e-04, 1.4755e-03,
        6.7538e-03, 7.3092e-02, 6.9529e-02, 2.5246e-02, 7.9594e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,004][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([1.5421e-03, 5.5340e-09, 3.2395e-06, 1.4529e-06, 3.3005e-05, 2.7038e-05,
        5.6954e-05, 2.1402e-02, 5.4737e-03, 6.1636e-03, 9.6530e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,004][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0024, 0.0496, 0.0730, 0.0719, 0.0994, 0.0547, 0.0874, 0.1105, 0.1371,
        0.1976, 0.1165], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,004][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0340, 0.0030, 0.0755, 0.0273, 0.1013, 0.0849, 0.0717, 0.2211, 0.0863,
        0.2533, 0.0416], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,005][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([5.0884e-02, 5.8353e-06, 7.2265e-04, 2.4452e-04, 3.3202e-03, 1.5380e-03,
        3.1130e-03, 7.7423e-02, 3.0608e-02, 3.5603e-02, 7.9654e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,009][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0007, 0.0105, 0.0383, 0.1193, 0.1251, 0.0944, 0.1134, 0.2592, 0.0789,
        0.0711, 0.0890], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,012][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([2.3244e-02, 9.7782e-07, 6.7664e-05, 9.3492e-05, 1.4922e-04, 3.4810e-04,
        8.9554e-04, 4.9371e-02, 2.0512e-02, 5.8077e-03, 8.9951e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,015][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([2.0590e-01, 1.0532e-04, 3.6842e-03, 3.0030e-03, 1.0669e-02, 9.0410e-03,
        1.9875e-02, 7.5749e-02, 8.7583e-02, 1.4921e-01, 4.3519e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,016][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0200, 0.1908, 0.0672, 0.1639, 0.0562, 0.1145, 0.0557, 0.0541, 0.1229,
        0.0757, 0.0789], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,016][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.2342e-01, 6.7625e-05, 1.0890e-03, 1.1015e-03, 3.5460e-03, 2.4317e-03,
        7.2780e-03, 2.8214e-01, 8.9363e-02, 7.9648e-02, 4.0991e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,016][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.3297, 0.0740, 0.0338, 0.0749, 0.0266, 0.0544, 0.0907, 0.0505, 0.0793,
        0.0168, 0.0501, 0.1190], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,017][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.8211e-04, 3.5762e-08, 2.1520e-08, 1.6960e-07, 2.2715e-05, 4.1491e-08,
        1.6417e-07, 1.4213e-07, 4.2534e-07, 7.4487e-05, 7.8544e-02, 9.2118e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,017][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([7.7273e-03, 4.7384e-09, 1.0641e-06, 9.6697e-07, 5.9172e-06, 8.7504e-06,
        2.7833e-05, 3.1790e-04, 1.0338e-03, 1.2190e-04, 2.9740e-01, 6.9336e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,018][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([8.8686e-04, 1.9283e-10, 3.0330e-07, 5.9790e-08, 2.8903e-06, 1.0438e-06,
        1.9727e-06, 1.0851e-03, 6.3584e-05, 1.3528e-04, 5.0992e-01, 4.8790e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,018][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0022, 0.0430, 0.0697, 0.0608, 0.0911, 0.0461, 0.0776, 0.0980, 0.1143,
        0.1987, 0.1010, 0.0977], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,018][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0257, 0.0023, 0.0695, 0.0304, 0.0929, 0.0830, 0.0705, 0.2390, 0.0755,
        0.2257, 0.0472, 0.0383], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,019][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([7.1977e-02, 7.2801e-07, 1.5911e-04, 3.8045e-05, 3.2066e-04, 1.6761e-04,
        2.6220e-04, 4.8639e-03, 3.7273e-03, 3.8847e-03, 3.1575e-01, 5.9885e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,022][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0008, 0.0087, 0.0344, 0.1085, 0.1195, 0.0876, 0.1001, 0.2306, 0.0697,
        0.0576, 0.1037, 0.0788], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,026][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.3964e-02, 2.3815e-08, 2.1637e-06, 3.8771e-06, 8.3772e-06, 1.1441e-05,
        2.0404e-05, 5.6492e-04, 1.0053e-03, 1.7841e-04, 3.7309e-01, 6.1115e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,028][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([6.3679e-02, 1.6490e-05, 6.4225e-04, 3.5779e-04, 1.3752e-03, 7.6372e-04,
        1.5327e-03, 2.0399e-02, 9.5603e-03, 1.5468e-02, 3.7314e-01, 5.1307e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,032][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0212, 0.1602, 0.0686, 0.1216, 0.0668, 0.1276, 0.0543, 0.0786, 0.0837,
        0.0774, 0.0439, 0.0961], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,032][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.8398e-01, 8.8038e-06, 3.4160e-04, 1.5266e-04, 9.9137e-04, 5.3705e-04,
        1.7218e-03, 2.6951e-02, 1.2168e-02, 1.1484e-02, 2.0543e-01, 5.5623e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,033][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.4703, 0.0702, 0.0155, 0.0662, 0.0121, 0.0386, 0.0743, 0.0380, 0.0639,
        0.0068, 0.0392, 0.0959, 0.0091], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,033][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([8.0496e-06, 3.7896e-08, 2.5426e-09, 2.2438e-07, 3.1325e-06, 4.3061e-09,
        1.2591e-07, 1.7248e-08, 2.9134e-07, 1.4475e-05, 3.0990e-02, 5.6301e-01,
        4.0597e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,034][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([8.4236e-04, 5.1395e-11, 3.8022e-08, 1.7684e-08, 1.1214e-07, 2.0818e-07,
        6.8493e-07, 8.6631e-06, 4.2805e-05, 7.0324e-06, 2.3589e-02, 5.7007e-01,
        4.0544e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,034][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([3.6024e-04, 6.0848e-12, 1.0500e-08, 2.2549e-09, 3.8159e-08, 4.8821e-08,
        2.8967e-07, 1.8334e-05, 1.2043e-05, 1.6252e-06, 4.0675e-02, 2.2780e-01,
        7.3113e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,034][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0008, 0.0245, 0.0381, 0.0372, 0.0575, 0.0261, 0.0551, 0.0760, 0.0990,
        0.2046, 0.0888, 0.0825, 0.2097], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,035][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0269, 0.0020, 0.0300, 0.0379, 0.0334, 0.0696, 0.0894, 0.0839, 0.0687,
        0.2051, 0.0784, 0.0709, 0.2036], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,035][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([5.7352e-03, 2.7799e-08, 2.9706e-06, 1.7637e-06, 9.5843e-06, 1.0551e-05,
        1.4965e-05, 2.5947e-04, 3.8953e-04, 1.5991e-04, 4.2049e-02, 1.6063e-01,
        7.9073e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,038][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0008, 0.0062, 0.0199, 0.0951, 0.0876, 0.0851, 0.0937, 0.1609, 0.0601,
        0.0421, 0.1265, 0.1142, 0.1079], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,041][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([7.4061e-03, 1.4073e-09, 2.4929e-07, 3.5545e-07, 1.3909e-06, 1.5109e-06,
        4.5127e-06, 1.3667e-04, 2.4246e-04, 2.8535e-05, 1.9145e-01, 3.9817e-01,
        4.0256e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,044][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([3.0015e-02, 1.3919e-06, 3.1490e-05, 4.4305e-05, 2.6261e-04, 1.2051e-04,
        2.9168e-04, 5.6263e-03, 3.5894e-03, 2.6507e-03, 5.2065e-01, 2.8611e-01,
        1.5061e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,049][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0186, 0.1556, 0.0479, 0.1068, 0.0490, 0.1247, 0.0444, 0.0693, 0.0957,
        0.0798, 0.0560, 0.0709, 0.0810], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,049][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([5.3789e-02, 8.6181e-07, 1.4229e-05, 1.4591e-05, 5.4769e-05, 7.2200e-05,
        1.5074e-04, 3.7412e-03, 2.4694e-03, 1.2935e-03, 8.7674e-02, 2.9777e-01,
        5.5296e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,049][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.2986, 0.0736, 0.0291, 0.0723, 0.0241, 0.0532, 0.0857, 0.0421, 0.0716,
        0.0150, 0.0500, 0.1018, 0.0111, 0.0717], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,050][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([1.4181e-05, 1.0833e-08, 2.8563e-09, 1.6096e-08, 2.2253e-06, 4.0018e-09,
        6.5855e-09, 9.4937e-09, 2.1519e-08, 6.3128e-06, 5.2960e-03, 1.0642e-01,
        7.2539e-01, 1.6287e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,050][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([1.5327e-05, 1.2786e-10, 2.8315e-08, 2.8625e-08, 1.9718e-07, 2.5123e-07,
        1.5685e-06, 3.2029e-05, 2.3946e-05, 2.1949e-05, 7.8872e-03, 3.2448e-01,
        6.6508e-01, 2.4549e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,051][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.5764e-07, 2.1514e-13, 5.2112e-10, 2.3258e-10, 6.8254e-09, 5.5276e-09,
        6.1261e-08, 1.6192e-05, 1.6721e-06, 6.8507e-06, 2.3744e-03, 4.6797e-02,
        9.4749e-01, 3.3104e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,051][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0013, 0.0311, 0.0561, 0.0465, 0.0642, 0.0318, 0.0569, 0.0729, 0.0887,
        0.1541, 0.0796, 0.0732, 0.1583, 0.0855], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,051][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0190, 0.0010, 0.0302, 0.0197, 0.0427, 0.0668, 0.0634, 0.1582, 0.0522,
        0.2383, 0.0348, 0.0378, 0.2163, 0.0195], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,052][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([9.0023e-05, 5.7379e-09, 4.0784e-06, 1.3422e-06, 1.2088e-05, 3.4894e-06,
        1.0234e-05, 2.3181e-04, 1.2163e-04, 2.3830e-04, 1.4185e-02, 8.4409e-02,
        8.9364e-01, 7.0564e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,055][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0005, 0.0063, 0.0229, 0.0805, 0.0906, 0.0642, 0.0844, 0.1842, 0.0615,
        0.0534, 0.0905, 0.0829, 0.1355, 0.0427], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,057][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([5.8986e-05, 4.2759e-10, 4.6759e-08, 9.2931e-08, 4.2616e-07, 2.9402e-07,
        1.8465e-06, 8.3108e-05, 4.5611e-05, 2.1501e-05, 1.6923e-02, 1.3969e-01,
        8.3363e-01, 9.5451e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,061][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([4.2759e-03, 2.8113e-06, 1.3731e-04, 9.1159e-05, 6.1486e-04, 2.6809e-04,
        3.6569e-04, 5.2723e-03, 1.9410e-03, 3.9024e-03, 9.2534e-02, 2.5610e-01,
        5.7729e-01, 5.7205e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,065][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0193, 0.1606, 0.0503, 0.1251, 0.0435, 0.0834, 0.0458, 0.0430, 0.0848,
        0.0504, 0.0470, 0.0769, 0.0580, 0.1120], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,066][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([9.2671e-04, 1.6522e-07, 7.4623e-06, 7.0372e-06, 3.2831e-05, 1.6771e-05,
        5.2707e-05, 1.6182e-03, 4.6160e-04, 1.3479e-03, 1.7907e-02, 1.1285e-01,
        8.4839e-01, 1.6376e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,066][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.5202, 0.0626, 0.0125, 0.0490, 0.0221, 0.0348, 0.0604, 0.0237, 0.0555,
        0.0058, 0.0257, 0.0694, 0.0032, 0.0472, 0.0077], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,066][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([2.7513e-05, 6.1226e-09, 1.5735e-10, 1.2678e-09, 1.5085e-07, 2.5742e-10,
        1.6460e-09, 3.7960e-09, 5.8602e-09, 1.0356e-06, 1.9170e-03, 1.6355e-02,
        5.1992e-02, 1.6509e-02, 9.1320e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,067][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([4.4803e-03, 5.8357e-10, 1.2148e-07, 1.0753e-07, 4.1656e-07, 5.6847e-07,
        2.0591e-06, 1.2250e-05, 4.1643e-05, 1.9338e-05, 1.3318e-02, 3.5895e-01,
        5.1631e-01, 7.5712e-03, 9.9294e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,067][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([1.5769e-04, 6.4320e-12, 7.1108e-09, 7.2420e-10, 2.6058e-08, 6.7646e-09,
        6.1718e-08, 8.7261e-06, 1.6581e-06, 8.2063e-07, 3.1761e-03, 3.6525e-02,
        6.4291e-01, 6.9593e-03, 3.1026e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,068][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0010, 0.0217, 0.0380, 0.0356, 0.0399, 0.0251, 0.0516, 0.0613, 0.0927,
        0.1510, 0.0834, 0.0759, 0.1690, 0.0823, 0.0717], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,068][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.0429, 0.0025, 0.0482, 0.0188, 0.0360, 0.0109, 0.0129, 0.0291, 0.0108,
        0.0259, 0.0260, 0.0157, 0.1367, 0.0276, 0.5560], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,069][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([7.6978e-03, 4.1279e-08, 8.8990e-06, 1.8288e-06, 7.6302e-06, 3.3121e-06,
        7.8016e-06, 2.8127e-04, 1.7034e-04, 1.8743e-04, 2.5736e-02, 6.0697e-02,
        7.3306e-01, 2.0818e-02, 1.5132e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,073][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0007, 0.0060, 0.0163, 0.0749, 0.0461, 0.0522, 0.0692, 0.1644, 0.0365,
        0.0335, 0.0871, 0.0919, 0.1156, 0.0431, 0.1626], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,076][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([1.9808e-03, 7.8782e-10, 2.1187e-07, 1.6075e-07, 4.0634e-07, 4.7150e-07,
        1.0449e-06, 3.6830e-05, 3.7413e-05, 1.8100e-05, 1.8262e-02, 9.1470e-02,
        7.9465e-01, 1.0508e-02, 8.3039e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,080][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([4.8166e-02, 2.6467e-06, 1.1865e-04, 6.0476e-05, 2.5976e-04, 5.0766e-05,
        2.7829e-04, 2.4293e-03, 1.3123e-03, 8.3431e-04, 9.9049e-03, 2.2605e-01,
        1.4879e-01, 6.4394e-02, 4.9734e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,082][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0144, 0.1062, 0.0442, 0.0948, 0.0607, 0.1175, 0.0519, 0.0554, 0.0890,
        0.0643, 0.0371, 0.0837, 0.0627, 0.0657, 0.0525], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,082][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([3.5124e-02, 4.0702e-07, 1.3872e-05, 1.1093e-05, 3.1434e-05, 2.4214e-05,
        7.9168e-05, 4.9031e-04, 3.8839e-04, 5.7125e-04, 1.7006e-02, 1.3711e-01,
        6.8932e-01, 2.8480e-02, 9.1351e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,083][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.4202, 0.0712, 0.0182, 0.0674, 0.0167, 0.0415, 0.0728, 0.0312, 0.0654,
        0.0086, 0.0357, 0.0751, 0.0047, 0.0535, 0.0061, 0.0118],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,083][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([6.6307e-05, 5.0586e-08, 1.3914e-09, 7.1927e-08, 2.1740e-07, 2.3174e-10,
        2.1108e-08, 2.3379e-09, 2.5811e-08, 1.0340e-07, 5.9727e-04, 6.5418e-03,
        1.3069e-02, 1.7999e-03, 2.1827e-02, 9.5610e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,083][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.1224e-03, 2.7969e-11, 2.8526e-08, 3.5863e-09, 4.9326e-08, 2.0868e-08,
        1.4587e-07, 1.3809e-06, 2.8486e-06, 2.8938e-07, 4.6944e-04, 1.3188e-02,
        7.0172e-03, 2.0934e-04, 1.0545e-02, 9.6744e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,084][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.5996e-04, 2.6794e-13, 7.2650e-10, 1.1629e-10, 2.0742e-09, 6.4287e-10,
        3.6276e-09, 4.4368e-07, 1.3930e-07, 4.6171e-08, 1.0580e-04, 1.1541e-03,
        1.2312e-02, 1.5161e-04, 8.2011e-03, 9.7792e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,084][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0010, 0.0231, 0.0416, 0.0364, 0.0481, 0.0260, 0.0491, 0.0595, 0.0832,
        0.1303, 0.0730, 0.0650, 0.1382, 0.0736, 0.0844, 0.0677],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,085][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0171, 0.0014, 0.0234, 0.0222, 0.0253, 0.0427, 0.0518, 0.0966, 0.0402,
        0.1537, 0.0350, 0.0278, 0.2238, 0.0310, 0.1389, 0.0692],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,086][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([7.5059e-03, 4.1862e-09, 2.0537e-06, 2.8955e-07, 5.6037e-06, 1.2569e-06,
        5.0497e-06, 2.4508e-05, 3.3896e-05, 1.1497e-05, 2.4108e-03, 1.0932e-02,
        9.0757e-02, 3.0251e-03, 6.2110e-02, 8.2317e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,090][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0003, 0.0042, 0.0187, 0.0734, 0.0725, 0.0444, 0.0677, 0.1171, 0.0397,
        0.0291, 0.0678, 0.0599, 0.0814, 0.0337, 0.2194, 0.0706],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,093][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([4.6837e-03, 4.9228e-10, 3.4671e-08, 4.5155e-08, 7.6414e-08, 1.4125e-07,
        3.6370e-07, 2.9642e-06, 7.1806e-06, 1.5758e-06, 9.5724e-04, 1.1892e-02,
        3.6553e-02, 1.4131e-03, 7.6324e-03, 9.3686e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,096][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([7.9084e-02, 2.7433e-06, 2.8669e-05, 3.0155e-05, 9.3123e-05, 1.0160e-04,
        1.1018e-04, 3.9026e-04, 5.9391e-04, 2.9531e-04, 3.2641e-02, 4.2643e-02,
        3.1785e-02, 1.9837e-02, 7.1172e-02, 7.2119e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,099][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0120, 0.1225, 0.0356, 0.1026, 0.0367, 0.1025, 0.0466, 0.0576, 0.0880,
        0.0670, 0.0496, 0.0640, 0.0588, 0.0816, 0.0335, 0.0415],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,099][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.1739e-01, 4.1662e-07, 9.0717e-06, 9.3827e-06, 1.3759e-05, 1.4721e-05,
        4.3252e-05, 4.2399e-04, 4.8995e-04, 7.1964e-05, 7.2528e-03, 2.1146e-02,
        6.3697e-02, 1.0568e-02, 2.1290e-02, 7.5758e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,099][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3433, 0.0599, 0.0242, 0.0584, 0.0213, 0.0400, 0.0945, 0.0347, 0.0635,
        0.0107, 0.0397, 0.0844, 0.0068, 0.0540, 0.0087, 0.0081, 0.0477],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,100][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.4590e-06, 3.8830e-11, 7.9998e-13, 4.7250e-11, 6.2462e-10, 9.2121e-13,
        1.3762e-11, 2.7946e-12, 3.4698e-11, 1.3029e-09, 8.1222e-06, 1.8152e-04,
        4.1573e-04, 1.0914e-04, 1.8659e-03, 7.9730e-01, 2.0011e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,100][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([9.1792e-04, 4.2478e-12, 4.0217e-09, 8.9279e-10, 1.1395e-08, 8.1539e-09,
        6.4312e-09, 2.5093e-07, 1.0896e-06, 1.5387e-07, 2.3069e-04, 4.6073e-03,
        5.2420e-03, 8.7575e-05, 3.0691e-03, 6.8859e-01, 2.9726e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,101][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([2.9241e-05, 1.7705e-14, 3.4027e-11, 3.8547e-12, 1.8239e-10, 1.2492e-10,
        1.4987e-10, 4.3801e-07, 1.0028e-08, 8.7175e-09, 2.7557e-05, 9.9907e-05,
        2.3654e-03, 1.9464e-05, 1.5014e-03, 6.9924e-01, 2.9671e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,101][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0013, 0.0252, 0.0419, 0.0362, 0.0517, 0.0281, 0.0471, 0.0587, 0.0734,
        0.1062, 0.0650, 0.0581, 0.1135, 0.0685, 0.0849, 0.0663, 0.0739],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,101][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0086, 0.0012, 0.0281, 0.0169, 0.0303, 0.0357, 0.0350, 0.1226, 0.0363,
        0.1189, 0.0229, 0.0249, 0.2140, 0.0190, 0.1810, 0.0664, 0.0382],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,103][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([8.7973e-03, 1.5569e-09, 6.7138e-07, 1.0248e-07, 1.3128e-06, 4.0855e-07,
        4.0278e-07, 2.2175e-05, 1.9891e-05, 1.3443e-05, 7.1175e-04, 2.3416e-03,
        4.5125e-02, 1.2192e-03, 2.0762e-02, 5.0459e-01, 4.1640e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,107][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0005, 0.0042, 0.0182, 0.0620, 0.0669, 0.0482, 0.0516, 0.1050, 0.0374,
        0.0279, 0.0599, 0.0509, 0.0828, 0.0290, 0.1912, 0.0822, 0.0822],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,111][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.8584e-03, 3.5952e-11, 6.3749e-09, 6.2962e-09, 1.8276e-08, 1.2458e-08,
        2.2352e-08, 1.4784e-06, 2.2637e-06, 2.5239e-07, 4.3163e-04, 9.6698e-04,
        1.0982e-02, 3.3985e-04, 3.1772e-03, 5.8325e-01, 3.9899e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,114][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.0792e-03, 1.0255e-07, 4.2873e-06, 2.5293e-06, 1.8635e-05, 5.9821e-06,
        8.6647e-06, 1.6973e-04, 7.7242e-05, 9.1871e-05, 4.0114e-03, 5.4818e-03,
        1.5630e-02, 2.0236e-03, 1.7048e-02, 7.9347e-01, 1.5287e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,115][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0148, 0.1141, 0.0579, 0.0922, 0.0479, 0.0878, 0.0459, 0.0647, 0.0623,
        0.0563, 0.0363, 0.0669, 0.0567, 0.0750, 0.0457, 0.0356, 0.0399],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,116][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([4.6786e-02, 6.6915e-08, 3.4738e-06, 1.3947e-06, 7.0562e-06, 3.5891e-06,
        3.7838e-06, 2.5390e-04, 1.3581e-04, 8.1352e-05, 2.0984e-03, 1.5364e-02,
        5.4201e-02, 4.6957e-03, 1.5369e-02, 6.0354e-01, 2.5746e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,116][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.4994, 0.0602, 0.0141, 0.0505, 0.0097, 0.0280, 0.0538, 0.0266, 0.0589,
        0.0046, 0.0285, 0.0764, 0.0034, 0.0473, 0.0031, 0.0035, 0.0213, 0.0108],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,116][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([6.9857e-07, 7.9081e-11, 3.9809e-13, 8.6444e-11, 1.1628e-10, 7.2557e-13,
        1.7361e-11, 1.3826e-11, 3.0409e-11, 1.5311e-09, 1.3224e-05, 2.4994e-04,
        4.6618e-04, 1.5031e-04, 1.0271e-03, 7.0519e-01, 2.5766e-01, 3.5239e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,117][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([3.4947e-04, 3.0396e-14, 4.4053e-11, 1.3243e-11, 1.7359e-10, 1.3156e-10,
        1.4864e-09, 5.3642e-08, 8.9496e-08, 1.0932e-08, 3.8821e-05, 8.1193e-04,
        1.3581e-03, 7.4853e-06, 2.0343e-04, 3.2181e-01, 3.4527e-01, 3.3015e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,117][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([1.9774e-05, 9.1199e-16, 6.3367e-13, 1.0233e-13, 1.3286e-11, 3.5952e-12,
        2.3858e-11, 1.0905e-08, 1.9124e-09, 3.4184e-09, 5.9463e-06, 7.9766e-05,
        8.8185e-04, 5.3997e-06, 6.7575e-04, 4.6948e-01, 2.8901e-01, 2.3984e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,118][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0006, 0.0160, 0.0261, 0.0243, 0.0365, 0.0174, 0.0349, 0.0482, 0.0612,
        0.1271, 0.0554, 0.0520, 0.1350, 0.0592, 0.0669, 0.0507, 0.0650, 0.1235],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,118][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0186, 0.0014, 0.0118, 0.0186, 0.0090, 0.0213, 0.0338, 0.0441, 0.0233,
        0.0977, 0.0394, 0.0391, 0.2688, 0.0601, 0.0545, 0.0551, 0.0630, 0.1404],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,119][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([3.6184e-03, 1.3999e-10, 3.9073e-08, 6.7602e-09, 1.2910e-07, 2.6730e-08,
        1.1147e-07, 1.6855e-06, 1.7381e-06, 1.3784e-06, 2.3432e-04, 1.0480e-03,
        7.4847e-03, 2.7657e-04, 4.2524e-03, 1.4359e-01, 1.9625e-01, 6.4324e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,124][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0005, 0.0033, 0.0111, 0.0515, 0.0477, 0.0411, 0.0484, 0.0815, 0.0317,
        0.0199, 0.0662, 0.0640, 0.0825, 0.0311, 0.1647, 0.0815, 0.1001, 0.0729],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,127][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([9.2031e-04, 3.3851e-12, 4.0012e-10, 3.5515e-10, 4.2321e-09, 1.6403e-09,
        5.5686e-09, 3.3644e-07, 1.9695e-07, 8.2237e-08, 1.4562e-04, 6.8179e-04,
        2.9454e-03, 6.5511e-05, 1.8167e-03, 5.6417e-01, 3.1401e-01, 1.1524e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,130][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([1.2481e-02, 2.1072e-08, 2.6632e-06, 7.0259e-07, 6.0971e-06, 2.2402e-06,
        4.0036e-06, 6.0804e-05, 3.5701e-05, 2.2943e-05, 1.2546e-03, 4.9312e-03,
        1.6517e-02, 1.4194e-03, 1.0712e-02, 3.9237e-01, 1.5226e-01, 4.0792e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,132][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0113, 0.1388, 0.0315, 0.1105, 0.0424, 0.1132, 0.0321, 0.0388, 0.0836,
        0.0530, 0.0440, 0.0548, 0.0541, 0.0675, 0.0355, 0.0348, 0.0262, 0.0280],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,132][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([1.4593e-02, 3.0187e-09, 1.8850e-07, 1.1860e-07, 8.0235e-07, 2.3856e-07,
        9.2978e-07, 5.3120e-05, 2.4413e-05, 2.4144e-05, 9.4549e-04, 3.3867e-03,
        2.1255e-02, 8.8223e-04, 3.6734e-03, 3.9392e-01, 1.5172e-01, 4.0951e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,132][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3121, 0.0625, 0.0274, 0.0597, 0.0181, 0.0425, 0.0689, 0.0311, 0.0644,
        0.0102, 0.0433, 0.0839, 0.0076, 0.0589, 0.0079, 0.0099, 0.0351, 0.0108,
        0.0458], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,133][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.5360e-05, 1.4058e-11, 5.3014e-13, 1.8626e-11, 1.4481e-10, 5.4297e-13,
        1.4064e-12, 8.2214e-13, 4.1934e-12, 8.8738e-11, 3.3597e-07, 4.7299e-06,
        2.9062e-05, 2.3314e-06, 6.3742e-05, 9.0621e-02, 3.5538e-03, 5.4031e-03,
        9.0031e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,133][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([4.7788e-04, 1.2035e-12, 6.2409e-10, 1.5075e-10, 2.0444e-09, 2.1051e-09,
        1.1013e-08, 9.2389e-08, 1.9868e-07, 1.4523e-08, 1.2442e-05, 9.8265e-04,
        4.0306e-04, 7.8189e-06, 3.0252e-04, 1.5780e-01, 2.2362e-01, 5.1215e-01,
        1.0424e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,134][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.3189e-05, 3.0406e-15, 2.4781e-12, 4.6601e-13, 8.2671e-12, 2.3350e-11,
        1.1710e-10, 1.9499e-08, 1.8651e-09, 1.5519e-09, 6.0589e-07, 1.5117e-05,
        8.7239e-05, 8.6481e-07, 3.3131e-05, 3.0160e-02, 6.6135e-02, 7.4253e-01,
        1.6102e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,134][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0009, 0.0213, 0.0352, 0.0304, 0.0409, 0.0225, 0.0378, 0.0490, 0.0599,
        0.0953, 0.0551, 0.0485, 0.0996, 0.0569, 0.0673, 0.0553, 0.0607, 0.0936,
        0.0698], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,135][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0054, 0.0010, 0.0355, 0.0102, 0.0311, 0.0168, 0.0181, 0.0719, 0.0240,
        0.0470, 0.0117, 0.0149, 0.1299, 0.0102, 0.2393, 0.0395, 0.0245, 0.2584,
        0.0105], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,137][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.0523e-03, 2.4930e-10, 1.0054e-07, 1.1817e-08, 2.7742e-07, 6.7761e-08,
        1.7372e-07, 2.1654e-06, 1.2647e-06, 1.0491e-06, 7.6468e-05, 6.3740e-04,
        4.3283e-03, 9.6170e-05, 2.7292e-03, 3.0660e-02, 1.1453e-01, 4.5620e-01,
        3.8868e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,142][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0004, 0.0037, 0.0152, 0.0541, 0.0515, 0.0415, 0.0531, 0.0948, 0.0331,
        0.0224, 0.0516, 0.0456, 0.0629, 0.0237, 0.1332, 0.0706, 0.0786, 0.0839,
        0.0802], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,146][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.4467e-03, 2.2114e-11, 3.2643e-09, 1.5401e-09, 4.9436e-09, 7.1542e-09,
        1.1296e-08, 2.8118e-07, 2.9618e-07, 2.8553e-08, 2.6851e-05, 3.6545e-04,
        1.3761e-03, 4.7506e-05, 2.8558e-04, 7.0955e-02, 9.7393e-02, 1.3348e-01,
        6.9462e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,148][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.3067e-03, 1.2426e-07, 3.4109e-06, 1.7535e-06, 1.1198e-05, 5.4849e-06,
        8.2067e-06, 7.0731e-05, 3.1762e-05, 2.0719e-05, 2.2798e-04, 2.8453e-03,
        2.3483e-03, 9.6994e-04, 7.3911e-03, 3.7931e-01, 9.7618e-02, 4.6375e-01,
        3.8078e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,148][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0116, 0.1318, 0.0431, 0.0955, 0.0369, 0.0988, 0.0305, 0.0385, 0.0745,
        0.0433, 0.0503, 0.0515, 0.0597, 0.0752, 0.0327, 0.0359, 0.0250, 0.0306,
        0.0346], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,148][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.3101e-02, 1.9064e-08, 6.9364e-07, 3.0868e-07, 8.4513e-07, 6.3543e-07,
        2.3519e-06, 4.8398e-05, 2.3469e-05, 2.8434e-05, 3.6685e-04, 3.0321e-03,
        7.8180e-03, 5.1237e-04, 1.0862e-03, 1.5916e-01, 8.3390e-02, 5.8131e-01,
        1.5012e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,149][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:19,151][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12308],
        [17503],
        [  808],
        [11556],
        [ 8188],
        [14560],
        [17397],
        [10716],
        [17366],
        [15658],
        [27107],
        [16354],
        [14926],
        [12491],
        [13079],
        [ 8184],
        [18913],
        [ 7389],
        [18848]], device='cuda:0')
[2024-07-24 10:27:19,152][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12222],
        [21531],
        [  524],
        [13544],
        [ 3622],
        [12941],
        [21013],
        [ 8444],
        [23395],
        [22736],
        [37406],
        [22545],
        [18419],
        [12061],
        [ 5840],
        [ 6386],
        [21127],
        [14072],
        [18779]], device='cuda:0')
[2024-07-24 10:27:19,155][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[45272],
        [45276],
        [45288],
        [45297],
        [45287],
        [45331],
        [45329],
        [45289],
        [45292],
        [45284],
        [45361],
        [45449],
        [45304],
        [45373],
        [45305],
        [45356],
        [45450],
        [45349],
        [45797]], device='cuda:0')
[2024-07-24 10:27:19,157][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[32159],
        [36919],
        [38654],
        [38032],
        [38258],
        [38263],
        [38995],
        [39237],
        [39690],
        [39298],
        [39928],
        [40285],
        [40435],
        [40448],
        [40587],
        [40692],
        [40952],
        [41088],
        [41073]], device='cuda:0')
[2024-07-24 10:27:19,160][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[18257],
        [11303],
        [10366],
        [ 9405],
        [ 9127],
        [ 9289],
        [ 8776],
        [ 8942],
        [ 9564],
        [ 9941],
        [10635],
        [ 9850],
        [ 9606],
        [ 9630],
        [ 9581],
        [ 9599],
        [ 9733],
        [ 9352],
        [ 9644]], device='cuda:0')
[2024-07-24 10:27:19,163][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[28706],
        [26541],
        [27386],
        [29385],
        [30157],
        [30437],
        [28693],
        [27581],
        [29437],
        [28393],
        [28941],
        [29790],
        [29148],
        [30450],
        [29837],
        [30478],
        [30785],
        [29961],
        [30282]], device='cuda:0')
[2024-07-24 10:27:19,165][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[43981],
        [43999],
        [43989],
        [43996],
        [44006],
        [43998],
        [44000],
        [44037],
        [44034],
        [44025],
        [44036],
        [43872],
        [43457],
        [43799],
        [42141],
        [42457],
        [40764],
        [40669],
        [40027]], device='cuda:0')
[2024-07-24 10:27:19,168][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[14250],
        [10451],
        [ 6702],
        [ 6475],
        [ 5040],
        [ 5099],
        [ 5047],
        [ 4928],
        [ 4841],
        [ 4477],
        [ 4123],
        [ 4284],
        [ 4109],
        [ 4068],
        [ 3892],
        [ 3842],
        [ 3906],
        [ 3941],
        [ 3994]], device='cuda:0')
[2024-07-24 10:27:19,169][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[17020],
        [12077],
        [11564],
        [ 9733],
        [ 9917],
        [ 9141],
        [ 8679],
        [ 8601],
        [ 8138],
        [ 8149],
        [ 8164],
        [ 8005],
        [ 8093],
        [ 7916],
        [ 8122],
        [ 7980],
        [ 7887],
        [ 7893],
        [ 7856]], device='cuda:0')
[2024-07-24 10:27:19,170][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[16140],
        [18611],
        [19216],
        [19284],
        [20400],
        [21355],
        [21559],
        [22462],
        [22502],
        [22027],
        [22919],
        [22549],
        [23278],
        [23948],
        [23854],
        [24247],
        [24306],
        [24976],
        [25532]], device='cuda:0')
[2024-07-24 10:27:19,171][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21129],
        [21898],
        [21546],
        [21475],
        [21843],
        [21488],
        [21662],
        [24070],
        [23895],
        [24981],
        [22866],
        [23736],
        [25717],
        [24574],
        [26872],
        [26410],
        [25499],
        [28081],
        [25941]], device='cuda:0')
[2024-07-24 10:27:19,172][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 5992],
        [ 9085],
        [37266],
        [21958],
        [37882],
        [24230],
        [10375],
        [34002],
        [30216],
        [39479],
        [32281],
        [29111],
        [25409],
        [26253],
        [33900],
        [33003],
        [28332],
        [27196],
        [28514]], device='cuda:0')
[2024-07-24 10:27:19,175][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 1596],
        [ 1658],
        [ 3374],
        [ 3185],
        [ 5420],
        [ 6894],
        [ 7010],
        [ 9945],
        [ 8279],
        [ 9757],
        [ 6167],
        [ 4221],
        [15150],
        [15103],
        [14219],
        [15829],
        [16210],
        [19629],
        [19026]], device='cuda:0')
[2024-07-24 10:27:19,177][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31639],
        [34580],
        [39425],
        [34474],
        [38076],
        [33414],
        [27775],
        [14809],
        [13505],
        [16764],
        [27070],
        [19188],
        [30479],
        [36134],
        [36645],
        [30251],
        [24417],
        [24886],
        [26857]], device='cuda:0')
[2024-07-24 10:27:19,180][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21751],
        [ 8470],
        [17689],
        [ 6165],
        [20956],
        [12308],
        [15166],
        [16073],
        [11667],
        [ 5296],
        [15143],
        [12417],
        [ 5795],
        [17159],
        [20571],
        [ 4562],
        [13729],
        [ 8230],
        [12081]], device='cuda:0')
[2024-07-24 10:27:19,183][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15752],
        [16325],
        [16594],
        [17610],
        [16685],
        [17122],
        [17173],
        [16722],
        [17205],
        [16989],
        [17203],
        [16852],
        [16824],
        [17308],
        [17029],
        [17185],
        [17091],
        [17050],
        [17199]], device='cuda:0')
[2024-07-24 10:27:19,185][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12111],
        [ 8492],
        [45168],
        [44544],
        [45951],
        [45947],
        [45859],
        [44945],
        [44603],
        [16379],
        [38440],
        [14303],
        [15162],
        [23030],
        [46058],
        [28160],
        [26921],
        [26067],
        [27873]], device='cuda:0')
[2024-07-24 10:27:19,188][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[3617],
        [ 628],
        [ 521],
        [1123],
        [1756],
        [1301],
        [ 507],
        [2399],
        [2953],
        [3377],
        [1137],
        [1048],
        [3180],
        [4451],
        [3725],
        [1390],
        [ 720],
        [1851],
        [3574]], device='cuda:0')
[2024-07-24 10:27:19,189][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[17022],
        [  174],
        [ 1026],
        [ 1187],
        [ 5426],
        [ 3473],
        [ 1720],
        [ 4748],
        [ 4869],
        [ 2562],
        [ 8954],
        [ 8490],
        [ 1537],
        [ 1831],
        [ 6162],
        [ 3145],
        [ 1987],
        [ 2953],
        [ 2465]], device='cuda:0')
[2024-07-24 10:27:19,190][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[20719],
        [13275],
        [16831],
        [17612],
        [18173],
        [17139],
        [15945],
        [14895],
        [13722],
        [10401],
        [11215],
        [11019],
        [ 9985],
        [10435],
        [10115],
        [10295],
        [10234],
        [ 9666],
        [ 9698]], device='cuda:0')
[2024-07-24 10:27:19,191][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12393],
        [15014],
        [ 8657],
        [13343],
        [10380],
        [17798],
        [18505],
        [21747],
        [22718],
        [19011],
        [19223],
        [19512],
        [16890],
        [16150],
        [14379],
        [15921],
        [16358],
        [14946],
        [18283]], device='cuda:0')
[2024-07-24 10:27:19,192][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14323],
        [12199],
        [16145],
        [11083],
        [ 7991],
        [ 7349],
        [ 8112],
        [18888],
        [17694],
        [24431],
        [ 1971],
        [ 4779],
        [26349],
        [28441],
        [24689],
        [30347],
        [24670],
        [30561],
        [20158]], device='cuda:0')
[2024-07-24 10:27:19,195][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[10720],
        [ 8885],
        [ 7308],
        [ 8280],
        [ 7795],
        [ 8265],
        [ 9361],
        [10773],
        [11402],
        [11394],
        [12170],
        [12793],
        [13601],
        [13469],
        [13385],
        [12505],
        [12797],
        [13136],
        [13187]], device='cuda:0')
[2024-07-24 10:27:19,198][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[20215],
        [ 8708],
        [11785],
        [16964],
        [ 9440],
        [14128],
        [28663],
        [32171],
        [35370],
        [32548],
        [28647],
        [16150],
        [17381],
        [14770],
        [13476],
        [25553],
        [17088],
        [16427],
        [12798]], device='cuda:0')
[2024-07-24 10:27:19,200][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 758],
        [ 146],
        [3695],
        [ 446],
        [7488],
        [3175],
        [1647],
        [1270],
        [ 702],
        [ 524],
        [3018],
        [3734],
        [4555],
        [1493],
        [6229],
        [1218],
        [1002],
        [1836],
        [1656]], device='cuda:0')
[2024-07-24 10:27:19,203][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[18309],
        [18479],
        [19222],
        [18722],
        [18822],
        [19151],
        [19462],
        [19970],
        [18665],
        [19953],
        [19674],
        [19752],
        [20261],
        [20804],
        [20334],
        [20834],
        [20674],
        [20628],
        [21040]], device='cuda:0')
[2024-07-24 10:27:19,205][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[1062],
        [1302],
        [1376],
        [ 804],
        [2339],
        [2784],
        [3638],
        [2273],
        [3704],
        [4072],
        [3336],
        [5584],
        [3350],
        [1354],
        [1610],
        [2827],
        [7771],
        [7349],
        [3496]], device='cuda:0')
[2024-07-24 10:27:19,208][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[41587],
        [47742],
        [44282],
        [44283],
        [38992],
        [40331],
        [42379],
        [38413],
        [37034],
        [40593],
        [39546],
        [41675],
        [41095],
        [41842],
        [36826],
        [40062],
        [42266],
        [40845],
        [41667]], device='cuda:0')
[2024-07-24 10:27:19,209][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[22403],
        [33929],
        [30052],
        [31611],
        [32663],
        [23400],
        [18223],
        [ 7568],
        [ 9048],
        [12545],
        [ 4816],
        [14085],
        [21396],
        [11874],
        [18087],
        [27926],
        [18215],
        [ 8047],
        [ 9887]], device='cuda:0')
[2024-07-24 10:27:19,210][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435],
        [8435]], device='cuda:0')
[2024-07-24 10:27:19,239][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:19,239][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,239][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,241][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,241][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,241][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,242][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,242][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,242][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,242][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,243][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,243][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,243][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,244][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2832, 0.7168], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,244][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0471, 0.9529], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,244][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2123, 0.7877], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,245][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4743, 0.5257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,245][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2211, 0.7789], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,245][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.7733, 0.2267], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,246][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.5629, 0.4371], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,246][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3560, 0.6440], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,246][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8628, 0.1372], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,247][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3128, 0.6872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,247][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1036, 0.8964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,247][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9974e-01, 2.5700e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,248][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.1315, 0.5358, 0.3327], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,250][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([0.0236, 0.2793, 0.6971], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,261][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.1235, 0.4681, 0.4083], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,262][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.4226, 0.0579, 0.5194], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,262][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.1130, 0.4624, 0.4246], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,262][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([0.6023, 0.0571, 0.3406], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,263][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.3080, 0.2298, 0.4622], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,263][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.2135, 0.4229, 0.3636], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,263][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.5890, 0.1712, 0.2398], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,264][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.1287, 0.2440, 0.6273], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,264][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.0465, 0.5128, 0.4407], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,264][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.9933, 0.0010, 0.0057], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,266][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1066, 0.3082, 0.4055, 0.1797], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,271][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0176, 0.1809, 0.4829, 0.3186], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,276][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0757, 0.3982, 0.2575, 0.2686], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,278][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1516, 0.0144, 0.4245, 0.4096], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,278][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0828, 0.3165, 0.2901, 0.3107], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,278][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4957, 0.0317, 0.2832, 0.1895], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,279][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1849, 0.1213, 0.3882, 0.3057], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,279][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1421, 0.3045, 0.2618, 0.2916], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,279][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6087, 0.1113, 0.1520, 0.1280], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,279][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0951, 0.1345, 0.3316, 0.4388], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,280][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0342, 0.3565, 0.3087, 0.3006], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,280][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([9.9531e-01, 4.0123e-04, 3.2933e-03, 9.9964e-04], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,283][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0294, 0.3169, 0.1950, 0.2627, 0.1960], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,288][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0198, 0.1357, 0.3070, 0.2284, 0.3090], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,293][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0184, 0.2329, 0.2534, 0.1702, 0.3251], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,294][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.2662, 0.0079, 0.1714, 0.1964, 0.3581], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,294][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0583, 0.2414, 0.2216, 0.2368, 0.2418], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,294][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.4871, 0.0109, 0.1120, 0.1025, 0.2875], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,295][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.1627, 0.1017, 0.2030, 0.2187, 0.3139], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,295][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.1129, 0.2432, 0.2134, 0.2357, 0.1948], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,295][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.4498, 0.0936, 0.1773, 0.1094, 0.1699], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,296][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0611, 0.0948, 0.1977, 0.2546, 0.3917], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,296][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0239, 0.2760, 0.2347, 0.2323, 0.2330], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,296][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.9738, 0.0017, 0.0089, 0.0038, 0.0117], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,297][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0256, 0.1804, 0.2059, 0.1745, 0.2875, 0.1260], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,302][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0165, 0.0973, 0.2375, 0.1908, 0.2634, 0.1946], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,308][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0539, 0.2658, 0.2340, 0.2105, 0.1260, 0.1099], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,310][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0641, 0.0042, 0.1173, 0.1090, 0.4473, 0.2581], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,310][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0489, 0.1946, 0.1795, 0.1911, 0.1944, 0.1915], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,310][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.3376, 0.0065, 0.0859, 0.0966, 0.2222, 0.2512], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,311][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0858, 0.0601, 0.1716, 0.1528, 0.3400, 0.1898], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,311][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0904, 0.2026, 0.1810, 0.1995, 0.1649, 0.1617], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,311][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3598, 0.0799, 0.1531, 0.0935, 0.1478, 0.1660], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,312][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0491, 0.0729, 0.1395, 0.1945, 0.3045, 0.2394], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,312][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0195, 0.2230, 0.1900, 0.1907, 0.1920, 0.1847], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,312][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.9590, 0.0016, 0.0110, 0.0039, 0.0163, 0.0082], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,312][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0500, 0.1655, 0.1815, 0.1106, 0.2897, 0.1436, 0.0592],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,316][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0168, 0.0747, 0.1865, 0.1438, 0.1996, 0.1629, 0.2157],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,320][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0516, 0.1716, 0.1945, 0.1325, 0.1642, 0.1691, 0.1166],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,326][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0911, 0.0028, 0.1006, 0.0950, 0.2893, 0.1679, 0.2533],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,326][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0418, 0.1631, 0.1509, 0.1608, 0.1631, 0.1613, 0.1590],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,327][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.4316, 0.0034, 0.0791, 0.0361, 0.2320, 0.0850, 0.1328],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,327][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0820, 0.0525, 0.1432, 0.1189, 0.2875, 0.1631, 0.1527],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,327][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0768, 0.1725, 0.1529, 0.1678, 0.1394, 0.1366, 0.1541],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,328][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.3588, 0.0768, 0.1082, 0.0881, 0.1044, 0.1695, 0.0941],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,328][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0438, 0.0593, 0.1032, 0.1405, 0.2235, 0.1725, 0.2572],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,328][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0158, 0.1927, 0.1631, 0.1622, 0.1624, 0.1565, 0.1473],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,329][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.7535e-01, 7.0683e-04, 5.2046e-03, 1.6818e-03, 7.8817e-03, 4.1696e-03,
        5.0021e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,329][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0593, 0.1595, 0.1555, 0.1341, 0.2101, 0.1755, 0.0632, 0.0427],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,332][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0344, 0.0748, 0.1474, 0.1234, 0.1570, 0.1225, 0.1762, 0.1642],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,337][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.1005, 0.1874, 0.1363, 0.1245, 0.0919, 0.0976, 0.0956, 0.1663],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,340][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([1.0371e-01, 3.1578e-04, 1.3480e-02, 8.5982e-03, 3.4545e-02, 1.8388e-02,
        2.4512e-02, 7.9645e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,343][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0372, 0.1395, 0.1282, 0.1365, 0.1384, 0.1371, 0.1352, 0.1479],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,343][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([2.9663e-01, 2.1466e-04, 6.0572e-03, 3.1891e-03, 2.1553e-02, 1.0116e-02,
        4.3652e-02, 6.1859e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,343][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0958, 0.0577, 0.1106, 0.1119, 0.1844, 0.1308, 0.1266, 0.1823],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,344][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0760, 0.1495, 0.1304, 0.1430, 0.1191, 0.1167, 0.1310, 0.1343],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,344][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.3990, 0.0625, 0.0873, 0.0695, 0.0857, 0.1359, 0.0784, 0.0817],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,344][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0417, 0.0551, 0.0855, 0.1108, 0.1691, 0.1479, 0.2123, 0.1777],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,345][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0135, 0.1672, 0.1470, 0.1416, 0.1422, 0.1358, 0.1273, 0.1255],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,345][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.9570, 0.0011, 0.0059, 0.0023, 0.0093, 0.0052, 0.0070, 0.0123],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,345][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0451, 0.1143, 0.1793, 0.0813, 0.2855, 0.1214, 0.0630, 0.0419, 0.0682],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,346][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0131, 0.0432, 0.1220, 0.0839, 0.1404, 0.1176, 0.1662, 0.1799, 0.1339],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,349][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0359, 0.1817, 0.1193, 0.1481, 0.0312, 0.1249, 0.1155, 0.1580, 0.0855],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,351][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ of] are: tensor([1.1693e-02, 1.1024e-04, 4.8296e-03, 4.2437e-03, 1.8265e-02, 1.0823e-02,
        2.3762e-02, 8.7540e-01, 5.0872e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,357][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0320, 0.1218, 0.1125, 0.1197, 0.1213, 0.1202, 0.1187, 0.1292, 0.1247],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,359][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ of] are: tensor([3.7239e-02, 2.0385e-04, 2.8897e-03, 2.6825e-03, 5.9951e-03, 5.7790e-03,
        2.1617e-02, 8.6840e-01, 5.5192e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,359][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0596, 0.0317, 0.0848, 0.0771, 0.1970, 0.1227, 0.1134, 0.2042, 0.1095],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,360][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0649, 0.1345, 0.1156, 0.1284, 0.1058, 0.1034, 0.1178, 0.1209, 0.1086],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,360][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.4265, 0.0582, 0.0832, 0.0656, 0.0649, 0.1221, 0.0696, 0.0699, 0.0400],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,361][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0265, 0.0413, 0.0729, 0.0914, 0.1593, 0.1350, 0.1977, 0.1651, 0.1106],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,361][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0108, 0.1526, 0.1327, 0.1278, 0.1273, 0.1236, 0.1139, 0.1122, 0.0991],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,361][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ of] are: tensor([9.4917e-01, 8.8753e-04, 5.6525e-03, 1.9989e-03, 9.3669e-03, 4.9388e-03,
        6.5004e-03, 1.4910e-02, 6.5788e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,362][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0476, 0.1314, 0.1478, 0.1197, 0.1798, 0.1299, 0.0663, 0.0397, 0.1162,
        0.0215], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,362][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0278, 0.0604, 0.0996, 0.0909, 0.1090, 0.0956, 0.1292, 0.1313, 0.1320,
        0.1242], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,363][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0450, 0.1415, 0.1226, 0.1059, 0.0792, 0.1504, 0.1276, 0.1080, 0.0915,
        0.0283], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,365][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([4.7033e-02, 1.7608e-04, 7.5674e-03, 3.8056e-03, 3.1518e-02, 9.2796e-03,
        1.5520e-02, 5.5757e-01, 4.7610e-02, 2.7992e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,370][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0259, 0.1074, 0.0988, 0.1053, 0.1075, 0.1067, 0.1054, 0.1149, 0.1119,
        0.1162], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,374][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([3.9458e-02, 9.0068e-05, 1.1403e-03, 1.5556e-03, 6.3711e-03, 5.3489e-03,
        1.3274e-02, 5.7089e-01, 1.1100e-01, 2.5087e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,376][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0729, 0.0365, 0.0683, 0.0737, 0.1429, 0.0893, 0.0881, 0.1486, 0.1022,
        0.1774], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,376][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0556, 0.1229, 0.1060, 0.1182, 0.0963, 0.0939, 0.1071, 0.1108, 0.0983,
        0.0909], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,376][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.3729, 0.0579, 0.0740, 0.0607, 0.0710, 0.1176, 0.0709, 0.0798, 0.0436,
        0.0517], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,377][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0311, 0.0480, 0.0688, 0.0897, 0.1361, 0.1137, 0.1569, 0.1366, 0.1026,
        0.1165], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,377][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0094, 0.1384, 0.1194, 0.1156, 0.1140, 0.1094, 0.1011, 0.1001, 0.0886,
        0.1041], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,377][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([9.4388e-01, 8.7980e-04, 4.9754e-03, 2.0518e-03, 8.4321e-03, 4.9517e-03,
        6.4282e-03, 1.2772e-02, 6.2453e-03, 9.3854e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,378][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0494, 0.1176, 0.1035, 0.0825, 0.1621, 0.1028, 0.0865, 0.0517, 0.0981,
        0.0598, 0.0859], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,378][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0204, 0.0438, 0.1034, 0.0711, 0.0947, 0.0887, 0.1094, 0.1129, 0.0994,
        0.0768, 0.1793], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,379][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0223, 0.1234, 0.1242, 0.1653, 0.0832, 0.1388, 0.0693, 0.0867, 0.1141,
        0.0135, 0.0591], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,379][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ at] are: tensor([3.6905e-02, 1.4992e-04, 6.6192e-03, 2.6697e-03, 1.0225e-02, 9.6255e-03,
        2.1209e-02, 2.9098e-01, 4.2666e-02, 1.0637e-01, 4.7259e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,382][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0252, 0.0965, 0.0891, 0.0951, 0.0967, 0.0954, 0.0942, 0.1028, 0.0990,
        0.1041, 0.1019], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,386][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ at] are: tensor([1.8350e-01, 2.8282e-04, 3.0845e-03, 2.1996e-03, 3.0085e-03, 8.7807e-03,
        1.4317e-02, 3.6001e-01, 7.4538e-02, 7.1690e-02, 2.7859e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,391][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0624, 0.0290, 0.0686, 0.0632, 0.1350, 0.0815, 0.0782, 0.1401, 0.0757,
        0.1505, 0.1158], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,392][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0517, 0.1122, 0.0959, 0.1069, 0.0876, 0.0858, 0.0979, 0.1004, 0.0903,
        0.0827, 0.0887], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,393][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.3116, 0.0602, 0.0718, 0.0678, 0.0565, 0.1203, 0.0738, 0.0727, 0.0480,
        0.0624, 0.0550], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,393][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0258, 0.0284, 0.0542, 0.0700, 0.1225, 0.0916, 0.1364, 0.1372, 0.0973,
        0.1034, 0.1332], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,393][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0084, 0.1243, 0.1064, 0.1034, 0.1014, 0.0985, 0.0912, 0.0928, 0.0827,
        0.0969, 0.0940], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,394][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ at] are: tensor([9.4648e-01, 7.7508e-04, 4.5690e-03, 1.7053e-03, 7.8492e-03, 4.6061e-03,
        5.7088e-03, 1.2072e-02, 5.4195e-03, 7.7815e-03, 3.0352e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,394][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0416, 0.1011, 0.1198, 0.0644, 0.1916, 0.0917, 0.0361, 0.0438, 0.0924,
        0.0524, 0.1136, 0.0515], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,395][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0183, 0.0369, 0.0864, 0.0584, 0.0802, 0.0708, 0.0858, 0.0857, 0.0808,
        0.0627, 0.1747, 0.1593], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,395][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0532, 0.1124, 0.1180, 0.0984, 0.0635, 0.1130, 0.0947, 0.1355, 0.0590,
        0.0178, 0.0454, 0.0890], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,395][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ the] are: tensor([6.6693e-02, 7.3634e-05, 3.2305e-03, 1.1799e-03, 5.1028e-03, 3.6069e-03,
        4.4610e-03, 6.3678e-02, 1.3729e-02, 2.4729e-02, 3.5736e-01, 4.5616e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,398][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0235, 0.0880, 0.0811, 0.0864, 0.0875, 0.0863, 0.0852, 0.0930, 0.0896,
        0.0939, 0.0922, 0.0932], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,401][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ the] are: tensor([1.8332e-01, 9.3254e-05, 1.2478e-03, 7.1497e-04, 1.5124e-03, 1.7754e-03,
        3.4810e-03, 4.4266e-02, 1.3723e-02, 1.3461e-02, 2.6597e-01, 4.7044e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,407][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0548, 0.0281, 0.0649, 0.0548, 0.1228, 0.0702, 0.0638, 0.1156, 0.0628,
        0.1221, 0.1128, 0.1273], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,409][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0525, 0.1023, 0.0873, 0.0964, 0.0799, 0.0781, 0.0885, 0.0906, 0.0819,
        0.0757, 0.0803, 0.0865], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,409][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2601, 0.0557, 0.0661, 0.0656, 0.0605, 0.1175, 0.0622, 0.0728, 0.0465,
        0.0687, 0.0532, 0.0712], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,410][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0258, 0.0264, 0.0485, 0.0628, 0.1003, 0.0851, 0.1200, 0.1158, 0.0871,
        0.0861, 0.1256, 0.1166], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,410][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0074, 0.1134, 0.0956, 0.0946, 0.0911, 0.0908, 0.0827, 0.0850, 0.0764,
        0.0874, 0.0859, 0.0897], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,410][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ the] are: tensor([9.7769e-01, 2.9900e-04, 2.1267e-03, 6.3496e-04, 3.5443e-03, 1.9561e-03,
        2.3030e-03, 4.4891e-03, 1.9390e-03, 2.8633e-03, 1.0376e-03, 1.1158e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,411][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0263, 0.1014, 0.1113, 0.0914, 0.1015, 0.0737, 0.0575, 0.0322, 0.0923,
        0.0224, 0.1391, 0.0649, 0.0861], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,411][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0286, 0.0357, 0.0789, 0.0530, 0.0743, 0.0675, 0.0731, 0.0735, 0.0690,
        0.0555, 0.1398, 0.1305, 0.1205], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,411][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0265, 0.1068, 0.0936, 0.0881, 0.1865, 0.1399, 0.0568, 0.0824, 0.0489,
        0.0092, 0.0536, 0.0953, 0.0124], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,412][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ store] are: tensor([2.5630e-02, 5.0193e-06, 5.7275e-04, 9.3997e-05, 6.5612e-04, 5.5041e-04,
        8.3449e-04, 3.2699e-03, 1.7167e-03, 2.7540e-03, 8.7566e-02, 2.8997e-01,
        5.8638e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,415][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0199, 0.0800, 0.0738, 0.0784, 0.0803, 0.0789, 0.0779, 0.0852, 0.0823,
        0.0861, 0.0839, 0.0848, 0.0886], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,418][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ store] are: tensor([6.7672e-02, 6.1726e-06, 1.8495e-04, 9.8762e-05, 2.3043e-04, 4.1191e-04,
        6.2404e-04, 7.1335e-03, 3.8686e-03, 1.1588e-03, 6.3292e-02, 2.6362e-01,
        5.9170e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,423][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0620, 0.0293, 0.0492, 0.0538, 0.0848, 0.0608, 0.0596, 0.0959, 0.0606,
        0.0888, 0.0963, 0.1074, 0.1514], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,425][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0502, 0.0938, 0.0806, 0.0883, 0.0736, 0.0715, 0.0808, 0.0836, 0.0751,
        0.0696, 0.0735, 0.0785, 0.0808], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,426][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.2989, 0.0446, 0.0655, 0.0516, 0.0611, 0.1056, 0.0562, 0.0575, 0.0343,
        0.0510, 0.0475, 0.0583, 0.0679], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,426][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0216, 0.0235, 0.0382, 0.0502, 0.0776, 0.0608, 0.0919, 0.0963, 0.0727,
        0.0753, 0.1028, 0.1008, 0.1882], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,427][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0072, 0.1033, 0.0883, 0.0863, 0.0856, 0.0846, 0.0748, 0.0741, 0.0679,
        0.0784, 0.0759, 0.0804, 0.0933], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,427][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ store] are: tensor([9.6571e-01, 3.9845e-04, 2.9793e-03, 8.7661e-04, 5.0760e-03, 2.5220e-03,
        3.4996e-03, 5.8413e-03, 2.4931e-03, 4.0717e-03, 1.3800e-03, 1.9260e-03,
        3.2244e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,427][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.0281, 0.0584, 0.1365, 0.0434, 0.1706, 0.0599, 0.0567, 0.0344, 0.0609,
        0.0450, 0.0698, 0.0659, 0.1326, 0.0377], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,428][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0108, 0.0262, 0.0543, 0.0400, 0.0622, 0.0500, 0.0580, 0.0543, 0.0566,
        0.0518, 0.1616, 0.1520, 0.1468, 0.0756], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,428][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0210, 0.1064, 0.0759, 0.0805, 0.0355, 0.1477, 0.1052, 0.1521, 0.0328,
        0.0102, 0.0535, 0.0460, 0.0058, 0.1273], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,428][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [.] are: tensor([3.0590e-03, 7.1047e-06, 3.9998e-04, 1.3517e-04, 9.6860e-04, 5.3105e-04,
        1.3313e-03, 1.1505e-02, 3.1359e-03, 6.4995e-03, 5.3152e-02, 1.8304e-01,
        6.8469e-01, 5.1542e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,429][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0170, 0.0747, 0.0683, 0.0736, 0.0738, 0.0730, 0.0723, 0.0792, 0.0765,
        0.0796, 0.0786, 0.0798, 0.0817, 0.0719], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,430][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [.] are: tensor([1.2863e-02, 8.3688e-06, 1.7359e-04, 1.4316e-04, 2.7548e-04, 4.1132e-04,
        8.4786e-04, 9.7458e-03, 4.2025e-03, 3.4489e-03, 4.7470e-02, 2.2476e-01,
        6.1688e-01, 7.8772e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,436][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0338, 0.0162, 0.0404, 0.0331, 0.0806, 0.0484, 0.0448, 0.0870, 0.0390,
        0.0953, 0.0938, 0.1148, 0.1902, 0.0828], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,441][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0407, 0.0891, 0.0756, 0.0838, 0.0685, 0.0666, 0.0769, 0.0797, 0.0706,
        0.0645, 0.0685, 0.0746, 0.0765, 0.0644], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,442][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.3024, 0.0416, 0.0643, 0.0530, 0.0515, 0.0920, 0.0524, 0.0488, 0.0321,
        0.0424, 0.0375, 0.0605, 0.0719, 0.0498], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,443][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0133, 0.0183, 0.0350, 0.0420, 0.0728, 0.0551, 0.0806, 0.0790, 0.0563,
        0.0641, 0.0952, 0.1031, 0.1889, 0.0963], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,443][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0061, 0.0973, 0.0819, 0.0794, 0.0786, 0.0783, 0.0706, 0.0681, 0.0619,
        0.0740, 0.0712, 0.0766, 0.0868, 0.0693], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,443][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [.] are: tensor([9.5787e-01, 4.0459e-04, 3.2283e-03, 9.1304e-04, 5.3514e-03, 2.6479e-03,
        3.5322e-03, 7.7380e-03, 3.2534e-03, 5.5833e-03, 1.5768e-03, 1.9040e-03,
        3.8850e-03, 2.1086e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,444][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0127, 0.1285, 0.0804, 0.1095, 0.0710, 0.0698, 0.0583, 0.0275, 0.0913,
        0.0210, 0.1001, 0.0590, 0.0676, 0.0451, 0.0582], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,444][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0186, 0.0264, 0.0548, 0.0383, 0.0601, 0.0458, 0.0513, 0.0520, 0.0470,
        0.0413, 0.1249, 0.1189, 0.1200, 0.0676, 0.1329], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,445][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0088, 0.0887, 0.0846, 0.0683, 0.1092, 0.0602, 0.0416, 0.0670, 0.0464,
        0.0285, 0.0498, 0.0644, 0.0286, 0.1023, 0.1516], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,445][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([3.0477e-02, 9.2132e-06, 5.6756e-04, 1.3043e-04, 8.1777e-04, 2.3597e-04,
        5.6053e-04, 3.7149e-03, 1.2171e-03, 1.6705e-03, 5.8566e-02, 1.2632e-01,
        3.4678e-01, 4.1087e-02, 3.8785e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,445][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0146, 0.0708, 0.0640, 0.0686, 0.0708, 0.0686, 0.0678, 0.0740, 0.0716,
        0.0740, 0.0734, 0.0748, 0.0769, 0.0660, 0.0641], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,447][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([9.1074e-02, 1.0850e-05, 2.2580e-04, 1.1652e-04, 3.4560e-04, 2.1080e-04,
        6.6215e-04, 3.5515e-03, 1.9825e-03, 1.6023e-03, 7.7473e-02, 2.0854e-01,
        3.7151e-01, 8.4597e-02, 1.5809e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,452][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0579, 0.0228, 0.0355, 0.0360, 0.0467, 0.0380, 0.0354, 0.0715, 0.0349,
        0.0768, 0.0688, 0.0824, 0.1570, 0.0608, 0.1754], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,457][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0353, 0.0831, 0.0731, 0.0806, 0.0663, 0.0636, 0.0733, 0.0754, 0.0667,
        0.0613, 0.0653, 0.0710, 0.0719, 0.0602, 0.0529], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,461][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.2100, 0.0357, 0.0620, 0.0428, 0.0569, 0.1207, 0.0577, 0.0470, 0.0348,
        0.0455, 0.0448, 0.0564, 0.0765, 0.0501, 0.0591], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,461][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0158, 0.0198, 0.0321, 0.0388, 0.0586, 0.0459, 0.0664, 0.0733, 0.0542,
        0.0589, 0.0836, 0.0865, 0.1415, 0.0774, 0.1474], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,461][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0058, 0.0920, 0.0757, 0.0737, 0.0721, 0.0714, 0.0638, 0.0644, 0.0588,
        0.0703, 0.0661, 0.0711, 0.0786, 0.0633, 0.0727], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,462][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.8906, 0.0013, 0.0068, 0.0026, 0.0094, 0.0056, 0.0077, 0.0135, 0.0064,
        0.0106, 0.0045, 0.0058, 0.0107, 0.0064, 0.0182], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,462][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0073, 0.0828, 0.1022, 0.0727, 0.1178, 0.0592, 0.0566, 0.0212, 0.0693,
        0.0215, 0.0805, 0.0560, 0.0759, 0.0423, 0.1014, 0.0334],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,463][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0308, 0.0271, 0.0583, 0.0392, 0.0525, 0.0452, 0.0568, 0.0575, 0.0514,
        0.0372, 0.0970, 0.0864, 0.0926, 0.0431, 0.0814, 0.1436],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,463][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0210, 0.1277, 0.0658, 0.0667, 0.0598, 0.0361, 0.0508, 0.0365, 0.0747,
        0.0315, 0.0329, 0.1079, 0.0095, 0.1892, 0.0717, 0.0181],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,465][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.7831e-02, 6.0975e-06, 5.9270e-04, 7.2991e-05, 5.8527e-04, 2.7645e-04,
        3.4757e-04, 3.6579e-03, 7.9555e-04, 6.0796e-04, 2.3137e-02, 2.9453e-02,
        1.1797e-01, 2.0130e-02, 1.4035e-01, 6.4419e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,470][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0146, 0.0659, 0.0603, 0.0641, 0.0664, 0.0642, 0.0634, 0.0695, 0.0670,
        0.0703, 0.0687, 0.0702, 0.0725, 0.0618, 0.0591, 0.0621],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,473][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([4.7078e-02, 4.9413e-06, 1.8906e-04, 6.8968e-05, 1.5145e-04, 3.2765e-04,
        5.7508e-04, 3.7539e-03, 1.1982e-03, 3.7798e-04, 1.0055e-02, 5.1781e-02,
        1.0920e-01, 2.9958e-02, 5.4597e-02, 6.9069e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,477][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0516, 0.0193, 0.0389, 0.0341, 0.0564, 0.0381, 0.0366, 0.0575, 0.0338,
        0.0486, 0.0599, 0.0628, 0.1013, 0.0460, 0.1499, 0.1651],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,477][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0316, 0.0788, 0.0693, 0.0771, 0.0626, 0.0609, 0.0704, 0.0724, 0.0637,
        0.0581, 0.0619, 0.0677, 0.0685, 0.0573, 0.0495, 0.0502],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,477][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.1924, 0.0344, 0.0549, 0.0396, 0.0558, 0.0802, 0.0508, 0.0591, 0.0349,
        0.0487, 0.0450, 0.0535, 0.0751, 0.0401, 0.0650, 0.0705],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,478][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0184, 0.0151, 0.0233, 0.0329, 0.0455, 0.0393, 0.0582, 0.0643, 0.0555,
        0.0550, 0.0734, 0.0725, 0.1337, 0.0772, 0.1338, 0.1019],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,478][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0053, 0.0836, 0.0688, 0.0689, 0.0674, 0.0676, 0.0606, 0.0599, 0.0536,
        0.0631, 0.0632, 0.0681, 0.0728, 0.0598, 0.0692, 0.0683],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,479][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([9.2554e-01, 7.8017e-04, 5.0668e-03, 1.6890e-03, 7.6453e-03, 3.9630e-03,
        5.1807e-03, 9.2878e-03, 4.3910e-03, 6.2826e-03, 2.7352e-03, 3.2784e-03,
        4.9232e-03, 3.0463e-03, 1.0973e-02, 5.2188e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,479][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0181, 0.0664, 0.0866, 0.0424, 0.1248, 0.0479, 0.0259, 0.0252, 0.0526,
        0.0293, 0.0647, 0.0413, 0.1202, 0.0439, 0.1250, 0.0512, 0.0345],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,479][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0227, 0.0187, 0.0421, 0.0282, 0.0403, 0.0360, 0.0410, 0.0477, 0.0410,
        0.0343, 0.0948, 0.0786, 0.0859, 0.0402, 0.0796, 0.1412, 0.1279],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,483][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0333, 0.0812, 0.0690, 0.0606, 0.0610, 0.0754, 0.0494, 0.0774, 0.0428,
        0.0126, 0.0267, 0.0632, 0.0065, 0.1841, 0.0672, 0.0386, 0.0509],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,485][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([5.8641e-03, 1.7085e-06, 1.6036e-04, 2.8474e-05, 2.2460e-04, 1.0612e-04,
        1.5707e-04, 2.8212e-03, 5.6760e-04, 7.8872e-04, 1.4276e-02, 1.9928e-02,
        7.8989e-02, 1.1768e-02, 1.0085e-01, 4.3499e-01, 3.2848e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,491][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0129, 0.0625, 0.0571, 0.0611, 0.0626, 0.0608, 0.0602, 0.0664, 0.0635,
        0.0669, 0.0656, 0.0670, 0.0694, 0.0592, 0.0553, 0.0583, 0.0512],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,493][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([4.5661e-02, 2.8787e-06, 1.0023e-04, 2.1399e-05, 1.3309e-04, 1.0466e-04,
        9.2348e-05, 3.1822e-03, 9.0627e-04, 3.9918e-04, 6.6255e-03, 3.4322e-02,
        8.3027e-02, 2.4709e-02, 5.7536e-02, 5.2825e-01, 2.1493e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,494][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0403, 0.0130, 0.0280, 0.0238, 0.0474, 0.0272, 0.0256, 0.0482, 0.0230,
        0.0424, 0.0468, 0.0509, 0.1011, 0.0388, 0.1495, 0.1793, 0.1146],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,494][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0304, 0.0750, 0.0657, 0.0722, 0.0594, 0.0579, 0.0665, 0.0685, 0.0596,
        0.0547, 0.0580, 0.0636, 0.0652, 0.0544, 0.0469, 0.0477, 0.0543],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,494][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1785, 0.0394, 0.0510, 0.0443, 0.0485, 0.0815, 0.0433, 0.0587, 0.0331,
        0.0504, 0.0390, 0.0513, 0.0690, 0.0427, 0.0556, 0.0666, 0.0470],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,495][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0177, 0.0153, 0.0208, 0.0282, 0.0414, 0.0328, 0.0491, 0.0598, 0.0473,
        0.0494, 0.0631, 0.0665, 0.1180, 0.0638, 0.1237, 0.0912, 0.1118],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,495][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0048, 0.0802, 0.0656, 0.0650, 0.0638, 0.0635, 0.0576, 0.0575, 0.0507,
        0.0594, 0.0587, 0.0631, 0.0680, 0.0555, 0.0652, 0.0642, 0.0571],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,496][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.4539e-01, 4.9819e-04, 3.6911e-03, 1.1239e-03, 6.0080e-03, 2.8918e-03,
        3.6304e-03, 7.4558e-03, 3.3579e-03, 4.6381e-03, 1.7535e-03, 1.8830e-03,
        2.7032e-03, 1.6908e-03, 7.1558e-03, 3.4625e-03, 2.6636e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,496][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0083, 0.0842, 0.0932, 0.0687, 0.0997, 0.0418, 0.0383, 0.0167, 0.0731,
        0.0175, 0.0891, 0.0489, 0.0784, 0.0389, 0.0865, 0.0305, 0.0465, 0.0396],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,498][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0334, 0.0225, 0.0392, 0.0293, 0.0373, 0.0345, 0.0394, 0.0413, 0.0347,
        0.0305, 0.0794, 0.0747, 0.0693, 0.0416, 0.0678, 0.1174, 0.1164, 0.0912],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,503][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0258, 0.0677, 0.1094, 0.0661, 0.0631, 0.0969, 0.0524, 0.0454, 0.0329,
        0.0315, 0.0460, 0.0456, 0.0097, 0.0989, 0.0766, 0.0523, 0.0613, 0.0184],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,506][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([3.8441e-03, 3.7503e-07, 3.8573e-05, 5.7540e-06, 5.1545e-05, 1.7703e-05,
        4.8334e-05, 5.5311e-04, 1.4053e-04, 1.3522e-04, 5.0174e-03, 1.3986e-02,
        3.8681e-02, 4.8532e-03, 5.0557e-02, 2.8456e-01, 2.2344e-01, 3.7407e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,510][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0135, 0.0584, 0.0534, 0.0570, 0.0586, 0.0572, 0.0566, 0.0621, 0.0599,
        0.0623, 0.0609, 0.0618, 0.0644, 0.0550, 0.0532, 0.0561, 0.0494, 0.0602],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,510][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([7.5661e-03, 1.2543e-07, 6.4165e-06, 1.6653e-06, 9.2547e-06, 7.4755e-06,
        2.3841e-05, 2.8804e-04, 8.7265e-05, 6.9125e-05, 1.3487e-03, 1.0309e-02,
        2.4116e-02, 4.3067e-03, 1.2914e-02, 2.4626e-01, 1.5997e-01, 5.3271e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,511][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0458, 0.0141, 0.0243, 0.0224, 0.0396, 0.0253, 0.0230, 0.0411, 0.0208,
        0.0354, 0.0435, 0.0446, 0.0771, 0.0346, 0.1278, 0.1430, 0.0983, 0.1395],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,511][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0363, 0.0712, 0.0604, 0.0667, 0.0549, 0.0537, 0.0608, 0.0624, 0.0561,
        0.0517, 0.0550, 0.0588, 0.0599, 0.0513, 0.0441, 0.0448, 0.0506, 0.0614],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,511][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.2150, 0.0331, 0.0436, 0.0389, 0.0489, 0.0721, 0.0425, 0.0458, 0.0278,
        0.0384, 0.0336, 0.0506, 0.0586, 0.0403, 0.0560, 0.0605, 0.0479, 0.0466],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,512][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0164, 0.0171, 0.0202, 0.0282, 0.0401, 0.0309, 0.0457, 0.0510, 0.0417,
        0.0471, 0.0564, 0.0597, 0.0990, 0.0593, 0.1080, 0.0792, 0.0994, 0.1007],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,512][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0043, 0.0768, 0.0611, 0.0626, 0.0600, 0.0607, 0.0541, 0.0536, 0.0469,
        0.0560, 0.0555, 0.0602, 0.0640, 0.0522, 0.0600, 0.0614, 0.0537, 0.0571],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,514][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([9.2749e-01, 5.1361e-04, 3.8425e-03, 1.1946e-03, 6.4670e-03, 3.2515e-03,
        4.3359e-03, 7.8103e-03, 3.6170e-03, 5.4564e-03, 2.0760e-03, 2.4273e-03,
        4.0081e-03, 2.3607e-03, 9.8750e-03, 4.6713e-03, 3.8847e-03, 6.7228e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,519][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0143, 0.0430, 0.0968, 0.0329, 0.1470, 0.0392, 0.0389, 0.0238, 0.0334,
        0.0295, 0.0340, 0.0442, 0.0960, 0.0241, 0.1326, 0.0429, 0.0449, 0.0584,
        0.0239], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,524][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0215, 0.0141, 0.0345, 0.0218, 0.0312, 0.0302, 0.0349, 0.0425, 0.0305,
        0.0269, 0.0745, 0.0586, 0.0729, 0.0240, 0.0538, 0.1202, 0.1011, 0.0930,
        0.1139], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,526][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0270, 0.0905, 0.0581, 0.0859, 0.0344, 0.0707, 0.0630, 0.0964, 0.0527,
        0.0092, 0.0357, 0.0429, 0.0047, 0.1180, 0.0343, 0.0529, 0.0535, 0.0335,
        0.0368], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,526][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.8917e-03, 6.9708e-07, 4.9348e-05, 7.2830e-06, 5.5091e-05, 4.2319e-05,
        7.8451e-05, 9.7564e-04, 1.7010e-04, 2.6165e-04, 3.6017e-03, 6.1851e-03,
        2.0152e-02, 3.1004e-03, 2.2437e-02, 1.3067e-01, 1.6240e-01, 4.6075e-01,
        1.8617e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,526][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0123, 0.0557, 0.0510, 0.0546, 0.0559, 0.0543, 0.0536, 0.0591, 0.0565,
        0.0597, 0.0585, 0.0595, 0.0616, 0.0529, 0.0501, 0.0526, 0.0462, 0.0569,
        0.0489], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,527][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.7868e-02, 1.0953e-06, 3.1089e-05, 8.1603e-06, 2.0551e-05, 3.8477e-05,
        8.8266e-05, 1.0658e-03, 2.5629e-04, 1.2930e-04, 1.7917e-03, 1.0591e-02,
        1.8992e-02, 6.4999e-03, 8.8783e-03, 1.8338e-01, 1.6995e-01, 4.3142e-01,
        1.4898e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,527][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0290, 0.0086, 0.0196, 0.0160, 0.0369, 0.0196, 0.0190, 0.0343, 0.0143,
        0.0294, 0.0310, 0.0342, 0.0754, 0.0232, 0.1104, 0.1346, 0.0914, 0.1536,
        0.1194], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,528][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0271, 0.0662, 0.0577, 0.0638, 0.0524, 0.0512, 0.0590, 0.0599, 0.0536,
        0.0488, 0.0519, 0.0566, 0.0573, 0.0487, 0.0425, 0.0426, 0.0484, 0.0589,
        0.0534], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,528][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2043, 0.0326, 0.0484, 0.0409, 0.0429, 0.0677, 0.0401, 0.0425, 0.0282,
        0.0400, 0.0338, 0.0468, 0.0553, 0.0391, 0.0498, 0.0522, 0.0439, 0.0580,
        0.0335], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,528][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0169, 0.0130, 0.0183, 0.0233, 0.0369, 0.0299, 0.0433, 0.0458, 0.0326,
        0.0369, 0.0489, 0.0560, 0.0889, 0.0430, 0.0902, 0.0797, 0.0964, 0.0920,
        0.1081], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,532][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0043, 0.0722, 0.0590, 0.0579, 0.0572, 0.0568, 0.0508, 0.0500, 0.0442,
        0.0538, 0.0526, 0.0564, 0.0619, 0.0496, 0.0579, 0.0584, 0.0518, 0.0535,
        0.0519], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,534][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([8.8132e-01, 7.7178e-04, 5.2945e-03, 1.6616e-03, 8.7068e-03, 4.5827e-03,
        6.4255e-03, 1.2823e-02, 5.7462e-03, 8.8376e-03, 2.9036e-03, 3.7173e-03,
        6.4325e-03, 3.3738e-03, 1.3897e-02, 6.8431e-03, 5.5503e-03, 9.9889e-03,
        1.1125e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,577][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:19,577][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,578][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,578][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,578][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,579][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,582][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,584][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,588][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,591][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,592][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,593][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,593][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,593][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7295, 0.2705], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,593][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1108, 0.8892], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,594][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5745, 0.4255], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,594][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4743, 0.5257], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,594][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4059, 0.5941], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,595][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7733, 0.2267], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,598][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6555, 0.3445], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,602][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3462, 0.6538], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,608][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2982, 0.7018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,608][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.8544, 0.1456], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,608][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9967, 0.0033], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,609][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.0000e+00, 3.5205e-07], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:19,609][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.2710, 0.4676, 0.2614], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,609][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([0.0645, 0.1183, 0.8171], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,609][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.6582, 0.2154, 0.1264], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,610][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.4226, 0.0579, 0.5194], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,610][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.2486, 0.1149, 0.6365], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,610][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.6023, 0.0571, 0.3406], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,611][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.5974, 0.1617, 0.2409], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,612][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.0846, 0.2019, 0.7135], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,618][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.1846, 0.5643, 0.2511], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,622][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.7526, 0.0208, 0.2266], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,624][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.9516, 0.0153, 0.0330], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,624][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([9.6130e-01, 4.4091e-04, 3.8256e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:19,625][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2614, 0.1876, 0.1396, 0.4115], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,625][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0300, 0.0319, 0.2649, 0.6732], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,625][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3726, 0.2022, 0.1418, 0.2834], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,625][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1516, 0.0144, 0.4245, 0.4096], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,626][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3421, 0.1725, 0.0877, 0.3977], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,626][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4957, 0.0317, 0.2832, 0.1895], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,626][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4550, 0.0197, 0.1337, 0.3916], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,630][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0142, 0.0354, 0.1795, 0.7709], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,635][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1030, 0.5821, 0.1244, 0.1906], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,639][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6788, 0.0118, 0.2150, 0.0944], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,640][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9655, 0.0043, 0.0061, 0.0240], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,640][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([6.0538e-03, 6.2015e-08, 9.6426e-01, 2.9687e-02], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:19,640][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.2251, 0.1536, 0.1091, 0.3943, 0.1179], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,641][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0181, 0.0133, 0.1112, 0.3044, 0.5530], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,641][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.5290, 0.1243, 0.1021, 0.1564, 0.0882], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,641][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.2662, 0.0079, 0.1714, 0.1964, 0.3581], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,641][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0199, 0.0076, 0.0754, 0.0047, 0.8924], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,642][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.4871, 0.0109, 0.1120, 0.1025, 0.2875], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,642][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.4998, 0.0433, 0.0764, 0.3224, 0.0582], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,642][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0196, 0.0283, 0.1201, 0.2673, 0.5646], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,645][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.1302, 0.3492, 0.2000, 0.1373, 0.1834], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,650][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.6084, 0.0058, 0.1149, 0.0536, 0.2173], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,656][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.9216, 0.0112, 0.0180, 0.0391, 0.0101], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,656][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([4.7859e-01, 3.8422e-06, 3.8975e-03, 5.1215e-01, 5.3623e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:19,656][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1771, 0.1698, 0.0661, 0.3644, 0.0987, 0.1238], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,656][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0111, 0.0075, 0.0718, 0.2030, 0.3723, 0.3342], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,657][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.5799, 0.0981, 0.0619, 0.1088, 0.0868, 0.0644], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,657][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0641, 0.0042, 0.1173, 0.1090, 0.4473, 0.2581], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,657][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0501, 0.0144, 0.0291, 0.0155, 0.1502, 0.7407], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,658][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3376, 0.0065, 0.0859, 0.0966, 0.2222, 0.2512], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,658][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.1941, 0.0152, 0.0997, 0.2160, 0.3106, 0.1644], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,661][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0059, 0.0129, 0.0381, 0.2136, 0.1261, 0.6034], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,667][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1296, 0.3613, 0.1000, 0.1278, 0.1561, 0.1252], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,671][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.4927, 0.0068, 0.0853, 0.0367, 0.2275, 0.1511], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,671][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.9380, 0.0055, 0.0056, 0.0218, 0.0037, 0.0254], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,672][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([1.0185e-04, 1.5177e-09, 2.0293e-03, 6.4059e-03, 9.6472e-01, 2.6743e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:19,672][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0726, 0.0882, 0.0533, 0.2138, 0.0830, 0.3081, 0.1810],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,672][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0101, 0.0051, 0.0495, 0.1343, 0.2528, 0.2295, 0.3187],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,673][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.6582, 0.0614, 0.0413, 0.0791, 0.0547, 0.0441, 0.0611],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,673][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0911, 0.0028, 0.1006, 0.0950, 0.2893, 0.1679, 0.2533],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,673][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0577, 0.0213, 0.0562, 0.0309, 0.3276, 0.2410, 0.2653],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,674][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4316, 0.0034, 0.0791, 0.0361, 0.2320, 0.0850, 0.1328],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,674][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4011, 0.0070, 0.0514, 0.0867, 0.1130, 0.1131, 0.2277],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,677][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0138, 0.0136, 0.0348, 0.1350, 0.1099, 0.2980, 0.3949],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,682][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1118, 0.3687, 0.0833, 0.1137, 0.1120, 0.1075, 0.1031],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,687][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.5052, 0.0023, 0.0448, 0.0193, 0.1269, 0.1189, 0.1826],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,688][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9512, 0.0037, 0.0052, 0.0119, 0.0027, 0.0098, 0.0156],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,688][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([8.0813e-03, 8.1318e-10, 1.3277e-03, 3.9486e-04, 2.1094e-01, 2.0982e-01,
        5.6944e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:19,688][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.1094, 0.0136, 0.0167, 0.0429, 0.0263, 0.0810, 0.0522, 0.6579],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,689][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0074, 0.0025, 0.0267, 0.0721, 0.1515, 0.1165, 0.1789, 0.4445],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,689][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.6587, 0.0341, 0.0242, 0.0497, 0.0306, 0.0356, 0.0451, 0.1221],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,689][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([1.0371e-01, 3.1578e-04, 1.3480e-02, 8.5982e-03, 3.4545e-02, 1.8388e-02,
        2.4512e-02, 7.9645e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,689][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0672, 0.0159, 0.0161, 0.0183, 0.0944, 0.0508, 0.0334, 0.7038],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,691][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([2.9663e-01, 2.1466e-04, 6.0572e-03, 3.1891e-03, 2.1553e-02, 1.0116e-02,
        4.3652e-02, 6.1859e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,697][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.3697, 0.0031, 0.0125, 0.0152, 0.0467, 0.0313, 0.1396, 0.3820],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,701][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0054, 0.0038, 0.0087, 0.0271, 0.0367, 0.0581, 0.0820, 0.7782],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,703][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0780, 0.2726, 0.0741, 0.1229, 0.0928, 0.0983, 0.0999, 0.1615],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,703][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([5.2685e-01, 4.1155e-04, 1.2094e-02, 6.2104e-03, 5.2055e-02, 2.5735e-02,
        5.3451e-02, 3.2319e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,703][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([9.7680e-01, 1.3866e-03, 3.8387e-03, 4.4350e-03, 1.9701e-03, 2.2174e-03,
        8.4466e-03, 9.0324e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,704][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([1.1587e-05, 7.2682e-16, 3.4215e-09, 4.7736e-10, 5.4474e-07, 1.1010e-07,
        1.6511e-03, 9.9834e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:19,704][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0320, 0.0109, 0.0237, 0.0241, 0.0394, 0.0291, 0.0541, 0.6696, 0.1171],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,704][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0041, 0.0020, 0.0205, 0.0536, 0.1139, 0.1009, 0.1488, 0.3646, 0.1917],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,705][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.4317, 0.0399, 0.0243, 0.0526, 0.0258, 0.0331, 0.0436, 0.2032, 0.1459],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,705][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([1.1693e-02, 1.1024e-04, 4.8296e-03, 4.2437e-03, 1.8265e-02, 1.0823e-02,
        2.3762e-02, 8.7540e-01, 5.0872e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,708][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0469, 0.0177, 0.0153, 0.0372, 0.0376, 0.0720, 0.1240, 0.6300, 0.0194],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,711][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([3.7239e-02, 2.0385e-04, 2.8897e-03, 2.6825e-03, 5.9951e-03, 5.7790e-03,
        2.1617e-02, 8.6840e-01, 5.5192e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,716][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.1378, 0.0019, 0.0119, 0.0161, 0.0284, 0.0280, 0.1056, 0.5304, 0.1401],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,718][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0040, 0.0030, 0.0088, 0.0252, 0.0241, 0.0547, 0.0840, 0.5830, 0.2132],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,719][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0700, 0.2884, 0.0778, 0.0894, 0.0956, 0.0718, 0.0723, 0.1477, 0.0870],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,719][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.3059, 0.0007, 0.0168, 0.0061, 0.0561, 0.0344, 0.0690, 0.4249, 0.0861],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,719][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.9475, 0.0037, 0.0059, 0.0101, 0.0022, 0.0089, 0.0109, 0.0015, 0.0093],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,720][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([2.0399e-09, 2.5392e-19, 1.4625e-11, 1.1873e-13, 4.9223e-09, 2.4269e-10,
        1.1318e-07, 9.9999e-01, 1.2673e-05], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:19,720][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0114, 0.0059, 0.0050, 0.0160, 0.0094, 0.0181, 0.0209, 0.4056, 0.0968,
        0.4108], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,720][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0044, 0.0014, 0.0143, 0.0406, 0.0852, 0.0641, 0.0999, 0.2410, 0.1424,
        0.3068], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,721][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.3579, 0.0256, 0.0212, 0.0457, 0.0222, 0.0265, 0.0410, 0.1816, 0.1349,
        0.1434], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,722][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([4.7033e-02, 1.7608e-04, 7.5674e-03, 3.8056e-03, 3.1518e-02, 9.2796e-03,
        1.5520e-02, 5.5757e-01, 4.7610e-02, 2.7992e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,728][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0555, 0.0214, 0.0110, 0.0299, 0.0787, 0.2239, 0.0516, 0.4176, 0.0150,
        0.0953], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,731][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([3.9458e-02, 9.0068e-05, 1.1403e-03, 1.5556e-03, 6.3711e-03, 5.3489e-03,
        1.3274e-02, 5.7089e-01, 1.1100e-01, 2.5087e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,734][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1433, 0.0015, 0.0069, 0.0152, 0.0207, 0.0206, 0.0638, 0.3715, 0.1496,
        0.2070], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,735][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0020, 0.0017, 0.0037, 0.0169, 0.0180, 0.0412, 0.0473, 0.3850, 0.1347,
        0.3496], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,735][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0573, 0.2072, 0.0537, 0.0822, 0.0708, 0.0722, 0.0756, 0.1428, 0.0919,
        0.1461], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,735][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.1873, 0.0004, 0.0107, 0.0047, 0.0340, 0.0297, 0.0451, 0.3747, 0.0866,
        0.2269], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,736][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.8718, 0.0080, 0.0078, 0.0238, 0.0059, 0.0106, 0.0322, 0.0046, 0.0310,
        0.0041], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,736][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([9.2796e-07, 1.5621e-16, 5.1468e-11, 4.2988e-10, 2.3268e-08, 6.7136e-08,
        1.0145e-05, 8.8634e-01, 5.6350e-02, 5.7294e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:19,736][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0123, 0.0104, 0.0053, 0.0192, 0.0048, 0.0195, 0.0226, 0.2809, 0.1204,
        0.4130, 0.0917], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,737][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0035, 0.0016, 0.0134, 0.0363, 0.0628, 0.0673, 0.0902, 0.1834, 0.1148,
        0.1703, 0.2565], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,737][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.3089, 0.0348, 0.0265, 0.0414, 0.0281, 0.0318, 0.0407, 0.1723, 0.1002,
        0.1374, 0.0781], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,737][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([3.6905e-02, 1.4992e-04, 6.6192e-03, 2.6697e-03, 1.0225e-02, 9.6255e-03,
        2.1209e-02, 2.9098e-01, 4.2666e-02, 1.0637e-01, 4.7259e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,741][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0529, 0.0368, 0.0282, 0.0458, 0.1496, 0.1383, 0.0965, 0.3549, 0.0041,
        0.0158, 0.0769], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,745][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.8350e-01, 2.8282e-04, 3.0845e-03, 2.1996e-03, 3.0085e-03, 8.7807e-03,
        1.4317e-02, 3.6001e-01, 7.4538e-02, 7.1690e-02, 2.7859e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,747][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([1.4478e-01, 3.2043e-04, 4.2400e-03, 3.5674e-03, 4.2588e-03, 8.4380e-03,
        1.2764e-02, 1.3672e-01, 3.4072e-02, 3.4199e-02, 6.1664e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,751][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0037, 0.0021, 0.0050, 0.0153, 0.0124, 0.0399, 0.0538, 0.2898, 0.1378,
        0.1171, 0.3232], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,751][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0476, 0.2386, 0.0458, 0.0657, 0.0552, 0.0614, 0.0568, 0.1292, 0.0684,
        0.1267, 0.1046], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,752][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.2508, 0.0004, 0.0125, 0.0033, 0.0222, 0.0275, 0.0435, 0.2054, 0.0557,
        0.1454, 0.2333], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,752][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.8049, 0.0117, 0.0171, 0.0357, 0.0098, 0.0241, 0.0421, 0.0051, 0.0357,
        0.0071, 0.0067], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,752][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([4.4810e-07, 2.6585e-18, 4.3196e-11, 5.9832e-14, 1.6528e-10, 3.2649e-10,
        2.0461e-08, 9.6101e-04, 3.5381e-06, 1.0251e-05, 9.9902e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:19,753][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0123, 0.0059, 0.0068, 0.0165, 0.0087, 0.0158, 0.0130, 0.1596, 0.0954,
        0.1650, 0.3196, 0.1814], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,753][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0030, 0.0014, 0.0112, 0.0298, 0.0517, 0.0531, 0.0691, 0.1326, 0.0878,
        0.1282, 0.2072, 0.2250], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,753][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.4433, 0.0198, 0.0148, 0.0272, 0.0192, 0.0222, 0.0260, 0.1424, 0.0682,
        0.0979, 0.0610, 0.0581], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,755][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([6.6693e-02, 7.3634e-05, 3.2305e-03, 1.1799e-03, 5.1028e-03, 3.6069e-03,
        4.4610e-03, 6.3678e-02, 1.3729e-02, 2.4729e-02, 3.5736e-01, 4.5616e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,760][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0424, 0.0134, 0.0365, 0.0241, 0.1033, 0.1053, 0.0563, 0.4432, 0.0078,
        0.0214, 0.0195, 0.1268], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,763][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([1.8332e-01, 9.3254e-05, 1.2478e-03, 7.1497e-04, 1.5124e-03, 1.7754e-03,
        3.4810e-03, 4.4266e-02, 1.3723e-02, 1.3461e-02, 2.6597e-01, 4.7044e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,767][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.1567e-01, 2.3192e-04, 1.9899e-03, 1.4162e-03, 2.2824e-03, 3.1492e-03,
        6.3665e-03, 4.9919e-02, 1.2191e-02, 9.7355e-03, 3.9441e-01, 4.0264e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,767][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0057, 0.0015, 0.0049, 0.0087, 0.0111, 0.0270, 0.0299, 0.1119, 0.0584,
        0.0512, 0.2121, 0.4776], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,767][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0521, 0.1962, 0.0477, 0.0659, 0.0643, 0.0565, 0.0517, 0.1103, 0.0653,
        0.1126, 0.0943, 0.0830], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,768][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.0541e-01, 2.3795e-04, 6.3429e-03, 1.4827e-03, 1.0798e-02, 1.2842e-02,
        1.3952e-02, 6.2233e-02, 2.2543e-02, 3.3706e-02, 1.5089e-01, 3.7956e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,768][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.8193, 0.0095, 0.0137, 0.0314, 0.0070, 0.0267, 0.0350, 0.0054, 0.0331,
        0.0044, 0.0048, 0.0096], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,768][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([3.9200e-07, 7.0147e-20, 1.0368e-13, 3.2990e-15, 3.5047e-13, 8.6318e-12,
        2.2523e-11, 2.6125e-07, 1.6170e-07, 2.8281e-09, 7.8522e-01, 2.1478e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:19,769][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0098, 0.0031, 0.0037, 0.0088, 0.0032, 0.0061, 0.0089, 0.0817, 0.0700,
        0.0761, 0.3273, 0.2080, 0.1934], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,769][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0025, 0.0006, 0.0062, 0.0170, 0.0309, 0.0324, 0.0429, 0.0888, 0.0569,
        0.0871, 0.1416, 0.1674, 0.3257], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,770][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.3663, 0.0161, 0.0197, 0.0310, 0.0226, 0.0203, 0.0265, 0.0875, 0.0718,
        0.0647, 0.0637, 0.0554, 0.1544], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,771][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([2.5630e-02, 5.0193e-06, 5.7275e-04, 9.3997e-05, 6.5612e-04, 5.5041e-04,
        8.3449e-04, 3.2699e-03, 1.7167e-03, 2.7540e-03, 8.7566e-02, 2.8997e-01,
        5.8638e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,775][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0127, 0.0297, 0.0041, 0.0363, 0.0168, 0.0331, 0.0287, 0.4129, 0.0089,
        0.0090, 0.0230, 0.0807, 0.3041], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,779][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([6.7672e-02, 6.1726e-06, 1.8495e-04, 9.8762e-05, 2.3043e-04, 4.1191e-04,
        6.2404e-04, 7.1335e-03, 3.8686e-03, 1.1588e-03, 6.3292e-02, 2.6362e-01,
        5.9170e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,782][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([7.7429e-02, 1.9669e-04, 1.0557e-03, 8.5765e-04, 1.3689e-03, 1.4980e-03,
        2.4836e-03, 1.2198e-02, 4.3564e-03, 3.2747e-03, 1.8352e-01, 4.8700e-01,
        2.2475e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,783][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0018, 0.0005, 0.0015, 0.0032, 0.0038, 0.0094, 0.0112, 0.0435, 0.0345,
        0.0211, 0.1231, 0.2707, 0.4758], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,784][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0356, 0.1195, 0.0454, 0.0603, 0.0571, 0.0564, 0.0577, 0.0998, 0.0657,
        0.1012, 0.1018, 0.0881, 0.1116], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,784][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([2.2131e-01, 4.9718e-05, 2.6010e-03, 5.1229e-04, 4.4186e-03, 3.3006e-03,
        6.1852e-03, 2.3157e-02, 9.2073e-03, 1.1825e-02, 1.0342e-01, 2.4893e-01,
        3.6508e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,785][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.7504, 0.0106, 0.0121, 0.0472, 0.0078, 0.0462, 0.0433, 0.0046, 0.0435,
        0.0066, 0.0048, 0.0095, 0.0134], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,785][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.3263e-09, 4.1142e-23, 6.7968e-17, 8.0472e-18, 4.4730e-16, 3.0675e-15,
        4.3937e-12, 5.8917e-11, 1.0635e-10, 6.9530e-13, 5.0193e-03, 9.7890e-01,
        1.6084e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:19,785][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0081, 0.0033, 0.0022, 0.0074, 0.0029, 0.0072, 0.0127, 0.1041, 0.0538,
        0.1566, 0.1169, 0.1715, 0.2390, 0.1142], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,786][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0027, 0.0007, 0.0060, 0.0146, 0.0282, 0.0245, 0.0342, 0.0728, 0.0444,
        0.0789, 0.1064, 0.1210, 0.2407, 0.2250], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,789][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.3402, 0.0137, 0.0108, 0.0255, 0.0151, 0.0154, 0.0185, 0.0964, 0.0540,
        0.0693, 0.0444, 0.0494, 0.1602, 0.0872], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,793][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([3.0590e-03, 7.1047e-06, 3.9998e-04, 1.3517e-04, 9.6860e-04, 5.3105e-04,
        1.3313e-03, 1.1505e-02, 3.1359e-03, 6.4995e-03, 5.3152e-02, 1.8304e-01,
        6.8469e-01, 5.1542e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,798][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0348, 0.0209, 0.0207, 0.0453, 0.0949, 0.1006, 0.0701, 0.3651, 0.0098,
        0.0304, 0.0321, 0.0736, 0.0899, 0.0116], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,799][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.2863e-02, 8.3688e-06, 1.7359e-04, 1.4316e-04, 2.7548e-04, 4.1132e-04,
        8.4786e-04, 9.7458e-03, 4.2025e-03, 3.4489e-03, 4.7470e-02, 2.2476e-01,
        6.1688e-01, 7.8772e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,800][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([8.7096e-03, 8.4175e-05, 3.8643e-04, 5.4279e-04, 1.0700e-03, 1.3435e-03,
        2.4948e-03, 2.0135e-02, 4.0194e-03, 6.8017e-03, 9.0503e-02, 2.8204e-01,
        5.1708e-01, 6.4795e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,800][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0008, 0.0006, 0.0013, 0.0060, 0.0042, 0.0152, 0.0147, 0.0555, 0.0378,
        0.0351, 0.1001, 0.2308, 0.3469, 0.1509], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,800][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0473, 0.1501, 0.0355, 0.0491, 0.0453, 0.0532, 0.0445, 0.0993, 0.0524,
        0.1063, 0.0806, 0.0690, 0.1053, 0.0621], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,801][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([7.9690e-02, 9.3084e-05, 2.5053e-03, 7.0071e-04, 4.9852e-03, 5.3970e-03,
        9.3156e-03, 4.4197e-02, 1.1920e-02, 3.0256e-02, 8.7010e-02, 3.0360e-01,
        3.5542e-01, 6.4906e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,801][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.7609, 0.0107, 0.0151, 0.0333, 0.0083, 0.0454, 0.0390, 0.0034, 0.0405,
        0.0059, 0.0045, 0.0098, 0.0045, 0.0187], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,801][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([1.0928e-12, 2.7959e-24, 1.0666e-16, 6.9092e-19, 2.2258e-15, 4.6432e-16,
        2.7036e-13, 1.6047e-09, 3.1653e-11, 2.7155e-10, 2.7574e-04, 2.1534e-02,
        9.7819e-01, 1.1038e-06], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:19,802][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.0355, 0.0048, 0.0055, 0.0100, 0.0040, 0.0096, 0.0156, 0.0653, 0.0399,
        0.0493, 0.1685, 0.2207, 0.1590, 0.1157, 0.0966], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,802][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0018, 0.0005, 0.0044, 0.0123, 0.0218, 0.0208, 0.0271, 0.0534, 0.0349,
        0.0559, 0.0926, 0.1057, 0.2086, 0.2094, 0.1508], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,805][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.4440, 0.0089, 0.0074, 0.0132, 0.0081, 0.0124, 0.0122, 0.0760, 0.0330,
        0.0512, 0.0319, 0.0446, 0.1523, 0.0672, 0.0376], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,808][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([3.0477e-02, 9.2132e-06, 5.6756e-04, 1.3043e-04, 8.1777e-04, 2.3597e-04,
        5.6053e-04, 3.7149e-03, 1.2171e-03, 1.6705e-03, 5.8566e-02, 1.2632e-01,
        3.4678e-01, 4.1087e-02, 3.8785e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,814][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0076, 0.0031, 0.0400, 0.0020, 0.3945, 0.0808, 0.0051, 0.0149, 0.0006,
        0.0112, 0.0030, 0.0059, 0.0186, 0.0017, 0.4110], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,816][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([9.1074e-02, 1.0850e-05, 2.2580e-04, 1.1652e-04, 3.4560e-04, 2.1080e-04,
        6.6215e-04, 3.5515e-03, 1.9825e-03, 1.6023e-03, 7.7473e-02, 2.0854e-01,
        3.7151e-01, 8.4597e-02, 1.5809e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,816][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([5.0177e-02, 2.7889e-04, 4.5705e-04, 5.5993e-04, 3.1306e-04, 1.4587e-03,
        1.6150e-03, 1.5647e-02, 3.7979e-03, 3.1908e-03, 7.2693e-02, 1.9570e-01,
        5.3620e-01, 5.3200e-02, 6.4712e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,817][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0025, 0.0005, 0.0025, 0.0023, 0.0087, 0.0119, 0.0127, 0.0276, 0.0229,
        0.0180, 0.0666, 0.2346, 0.2504, 0.1162, 0.2223], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,817][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.0546, 0.0937, 0.0560, 0.0413, 0.0462, 0.0457, 0.0377, 0.0693, 0.0485,
        0.0958, 0.0688, 0.0640, 0.1129, 0.0592, 0.1063], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,817][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([1.8100e-01, 5.5619e-05, 1.9206e-03, 3.8364e-04, 2.3647e-03, 2.8953e-03,
        3.2780e-03, 1.5499e-02, 6.1183e-03, 1.0833e-02, 7.7923e-02, 1.8447e-01,
        2.4013e-01, 5.1154e-02, 2.2197e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,818][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.6877, 0.0129, 0.0178, 0.0416, 0.0119, 0.0465, 0.0416, 0.0061, 0.0502,
        0.0156, 0.0075, 0.0173, 0.0093, 0.0283, 0.0057], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,818][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([4.0853e-06, 4.1983e-20, 1.5638e-14, 3.6397e-16, 1.6817e-15, 9.4664e-14,
        3.7636e-12, 1.0169e-09, 9.4688e-11, 1.2953e-11, 6.5826e-03, 3.2533e-01,
        6.6775e-01, 2.5908e-05, 3.0517e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:19,822][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0383, 0.0081, 0.0044, 0.0151, 0.0024, 0.0134, 0.0093, 0.0750, 0.0428,
        0.0426, 0.1213, 0.1257, 0.1559, 0.0989, 0.0391, 0.2077],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,828][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0014, 0.0004, 0.0040, 0.0112, 0.0190, 0.0206, 0.0280, 0.0529, 0.0344,
        0.0477, 0.0718, 0.0834, 0.1702, 0.1803, 0.1194, 0.1552],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,832][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.4305, 0.0110, 0.0157, 0.0183, 0.0137, 0.0148, 0.0146, 0.0715, 0.0427,
        0.0532, 0.0343, 0.0369, 0.0861, 0.0559, 0.0499, 0.0508],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,832][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.7831e-02, 6.0975e-06, 5.9270e-04, 7.2991e-05, 5.8527e-04, 2.7645e-04,
        3.4757e-04, 3.6579e-03, 7.9555e-04, 6.0796e-04, 2.3137e-02, 2.9453e-02,
        1.1797e-01, 2.0130e-02, 1.4035e-01, 6.4419e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,832][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0116, 0.0151, 0.0467, 0.0199, 0.0437, 0.2096, 0.1053, 0.1353, 0.0037,
        0.0115, 0.0162, 0.1144, 0.0657, 0.0076, 0.0385, 0.1552],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,833][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([4.7078e-02, 4.9413e-06, 1.8906e-04, 6.8968e-05, 1.5145e-04, 3.2765e-04,
        5.7508e-04, 3.7539e-03, 1.1982e-03, 3.7798e-04, 1.0055e-02, 5.1781e-02,
        1.0920e-01, 2.9958e-02, 5.4597e-02, 6.9069e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,833][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([8.0225e-02, 1.1425e-04, 9.7333e-04, 3.3330e-04, 1.3364e-03, 8.4392e-04,
        1.7882e-03, 7.7159e-03, 2.2390e-03, 2.0630e-03, 4.1459e-02, 6.7784e-02,
        2.7958e-01, 3.7684e-02, 2.4386e-01, 2.3201e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,834][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0021, 0.0005, 0.0014, 0.0032, 0.0030, 0.0128, 0.0115, 0.0277, 0.0197,
        0.0088, 0.0427, 0.1093, 0.1771, 0.0814, 0.0665, 0.4325],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,834][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0444, 0.1020, 0.0263, 0.0422, 0.0348, 0.0454, 0.0418, 0.0853, 0.0482,
        0.0801, 0.0689, 0.0584, 0.0890, 0.0521, 0.0810, 0.1003],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,834][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([3.2502e-01, 7.1152e-05, 1.6096e-03, 2.5016e-04, 1.7051e-03, 1.8007e-03,
        3.6795e-03, 7.4598e-03, 4.2796e-03, 2.3160e-03, 2.7718e-02, 9.4848e-02,
        7.1186e-02, 2.2375e-02, 1.0285e-01, 3.3283e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,835][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.5987, 0.0168, 0.0204, 0.0561, 0.0100, 0.0749, 0.0549, 0.0074, 0.0766,
        0.0058, 0.0107, 0.0124, 0.0072, 0.0273, 0.0037, 0.0171],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,835][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.2458e-08, 3.7054e-24, 6.3069e-15, 1.2095e-18, 3.5024e-15, 1.1167e-15,
        9.3419e-14, 5.8719e-11, 3.1983e-12, 5.0775e-14, 3.4604e-05, 8.1051e-04,
        2.3847e-02, 5.8226e-08, 7.0435e-04, 9.7460e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:19,838][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0074, 0.0030, 0.0021, 0.0054, 0.0018, 0.0071, 0.0040, 0.0562, 0.0355,
        0.0531, 0.0687, 0.0433, 0.0998, 0.0645, 0.0372, 0.2561, 0.2546],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,843][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0012, 0.0004, 0.0033, 0.0091, 0.0159, 0.0162, 0.0217, 0.0472, 0.0291,
        0.0458, 0.0617, 0.0697, 0.1492, 0.1538, 0.1037, 0.1282, 0.1439],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,849][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4306, 0.0074, 0.0068, 0.0132, 0.0084, 0.0086, 0.0109, 0.0657, 0.0390,
        0.0486, 0.0320, 0.0283, 0.1053, 0.0531, 0.0435, 0.0525, 0.0461],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,849][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([5.8641e-03, 1.7085e-06, 1.6036e-04, 2.8474e-05, 2.2460e-04, 1.0612e-04,
        1.5707e-04, 2.8212e-03, 5.6760e-04, 7.8872e-04, 1.4276e-02, 1.9928e-02,
        7.8989e-02, 1.1768e-02, 1.0085e-01, 4.3499e-01, 3.2848e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,850][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0204, 0.0087, 0.0253, 0.0134, 0.1294, 0.1080, 0.1189, 0.1549, 0.0033,
        0.0190, 0.0188, 0.0467, 0.0783, 0.0045, 0.1099, 0.0134, 0.1270],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,850][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([4.5661e-02, 2.8787e-06, 1.0023e-04, 2.1399e-05, 1.3309e-04, 1.0466e-04,
        9.2348e-05, 3.1822e-03, 9.0627e-04, 3.9918e-04, 6.6255e-03, 3.4322e-02,
        8.3027e-02, 2.4709e-02, 5.7536e-02, 5.2825e-01, 2.1493e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,850][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([6.6358e-02, 5.1175e-05, 4.4767e-04, 1.6384e-04, 4.5955e-04, 5.0959e-04,
        7.1878e-04, 8.9753e-03, 1.7348e-03, 2.1381e-03, 2.9728e-02, 5.0163e-02,
        1.7350e-01, 2.5076e-02, 1.1535e-01, 2.5991e-01, 2.6472e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,851][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([1.3590e-03, 3.5276e-04, 7.8408e-04, 1.6286e-03, 1.7806e-03, 4.7536e-03,
        5.8941e-03, 2.6962e-02, 1.4560e-02, 1.3488e-02, 4.2415e-02, 8.3692e-02,
        1.1094e-01, 5.5970e-02, 5.0078e-02, 1.9518e-01, 3.9017e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,851][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0433, 0.1138, 0.0268, 0.0407, 0.0328, 0.0366, 0.0328, 0.0708, 0.0419,
        0.0697, 0.0612, 0.0522, 0.0856, 0.0501, 0.0730, 0.0788, 0.0899],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,853][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([9.6978e-02, 1.9169e-05, 7.5571e-04, 1.2416e-04, 1.1409e-03, 1.2298e-03,
        1.3219e-03, 7.1118e-03, 2.4385e-03, 2.9124e-03, 1.1901e-02, 4.5888e-02,
        5.8217e-02, 1.3102e-02, 9.6538e-02, 2.7334e-01, 3.8698e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,858][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7859, 0.0105, 0.0130, 0.0278, 0.0074, 0.0255, 0.0320, 0.0042, 0.0330,
        0.0045, 0.0049, 0.0097, 0.0050, 0.0199, 0.0029, 0.0071, 0.0066],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,861][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([5.3652e-09, 5.0829e-25, 1.1012e-16, 1.1882e-20, 2.1121e-16, 7.0994e-17,
        2.7374e-16, 1.4887e-11, 1.0198e-12, 1.4959e-13, 1.5252e-06, 5.5078e-06,
        2.8215e-04, 1.1030e-08, 4.7340e-05, 6.5463e-02, 9.3420e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:19,865][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0046, 0.0010, 0.0007, 0.0016, 0.0004, 0.0036, 0.0028, 0.0212, 0.0126,
        0.0228, 0.0406, 0.0333, 0.0623, 0.0316, 0.0140, 0.2021, 0.2819, 0.2629],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,865][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([9.4101e-04, 1.8947e-04, 2.1281e-03, 5.8226e-03, 1.0869e-02, 1.0929e-02,
        1.5569e-02, 3.3160e-02, 2.0407e-02, 3.5323e-02, 4.9222e-02, 5.9612e-02,
        1.1960e-01, 1.2209e-01, 8.4979e-02, 1.0973e-01, 1.2455e-01, 1.9488e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,865][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.3287, 0.0080, 0.0052, 0.0110, 0.0079, 0.0100, 0.0106, 0.0680, 0.0333,
        0.0600, 0.0307, 0.0289, 0.1042, 0.0511, 0.0415, 0.0729, 0.0421, 0.0859],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,866][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([3.8441e-03, 3.7503e-07, 3.8573e-05, 5.7540e-06, 5.1545e-05, 1.7703e-05,
        4.8334e-05, 5.5311e-04, 1.4053e-04, 1.3522e-04, 5.0174e-03, 1.3986e-02,
        3.8681e-02, 4.8532e-03, 5.0557e-02, 2.8456e-01, 2.2344e-01, 3.7407e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,866][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0628, 0.0144, 0.0118, 0.0232, 0.0467, 0.1152, 0.0602, 0.1472, 0.0081,
        0.0290, 0.0106, 0.0786, 0.0731, 0.0122, 0.0363, 0.0182, 0.0706, 0.1818],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,867][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([7.5661e-03, 1.2543e-07, 6.4165e-06, 1.6653e-06, 9.2547e-06, 7.4755e-06,
        2.3841e-05, 2.8804e-04, 8.7265e-05, 6.9125e-05, 1.3487e-03, 1.0309e-02,
        2.4116e-02, 4.3067e-03, 1.2914e-02, 2.4626e-01, 1.5997e-01, 5.3271e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,867][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([1.3200e-02, 2.1397e-05, 1.0690e-04, 5.9530e-05, 2.2998e-04, 2.0288e-04,
        4.3454e-04, 2.6106e-03, 3.3428e-04, 8.3696e-04, 1.6726e-02, 3.2788e-02,
        9.1568e-02, 1.6649e-02, 9.2656e-02, 2.7214e-01, 2.6516e-01, 1.9428e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,867][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([3.6358e-04, 8.8671e-05, 1.9278e-04, 5.2106e-04, 5.0861e-04, 1.6185e-03,
        2.3532e-03, 1.4345e-02, 5.3912e-03, 5.8894e-03, 1.9246e-02, 4.0817e-02,
        6.6670e-02, 2.4311e-02, 2.3852e-02, 1.4888e-01, 2.2917e-01, 4.1578e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,869][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.0261, 0.0974, 0.0231, 0.0413, 0.0342, 0.0357, 0.0325, 0.0623, 0.0419,
        0.0685, 0.0573, 0.0511, 0.0808, 0.0419, 0.0672, 0.0704, 0.0788, 0.0896],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,873][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([6.8665e-02, 3.4275e-06, 2.6691e-04, 3.7418e-05, 4.8859e-04, 2.4749e-04,
        4.6540e-04, 1.9043e-03, 7.7537e-04, 1.1303e-03, 6.6714e-03, 3.3083e-02,
        3.5288e-02, 5.5911e-03, 8.0643e-02, 1.9511e-01, 2.9805e-01, 2.7158e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,878][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.7326, 0.0175, 0.0052, 0.0431, 0.0046, 0.0331, 0.0483, 0.0077, 0.0400,
        0.0049, 0.0065, 0.0115, 0.0032, 0.0191, 0.0022, 0.0064, 0.0074, 0.0067],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,881][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([4.2126e-12, 6.4110e-30, 6.3838e-22, 1.2107e-24, 5.7108e-21, 8.6708e-21,
        1.0760e-17, 5.3536e-15, 3.7041e-16, 9.9208e-18, 1.4799e-08, 2.2616e-06,
        3.2694e-06, 3.5131e-11, 2.4980e-07, 4.0149e-03, 9.8663e-01, 9.3491e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:19,882][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0071, 0.0028, 0.0012, 0.0036, 0.0009, 0.0039, 0.0035, 0.0384, 0.0217,
        0.0272, 0.0240, 0.0352, 0.0315, 0.0338, 0.0169, 0.1639, 0.2327, 0.2334,
        0.1183], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,882][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0009, 0.0002, 0.0023, 0.0060, 0.0102, 0.0105, 0.0144, 0.0289, 0.0181,
        0.0258, 0.0442, 0.0499, 0.1019, 0.0986, 0.0664, 0.0910, 0.1053, 0.1598,
        0.1656], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,883][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.3323, 0.0076, 0.0054, 0.0129, 0.0070, 0.0092, 0.0095, 0.0657, 0.0346,
        0.0422, 0.0265, 0.0279, 0.0980, 0.0525, 0.0356, 0.0536, 0.0397, 0.0801,
        0.0596], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,883][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.8917e-03, 6.9708e-07, 4.9348e-05, 7.2830e-06, 5.5091e-05, 4.2319e-05,
        7.8451e-05, 9.7564e-04, 1.7010e-04, 2.6165e-04, 3.6017e-03, 6.1851e-03,
        2.0152e-02, 3.1004e-03, 2.2437e-02, 1.3067e-01, 1.6240e-01, 4.6075e-01,
        1.8617e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,883][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0519, 0.0216, 0.0386, 0.0472, 0.0538, 0.0849, 0.1079, 0.1773, 0.0051,
        0.0186, 0.0224, 0.0910, 0.0661, 0.0102, 0.0477, 0.0193, 0.1009, 0.0242,
        0.0112], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,884][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([1.7868e-02, 1.0953e-06, 3.1089e-05, 8.1603e-06, 2.0551e-05, 3.8477e-05,
        8.8266e-05, 1.0658e-03, 2.5629e-04, 1.2930e-04, 1.7917e-03, 1.0591e-02,
        1.8992e-02, 6.4999e-03, 8.8783e-03, 1.8338e-01, 1.6995e-01, 4.3142e-01,
        1.4898e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,884][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([2.9431e-02, 2.1665e-05, 1.5241e-04, 7.0324e-05, 1.9940e-04, 2.1461e-04,
        3.6835e-04, 2.2908e-03, 4.3431e-04, 4.6277e-04, 1.0518e-02, 1.3719e-02,
        6.3211e-02, 6.8595e-03, 3.9039e-02, 8.6423e-02, 1.5684e-01, 3.3827e-01,
        2.5148e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,886][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([5.5399e-04, 1.2001e-04, 2.7533e-04, 5.4938e-04, 6.3920e-04, 1.5151e-03,
        2.2458e-03, 9.9060e-03, 5.6939e-03, 4.3980e-03, 1.4052e-02, 3.0034e-02,
        3.7815e-02, 1.8618e-02, 1.6588e-02, 8.6605e-02, 1.5637e-01, 2.8507e-01,
        3.2895e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,891][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0387, 0.0988, 0.0255, 0.0316, 0.0295, 0.0301, 0.0272, 0.0580, 0.0323,
        0.0587, 0.0482, 0.0410, 0.0673, 0.0359, 0.0602, 0.0647, 0.0721, 0.1082,
        0.0721], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,894][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([7.0502e-02, 1.1322e-05, 4.4264e-04, 7.6544e-05, 8.9011e-04, 5.3175e-04,
        8.5793e-04, 3.3323e-03, 1.2899e-03, 1.1607e-03, 6.5391e-03, 2.3983e-02,
        1.8031e-02, 6.6194e-03, 5.3479e-02, 1.1015e-01, 2.3189e-01, 2.7222e-01,
        1.9799e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,898][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7546, 0.0136, 0.0119, 0.0334, 0.0081, 0.0328, 0.0373, 0.0053, 0.0285,
        0.0065, 0.0054, 0.0111, 0.0047, 0.0199, 0.0032, 0.0064, 0.0072, 0.0036,
        0.0064], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,898][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.6805e-10, 1.7875e-27, 2.8107e-19, 1.0089e-23, 2.3710e-19, 2.1074e-19,
        6.3923e-17, 1.9248e-13, 8.7645e-16, 1.7960e-16, 3.2168e-09, 2.5389e-07,
        9.8730e-06, 2.2879e-11, 1.0481e-07, 2.1833e-03, 1.1053e-01, 5.0225e-01,
        3.8503e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:19,899][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:19,900][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10826],
        [ 8616],
        [ 3627],
        [ 4729],
        [ 4023],
        [ 6591],
        [ 8738],
        [ 5423],
        [ 9469],
        [10255],
        [16431],
        [ 8324],
        [ 8855],
        [ 5702],
        [ 6656],
        [ 3442],
        [ 9971],
        [ 3473],
        [11869]], device='cuda:0')
[2024-07-24 10:27:19,902][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[12016],
        [16091],
        [ 9000],
        [ 9940],
        [ 8982],
        [13021],
        [16235],
        [13747],
        [20926],
        [21557],
        [28075],
        [15571],
        [13673],
        [11892],
        [15717],
        [ 6882],
        [19021],
        [ 6250],
        [24040]], device='cuda:0')
[2024-07-24 10:27:19,903][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[9117],
        [3939],
        [2331],
        [2071],
        [1898],
        [1698],
        [1818],
        [2012],
        [1748],
        [2032],
        [2434],
        [2408],
        [3241],
        [2834],
        [3083],
        [2417],
        [2355],
        [2430],
        [1840]], device='cuda:0')
[2024-07-24 10:27:19,905][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[30217],
        [ 8887],
        [12247],
        [12082],
        [14631],
        [14614],
        [16566],
        [17685],
        [18015],
        [18742],
        [20589],
        [21055],
        [21183],
        [22684],
        [23388],
        [23290],
        [24058],
        [23674],
        [24004]], device='cuda:0')
[2024-07-24 10:27:19,908][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[15183],
        [ 3599],
        [ 5790],
        [ 4132],
        [ 2782],
        [ 3322],
        [ 3434],
        [ 5315],
        [ 5579],
        [ 4631],
        [ 4018],
        [ 5734],
        [ 4061],
        [ 5212],
        [ 2488],
        [ 3387],
        [ 4179],
        [ 3733],
        [ 4600]], device='cuda:0')
[2024-07-24 10:27:19,911][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 4667],
        [  301],
        [24727],
        [ 6792],
        [17882],
        [20604],
        [10299],
        [  526],
        [  469],
        [  684],
        [ 1500],
        [ 1459],
        [  755],
        [  727],
        [ 3532],
        [  970],
        [  881],
        [  206],
        [  162]], device='cuda:0')
[2024-07-24 10:27:19,913][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6734],
        [ 6933],
        [ 7475],
        [ 8667],
        [ 9993],
        [10736],
        [11016],
        [11614],
        [11531],
        [12310],
        [12318],
        [12279],
        [12509],
        [12377],
        [12430],
        [12568],
        [12545],
        [12718],
        [12647]], device='cuda:0')
[2024-07-24 10:27:19,916][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[1687],
        [1232],
        [4473],
        [2922],
        [3763],
        [1786],
        [3450],
        [1073],
        [1575],
        [1325],
        [ 392],
        [1381],
        [5421],
        [6123],
        [4540],
        [2024],
        [2263],
        [9401],
        [7258]], device='cuda:0')
[2024-07-24 10:27:19,919][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[29149],
        [18754],
        [11857],
        [11151],
        [10223],
        [10811],
        [10873],
        [11462],
        [11668],
        [14346],
        [14980],
        [14849],
        [17468],
        [17782],
        [16602],
        [15708],
        [15894],
        [15597],
        [15993]], device='cuda:0')
[2024-07-24 10:27:19,920][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[28790],
        [31580],
        [31916],
        [32112],
        [32568],
        [33227],
        [33459],
        [33704],
        [33828],
        [34111],
        [34257],
        [34237],
        [34488],
        [34662],
        [34744],
        [34885],
        [34861],
        [34824],
        [34804]], device='cuda:0')
[2024-07-24 10:27:19,921][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15644],
        [16324],
        [14382],
        [14667],
        [12075],
        [11509],
        [11564],
        [11634],
        [12132],
        [12007],
        [12168],
        [12132],
        [12073],
        [12384],
        [11748],
        [11595],
        [11715],
        [11952],
        [11972]], device='cuda:0')
[2024-07-24 10:27:19,922][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[16592],
        [21106],
        [29168],
        [28399],
        [30075],
        [29420],
        [27755],
        [28772],
        [29459],
        [30255],
        [31445],
        [31140],
        [31888],
        [32542],
        [33756],
        [33955],
        [33658],
        [34234],
        [34884]], device='cuda:0')
[2024-07-24 10:27:19,923][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[5437],
        [5427],
        [5634],
        [6157],
        [6396],
        [6234],
        [5762],
        [5705],
        [5636],
        [5690],
        [5396],
        [4973],
        [4976],
        [5039],
        [5064],
        [5134],
        [5151],
        [5250],
        [5248]], device='cuda:0')
[2024-07-24 10:27:19,926][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[5448],
        [5448],
        [5441],
        [5444],
        [5374],
        [5332],
        [5350],
        [5260],
        [5205],
        [5170],
        [5178],
        [5320],
        [5267],
        [5224],
        [4996],
        [5127],
        [5181],
        [5120],
        [4956]], device='cuda:0')
[2024-07-24 10:27:19,928][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[13269],
        [16924],
        [13995],
        [21528],
        [20719],
        [21392],
        [25392],
        [22310],
        [24435],
        [22643],
        [23980],
        [23582],
        [32875],
        [17619],
        [ 9684],
        [27172],
        [20618],
        [30705],
        [16738]], device='cuda:0')
[2024-07-24 10:27:19,931][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 3502],
        [ 2647],
        [ 5013],
        [ 6356],
        [10273],
        [ 9690],
        [ 8860],
        [10090],
        [10743],
        [15057],
        [17054],
        [11447],
        [13361],
        [19692],
        [18200],
        [13485],
        [11978],
        [11886],
        [10814]], device='cuda:0')
[2024-07-24 10:27:19,934][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[25826],
        [26369],
        [16277],
        [21422],
        [18831],
        [21353],
        [22345],
        [21314],
        [23106],
        [24778],
        [24096],
        [24239],
        [22548],
        [24031],
        [23389],
        [24028],
        [24518],
        [23748],
        [24196]], device='cuda:0')
[2024-07-24 10:27:19,936][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 6952],
        [14232],
        [12751],
        [ 7088],
        [ 7170],
        [ 6560],
        [ 6516],
        [ 5661],
        [ 4753],
        [ 4740],
        [ 4749],
        [ 4811],
        [ 5522],
        [ 5323],
        [ 5552],
        [ 5582],
        [ 5581],
        [ 5528],
        [ 5393]], device='cuda:0')
[2024-07-24 10:27:19,939][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10811],
        [ 7292],
        [11330],
        [15291],
        [12087],
        [ 6968],
        [ 7450],
        [15906],
        [17156],
        [12419],
        [ 7536],
        [ 6373],
        [10605],
        [10979],
        [ 6928],
        [ 8343],
        [ 7674],
        [12017],
        [12224]], device='cuda:0')
[2024-07-24 10:27:19,940][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 6063],
        [ 3466],
        [ 7228],
        [ 3419],
        [11728],
        [ 4644],
        [ 6371],
        [10788],
        [ 9055],
        [ 7132],
        [ 7127],
        [ 7850],
        [ 8062],
        [ 7313],
        [11448],
        [ 5423],
        [ 7427],
        [ 7140],
        [ 6368]], device='cuda:0')
[2024-07-24 10:27:19,941][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[28489],
        [44236],
        [20082],
        [13482],
        [20565],
        [30617],
        [35214],
        [42496],
        [39343],
        [40551],
        [44283],
        [14859],
        [15548],
        [17654],
        [30633],
        [40851],
        [45601],
        [45945],
        [45617]], device='cuda:0')
[2024-07-24 10:27:19,942][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[1354],
        [1301],
        [ 846],
        [ 711],
        [ 666],
        [ 719],
        [ 970],
        [2764],
        [5003],
        [6315],
        [ 364],
        [ 885],
        [1839],
        [2896],
        [2918],
        [3817],
        [5301],
        [9005],
        [9321]], device='cuda:0')
[2024-07-24 10:27:19,943][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[34787],
        [30967],
        [28173],
        [24055],
        [23835],
        [24925],
        [23965],
        [18490],
        [19128],
        [18913],
        [21660],
        [24400],
        [18808],
        [20418],
        [21780],
        [26201],
        [24412],
        [22384],
        [23820]], device='cuda:0')
[2024-07-24 10:27:19,946][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 4668],
        [20138],
        [17792],
        [18459],
        [15393],
        [14277],
        [14185],
        [12732],
        [13074],
        [11963],
        [13064],
        [12531],
        [12053],
        [12403],
        [11519],
        [11271],
        [11292],
        [11384],
        [11472]], device='cuda:0')
[2024-07-24 10:27:19,948][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[14538],
        [10351],
        [15214],
        [14150],
        [16711],
        [17246],
        [10985],
        [ 8487],
        [ 6410],
        [ 1569],
        [ 2593],
        [ 3839],
        [ 7034],
        [ 6077],
        [ 9181],
        [ 5876],
        [ 2124],
        [ 2421],
        [ 2112]], device='cuda:0')
[2024-07-24 10:27:19,951][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[10221],
        [10034],
        [ 8492],
        [ 8346],
        [ 6480],
        [ 6394],
        [ 7539],
        [ 9147],
        [ 7669],
        [ 4997],
        [ 3322],
        [ 3508],
        [ 2207],
        [ 2511],
        [ 2135],
        [ 1673],
        [ 3218],
        [ 2284],
        [ 2582]], device='cuda:0')
[2024-07-24 10:27:19,953][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[35564],
        [35564],
        [33712],
        [13537],
        [21528],
        [ 9627],
        [17075],
        [ 9128],
        [ 9110],
        [ 9635],
        [19369],
        [19800],
        [23029],
        [ 9140],
        [10407],
        [22521],
        [19998],
        [19881],
        [ 5094]], device='cuda:0')
[2024-07-24 10:27:19,956][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[42012],
        [40769],
        [40187],
        [43518],
        [39856],
        [42613],
        [40599],
        [37924],
        [38843],
        [41968],
        [43028],
        [44867],
        [43378],
        [43444],
        [41040],
        [43438],
        [42424],
        [41826],
        [43815]], device='cuda:0')
[2024-07-24 10:27:19,959][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[16792],
        [36519],
        [39713],
        [36719],
        [39145],
        [40970],
        [34527],
        [31254],
        [28689],
        [32756],
        [36159],
        [36386],
        [33722],
        [42803],
        [47259],
        [36008],
        [36865],
        [29111],
        [37340]], device='cuda:0')
[2024-07-24 10:27:19,961][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453],
        [6453]], device='cuda:0')
[2024-07-24 10:27:19,991][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:19,991][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,993][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,995][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:19,997][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,013][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,017][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,021][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,023][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,023][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,023][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,024][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,024][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,024][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1195, 0.8805], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,025][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1126, 0.8874], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,025][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7153, 0.2847], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,028][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9230, 0.0770], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,034][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3993, 0.6007], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,038][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4958, 0.5042], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,039][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0287, 0.9713], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,039][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9354, 0.0646], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,039][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2597, 0.7403], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,040][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0580, 0.9420], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,040][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5458, 0.4542], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,040][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1024, 0.8976], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,041][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.1738, 0.1397, 0.6865], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,041][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([0.0583, 0.1670, 0.7747], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,041][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.6155, 0.2761, 0.1084], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,045][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.4836, 0.3403, 0.1761], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,050][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.2446, 0.6303, 0.1251], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,054][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([0.3432, 0.3273, 0.3295], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,055][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.0174, 0.4729, 0.5097], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,055][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.4507, 0.1086, 0.4406], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,055][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.1829, 0.4809, 0.3362], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,056][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.0318, 0.4834, 0.4848], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,056][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.3820, 0.2829, 0.3351], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,056][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.0986, 0.2138, 0.6877], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,057][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0464, 0.1939, 0.6396, 0.1201], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,057][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0020, 0.0733, 0.4301, 0.4946], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,060][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5016, 0.2376, 0.1230, 0.1378], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,065][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.7913, 0.0910, 0.0599, 0.0578], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,070][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3623, 0.0865, 0.0468, 0.5044], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,071][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.2077, 0.2212, 0.2224, 0.3487], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,071][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0090, 0.2948, 0.3218, 0.3743], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,072][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.4480, 0.0328, 0.4747, 0.0445], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,072][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1136, 0.3091, 0.3051, 0.2722], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,072][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0226, 0.3164, 0.3223, 0.3387], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,073][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2783, 0.2130, 0.2541, 0.2546], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,073][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0529, 0.1397, 0.2582, 0.5493], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,073][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0069, 0.0055, 0.0859, 0.0240, 0.8777], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,076][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.2987, 0.0963, 0.2817, 0.2246, 0.0986], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,081][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.4853, 0.1687, 0.0884, 0.2149, 0.0428], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,087][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.2991, 0.2605, 0.1125, 0.2053, 0.1226], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,087][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.1300, 0.1374, 0.0355, 0.6400, 0.0571], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,087][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.1957, 0.1994, 0.1880, 0.2695, 0.1474], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,088][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0079, 0.2105, 0.2308, 0.2662, 0.2846], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,088][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.2395, 0.0076, 0.5023, 0.0479, 0.2028], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,088][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.1005, 0.2448, 0.1892, 0.2883, 0.1771], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,089][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0152, 0.2423, 0.2544, 0.2654, 0.2228], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,089][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.2178, 0.1700, 0.1898, 0.1980, 0.2244], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,089][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0542, 0.2579, 0.2196, 0.1520, 0.3164], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,093][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0142, 0.0478, 0.2610, 0.0406, 0.5597, 0.0768], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,098][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0140, 0.0497, 0.6164, 0.2773, 0.0099, 0.0326], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,103][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4546, 0.1724, 0.0862, 0.1311, 0.0522, 0.1036], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,103][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.4341, 0.0856, 0.0653, 0.0627, 0.1030, 0.2493], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,103][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.4198, 0.0342, 0.0168, 0.2050, 0.0367, 0.2876], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,104][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1365, 0.1619, 0.1495, 0.2340, 0.1142, 0.2038], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,104][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0053, 0.1602, 0.1714, 0.2011, 0.2147, 0.2472], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,104][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.3364, 0.0146, 0.2588, 0.0732, 0.3043, 0.0128], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,105][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0735, 0.1937, 0.1713, 0.2197, 0.1866, 0.1552], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,105][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0157, 0.1938, 0.2027, 0.2106, 0.1823, 0.1948], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,106][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1841, 0.1424, 0.1559, 0.1581, 0.1835, 0.1759], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,106][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1226, 0.1176, 0.2127, 0.1852, 0.1566, 0.2052], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,109][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0588, 0.0236, 0.1363, 0.0142, 0.6650, 0.0335, 0.0686],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,113][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0185, 0.0782, 0.5204, 0.1034, 0.0192, 0.0435, 0.2168],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,119][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3042, 0.1700, 0.0911, 0.1525, 0.0528, 0.1192, 0.1102],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,120][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.3983, 0.0610, 0.0419, 0.0531, 0.0783, 0.2626, 0.1049],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,120][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2114, 0.0065, 0.0077, 0.0733, 0.0192, 0.4869, 0.1949],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,120][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1068, 0.1466, 0.1290, 0.1947, 0.0961, 0.1683, 0.1585],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,121][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0037, 0.1285, 0.1400, 0.1644, 0.1774, 0.2080, 0.1780],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,121][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0892, 0.0258, 0.4349, 0.0485, 0.2209, 0.1404, 0.0403],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,121][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0564, 0.1661, 0.1402, 0.1893, 0.1488, 0.1730, 0.1263],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,122][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0130, 0.1620, 0.1663, 0.1733, 0.1489, 0.1616, 0.1748],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,125][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1649, 0.1220, 0.1322, 0.1314, 0.1618, 0.1589, 0.1287],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,131][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0892, 0.0769, 0.2004, 0.1033, 0.0692, 0.0383, 0.4227],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,135][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0359, 0.0448, 0.1135, 0.0109, 0.2690, 0.0164, 0.0394, 0.4701],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,136][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0259, 0.0177, 0.2361, 0.1687, 0.0358, 0.0626, 0.3873, 0.0658],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,136][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.3472, 0.1211, 0.0611, 0.1156, 0.0402, 0.0817, 0.1058, 0.1273],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,136][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.2820, 0.0762, 0.0431, 0.0639, 0.0748, 0.2002, 0.1386, 0.1213],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,137][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.1146, 0.0036, 0.0030, 0.0537, 0.0162, 0.3511, 0.1750, 0.2829],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,137][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0974, 0.1180, 0.1092, 0.1522, 0.0928, 0.1467, 0.1453, 0.1385],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,138][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0052, 0.1157, 0.1253, 0.1443, 0.1526, 0.1747, 0.1550, 0.1272],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,138][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.2458, 0.0033, 0.2824, 0.0169, 0.3886, 0.0390, 0.0146, 0.0095],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,138][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0599, 0.1294, 0.1254, 0.1528, 0.1390, 0.1360, 0.1375, 0.1200],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,139][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.0112, 0.1382, 0.1448, 0.1511, 0.1290, 0.1410, 0.1518, 0.1329],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,142][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.1671, 0.1094, 0.1158, 0.1182, 0.1455, 0.1384, 0.1123, 0.0933],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,146][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0215, 0.0344, 0.1346, 0.0953, 0.0255, 0.0366, 0.2583, 0.3937],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,152][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0734, 0.0120, 0.0643, 0.0103, 0.3117, 0.0283, 0.0394, 0.4448, 0.0158],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,153][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0057, 0.0190, 0.1109, 0.0722, 0.0052, 0.0223, 0.1523, 0.0771, 0.5354],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,153][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.2386, 0.1216, 0.0594, 0.0965, 0.0365, 0.0929, 0.0950, 0.1851, 0.0745],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,153][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.3718, 0.0412, 0.0388, 0.0362, 0.0677, 0.1844, 0.0989, 0.1040, 0.0569],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,154][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.1657, 0.0009, 0.0028, 0.0174, 0.0087, 0.2145, 0.1437, 0.1081, 0.3383],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,154][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0934, 0.1013, 0.0948, 0.1271, 0.0777, 0.1309, 0.1345, 0.1197, 0.1206],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,155][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0046, 0.1016, 0.1090, 0.1254, 0.1329, 0.1530, 0.1348, 0.1110, 0.1278],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,158][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0250, 0.0038, 0.1232, 0.0134, 0.2994, 0.0158, 0.0180, 0.4785, 0.0229],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,164][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0458, 0.1083, 0.1158, 0.1150, 0.1227, 0.1210, 0.1215, 0.1350, 0.1150],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,168][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0094, 0.1222, 0.1283, 0.1333, 0.1142, 0.1251, 0.1340, 0.1184, 0.1151],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,169][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.1522, 0.1008, 0.1057, 0.1079, 0.1312, 0.1248, 0.1029, 0.0867, 0.0879],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,169][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0237, 0.0538, 0.1982, 0.1712, 0.0387, 0.0273, 0.1614, 0.1407, 0.1849],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,169][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0138, 0.0123, 0.0627, 0.0094, 0.2271, 0.0186, 0.0375, 0.3719, 0.0211,
        0.2256], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,170][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0056, 0.0127, 0.0876, 0.0336, 0.0107, 0.0625, 0.1696, 0.1748, 0.3471,
        0.0959], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,170][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.2091, 0.1198, 0.0559, 0.1053, 0.0258, 0.0831, 0.0949, 0.1500, 0.1169,
        0.0391], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,171][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.1802, 0.0668, 0.0497, 0.0476, 0.0604, 0.1814, 0.1424, 0.1234, 0.0915,
        0.0567], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,171][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.1697, 0.0026, 0.0024, 0.0336, 0.0144, 0.0817, 0.0778, 0.0479, 0.3360,
        0.2338], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,171][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0883, 0.0841, 0.0876, 0.1116, 0.0809, 0.1269, 0.1166, 0.1066, 0.1095,
        0.0880], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,173][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0045, 0.0921, 0.0989, 0.1147, 0.1197, 0.1374, 0.1222, 0.0994, 0.1167,
        0.0943], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,179][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.2023, 0.0070, 0.2388, 0.0535, 0.0844, 0.0155, 0.1802, 0.0358, 0.0575,
        0.1249], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,184][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0428, 0.0994, 0.0922, 0.1079, 0.1043, 0.1083, 0.1112, 0.1120, 0.1498,
        0.0721], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,185][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0079, 0.1089, 0.1161, 0.1205, 0.1024, 0.1117, 0.1205, 0.1061, 0.1051,
        0.1009], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,186][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1451, 0.0941, 0.0978, 0.1010, 0.1201, 0.1125, 0.0947, 0.0788, 0.0807,
        0.0753], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,186][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0387, 0.0720, 0.1108, 0.1183, 0.0586, 0.0215, 0.0914, 0.1195, 0.0985,
        0.2708], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,187][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0340, 0.0148, 0.0696, 0.0091, 0.3154, 0.0238, 0.0266, 0.3889, 0.0105,
        0.1010, 0.0064], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,187][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0016, 0.0509, 0.2241, 0.0630, 0.0166, 0.0209, 0.1505, 0.0785, 0.2903,
        0.0333, 0.0702], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,187][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1788, 0.1116, 0.0525, 0.0892, 0.0297, 0.0887, 0.0977, 0.1314, 0.0994,
        0.0459, 0.0750], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,188][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.3537, 0.0468, 0.0297, 0.0367, 0.0589, 0.1756, 0.0774, 0.0819, 0.0525,
        0.0559, 0.0310], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,189][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ at] are: tensor([2.4724e-01, 1.4743e-04, 1.5137e-04, 5.6597e-04, 1.1736e-04, 4.5952e-03,
        2.6290e-03, 5.1416e-04, 1.0813e-02, 5.9849e-04, 7.3263e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,195][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0668, 0.0816, 0.0821, 0.1165, 0.0694, 0.1132, 0.1074, 0.0929, 0.0945,
        0.0701, 0.1055], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,199][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0027, 0.0793, 0.0863, 0.0998, 0.1070, 0.1238, 0.1073, 0.0919, 0.1056,
        0.0856, 0.1107], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,201][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0716, 0.0052, 0.1473, 0.0324, 0.1039, 0.0483, 0.0807, 0.2017, 0.0244,
        0.2387, 0.0459], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,202][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0380, 0.0805, 0.0885, 0.0984, 0.1015, 0.1040, 0.1044, 0.1165, 0.1094,
        0.0916, 0.0672], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,202][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0082, 0.1002, 0.1029, 0.1078, 0.0929, 0.0993, 0.1073, 0.0975, 0.0951,
        0.0906, 0.0983], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,202][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1093, 0.0847, 0.0874, 0.0902, 0.1079, 0.1060, 0.0883, 0.0778, 0.0784,
        0.0733, 0.0968], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,203][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0167, 0.0475, 0.1065, 0.1061, 0.0368, 0.0331, 0.2394, 0.1062, 0.0819,
        0.0700, 0.1559], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,203][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1374, 0.0153, 0.0717, 0.0069, 0.4291, 0.0177, 0.0167, 0.2444, 0.0056,
        0.0505, 0.0023, 0.0025], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,203][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0021, 0.0217, 0.1321, 0.0765, 0.0081, 0.0155, 0.1737, 0.0520, 0.3020,
        0.0256, 0.0689, 0.1216], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,204][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1349, 0.1093, 0.0455, 0.0800, 0.0273, 0.0768, 0.0742, 0.1339, 0.0893,
        0.0514, 0.0942, 0.0832], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,204][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.3033, 0.0453, 0.0259, 0.0346, 0.0460, 0.1867, 0.0717, 0.0769, 0.0495,
        0.0580, 0.0393, 0.0627], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,204][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ the] are: tensor([1.4056e-01, 5.2180e-05, 6.2348e-05, 2.1933e-04, 3.8639e-05, 2.0603e-03,
        8.3204e-04, 1.3632e-04, 5.2993e-03, 2.0605e-04, 6.4970e-01, 2.0083e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,206][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0633, 0.0777, 0.0725, 0.1059, 0.0598, 0.0959, 0.0936, 0.0838, 0.0853,
        0.0644, 0.0993, 0.0984], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,212][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0019, 0.0717, 0.0791, 0.0915, 0.1004, 0.1161, 0.0990, 0.0826, 0.0949,
        0.0754, 0.0999, 0.0875], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,216][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0700, 0.0077, 0.0977, 0.0212, 0.1540, 0.0268, 0.0163, 0.1280, 0.0907,
        0.2459, 0.1126, 0.0291], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,218][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0273, 0.0774, 0.0695, 0.0886, 0.0803, 0.0907, 0.0826, 0.1075, 0.1119,
        0.0886, 0.0973, 0.0783], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,219][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0070, 0.0914, 0.0935, 0.0982, 0.0841, 0.0911, 0.0990, 0.0882, 0.0862,
        0.0821, 0.0886, 0.0908], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,219][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0908, 0.0764, 0.0803, 0.0804, 0.0978, 0.0967, 0.0782, 0.0730, 0.0731,
        0.0705, 0.0860, 0.0969], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,219][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0309, 0.0553, 0.1416, 0.0967, 0.0333, 0.0226, 0.2110, 0.0941, 0.0501,
        0.0682, 0.0605, 0.1358], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,220][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.2430, 0.0244, 0.0675, 0.0125, 0.2249, 0.0213, 0.0234, 0.1609, 0.0114,
        0.1182, 0.0046, 0.0117, 0.0760], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,220][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0027, 0.0171, 0.0380, 0.1104, 0.0063, 0.0202, 0.2330, 0.0387, 0.2970,
        0.0303, 0.0755, 0.1087, 0.0221], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,220][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.2029, 0.0899, 0.0353, 0.0735, 0.0179, 0.0735, 0.0649, 0.0967, 0.0738,
        0.0382, 0.0810, 0.0982, 0.0541], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,221][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.1687, 0.0629, 0.0262, 0.0526, 0.0413, 0.1337, 0.0894, 0.0657, 0.0693,
        0.0522, 0.0485, 0.1014, 0.0882], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,222][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ store] are: tensor([3.3265e-02, 1.0770e-04, 3.4368e-05, 2.6315e-04, 2.4518e-05, 5.2468e-04,
        4.9454e-04, 6.4822e-05, 3.2702e-03, 5.9828e-05, 6.4193e-01, 3.0216e-01,
        1.7807e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,228][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0659, 0.0709, 0.0686, 0.0905, 0.0615, 0.0945, 0.0823, 0.0755, 0.0770,
        0.0642, 0.0843, 0.0837, 0.0812], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,232][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0026, 0.0679, 0.0737, 0.0861, 0.0910, 0.1043, 0.0916, 0.0758, 0.0891,
        0.0701, 0.0927, 0.0827, 0.0724], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,234][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0480, 0.0009, 0.1213, 0.0100, 0.1129, 0.0071, 0.0113, 0.0320, 0.0251,
        0.5062, 0.0916, 0.0178, 0.0159], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,235][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0332, 0.0756, 0.0720, 0.0808, 0.0815, 0.0773, 0.0820, 0.0783, 0.1001,
        0.0774, 0.0820, 0.0957, 0.0642], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,235][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.0076, 0.0821, 0.0867, 0.0897, 0.0774, 0.0832, 0.0901, 0.0797, 0.0794,
        0.0750, 0.0818, 0.0833, 0.0840], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,235][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0996, 0.0700, 0.0714, 0.0752, 0.0885, 0.0848, 0.0704, 0.0630, 0.0637,
        0.0599, 0.0779, 0.0903, 0.0852], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,236][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0296, 0.0455, 0.0746, 0.0843, 0.0324, 0.0241, 0.1384, 0.0671, 0.0811,
        0.1042, 0.0481, 0.0735, 0.1970], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,236][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1334, 0.0201, 0.0768, 0.0085, 0.3763, 0.0180, 0.0233, 0.2217, 0.0078,
        0.0756, 0.0044, 0.0057, 0.0259, 0.0026], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,236][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0026, 0.0422, 0.0908, 0.2285, 0.0026, 0.0170, 0.0832, 0.0259, 0.2758,
        0.0061, 0.0422, 0.0937, 0.0164, 0.0732], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,237][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1399, 0.0789, 0.0379, 0.0555, 0.0183, 0.0690, 0.0601, 0.1235, 0.0831,
        0.0289, 0.0693, 0.1084, 0.0879, 0.0394], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,237][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.1854, 0.0299, 0.0321, 0.0241, 0.0618, 0.1556, 0.0835, 0.0908, 0.0341,
        0.0555, 0.0356, 0.0650, 0.1227, 0.0241], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,238][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [.] are: tensor([3.1032e-02, 4.3678e-05, 6.4734e-05, 3.7048e-04, 8.9418e-05, 2.4508e-03,
        2.0170e-03, 4.5820e-04, 6.4370e-03, 1.5386e-03, 4.7508e-01, 3.6719e-01,
        4.1215e-02, 7.2011e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,243][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0549, 0.0644, 0.0599, 0.0867, 0.0494, 0.0842, 0.0771, 0.0726, 0.0718,
        0.0577, 0.0817, 0.0839, 0.0776, 0.0780], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,249][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0025, 0.0615, 0.0679, 0.0788, 0.0839, 0.0972, 0.0846, 0.0716, 0.0838,
        0.0674, 0.0865, 0.0760, 0.0681, 0.0702], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,251][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0612, 0.0037, 0.1417, 0.0218, 0.2793, 0.0128, 0.0486, 0.0928, 0.0440,
        0.0838, 0.0912, 0.0750, 0.0251, 0.0191], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,251][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0244, 0.0610, 0.0670, 0.0709, 0.0761, 0.0731, 0.0798, 0.0876, 0.0821,
        0.0739, 0.0732, 0.0896, 0.0809, 0.0603], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,251][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0060, 0.0760, 0.0807, 0.0835, 0.0714, 0.0774, 0.0841, 0.0731, 0.0727,
        0.0695, 0.0765, 0.0776, 0.0785, 0.0730], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,252][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1037, 0.0651, 0.0649, 0.0696, 0.0812, 0.0783, 0.0663, 0.0566, 0.0564,
        0.0526, 0.0733, 0.0865, 0.0799, 0.0655], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,252][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0111, 0.0740, 0.0755, 0.1711, 0.0212, 0.0163, 0.1080, 0.0628, 0.0793,
        0.0545, 0.0461, 0.0457, 0.0392, 0.1952], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,253][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0618, 0.0033, 0.0310, 0.0059, 0.4606, 0.0066, 0.0136, 0.0897, 0.0298,
        0.0859, 0.0034, 0.0051, 0.0215, 0.0032, 0.1787], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,253][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0503, 0.0064, 0.0412, 0.0265, 0.0302, 0.0273, 0.0878, 0.0719, 0.1533,
        0.0477, 0.1505, 0.1168, 0.0411, 0.0877, 0.0614], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,253][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.1661, 0.0672, 0.0318, 0.0917, 0.0119, 0.0528, 0.0570, 0.0990, 0.0856,
        0.0294, 0.0667, 0.0857, 0.0707, 0.0692, 0.0155], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,254][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0768, 0.0486, 0.0239, 0.0383, 0.0234, 0.1246, 0.0745, 0.0782, 0.0645,
        0.0467, 0.0536, 0.1286, 0.1296, 0.0644, 0.0242], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,255][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([1.0992e-02, 2.7365e-05, 2.6333e-05, 1.2945e-04, 2.2442e-05, 5.3955e-04,
        2.5406e-04, 5.0330e-05, 9.5773e-04, 1.3343e-04, 5.8163e-01, 3.0617e-01,
        6.7966e-02, 2.2261e-02, 8.8389e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,261][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.0590, 0.0623, 0.0597, 0.0803, 0.0530, 0.0792, 0.0700, 0.0659, 0.0651,
        0.0576, 0.0708, 0.0717, 0.0696, 0.0700, 0.0656], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,266][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0022, 0.0591, 0.0645, 0.0758, 0.0789, 0.0927, 0.0802, 0.0654, 0.0776,
        0.0612, 0.0806, 0.0731, 0.0643, 0.0668, 0.0576], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,267][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.1580, 0.0027, 0.2106, 0.0178, 0.0901, 0.0082, 0.0242, 0.0218, 0.0644,
        0.1013, 0.0616, 0.0259, 0.0387, 0.0328, 0.1419], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,268][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.0259, 0.0621, 0.0458, 0.0732, 0.0421, 0.0635, 0.0669, 0.0839, 0.0916,
        0.0541, 0.0887, 0.0907, 0.0748, 0.0944, 0.0422], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,268][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0043, 0.0717, 0.0771, 0.0797, 0.0664, 0.0730, 0.0794, 0.0693, 0.0682,
        0.0648, 0.0720, 0.0730, 0.0752, 0.0687, 0.0572], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,268][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0924, 0.0596, 0.0599, 0.0658, 0.0751, 0.0738, 0.0629, 0.0534, 0.0544,
        0.0500, 0.0695, 0.0822, 0.0740, 0.0607, 0.0664], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,269][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0112, 0.0804, 0.0717, 0.0514, 0.0711, 0.0164, 0.0799, 0.0426, 0.0595,
        0.0629, 0.0375, 0.0597, 0.0756, 0.1541, 0.1260], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,269][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1220, 0.0038, 0.0249, 0.0022, 0.1438, 0.0086, 0.0180, 0.1547, 0.0098,
        0.0934, 0.0077, 0.0096, 0.0377, 0.0035, 0.2935, 0.0669],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,269][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0337, 0.0109, 0.1235, 0.0497, 0.0220, 0.0208, 0.0699, 0.0352, 0.1541,
        0.0314, 0.0762, 0.0746, 0.0838, 0.1201, 0.0533, 0.0408],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,270][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1237, 0.0813, 0.0394, 0.0603, 0.0153, 0.0588, 0.0577, 0.0998, 0.0699,
        0.0416, 0.0715, 0.0933, 0.0691, 0.0548, 0.0207, 0.0426],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,270][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.1716, 0.0381, 0.0186, 0.0254, 0.0291, 0.1132, 0.0778, 0.0705, 0.0461,
        0.0382, 0.0335, 0.1057, 0.0723, 0.0425, 0.0302, 0.0871],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,271][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([3.9747e-01, 9.2298e-05, 4.5169e-05, 1.3031e-04, 1.2385e-05, 3.1332e-04,
        2.2459e-04, 3.0719e-05, 7.7341e-04, 7.6095e-06, 7.5522e-02, 3.6535e-02,
        3.1858e-03, 1.6377e-02, 1.3792e-03, 4.6790e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,274][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0617, 0.0588, 0.0550, 0.0741, 0.0475, 0.0727, 0.0648, 0.0592, 0.0621,
        0.0502, 0.0644, 0.0635, 0.0631, 0.0639, 0.0592, 0.0799],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,278][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0014, 0.0553, 0.0592, 0.0691, 0.0745, 0.0867, 0.0748, 0.0641, 0.0742,
        0.0585, 0.0761, 0.0672, 0.0601, 0.0622, 0.0535, 0.0631],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,284][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.1122, 0.0027, 0.0461, 0.0090, 0.0766, 0.0098, 0.0262, 0.1819, 0.0541,
        0.1875, 0.0612, 0.0189, 0.0100, 0.0470, 0.1437, 0.0131],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,285][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0226, 0.0587, 0.0530, 0.0656, 0.0618, 0.0561, 0.0618, 0.0762, 0.0801,
        0.0610, 0.0814, 0.0797, 0.0611, 0.0739, 0.0670, 0.0399],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,285][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0053, 0.0675, 0.0713, 0.0738, 0.0633, 0.0682, 0.0735, 0.0653, 0.0639,
        0.0607, 0.0671, 0.0679, 0.0714, 0.0664, 0.0558, 0.0586],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,285][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0753, 0.0547, 0.0572, 0.0599, 0.0718, 0.0687, 0.0576, 0.0517, 0.0532,
        0.0486, 0.0641, 0.0757, 0.0714, 0.0595, 0.0667, 0.0639],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,286][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0133, 0.0363, 0.0906, 0.0960, 0.0214, 0.0462, 0.1651, 0.0550, 0.0481,
        0.0491, 0.0421, 0.0815, 0.0608, 0.0709, 0.0255, 0.0982],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,286][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1066, 0.0023, 0.0109, 0.0009, 0.1141, 0.0049, 0.0133, 0.3755, 0.0085,
        0.0796, 0.0062, 0.0072, 0.0224, 0.0018, 0.1841, 0.0297, 0.0320],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,286][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0030, 0.0191, 0.0846, 0.0295, 0.0100, 0.0135, 0.0886, 0.0438, 0.1550,
        0.0307, 0.0583, 0.1239, 0.0140, 0.0541, 0.0149, 0.0680, 0.1892],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,290][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1090, 0.0760, 0.0389, 0.0635, 0.0178, 0.0600, 0.0412, 0.1064, 0.0630,
        0.0394, 0.0636, 0.0676, 0.0815, 0.0614, 0.0234, 0.0504, 0.0368],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,294][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1831, 0.0296, 0.0165, 0.0222, 0.0311, 0.1148, 0.0401, 0.0576, 0.0399,
        0.0414, 0.0297, 0.0563, 0.1023, 0.0326, 0.0338, 0.1213, 0.0478],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,298][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([8.2296e-02, 9.5231e-06, 1.2974e-05, 3.6539e-05, 6.4656e-06, 3.3501e-04,
        1.0787e-04, 4.0883e-05, 1.0035e-03, 3.8124e-05, 6.5734e-02, 2.9226e-02,
        3.4390e-03, 1.0478e-02, 1.3352e-03, 5.1648e-01, 2.8942e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,300][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0491, 0.0563, 0.0489, 0.0706, 0.0399, 0.0630, 0.0622, 0.0555, 0.0576,
        0.0433, 0.0660, 0.0672, 0.0598, 0.0594, 0.0570, 0.0749, 0.0693],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,301][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0010, 0.0510, 0.0549, 0.0657, 0.0708, 0.0846, 0.0715, 0.0602, 0.0704,
        0.0548, 0.0730, 0.0631, 0.0558, 0.0587, 0.0492, 0.0591, 0.0563],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,301][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0242, 0.0051, 0.1050, 0.0106, 0.0574, 0.0320, 0.0073, 0.0885, 0.0315,
        0.0626, 0.0532, 0.0191, 0.0395, 0.0462, 0.0982, 0.3056, 0.0142],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,301][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0183, 0.0597, 0.0479, 0.0694, 0.0502, 0.0652, 0.0428, 0.0768, 0.0803,
        0.0581, 0.0703, 0.0725, 0.0616, 0.0760, 0.0505, 0.0622, 0.0383],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,302][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0048, 0.0638, 0.0664, 0.0692, 0.0586, 0.0636, 0.0691, 0.0621, 0.0609,
        0.0576, 0.0636, 0.0644, 0.0676, 0.0629, 0.0515, 0.0549, 0.0589],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,302][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0748, 0.0520, 0.0541, 0.0555, 0.0689, 0.0664, 0.0537, 0.0481, 0.0488,
        0.0454, 0.0606, 0.0720, 0.0680, 0.0553, 0.0641, 0.0613, 0.0512],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,302][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0218, 0.0299, 0.0881, 0.0497, 0.0176, 0.0108, 0.1843, 0.0526, 0.0230,
        0.0552, 0.0452, 0.0680, 0.0581, 0.0428, 0.0211, 0.0355, 0.1963],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,303][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.1316, 0.0059, 0.0231, 0.0051, 0.1511, 0.0120, 0.0379, 0.1368, 0.0210,
        0.1054, 0.0124, 0.0173, 0.0259, 0.0041, 0.1552, 0.0450, 0.0372, 0.0729],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,303][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0019, 0.0009, 0.0096, 0.0127, 0.0021, 0.0045, 0.0320, 0.0086, 0.0839,
        0.0321, 0.0449, 0.0479, 0.0261, 0.0244, 0.0061, 0.0139, 0.0848, 0.5637],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,305][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.1122, 0.0598, 0.0251, 0.0634, 0.0100, 0.0484, 0.0511, 0.0865, 0.0767,
        0.0313, 0.0582, 0.0740, 0.0502, 0.0595, 0.0119, 0.0508, 0.0603, 0.0706],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,307][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.0970, 0.0326, 0.0188, 0.0254, 0.0240, 0.0952, 0.0677, 0.0505, 0.0496,
        0.0384, 0.0342, 0.0996, 0.0781, 0.0487, 0.0261, 0.1132, 0.0882, 0.0128],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,307][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([8.3156e-03, 2.0653e-06, 2.7346e-06, 9.6244e-06, 1.8949e-06, 5.2123e-05,
        3.0109e-05, 5.8271e-06, 1.2311e-04, 5.9483e-06, 3.7839e-02, 3.4261e-02,
        2.6760e-03, 4.3109e-03, 1.2389e-03, 5.7521e-01, 3.0709e-01, 2.8821e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,307][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0563, 0.0525, 0.0482, 0.0605, 0.0431, 0.0596, 0.0580, 0.0516, 0.0555,
        0.0439, 0.0564, 0.0570, 0.0571, 0.0574, 0.0544, 0.0696, 0.0640, 0.0547],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,308][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0014, 0.0502, 0.0535, 0.0630, 0.0669, 0.0778, 0.0677, 0.0559, 0.0663,
        0.0521, 0.0689, 0.0616, 0.0535, 0.0565, 0.0476, 0.0560, 0.0548, 0.0463],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,312][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0540, 0.0006, 0.1253, 0.0039, 0.0595, 0.0061, 0.0078, 0.0069, 0.0134,
        0.0707, 0.0566, 0.0105, 0.0267, 0.0090, 0.1130, 0.0640, 0.0191, 0.3527],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,317][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0278, 0.0514, 0.0490, 0.0537, 0.0482, 0.0545, 0.0567, 0.0620, 0.0664,
        0.0547, 0.0646, 0.0664, 0.0591, 0.0599, 0.0508, 0.0573, 0.0608, 0.0568],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,319][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.0058, 0.0592, 0.0623, 0.0637, 0.0555, 0.0598, 0.0639, 0.0580, 0.0568,
        0.0548, 0.0597, 0.0599, 0.0616, 0.0579, 0.0495, 0.0528, 0.0557, 0.0629],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,319][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0737, 0.0503, 0.0522, 0.0541, 0.0653, 0.0627, 0.0516, 0.0452, 0.0460,
        0.0433, 0.0570, 0.0675, 0.0631, 0.0522, 0.0595, 0.0569, 0.0480, 0.0515],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,319][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0125, 0.0399, 0.1252, 0.0491, 0.0425, 0.0204, 0.0822, 0.0489, 0.0410,
        0.0695, 0.0438, 0.0543, 0.0869, 0.0593, 0.0505, 0.0272, 0.0765, 0.0703],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,320][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0620, 0.0032, 0.0091, 0.0009, 0.0897, 0.0036, 0.0135, 0.2980, 0.0073,
        0.0694, 0.0032, 0.0081, 0.0338, 0.0027, 0.2262, 0.0271, 0.0468, 0.0600,
        0.0354], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,320][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0026, 0.0099, 0.0431, 0.0318, 0.0048, 0.0058, 0.0624, 0.0215, 0.1612,
        0.0125, 0.0401, 0.0865, 0.0163, 0.0421, 0.0081, 0.0268, 0.1307, 0.1099,
        0.1839], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,321][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0848, 0.0597, 0.0387, 0.0416, 0.0153, 0.0473, 0.0484, 0.0977, 0.0580,
        0.0338, 0.0499, 0.0705, 0.0781, 0.0438, 0.0208, 0.0443, 0.0477, 0.0825,
        0.0369], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,321][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.2559, 0.0299, 0.0123, 0.0174, 0.0232, 0.1036, 0.0440, 0.0488, 0.0274,
        0.0317, 0.0217, 0.0403, 0.0791, 0.0273, 0.0238, 0.1013, 0.0523, 0.0113,
        0.0487], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,322][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([1.0794e-01, 4.3389e-06, 6.5871e-06, 1.2380e-05, 2.1703e-06, 1.6836e-04,
        7.8594e-05, 1.4569e-05, 2.8204e-04, 1.0635e-05, 1.4108e-02, 9.6103e-03,
        8.5810e-04, 3.1195e-03, 2.9953e-04, 1.5908e-01, 1.3115e-01, 1.0418e-02,
        5.6283e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,328][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0500, 0.0484, 0.0435, 0.0600, 0.0371, 0.0555, 0.0561, 0.0493, 0.0519,
        0.0394, 0.0567, 0.0572, 0.0531, 0.0504, 0.0493, 0.0630, 0.0603, 0.0543,
        0.0644], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,333][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0010, 0.0452, 0.0490, 0.0577, 0.0631, 0.0730, 0.0629, 0.0536, 0.0609,
        0.0483, 0.0635, 0.0549, 0.0491, 0.0521, 0.0449, 0.0519, 0.0506, 0.0451,
        0.0732], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,334][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0359, 0.0008, 0.0530, 0.0024, 0.1039, 0.0048, 0.0122, 0.0538, 0.0074,
        0.0328, 0.0247, 0.0218, 0.0204, 0.0186, 0.2293, 0.0751, 0.0309, 0.2536,
        0.0184], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,335][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0174, 0.0471, 0.0430, 0.0514, 0.0475, 0.0537, 0.0534, 0.0649, 0.0594,
        0.0560, 0.0515, 0.0673, 0.0518, 0.0533, 0.0498, 0.0519, 0.0579, 0.0699,
        0.0530], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,335][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0046, 0.0563, 0.0592, 0.0612, 0.0526, 0.0565, 0.0609, 0.0549, 0.0534,
        0.0515, 0.0560, 0.0567, 0.0578, 0.0539, 0.0457, 0.0491, 0.0526, 0.0596,
        0.0573], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,336][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0663, 0.0477, 0.0485, 0.0516, 0.0599, 0.0589, 0.0503, 0.0440, 0.0448,
        0.0413, 0.0558, 0.0644, 0.0590, 0.0495, 0.0548, 0.0551, 0.0478, 0.0498,
        0.0506], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,336][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0147, 0.0403, 0.0757, 0.0888, 0.0172, 0.0125, 0.0876, 0.0539, 0.0444,
        0.0430, 0.0534, 0.0411, 0.0474, 0.0765, 0.0205, 0.0382, 0.0925, 0.0345,
        0.1176], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,367][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:20,369][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,370][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,370][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,370][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,371][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,371][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,371][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,372][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,372][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,372][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,373][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,373][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,373][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1061, 0.8939], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,374][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1335, 0.8665], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,374][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7904, 0.2096], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,374][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5661, 0.4339], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,375][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9623, 0.0377], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,375][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9466, 0.0534], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,375][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.7599, 0.2401], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,376][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8127, 0.1873], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,378][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8819, 0.1181], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,381][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7969, 0.2031], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,381][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9944, 0.0056], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,381][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4917, 0.5083], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,382][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.1287, 0.5481, 0.3232], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,382][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([0.0095, 0.6754, 0.3152], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,382][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.6925, 0.1981, 0.1093], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,383][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.5851, 0.1366, 0.2783], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,386][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.8331, 0.1321, 0.0348], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,390][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.8003, 0.0848, 0.1149], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,390][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.7259, 0.1029, 0.1711], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,390][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.2342, 0.0909, 0.6749], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,391][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.8935, 0.0660, 0.0404], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,391][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.6413, 0.1691, 0.1895], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,391][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.8227, 0.0325, 0.1448], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,392][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.4342, 0.2317, 0.3341], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,392][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0338, 0.1633, 0.2283, 0.5746], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,392][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0149, 0.0503, 0.8526, 0.0822], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,394][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6375, 0.1470, 0.0940, 0.1214], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,400][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6285, 0.0695, 0.1850, 0.1170], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,404][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7130, 0.0861, 0.1398, 0.0611], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,406][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8223, 0.0337, 0.0933, 0.0507], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,406][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4823, 0.0798, 0.2369, 0.2010], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,406][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2179, 0.0356, 0.6985, 0.0480], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,407][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7448, 0.1537, 0.0687, 0.0329], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,407][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5229, 0.1279, 0.1754, 0.1739], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,407][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9695, 0.0029, 0.0195, 0.0081], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,408][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1711, 0.0946, 0.0290, 0.7052], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,408][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.0676, 0.1923, 0.1250, 0.4480, 0.1671], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,408][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0024, 0.2486, 0.4951, 0.1690, 0.0848], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,409][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.5686, 0.1420, 0.0812, 0.1164, 0.0918], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,409][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.5509, 0.0529, 0.1384, 0.1320, 0.1259], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,409][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.5335, 0.1733, 0.0810, 0.1930, 0.0192], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,412][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.7087, 0.0593, 0.0780, 0.1224, 0.0316], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,417][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.8278, 0.0250, 0.0667, 0.0420, 0.0384], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,422][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.1059, 0.0039, 0.5887, 0.0301, 0.2714], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,423][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.8813, 0.0615, 0.0268, 0.0165, 0.0139], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,423][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.4351, 0.1290, 0.1663, 0.1471, 0.1226], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,423][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.7596, 0.0279, 0.0843, 0.0563, 0.0719], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,424][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.2304, 0.1658, 0.1098, 0.1416, 0.3524], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,424][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0301, 0.1125, 0.1763, 0.3808, 0.1593, 0.1412], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,424][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0663, 0.1285, 0.3563, 0.2070, 0.1156, 0.1263], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,425][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.5481, 0.1144, 0.0710, 0.0956, 0.0847, 0.0862], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,425][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.5064, 0.0403, 0.1026, 0.0777, 0.1240, 0.1490], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,428][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.8047, 0.0548, 0.0596, 0.0548, 0.0152, 0.0109], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,434][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.8735, 0.0158, 0.0345, 0.0264, 0.0361, 0.0138], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,438][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.4260, 0.0407, 0.1006, 0.1287, 0.1980, 0.1060], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,438][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0963, 0.0175, 0.3090, 0.0750, 0.4813, 0.0209], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,439][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.8062, 0.1209, 0.0310, 0.0211, 0.0145, 0.0063], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,439][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3648, 0.1023, 0.1405, 0.1282, 0.1418, 0.1224], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,439][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.9437, 0.0047, 0.0201, 0.0090, 0.0116, 0.0110], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,440][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0800, 0.0560, 0.0132, 0.0999, 0.0318, 0.7192], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,440][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0283, 0.1043, 0.1455, 0.3254, 0.1296, 0.1234, 0.1433],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,440][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0162, 0.1589, 0.2165, 0.1495, 0.0721, 0.3404, 0.0465],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,441][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.5170, 0.1044, 0.0625, 0.0836, 0.0761, 0.0791, 0.0772],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,441][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5345, 0.0200, 0.0802, 0.0514, 0.0924, 0.1342, 0.0874],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,441][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.6755, 0.1002, 0.0613, 0.0868, 0.0220, 0.0268, 0.0274],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,442][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.8135, 0.0157, 0.0479, 0.0319, 0.0346, 0.0286, 0.0279],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,445][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4996, 0.0255, 0.0784, 0.0651, 0.1208, 0.1186, 0.0920],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,451][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0505, 0.0176, 0.4465, 0.0381, 0.2816, 0.1313, 0.0344],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,455][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7489, 0.1372, 0.0396, 0.0254, 0.0148, 0.0054, 0.0287],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,455][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3772, 0.0913, 0.1136, 0.1087, 0.1089, 0.0989, 0.1014],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,455][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.9450, 0.0036, 0.0170, 0.0083, 0.0117, 0.0086, 0.0057],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,456][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1228, 0.0469, 0.0591, 0.1207, 0.0586, 0.1426, 0.4493],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,456][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0265, 0.1023, 0.1220, 0.2731, 0.1236, 0.1240, 0.1330, 0.0955],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,456][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0412, 0.1808, 0.1794, 0.1774, 0.1257, 0.1409, 0.0841, 0.0705],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,457][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.4903, 0.0918, 0.0585, 0.0766, 0.0754, 0.0733, 0.0723, 0.0618],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,457][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.5706, 0.0068, 0.0365, 0.0246, 0.0585, 0.0583, 0.0570, 0.1877],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,457][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.7442, 0.0631, 0.0542, 0.0606, 0.0164, 0.0185, 0.0274, 0.0157],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,458][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.8446, 0.0193, 0.0304, 0.0170, 0.0294, 0.0172, 0.0349, 0.0071],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,459][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.6298, 0.0054, 0.0198, 0.0180, 0.0312, 0.0351, 0.0615, 0.1992],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,465][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0975, 0.0030, 0.2422, 0.0153, 0.5588, 0.0497, 0.0142, 0.0192],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,469][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.7693, 0.1388, 0.0312, 0.0235, 0.0085, 0.0042, 0.0212, 0.0032],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,473][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.2705, 0.0920, 0.1160, 0.1042, 0.1158, 0.1032, 0.0966, 0.1017],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,473][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.9658, 0.0024, 0.0099, 0.0047, 0.0046, 0.0048, 0.0043, 0.0035],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,474][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0778, 0.0703, 0.0266, 0.0860, 0.0187, 0.1802, 0.1398, 0.4005],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,474][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0147, 0.0621, 0.1043, 0.2027, 0.0979, 0.0889, 0.0993, 0.0701, 0.2598],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,474][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0042, 0.0300, 0.2248, 0.0324, 0.0928, 0.2979, 0.0884, 0.1909, 0.0386],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,475][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.5507, 0.0793, 0.0447, 0.0564, 0.0572, 0.0584, 0.0559, 0.0521, 0.0454],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,475][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.4796, 0.0117, 0.0518, 0.0283, 0.0628, 0.0705, 0.0680, 0.1646, 0.0628],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,475][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.5641, 0.0787, 0.1119, 0.0660, 0.0325, 0.0278, 0.0566, 0.0297, 0.0327],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,479][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.8765, 0.0083, 0.0307, 0.0125, 0.0198, 0.0188, 0.0161, 0.0102, 0.0071],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,484][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.3092, 0.0071, 0.0192, 0.0166, 0.0277, 0.0289, 0.0530, 0.4768, 0.0615],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,489][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0187, 0.0021, 0.0809, 0.0075, 0.2795, 0.0122, 0.0109, 0.5701, 0.0180],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,489][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([9.1733e-01, 4.4771e-02, 1.3078e-02, 7.4581e-03, 4.5780e-03, 1.9905e-03,
        8.5622e-03, 1.6268e-03, 6.0909e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,489][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.3533, 0.0685, 0.0921, 0.0854, 0.1002, 0.0776, 0.0768, 0.0982, 0.0479],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,489][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.9588, 0.0023, 0.0118, 0.0042, 0.0076, 0.0050, 0.0032, 0.0026, 0.0045],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,490][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1226, 0.0434, 0.0214, 0.1916, 0.0346, 0.1485, 0.0669, 0.0738, 0.2974],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,490][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0084, 0.0996, 0.1346, 0.1779, 0.1041, 0.0843, 0.0909, 0.0561, 0.1851,
        0.0590], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,491][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0025, 0.0601, 0.2175, 0.0776, 0.0902, 0.1586, 0.1209, 0.1025, 0.0980,
        0.0719], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,491][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.4364, 0.0880, 0.0490, 0.0689, 0.0608, 0.0656, 0.0630, 0.0581, 0.0523,
        0.0579], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,491][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.3246, 0.0055, 0.0251, 0.0192, 0.0431, 0.0513, 0.0613, 0.1820, 0.0730,
        0.2148], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,493][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.4368, 0.1361, 0.0696, 0.1291, 0.0219, 0.0228, 0.0675, 0.0343, 0.0595,
        0.0224], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,499][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.6092, 0.0354, 0.0583, 0.0382, 0.0515, 0.0586, 0.0661, 0.0254, 0.0463,
        0.0111], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,503][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.3534, 0.0064, 0.0167, 0.0165, 0.0288, 0.0396, 0.0416, 0.3023, 0.1035,
        0.0911], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,505][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0819, 0.0058, 0.2529, 0.0535, 0.1146, 0.0159, 0.2284, 0.0811, 0.0741,
        0.0919], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,505][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([8.8360e-01, 6.7150e-02, 1.6244e-02, 9.5343e-03, 5.6108e-03, 2.1607e-03,
        1.0565e-02, 1.6329e-03, 5.7948e-04, 2.9192e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,505][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.3015, 0.0791, 0.0840, 0.0889, 0.0928, 0.0897, 0.0718, 0.1069, 0.0539,
        0.0315], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,506][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.7859, 0.0167, 0.0223, 0.0273, 0.0339, 0.0261, 0.0236, 0.0167, 0.0382,
        0.0092], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,506][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.1772, 0.0559, 0.0435, 0.0922, 0.0919, 0.0451, 0.0360, 0.1095, 0.1061,
        0.2425], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,506][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0055, 0.0662, 0.1530, 0.2235, 0.1005, 0.0883, 0.0829, 0.0347, 0.1668,
        0.0364, 0.0423], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,507][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0077, 0.0399, 0.1359, 0.0490, 0.1113, 0.1659, 0.1413, 0.1155, 0.1037,
        0.1194, 0.0105], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,507][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.3388, 0.0925, 0.0506, 0.0660, 0.0614, 0.0662, 0.0673, 0.0621, 0.0584,
        0.0555, 0.0812], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,510][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.3565, 0.0120, 0.0368, 0.0233, 0.0287, 0.0744, 0.0569, 0.1274, 0.0590,
        0.0976, 0.1274], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,515][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.6269, 0.0636, 0.0663, 0.0533, 0.0224, 0.0215, 0.0466, 0.0216, 0.0277,
        0.0297, 0.0206], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,520][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.4926, 0.0292, 0.0800, 0.0420, 0.0922, 0.0605, 0.0687, 0.0500, 0.0431,
        0.0277, 0.0140], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,521][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.3970, 0.0074, 0.0120, 0.0121, 0.0132, 0.0384, 0.0531, 0.1881, 0.0705,
        0.0674, 0.1409], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,521][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0262, 0.0028, 0.1674, 0.0219, 0.1276, 0.0402, 0.0630, 0.3419, 0.0179,
        0.1531, 0.0379], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,522][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([9.0438e-01, 5.3037e-02, 1.2965e-02, 7.9449e-03, 4.8694e-03, 1.7937e-03,
        1.0827e-02, 9.2156e-04, 3.6703e-04, 1.9293e-03, 9.6901e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,522][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.3071, 0.0625, 0.0927, 0.0784, 0.0903, 0.0680, 0.0775, 0.0907, 0.0467,
        0.0387, 0.0474], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,522][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.8038, 0.0106, 0.0300, 0.0197, 0.0283, 0.0227, 0.0212, 0.0199, 0.0260,
        0.0132, 0.0047], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,523][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0788, 0.0367, 0.0152, 0.1103, 0.0295, 0.1221, 0.1066, 0.0327, 0.1179,
        0.0371, 0.3130], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,523][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0063, 0.0628, 0.1268, 0.2020, 0.1175, 0.0886, 0.0786, 0.0343, 0.1760,
        0.0270, 0.0377, 0.0425], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,523][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0036, 0.0493, 0.0567, 0.0456, 0.0524, 0.3130, 0.0457, 0.1454, 0.1212,
        0.0853, 0.0661, 0.0157], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,525][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3378, 0.0801, 0.0452, 0.0626, 0.0569, 0.0599, 0.0594, 0.0559, 0.0537,
        0.0498, 0.0774, 0.0612], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,531][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4770, 0.0069, 0.0240, 0.0143, 0.0212, 0.0469, 0.0293, 0.0729, 0.0321,
        0.0440, 0.0902, 0.1413], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,535][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.5626, 0.0895, 0.0500, 0.0522, 0.0140, 0.0235, 0.0274, 0.0258, 0.0365,
        0.0284, 0.0435, 0.0466], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,537][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.5430, 0.0369, 0.0623, 0.0428, 0.0683, 0.0469, 0.0532, 0.0431, 0.0535,
        0.0191, 0.0164, 0.0146], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,537][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.4020, 0.0050, 0.0115, 0.0096, 0.0135, 0.0232, 0.0224, 0.1265, 0.0492,
        0.0351, 0.1677, 0.1345], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,538][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0408, 0.0049, 0.1034, 0.0139, 0.1961, 0.0274, 0.0158, 0.2221, 0.0735,
        0.1786, 0.0917, 0.0318], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,538][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([8.5997e-01, 7.7498e-02, 1.6141e-02, 1.1075e-02, 7.6756e-03, 2.8670e-03,
        1.4915e-02, 1.4266e-03, 6.6360e-04, 3.4637e-03, 1.9166e-03, 2.3904e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,538][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3106, 0.0607, 0.0789, 0.0736, 0.0680, 0.0602, 0.0718, 0.0869, 0.0471,
        0.0376, 0.0488, 0.0559], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,539][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.7800, 0.0106, 0.0344, 0.0212, 0.0356, 0.0257, 0.0213, 0.0173, 0.0276,
        0.0163, 0.0049, 0.0051], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,539][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0641, 0.0386, 0.0269, 0.0618, 0.0266, 0.1001, 0.1389, 0.0530, 0.0578,
        0.0235, 0.0426, 0.3660], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,540][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0147, 0.0757, 0.1085, 0.2005, 0.0872, 0.0771, 0.0697, 0.0382, 0.1580,
        0.0356, 0.0347, 0.0470, 0.0531], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,543][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0086, 0.0687, 0.1703, 0.1149, 0.0966, 0.0772, 0.0964, 0.0610, 0.1084,
        0.0609, 0.0661, 0.0444, 0.0264], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,549][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.3175, 0.0712, 0.0441, 0.0561, 0.0543, 0.0549, 0.0550, 0.0542, 0.0532,
        0.0485, 0.0725, 0.0600, 0.0585], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,553][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.3875, 0.0043, 0.0189, 0.0092, 0.0164, 0.0321, 0.0222, 0.0422, 0.0292,
        0.0390, 0.0870, 0.1832, 0.1288], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,553][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.4742, 0.0904, 0.0439, 0.0930, 0.0101, 0.0141, 0.0455, 0.0165, 0.0380,
        0.0163, 0.0648, 0.0736, 0.0196], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,554][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.4347, 0.0313, 0.0937, 0.0376, 0.0834, 0.0670, 0.0848, 0.0352, 0.0498,
        0.0202, 0.0186, 0.0314, 0.0122], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,554][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.2767, 0.0030, 0.0064, 0.0060, 0.0082, 0.0140, 0.0213, 0.0541, 0.0386,
        0.0254, 0.1493, 0.2239, 0.1730], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,554][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0345, 0.0005, 0.1622, 0.0072, 0.1449, 0.0084, 0.0128, 0.0619, 0.0249,
        0.3722, 0.1223, 0.0259, 0.0224], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,555][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.8638, 0.0656, 0.0177, 0.0116, 0.0074, 0.0032, 0.0132, 0.0021, 0.0010,
        0.0042, 0.0020, 0.0023, 0.0060], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,555][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.1982, 0.0614, 0.0871, 0.0750, 0.0774, 0.0740, 0.0751, 0.0840, 0.0539,
        0.0515, 0.0537, 0.0547, 0.0540], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,555][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.6950, 0.0204, 0.0373, 0.0355, 0.0344, 0.0334, 0.0373, 0.0269, 0.0422,
        0.0157, 0.0070, 0.0067, 0.0082], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,556][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.1193, 0.0344, 0.0202, 0.0621, 0.0358, 0.0351, 0.0391, 0.0277, 0.0923,
        0.0481, 0.0278, 0.0504, 0.4078], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,559][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0089, 0.0824, 0.0912, 0.1667, 0.0782, 0.0602, 0.0617, 0.0286, 0.1239,
        0.0325, 0.0326, 0.0420, 0.0355, 0.1555], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,564][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0022, 0.0081, 0.1565, 0.0181, 0.1018, 0.2227, 0.0817, 0.1178, 0.0618,
        0.0969, 0.0185, 0.0333, 0.0661, 0.0146], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,569][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.4327, 0.0696, 0.0358, 0.0458, 0.0403, 0.0438, 0.0415, 0.0403, 0.0324,
        0.0347, 0.0564, 0.0452, 0.0489, 0.0325], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,570][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.3049, 0.0058, 0.0202, 0.0131, 0.0184, 0.0336, 0.0254, 0.0594, 0.0277,
        0.0550, 0.0760, 0.1520, 0.1404, 0.0680], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,570][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.3110, 0.0442, 0.0799, 0.0457, 0.0266, 0.0209, 0.0758, 0.0328, 0.0379,
        0.0448, 0.0419, 0.1428, 0.0642, 0.0315], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,571][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.5094, 0.0302, 0.0660, 0.0548, 0.0666, 0.0520, 0.0545, 0.0388, 0.0475,
        0.0197, 0.0129, 0.0177, 0.0132, 0.0165], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,571][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.2477, 0.0028, 0.0079, 0.0072, 0.0105, 0.0134, 0.0227, 0.0657, 0.0312,
        0.0441, 0.0873, 0.1583, 0.2313, 0.0701], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,571][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0263, 0.0028, 0.1265, 0.0170, 0.2992, 0.0127, 0.0433, 0.1474, 0.0477,
        0.0638, 0.0717, 0.0876, 0.0319, 0.0220], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,572][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.8346, 0.0643, 0.0249, 0.0130, 0.0113, 0.0043, 0.0166, 0.0024, 0.0010,
        0.0048, 0.0023, 0.0029, 0.0092, 0.0086], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,572][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.2518, 0.0551, 0.0718, 0.0688, 0.0749, 0.0593, 0.0616, 0.0744, 0.0439,
        0.0331, 0.0488, 0.0485, 0.0614, 0.0466], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,575][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.7799, 0.0100, 0.0365, 0.0190, 0.0315, 0.0270, 0.0188, 0.0155, 0.0265,
        0.0116, 0.0048, 0.0051, 0.0040, 0.0096], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,581][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0990, 0.0711, 0.0196, 0.2021, 0.0212, 0.1110, 0.0416, 0.0416, 0.1202,
        0.0372, 0.0360, 0.0475, 0.0499, 0.1019], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,585][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.0213, 0.0535, 0.0394, 0.1458, 0.0494, 0.0608, 0.0734, 0.0460, 0.1643,
        0.0430, 0.0355, 0.0390, 0.0469, 0.1316, 0.0498], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,586][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0002, 0.0474, 0.0815, 0.0238, 0.0143, 0.1340, 0.0318, 0.1603, 0.0462,
        0.0975, 0.0994, 0.0161, 0.1663, 0.0644, 0.0168], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,586][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.3105, 0.0686, 0.0367, 0.0489, 0.0419, 0.0478, 0.0452, 0.0411, 0.0403,
        0.0367, 0.0694, 0.0560, 0.0575, 0.0422, 0.0574], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,587][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.2574, 0.0037, 0.0137, 0.0087, 0.0096, 0.0176, 0.0149, 0.0238, 0.0201,
        0.0279, 0.0897, 0.1765, 0.1708, 0.0612, 0.1044], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,587][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.3722, 0.0832, 0.0377, 0.0928, 0.0085, 0.0124, 0.0338, 0.0266, 0.0416,
        0.0167, 0.0489, 0.1054, 0.0285, 0.0752, 0.0163], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,587][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.3027, 0.0535, 0.0576, 0.0773, 0.0287, 0.0997, 0.0850, 0.0638, 0.0619,
        0.0267, 0.0311, 0.0371, 0.0242, 0.0358, 0.0151], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,588][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.5219, 0.0023, 0.0062, 0.0027, 0.0035, 0.0052, 0.0082, 0.0126, 0.0105,
        0.0142, 0.0626, 0.1166, 0.1428, 0.0434, 0.0473], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,588][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0800, 0.0015, 0.2559, 0.0132, 0.1302, 0.0113, 0.0210, 0.0239, 0.0418,
        0.0629, 0.0486, 0.0306, 0.0394, 0.0325, 0.2073], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,588][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([9.0628e-01, 3.8145e-02, 9.7813e-03, 7.0626e-03, 4.8352e-03, 2.3817e-03,
        8.7209e-03, 9.7583e-04, 4.3949e-04, 1.9634e-03, 1.3388e-03, 1.3822e-03,
        3.8413e-03, 4.3913e-03, 8.4647e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,592][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.2051, 0.0538, 0.0725, 0.0598, 0.0486, 0.0597, 0.0617, 0.0862, 0.0482,
        0.0441, 0.0523, 0.0499, 0.0588, 0.0567, 0.0424], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,598][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.4702, 0.0351, 0.0729, 0.0518, 0.0775, 0.0580, 0.0392, 0.0638, 0.0449,
        0.0244, 0.0091, 0.0092, 0.0085, 0.0160, 0.0195], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,602][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0600, 0.0392, 0.0221, 0.0312, 0.0817, 0.1252, 0.0533, 0.0072, 0.1219,
        0.0430, 0.0477, 0.0959, 0.1176, 0.0612, 0.0927], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,602][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0110, 0.0489, 0.0615, 0.1690, 0.0700, 0.0715, 0.0668, 0.0355, 0.1620,
        0.0236, 0.0287, 0.0352, 0.0296, 0.0940, 0.0399, 0.0526],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,603][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0054, 0.0505, 0.1613, 0.0639, 0.0625, 0.0491, 0.0458, 0.0671, 0.0388,
        0.0761, 0.0429, 0.0341, 0.1147, 0.0827, 0.0604, 0.0446],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,603][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2531, 0.0653, 0.0379, 0.0484, 0.0463, 0.0483, 0.0516, 0.0463, 0.0421,
        0.0391, 0.0713, 0.0574, 0.0533, 0.0422, 0.0541, 0.0431],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,603][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.4938, 0.0040, 0.0122, 0.0060, 0.0075, 0.0181, 0.0156, 0.0219, 0.0127,
        0.0132, 0.0352, 0.0887, 0.0566, 0.0373, 0.0472, 0.1300],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,604][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.4887, 0.0608, 0.0492, 0.0563, 0.0107, 0.0117, 0.0321, 0.0162, 0.0373,
        0.0141, 0.0437, 0.0744, 0.0292, 0.0399, 0.0211, 0.0144],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,604][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.5914, 0.0163, 0.0495, 0.0206, 0.0498, 0.0337, 0.0446, 0.0278, 0.0343,
        0.0164, 0.0153, 0.0168, 0.0173, 0.0189, 0.0391, 0.0083],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,606][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.2471, 0.0026, 0.0090, 0.0051, 0.0091, 0.0122, 0.0195, 0.0476, 0.0201,
        0.0134, 0.0635, 0.0981, 0.1512, 0.0478, 0.0689, 0.1847],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,612][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0382, 0.0028, 0.0410, 0.0081, 0.0821, 0.0114, 0.0265, 0.2844, 0.0551,
        0.1236, 0.0530, 0.0245, 0.0110, 0.0534, 0.1598, 0.0251],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,614][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([8.0384e-01, 9.0888e-02, 1.7306e-02, 1.4858e-02, 6.9916e-03, 3.2728e-03,
        1.6928e-02, 1.4528e-03, 6.5261e-04, 2.8383e-03, 1.8592e-03, 2.1486e-03,
        4.6118e-03, 5.7130e-03, 1.1466e-02, 1.5173e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,618][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.2088, 0.0506, 0.0672, 0.0584, 0.0694, 0.0530, 0.0582, 0.0734, 0.0408,
        0.0334, 0.0477, 0.0481, 0.0573, 0.0445, 0.0551, 0.0342],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,618][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.6518, 0.0167, 0.0419, 0.0365, 0.0382, 0.0390, 0.0365, 0.0237, 0.0465,
        0.0160, 0.0070, 0.0073, 0.0060, 0.0144, 0.0126, 0.0058],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,619][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0322, 0.0469, 0.0156, 0.1043, 0.0167, 0.1828, 0.0704, 0.0084, 0.0415,
        0.0188, 0.0261, 0.0731, 0.0650, 0.0448, 0.0165, 0.2370],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:20,619][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0061, 0.0569, 0.0935, 0.1601, 0.0726, 0.0622, 0.0612, 0.0242, 0.1240,
        0.0198, 0.0288, 0.0350, 0.0282, 0.1062, 0.0373, 0.0442, 0.0397],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,619][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0043, 0.0585, 0.0883, 0.0540, 0.0327, 0.1450, 0.0184, 0.0806, 0.0791,
        0.0879, 0.0461, 0.0224, 0.0562, 0.0667, 0.0400, 0.0962, 0.0236],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,620][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2601, 0.0633, 0.0331, 0.0429, 0.0427, 0.0462, 0.0465, 0.0418, 0.0406,
        0.0373, 0.0651, 0.0522, 0.0500, 0.0378, 0.0533, 0.0396, 0.0473],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,620][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4089, 0.0025, 0.0113, 0.0051, 0.0081, 0.0182, 0.0115, 0.0323, 0.0140,
        0.0233, 0.0317, 0.0563, 0.0540, 0.0360, 0.0539, 0.1337, 0.0992],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,621][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.5481, 0.0587, 0.0285, 0.0445, 0.0089, 0.0143, 0.0117, 0.0193, 0.0275,
        0.0196, 0.0298, 0.0545, 0.0370, 0.0411, 0.0169, 0.0174, 0.0221],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,622][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4466, 0.0272, 0.0676, 0.0400, 0.0584, 0.0500, 0.0391, 0.0526, 0.0446,
        0.0270, 0.0167, 0.0199, 0.0157, 0.0235, 0.0346, 0.0245, 0.0122],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,628][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2375, 0.0016, 0.0047, 0.0030, 0.0055, 0.0090, 0.0071, 0.0580, 0.0201,
        0.0167, 0.0502, 0.0519, 0.1112, 0.0378, 0.0547, 0.2109, 0.1202],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,633][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0121, 0.0028, 0.0806, 0.0062, 0.0488, 0.0229, 0.0059, 0.1338, 0.0294,
        0.0441, 0.0413, 0.0189, 0.0398, 0.0373, 0.0794, 0.3851, 0.0116],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,635][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7994, 0.0795, 0.0201, 0.0174, 0.0078, 0.0032, 0.0159, 0.0018, 0.0009,
        0.0033, 0.0019, 0.0023, 0.0044, 0.0057, 0.0101, 0.0138, 0.0123],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,635][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2031, 0.0481, 0.0623, 0.0576, 0.0548, 0.0493, 0.0542, 0.0694, 0.0379,
        0.0288, 0.0421, 0.0455, 0.0515, 0.0476, 0.0470, 0.0454, 0.0556],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,635][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.7613, 0.0111, 0.0301, 0.0201, 0.0353, 0.0269, 0.0190, 0.0164, 0.0257,
        0.0164, 0.0047, 0.0042, 0.0042, 0.0085, 0.0091, 0.0036, 0.0036],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,636][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0466, 0.0170, 0.0201, 0.0412, 0.0208, 0.0533, 0.1768, 0.0222, 0.0395,
        0.0308, 0.0453, 0.0921, 0.1124, 0.0308, 0.0227, 0.0502, 0.1781],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:20,636][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0159, 0.0684, 0.0588, 0.1337, 0.0532, 0.0705, 0.0588, 0.0294, 0.1098,
        0.0211, 0.0206, 0.0278, 0.0415, 0.1027, 0.0430, 0.0564, 0.0466, 0.0419],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,636][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0011, 0.0258, 0.0553, 0.0282, 0.0362, 0.1058, 0.0474, 0.0642, 0.0446,
        0.1128, 0.0613, 0.0322, 0.1202, 0.0325, 0.0383, 0.0841, 0.0563, 0.0536],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,637][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.2242, 0.0529, 0.0299, 0.0391, 0.0389, 0.0430, 0.0443, 0.0387, 0.0381,
        0.0369, 0.0620, 0.0519, 0.0496, 0.0391, 0.0532, 0.0442, 0.0539, 0.0601],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,640][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.2655, 0.0009, 0.0053, 0.0021, 0.0045, 0.0071, 0.0072, 0.0125, 0.0074,
        0.0127, 0.0309, 0.0698, 0.0502, 0.0315, 0.0657, 0.1462, 0.1361, 0.1446],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,646][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.3145, 0.0675, 0.0449, 0.0674, 0.0093, 0.0155, 0.0342, 0.0214, 0.0466,
        0.0177, 0.0497, 0.0891, 0.0343, 0.0517, 0.0189, 0.0216, 0.0756, 0.0201],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,650][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.3776, 0.0559, 0.0657, 0.0337, 0.0494, 0.0549, 0.0569, 0.0478, 0.0450,
        0.0308, 0.0124, 0.0233, 0.0317, 0.0258, 0.0328, 0.0177, 0.0153, 0.0234],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,651][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.1698, 0.0005, 0.0016, 0.0010, 0.0017, 0.0040, 0.0074, 0.0194, 0.0120,
        0.0101, 0.0445, 0.0587, 0.0787, 0.0284, 0.0374, 0.1910, 0.1902, 0.1435],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,651][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0337, 0.0005, 0.1506, 0.0031, 0.0855, 0.0070, 0.0084, 0.0109, 0.0133,
        0.0582, 0.0578, 0.0139, 0.0301, 0.0100, 0.1504, 0.1523, 0.0212, 0.1933],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,652][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.6978, 0.0958, 0.0264, 0.0236, 0.0116, 0.0058, 0.0194, 0.0036, 0.0022,
        0.0063, 0.0035, 0.0040, 0.0065, 0.0079, 0.0129, 0.0191, 0.0162, 0.0375],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,652][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.1429, 0.0535, 0.0628, 0.0594, 0.0646, 0.0480, 0.0473, 0.0620, 0.0395,
        0.0349, 0.0469, 0.0435, 0.0546, 0.0472, 0.0552, 0.0394, 0.0482, 0.0501],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,652][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.7558, 0.0123, 0.0250, 0.0278, 0.0239, 0.0312, 0.0189, 0.0215, 0.0338,
        0.0112, 0.0037, 0.0044, 0.0023, 0.0094, 0.0086, 0.0030, 0.0033, 0.0037],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,653][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.0820, 0.0354, 0.0395, 0.0475, 0.0537, 0.0992, 0.0435, 0.0314, 0.0568,
        0.0269, 0.0244, 0.0715, 0.0512, 0.0374, 0.0559, 0.1124, 0.0419, 0.0896],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:20,653][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0035, 0.0453, 0.1030, 0.1133, 0.0659, 0.0463, 0.0457, 0.0248, 0.1138,
        0.0222, 0.0245, 0.0279, 0.0222, 0.0852, 0.0414, 0.0330, 0.0300, 0.0202,
        0.1317], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,656][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0124, 0.0073, 0.0508, 0.0135, 0.0448, 0.1288, 0.0793, 0.0708, 0.0301,
        0.0661, 0.0145, 0.0458, 0.0312, 0.0133, 0.0612, 0.1409, 0.0829, 0.0876,
        0.0185], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,661][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2191, 0.0542, 0.0310, 0.0394, 0.0372, 0.0435, 0.0433, 0.0362, 0.0363,
        0.0337, 0.0564, 0.0477, 0.0464, 0.0359, 0.0474, 0.0393, 0.0486, 0.0551,
        0.0492], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,667][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3105, 0.0020, 0.0084, 0.0033, 0.0053, 0.0131, 0.0088, 0.0161, 0.0091,
        0.0140, 0.0240, 0.0436, 0.0471, 0.0260, 0.0338, 0.1194, 0.0870, 0.1099,
        0.1186], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,667][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2885, 0.0623, 0.0409, 0.0503, 0.0141, 0.0160, 0.0394, 0.0228, 0.0272,
        0.0279, 0.0275, 0.1047, 0.0572, 0.0414, 0.0271, 0.0239, 0.0841, 0.0231,
        0.0217], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,668][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.5322, 0.0236, 0.0466, 0.0245, 0.0473, 0.0373, 0.0397, 0.0371, 0.0248,
        0.0183, 0.0118, 0.0183, 0.0124, 0.0177, 0.0328, 0.0158, 0.0181, 0.0286,
        0.0132], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,668][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1716, 0.0008, 0.0019, 0.0014, 0.0020, 0.0058, 0.0092, 0.0396, 0.0105,
        0.0079, 0.0339, 0.0530, 0.0626, 0.0248, 0.0217, 0.1509, 0.1389, 0.1496,
        0.1142], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,668][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0153, 0.0006, 0.0486, 0.0019, 0.1228, 0.0041, 0.0103, 0.0945, 0.0105,
        0.0194, 0.0230, 0.0256, 0.0244, 0.0206, 0.2400, 0.1643, 0.0280, 0.1232,
        0.0228], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,669][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.5901, 0.0747, 0.0277, 0.0196, 0.0176, 0.0093, 0.0213, 0.0052, 0.0032,
        0.0096, 0.0077, 0.0072, 0.0143, 0.0153, 0.0247, 0.0351, 0.0266, 0.0568,
        0.0340], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,669][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1511, 0.0440, 0.0571, 0.0534, 0.0572, 0.0461, 0.0504, 0.0608, 0.0362,
        0.0300, 0.0390, 0.0430, 0.0471, 0.0398, 0.0481, 0.0398, 0.0506, 0.0551,
        0.0511], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,673][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.7751, 0.0103, 0.0285, 0.0168, 0.0301, 0.0230, 0.0171, 0.0153, 0.0230,
        0.0127, 0.0043, 0.0043, 0.0042, 0.0089, 0.0105, 0.0047, 0.0040, 0.0026,
        0.0045], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,679][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0407, 0.0405, 0.0111, 0.0991, 0.0089, 0.0561, 0.0522, 0.0301, 0.0430,
        0.0108, 0.0338, 0.0471, 0.0452, 0.0489, 0.0088, 0.0849, 0.0545, 0.0275,
        0.2569], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:20,680][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:20,683][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[10963],
        [12084],
        [31169],
        [11701],
        [14168],
        [12273],
        [19821],
        [14637],
        [17430],
        [21748],
        [22250],
        [14558],
        [10910],
        [ 8501],
        [15570],
        [ 7776],
        [16754],
        [ 4841],
        [11622]], device='cuda:0')
[2024-07-24 10:27:20,685][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11370],
        [14568],
        [28499],
        [ 9274],
        [10045],
        [11674],
        [17679],
        [14136],
        [22137],
        [24562],
        [28450],
        [16914],
        [12335],
        [ 9721],
        [15381],
        [ 6334],
        [20967],
        [ 7303],
        [26634]], device='cuda:0')
[2024-07-24 10:27:20,686][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[30731],
        [ 1112],
        [15851],
        [13197],
        [16150],
        [15095],
        [14926],
        [ 6874],
        [ 7455],
        [ 6304],
        [ 7314],
        [ 9968],
        [ 8858],
        [ 9564],
        [12496],
        [ 9922],
        [ 7017],
        [ 8764],
        [ 7727]], device='cuda:0')
[2024-07-24 10:27:20,687][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 6068],
        [24108],
        [33601],
        [36528],
        [36635],
        [36221],
        [36742],
        [38283],
        [41563],
        [40942],
        [40584],
        [40718],
        [40809],
        [40965],
        [42455],
        [42699],
        [40769],
        [39745],
        [41389]], device='cuda:0')
[2024-07-24 10:27:20,688][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[2546],
        [2642],
        [2896],
        [3199],
        [3757],
        [4068],
        [4030],
        [3414],
        [3556],
        [3571],
        [3613],
        [3463],
        [3166],
        [3274],
        [3594],
        [3685],
        [3869],
        [4149],
        [4488]], device='cuda:0')
[2024-07-24 10:27:20,690][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[10104],
        [10075],
        [10277],
        [10213],
        [11138],
        [ 6316],
        [ 7223],
        [ 9759],
        [ 9516],
        [10770],
        [ 8851],
        [ 9377],
        [11318],
        [10250],
        [11656],
        [10650],
        [ 9937],
        [10984],
        [ 9827]], device='cuda:0')
[2024-07-24 10:27:20,692][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[13250],
        [34543],
        [36779],
        [41472],
        [43217],
        [44617],
        [45279],
        [43838],
        [42911],
        [42249],
        [39583],
        [40748],
        [41303],
        [41679],
        [41385],
        [40671],
        [42361],
        [42414],
        [40351]], device='cuda:0')
[2024-07-24 10:27:20,695][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[31779],
        [38584],
        [37905],
        [41105],
        [39955],
        [40371],
        [40542],
        [39886],
        [39794],
        [39592],
        [39955],
        [39865],
        [39463],
        [39722],
        [39451],
        [39321],
        [39319],
        [38910],
        [38846]], device='cuda:0')
[2024-07-24 10:27:20,698][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[19990],
        [13755],
        [13516],
        [13439],
        [13005],
        [13246],
        [13233],
        [13629],
        [13926],
        [14077],
        [13837],
        [13703],
        [13576],
        [13488],
        [13341],
        [13199],
        [13120],
        [13162],
        [13038]], device='cuda:0')
[2024-07-24 10:27:20,700][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 7759],
        [10088],
        [26303],
        [24361],
        [29248],
        [26702],
        [28411],
        [30236],
        [35233],
        [29204],
        [34166],
        [33505],
        [35655],
        [32772],
        [33567],
        [36562],
        [39354],
        [30215],
        [34630]], device='cuda:0')
[2024-07-24 10:27:20,703][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11289],
        [31075],
        [30750],
        [31579],
        [32959],
        [34472],
        [35783],
        [36214],
        [36689],
        [36789],
        [36432],
        [37019],
        [36820],
        [36996],
        [36753],
        [36333],
        [36298],
        [36158],
        [36378]], device='cuda:0')
[2024-07-24 10:27:20,706][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[20782],
        [16375],
        [13566],
        [11513],
        [12151],
        [12793],
        [12021],
        [12302],
        [12715],
        [13063],
        [13322],
        [12726],
        [12545],
        [12533],
        [12733],
        [12765],
        [12536],
        [12615],
        [12588]], device='cuda:0')
[2024-07-24 10:27:20,707][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[27551],
        [41626],
        [43393],
        [44124],
        [44529],
        [44867],
        [45368],
        [45564],
        [45726],
        [46142],
        [46462],
        [46657],
        [46590],
        [46591],
        [46502],
        [46475],
        [46355],
        [46436],
        [46525]], device='cuda:0')
[2024-07-24 10:27:20,708][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 9265],
        [ 8958],
        [19841],
        [ 3243],
        [ 8222],
        [ 2945],
        [ 2903],
        [ 4129],
        [ 3473],
        [ 3834],
        [ 3158],
        [ 3461],
        [ 1972],
        [ 2892],
        [ 3632],
        [ 2574],
        [ 2934],
        [ 3478],
        [ 3410]], device='cuda:0')
[2024-07-24 10:27:20,709][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[37920],
        [27783],
        [26994],
        [31422],
        [31589],
        [26151],
        [33422],
        [16810],
        [22759],
        [28738],
        [20629],
        [25544],
        [17137],
        [25395],
        [33037],
        [41677],
        [32516],
        [14402],
        [14940]], device='cuda:0')
[2024-07-24 10:27:20,710][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[18030],
        [ 2797],
        [ 2569],
        [ 3897],
        [ 3271],
        [ 3381],
        [ 3277],
        [ 2921],
        [ 2170],
        [ 2210],
        [ 2547],
        [ 2494],
        [ 2508],
        [ 2809],
        [ 2706],
        [ 2807],
        [ 2948],
        [ 3086],
        [ 3041]], device='cuda:0')
[2024-07-24 10:27:20,713][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9944],
        [ 3720],
        [ 4710],
        [10170],
        [ 7379],
        [ 8302],
        [ 9215],
        [ 8826],
        [11659],
        [11532],
        [12600],
        [11418],
        [10344],
        [12079],
        [10037],
        [10643],
        [11683],
        [11430],
        [12646]], device='cuda:0')
[2024-07-24 10:27:20,715][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[20632],
        [28927],
        [30145],
        [30591],
        [31000],
        [31257],
        [31565],
        [31890],
        [31839],
        [32172],
        [32734],
        [33004],
        [33118],
        [33148],
        [33002],
        [32846],
        [32799],
        [32810],
        [33022]], device='cuda:0')
[2024-07-24 10:27:20,718][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 1175],
        [29365],
        [16560],
        [15950],
        [19491],
        [28751],
        [27618],
        [27161],
        [30259],
        [36942],
        [33715],
        [30218],
        [31859],
        [33645],
        [32519],
        [31042],
        [32652],
        [32372],
        [32221]], device='cuda:0')
[2024-07-24 10:27:20,721][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[16999],
        [13730],
        [ 8362],
        [10504],
        [ 7662],
        [ 9396],
        [ 8273],
        [ 8598],
        [ 9018],
        [ 7588],
        [ 8869],
        [ 8484],
        [ 8083],
        [ 7941],
        [ 7367],
        [ 8387],
        [ 7818],
        [ 7791],
        [ 7715]], device='cuda:0')
[2024-07-24 10:27:20,723][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[19883],
        [18770],
        [17599],
        [17180],
        [17258],
        [16785],
        [16263],
        [16288],
        [16548],
        [15215],
        [14986],
        [15079],
        [15304],
        [15202],
        [15933],
        [14801],
        [15248],
        [16259],
        [15214]], device='cuda:0')
[2024-07-24 10:27:20,726][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[18430],
        [24792],
        [22069],
        [34990],
        [21261],
        [35521],
        [31771],
        [32475],
        [37775],
        [36640],
        [33477],
        [34875],
        [34407],
        [34704],
        [30356],
        [37613],
        [37507],
        [35188],
        [35468]], device='cuda:0')
[2024-07-24 10:27:20,727][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 3464],
        [ 3881],
        [38453],
        [38661],
        [31539],
        [13772],
        [30312],
        [10573],
        [ 2233],
        [19634],
        [ 9028],
        [ 8828],
        [18285],
        [ 9204],
        [17474],
        [ 6135],
        [ 8705],
        [23368],
        [10985]], device='cuda:0')
[2024-07-24 10:27:20,728][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 8225],
        [ 9983],
        [ 9256],
        [10957],
        [ 9382],
        [10301],
        [10584],
        [10650],
        [ 9045],
        [ 9402],
        [ 9171],
        [ 9599],
        [ 9425],
        [ 9410],
        [ 8852],
        [ 9585],
        [ 9417],
        [ 9367],
        [ 8473]], device='cuda:0')
[2024-07-24 10:27:20,729][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[2575],
        [2555],
        [2254],
        [2402],
        [2379],
        [2575],
        [2241],
        [2229],
        [1929],
        [1971],
        [1729],
        [1583],
        [1760],
        [1778],
        [1765],
        [1809],
        [1732],
        [1793],
        [1728]], device='cuda:0')
[2024-07-24 10:27:20,730][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[14143],
        [14133],
        [ 4034],
        [11714],
        [ 3060],
        [10177],
        [10246],
        [11892],
        [11541],
        [ 7203],
        [ 7319],
        [ 6798],
        [ 6554],
        [ 7016],
        [ 4185],
        [ 6236],
        [ 7034],
        [ 7624],
        [ 7413]], device='cuda:0')
[2024-07-24 10:27:20,733][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 2155],
        [25207],
        [11888],
        [32712],
        [23535],
        [22337],
        [18799],
        [ 7695],
        [21624],
        [ 8638],
        [33212],
        [17296],
        [  561],
        [18272],
        [11521],
        [13716],
        [ 5760],
        [ 8322],
        [16593]], device='cuda:0')
[2024-07-24 10:27:20,735][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[43137],
        [36041],
        [38063],
        [29172],
        [38787],
        [32779],
        [31981],
        [36622],
        [36118],
        [33059],
        [32459],
        [34842],
        [35768],
        [34447],
        [36087],
        [36342],
        [35604],
        [32345],
        [33966]], device='cuda:0')
[2024-07-24 10:27:20,738][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[41184],
        [47802],
        [43443],
        [35154],
        [32180],
        [36855],
        [30507],
        [45244],
        [38696],
        [38805],
        [40777],
        [39878],
        [48922],
        [39119],
        [36115],
        [36677],
        [35943],
        [42216],
        [36253]], device='cuda:0')
[2024-07-24 10:27:20,741][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632],
        [22632]], device='cuda:0')
[2024-07-24 10:27:20,765][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:20,769][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,769][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,769][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,770][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,770][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,770][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,771][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,771][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,771][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,772][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,772][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,772][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:20,773][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9807, 0.0193], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,773][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1087, 0.8913], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,773][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7014, 0.2986], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,774][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9933, 0.0067], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,774][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9584, 0.0416], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,774][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2088, 0.7912], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,775][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9972, 0.0028], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,775][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0388, 0.9612], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,775][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5154, 0.4846], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,776][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4328, 0.5672], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,789][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1550, 0.8450], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,794][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0268, 0.9732], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:20,799][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.8567, 0.0627, 0.0806], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,800][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([0.0614, 0.4976, 0.4411], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,800][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.5195, 0.2250, 0.2555], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,800][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.5675, 0.3508, 0.0816], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,800][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.9236, 0.0475, 0.0289], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,801][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([0.1287, 0.4373, 0.4340], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,801][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.9505, 0.0045, 0.0450], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,801][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.0279, 0.3265, 0.6456], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,802][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.4827, 0.2993, 0.2180], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,802][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.1714, 0.5487, 0.2799], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,802][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.0704, 0.3859, 0.5437], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,804][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.0108, 0.9541, 0.0351], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:20,809][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9152, 0.0266, 0.0341, 0.0241], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,814][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0377, 0.3332, 0.2963, 0.3329], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,816][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4460, 0.1750, 0.2109, 0.1682], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,816][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9663, 0.0160, 0.0143, 0.0034], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,816][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9551, 0.0128, 0.0132, 0.0190], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,816][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0892, 0.2980, 0.3015, 0.3113], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,817][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([9.9112e-01, 8.7342e-04, 4.3130e-03, 3.6984e-03], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,817][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0157, 0.1721, 0.2933, 0.5189], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,817][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2248, 0.2489, 0.2647, 0.2616], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,818][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1668, 0.3364, 0.2031, 0.2937], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,818][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0450, 0.2579, 0.3503, 0.3469], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,821][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0744, 0.2436, 0.3182, 0.3638], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:20,827][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.8590, 0.0312, 0.0464, 0.0487, 0.0147], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,831][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0266, 0.2612, 0.2334, 0.2644, 0.2143], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,831][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.3276, 0.1672, 0.1878, 0.1468, 0.1705], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,832][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.3481, 0.4736, 0.1079, 0.0480, 0.0225], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,832][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.8684, 0.0434, 0.0208, 0.0520, 0.0155], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,832][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.0669, 0.2294, 0.2282, 0.2387, 0.2368], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,832][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.9712, 0.0026, 0.0110, 0.0028, 0.0124], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,833][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0127, 0.1147, 0.1988, 0.4052, 0.2687], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,833][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.3893, 0.1604, 0.1350, 0.1683, 0.1471], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,833][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.1948, 0.2576, 0.1365, 0.2011, 0.2100], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,834][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0364, 0.2089, 0.2723, 0.2366, 0.2458], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,834][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0025, 0.3376, 0.0154, 0.6417, 0.0028], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:20,837][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.8465, 0.0289, 0.0415, 0.0315, 0.0208, 0.0308], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,841][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0202, 0.2091, 0.1889, 0.2117, 0.1724, 0.1977], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,847][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3254, 0.1302, 0.1539, 0.1268, 0.1443, 0.1194], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,847][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([9.2888e-01, 1.3330e-02, 3.3314e-02, 3.8722e-03, 2.0151e-02, 4.5746e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,848][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.8369, 0.0221, 0.0182, 0.0348, 0.0151, 0.0728], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,848][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0545, 0.1825, 0.1825, 0.1897, 0.1903, 0.2005], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,848][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([9.9159e-01, 3.2753e-04, 5.6262e-03, 5.7005e-04, 1.1402e-03, 7.4214e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,849][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0133, 0.0873, 0.1419, 0.2667, 0.2015, 0.2893], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,849][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.2201, 0.1466, 0.1307, 0.1691, 0.1410, 0.1924], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,849][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1586, 0.1711, 0.1123, 0.1540, 0.1977, 0.2063], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,850][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0269, 0.1984, 0.2434, 0.2350, 0.1829, 0.1135], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,853][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0211, 0.1231, 0.0751, 0.6826, 0.0407, 0.0573], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:20,859][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.7956, 0.0269, 0.0317, 0.0361, 0.0151, 0.0300, 0.0647],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,863][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0187, 0.1717, 0.1535, 0.1717, 0.1414, 0.1609, 0.1820],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,863][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2916, 0.1159, 0.1348, 0.1094, 0.1246, 0.1037, 0.1199],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,863][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.9172, 0.0135, 0.0416, 0.0071, 0.0131, 0.0043, 0.0032],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,864][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.6794, 0.0238, 0.0196, 0.0453, 0.0156, 0.0908, 0.1255],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,864][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0476, 0.1516, 0.1514, 0.1569, 0.1575, 0.1658, 0.1692],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,864][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.9416e-01, 2.3988e-04, 2.5924e-03, 5.6086e-04, 4.2017e-04, 3.6822e-04,
        1.6537e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,865][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0094, 0.0713, 0.1082, 0.2114, 0.1482, 0.2136, 0.2379],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,865][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1708, 0.1281, 0.1258, 0.1344, 0.1256, 0.1495, 0.1658],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,865][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1429, 0.1570, 0.1015, 0.1367, 0.1599, 0.1776, 0.1244],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,865][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0226, 0.1538, 0.1928, 0.1833, 0.1535, 0.0855, 0.2084],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,869][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0357, 0.1046, 0.0557, 0.5392, 0.1329, 0.0692, 0.0627],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:20,873][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.7334, 0.0277, 0.0325, 0.0371, 0.0152, 0.0245, 0.1098, 0.0198],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,879][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0185, 0.1456, 0.1293, 0.1440, 0.1197, 0.1346, 0.1521, 0.1562],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,879][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2117, 0.1030, 0.1246, 0.0948, 0.1151, 0.0928, 0.1065, 0.1515],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,879][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.7629, 0.0483, 0.0496, 0.0199, 0.0197, 0.0066, 0.0495, 0.0434],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,880][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.6608, 0.0254, 0.0143, 0.0361, 0.0108, 0.0540, 0.1023, 0.0963],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,880][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0453, 0.1274, 0.1276, 0.1315, 0.1318, 0.1397, 0.1427, 0.1539],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,880][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([9.7483e-01, 6.5374e-04, 4.7082e-03, 1.2489e-03, 8.2315e-04, 7.4536e-04,
        1.2006e-03, 1.5791e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,881][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0197, 0.0621, 0.0843, 0.1500, 0.1083, 0.1629, 0.1880, 0.2248],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,881][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.2805, 0.0738, 0.0813, 0.0823, 0.0894, 0.1047, 0.1293, 0.1587],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,884][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.1703, 0.1498, 0.0791, 0.1024, 0.1503, 0.1265, 0.1102, 0.1114],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,889][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0193, 0.1550, 0.1768, 0.1786, 0.1416, 0.0859, 0.1525, 0.0904],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,894][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0025, 0.0794, 0.0570, 0.5612, 0.0315, 0.0353, 0.2228, 0.0103],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:20,895][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.7569, 0.0205, 0.0278, 0.0326, 0.0146, 0.0231, 0.0801, 0.0237, 0.0207],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,895][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0129, 0.1257, 0.1132, 0.1260, 0.1042, 0.1200, 0.1348, 0.1406, 0.1226],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,895][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.1923, 0.0903, 0.1124, 0.0863, 0.1076, 0.0837, 0.0969, 0.1229, 0.1076],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,896][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.9157, 0.0164, 0.0372, 0.0057, 0.0047, 0.0021, 0.0041, 0.0114, 0.0026],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,896][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.6360, 0.0115, 0.0099, 0.0196, 0.0078, 0.0464, 0.0595, 0.0753, 0.1340],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,896][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0351, 0.1106, 0.1117, 0.1149, 0.1163, 0.1225, 0.1252, 0.1375, 0.1262],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,897][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ of] are: tensor([9.8628e-01, 2.8590e-04, 3.8253e-03, 9.8872e-04, 7.7776e-04, 2.6332e-04,
        1.0499e-03, 2.1550e-03, 4.3740e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,898][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0059, 0.0470, 0.0761, 0.1265, 0.1052, 0.1391, 0.1596, 0.2004, 0.1402],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,904][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.2152, 0.0796, 0.0880, 0.0747, 0.0763, 0.0983, 0.1003, 0.1443, 0.1232],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,908][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0964, 0.1433, 0.0699, 0.1069, 0.1317, 0.1173, 0.0914, 0.1145, 0.1287],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,910][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0208, 0.1220, 0.1542, 0.1504, 0.1270, 0.0729, 0.1375, 0.0716, 0.1436],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,910][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0113, 0.0500, 0.1014, 0.3758, 0.1787, 0.0630, 0.1251, 0.0210, 0.0737],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:20,911][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.7482, 0.0218, 0.0284, 0.0320, 0.0112, 0.0208, 0.0803, 0.0211, 0.0284,
        0.0077], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,911][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0105, 0.1159, 0.1027, 0.1154, 0.0937, 0.1082, 0.1226, 0.1268, 0.1082,
        0.0959], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,911][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.1696, 0.0841, 0.0975, 0.0747, 0.0874, 0.0776, 0.0848, 0.1139, 0.0968,
        0.1137], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,912][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.4225, 0.1562, 0.0802, 0.0335, 0.0459, 0.0077, 0.0384, 0.1354, 0.0473,
        0.0330], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,912][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.4620, 0.0191, 0.0089, 0.0321, 0.0070, 0.0477, 0.0984, 0.0632, 0.2170,
        0.0446], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,912][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0295, 0.0967, 0.0972, 0.1013, 0.1012, 0.1093, 0.1113, 0.1212, 0.1121,
        0.1201], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,913][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.9347, 0.0011, 0.0049, 0.0018, 0.0017, 0.0018, 0.0016, 0.0105, 0.0028,
        0.0391], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,913][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0146, 0.0434, 0.0520, 0.0988, 0.0673, 0.1092, 0.1261, 0.1676, 0.1162,
        0.2049], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,916][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.5368, 0.0390, 0.0265, 0.0365, 0.0366, 0.0623, 0.0590, 0.0609, 0.0616,
        0.0809], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,921][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.1489, 0.0989, 0.0523, 0.0754, 0.1219, 0.0974, 0.0815, 0.0974, 0.1288,
        0.0975], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,927][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.0268, 0.1110, 0.1263, 0.1227, 0.1078, 0.0709, 0.1123, 0.0684, 0.1228,
        0.1309], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,927][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0081, 0.0631, 0.0530, 0.2326, 0.0419, 0.0299, 0.4788, 0.0114, 0.0763,
        0.0050], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:20,927][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.8282, 0.0161, 0.0142, 0.0176, 0.0090, 0.0178, 0.0383, 0.0106, 0.0111,
        0.0060, 0.0312], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,928][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0112, 0.1038, 0.0919, 0.1024, 0.0844, 0.0970, 0.1089, 0.1142, 0.0984,
        0.0875, 0.1004], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,928][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.1775, 0.0747, 0.0819, 0.0694, 0.0763, 0.0731, 0.0787, 0.1115, 0.0902,
        0.1024, 0.0644], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,928][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.8819, 0.0228, 0.0294, 0.0071, 0.0044, 0.0025, 0.0100, 0.0098, 0.0070,
        0.0167, 0.0083], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,929][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.4452, 0.0107, 0.0090, 0.0201, 0.0080, 0.0448, 0.0632, 0.0831, 0.1675,
        0.0602, 0.0882], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,929][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0267, 0.0873, 0.0876, 0.0908, 0.0913, 0.0967, 0.0991, 0.1090, 0.1001,
        0.1067, 0.1047], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,933][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.9097, 0.0030, 0.0195, 0.0050, 0.0051, 0.0020, 0.0046, 0.0149, 0.0083,
        0.0113, 0.0166], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,938][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0063, 0.0338, 0.0423, 0.0858, 0.0573, 0.0867, 0.1032, 0.1381, 0.0963,
        0.1839, 0.1663], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,943][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.3723, 0.0572, 0.0378, 0.0331, 0.0265, 0.0563, 0.0462, 0.0545, 0.0562,
        0.0403, 0.2196], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,943][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.1404, 0.1001, 0.0567, 0.0809, 0.1289, 0.0856, 0.0745, 0.0764, 0.1007,
        0.0919, 0.0639], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,943][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.0235, 0.0859, 0.1142, 0.1032, 0.0997, 0.0564, 0.1063, 0.0568, 0.1058,
        0.1087, 0.1396], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,944][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0534, 0.2618, 0.0458, 0.1509, 0.0846, 0.1158, 0.0911, 0.0264, 0.0485,
        0.0505, 0.0712], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:20,944][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.6954, 0.0221, 0.0211, 0.0302, 0.0092, 0.0279, 0.0602, 0.0170, 0.0184,
        0.0082, 0.0587, 0.0316], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,944][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0115, 0.0939, 0.0833, 0.0917, 0.0763, 0.0876, 0.0980, 0.1025, 0.0888,
        0.0790, 0.0902, 0.0972], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,945][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.1840, 0.0706, 0.0774, 0.0648, 0.0687, 0.0634, 0.0693, 0.1065, 0.0843,
        0.0962, 0.0603, 0.0546], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,945][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.8940, 0.0196, 0.0261, 0.0036, 0.0054, 0.0041, 0.0031, 0.0121, 0.0027,
        0.0131, 0.0073, 0.0090], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,945][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.2406, 0.0088, 0.0066, 0.0235, 0.0057, 0.0513, 0.0835, 0.0738, 0.1939,
        0.0431, 0.0877, 0.1816], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,947][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0250, 0.0797, 0.0798, 0.0828, 0.0828, 0.0878, 0.0897, 0.0983, 0.0901,
        0.0960, 0.0940, 0.0939], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,951][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ the] are: tensor([9.8560e-01, 3.7718e-04, 3.1420e-03, 8.6959e-04, 6.0508e-04, 4.0244e-04,
        1.2113e-03, 2.0923e-03, 1.5729e-03, 2.5834e-03, 5.4708e-04, 9.9745e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,955][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0052, 0.0287, 0.0390, 0.0709, 0.0582, 0.0770, 0.0865, 0.1219, 0.0779,
        0.1714, 0.1396, 0.1237], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,959][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.2045, 0.0565, 0.0427, 0.0318, 0.0266, 0.0422, 0.0391, 0.0496, 0.0562,
        0.0398, 0.2155, 0.1955], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,959][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0642, 0.0995, 0.0484, 0.0770, 0.1071, 0.0997, 0.0773, 0.0883, 0.1141,
        0.1048, 0.0716, 0.0482], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,960][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.0189, 0.0766, 0.1058, 0.0896, 0.0886, 0.0482, 0.0982, 0.0500, 0.0942,
        0.0954, 0.1294, 0.1051], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,960][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0510, 0.0539, 0.0162, 0.1091, 0.0615, 0.0434, 0.0336, 0.0111, 0.0578,
        0.1457, 0.2605, 0.1563], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:20,961][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.6318, 0.0232, 0.0225, 0.0337, 0.0113, 0.0304, 0.0639, 0.0172, 0.0261,
        0.0098, 0.0655, 0.0487, 0.0161], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,961][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0107, 0.0867, 0.0768, 0.0853, 0.0699, 0.0800, 0.0896, 0.0923, 0.0796,
        0.0711, 0.0820, 0.0881, 0.0880], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,961][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.1266, 0.0708, 0.0792, 0.0648, 0.0727, 0.0663, 0.0728, 0.0945, 0.0801,
        0.0879, 0.0549, 0.0518, 0.0776], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,962][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.5521, 0.0997, 0.0626, 0.0287, 0.0242, 0.0098, 0.0199, 0.0407, 0.0142,
        0.0328, 0.0361, 0.0502, 0.0291], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,965][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.3487, 0.0133, 0.0066, 0.0214, 0.0053, 0.0345, 0.0668, 0.0426, 0.1333,
        0.0315, 0.0790, 0.1803, 0.0368], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,971][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0246, 0.0718, 0.0719, 0.0748, 0.0746, 0.0802, 0.0818, 0.0887, 0.0823,
        0.0856, 0.0860, 0.0855, 0.0923], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,975][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.8678, 0.0020, 0.0089, 0.0039, 0.0026, 0.0033, 0.0041, 0.0191, 0.0050,
        0.0197, 0.0042, 0.0018, 0.0576], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,977][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0099, 0.0223, 0.0309, 0.0541, 0.0454, 0.0662, 0.0775, 0.1089, 0.0670,
        0.1500, 0.1327, 0.1090, 0.1262], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,977][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.5152, 0.0228, 0.0115, 0.0089, 0.0069, 0.0164, 0.0139, 0.0101, 0.0113,
        0.0045, 0.1046, 0.1843, 0.0897], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,978][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.1501, 0.0695, 0.0453, 0.0556, 0.1457, 0.0863, 0.0705, 0.0688, 0.0952,
        0.0788, 0.0546, 0.0428, 0.0368], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,978][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0212, 0.0731, 0.0977, 0.0860, 0.0844, 0.0450, 0.0919, 0.0469, 0.0872,
        0.0830, 0.1093, 0.0959, 0.0784], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,979][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0016, 0.1274, 0.0138, 0.3243, 0.0198, 0.0207, 0.1683, 0.0126, 0.0605,
        0.0112, 0.1050, 0.1319, 0.0028], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:20,979][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.5326, 0.0225, 0.0288, 0.0291, 0.0162, 0.0337, 0.0781, 0.0243, 0.0224,
        0.0143, 0.0840, 0.0556, 0.0236, 0.0346], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,979][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0076, 0.0798, 0.0700, 0.0783, 0.0641, 0.0739, 0.0832, 0.0866, 0.0740,
        0.0667, 0.0773, 0.0838, 0.0836, 0.0712], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,980][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1432, 0.0629, 0.0723, 0.0592, 0.0663, 0.0589, 0.0671, 0.0887, 0.0703,
        0.0776, 0.0498, 0.0485, 0.0745, 0.0607], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,980][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [.] are: tensor([9.4894e-01, 2.3223e-03, 1.0986e-02, 7.5036e-04, 1.6923e-03, 1.5832e-03,
        1.4307e-03, 6.4395e-03, 1.3133e-03, 3.8354e-03, 4.5445e-03, 4.4312e-03,
        1.0009e-02, 1.7205e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,983][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.4705, 0.0069, 0.0064, 0.0168, 0.0044, 0.0318, 0.0428, 0.0445, 0.1087,
        0.0274, 0.0616, 0.1138, 0.0325, 0.0320], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,989][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0195, 0.0664, 0.0660, 0.0689, 0.0692, 0.0735, 0.0750, 0.0826, 0.0762,
        0.0807, 0.0794, 0.0790, 0.0875, 0.0760], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,992][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [.] are: tensor([9.6198e-01, 4.8116e-04, 5.9497e-03, 1.5289e-03, 1.4040e-03, 4.5316e-04,
        1.5852e-03, 5.5734e-03, 4.0619e-03, 5.3231e-03, 3.4826e-03, 5.0013e-04,
        6.3078e-03, 1.3673e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,993][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0040, 0.0214, 0.0290, 0.0506, 0.0433, 0.0568, 0.0673, 0.0942, 0.0631,
        0.1392, 0.1190, 0.1058, 0.1500, 0.0564], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,994][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0391, 0.0175, 0.0121, 0.0104, 0.0077, 0.0144, 0.0176, 0.0190, 0.0183,
        0.0208, 0.1791, 0.2115, 0.3960, 0.0365], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,994][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0299, 0.0997, 0.0449, 0.0670, 0.1079, 0.0913, 0.0697, 0.0787, 0.0932,
        0.0881, 0.0679, 0.0455, 0.0436, 0.0726], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,995][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.0192, 0.0688, 0.0858, 0.0786, 0.0732, 0.0438, 0.0836, 0.0466, 0.0831,
        0.0786, 0.1030, 0.0795, 0.0802, 0.0760], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,995][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0029, 0.0035, 0.0069, 0.0200, 0.0267, 0.0212, 0.1526, 0.0087, 0.0306,
        0.0241, 0.1504, 0.4784, 0.0081, 0.0657], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:20,995][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.6262, 0.0203, 0.0297, 0.0322, 0.0080, 0.0184, 0.0619, 0.0134, 0.0216,
        0.0056, 0.0668, 0.0419, 0.0134, 0.0305, 0.0099], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,996][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0063, 0.0744, 0.0671, 0.0749, 0.0612, 0.0710, 0.0799, 0.0827, 0.0710,
        0.0620, 0.0716, 0.0780, 0.0792, 0.0671, 0.0536], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,996][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.1032, 0.0577, 0.0708, 0.0573, 0.0656, 0.0603, 0.0694, 0.0926, 0.0739,
        0.0767, 0.0462, 0.0447, 0.0692, 0.0582, 0.0541], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:20,998][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.2078, 0.1305, 0.0437, 0.0171, 0.0110, 0.0091, 0.0188, 0.0386, 0.0150,
        0.0355, 0.0374, 0.1254, 0.1891, 0.0898, 0.0310], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,004][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.2636, 0.0164, 0.0055, 0.0246, 0.0049, 0.0400, 0.0727, 0.0495, 0.1528,
        0.0336, 0.0842, 0.1602, 0.0393, 0.0396, 0.0131], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,008][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.0158, 0.0615, 0.0610, 0.0642, 0.0636, 0.0684, 0.0696, 0.0771, 0.0712,
        0.0772, 0.0747, 0.0743, 0.0829, 0.0724, 0.0659], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,010][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.8646, 0.0034, 0.0109, 0.0033, 0.0140, 0.0012, 0.0044, 0.0162, 0.0073,
        0.0236, 0.0033, 0.0031, 0.0164, 0.0031, 0.0252], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,010][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0062, 0.0198, 0.0308, 0.0533, 0.0420, 0.0571, 0.0682, 0.0930, 0.0597,
        0.1274, 0.1130, 0.0928, 0.1221, 0.0494, 0.0651], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,011][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.2018, 0.0126, 0.0061, 0.0056, 0.0037, 0.0110, 0.0083, 0.0043, 0.0069,
        0.0026, 0.1752, 0.2073, 0.3003, 0.0217, 0.0327], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,011][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0840, 0.1064, 0.0441, 0.0691, 0.0814, 0.0784, 0.0621, 0.0578, 0.0808,
        0.0586, 0.0469, 0.0407, 0.0388, 0.0793, 0.0717], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,011][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0154, 0.0605, 0.0797, 0.0703, 0.0724, 0.0409, 0.0767, 0.0380, 0.0807,
        0.0712, 0.0971, 0.0825, 0.0725, 0.0862, 0.0559], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,012][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0043, 0.1749, 0.0054, 0.2493, 0.0016, 0.0191, 0.0969, 0.0031, 0.0519,
        0.0016, 0.1218, 0.2078, 0.0025, 0.0586, 0.0013], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,012][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.6509, 0.0190, 0.0150, 0.0251, 0.0063, 0.0145, 0.0506, 0.0119, 0.0206,
        0.0058, 0.0584, 0.0444, 0.0156, 0.0271, 0.0083, 0.0267],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,013][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0062, 0.0703, 0.0639, 0.0706, 0.0577, 0.0668, 0.0752, 0.0788, 0.0666,
        0.0591, 0.0676, 0.0732, 0.0740, 0.0624, 0.0503, 0.0574],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,014][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.1299, 0.0521, 0.0652, 0.0494, 0.0571, 0.0523, 0.0572, 0.0915, 0.0649,
        0.0753, 0.0415, 0.0398, 0.0680, 0.0519, 0.0497, 0.0541],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,019][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.6938, 0.0391, 0.0222, 0.0110, 0.0134, 0.0043, 0.0150, 0.0191, 0.0145,
        0.0270, 0.0204, 0.0311, 0.0353, 0.0155, 0.0239, 0.0145],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,024][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.2722, 0.0127, 0.0073, 0.0221, 0.0056, 0.0409, 0.0686, 0.0486, 0.1287,
        0.0289, 0.0780, 0.1536, 0.0405, 0.0403, 0.0142, 0.0377],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,026][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0154, 0.0575, 0.0571, 0.0599, 0.0596, 0.0640, 0.0654, 0.0723, 0.0665,
        0.0710, 0.0696, 0.0695, 0.0768, 0.0668, 0.0613, 0.0673],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,027][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.9299, 0.0019, 0.0084, 0.0021, 0.0019, 0.0018, 0.0029, 0.0072, 0.0034,
        0.0130, 0.0026, 0.0019, 0.0069, 0.0015, 0.0026, 0.0121],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,027][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0056, 0.0192, 0.0279, 0.0513, 0.0397, 0.0550, 0.0656, 0.0858, 0.0587,
        0.1201, 0.1126, 0.0871, 0.1056, 0.0432, 0.0551, 0.0675],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,028][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.6879, 0.0236, 0.0086, 0.0052, 0.0035, 0.0112, 0.0066, 0.0039, 0.0040,
        0.0010, 0.0492, 0.0717, 0.0365, 0.0026, 0.0017, 0.0829],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,028][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.0724, 0.0764, 0.0387, 0.0552, 0.0925, 0.0829, 0.0546, 0.0566, 0.0821,
        0.0766, 0.0500, 0.0349, 0.0376, 0.0722, 0.0923, 0.0251],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,028][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.0088, 0.0467, 0.0531, 0.0573, 0.0492, 0.0337, 0.0643, 0.0438, 0.0797,
        0.0722, 0.0892, 0.0678, 0.0670, 0.0644, 0.0407, 0.1622],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,029][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0108, 0.1288, 0.0155, 0.1464, 0.0099, 0.0278, 0.1445, 0.0270, 0.1056,
        0.0122, 0.1402, 0.1403, 0.0086, 0.0726, 0.0063, 0.0037],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,029][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5995, 0.0215, 0.0182, 0.0309, 0.0084, 0.0171, 0.0387, 0.0129, 0.0167,
        0.0060, 0.0538, 0.0266, 0.0150, 0.0370, 0.0114, 0.0300, 0.0564],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,031][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0064, 0.0656, 0.0594, 0.0651, 0.0544, 0.0623, 0.0697, 0.0734, 0.0633,
        0.0563, 0.0636, 0.0686, 0.0691, 0.0589, 0.0481, 0.0546, 0.0614],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,037][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.1194, 0.0511, 0.0631, 0.0485, 0.0568, 0.0514, 0.0545, 0.0794, 0.0580,
        0.0666, 0.0412, 0.0390, 0.0633, 0.0504, 0.0476, 0.0539, 0.0560],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,041][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.7862, 0.0115, 0.0280, 0.0046, 0.0084, 0.0042, 0.0017, 0.0125, 0.0031,
        0.0195, 0.0078, 0.0123, 0.0375, 0.0069, 0.0225, 0.0287, 0.0046],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,043][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1169, 0.0069, 0.0047, 0.0176, 0.0043, 0.0389, 0.0653, 0.0541, 0.1451,
        0.0347, 0.0763, 0.1733, 0.0352, 0.0437, 0.0097, 0.0397, 0.1337],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,043][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0147, 0.0547, 0.0541, 0.0567, 0.0563, 0.0605, 0.0617, 0.0680, 0.0624,
        0.0660, 0.0648, 0.0648, 0.0714, 0.0625, 0.0570, 0.0627, 0.0616],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,044][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([9.7183e-01, 3.9120e-04, 2.9045e-03, 7.5759e-04, 7.9458e-04, 4.9426e-04,
        2.9644e-03, 2.5905e-03, 2.4057e-03, 2.4679e-03, 9.5967e-04, 9.7814e-04,
        4.5167e-03, 9.8142e-04, 1.3763e-03, 1.7603e-03, 1.8240e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,044][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0052, 0.0177, 0.0254, 0.0433, 0.0354, 0.0469, 0.0552, 0.0802, 0.0521,
        0.1149, 0.0917, 0.0730, 0.1054, 0.0402, 0.0579, 0.0643, 0.0911],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,045][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1630, 0.0379, 0.0138, 0.0100, 0.0056, 0.0166, 0.0114, 0.0107, 0.0123,
        0.0051, 0.1118, 0.1290, 0.1116, 0.0073, 0.0051, 0.2233, 0.1255],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,045][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0535, 0.0834, 0.0395, 0.0596, 0.0760, 0.0754, 0.0500, 0.0703, 0.0888,
        0.0844, 0.0571, 0.0355, 0.0371, 0.0719, 0.0720, 0.0215, 0.0238],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,045][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0083, 0.0396, 0.0496, 0.0486, 0.0430, 0.0293, 0.0587, 0.0390, 0.0705,
        0.0653, 0.0851, 0.0693, 0.0671, 0.0586, 0.0413, 0.1350, 0.0916],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,046][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0289, 0.0370, 0.0072, 0.0943, 0.0297, 0.0218, 0.0179, 0.0213, 0.0852,
        0.1294, 0.1047, 0.0994, 0.0732, 0.1506, 0.0444, 0.0259, 0.0291],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,049][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.4671, 0.0191, 0.0213, 0.0274, 0.0091, 0.0192, 0.0681, 0.0148, 0.0206,
        0.0064, 0.0561, 0.0430, 0.0138, 0.0295, 0.0121, 0.0454, 0.1181, 0.0086],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,054][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0078, 0.0623, 0.0565, 0.0613, 0.0515, 0.0588, 0.0648, 0.0668, 0.0576,
        0.0523, 0.0591, 0.0632, 0.0640, 0.0555, 0.0458, 0.0518, 0.0580, 0.0628],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,060][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0896, 0.0475, 0.0567, 0.0460, 0.0537, 0.0494, 0.0532, 0.0763, 0.0591,
        0.0683, 0.0403, 0.0390, 0.0578, 0.0490, 0.0471, 0.0533, 0.0557, 0.0582],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,060][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.2287, 0.0773, 0.0371, 0.0206, 0.0209, 0.0044, 0.0286, 0.0704, 0.0228,
        0.0378, 0.0413, 0.0911, 0.0541, 0.1010, 0.0387, 0.0460, 0.0590, 0.0200],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,060][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.2465, 0.0120, 0.0052, 0.0183, 0.0041, 0.0278, 0.0572, 0.0357, 0.1101,
        0.0230, 0.0664, 0.1731, 0.0308, 0.0278, 0.0092, 0.0271, 0.1128, 0.0129],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,061][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0161, 0.0508, 0.0508, 0.0527, 0.0526, 0.0566, 0.0577, 0.0626, 0.0580,
        0.0612, 0.0610, 0.0603, 0.0656, 0.0585, 0.0541, 0.0591, 0.0583, 0.0638],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,061][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.8435, 0.0021, 0.0102, 0.0043, 0.0037, 0.0024, 0.0043, 0.0262, 0.0031,
        0.0233, 0.0021, 0.0022, 0.0276, 0.0015, 0.0048, 0.0057, 0.0020, 0.0311],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,062][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0078, 0.0145, 0.0207, 0.0354, 0.0305, 0.0446, 0.0573, 0.0781, 0.0482,
        0.1076, 0.0879, 0.0706, 0.0941, 0.0338, 0.0481, 0.0602, 0.0876, 0.0731],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,062][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.4137, 0.0135, 0.0065, 0.0046, 0.0036, 0.0089, 0.0071, 0.0037, 0.0043,
        0.0017, 0.0413, 0.0846, 0.0596, 0.0049, 0.0065, 0.1834, 0.1314, 0.0208],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,062][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.1240, 0.0764, 0.0365, 0.0534, 0.0829, 0.0662, 0.0522, 0.0556, 0.0795,
        0.0616, 0.0356, 0.0327, 0.0258, 0.0665, 0.0825, 0.0239, 0.0292, 0.0155],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,066][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0105, 0.0468, 0.0597, 0.0581, 0.0485, 0.0290, 0.0558, 0.0292, 0.0556,
        0.0607, 0.0758, 0.0597, 0.0528, 0.0576, 0.0356, 0.1161, 0.0776, 0.0709],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,070][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0012, 0.0696, 0.0106, 0.2175, 0.0039, 0.0263, 0.2112, 0.0105, 0.0593,
        0.0042, 0.1001, 0.1192, 0.0011, 0.0710, 0.0015, 0.0034, 0.0884, 0.0009],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,076][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.5529, 0.0176, 0.0208, 0.0246, 0.0097, 0.0151, 0.0497, 0.0139, 0.0137,
        0.0062, 0.0407, 0.0310, 0.0141, 0.0272, 0.0117, 0.0317, 0.0778, 0.0087,
        0.0327], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,076][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0063, 0.0583, 0.0522, 0.0569, 0.0475, 0.0549, 0.0616, 0.0641, 0.0549,
        0.0491, 0.0564, 0.0601, 0.0609, 0.0523, 0.0422, 0.0486, 0.0546, 0.0594,
        0.0596], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,077][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0955, 0.0456, 0.0535, 0.0436, 0.0520, 0.0467, 0.0511, 0.0670, 0.0524,
        0.0598, 0.0393, 0.0371, 0.0542, 0.0446, 0.0451, 0.0504, 0.0532, 0.0539,
        0.0551], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,077][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.7958, 0.0170, 0.0140, 0.0032, 0.0034, 0.0026, 0.0059, 0.0080, 0.0036,
        0.0137, 0.0151, 0.0262, 0.0280, 0.0058, 0.0084, 0.0185, 0.0174, 0.0029,
        0.0107], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,078][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.1871, 0.0054, 0.0040, 0.0129, 0.0040, 0.0314, 0.0440, 0.0440, 0.1114,
        0.0299, 0.0587, 0.1342, 0.0313, 0.0382, 0.0110, 0.0455, 0.1104, 0.0158,
        0.0810], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,078][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0138, 0.0476, 0.0480, 0.0496, 0.0497, 0.0531, 0.0542, 0.0600, 0.0547,
        0.0586, 0.0571, 0.0569, 0.0632, 0.0554, 0.0508, 0.0556, 0.0543, 0.0613,
        0.0563], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,078][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.7072e-01, 5.1570e-04, 3.5291e-03, 1.1194e-03, 1.3749e-03, 2.7737e-04,
        9.3705e-04, 1.6121e-03, 2.1124e-03, 2.9689e-03, 1.8532e-03, 4.1829e-04,
        4.1132e-03, 7.3703e-04, 2.4486e-03, 1.1791e-03, 4.2382e-04, 2.4234e-03,
        1.2326e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,079][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0051, 0.0142, 0.0206, 0.0346, 0.0284, 0.0384, 0.0472, 0.0692, 0.0426,
        0.0985, 0.0767, 0.0599, 0.0909, 0.0323, 0.0471, 0.0544, 0.0770, 0.0725,
        0.0907], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,082][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2231, 0.0444, 0.0190, 0.0115, 0.0065, 0.0180, 0.0126, 0.0086, 0.0102,
        0.0030, 0.0877, 0.1163, 0.0693, 0.0049, 0.0031, 0.1147, 0.0873, 0.0269,
        0.1331], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,087][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0466, 0.0761, 0.0368, 0.0571, 0.0770, 0.0611, 0.0496, 0.0755, 0.0852,
        0.0823, 0.0496, 0.0372, 0.0341, 0.0716, 0.0729, 0.0223, 0.0252, 0.0197,
        0.0199], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,093][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0127, 0.0451, 0.0561, 0.0503, 0.0486, 0.0278, 0.0539, 0.0301, 0.0559,
        0.0519, 0.0670, 0.0532, 0.0480, 0.0483, 0.0358, 0.1031, 0.0689, 0.0621,
        0.0811], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,093][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0418, 0.0172, 0.0144, 0.0641, 0.0785, 0.0133, 0.0716, 0.0145, 0.0254,
        0.0608, 0.0678, 0.1357, 0.0525, 0.0798, 0.0891, 0.0149, 0.1031, 0.0220,
        0.0336], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,118][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:21,122][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,122][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,123][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,123][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,123][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,124][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,124][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,124][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,124][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,125][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,125][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,126][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,126][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9405, 0.0595], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,127][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.9832, 0.0168], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,127][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8033, 0.1967], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,127][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9748, 0.0252], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,128][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9960, 0.0040], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,128][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3008, 0.6992], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,128][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9121, 0.0879], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,129][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3103, 0.6897], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,129][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8509, 0.1491], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,129][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0680, 0.9320], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,130][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3804, 0.6196], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,130][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2053, 0.7947], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,130][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.7380, 0.0334, 0.2286], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,131][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([0.5063, 0.4150, 0.0787], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,131][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.6021, 0.1614, 0.2366], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,131][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.9308, 0.0175, 0.0517], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,132][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.9295, 0.0191, 0.0514], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,132][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.1661, 0.4847, 0.3492], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,133][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.7840, 0.0757, 0.1403], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,133][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.2391, 0.3573, 0.4036], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,133][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.8653, 0.0348, 0.0998], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,134][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.0829, 0.2879, 0.6292], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,134][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.2862, 0.3075, 0.4063], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,134][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.1751, 0.3071, 0.5178], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,135][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6945, 0.0140, 0.1711, 0.1203], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,136][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.9463, 0.0134, 0.0387, 0.0016], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,136][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6209, 0.0681, 0.1414, 0.1696], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,137][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9311, 0.0092, 0.0345, 0.0251], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,139][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9706, 0.0024, 0.0129, 0.0141], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,143][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1382, 0.3250, 0.2392, 0.2976], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,146][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6729, 0.0713, 0.1219, 0.1339], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,150][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1270, 0.2355, 0.3211, 0.3164], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,150][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6517, 0.0204, 0.1385, 0.1893], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,151][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0301, 0.1098, 0.3046, 0.5554], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,151][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.3307, 0.1761, 0.2051, 0.2881], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,151][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1844, 0.1036, 0.3043, 0.4078], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,152][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.6414, 0.0114, 0.1115, 0.1183, 0.1174], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,152][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0643, 0.3680, 0.0576, 0.4914, 0.0187], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,152][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.5029, 0.0834, 0.1215, 0.1964, 0.0958], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,152][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.8877, 0.0091, 0.0298, 0.0382, 0.0352], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,153][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.8749, 0.0145, 0.0341, 0.0467, 0.0298], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,153][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.0866, 0.2534, 0.1816, 0.2448, 0.2337], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,156][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.6392, 0.0550, 0.0980, 0.1079, 0.1000], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,161][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.1220, 0.1863, 0.2290, 0.2612, 0.2016], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,167][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.8112, 0.0062, 0.0568, 0.0688, 0.0571], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,167][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.0418, 0.1052, 0.1930, 0.5081, 0.1519], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,167][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.1440, 0.1332, 0.1907, 0.2175, 0.3147], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,167][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.1330, 0.0547, 0.1049, 0.2357, 0.4717], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,168][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.6704, 0.0055, 0.0803, 0.0637, 0.0894, 0.0906], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,168][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.4912, 0.1228, 0.1713, 0.1192, 0.0440, 0.0514], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,168][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.5482, 0.0520, 0.1066, 0.1212, 0.0790, 0.0928], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,169][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.8976, 0.0046, 0.0160, 0.0198, 0.0215, 0.0404], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,169][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.9096, 0.0061, 0.0202, 0.0242, 0.0180, 0.0219], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,169][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0851, 0.2039, 0.1364, 0.1783, 0.1864, 0.2099], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,170][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.5854, 0.0534, 0.0906, 0.1006, 0.0901, 0.0798], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,173][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0712, 0.1530, 0.2004, 0.2182, 0.1848, 0.1724], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,177][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.7463, 0.0031, 0.0273, 0.0475, 0.0549, 0.1208], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,183][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0766, 0.0497, 0.1451, 0.2681, 0.2887, 0.1717], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,183][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2709, 0.0887, 0.1035, 0.1644, 0.1855, 0.1870], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,184][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0795, 0.0183, 0.0407, 0.0863, 0.4286, 0.3467], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,184][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.5677, 0.0030, 0.0665, 0.0529, 0.0970, 0.0883, 0.1247],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,184][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.7027, 0.1013, 0.0685, 0.0469, 0.0180, 0.0266, 0.0360],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,185][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.5850, 0.0259, 0.0633, 0.0683, 0.0450, 0.0578, 0.1546],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,185][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.8518, 0.0033, 0.0168, 0.0173, 0.0222, 0.0476, 0.0411],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,185][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.9260, 0.0029, 0.0125, 0.0151, 0.0108, 0.0152, 0.0177],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,186][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0749, 0.1581, 0.1099, 0.1436, 0.1495, 0.1678, 0.1962],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,186][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5835, 0.0486, 0.0777, 0.0864, 0.0766, 0.0652, 0.0619],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,189][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0666, 0.1153, 0.1527, 0.1749, 0.1533, 0.1395, 0.1976],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,194][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.6384, 0.0022, 0.0246, 0.0361, 0.0687, 0.1084, 0.1216],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,199][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0441, 0.0493, 0.1350, 0.2716, 0.1412, 0.1760, 0.1828],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,200][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1384, 0.0903, 0.1192, 0.1523, 0.1854, 0.2371, 0.0773],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,200][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0771, 0.0087, 0.0169, 0.0572, 0.1765, 0.2220, 0.4415],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,200][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.5279, 0.0012, 0.0243, 0.0237, 0.0489, 0.0344, 0.0695, 0.2702],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,201][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.2432, 0.1188, 0.1682, 0.1024, 0.0715, 0.0603, 0.1207, 0.1148],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,201][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.4600, 0.0206, 0.0728, 0.0654, 0.0540, 0.0624, 0.1813, 0.0834],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,201][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.8515, 0.0023, 0.0100, 0.0109, 0.0151, 0.0305, 0.0368, 0.0428],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,202][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.9526, 0.0014, 0.0074, 0.0095, 0.0062, 0.0074, 0.0101, 0.0054],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,202][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0642, 0.1330, 0.0938, 0.1177, 0.1163, 0.1364, 0.1593, 0.1792],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,202][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.6238, 0.0413, 0.0624, 0.0720, 0.0620, 0.0535, 0.0514, 0.0337],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,205][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0708, 0.0964, 0.1188, 0.1416, 0.1161, 0.1151, 0.1682, 0.1730],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,208][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([6.6754e-01, 4.9106e-04, 9.4057e-03, 1.4288e-02, 4.0733e-02, 3.6774e-02,
        8.1421e-02, 1.4935e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,214][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0324, 0.0798, 0.0902, 0.1520, 0.1503, 0.1316, 0.2856, 0.0782],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,216][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.0600, 0.0826, 0.1265, 0.1415, 0.1553, 0.2331, 0.0654, 0.1356],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,216][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.1387, 0.0031, 0.0030, 0.0206, 0.0659, 0.0482, 0.1364, 0.5841],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,217][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.4667, 0.0014, 0.0344, 0.0212, 0.0443, 0.0345, 0.0797, 0.2480, 0.0698],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,217][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.7669, 0.0247, 0.0856, 0.0084, 0.0141, 0.0170, 0.0138, 0.0627, 0.0068],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,217][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.5568, 0.0217, 0.0550, 0.0603, 0.0363, 0.0496, 0.1235, 0.0455, 0.0514],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,218][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.8982, 0.0014, 0.0082, 0.0069, 0.0109, 0.0187, 0.0204, 0.0189, 0.0164],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,218][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.9167, 0.0024, 0.0108, 0.0106, 0.0091, 0.0107, 0.0123, 0.0085, 0.0189],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,218][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.0596, 0.1053, 0.0777, 0.0950, 0.0986, 0.1122, 0.1326, 0.1578, 0.1613],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,219][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.5834, 0.0418, 0.0611, 0.0692, 0.0597, 0.0510, 0.0502, 0.0330, 0.0506],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,219][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0458, 0.0844, 0.1181, 0.1180, 0.1147, 0.1070, 0.1522, 0.1621, 0.0976],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,222][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.4288, 0.0011, 0.0165, 0.0185, 0.0348, 0.0591, 0.0893, 0.2156, 0.1362],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,228][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0420, 0.0259, 0.0991, 0.1157, 0.1397, 0.1613, 0.1335, 0.1693, 0.1135],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,232][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0730, 0.0737, 0.0979, 0.1387, 0.1679, 0.1516, 0.0641, 0.1338, 0.0993],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,233][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0416, 0.0025, 0.0049, 0.0125, 0.0404, 0.0266, 0.0897, 0.6002, 0.1817],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,233][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.2923, 0.0012, 0.0162, 0.0234, 0.0316, 0.0333, 0.0566, 0.2173, 0.1178,
        0.2102], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,233][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0462, 0.1197, 0.0885, 0.0957, 0.0584, 0.0305, 0.1544, 0.1089, 0.1820,
        0.1157], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,234][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.2452, 0.0281, 0.0730, 0.0644, 0.0571, 0.0682, 0.1961, 0.0918, 0.0817,
        0.0945], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,234][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.7877, 0.0019, 0.0105, 0.0114, 0.0136, 0.0277, 0.0339, 0.0320, 0.0396,
        0.0418], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,234][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.8163, 0.0056, 0.0156, 0.0237, 0.0196, 0.0202, 0.0311, 0.0153, 0.0446,
        0.0080], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,235][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0428, 0.0955, 0.0697, 0.0889, 0.0893, 0.1017, 0.1191, 0.1286, 0.1422,
        0.1223], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,236][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.5792, 0.0394, 0.0575, 0.0651, 0.0575, 0.0493, 0.0496, 0.0307, 0.0458,
        0.0258], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,242][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0512, 0.0776, 0.0899, 0.1126, 0.0989, 0.0992, 0.1351, 0.1605, 0.0999,
        0.0751], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,247][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.2544, 0.0005, 0.0043, 0.0145, 0.0208, 0.0352, 0.0510, 0.1175, 0.1328,
        0.3690], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,248][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0069, 0.0322, 0.0478, 0.1286, 0.0916, 0.1402, 0.1863, 0.1158, 0.2020,
        0.0486], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,249][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.0550, 0.0816, 0.0890, 0.1040, 0.1267, 0.1645, 0.0506, 0.1046, 0.1111,
        0.1129], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,249][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([3.5871e-02, 9.0952e-04, 7.0778e-04, 5.2800e-03, 1.7867e-02, 7.6617e-03,
        2.4086e-02, 7.1560e-02, 8.9988e-02, 7.4607e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,249][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.4599, 0.0016, 0.0189, 0.0146, 0.0150, 0.0435, 0.0557, 0.0950, 0.0504,
        0.0502, 0.1951], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,250][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.5884, 0.0439, 0.0415, 0.0232, 0.0074, 0.0159, 0.0376, 0.0683, 0.0282,
        0.1342, 0.0113], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,250][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.2675, 0.0325, 0.0597, 0.0642, 0.0467, 0.0672, 0.1634, 0.0770, 0.0712,
        0.0934, 0.0572], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,250][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.7103, 0.0034, 0.0131, 0.0133, 0.0133, 0.0430, 0.0529, 0.0395, 0.0394,
        0.0339, 0.0378], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,251][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.7639, 0.0050, 0.0187, 0.0238, 0.0216, 0.0228, 0.0308, 0.0240, 0.0560,
        0.0220, 0.0113], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,251][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0488, 0.0792, 0.0578, 0.0732, 0.0747, 0.0864, 0.1032, 0.1218, 0.1268,
        0.1066, 0.1215], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,254][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.4776, 0.0457, 0.0647, 0.0716, 0.0637, 0.0543, 0.0533, 0.0357, 0.0528,
        0.0285, 0.0520], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,259][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0372, 0.0662, 0.1037, 0.1071, 0.0958, 0.0849, 0.1264, 0.1399, 0.0841,
        0.0747, 0.0801], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,265][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.4210, 0.0005, 0.0051, 0.0067, 0.0059, 0.0350, 0.0359, 0.0396, 0.0454,
        0.0318, 0.3732], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,265][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0053, 0.0243, 0.0469, 0.0991, 0.1261, 0.1083, 0.1254, 0.1263, 0.1889,
        0.0881, 0.0612], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,265][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.0401, 0.0608, 0.0810, 0.1112, 0.1379, 0.1196, 0.0571, 0.1018, 0.0862,
        0.1187, 0.0856], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,266][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([7.0056e-02, 5.2553e-04, 6.8550e-04, 1.7634e-03, 2.0465e-03, 5.5518e-03,
        1.4322e-02, 2.1929e-02, 2.4707e-02, 3.9736e-02, 8.1868e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,266][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.4441, 0.0008, 0.0118, 0.0086, 0.0083, 0.0222, 0.0254, 0.0489, 0.0303,
        0.0223, 0.1725, 0.2047], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,266][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.7891, 0.0279, 0.0109, 0.0048, 0.0047, 0.0098, 0.0119, 0.0265, 0.0101,
        0.0351, 0.0107, 0.0584], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,267][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.3188, 0.0252, 0.0570, 0.0549, 0.0430, 0.0574, 0.1451, 0.0588, 0.0565,
        0.0540, 0.0460, 0.0833], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,267][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.6678, 0.0034, 0.0126, 0.0129, 0.0121, 0.0468, 0.0441, 0.0419, 0.0372,
        0.0363, 0.0373, 0.0475], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,268][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.7395, 0.0053, 0.0174, 0.0254, 0.0217, 0.0286, 0.0343, 0.0251, 0.0531,
        0.0204, 0.0099, 0.0194], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,269][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0393, 0.0713, 0.0521, 0.0661, 0.0648, 0.0778, 0.0918, 0.1033, 0.1121,
        0.0913, 0.1103, 0.1200], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,275][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.4871, 0.0410, 0.0601, 0.0662, 0.0582, 0.0487, 0.0472, 0.0298, 0.0454,
        0.0236, 0.0442, 0.0484], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,280][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0294, 0.0611, 0.0866, 0.0937, 0.0871, 0.0787, 0.1119, 0.1272, 0.0762,
        0.0706, 0.0798, 0.0979], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,281][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([4.5692e-01, 2.8804e-04, 2.2304e-03, 2.5882e-03, 2.3216e-03, 1.0928e-02,
        1.0996e-02, 1.0051e-02, 1.6868e-02, 8.6079e-03, 2.1501e-01, 2.6319e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,282][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0099, 0.0368, 0.0473, 0.1269, 0.0588, 0.0985, 0.1014, 0.1100, 0.1984,
        0.0732, 0.0751, 0.0637], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,282][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.0573, 0.0494, 0.0857, 0.0903, 0.1154, 0.1337, 0.0454, 0.0887, 0.0820,
        0.1104, 0.0805, 0.0611], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,282][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([2.0052e-02, 1.7018e-04, 9.6494e-05, 4.8500e-04, 3.4997e-04, 1.5929e-03,
        2.4464e-03, 5.3825e-03, 7.9099e-03, 1.0564e-02, 5.3550e-01, 4.1545e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,283][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.2798, 0.0005, 0.0057, 0.0051, 0.0047, 0.0159, 0.0166, 0.0267, 0.0213,
        0.0158, 0.1813, 0.2526, 0.1740], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,283][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.2872, 0.0516, 0.0459, 0.0357, 0.0082, 0.0182, 0.0384, 0.0146, 0.0495,
        0.0934, 0.0776, 0.1893, 0.0902], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,283][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.2414, 0.0233, 0.0444, 0.0577, 0.0321, 0.0569, 0.1276, 0.0516, 0.0598,
        0.0531, 0.0497, 0.0789, 0.1233], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,284][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.6722, 0.0020, 0.0085, 0.0102, 0.0084, 0.0299, 0.0318, 0.0292, 0.0310,
        0.0331, 0.0402, 0.0529, 0.0507], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,284][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.6492, 0.0136, 0.0245, 0.0356, 0.0381, 0.0352, 0.0414, 0.0331, 0.0504,
        0.0191, 0.0132, 0.0244, 0.0224], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,287][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0317, 0.0656, 0.0467, 0.0607, 0.0578, 0.0707, 0.0839, 0.0863, 0.1028,
        0.0748, 0.1051, 0.1160, 0.0979], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,293][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.4974, 0.0347, 0.0534, 0.0611, 0.0534, 0.0451, 0.0435, 0.0270, 0.0416,
        0.0218, 0.0404, 0.0432, 0.0374], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,297][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0335, 0.0554, 0.0776, 0.0785, 0.0768, 0.0702, 0.1039, 0.1114, 0.0781,
        0.0638, 0.0827, 0.0916, 0.0764], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,298][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([2.7280e-01, 1.2713e-04, 1.3466e-03, 1.2933e-03, 1.2835e-03, 4.9461e-03,
        6.8635e-03, 4.7684e-03, 7.8173e-03, 4.5537e-03, 1.2417e-01, 3.0965e-01,
        2.6039e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,298][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0036, 0.0459, 0.0334, 0.1038, 0.0555, 0.0878, 0.1410, 0.0883, 0.1935,
        0.0557, 0.0662, 0.1024, 0.0229], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,298][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0710, 0.0464, 0.0673, 0.0840, 0.0946, 0.1223, 0.0378, 0.0813, 0.0654,
        0.0650, 0.0590, 0.0599, 0.1460], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,299][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([3.2704e-02, 1.2328e-04, 8.9477e-05, 2.5015e-04, 2.5612e-04, 7.3806e-04,
        1.2391e-03, 1.1403e-03, 3.2261e-03, 2.7075e-03, 2.4792e-01, 2.3211e-01,
        4.7750e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,299][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.2336, 0.0004, 0.0074, 0.0053, 0.0075, 0.0123, 0.0166, 0.0368, 0.0188,
        0.0340, 0.0901, 0.1984, 0.2246, 0.1144], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,300][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.3925, 0.0074, 0.0170, 0.0015, 0.0051, 0.0091, 0.0123, 0.0375, 0.0055,
        0.0291, 0.0156, 0.1689, 0.2938, 0.0048], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,300][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1956, 0.0263, 0.0507, 0.0573, 0.0444, 0.0497, 0.1225, 0.0596, 0.0470,
        0.0576, 0.0464, 0.0869, 0.1123, 0.0438], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,300][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.6588, 0.0017, 0.0103, 0.0085, 0.0104, 0.0273, 0.0258, 0.0260, 0.0284,
        0.0340, 0.0320, 0.0423, 0.0571, 0.0374], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,301][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.7955, 0.0041, 0.0177, 0.0190, 0.0177, 0.0220, 0.0200, 0.0147, 0.0357,
        0.0112, 0.0073, 0.0133, 0.0123, 0.0096], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,304][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0308, 0.0602, 0.0429, 0.0543, 0.0542, 0.0625, 0.0763, 0.0839, 0.0946,
        0.0766, 0.0928, 0.1011, 0.0900, 0.0800], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,309][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.4799, 0.0340, 0.0519, 0.0581, 0.0509, 0.0424, 0.0404, 0.0253, 0.0393,
        0.0202, 0.0376, 0.0408, 0.0354, 0.0438], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,314][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0253, 0.0530, 0.0739, 0.0722, 0.0701, 0.0679, 0.1083, 0.1095, 0.0684,
        0.0575, 0.0720, 0.0928, 0.0801, 0.0490], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,315][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([1.4892e-01, 1.6394e-04, 1.6569e-03, 1.7886e-03, 1.9897e-03, 4.7640e-03,
        8.2105e-03, 9.2925e-03, 9.4339e-03, 1.2541e-02, 9.2919e-02, 2.5732e-01,
        3.5642e-01, 9.4576e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,315][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0036, 0.0396, 0.0357, 0.0953, 0.0650, 0.0795, 0.1128, 0.1165, 0.1378,
        0.0831, 0.0625, 0.0778, 0.0388, 0.0519], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,315][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.0474, 0.0391, 0.0688, 0.0771, 0.0791, 0.0838, 0.0399, 0.0816, 0.0683,
        0.0902, 0.0728, 0.0595, 0.1370, 0.0555], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,316][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([2.6897e-03, 4.6687e-05, 4.5445e-05, 1.4997e-04, 1.6561e-04, 2.9608e-04,
        5.0139e-04, 1.1556e-03, 1.5184e-03, 4.1844e-03, 1.5271e-01, 2.5214e-01,
        5.3291e-01, 5.1486e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,316][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.2236, 0.0003, 0.0030, 0.0029, 0.0025, 0.0047, 0.0049, 0.0050, 0.0079,
        0.0054, 0.1454, 0.2184, 0.1778, 0.0645, 0.1338], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,317][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0269, 0.0808, 0.0103, 0.0768, 0.0033, 0.0121, 0.0536, 0.0185, 0.0505,
        0.0196, 0.0919, 0.3905, 0.1187, 0.0375, 0.0090], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,317][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.2298, 0.0268, 0.0350, 0.0558, 0.0220, 0.0422, 0.1008, 0.0368, 0.0436,
        0.0635, 0.0467, 0.0877, 0.1374, 0.0510, 0.0210], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,320][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.5789, 0.0027, 0.0103, 0.0133, 0.0102, 0.0368, 0.0268, 0.0206, 0.0218,
        0.0273, 0.0418, 0.0622, 0.0599, 0.0420, 0.0455], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,326][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.6374, 0.0121, 0.0208, 0.0326, 0.0278, 0.0321, 0.0365, 0.0342, 0.0539,
        0.0179, 0.0135, 0.0171, 0.0263, 0.0184, 0.0193], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,330][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.0231, 0.0554, 0.0381, 0.0519, 0.0484, 0.0597, 0.0684, 0.0815, 0.0880,
        0.0703, 0.0892, 0.1010, 0.0948, 0.0800, 0.0502], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,331][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.4583, 0.0307, 0.0485, 0.0556, 0.0497, 0.0410, 0.0395, 0.0244, 0.0375,
        0.0198, 0.0359, 0.0384, 0.0336, 0.0401, 0.0471], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,331][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0361, 0.0561, 0.0681, 0.0762, 0.0662, 0.0624, 0.0792, 0.0999, 0.0633,
        0.0541, 0.0704, 0.0780, 0.0700, 0.0557, 0.0642], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,331][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([1.6946e-01, 6.1948e-05, 9.1384e-04, 6.5111e-04, 5.3007e-04, 1.6159e-03,
        1.6129e-03, 7.6263e-04, 2.4909e-03, 1.2074e-03, 1.2589e-01, 1.9758e-01,
        3.3168e-01, 4.8131e-02, 1.1741e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,332][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.0023, 0.0236, 0.0344, 0.0876, 0.0279, 0.1082, 0.0997, 0.0868, 0.1949,
        0.0490, 0.0751, 0.0892, 0.0544, 0.0469, 0.0200], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,332][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0288, 0.0333, 0.0546, 0.0524, 0.0857, 0.0968, 0.0291, 0.0648, 0.0593,
        0.0737, 0.0524, 0.0442, 0.1496, 0.0426, 0.1328], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,333][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([6.9994e-03, 4.9858e-05, 4.6692e-05, 1.1115e-04, 9.5320e-05, 1.7426e-04,
        2.3055e-04, 1.7965e-04, 7.7415e-04, 6.7369e-04, 1.8655e-01, 2.0950e-01,
        4.7618e-01, 3.8208e-02, 8.0229e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,333][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([3.4424e-01, 3.3612e-04, 5.4478e-03, 2.8408e-03, 2.6868e-03, 9.3766e-03,
        9.5435e-03, 1.0827e-02, 7.6522e-03, 2.6594e-03, 5.5352e-02, 7.9482e-02,
        6.5414e-02, 5.0182e-02, 4.0662e-02, 3.1330e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,333][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1890, 0.0361, 0.0654, 0.0123, 0.0142, 0.0060, 0.0221, 0.0271, 0.0140,
        0.0957, 0.0453, 0.1659, 0.2231, 0.0203, 0.0346, 0.0290],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,336][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.2652, 0.0172, 0.0436, 0.0368, 0.0366, 0.0436, 0.0936, 0.0521, 0.0389,
        0.0466, 0.0359, 0.0616, 0.1075, 0.0402, 0.0379, 0.0428],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,341][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.7238, 0.0012, 0.0069, 0.0061, 0.0067, 0.0189, 0.0176, 0.0171, 0.0201,
        0.0151, 0.0240, 0.0269, 0.0363, 0.0235, 0.0253, 0.0305],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,347][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.6458, 0.0120, 0.0271, 0.0341, 0.0299, 0.0305, 0.0416, 0.0316, 0.0508,
        0.0140, 0.0121, 0.0193, 0.0171, 0.0147, 0.0155, 0.0041],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,347][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0288, 0.0538, 0.0362, 0.0478, 0.0463, 0.0557, 0.0680, 0.0776, 0.0832,
        0.0650, 0.0807, 0.0903, 0.0805, 0.0719, 0.0466, 0.0676],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,348][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.4057, 0.0324, 0.0487, 0.0547, 0.0489, 0.0407, 0.0395, 0.0250, 0.0373,
        0.0204, 0.0375, 0.0410, 0.0357, 0.0423, 0.0477, 0.0424],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,348][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0185, 0.0459, 0.0618, 0.0699, 0.0654, 0.0567, 0.0808, 0.0947, 0.0609,
        0.0546, 0.0682, 0.0794, 0.0657, 0.0497, 0.0677, 0.0600],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,348][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([3.5646e-01, 7.0908e-05, 7.8989e-04, 5.5420e-04, 3.6437e-04, 2.7397e-03,
        2.7135e-03, 1.6814e-03, 2.3915e-03, 8.0558e-04, 4.0729e-02, 7.3909e-02,
        8.7103e-02, 2.6554e-02, 2.3301e-02, 3.7984e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,349][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.0066, 0.0162, 0.0306, 0.0528, 0.0678, 0.0666, 0.0960, 0.0676, 0.1528,
        0.0592, 0.0791, 0.0963, 0.0449, 0.0680, 0.0734, 0.0222],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,349][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.0294, 0.0322, 0.0564, 0.0596, 0.0746, 0.0791, 0.0354, 0.0650, 0.0574,
        0.0736, 0.0525, 0.0512, 0.1283, 0.0409, 0.1128, 0.0515],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,350][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([7.6838e-02, 5.7915e-05, 6.2882e-05, 1.1388e-04, 7.0462e-05, 2.5875e-04,
        4.7792e-04, 3.3940e-04, 1.0073e-03, 2.3921e-04, 4.4922e-02, 4.1908e-02,
        1.1547e-01, 8.3014e-03, 9.0958e-03, 7.0084e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,350][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([2.5959e-01, 1.9246e-04, 2.8120e-03, 2.0112e-03, 1.7546e-03, 6.9745e-03,
        6.6432e-03, 1.6476e-02, 8.6814e-03, 5.7311e-03, 3.0302e-02, 4.6988e-02,
        5.7515e-02, 4.6995e-02, 4.2079e-02, 2.3750e-01, 2.2776e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,350][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2327, 0.0329, 0.0137, 0.0089, 0.0030, 0.0072, 0.0068, 0.0824, 0.0251,
        0.0623, 0.0407, 0.2109, 0.1675, 0.0244, 0.0102, 0.0484, 0.0229],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,354][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2981, 0.0173, 0.0396, 0.0360, 0.0313, 0.0403, 0.0902, 0.0474, 0.0364,
        0.0406, 0.0298, 0.0563, 0.0816, 0.0340, 0.0274, 0.0377, 0.0560],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,360][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.6439, 0.0013, 0.0060, 0.0071, 0.0055, 0.0230, 0.0200, 0.0226, 0.0241,
        0.0234, 0.0223, 0.0253, 0.0322, 0.0273, 0.0252, 0.0351, 0.0556],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,364][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.7614, 0.0052, 0.0142, 0.0196, 0.0191, 0.0191, 0.0229, 0.0204, 0.0334,
        0.0151, 0.0076, 0.0150, 0.0144, 0.0111, 0.0082, 0.0042, 0.0091],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,364][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0304, 0.0507, 0.0341, 0.0449, 0.0442, 0.0523, 0.0627, 0.0741, 0.0775,
        0.0630, 0.0723, 0.0789, 0.0723, 0.0651, 0.0446, 0.0597, 0.0731],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,365][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4337, 0.0308, 0.0452, 0.0504, 0.0444, 0.0367, 0.0356, 0.0219, 0.0331,
        0.0180, 0.0329, 0.0362, 0.0307, 0.0377, 0.0421, 0.0364, 0.0341],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,365][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0239, 0.0432, 0.0550, 0.0648, 0.0613, 0.0526, 0.0696, 0.0818, 0.0555,
        0.0501, 0.0573, 0.0659, 0.0658, 0.0480, 0.0629, 0.0602, 0.0821],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,365][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.8400e-01, 4.1498e-05, 4.5383e-04, 4.6397e-04, 3.8714e-04, 2.3165e-03,
        1.7469e-03, 2.1676e-03, 3.0756e-03, 1.7094e-03, 2.3386e-02, 3.8792e-02,
        7.7934e-02, 2.7531e-02, 3.2192e-02, 3.1069e-01, 2.9310e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,366][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0052, 0.0283, 0.0395, 0.0826, 0.0537, 0.0711, 0.0612, 0.1316, 0.1364,
        0.0638, 0.0556, 0.0633, 0.0347, 0.0525, 0.0442, 0.0336, 0.0427],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,366][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0376, 0.0355, 0.0507, 0.0511, 0.0735, 0.0847, 0.0270, 0.0581, 0.0495,
        0.0742, 0.0485, 0.0401, 0.1219, 0.0390, 0.1241, 0.0505, 0.0340],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,366][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.3150e-02, 1.1605e-05, 7.5304e-06, 3.0970e-05, 1.6040e-05, 7.8947e-05,
        1.3955e-04, 3.4948e-04, 5.4716e-04, 4.7979e-04, 2.5753e-02, 2.1420e-02,
        7.2946e-02, 6.2021e-03, 5.9682e-03, 4.7104e-01, 3.8186e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,367][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([1.2973e-01, 8.5500e-05, 9.4004e-04, 6.1186e-04, 7.4829e-04, 2.0358e-03,
        3.4220e-03, 4.1826e-03, 2.7343e-03, 1.9807e-03, 2.9213e-02, 5.5729e-02,
        4.7594e-02, 2.7527e-02, 4.0916e-02, 2.4512e-01, 2.7938e-01, 1.2804e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,370][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0244, 0.0529, 0.0079, 0.0198, 0.0062, 0.0087, 0.0315, 0.0231, 0.0491,
        0.0282, 0.0704, 0.2257, 0.1923, 0.0354, 0.0184, 0.0805, 0.0965, 0.0288],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,376][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.2212, 0.0148, 0.0260, 0.0320, 0.0224, 0.0354, 0.0912, 0.0434, 0.0453,
        0.0355, 0.0393, 0.0651, 0.0905, 0.0397, 0.0285, 0.0441, 0.0777, 0.0479],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,380][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.5851, 0.0006, 0.0050, 0.0041, 0.0049, 0.0119, 0.0132, 0.0115, 0.0169,
        0.0168, 0.0206, 0.0290, 0.0385, 0.0224, 0.0327, 0.0412, 0.0554, 0.0898],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,381][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.7889, 0.0078, 0.0155, 0.0238, 0.0210, 0.0178, 0.0197, 0.0168, 0.0236,
        0.0060, 0.0044, 0.0132, 0.0094, 0.0085, 0.0100, 0.0021, 0.0050, 0.0065],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,381][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0232, 0.0468, 0.0326, 0.0425, 0.0411, 0.0489, 0.0583, 0.0634, 0.0719,
        0.0548, 0.0710, 0.0782, 0.0685, 0.0622, 0.0424, 0.0585, 0.0706, 0.0652],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,382][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.4455, 0.0272, 0.0393, 0.0456, 0.0406, 0.0344, 0.0341, 0.0212, 0.0319,
        0.0184, 0.0315, 0.0340, 0.0292, 0.0343, 0.0390, 0.0355, 0.0330, 0.0253],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,382][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0340, 0.0405, 0.0506, 0.0602, 0.0535, 0.0490, 0.0668, 0.0768, 0.0518,
        0.0413, 0.0545, 0.0627, 0.0588, 0.0433, 0.0525, 0.0576, 0.0779, 0.0683],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,382][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([7.4662e-02, 8.3100e-06, 1.0530e-04, 1.2127e-04, 1.0344e-04, 5.1606e-04,
        7.2453e-04, 4.8309e-04, 8.9498e-04, 5.3269e-04, 1.8224e-02, 3.5187e-02,
        5.9982e-02, 1.1980e-02, 2.2785e-02, 3.4809e-01, 3.1002e-01, 1.1559e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,383][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.0008, 0.0316, 0.0160, 0.0648, 0.0309, 0.0430, 0.0671, 0.1096, 0.1620,
        0.0739, 0.0555, 0.0702, 0.0609, 0.0625, 0.0330, 0.0252, 0.0533, 0.0395],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,386][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0308, 0.0384, 0.0509, 0.0484, 0.0599, 0.0723, 0.0278, 0.0519, 0.0568,
        0.0654, 0.0495, 0.0413, 0.1374, 0.0432, 0.0926, 0.0409, 0.0353, 0.0570],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,390][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([7.1418e-03, 1.0103e-05, 4.5209e-06, 2.1350e-05, 1.2451e-05, 4.0556e-05,
        7.0897e-05, 8.4209e-05, 2.2032e-04, 1.7844e-04, 2.0369e-02, 2.2736e-02,
        4.8553e-02, 5.5987e-03, 7.2381e-03, 5.1504e-01, 2.9308e-01, 7.9603e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,393][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([1.9162e-01, 1.3074e-04, 2.2447e-03, 1.0602e-03, 1.1680e-03, 3.3720e-03,
        4.7853e-03, 5.8849e-03, 3.5687e-03, 2.3708e-03, 1.6479e-02, 3.3124e-02,
        3.8089e-02, 2.5698e-02, 2.5336e-02, 1.5978e-01, 2.0188e-01, 1.0617e-01,
        1.7726e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,396][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.4575, 0.0143, 0.0148, 0.0016, 0.0031, 0.0054, 0.0078, 0.0396, 0.0032,
        0.0488, 0.0058, 0.0881, 0.1586, 0.0040, 0.0112, 0.0347, 0.0316, 0.0669,
        0.0028], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,397][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.2562, 0.0183, 0.0343, 0.0366, 0.0270, 0.0384, 0.0802, 0.0456, 0.0378,
        0.0393, 0.0310, 0.0526, 0.0739, 0.0333, 0.0244, 0.0361, 0.0520, 0.0407,
        0.0422], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,397][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.5957, 0.0009, 0.0044, 0.0046, 0.0043, 0.0149, 0.0141, 0.0117, 0.0157,
        0.0163, 0.0179, 0.0205, 0.0294, 0.0205, 0.0209, 0.0275, 0.0529, 0.0846,
        0.0432], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,398][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.7429, 0.0048, 0.0180, 0.0192, 0.0220, 0.0193, 0.0196, 0.0168, 0.0317,
        0.0139, 0.0069, 0.0155, 0.0126, 0.0118, 0.0123, 0.0051, 0.0087, 0.0088,
        0.0101], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,398][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0279, 0.0439, 0.0304, 0.0387, 0.0384, 0.0458, 0.0549, 0.0626, 0.0679,
        0.0541, 0.0639, 0.0688, 0.0606, 0.0569, 0.0388, 0.0533, 0.0652, 0.0604,
        0.0673], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,398][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.3674, 0.0304, 0.0448, 0.0497, 0.0449, 0.0368, 0.0361, 0.0230, 0.0343,
        0.0199, 0.0344, 0.0354, 0.0302, 0.0355, 0.0396, 0.0352, 0.0330, 0.0254,
        0.0442], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,399][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0203, 0.0363, 0.0490, 0.0521, 0.0501, 0.0452, 0.0630, 0.0688, 0.0470,
        0.0420, 0.0490, 0.0594, 0.0547, 0.0387, 0.0507, 0.0537, 0.0756, 0.0682,
        0.0763], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,399][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([9.2908e-02, 1.8291e-05, 2.5252e-04, 2.1790e-04, 1.5374e-04, 1.1488e-03,
        1.2389e-03, 7.5472e-04, 1.2736e-03, 4.9569e-04, 1.3332e-02, 2.5410e-02,
        4.6937e-02, 1.1562e-02, 1.2714e-02, 2.1287e-01, 2.5254e-01, 8.5233e-02,
        2.4094e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,400][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0052, 0.0204, 0.0303, 0.0646, 0.0500, 0.0753, 0.0672, 0.0808, 0.1057,
        0.0589, 0.0623, 0.0599, 0.0332, 0.0518, 0.0437, 0.0314, 0.0554, 0.0357,
        0.0684], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,403][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0215, 0.0246, 0.0568, 0.0491, 0.0699, 0.0765, 0.0232, 0.0650, 0.0407,
        0.0737, 0.0453, 0.0352, 0.1190, 0.0281, 0.1151, 0.0445, 0.0269, 0.0583,
        0.0266], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,405][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.0184e-02, 6.5752e-06, 4.2262e-06, 1.1210e-05, 6.1335e-06, 3.8068e-05,
        6.5200e-05, 7.0369e-05, 1.4739e-04, 9.1141e-05, 1.0752e-02, 1.0017e-02,
        2.9771e-02, 2.0152e-03, 1.4183e-03, 3.0772e-01, 1.7810e-01, 3.5041e-02,
        4.1453e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,406][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:21,409][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[11249],
        [10177],
        [30104],
        [ 8219],
        [ 6770],
        [ 6406],
        [ 8813],
        [ 4364],
        [ 6921],
        [ 5746],
        [ 3356],
        [ 2893],
        [ 2401],
        [ 2568],
        [ 4168],
        [ 2694],
        [ 4921],
        [ 1334],
        [ 2076]], device='cuda:0')
[2024-07-24 10:27:21,412][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11187],
        [17308],
        [47526],
        [17141],
        [26714],
        [18579],
        [28199],
        [23473],
        [26672],
        [29922],
        [26199],
        [19829],
        [11931],
        [10869],
        [25352],
        [11194],
        [21301],
        [ 6247],
        [16914]], device='cuda:0')
[2024-07-24 10:27:21,415][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[19365],
        [20741],
        [24250],
        [24468],
        [28105],
        [28213],
        [31974],
        [34379],
        [33264],
        [33369],
        [28415],
        [32101],
        [32436],
        [32478],
        [31245],
        [30917],
        [30658],
        [30899],
        [29984]], device='cuda:0')
[2024-07-24 10:27:21,417][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[6574],
        [3863],
        [4196],
        [4830],
        [5045],
        [5127],
        [5290],
        [5161],
        [5230],
        [4917],
        [4812],
        [4673],
        [4322],
        [4307],
        [4404],
        [4391],
        [4512],
        [4473],
        [4582]], device='cuda:0')
[2024-07-24 10:27:21,418][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[15542],
        [17108],
        [16689],
        [17537],
        [18361],
        [18303],
        [18445],
        [17715],
        [17355],
        [16763],
        [16210],
        [16079],
        [15724],
        [15270],
        [15202],
        [14602],
        [14193],
        [13643],
        [13574]], device='cuda:0')
[2024-07-24 10:27:21,419][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 4021],
        [ 4371],
        [30386],
        [ 6632],
        [33880],
        [ 9049],
        [10824],
        [21840],
        [10943],
        [27844],
        [12170],
        [11078],
        [26642],
        [ 6079],
        [27698],
        [18893],
        [12943],
        [27810],
        [13942]], device='cuda:0')
[2024-07-24 10:27:21,420][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 3538],
        [ 4806],
        [ 8110],
        [ 5061],
        [ 8501],
        [ 8131],
        [ 9890],
        [ 9459],
        [ 9411],
        [11473],
        [11176],
        [11683],
        [11089],
        [10038],
        [11518],
        [11661],
        [12222],
        [11852],
        [12751]], device='cuda:0')
[2024-07-24 10:27:21,423][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[10175],
        [25377],
        [28827],
        [30164],
        [32312],
        [33577],
        [33829],
        [33812],
        [33866],
        [34908],
        [35188],
        [35443],
        [35743],
        [35860],
        [36193],
        [36354],
        [36253],
        [36320],
        [36271]], device='cuda:0')
[2024-07-24 10:27:21,426][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[3278],
        [3172],
        [5721],
        [3170],
        [3747],
        [3430],
        [3263],
        [3085],
        [3053],
        [1766],
        [2701],
        [2966],
        [1148],
        [2417],
        [2204],
        [2149],
        [2565],
        [1361],
        [2569]], device='cuda:0')
[2024-07-24 10:27:21,428][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[ 3442],
        [ 6271],
        [12850],
        [10206],
        [11531],
        [11801],
        [10432],
        [ 9777],
        [ 8870],
        [ 8715],
        [ 8434],
        [ 8180],
        [ 8252],
        [ 8170],
        [ 8076],
        [ 7781],
        [ 7128],
        [ 7400],
        [ 7162]], device='cuda:0')
[2024-07-24 10:27:21,431][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21089],
        [16159],
        [20905],
        [21954],
        [20603],
        [22252],
        [23545],
        [23758],
        [23403],
        [21234],
        [21104],
        [21355],
        [22178],
        [23607],
        [23149],
        [22787],
        [23159],
        [23047],
        [23359]], device='cuda:0')
[2024-07-24 10:27:21,434][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39614],
        [26228],
        [28124],
        [22889],
        [25102],
        [21655],
        [19653],
        [18459],
        [16467],
        [15490],
        [15376],
        [13554],
        [14994],
        [13101],
        [14807],
        [14478],
        [13679],
        [14944],
        [13527]], device='cuda:0')
[2024-07-24 10:27:21,436][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[35925],
        [38634],
        [37714],
        [37172],
        [35602],
        [35459],
        [34090],
        [33329],
        [31225],
        [30000],
        [29264],
        [28493],
        [28417],
        [28245],
        [28185],
        [26760],
        [26461],
        [27239],
        [27055]], device='cuda:0')
[2024-07-24 10:27:21,437][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35601],
        [26915],
        [26195],
        [15102],
        [20427],
        [16865],
        [14939],
        [16709],
        [13094],
        [16520],
        [18661],
        [19596],
        [20471],
        [21419],
        [22535],
        [22344],
        [17855],
        [21038],
        [15739]], device='cuda:0')
[2024-07-24 10:27:21,438][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 2556],
        [10803],
        [   21],
        [ 5425],
        [  267],
        [ 3452],
        [ 5992],
        [ 1711],
        [ 9457],
        [  757],
        [ 2628],
        [ 3783],
        [  630],
        [ 5064],
        [ 1678],
        [ 3597],
        [ 6548],
        [  528],
        [ 6455]], device='cuda:0')
[2024-07-24 10:27:21,439][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[28826],
        [25549],
        [15478],
        [11706],
        [ 9214],
        [10881],
        [10321],
        [19404],
        [17610],
        [14655],
        [20229],
        [22880],
        [21814],
        [19876],
        [18834],
        [18313],
        [22395],
        [22609],
        [21275]], device='cuda:0')
[2024-07-24 10:27:21,440][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 9921],
        [ 8888],
        [20585],
        [10087],
        [24308],
        [24757],
        [16434],
        [22724],
        [13577],
        [25732],
        [25348],
        [13112],
        [22642],
        [27907],
        [19386],
        [25994],
        [20861],
        [19435],
        [22840]], device='cuda:0')
[2024-07-24 10:27:21,442][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[4357],
        [1493],
        [ 446],
        [ 423],
        [ 263],
        [ 235],
        [ 270],
        [ 284],
        [ 266],
        [ 402],
        [ 407],
        [ 320],
        [ 410],
        [ 390],
        [ 450],
        [ 366],
        [ 369],
        [ 527],
        [ 456]], device='cuda:0')
[2024-07-24 10:27:21,444][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 2582],
        [ 4228],
        [ 6926],
        [ 7247],
        [14041],
        [12124],
        [14469],
        [11645],
        [ 9446],
        [14749],
        [14740],
        [14534],
        [15124],
        [16588],
        [18425],
        [15982],
        [14367],
        [11789],
        [11333]], device='cuda:0')
[2024-07-24 10:27:21,447][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[22111],
        [21938],
        [17914],
        [20505],
        [16591],
        [17359],
        [18050],
        [19719],
        [17986],
        [15079],
        [15031],
        [14717],
        [16730],
        [15599],
        [16440],
        [16077],
        [15812],
        [15663],
        [15886]], device='cuda:0')
[2024-07-24 10:27:21,450][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[12684],
        [ 7827],
        [ 5373],
        [ 5758],
        [ 4286],
        [ 4029],
        [ 3707],
        [ 3883],
        [ 3968],
        [ 3549],
        [ 3524],
        [ 3867],
        [ 3539],
        [ 3519],
        [ 3309],
        [ 3301],
        [ 3229],
        [ 3053],
        [ 3039]], device='cuda:0')
[2024-07-24 10:27:21,452][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[15675],
        [18215],
        [20331],
        [21896],
        [22305],
        [22366],
        [22471],
        [21610],
        [21862],
        [21851],
        [23049],
        [23360],
        [23294],
        [23411],
        [23592],
        [23896],
        [23901],
        [24139],
        [25167]], device='cuda:0')
[2024-07-24 10:27:21,455][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22800],
        [15078],
        [13948],
        [13907],
        [14337],
        [14550],
        [14384],
        [14975],
        [14641],
        [14452],
        [14388],
        [14013],
        [13755],
        [13428],
        [13511],
        [12940],
        [12389],
        [12324],
        [12152]], device='cuda:0')
[2024-07-24 10:27:21,458][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[13989],
        [14052],
        [ 9917],
        [ 6726],
        [ 9028],
        [ 6459],
        [ 6410],
        [10754],
        [ 8538],
        [ 5441],
        [ 6155],
        [ 7664],
        [ 6732],
        [ 5867],
        [ 5092],
        [ 2961],
        [ 3807],
        [ 5034],
        [ 5792]], device='cuda:0')
[2024-07-24 10:27:21,459][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[5386],
        [ 561],
        [ 771],
        [ 625],
        [ 618],
        [ 569],
        [ 460],
        [ 457],
        [ 470],
        [ 436],
        [ 446],
        [ 448],
        [ 456],
        [ 432],
        [ 428],
        [ 444],
        [ 439],
        [ 450],
        [ 417]], device='cuda:0')
[2024-07-24 10:27:21,460][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[1102],
        [5808],
        [4586],
        [4905],
        [5041],
        [4694],
        [4823],
        [5453],
        [5365],
        [5523],
        [5803],
        [5627],
        [5740],
        [5989],
        [6107],
        [5924],
        [5952],
        [5782],
        [5821]], device='cuda:0')
[2024-07-24 10:27:21,461][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 3052],
        [ 1628],
        [ 2568],
        [ 3136],
        [13925],
        [19714],
        [19938],
        [23471],
        [21691],
        [13923],
        [10726],
        [12809],
        [12389],
        [12077],
        [13511],
        [ 7715],
        [ 8669],
        [ 7791],
        [ 6870]], device='cuda:0')
[2024-07-24 10:27:21,462][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[48381],
        [49396],
        [49477],
        [49910],
        [48993],
        [49126],
        [49284],
        [47885],
        [48852],
        [48657],
        [48587],
        [48814],
        [48227],
        [48325],
        [48414],
        [48927],
        [48874],
        [48823],
        [48753]], device='cuda:0')
[2024-07-24 10:27:21,465][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[46633],
        [47576],
        [50017],
        [48463],
        [49739],
        [48962],
        [46107],
        [47626],
        [42858],
        [48590],
        [47362],
        [47193],
        [49279],
        [47179],
        [47254],
        [48957],
        [46335],
        [48961],
        [44997]], device='cuda:0')
[2024-07-24 10:27:21,467][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600],
        [12600]], device='cuda:0')
[2024-07-24 10:27:21,496][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:21,496][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,497][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,497][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,497][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,498][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,498][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,498][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,499][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,499][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,499][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,500][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,500][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,500][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.7083, 0.2917], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,501][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6030, 0.3970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,501][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([4.2487e-05, 9.9996e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,501][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9222, 0.0778], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,501][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4416, 0.5584], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,502][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8710, 0.1290], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,502][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3029, 0.6971], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,502][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2073, 0.7927], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,503][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.2538, 0.7462], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,503][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.4238, 0.5762], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,503][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0034, 0.9966], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,504][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0866, 0.9134], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,504][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.2857, 0.3081, 0.4062], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,504][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([0.0895, 0.1420, 0.7686], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,505][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([2.6867e-05, 8.6861e-01, 1.3136e-01], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,505][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.6593, 0.2402, 0.1005], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,505][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.2704, 0.3647, 0.3649], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,506][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([0.4102, 0.3528, 0.2370], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,506][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.1963, 0.4213, 0.3824], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,507][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.0447, 0.2852, 0.6701], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,510][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.3906, 0.4147, 0.1947], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,514][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.3498, 0.3514, 0.2988], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,518][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.0046, 0.6271, 0.3683], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,520][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.0047, 0.9094, 0.0859], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,520][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1544, 0.0492, 0.2989, 0.4975], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,520][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2645, 0.0989, 0.4502, 0.1865], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,521][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([2.0953e-05, 3.9653e-01, 5.7738e-02, 5.4571e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,521][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.8253, 0.0878, 0.0529, 0.0340], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,521][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1993, 0.2515, 0.2587, 0.2906], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,522][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7891, 0.0614, 0.0971, 0.0524], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,522][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1567, 0.2809, 0.2676, 0.2948], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,522][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0253, 0.0705, 0.1891, 0.7151], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,522][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2188, 0.1358, 0.1116, 0.5338], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,523][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3674, 0.0947, 0.1879, 0.3500], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,524][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0020, 0.2273, 0.1582, 0.6125], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,527][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0361, 0.3060, 0.1531, 0.5048], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,531][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.2132, 0.0442, 0.1069, 0.4051, 0.2307], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,535][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0528, 0.1344, 0.4094, 0.1947, 0.2087], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,538][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([2.2189e-05, 3.5516e-01, 4.4272e-02, 4.4453e-01, 1.5602e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,538][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.3311, 0.2965, 0.1232, 0.2397, 0.0095], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,538][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.1554, 0.1969, 0.2026, 0.2290, 0.2160], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,539][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.4266, 0.1564, 0.1316, 0.1901, 0.0954], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,539][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.1126, 0.2198, 0.2032, 0.2236, 0.2409], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,539][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0100, 0.1106, 0.1984, 0.6003, 0.0808], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,540][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.3902, 0.1021, 0.0747, 0.3149, 0.1180], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,540][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.2743, 0.0617, 0.1335, 0.3320, 0.1986], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,540][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0013, 0.2002, 0.1072, 0.3572, 0.3342], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,542][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0091, 0.5181, 0.0652, 0.3831, 0.0244], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,545][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1497, 0.0062, 0.0404, 0.1156, 0.0944, 0.5937], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,549][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0881, 0.0966, 0.3478, 0.1117, 0.2752, 0.0805], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,551][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([1.8628e-05, 2.2805e-01, 4.0632e-02, 4.3724e-01, 1.6184e-01, 1.3222e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,555][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.9101, 0.0313, 0.0273, 0.0212, 0.0019, 0.0083], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,556][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1315, 0.1591, 0.1631, 0.1830, 0.1753, 0.1880], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,556][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.6645, 0.0543, 0.0791, 0.0523, 0.0518, 0.0980], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,556][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0897, 0.1724, 0.1612, 0.1792, 0.1908, 0.2067], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,557][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0163, 0.0440, 0.0988, 0.6159, 0.0504, 0.1745], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,557][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1587, 0.0212, 0.0370, 0.1508, 0.0893, 0.5429], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,557][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2265, 0.0219, 0.0656, 0.1091, 0.1925, 0.3844], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,558][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0018, 0.0881, 0.0564, 0.4203, 0.2246, 0.2089], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,558][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0279, 0.3159, 0.0683, 0.3601, 0.0356, 0.1922], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,558][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0491, 0.0025, 0.0162, 0.0535, 0.0484, 0.2652, 0.5651],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,559][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1797, 0.0690, 0.2989, 0.1192, 0.1819, 0.0674, 0.0838],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,559][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.6673e-05, 1.1810e-01, 2.8721e-02, 2.6688e-01, 1.4366e-01, 1.1804e-01,
        3.2457e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,562][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.9019, 0.0300, 0.0194, 0.0157, 0.0014, 0.0075, 0.0241],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,565][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1063, 0.1306, 0.1367, 0.1525, 0.1472, 0.1577, 0.1691],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,569][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.7331, 0.0272, 0.0631, 0.0312, 0.0471, 0.0646, 0.0336],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,572][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0818, 0.1431, 0.1328, 0.1482, 0.1593, 0.1749, 0.1598],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,574][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0164, 0.0245, 0.0662, 0.3744, 0.0335, 0.1586, 0.3264],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,574][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1447, 0.0096, 0.0169, 0.0857, 0.0518, 0.3303, 0.3610],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,575][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.1538, 0.0068, 0.0216, 0.0474, 0.0775, 0.2209, 0.4720],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,575][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([4.5055e-04, 4.2542e-02, 3.1850e-02, 1.6582e-01, 1.3865e-01, 1.3724e-01,
        4.8345e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,575][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0482, 0.2534, 0.0751, 0.3204, 0.0294, 0.1797, 0.0939],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,575][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([1.7147e-02, 1.2240e-04, 9.8580e-04, 3.6228e-03, 6.7261e-03, 1.6713e-02,
        5.6303e-02, 8.9838e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,576][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.2787, 0.0785, 0.1881, 0.1006, 0.1162, 0.0649, 0.0866, 0.0865],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,576][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([1.3400e-05, 1.3746e-01, 1.5207e-02, 1.0548e-01, 8.4335e-02, 5.9372e-02,
        3.5315e-01, 2.4498e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,576][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.6368, 0.0681, 0.0548, 0.0522, 0.0044, 0.0136, 0.0700, 0.1003],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,578][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0836, 0.1113, 0.1124, 0.1287, 0.1235, 0.1322, 0.1430, 0.1654],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,581][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.8080, 0.0198, 0.0251, 0.0205, 0.0257, 0.0466, 0.0345, 0.0198],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,585][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0700, 0.1222, 0.1144, 0.1274, 0.1357, 0.1470, 0.1366, 0.1467],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,589][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0174, 0.0324, 0.0437, 0.2096, 0.0283, 0.0984, 0.3859, 0.1843],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,591][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0474, 0.0010, 0.0018, 0.0109, 0.0074, 0.0295, 0.0419, 0.8602],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,592][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.1354, 0.0014, 0.0077, 0.0175, 0.0350, 0.0455, 0.1506, 0.6070],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,592][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([2.5969e-04, 5.8867e-02, 1.0687e-02, 6.6122e-02, 4.5662e-02, 6.2668e-02,
        6.3483e-01, 1.2090e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,592][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0120, 0.4459, 0.0488, 0.1736, 0.0199, 0.1343, 0.1059, 0.0595],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,593][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ of] are: tensor([8.3319e-03, 1.5067e-04, 2.0213e-03, 3.2106e-03, 5.6778e-03, 1.2778e-02,
        6.3759e-02, 8.2122e-01, 8.2851e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,593][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.3322, 0.0460, 0.2146, 0.0712, 0.1203, 0.0577, 0.0581, 0.0640, 0.0359],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,593][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ of] are: tensor([1.1930e-05, 7.8707e-02, 1.3362e-02, 9.5824e-02, 6.1723e-02, 3.9719e-02,
        1.9596e-01, 1.7671e-01, 3.3798e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,594][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.7213, 0.0459, 0.0288, 0.0312, 0.0020, 0.0093, 0.0595, 0.0706, 0.0315],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,594][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0790, 0.0935, 0.0984, 0.1101, 0.1057, 0.1134, 0.1230, 0.1424, 0.1345],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,594][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.7895, 0.0185, 0.0407, 0.0156, 0.0263, 0.0444, 0.0285, 0.0153, 0.0212],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,596][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0583, 0.1020, 0.1025, 0.1095, 0.1247, 0.1306, 0.1181, 0.1286, 0.1256],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,599][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0138, 0.0378, 0.0481, 0.2450, 0.0209, 0.1211, 0.2648, 0.1474, 0.1012],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,603][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0302, 0.0013, 0.0035, 0.0100, 0.0104, 0.0384, 0.0603, 0.7119, 0.1340],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,607][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0761, 0.0018, 0.0089, 0.0137, 0.0253, 0.0597, 0.1367, 0.4497, 0.2280],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,610][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.0004, 0.0214, 0.0152, 0.0781, 0.0721, 0.0878, 0.3448, 0.1792, 0.2010],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,610][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0655, 0.1916, 0.0886, 0.1958, 0.0233, 0.1934, 0.0956, 0.0715, 0.0746],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,610][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([6.3878e-03, 6.6098e-05, 5.8281e-04, 2.1320e-03, 4.2442e-03, 6.0590e-03,
        2.3312e-02, 4.7088e-01, 8.6325e-02, 4.0001e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,611][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.1193, 0.0911, 0.2027, 0.0829, 0.1376, 0.0644, 0.1147, 0.0893, 0.0571,
        0.0408], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,611][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([2.6219e-06, 4.6529e-02, 4.3253e-03, 5.3159e-02, 2.2573e-02, 3.4078e-02,
        1.2738e-01, 1.4841e-01, 3.2690e-01, 2.3664e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,611][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.5425, 0.1011, 0.0488, 0.0649, 0.0040, 0.0211, 0.0704, 0.0549, 0.0708,
        0.0214], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,612][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0688, 0.0809, 0.0837, 0.0947, 0.0913, 0.0969, 0.1069, 0.1246, 0.1182,
        0.1342], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,612][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.7319, 0.0214, 0.0223, 0.0178, 0.0225, 0.0569, 0.0310, 0.0230, 0.0375,
        0.0356], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,613][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0408, 0.0922, 0.0882, 0.0994, 0.1106, 0.1201, 0.1076, 0.1185, 0.1196,
        0.1031], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,616][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0140, 0.0400, 0.0387, 0.1800, 0.0190, 0.0609, 0.2554, 0.1052, 0.0809,
        0.2059], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,620][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0148, 0.0005, 0.0009, 0.0065, 0.0048, 0.0146, 0.0255, 0.4857, 0.1210,
        0.3257], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,623][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.0530, 0.0009, 0.0060, 0.0090, 0.0302, 0.0286, 0.0816, 0.2611, 0.1989,
        0.3306], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,626][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([4.3432e-05, 1.3560e-02, 7.7467e-03, 3.4634e-02, 3.7218e-02, 6.0708e-02,
        3.5671e-01, 1.0844e-01, 2.2201e-01, 1.5893e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,627][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0064, 0.3103, 0.0224, 0.1894, 0.0115, 0.1317, 0.0714, 0.0635, 0.0933,
        0.1002], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,628][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ at] are: tensor([8.7266e-03, 7.6042e-05, 3.5706e-04, 5.3088e-04, 2.1890e-04, 7.3472e-03,
        1.5586e-02, 5.9962e-02, 1.7070e-02, 1.0099e-02, 8.8003e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,628][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0958, 0.0874, 0.1778, 0.1142, 0.1128, 0.0737, 0.0832, 0.0958, 0.0727,
        0.0667, 0.0199], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,628][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ at] are: tensor([2.1170e-06, 4.2552e-02, 4.2889e-03, 6.0906e-02, 2.4664e-02, 2.5468e-02,
        1.1892e-01, 1.3856e-01, 3.3737e-01, 1.8453e-01, 6.2737e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,629][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.4652, 0.1379, 0.0295, 0.0387, 0.0017, 0.0197, 0.0624, 0.0794, 0.0357,
        0.0185, 0.1113], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,629][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0582, 0.0738, 0.0749, 0.0847, 0.0797, 0.0891, 0.0958, 0.1097, 0.1047,
        0.1174, 0.1121], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,629][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.5342, 0.0347, 0.0319, 0.0267, 0.0232, 0.0774, 0.0520, 0.0446, 0.0578,
        0.0610, 0.0565], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,630][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0373, 0.0863, 0.0829, 0.0908, 0.1018, 0.1061, 0.0959, 0.1057, 0.1042,
        0.0935, 0.0955], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,630][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0102, 0.0322, 0.0425, 0.1384, 0.0153, 0.0829, 0.1776, 0.1380, 0.0816,
        0.2488, 0.0325], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,631][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ at] are: tensor([1.1776e-02, 4.6207e-04, 4.5969e-04, 2.0157e-03, 5.0593e-04, 1.0187e-02,
        1.7789e-02, 1.1317e-01, 3.7092e-02, 1.8832e-02, 7.8771e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,632][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.0691, 0.0021, 0.0044, 0.0061, 0.0061, 0.0447, 0.0809, 0.1403, 0.1042,
        0.0404, 0.5017], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,634][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ at] are: tensor([8.0006e-05, 1.7605e-02, 7.8528e-03, 5.2208e-02, 5.1150e-02, 3.9420e-02,
        2.8745e-01, 1.0947e-01, 1.8495e-01, 2.0448e-01, 4.5333e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,637][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0079, 0.2347, 0.0314, 0.2534, 0.0096, 0.1158, 0.0834, 0.0546, 0.0969,
        0.0541, 0.0583], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,639][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ the] are: tensor([7.9964e-03, 4.6544e-05, 1.7018e-04, 2.8965e-04, 1.0072e-04, 3.4485e-03,
        3.9015e-03, 2.3418e-02, 7.6903e-03, 3.1548e-03, 5.1611e-01, 4.3368e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,643][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0911, 0.0569, 0.1715, 0.0886, 0.0997, 0.0587, 0.1020, 0.1094, 0.0612,
        0.0687, 0.0398, 0.0524], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,646][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ the] are: tensor([3.2151e-06, 4.8506e-02, 5.4346e-03, 6.2212e-02, 2.5223e-02, 2.9179e-02,
        1.0275e-01, 1.3813e-01, 2.5165e-01, 1.8730e-01, 7.0435e-02, 7.9172e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,646][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ the] are: tensor([7.5869e-01, 4.4464e-02, 9.2475e-03, 1.4212e-02, 4.8995e-04, 6.4667e-03,
        1.6691e-02, 2.5050e-02, 1.4713e-02, 8.2171e-03, 5.7020e-02, 4.4737e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,646][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0532, 0.0669, 0.0675, 0.0760, 0.0714, 0.0795, 0.0858, 0.0980, 0.0938,
        0.1038, 0.1014, 0.1027], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,647][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.5728, 0.0229, 0.0303, 0.0208, 0.0227, 0.0722, 0.0396, 0.0335, 0.0527,
        0.0553, 0.0521, 0.0252], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,647][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0392, 0.0778, 0.0748, 0.0822, 0.0894, 0.0981, 0.0893, 0.0973, 0.0936,
        0.0875, 0.0871, 0.0836], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,648][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0107, 0.0150, 0.0261, 0.1463, 0.0127, 0.0669, 0.1875, 0.1180, 0.1138,
        0.2157, 0.0526, 0.0347], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,648][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ the] are: tensor([1.7854e-02, 4.2671e-04, 3.2240e-04, 1.5565e-03, 3.8038e-04, 8.1982e-03,
        8.7482e-03, 4.6421e-02, 2.4485e-02, 9.7055e-03, 5.7316e-01, 3.0874e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,648][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.0393, 0.0007, 0.0014, 0.0024, 0.0016, 0.0202, 0.0299, 0.0546, 0.0408,
        0.0132, 0.3294, 0.4665], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,649][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ the] are: tensor([4.0742e-05, 1.5753e-02, 8.2410e-03, 5.4888e-02, 3.7527e-02, 4.1667e-02,
        2.3398e-01, 1.2516e-01, 2.2668e-01, 1.4524e-01, 4.8271e-02, 6.2552e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,652][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0077, 0.2263, 0.0276, 0.2223, 0.0093, 0.1130, 0.0675, 0.0685, 0.1040,
        0.0560, 0.0670, 0.0309], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,654][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ store] are: tensor([6.4073e-03, 1.1763e-05, 6.7400e-05, 8.0923e-05, 4.6388e-05, 1.0502e-03,
        2.1799e-03, 5.7249e-03, 2.9790e-03, 9.3868e-04, 3.5364e-01, 3.5533e-01,
        2.7155e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,657][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0388, 0.0633, 0.1101, 0.1094, 0.0876, 0.0656, 0.1407, 0.0793, 0.0939,
        0.0447, 0.0450, 0.0747, 0.0468], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,659][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ store] are: tensor([1.8494e-06, 4.3859e-02, 2.6209e-03, 5.8313e-02, 1.3077e-02, 2.3928e-02,
        1.4790e-01, 9.7046e-02, 2.4292e-01, 1.7502e-01, 5.3949e-02, 1.2366e-01,
        1.7700e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,663][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.3706, 0.0648, 0.0148, 0.0291, 0.0013, 0.0095, 0.0522, 0.0497, 0.0387,
        0.0151, 0.1145, 0.2112, 0.0287], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,664][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0472, 0.0609, 0.0607, 0.0684, 0.0648, 0.0724, 0.0777, 0.0881, 0.0849,
        0.0950, 0.0921, 0.0942, 0.0936], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,664][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.3726, 0.0400, 0.0279, 0.0330, 0.0195, 0.0720, 0.0963, 0.0389, 0.0701,
        0.0523, 0.0709, 0.0480, 0.0586], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,664][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0389, 0.0712, 0.0688, 0.0750, 0.0829, 0.0901, 0.0831, 0.0894, 0.0864,
        0.0774, 0.0813, 0.0773, 0.0783], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,665][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0090, 0.0176, 0.0212, 0.1527, 0.0114, 0.0574, 0.2766, 0.1169, 0.0715,
        0.1658, 0.0311, 0.0387, 0.0300], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,665][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ store] are: tensor([1.8741e-02, 1.6658e-04, 2.9948e-04, 5.6126e-04, 2.4266e-04, 4.0504e-03,
        5.7278e-03, 2.0848e-02, 1.0480e-02, 6.1917e-03, 3.4896e-01, 2.4964e-01,
        3.3410e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,666][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ store] are: tensor([2.4878e-02, 3.1856e-04, 8.8999e-04, 1.2414e-03, 1.0828e-03, 7.8195e-03,
        1.1660e-02, 1.5781e-02, 1.7849e-02, 5.0090e-03, 1.4172e-01, 3.1182e-01,
        4.5993e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,666][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ store] are: tensor([2.8137e-05, 1.8336e-02, 5.5203e-03, 4.5193e-02, 2.8577e-02, 2.8714e-02,
        2.4205e-01, 8.0698e-02, 2.5848e-01, 1.3589e-01, 4.2360e-02, 1.0564e-01,
        8.5092e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,666][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0017, 0.1772, 0.0178, 0.2341, 0.0086, 0.1086, 0.1188, 0.0438, 0.1220,
        0.0397, 0.0576, 0.0564, 0.0138], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,667][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [.] are: tensor([4.6420e-03, 1.5330e-05, 1.6938e-04, 1.6853e-04, 1.9739e-04, 1.2835e-03,
        3.3595e-03, 1.6617e-02, 4.9207e-03, 5.0739e-03, 2.0563e-01, 3.4217e-01,
        3.3832e-01, 7.7434e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,670][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.1107, 0.0344, 0.1736, 0.0806, 0.0999, 0.0559, 0.0784, 0.0829, 0.0558,
        0.0451, 0.0297, 0.0472, 0.0622, 0.0435], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,672][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [.] are: tensor([3.4556e-06, 4.6554e-02, 4.4295e-03, 5.2025e-02, 2.1912e-02, 2.5809e-02,
        1.1788e-01, 1.1760e-01, 2.1027e-01, 1.8471e-01, 6.2264e-02, 1.0133e-01,
        2.2226e-02, 3.2990e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,675][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.5717, 0.0169, 0.0185, 0.0061, 0.0011, 0.0044, 0.0293, 0.0413, 0.0133,
        0.0113, 0.1295, 0.1200, 0.0167, 0.0199], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,679][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0488, 0.0541, 0.0564, 0.0625, 0.0594, 0.0650, 0.0706, 0.0817, 0.0768,
        0.0859, 0.0829, 0.0854, 0.0851, 0.0854], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,682][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.6267, 0.0112, 0.0395, 0.0139, 0.0259, 0.0491, 0.0298, 0.0204, 0.0243,
        0.0319, 0.0343, 0.0192, 0.0420, 0.0318], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,682][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0328, 0.0649, 0.0624, 0.0687, 0.0773, 0.0840, 0.0777, 0.0833, 0.0798,
        0.0710, 0.0745, 0.0716, 0.0760, 0.0759], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,682][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0080, 0.0241, 0.0298, 0.1636, 0.0101, 0.0760, 0.1613, 0.1009, 0.0751,
        0.1770, 0.0363, 0.0252, 0.0788, 0.0339], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,683][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [.] are: tensor([1.4381e-02, 2.7698e-04, 5.8527e-04, 1.1260e-03, 8.4714e-04, 5.8580e-03,
        6.6270e-03, 4.7546e-02, 1.4911e-02, 1.8893e-02, 2.4715e-01, 1.7095e-01,
        3.3509e-01, 1.3576e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,683][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [.] are: tensor([3.2914e-02, 3.4108e-04, 1.5063e-03, 1.6402e-03, 2.3468e-03, 7.5374e-03,
        1.1230e-02, 2.8701e-02, 1.8971e-02, 1.5797e-02, 1.1071e-01, 2.4347e-01,
        3.6476e-01, 1.6008e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,683][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [.] are: tensor([4.7332e-05, 2.2227e-02, 7.9603e-03, 4.3277e-02, 4.0959e-02, 3.7378e-02,
        2.3137e-01, 9.0553e-02, 2.0494e-01, 1.1866e-01, 4.1210e-02, 7.8439e-02,
        1.3121e-02, 6.9860e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,684][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0043, 0.1493, 0.0214, 0.2025, 0.0095, 0.1162, 0.1123, 0.0345, 0.1198,
        0.0391, 0.0466, 0.0475, 0.0168, 0.0802], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,684][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([2.1373e-03, 1.1929e-05, 4.5592e-05, 4.9572e-05, 3.0100e-05, 3.8601e-04,
        4.6542e-04, 4.9068e-04, 6.4562e-04, 1.9581e-04, 3.0502e-01, 3.6033e-01,
        2.7401e-01, 2.4988e-02, 3.1205e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,686][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0115, 0.0724, 0.1054, 0.0863, 0.1039, 0.0694, 0.0967, 0.1080, 0.0621,
        0.0520, 0.0315, 0.0465, 0.0627, 0.0408, 0.0507], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,688][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([7.0067e-07, 3.3704e-02, 3.0827e-03, 3.6127e-02, 1.1741e-02, 2.4968e-02,
        8.5790e-02, 1.2784e-01, 2.5797e-01, 1.9279e-01, 7.4146e-02, 8.9858e-02,
        2.0947e-02, 2.6357e-02, 1.4669e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,691][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.1088, 0.0932, 0.0322, 0.0653, 0.0023, 0.0053, 0.0451, 0.0209, 0.0266,
        0.0107, 0.1863, 0.2980, 0.0309, 0.0698, 0.0048], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,695][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0474, 0.0499, 0.0532, 0.0581, 0.0550, 0.0600, 0.0644, 0.0731, 0.0700,
        0.0770, 0.0784, 0.0803, 0.0807, 0.0790, 0.0736], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,699][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.3078, 0.0416, 0.0352, 0.0381, 0.0261, 0.0629, 0.0555, 0.0423, 0.0595,
        0.0394, 0.0866, 0.0390, 0.0772, 0.0491, 0.0398], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,700][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0258, 0.0614, 0.0573, 0.0628, 0.0680, 0.0764, 0.0685, 0.0792, 0.0735,
        0.0677, 0.0705, 0.0664, 0.0710, 0.0777, 0.0737], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,700][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0015, 0.0226, 0.0212, 0.1111, 0.0161, 0.0593, 0.1607, 0.1399, 0.0538,
        0.2116, 0.0306, 0.0307, 0.0932, 0.0161, 0.0316], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,700][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([1.1068e-02, 1.9220e-04, 2.1280e-04, 3.9090e-04, 1.5202e-04, 1.3851e-03,
        1.3195e-03, 4.6656e-03, 2.8638e-03, 1.2190e-03, 3.2967e-01, 2.1866e-01,
        3.1719e-01, 6.9453e-02, 4.1560e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,701][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([9.2878e-03, 1.3995e-04, 7.0649e-04, 6.2348e-04, 5.9048e-04, 2.8712e-03,
        3.0533e-03, 2.3051e-03, 4.6507e-03, 1.5423e-03, 1.5007e-01, 2.1314e-01,
        4.6151e-01, 7.2440e-02, 7.7064e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,701][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([2.1876e-05, 1.6425e-02, 5.8742e-03, 2.5512e-02, 2.9197e-02, 3.1401e-02,
        1.2944e-01, 1.2819e-01, 1.6658e-01, 1.4557e-01, 5.0510e-02, 1.3035e-01,
        1.6106e-02, 8.2701e-02, 4.2113e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,701][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0031, 0.1739, 0.0202, 0.1123, 0.0081, 0.0859, 0.0834, 0.0410, 0.0913,
        0.0231, 0.0870, 0.0562, 0.0604, 0.1455, 0.0085], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,702][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([9.6879e-03, 9.5549e-06, 5.1957e-05, 3.7321e-05, 1.3409e-05, 7.3299e-04,
        9.4401e-04, 2.7830e-03, 8.8609e-04, 1.4531e-04, 7.1958e-02, 6.6159e-02,
        6.0634e-02, 1.8893e-02, 2.7395e-03, 7.6432e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,702][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0435, 0.0605, 0.0932, 0.0489, 0.1362, 0.0468, 0.0817, 0.0738, 0.0494,
        0.0439, 0.0379, 0.0469, 0.0843, 0.0293, 0.0819, 0.0419],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,703][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([1.7807e-06, 4.5420e-02, 3.4101e-03, 4.7277e-02, 1.7039e-02, 2.5825e-02,
        1.1226e-01, 9.6363e-02, 2.4217e-01, 1.5882e-01, 7.3006e-02, 1.0028e-01,
        1.6055e-02, 2.9320e-02, 2.0740e-02, 1.2015e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,705][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.5425, 0.0561, 0.0163, 0.0249, 0.0010, 0.0059, 0.0424, 0.0266, 0.0243,
        0.0101, 0.0649, 0.1115, 0.0184, 0.0261, 0.0021, 0.0268],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,708][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0459, 0.0464, 0.0487, 0.0531, 0.0501, 0.0563, 0.0607, 0.0691, 0.0650,
        0.0712, 0.0702, 0.0727, 0.0728, 0.0720, 0.0657, 0.0800],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,711][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.4624, 0.0233, 0.0352, 0.0212, 0.0241, 0.0716, 0.0583, 0.0357, 0.0367,
        0.0346, 0.0380, 0.0212, 0.0403, 0.0375, 0.0302, 0.0298],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,715][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0221, 0.0569, 0.0532, 0.0606, 0.0644, 0.0729, 0.0649, 0.0735, 0.0717,
        0.0628, 0.0659, 0.0604, 0.0653, 0.0689, 0.0686, 0.0681],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,718][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0023, 0.0140, 0.0163, 0.1105, 0.0140, 0.0571, 0.2240, 0.0914, 0.0656,
        0.1902, 0.0306, 0.0263, 0.0489, 0.0191, 0.0325, 0.0572],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,718][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([2.4708e-02, 1.8838e-04, 3.7351e-04, 5.5846e-04, 1.6416e-04, 4.3480e-03,
        4.2351e-03, 1.5982e-02, 6.1262e-03, 1.4233e-03, 1.5924e-01, 6.9307e-02,
        9.9809e-02, 5.5511e-02, 1.0396e-02, 5.4763e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,718][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([2.9967e-02, 1.5558e-04, 6.0466e-04, 4.1439e-04, 4.1087e-04, 3.0746e-03,
        4.7028e-03, 3.4476e-03, 4.6525e-03, 7.2632e-04, 3.0768e-02, 6.4383e-02,
        1.5162e-01, 4.8477e-02, 2.7504e-02, 6.2909e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,719][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([8.6981e-05, 2.0687e-02, 4.6490e-03, 3.8805e-02, 2.6399e-02, 4.0026e-02,
        2.0394e-01, 5.7117e-02, 1.9029e-01, 1.3405e-01, 5.9413e-02, 8.8843e-02,
        1.4020e-02, 7.9856e-02, 3.2832e-02, 8.9835e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,719][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0012, 0.1380, 0.0146, 0.1336, 0.0065, 0.1129, 0.0618, 0.0397, 0.1183,
        0.0500, 0.0852, 0.0532, 0.0223, 0.1041, 0.0064, 0.0522],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,720][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([3.8073e-03, 3.4621e-06, 2.3144e-05, 2.2464e-05, 9.1145e-06, 2.8524e-04,
        3.5289e-04, 3.2229e-03, 7.1941e-04, 3.1881e-04, 2.4009e-02, 2.2914e-02,
        3.7455e-02, 1.1507e-02, 2.9200e-03, 3.9305e-01, 4.9938e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,720][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0784, 0.0448, 0.1046, 0.0723, 0.1010, 0.0422, 0.0608, 0.0787, 0.0523,
        0.0519, 0.0349, 0.0569, 0.0534, 0.0354, 0.0725, 0.0288, 0.0312],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,721][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([1.7324e-06, 4.3456e-02, 4.5090e-03, 5.1235e-02, 2.1028e-02, 2.5726e-02,
        7.7345e-02, 1.6610e-01, 2.1024e-01, 1.7081e-01, 5.6112e-02, 7.4854e-02,
        1.3867e-02, 2.4633e-02, 1.7819e-02, 1.3401e-02, 2.8867e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,722][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.3157e-01, 2.2572e-02, 7.9568e-03, 7.8875e-03, 4.9547e-04, 3.8062e-03,
        1.2394e-02, 2.8043e-02, 1.1065e-02, 7.4335e-03, 4.2349e-02, 3.7980e-02,
        6.6454e-03, 1.4010e-02, 9.9290e-04, 1.0049e-02, 5.4754e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,724][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0404, 0.0420, 0.0448, 0.0488, 0.0466, 0.0517, 0.0557, 0.0646, 0.0602,
        0.0668, 0.0651, 0.0667, 0.0676, 0.0673, 0.0617, 0.0742, 0.0758],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,728][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.6211, 0.0120, 0.0223, 0.0134, 0.0162, 0.0422, 0.0203, 0.0278, 0.0245,
        0.0415, 0.0213, 0.0121, 0.0334, 0.0255, 0.0260, 0.0213, 0.0190],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,732][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0233, 0.0533, 0.0497, 0.0556, 0.0597, 0.0677, 0.0614, 0.0673, 0.0649,
        0.0600, 0.0616, 0.0574, 0.0589, 0.0654, 0.0641, 0.0659, 0.0638],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,735][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0102, 0.0148, 0.0182, 0.1057, 0.0109, 0.0485, 0.1270, 0.1055, 0.0867,
        0.1507, 0.0460, 0.0298, 0.0447, 0.0338, 0.0279, 0.0700, 0.0696],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,736][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([1.3019e-02, 6.6207e-05, 1.3779e-04, 2.8505e-04, 9.8731e-05, 2.1196e-03,
        1.8152e-03, 1.4893e-02, 4.5920e-03, 2.4743e-03, 6.5125e-02, 3.4569e-02,
        9.6072e-02, 6.0477e-02, 1.0428e-02, 3.3342e-01, 3.6041e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,736][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.8621e-02, 6.1589e-05, 2.8435e-04, 2.4635e-04, 3.0177e-04, 3.0753e-03,
        3.0935e-03, 7.8622e-03, 5.2875e-03, 1.8515e-03, 2.4101e-02, 3.9470e-02,
        9.4788e-02, 4.3265e-02, 2.8706e-02, 4.2487e-01, 3.0412e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,736][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([4.6176e-05, 1.2394e-02, 5.5910e-03, 3.9367e-02, 2.3258e-02, 3.3477e-02,
        1.3512e-01, 1.4109e-01, 1.6210e-01, 1.5910e-01, 3.8877e-02, 7.1411e-02,
        8.3489e-03, 6.1365e-02, 2.9214e-02, 2.1574e-02, 5.7668e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,737][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0056, 0.1319, 0.0238, 0.1177, 0.0097, 0.0826, 0.0588, 0.0528, 0.1005,
        0.0640, 0.0865, 0.0502, 0.0264, 0.0813, 0.0093, 0.0602, 0.0386],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:21,737][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([4.4461e-04, 7.3772e-07, 3.6028e-06, 4.2412e-06, 2.7488e-06, 4.1014e-05,
        1.0535e-04, 3.6880e-04, 1.5054e-04, 4.8415e-05, 2.0126e-02, 2.5137e-02,
        1.9725e-02, 4.4456e-03, 3.0023e-03, 4.0132e-01, 4.1486e-01, 1.1021e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,737][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0598, 0.0446, 0.0855, 0.0730, 0.0830, 0.0482, 0.0844, 0.0555, 0.0624,
        0.0475, 0.0286, 0.0591, 0.0537, 0.0395, 0.0630, 0.0225, 0.0319, 0.0576],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,738][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([8.7223e-07, 4.7105e-02, 1.9653e-03, 3.2251e-02, 1.0447e-02, 1.2669e-02,
        8.7920e-02, 1.3050e-01, 2.3382e-01, 2.0829e-01, 5.8151e-02, 7.3751e-02,
        1.8125e-02, 2.9054e-02, 1.3947e-02, 6.8752e-03, 2.4787e-02, 1.0339e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,739][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.1466, 0.0532, 0.0152, 0.0285, 0.0010, 0.0062, 0.0447, 0.0497, 0.0373,
        0.0123, 0.1302, 0.1530, 0.0196, 0.0585, 0.0019, 0.0295, 0.2011, 0.0116],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,742][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0319, 0.0411, 0.0411, 0.0459, 0.0436, 0.0480, 0.0519, 0.0587, 0.0564,
        0.0629, 0.0610, 0.0622, 0.0624, 0.0634, 0.0586, 0.0708, 0.0725, 0.0674],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,745][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.4511, 0.0140, 0.0248, 0.0136, 0.0263, 0.0622, 0.0348, 0.0221, 0.0224,
        0.0270, 0.0357, 0.0183, 0.0483, 0.0291, 0.0500, 0.0379, 0.0374, 0.0449],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,749][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0240, 0.0480, 0.0479, 0.0506, 0.0595, 0.0632, 0.0586, 0.0641, 0.0598,
        0.0563, 0.0580, 0.0542, 0.0569, 0.0602, 0.0652, 0.0638, 0.0611, 0.0485],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,753][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0050, 0.0083, 0.0086, 0.0759, 0.0075, 0.0407, 0.1319, 0.0912, 0.0716,
        0.1684, 0.0365, 0.0278, 0.0657, 0.0253, 0.0274, 0.0624, 0.0734, 0.0723],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,753][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([5.1569e-03, 3.4148e-05, 3.5484e-05, 1.0785e-04, 3.4347e-05, 5.4633e-04,
        6.1818e-04, 4.2854e-03, 1.2247e-03, 6.1010e-04, 4.1681e-02, 3.8904e-02,
        5.3008e-02, 1.7129e-02, 7.6281e-03, 3.3793e-01, 2.6810e-01, 2.2296e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,754][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([8.6595e-03, 2.5592e-05, 1.4010e-04, 9.5387e-05, 1.5008e-04, 7.6120e-04,
        1.0535e-03, 1.2757e-03, 1.5751e-03, 4.7966e-04, 1.8129e-02, 3.8707e-02,
        8.2560e-02, 1.9429e-02, 2.8919e-02, 3.1755e-01, 3.0560e-01, 1.7489e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,754][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([1.6250e-05, 1.6787e-02, 3.4641e-03, 2.2914e-02, 1.8816e-02, 2.2827e-02,
        1.3845e-01, 9.5960e-02, 1.9318e-01, 1.5642e-01, 4.2355e-02, 6.4721e-02,
        1.3507e-02, 8.2277e-02, 2.5670e-02, 1.5330e-02, 6.9252e-02, 1.8053e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,755][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0015, 0.2861, 0.0098, 0.1033, 0.0063, 0.0894, 0.0458, 0.0482, 0.0802,
        0.0404, 0.0597, 0.0345, 0.0266, 0.0807, 0.0064, 0.0350, 0.0331, 0.0131],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:21,755][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([2.1918e-03, 8.0297e-07, 8.6032e-06, 4.0755e-06, 1.8760e-06, 7.2997e-05,
        1.5411e-04, 2.6699e-04, 1.1797e-04, 2.1712e-05, 6.3050e-03, 1.2494e-02,
        1.0798e-02, 3.1556e-03, 5.6439e-04, 2.1126e-01, 3.4495e-01, 8.1088e-02,
        3.2654e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,755][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0672, 0.0385, 0.0754, 0.0687, 0.0705, 0.0398, 0.0621, 0.0696, 0.0600,
        0.0552, 0.0318, 0.0519, 0.0563, 0.0382, 0.0570, 0.0299, 0.0340, 0.0640,
        0.0297], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,756][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.4944e-06, 5.6160e-02, 3.1730e-03, 5.0782e-02, 2.0527e-02, 2.4974e-02,
        9.7909e-02, 1.2929e-01, 2.1445e-01, 1.3690e-01, 5.2316e-02, 6.9732e-02,
        1.4485e-02, 3.1279e-02, 1.3961e-02, 1.2480e-02, 3.1848e-02, 9.2697e-03,
        3.0465e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,757][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.5241, 0.0255, 0.0098, 0.0097, 0.0007, 0.0032, 0.0252, 0.0234, 0.0096,
        0.0059, 0.0537, 0.0944, 0.0090, 0.0135, 0.0015, 0.0217, 0.1237, 0.0050,
        0.0405], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,760][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0345, 0.0375, 0.0393, 0.0429, 0.0409, 0.0454, 0.0488, 0.0554, 0.0526,
        0.0581, 0.0567, 0.0584, 0.0585, 0.0584, 0.0538, 0.0650, 0.0662, 0.0638,
        0.0638], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,764][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.6095, 0.0094, 0.0197, 0.0097, 0.0138, 0.0368, 0.0199, 0.0186, 0.0173,
        0.0274, 0.0193, 0.0119, 0.0308, 0.0268, 0.0254, 0.0205, 0.0226, 0.0351,
        0.0257], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,768][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0204, 0.0465, 0.0457, 0.0498, 0.0550, 0.0604, 0.0549, 0.0610, 0.0580,
        0.0533, 0.0536, 0.0515, 0.0554, 0.0576, 0.0595, 0.0584, 0.0563, 0.0467,
        0.0559], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,771][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0069, 0.0182, 0.0239, 0.1146, 0.0098, 0.0498, 0.1251, 0.0813, 0.0576,
        0.1164, 0.0374, 0.0218, 0.0626, 0.0212, 0.0210, 0.0646, 0.0660, 0.0713,
        0.0305], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,771][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([7.1558e-03, 2.4152e-05, 6.1014e-05, 8.0849e-05, 4.0549e-05, 6.7976e-04,
        7.0641e-04, 2.4594e-03, 1.0000e-03, 4.3356e-04, 3.0494e-02, 1.6475e-02,
        5.1432e-02, 2.0734e-02, 4.4909e-03, 1.7456e-01, 2.2455e-01, 1.4037e-01,
        3.2425e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,772][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.4576e-02, 3.4203e-05, 1.5201e-04, 1.2453e-04, 1.2834e-04, 1.4683e-03,
        1.8335e-03, 2.3011e-03, 1.8838e-03, 4.4174e-04, 1.2506e-02, 2.8152e-02,
        5.4055e-02, 2.1738e-02, 1.1083e-02, 2.4066e-01, 2.4253e-01, 1.3911e-01,
        2.2722e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,772][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([5.5573e-05, 1.1965e-02, 4.1414e-03, 3.5399e-02, 2.4155e-02, 3.6578e-02,
        1.6640e-01, 7.8329e-02, 1.5637e-01, 1.1452e-01, 3.3348e-02, 6.6589e-02,
        1.0435e-02, 7.7775e-02, 3.1384e-02, 1.8190e-02, 7.9059e-02, 2.4897e-02,
        3.0409e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,772][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0083, 0.1368, 0.0295, 0.1151, 0.0115, 0.1141, 0.0802, 0.0404, 0.0791,
        0.0427, 0.0573, 0.0338, 0.0276, 0.0808, 0.0094, 0.0496, 0.0325, 0.0133,
        0.0382], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:21,800][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:21,801][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,801][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,802][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,802][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,802][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,803][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,803][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,803][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,804][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,804][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,804][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,805][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:21,805][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.7083, 0.2917], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,805][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6030, 0.3970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,806][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([9.1482e-04, 9.9909e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,806][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8626, 0.1374], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,806][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8978, 0.1022], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,807][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.9085, 0.0915], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,807][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9607, 0.0393], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,807][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8019, 0.1981], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,808][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2538, 0.7462], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,808][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.4238, 0.5762], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,808][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0034, 0.9966], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,809][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7601, 0.2399], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:21,809][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.2857, 0.3081, 0.4062], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,809][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([0.0895, 0.1420, 0.7686], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,810][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.0008, 0.6989, 0.3003], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,810][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.7773, 0.0568, 0.1659], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,810][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.5858, 0.1101, 0.3041], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,811][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.5738, 0.2332, 0.1929], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,811][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.5821, 0.1551, 0.2628], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,811][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.1743, 0.1244, 0.7014], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,813][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.3906, 0.4147, 0.1947], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,814][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.3498, 0.3514, 0.2988], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,814][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.0046, 0.6271, 0.3683], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,814][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.2513, 0.2579, 0.4909], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:21,815][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1544, 0.0492, 0.2989, 0.4975], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,815][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2645, 0.0989, 0.4502, 0.1865], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,815][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.7948e-04, 2.7114e-01, 1.0079e-01, 6.2778e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,815][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.7270, 0.0331, 0.0911, 0.1488], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,816][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.6170, 0.0238, 0.1580, 0.2011], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,816][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8281, 0.0473, 0.0808, 0.0438], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,816][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8674, 0.0131, 0.0802, 0.0393], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,818][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3657, 0.0438, 0.3687, 0.2218], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,821][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2188, 0.1358, 0.1116, 0.5338], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,825][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3674, 0.0947, 0.1879, 0.3500], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,829][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0020, 0.2273, 0.1582, 0.6125], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,831][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4167, 0.0406, 0.2637, 0.2789], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:21,832][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.2132, 0.0442, 0.1069, 0.4051, 0.2307], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,832][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0528, 0.1344, 0.4094, 0.1947, 0.2087], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,832][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.0005, 0.1823, 0.0691, 0.4322, 0.3159], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,832][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.7278, 0.0231, 0.0778, 0.1003, 0.0711], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,833][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.4172, 0.0208, 0.1299, 0.2334, 0.1988], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,833][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.6528, 0.0870, 0.0914, 0.1191, 0.0497], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,833][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.5970, 0.0379, 0.1446, 0.0945, 0.1260], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,834][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.1096, 0.0397, 0.2726, 0.2049, 0.3732], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,835][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.3902, 0.1021, 0.0747, 0.3149, 0.1180], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,838][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.2743, 0.0617, 0.1335, 0.3320, 0.1986], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,842][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0013, 0.2002, 0.1072, 0.3572, 0.3342], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,845][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.3476, 0.0429, 0.2110, 0.2518, 0.1467], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:21,849][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1497, 0.0062, 0.0404, 0.1156, 0.0944, 0.5937], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,849][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0881, 0.0966, 0.3478, 0.1117, 0.2752, 0.0805], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,849][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([2.5344e-04, 1.2700e-01, 5.5996e-02, 4.0796e-01, 1.7507e-01, 2.3373e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,850][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.5027, 0.0097, 0.0407, 0.0604, 0.0593, 0.3273], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,850][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.6514, 0.0044, 0.0418, 0.0531, 0.0951, 0.1541], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,850][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.7829, 0.0304, 0.0604, 0.0305, 0.0403, 0.0555], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,851][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.6850, 0.0194, 0.0949, 0.0596, 0.0837, 0.0576], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,851][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1578, 0.0297, 0.2095, 0.2018, 0.2575, 0.1438], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,851][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1587, 0.0212, 0.0370, 0.1508, 0.0893, 0.5429], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,853][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2265, 0.0219, 0.0656, 0.1091, 0.1925, 0.3844], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,855][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0018, 0.0881, 0.0564, 0.4203, 0.2246, 0.2089], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,859][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.3247, 0.0283, 0.1686, 0.1915, 0.1251, 0.1617], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:21,863][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0491, 0.0025, 0.0162, 0.0535, 0.0484, 0.2652, 0.5651],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,866][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1797, 0.0690, 0.2989, 0.1192, 0.1819, 0.0674, 0.0838],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,867][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.4985e-04, 5.6703e-02, 3.7028e-02, 2.4538e-01, 1.3810e-01, 1.9003e-01,
        3.3261e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,867][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5273, 0.0045, 0.0245, 0.0314, 0.0354, 0.1364, 0.2404],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,867][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.5664, 0.0013, 0.0264, 0.0199, 0.0600, 0.0856, 0.2405],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,867][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.8131, 0.0198, 0.0496, 0.0242, 0.0341, 0.0389, 0.0202],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,868][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.6928, 0.0153, 0.0710, 0.0557, 0.0715, 0.0679, 0.0259],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,868][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1643, 0.0169, 0.1739, 0.1406, 0.1906, 0.1556, 0.1580],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,868][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1447, 0.0096, 0.0169, 0.0857, 0.0518, 0.3303, 0.3610],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,869][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.1538, 0.0068, 0.0216, 0.0474, 0.0775, 0.2209, 0.4720],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,869][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.5055e-04, 4.2542e-02, 3.1850e-02, 1.6582e-01, 1.3865e-01, 1.3724e-01,
        4.8345e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,871][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3755, 0.0228, 0.1770, 0.1491, 0.0872, 0.1098, 0.0786],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:21,873][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([1.7147e-02, 1.2240e-04, 9.8580e-04, 3.6228e-03, 6.7261e-03, 1.6713e-02,
        5.6303e-02, 8.9838e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,876][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.2787, 0.0785, 0.1881, 0.1006, 0.1162, 0.0649, 0.0866, 0.0865],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,878][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([8.4631e-05, 5.9693e-02, 1.2305e-02, 9.0625e-02, 6.2322e-02, 1.2754e-01,
        3.7667e-01, 2.7076e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,882][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.4569, 0.0011, 0.0125, 0.0117, 0.0240, 0.0475, 0.0777, 0.3685],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,884][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([1.4978e-01, 3.1930e-04, 4.7758e-03, 7.8270e-03, 1.9591e-02, 2.1191e-02,
        1.0926e-01, 6.8726e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,884][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.9245, 0.0064, 0.0146, 0.0078, 0.0141, 0.0154, 0.0095, 0.0078],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,885][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.8138, 0.0086, 0.0394, 0.0267, 0.0425, 0.0279, 0.0153, 0.0259],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,885][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.3223, 0.0132, 0.1027, 0.0697, 0.1251, 0.0914, 0.1567, 0.1190],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,885][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0474, 0.0010, 0.0018, 0.0109, 0.0074, 0.0295, 0.0419, 0.8602],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,886][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.1354, 0.0014, 0.0077, 0.0175, 0.0350, 0.0455, 0.1506, 0.6070],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,886][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([2.5969e-04, 5.8867e-02, 1.0687e-02, 6.6122e-02, 4.5662e-02, 6.2668e-02,
        6.3483e-01, 1.2090e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,886][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.3338, 0.0307, 0.1229, 0.0990, 0.0821, 0.1255, 0.1317, 0.0743],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:21,887][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([8.3319e-03, 1.5067e-04, 2.0213e-03, 3.2106e-03, 5.6778e-03, 1.2778e-02,
        6.3759e-02, 8.2122e-01, 8.2851e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,888][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.3322, 0.0460, 0.2146, 0.0712, 0.1203, 0.0577, 0.0581, 0.0640, 0.0359],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,890][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([7.7400e-05, 4.5766e-02, 1.8193e-02, 1.0292e-01, 5.5658e-02, 6.9774e-02,
        2.1979e-01, 2.1881e-01, 2.6901e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,893][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.3748, 0.0025, 0.0127, 0.0132, 0.0166, 0.0575, 0.0980, 0.3032, 0.1215],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,895][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([2.7184e-01, 5.0015e-04, 7.9333e-03, 7.1672e-03, 1.8258e-02, 2.5624e-02,
        8.7265e-02, 5.1380e-01, 6.7609e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,899][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.8326, 0.0155, 0.0358, 0.0139, 0.0237, 0.0303, 0.0194, 0.0124, 0.0165],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,902][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.7875, 0.0061, 0.0510, 0.0247, 0.0417, 0.0303, 0.0139, 0.0186, 0.0263],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,902][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.2317, 0.0242, 0.1235, 0.0854, 0.1122, 0.0971, 0.1228, 0.1272, 0.0759],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,902][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0302, 0.0013, 0.0035, 0.0100, 0.0104, 0.0384, 0.0603, 0.7119, 0.1340],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,903][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0761, 0.0018, 0.0089, 0.0137, 0.0253, 0.0597, 0.1367, 0.4497, 0.2280],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,903][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.0004, 0.0214, 0.0152, 0.0781, 0.0721, 0.0878, 0.3448, 0.1792, 0.2010],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,903][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.5181, 0.0124, 0.1151, 0.0725, 0.0418, 0.0857, 0.0624, 0.0396, 0.0524],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:21,904][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([6.3878e-03, 6.6098e-05, 5.8281e-04, 2.1320e-03, 4.2442e-03, 6.0590e-03,
        2.3312e-02, 4.7088e-01, 8.6325e-02, 4.0001e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,904][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.1193, 0.0911, 0.2027, 0.0829, 0.1376, 0.0644, 0.1147, 0.0893, 0.0571,
        0.0408], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,904][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([1.5121e-05, 2.9847e-02, 5.7024e-03, 5.2065e-02, 2.8291e-02, 6.4144e-02,
        1.5533e-01, 2.1983e-01, 2.3223e-01, 2.1254e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,905][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.2935, 0.0011, 0.0078, 0.0102, 0.0173, 0.0393, 0.0667, 0.2150, 0.1045,
        0.2446], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,906][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([6.1383e-02, 2.4756e-04, 2.3833e-03, 4.7013e-03, 9.6006e-03, 1.1425e-02,
        6.8344e-02, 3.5932e-01, 7.5056e-02, 4.0754e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,908][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.8700, 0.0087, 0.0151, 0.0087, 0.0142, 0.0268, 0.0122, 0.0128, 0.0174,
        0.0141], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,911][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.6024, 0.0124, 0.0625, 0.0455, 0.0649, 0.0514, 0.0311, 0.0509, 0.0560,
        0.0229], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,915][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.1882, 0.0210, 0.1203, 0.0722, 0.1171, 0.0651, 0.1232, 0.0838, 0.0641,
        0.1451], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,919][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0148, 0.0005, 0.0009, 0.0065, 0.0048, 0.0146, 0.0255, 0.4857, 0.1210,
        0.3257], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,920][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0530, 0.0009, 0.0060, 0.0090, 0.0302, 0.0286, 0.0816, 0.2611, 0.1989,
        0.3306], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,920][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([4.3432e-05, 1.3560e-02, 7.7467e-03, 3.4634e-02, 3.7218e-02, 6.0708e-02,
        3.5671e-01, 1.0844e-01, 2.2201e-01, 1.5893e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,920][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.3067, 0.0236, 0.0828, 0.1070, 0.0512, 0.1192, 0.0914, 0.0715, 0.0928,
        0.0539], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:21,921][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([8.7266e-03, 7.6042e-05, 3.5706e-04, 5.3088e-04, 2.1890e-04, 7.3472e-03,
        1.5586e-02, 5.9962e-02, 1.7070e-02, 1.0099e-02, 8.8003e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,921][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0958, 0.0874, 0.1778, 0.1142, 0.1128, 0.0737, 0.0832, 0.0958, 0.0727,
        0.0667, 0.0199], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,921][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([1.9236e-05, 2.9187e-02, 7.1273e-03, 6.9269e-02, 3.3364e-02, 5.2923e-02,
        1.5323e-01, 1.8572e-01, 2.3577e-01, 1.5363e-01, 7.9760e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,922][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.2110, 0.0026, 0.0059, 0.0077, 0.0044, 0.0493, 0.0782, 0.1633, 0.0845,
        0.0746, 0.3185], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,922][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.1712, 0.0004, 0.0035, 0.0044, 0.0033, 0.0260, 0.0793, 0.2111, 0.0443,
        0.0887, 0.3677], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,922][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.5609, 0.0313, 0.0372, 0.0265, 0.0289, 0.0688, 0.0453, 0.0512, 0.0516,
        0.0521, 0.0461], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,924][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.5084, 0.0201, 0.0503, 0.0599, 0.0555, 0.0633, 0.0379, 0.0642, 0.0768,
        0.0356, 0.0280], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,927][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.1104, 0.0213, 0.1221, 0.0712, 0.0994, 0.0907, 0.0938, 0.1181, 0.0735,
        0.1666, 0.0329], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,929][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([1.1776e-02, 4.6207e-04, 4.5969e-04, 2.0157e-03, 5.0593e-04, 1.0187e-02,
        1.7789e-02, 1.1317e-01, 3.7092e-02, 1.8832e-02, 7.8771e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,933][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0691, 0.0021, 0.0044, 0.0061, 0.0061, 0.0447, 0.0809, 0.1403, 0.1042,
        0.0404, 0.5017], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,936][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([8.0006e-05, 1.7605e-02, 7.8528e-03, 5.2208e-02, 5.1150e-02, 3.9420e-02,
        2.8745e-01, 1.0947e-01, 1.8495e-01, 2.0448e-01, 4.5333e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,938][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.1009, 0.0228, 0.0936, 0.1603, 0.0475, 0.1324, 0.1312, 0.0893, 0.1309,
        0.0410, 0.0500], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:21,938][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([7.9964e-03, 4.6544e-05, 1.7018e-04, 2.8965e-04, 1.0072e-04, 3.4485e-03,
        3.9015e-03, 2.3418e-02, 7.6903e-03, 3.1548e-03, 5.1611e-01, 4.3368e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,938][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0911, 0.0569, 0.1715, 0.0886, 0.0997, 0.0587, 0.1020, 0.1094, 0.0612,
        0.0687, 0.0398, 0.0524], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,939][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([3.2540e-05, 2.9923e-02, 7.8672e-03, 6.2375e-02, 2.6349e-02, 5.2051e-02,
        1.1873e-01, 1.7506e-01, 1.8595e-01, 1.5265e-01, 9.6170e-02, 9.2846e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,939][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.1769, 0.0015, 0.0037, 0.0043, 0.0027, 0.0308, 0.0414, 0.0747, 0.0460,
        0.0339, 0.2013, 0.3827], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,939][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([1.6332e-01, 3.2897e-04, 2.2930e-03, 1.6488e-03, 1.8191e-03, 1.0342e-02,
        2.9588e-02, 8.0584e-02, 1.8671e-02, 2.6431e-02, 2.3543e-01, 4.2955e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,940][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.6530, 0.0182, 0.0322, 0.0187, 0.0247, 0.0568, 0.0290, 0.0334, 0.0392,
        0.0406, 0.0371, 0.0171], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,940][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.4566, 0.0194, 0.0615, 0.0635, 0.0689, 0.0685, 0.0357, 0.0712, 0.0761,
        0.0349, 0.0277, 0.0160], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,942][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.1426, 0.0110, 0.0889, 0.0698, 0.0799, 0.0662, 0.1088, 0.0963, 0.0926,
        0.1502, 0.0515, 0.0422], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,944][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.7854e-02, 4.2671e-04, 3.2240e-04, 1.5565e-03, 3.8038e-04, 8.1982e-03,
        8.7482e-03, 4.6421e-02, 2.4485e-02, 9.7055e-03, 5.7316e-01, 3.0874e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,947][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0393, 0.0007, 0.0014, 0.0024, 0.0016, 0.0202, 0.0299, 0.0546, 0.0408,
        0.0132, 0.3294, 0.4665], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,949][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([4.0742e-05, 1.5753e-02, 8.2410e-03, 5.4888e-02, 3.7527e-02, 4.1667e-02,
        2.3398e-01, 1.2516e-01, 2.2668e-01, 1.4524e-01, 4.8271e-02, 6.2552e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,953][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.1909, 0.0270, 0.1092, 0.1285, 0.0508, 0.1053, 0.0833, 0.0797, 0.1018,
        0.0361, 0.0451, 0.0425], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:21,955][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([6.4073e-03, 1.1763e-05, 6.7400e-05, 8.0923e-05, 4.6388e-05, 1.0502e-03,
        2.1799e-03, 5.7249e-03, 2.9790e-03, 9.3868e-04, 3.5364e-01, 3.5533e-01,
        2.7155e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,956][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0388, 0.0633, 0.1101, 0.1094, 0.0876, 0.0656, 0.1407, 0.0793, 0.0939,
        0.0447, 0.0450, 0.0747, 0.0468], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,956][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([1.5343e-05, 2.8344e-02, 3.6096e-03, 5.4718e-02, 1.6206e-02, 3.3785e-02,
        1.7657e-01, 1.3931e-01, 1.7859e-01, 1.2354e-01, 6.3771e-02, 1.3992e-01,
        4.1617e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,957][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0938, 0.0005, 0.0020, 0.0020, 0.0019, 0.0150, 0.0185, 0.0400, 0.0237,
        0.0162, 0.1083, 0.2716, 0.4065], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,957][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([5.6621e-02, 1.0457e-04, 7.0555e-04, 7.2376e-04, 8.3219e-04, 5.7969e-03,
        1.5524e-02, 3.3738e-02, 1.1336e-02, 1.9311e-02, 1.2909e-01, 3.7731e-01,
        3.4891e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,957][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.5957, 0.0220, 0.0290, 0.0224, 0.0201, 0.0507, 0.0503, 0.0339, 0.0455,
        0.0319, 0.0397, 0.0234, 0.0355], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,958][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.3492, 0.0234, 0.0719, 0.0692, 0.0925, 0.0718, 0.0419, 0.0807, 0.0801,
        0.0351, 0.0365, 0.0222, 0.0256], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,958][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0878, 0.0168, 0.0789, 0.0743, 0.0799, 0.0655, 0.1348, 0.1026, 0.0674,
        0.1213, 0.0422, 0.0579, 0.0705], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,958][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([1.8741e-02, 1.6658e-04, 2.9948e-04, 5.6126e-04, 2.4266e-04, 4.0504e-03,
        5.7278e-03, 2.0848e-02, 1.0480e-02, 6.1917e-03, 3.4896e-01, 2.4964e-01,
        3.3410e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,959][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([2.4878e-02, 3.1856e-04, 8.8999e-04, 1.2414e-03, 1.0828e-03, 7.8195e-03,
        1.1660e-02, 1.5781e-02, 1.7849e-02, 5.0090e-03, 1.4172e-01, 3.1182e-01,
        4.5993e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,961][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([2.8137e-05, 1.8336e-02, 5.5203e-03, 4.5193e-02, 2.8577e-02, 2.8714e-02,
        2.4205e-01, 8.0698e-02, 2.5848e-01, 1.3589e-01, 4.2360e-02, 1.0564e-01,
        8.5092e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,964][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0430, 0.0170, 0.0593, 0.1237, 0.0583, 0.1367, 0.1580, 0.0970, 0.1293,
        0.0425, 0.0396, 0.0677, 0.0280], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:21,966][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([4.6420e-03, 1.5330e-05, 1.6938e-04, 1.6853e-04, 1.9739e-04, 1.2835e-03,
        3.3595e-03, 1.6617e-02, 4.9207e-03, 5.0739e-03, 2.0563e-01, 3.4217e-01,
        3.3832e-01, 7.7434e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,970][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.1107, 0.0344, 0.1736, 0.0806, 0.0999, 0.0559, 0.0784, 0.0829, 0.0558,
        0.0451, 0.0297, 0.0472, 0.0622, 0.0435], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,972][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([1.8736e-05, 2.9301e-02, 5.9080e-03, 4.8556e-02, 2.2222e-02, 3.8839e-02,
        1.2456e-01, 1.3476e-01, 1.6239e-01, 1.3819e-01, 8.3634e-02, 1.1075e-01,
        5.7531e-02, 4.3356e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,974][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.1144, 0.0007, 0.0026, 0.0027, 0.0025, 0.0150, 0.0195, 0.0485, 0.0244,
        0.0289, 0.0839, 0.1887, 0.3249, 0.1434], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,974][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([8.6684e-02, 1.3992e-04, 1.3914e-03, 1.4821e-03, 1.5839e-03, 5.4298e-03,
        1.6130e-02, 6.2319e-02, 1.3496e-02, 3.4303e-02, 1.1252e-01, 2.7089e-01,
        2.9115e-01, 1.0249e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,974][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.7092, 0.0098, 0.0384, 0.0124, 0.0233, 0.0341, 0.0212, 0.0168, 0.0190,
        0.0199, 0.0254, 0.0136, 0.0318, 0.0250], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,975][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.5356, 0.0103, 0.0705, 0.0425, 0.0602, 0.0572, 0.0267, 0.0436, 0.0457,
        0.0227, 0.0226, 0.0144, 0.0192, 0.0287], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,975][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0991, 0.0174, 0.0712, 0.0701, 0.0625, 0.0612, 0.0886, 0.0954, 0.0688,
        0.1176, 0.0410, 0.0361, 0.1323, 0.0387], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,976][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([1.4381e-02, 2.7698e-04, 5.8527e-04, 1.1260e-03, 8.4714e-04, 5.8580e-03,
        6.6270e-03, 4.7546e-02, 1.4911e-02, 1.8893e-02, 2.4715e-01, 1.7095e-01,
        3.3509e-01, 1.3576e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,976][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([3.2914e-02, 3.4108e-04, 1.5063e-03, 1.6402e-03, 2.3468e-03, 7.5374e-03,
        1.1230e-02, 2.8701e-02, 1.8971e-02, 1.5797e-02, 1.1071e-01, 2.4347e-01,
        3.6476e-01, 1.6008e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,976][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([4.7332e-05, 2.2227e-02, 7.9603e-03, 4.3277e-02, 4.0959e-02, 3.7378e-02,
        2.3137e-01, 9.0553e-02, 2.0494e-01, 1.1866e-01, 4.1210e-02, 7.8439e-02,
        1.3121e-02, 6.9860e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,977][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0958, 0.0229, 0.0794, 0.1254, 0.0576, 0.1159, 0.1133, 0.0612, 0.1135,
        0.0358, 0.0401, 0.0558, 0.0402, 0.0430], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:21,978][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([2.1373e-03, 1.1929e-05, 4.5592e-05, 4.9572e-05, 3.0100e-05, 3.8601e-04,
        4.6542e-04, 4.9068e-04, 6.4562e-04, 1.9581e-04, 3.0502e-01, 3.6033e-01,
        2.7401e-01, 2.4988e-02, 3.1205e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,980][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0115, 0.0724, 0.1054, 0.0863, 0.1039, 0.0694, 0.0967, 0.1080, 0.0621,
        0.0520, 0.0315, 0.0465, 0.0627, 0.0408, 0.0507], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,982][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([7.3800e-06, 1.2472e-02, 3.7158e-03, 2.6552e-02, 1.9989e-02, 4.4826e-02,
        1.0243e-01, 1.8979e-01, 1.7079e-01, 1.2173e-01, 8.5297e-02, 1.0104e-01,
        5.2646e-02, 3.1915e-02, 3.6805e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,986][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.0790, 0.0006, 0.0020, 0.0019, 0.0014, 0.0094, 0.0094, 0.0106, 0.0103,
        0.0060, 0.0939, 0.2240, 0.3878, 0.0929, 0.0709], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,988][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([2.7663e-02, 1.1699e-04, 8.1696e-04, 8.1984e-04, 6.1324e-04, 2.6161e-03,
        5.3062e-03, 9.3126e-03, 4.8612e-03, 4.8292e-03, 1.8721e-01, 3.1582e-01,
        3.1322e-01, 6.0705e-02, 6.6086e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,992][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.5100, 0.0300, 0.0338, 0.0307, 0.0214, 0.0469, 0.0356, 0.0358, 0.0449,
        0.0243, 0.0544, 0.0215, 0.0421, 0.0355, 0.0332], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,992][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.2939, 0.0254, 0.0808, 0.0620, 0.0720, 0.0662, 0.0306, 0.0636, 0.0710,
        0.0477, 0.0339, 0.0164, 0.0450, 0.0464, 0.0451], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,993][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0235, 0.0150, 0.0497, 0.0537, 0.0858, 0.0485, 0.0761, 0.1089, 0.0453,
        0.1043, 0.0356, 0.0443, 0.1540, 0.0220, 0.1334], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,993][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([1.1068e-02, 1.9220e-04, 2.1280e-04, 3.9090e-04, 1.5202e-04, 1.3851e-03,
        1.3195e-03, 4.6656e-03, 2.8638e-03, 1.2190e-03, 3.2967e-01, 2.1866e-01,
        3.1719e-01, 6.9453e-02, 4.1560e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,994][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([9.2878e-03, 1.3995e-04, 7.0649e-04, 6.2348e-04, 5.9048e-04, 2.8712e-03,
        3.0533e-03, 2.3051e-03, 4.6507e-03, 1.5423e-03, 1.5007e-01, 2.1314e-01,
        4.6151e-01, 7.2440e-02, 7.7064e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,994][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([2.1876e-05, 1.6425e-02, 5.8742e-03, 2.5512e-02, 2.9197e-02, 3.1401e-02,
        1.2944e-01, 1.2819e-01, 1.6658e-01, 1.4557e-01, 5.0510e-02, 1.3035e-01,
        1.6106e-02, 8.2701e-02, 4.2113e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,994][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.1042, 0.0170, 0.0722, 0.0830, 0.0471, 0.1089, 0.0952, 0.0768, 0.1012,
        0.0241, 0.0477, 0.0531, 0.0883, 0.0475, 0.0336], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:21,995][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([9.6879e-03, 9.5549e-06, 5.1957e-05, 3.7321e-05, 1.3409e-05, 7.3299e-04,
        9.4401e-04, 2.7830e-03, 8.8609e-04, 1.4531e-04, 7.1958e-02, 6.6159e-02,
        6.0634e-02, 1.8893e-02, 2.7395e-03, 7.6432e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,995][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0435, 0.0605, 0.0932, 0.0489, 0.1362, 0.0468, 0.0817, 0.0738, 0.0494,
        0.0439, 0.0379, 0.0469, 0.0843, 0.0293, 0.0819, 0.0419],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,996][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([2.2743e-05, 2.7618e-02, 5.5176e-03, 4.2721e-02, 2.6962e-02, 4.5305e-02,
        1.2038e-01, 1.1033e-01, 1.5988e-01, 1.2689e-01, 8.5001e-02, 1.0132e-01,
        4.3607e-02, 3.7075e-02, 4.4283e-02, 2.3092e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:21,999][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.1907, 0.0005, 0.0017, 0.0014, 0.0009, 0.0118, 0.0121, 0.0164, 0.0130,
        0.0059, 0.0450, 0.0938, 0.1501, 0.0632, 0.0241, 0.3693],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,001][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.3153e-01, 7.6785e-05, 5.1381e-04, 4.4932e-04, 3.2251e-04, 3.1284e-03,
        7.7657e-03, 1.6414e-02, 4.4653e-03, 4.3235e-03, 4.5891e-02, 1.0254e-01,
        1.0830e-01, 4.1246e-02, 1.9396e-02, 5.1364e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,004][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.6284, 0.0140, 0.0355, 0.0140, 0.0253, 0.0437, 0.0337, 0.0284, 0.0243,
        0.0212, 0.0222, 0.0112, 0.0269, 0.0227, 0.0310, 0.0174],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,008][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.2668, 0.0175, 0.0741, 0.0603, 0.1062, 0.0605, 0.0370, 0.0674, 0.0784,
        0.0334, 0.0312, 0.0193, 0.0307, 0.0391, 0.0565, 0.0218],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,010][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0365, 0.0160, 0.0496, 0.0620, 0.0838, 0.0651, 0.1138, 0.0795, 0.0588,
        0.1263, 0.0312, 0.0334, 0.0782, 0.0245, 0.1010, 0.0403],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,011][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([2.4708e-02, 1.8838e-04, 3.7351e-04, 5.5846e-04, 1.6416e-04, 4.3480e-03,
        4.2351e-03, 1.5982e-02, 6.1262e-03, 1.4233e-03, 1.5924e-01, 6.9307e-02,
        9.9809e-02, 5.5511e-02, 1.0396e-02, 5.4763e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,011][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.9967e-02, 1.5558e-04, 6.0466e-04, 4.1439e-04, 4.1087e-04, 3.0746e-03,
        4.7028e-03, 3.4476e-03, 4.6525e-03, 7.2632e-04, 3.0768e-02, 6.4383e-02,
        1.5162e-01, 4.8477e-02, 2.7504e-02, 6.2909e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,011][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([8.6981e-05, 2.0687e-02, 4.6490e-03, 3.8805e-02, 2.6399e-02, 4.0026e-02,
        2.0394e-01, 5.7117e-02, 1.9029e-01, 1.3405e-01, 5.9413e-02, 8.8843e-02,
        1.4020e-02, 7.9856e-02, 3.2832e-02, 8.9835e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,012][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0592, 0.0206, 0.0558, 0.0995, 0.0451, 0.1153, 0.0843, 0.0642, 0.1269,
        0.0351, 0.0433, 0.0606, 0.0449, 0.0493, 0.0374, 0.0584],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,012][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([3.8073e-03, 3.4621e-06, 2.3144e-05, 2.2464e-05, 9.1145e-06, 2.8524e-04,
        3.5289e-04, 3.2229e-03, 7.1941e-04, 3.1881e-04, 2.4009e-02, 2.2914e-02,
        3.7455e-02, 1.1507e-02, 2.9200e-03, 3.9305e-01, 4.9938e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,012][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0784, 0.0448, 0.1046, 0.0723, 0.1010, 0.0422, 0.0608, 0.0787, 0.0523,
        0.0519, 0.0349, 0.0569, 0.0534, 0.0354, 0.0725, 0.0288, 0.0312],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,013][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.7997e-05, 2.2608e-02, 7.5956e-03, 4.6881e-02, 2.7084e-02, 4.3380e-02,
        8.0195e-02, 1.8938e-01, 1.3688e-01, 1.3259e-01, 6.9861e-02, 8.0120e-02,
        3.4771e-02, 2.8434e-02, 3.2667e-02, 2.9532e-02, 3.8012e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,013][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.0300e-01, 2.5911e-04, 9.1692e-04, 9.9132e-04, 6.5700e-04, 6.7659e-03,
        9.4041e-03, 2.0097e-02, 1.1052e-02, 8.6955e-03, 2.9969e-02, 5.5355e-02,
        1.0744e-01, 6.9195e-02, 2.4740e-02, 2.5012e-01, 3.0134e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,015][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.0425e-01, 3.9389e-05, 5.0296e-04, 3.2730e-04, 3.8956e-04, 2.3873e-03,
        5.2941e-03, 2.2248e-02, 4.0573e-03, 6.1941e-03, 3.1967e-02, 6.1323e-02,
        8.0118e-02, 3.8284e-02, 2.1757e-02, 3.4306e-01, 2.7780e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,017][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.7038, 0.0094, 0.0220, 0.0114, 0.0163, 0.0291, 0.0145, 0.0259, 0.0190,
        0.0277, 0.0150, 0.0083, 0.0251, 0.0209, 0.0249, 0.0134, 0.0132],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,021][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4774, 0.0127, 0.0518, 0.0465, 0.0599, 0.0456, 0.0239, 0.0574, 0.0522,
        0.0296, 0.0197, 0.0121, 0.0211, 0.0309, 0.0341, 0.0155, 0.0096],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,024][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1207, 0.0095, 0.0538, 0.0451, 0.0516, 0.0436, 0.0555, 0.0751, 0.0649,
        0.0939, 0.0411, 0.0329, 0.0794, 0.0329, 0.0982, 0.0540, 0.0478],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,027][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([1.3019e-02, 6.6207e-05, 1.3779e-04, 2.8505e-04, 9.8731e-05, 2.1196e-03,
        1.8152e-03, 1.4893e-02, 4.5920e-03, 2.4743e-03, 6.5125e-02, 3.4569e-02,
        9.6072e-02, 6.0477e-02, 1.0428e-02, 3.3342e-01, 3.6041e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,028][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.8621e-02, 6.1589e-05, 2.8435e-04, 2.4635e-04, 3.0177e-04, 3.0753e-03,
        3.0935e-03, 7.8622e-03, 5.2875e-03, 1.8515e-03, 2.4101e-02, 3.9470e-02,
        9.4788e-02, 4.3265e-02, 2.8706e-02, 4.2487e-01, 3.0412e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,029][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.6176e-05, 1.2394e-02, 5.5910e-03, 3.9367e-02, 2.3258e-02, 3.3477e-02,
        1.3512e-01, 1.4109e-01, 1.6210e-01, 1.5910e-01, 3.8877e-02, 7.1411e-02,
        8.3489e-03, 6.1365e-02, 2.9214e-02, 2.1574e-02, 5.7668e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,029][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1128, 0.0191, 0.0855, 0.0816, 0.0463, 0.0852, 0.0654, 0.0624, 0.0835,
        0.0377, 0.0430, 0.0508, 0.0423, 0.0378, 0.0366, 0.0708, 0.0392],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,030][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([4.4461e-04, 7.3772e-07, 3.6028e-06, 4.2412e-06, 2.7488e-06, 4.1014e-05,
        1.0535e-04, 3.6880e-04, 1.5054e-04, 4.8415e-05, 2.0126e-02, 2.5137e-02,
        1.9725e-02, 4.4456e-03, 3.0023e-03, 4.0132e-01, 4.1486e-01, 1.1021e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,030][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.0598, 0.0446, 0.0855, 0.0730, 0.0830, 0.0482, 0.0844, 0.0555, 0.0624,
        0.0475, 0.0286, 0.0591, 0.0537, 0.0395, 0.0630, 0.0225, 0.0319, 0.0576],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,030][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([7.5589e-06, 2.2577e-02, 2.1310e-03, 2.5621e-02, 1.5756e-02, 2.4982e-02,
        9.1545e-02, 1.8065e-01, 1.5632e-01, 1.3584e-01, 6.8252e-02, 8.2114e-02,
        4.5148e-02, 3.8285e-02, 3.1669e-02, 1.5972e-02, 3.7921e-02, 2.5214e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,031][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([8.5654e-02, 1.2417e-04, 5.8658e-04, 5.7650e-04, 4.7692e-04, 2.9957e-03,
        3.6638e-03, 7.1147e-03, 4.5673e-03, 3.7372e-03, 2.2909e-02, 4.7197e-02,
        1.1022e-01, 3.2586e-02, 2.6042e-02, 2.1396e-01, 2.0668e-01, 2.3091e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,031][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([1.7968e-02, 2.2063e-05, 1.7546e-04, 1.1920e-04, 1.8472e-04, 6.5368e-04,
        2.0502e-03, 5.2239e-03, 1.3467e-03, 2.2134e-03, 2.1213e-02, 5.0700e-02,
        6.3135e-02, 2.1624e-02, 1.9148e-02, 3.1230e-01, 2.6561e-01, 2.1631e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,033][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.6086, 0.0092, 0.0212, 0.0102, 0.0222, 0.0409, 0.0210, 0.0204, 0.0180,
        0.0176, 0.0235, 0.0108, 0.0290, 0.0208, 0.0447, 0.0248, 0.0221, 0.0349],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,035][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.3945, 0.0118, 0.0759, 0.0403, 0.0915, 0.0379, 0.0262, 0.0454, 0.0464,
        0.0285, 0.0272, 0.0152, 0.0244, 0.0304, 0.0506, 0.0165, 0.0112, 0.0261],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,039][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0406, 0.0075, 0.0299, 0.0343, 0.0430, 0.0378, 0.0552, 0.0673, 0.0612,
        0.1051, 0.0342, 0.0291, 0.0995, 0.0270, 0.0975, 0.0441, 0.0470, 0.1395],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,042][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([5.1569e-03, 3.4148e-05, 3.5484e-05, 1.0785e-04, 3.4347e-05, 5.4633e-04,
        6.1818e-04, 4.2854e-03, 1.2247e-03, 6.1010e-04, 4.1681e-02, 3.8904e-02,
        5.3008e-02, 1.7129e-02, 7.6281e-03, 3.3793e-01, 2.6810e-01, 2.2296e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,044][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([8.6595e-03, 2.5592e-05, 1.4010e-04, 9.5387e-05, 1.5008e-04, 7.6120e-04,
        1.0535e-03, 1.2757e-03, 1.5751e-03, 4.7966e-04, 1.8129e-02, 3.8707e-02,
        8.2560e-02, 1.9429e-02, 2.8919e-02, 3.1755e-01, 3.0560e-01, 1.7489e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,047][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([1.6250e-05, 1.6787e-02, 3.4641e-03, 2.2914e-02, 1.8816e-02, 2.2827e-02,
        1.3845e-01, 9.5960e-02, 1.9318e-01, 1.5642e-01, 4.2355e-02, 6.4721e-02,
        1.3507e-02, 8.2277e-02, 2.5670e-02, 1.5330e-02, 6.9252e-02, 1.8053e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,047][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.0751, 0.0207, 0.0384, 0.0777, 0.0343, 0.1266, 0.0731, 0.0864, 0.1011,
        0.0429, 0.0370, 0.0512, 0.0449, 0.0366, 0.0293, 0.0430, 0.0449, 0.0368],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,047][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.1918e-03, 8.0297e-07, 8.6032e-06, 4.0755e-06, 1.8760e-06, 7.2997e-05,
        1.5411e-04, 2.6699e-04, 1.1797e-04, 2.1712e-05, 6.3050e-03, 1.2494e-02,
        1.0798e-02, 3.1556e-03, 5.6439e-04, 2.1126e-01, 3.4495e-01, 8.1088e-02,
        3.2654e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,048][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0672, 0.0385, 0.0754, 0.0687, 0.0705, 0.0398, 0.0621, 0.0696, 0.0600,
        0.0552, 0.0318, 0.0519, 0.0563, 0.0382, 0.0570, 0.0299, 0.0340, 0.0640,
        0.0297], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,048][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([3.3628e-05, 2.5421e-02, 4.2194e-03, 4.4520e-02, 2.1411e-02, 4.3068e-02,
        9.6259e-02, 1.5167e-01, 1.3336e-01, 9.4378e-02, 6.7364e-02, 6.9014e-02,
        4.4408e-02, 3.5474e-02, 2.3948e-02, 2.6271e-02, 3.8447e-02, 1.5355e-02,
        6.5369e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,049][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([9.0282e-02, 1.5642e-04, 4.4231e-04, 4.7133e-04, 2.2989e-04, 3.5200e-03,
        4.4705e-03, 7.0093e-03, 4.7902e-03, 2.8065e-03, 1.8538e-02, 3.5114e-02,
        7.0434e-02, 3.3611e-02, 9.2944e-03, 1.7072e-01, 1.9356e-01, 1.8742e-01,
        1.6712e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,049][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([8.1075e-02, 2.1122e-05, 3.1794e-04, 1.5754e-04, 1.9158e-04, 1.2430e-03,
        2.5664e-03, 6.4135e-03, 1.7614e-03, 2.3749e-03, 1.7656e-02, 3.9278e-02,
        4.8821e-02, 1.6863e-02, 1.0857e-02, 2.2684e-01, 1.8043e-01, 2.0446e-01,
        1.5867e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,051][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.6831, 0.0080, 0.0208, 0.0091, 0.0147, 0.0269, 0.0150, 0.0170, 0.0144,
        0.0191, 0.0150, 0.0087, 0.0243, 0.0211, 0.0245, 0.0133, 0.0163, 0.0302,
        0.0186], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,054][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.5279, 0.0078, 0.0468, 0.0331, 0.0482, 0.0348, 0.0220, 0.0429, 0.0410,
        0.0235, 0.0181, 0.0124, 0.0189, 0.0273, 0.0356, 0.0148, 0.0094, 0.0240,
        0.0115], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,057][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1182, 0.0082, 0.0517, 0.0383, 0.0462, 0.0361, 0.0483, 0.0542, 0.0409,
        0.0709, 0.0305, 0.0232, 0.0889, 0.0217, 0.0771, 0.0424, 0.0429, 0.1388,
        0.0215], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,060][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([7.1558e-03, 2.4152e-05, 6.1014e-05, 8.0849e-05, 4.0549e-05, 6.7976e-04,
        7.0641e-04, 2.4594e-03, 1.0000e-03, 4.3356e-04, 3.0494e-02, 1.6475e-02,
        5.1432e-02, 2.0734e-02, 4.4909e-03, 1.7456e-01, 2.2455e-01, 1.4037e-01,
        3.2425e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,062][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([1.4576e-02, 3.4203e-05, 1.5201e-04, 1.2453e-04, 1.2834e-04, 1.4683e-03,
        1.8335e-03, 2.3011e-03, 1.8838e-03, 4.4174e-04, 1.2506e-02, 2.8152e-02,
        5.4055e-02, 2.1738e-02, 1.1083e-02, 2.4066e-01, 2.4253e-01, 1.3911e-01,
        2.2722e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,064][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([5.5573e-05, 1.1965e-02, 4.1414e-03, 3.5399e-02, 2.4155e-02, 3.6578e-02,
        1.6640e-01, 7.8329e-02, 1.5637e-01, 1.1452e-01, 3.3348e-02, 6.6589e-02,
        1.0435e-02, 7.7775e-02, 3.1384e-02, 1.8190e-02, 7.9059e-02, 2.4897e-02,
        3.0409e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,066][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1424, 0.0143, 0.0765, 0.0777, 0.0385, 0.0956, 0.0722, 0.0479, 0.0695,
        0.0247, 0.0348, 0.0374, 0.0427, 0.0362, 0.0289, 0.0561, 0.0339, 0.0315,
        0.0391], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,067][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:22,069][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[ 9375],
        [31631],
        [29153],
        [15799],
        [ 8167],
        [ 6061],
        [ 7932],
        [ 3042],
        [10697],
        [ 8931],
        [ 6545],
        [ 9938],
        [ 5671],
        [ 4567],
        [ 3399],
        [ 4369],
        [ 7006],
        [ 2980],
        [ 4933]], device='cuda:0')
[2024-07-24 10:27:22,070][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[11716],
        [21531],
        [16864],
        [ 7406],
        [ 4434],
        [ 3647],
        [ 5924],
        [ 2346],
        [ 7970],
        [ 9998],
        [ 6148],
        [ 9838],
        [ 6474],
        [ 5891],
        [ 3566],
        [ 4511],
        [ 8042],
        [ 3989],
        [ 6522]], device='cuda:0')
[2024-07-24 10:27:22,071][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[37776],
        [31543],
        [32394],
        [33970],
        [35733],
        [30461],
        [27674],
        [24381],
        [23751],
        [22503],
        [17762],
        [19133],
        [20064],
        [21129],
        [20639],
        [33779],
        [30134],
        [29455],
        [28373]], device='cuda:0')
[2024-07-24 10:27:22,072][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[32657],
        [23214],
        [46635],
        [43178],
        [43136],
        [43103],
        [41324],
        [37052],
        [38720],
        [34265],
        [31412],
        [30530],
        [26299],
        [31205],
        [28178],
        [29448],
        [29152],
        [27920],
        [26664]], device='cuda:0')
[2024-07-24 10:27:22,075][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[25859],
        [48920],
        [49969],
        [50014],
        [50080],
        [50122],
        [50095],
        [49613],
        [49369],
        [46935],
        [47583],
        [47440],
        [47477],
        [47413],
        [46927],
        [47812],
        [47242],
        [46596],
        [48082]], device='cuda:0')
[2024-07-24 10:27:22,076][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 1107],
        [ 1968],
        [ 9890],
        [ 3463],
        [12373],
        [ 1669],
        [ 1446],
        [ 3434],
        [ 2163],
        [ 3994],
        [ 5247],
        [ 2415],
        [ 5369],
        [ 3592],
        [ 7464],
        [ 3700],
        [ 1959],
        [ 5542],
        [ 3798]], device='cuda:0')
[2024-07-24 10:27:22,078][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[26694],
        [28967],
        [29036],
        [28782],
        [29174],
        [29267],
        [29489],
        [29162],
        [28982],
        [28740],
        [29203],
        [29506],
        [29498],
        [29918],
        [29860],
        [29542],
        [29529],
        [28695],
        [28595]], device='cuda:0')
[2024-07-24 10:27:22,081][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[27143],
        [20431],
        [30052],
        [32600],
        [31455],
        [34821],
        [35071],
        [30437],
        [32296],
        [28739],
        [25707],
        [25697],
        [20079],
        [23667],
        [19260],
        [21151],
        [21548],
        [17885],
        [18760]], device='cuda:0')
[2024-07-24 10:27:22,084][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 2468],
        [ 5749],
        [17166],
        [16209],
        [21336],
        [18607],
        [18113],
        [20728],
        [22200],
        [23258],
        [24797],
        [24627],
        [24885],
        [24343],
        [26161],
        [26571],
        [25760],
        [26450],
        [26641]], device='cuda:0')
[2024-07-24 10:27:22,086][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[48881],
        [44103],
        [49154],
        [49362],
        [49246],
        [49259],
        [49032],
        [48822],
        [48932],
        [48227],
        [48009],
        [48173],
        [48192],
        [48091],
        [47604],
        [47904],
        [48084],
        [47722],
        [48069]], device='cuda:0')
[2024-07-24 10:27:22,089][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 7595],
        [11540],
        [16340],
        [12164],
        [11517],
        [ 9207],
        [ 9392],
        [13080],
        [11677],
        [ 6135],
        [ 6148],
        [ 6862],
        [ 4641],
        [ 4805],
        [ 4991],
        [ 5732],
        [ 5697],
        [ 6298],
        [ 6685]], device='cuda:0')
[2024-07-24 10:27:22,090][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[41368],
        [22070],
        [17252],
        [20831],
        [23525],
        [30244],
        [17064],
        [18463],
        [16807],
        [16437],
        [22996],
        [18015],
        [15550],
        [16944],
        [18070],
        [29594],
        [22938],
        [21810],
        [20070]], device='cuda:0')
[2024-07-24 10:27:22,091][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[21794],
        [34340],
        [49624],
        [45612],
        [36871],
        [36642],
        [43003],
        [44468],
        [41854],
        [41902],
        [41498],
        [41713],
        [41947],
        [41832],
        [41007],
        [41448],
        [41078],
        [41053],
        [41204]], device='cuda:0')
[2024-07-24 10:27:22,092][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[33303],
        [44338],
        [45434],
        [43308],
        [43500],
        [43217],
        [42618],
        [42495],
        [41480],
        [38747],
        [38211],
        [37790],
        [36885],
        [37131],
        [37481],
        [36558],
        [36608],
        [38429],
        [38132]], device='cuda:0')
[2024-07-24 10:27:22,093][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 2503],
        [24629],
        [ 4954],
        [ 7060],
        [ 3138],
        [ 2473],
        [ 1303],
        [ 1569],
        [ 3502],
        [  668],
        [ 3321],
        [ 3636],
        [ 2006],
        [ 1430],
        [ 3049],
        [  961],
        [ 1136],
        [ 1030],
        [ 1022]], device='cuda:0')
[2024-07-24 10:27:22,094][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[1486],
        [7313],
        [2277],
        [1159],
        [1473],
        [1003],
        [ 740],
        [5870],
        [5239],
        [3429],
        [ 708],
        [ 994],
        [1324],
        [1614],
        [1375],
        [1701],
        [ 981],
        [1182],
        [1237]], device='cuda:0')
[2024-07-24 10:27:22,095][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[15645],
        [22601],
        [18794],
        [21171],
        [27916],
        [31321],
        [32571],
        [33102],
        [33832],
        [34998],
        [34229],
        [35520],
        [37439],
        [38197],
        [37819],
        [39913],
        [38805],
        [38542],
        [38553]], device='cuda:0')
[2024-07-24 10:27:22,098][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[23705],
        [17244],
        [16839],
        [15273],
        [12702],
        [12916],
        [ 8907],
        [ 7105],
        [ 7033],
        [ 5487],
        [ 6084],
        [ 5607],
        [ 6343],
        [ 6733],
        [ 5951],
        [ 6047],
        [ 6165],
        [ 6191],
        [ 6507]], device='cuda:0')
[2024-07-24 10:27:22,099][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 8014],
        [ 6114],
        [ 9088],
        [10636],
        [11569],
        [18274],
        [16582],
        [29831],
        [24919],
        [22327],
        [16813],
        [18058],
        [ 9960],
        [11925],
        [10371],
        [ 7408],
        [13133],
        [11592],
        [14674]], device='cuda:0')
[2024-07-24 10:27:22,101][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[43530],
        [47866],
        [40896],
        [35585],
        [32818],
        [33595],
        [25942],
        [12816],
        [14535],
        [12452],
        [18860],
        [15446],
        [18801],
        [18587],
        [19763],
        [14891],
        [14222],
        [14446],
        [13186]], device='cuda:0')
[2024-07-24 10:27:22,104][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 4624],
        [13168],
        [24884],
        [14838],
        [24349],
        [18151],
        [16511],
        [ 9378],
        [15550],
        [13260],
        [32939],
        [30446],
        [34022],
        [27996],
        [36090],
        [31886],
        [28862],
        [36414],
        [33452]], device='cuda:0')
[2024-07-24 10:27:22,107][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[23548],
        [22062],
        [10934],
        [25116],
        [12798],
        [15987],
        [16282],
        [19251],
        [18803],
        [12651],
        [10339],
        [ 9610],
        [ 8441],
        [11192],
        [ 8803],
        [ 9013],
        [10823],
        [ 9854],
        [11501]], device='cuda:0')
[2024-07-24 10:27:22,109][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22096],
        [25862],
        [23005],
        [22824],
        [20462],
        [18048],
        [17179],
        [17533],
        [17169],
        [16073],
        [14457],
        [14707],
        [15029],
        [15430],
        [15829],
        [14645],
        [15508],
        [14522],
        [15463]], device='cuda:0')
[2024-07-24 10:27:22,112][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[30385],
        [17553],
        [27276],
        [25915],
        [30206],
        [28148],
        [26349],
        [ 3947],
        [ 6409],
        [11234],
        [17624],
        [20050],
        [24912],
        [24029],
        [24388],
        [15585],
        [16370],
        [19744],
        [20180]], device='cuda:0')
[2024-07-24 10:27:22,113][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[25771],
        [ 5242],
        [ 5955],
        [ 7943],
        [ 4977],
        [ 3439],
        [ 4686],
        [ 9111],
        [ 7167],
        [ 6232],
        [ 1659],
        [ 2685],
        [ 5993],
        [ 5531],
        [ 5274],
        [ 3132],
        [ 2312],
        [ 2006],
        [ 2073]], device='cuda:0')
[2024-07-24 10:27:22,114][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 7779],
        [ 8326],
        [ 3808],
        [ 8614],
        [ 9319],
        [10687],
        [ 7225],
        [ 6433],
        [ 8838],
        [ 7260],
        [ 7232],
        [ 8414],
        [ 8649],
        [ 9125],
        [ 9392],
        [ 9190],
        [ 8728],
        [ 9156],
        [ 9418]], device='cuda:0')
[2024-07-24 10:27:22,115][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[12165],
        [  731],
        [  422],
        [  862],
        [  601],
        [  573],
        [  498],
        [  473],
        [  673],
        [  588],
        [  658],
        [  655],
        [  605],
        [  621],
        [  652],
        [  605],
        [  551],
        [  602],
        [  539]], device='cuda:0')
[2024-07-24 10:27:22,116][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[36980],
        [38917],
        [43323],
        [43698],
        [42570],
        [43415],
        [46119],
        [47253],
        [45706],
        [47427],
        [46430],
        [46212],
        [44720],
        [44962],
        [43874],
        [46671],
        [46851],
        [45916],
        [45752]], device='cuda:0')
[2024-07-24 10:27:22,118][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[47453],
        [43325],
        [49608],
        [49068],
        [49230],
        [48461],
        [48603],
        [45214],
        [44220],
        [46182],
        [45198],
        [43202],
        [43076],
        [44061],
        [40380],
        [46427],
        [46095],
        [45289],
        [44216]], device='cuda:0')
[2024-07-24 10:27:22,120][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430],
        [3430]], device='cuda:0')
[2024-07-24 10:27:22,156][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:22,156][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,157][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,157][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,157][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,158][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,158][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,158][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,158][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,159][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,159][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,159][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,160][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,163][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9382, 0.0618], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,164][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1121, 0.8879], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,165][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1612, 0.8388], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,165][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0888, 0.9112], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,165][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0093, 0.9907], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,166][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2293, 0.7707], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,166][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1201, 0.8799], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,166][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0109, 0.9891], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,169][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3453, 0.6547], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,173][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9455, 0.0545], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,173][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8107, 0.1893], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,174][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4995, 0.5005], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,174][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.7322, 0.1708, 0.0970], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,174][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([0.0445, 0.5222, 0.4333], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,174][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.1376, 0.6825, 0.1799], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,175][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.0421, 0.5110, 0.4469], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,175][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.0086, 0.9429, 0.0486], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,175][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([0.2198, 0.4686, 0.3117], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,176][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.0762, 0.6772, 0.2466], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,176][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.0072, 0.4147, 0.5781], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,176][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.1306, 0.6340, 0.2354], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,178][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.6294, 0.1623, 0.2083], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,180][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.4565, 0.2320, 0.3115], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,184][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.0949, 0.6889, 0.2162], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,188][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.8982, 0.0374, 0.0361, 0.0282], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,191][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0336, 0.2304, 0.2417, 0.4944], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,191][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0690, 0.4231, 0.1116, 0.3963], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,192][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0248, 0.1958, 0.2005, 0.5789], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,192][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0133, 0.8162, 0.0782, 0.0922], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,192][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1356, 0.3118, 0.2235, 0.3291], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,192][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0715, 0.4082, 0.1348, 0.3855], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,193][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0026, 0.1565, 0.2451, 0.5959], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,193][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1996, 0.3043, 0.1477, 0.3485], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,193][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.8080, 0.0459, 0.0900, 0.0561], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,194][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6299, 0.0620, 0.1317, 0.1763], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,194][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.3763, 0.1261, 0.1029, 0.3947], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,196][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.7986, 0.0694, 0.0485, 0.0430, 0.0406], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,198][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0203, 0.2140, 0.2142, 0.2756, 0.2760], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,202][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0511, 0.2502, 0.0545, 0.2516, 0.3926], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,206][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0252, 0.1560, 0.1698, 0.4713, 0.1777], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,209][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0082, 0.5622, 0.0420, 0.3593, 0.0282], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,209][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.1298, 0.2341, 0.1651, 0.2507, 0.2203], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,209][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0250, 0.3296, 0.1266, 0.3175, 0.2013], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,210][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0022, 0.0488, 0.0724, 0.1953, 0.6812], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,210][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.0896, 0.3089, 0.1326, 0.3377, 0.1313], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,210][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.6958, 0.0490, 0.0857, 0.0767, 0.0928], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,211][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.4720, 0.0743, 0.1576, 0.1736, 0.1225], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,211][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0532, 0.2507, 0.1027, 0.5255, 0.0678], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,211][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.8432, 0.0385, 0.0431, 0.0315, 0.0344, 0.0094], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,211][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0305, 0.1151, 0.1482, 0.2741, 0.1786, 0.2534], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,212][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0328, 0.2195, 0.0577, 0.2083, 0.2987, 0.1830], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,213][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0104, 0.0811, 0.1329, 0.3328, 0.1368, 0.3060], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,216][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0117, 0.4289, 0.0600, 0.2841, 0.0143, 0.2010], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,220][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0978, 0.1660, 0.1200, 0.1830, 0.1750, 0.2582], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,223][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0253, 0.2316, 0.1282, 0.2545, 0.2433, 0.1171], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,225][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([3.4599e-04, 2.7691e-02, 4.9170e-02, 1.8377e-01, 5.9849e-01, 1.4053e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,227][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1686, 0.1910, 0.1073, 0.2355, 0.1099, 0.1876], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,227][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.8161, 0.0163, 0.0614, 0.0250, 0.0399, 0.0413], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,227][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.5077, 0.0254, 0.0919, 0.0890, 0.0625, 0.2235], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,228][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1932, 0.0662, 0.0722, 0.1956, 0.0676, 0.4052], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,228][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.4174, 0.0069, 0.0064, 0.0055, 0.0051, 0.0014, 0.5573],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,228][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0203, 0.0856, 0.1085, 0.1835, 0.1737, 0.2323, 0.1962],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,229][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0383, 0.1600, 0.0474, 0.1466, 0.2236, 0.1329, 0.2512],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,229][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0024, 0.0556, 0.0693, 0.2545, 0.0824, 0.2948, 0.2409],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,229][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0118, 0.3267, 0.0567, 0.2220, 0.0210, 0.2744, 0.0874],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,230][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0764, 0.1259, 0.0979, 0.1412, 0.1467, 0.2118, 0.2001],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,231][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0245, 0.2205, 0.0965, 0.2380, 0.1751, 0.0937, 0.1517],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,234][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0006, 0.0228, 0.0345, 0.1150, 0.4835, 0.0914, 0.2522],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,238][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.1327, 0.1719, 0.0958, 0.1994, 0.0862, 0.1571, 0.1569],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,242][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.7047, 0.0148, 0.0445, 0.0307, 0.0440, 0.0511, 0.1103],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,245][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.4493, 0.0156, 0.0551, 0.0550, 0.0444, 0.1264, 0.2542],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,245][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0903, 0.0274, 0.0276, 0.0926, 0.0243, 0.1923, 0.5455],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,245][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.4275, 0.0074, 0.0072, 0.0061, 0.0061, 0.0015, 0.5406, 0.0036],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,246][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0379, 0.0935, 0.0819, 0.1494, 0.1174, 0.1285, 0.2421, 0.1493],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,246][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0449, 0.1333, 0.0399, 0.1317, 0.2256, 0.1176, 0.1924, 0.1146],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,246][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.0072, 0.0220, 0.0763, 0.1413, 0.0658, 0.1735, 0.1698, 0.3441],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,247][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0020, 0.1359, 0.1073, 0.3003, 0.0145, 0.0698, 0.3510, 0.0191],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,247][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.0644, 0.1083, 0.0779, 0.1214, 0.1284, 0.1659, 0.1739, 0.1597],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,247][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0296, 0.1429, 0.0429, 0.1339, 0.0791, 0.0480, 0.0964, 0.4272],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,247][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([6.0749e-04, 3.2135e-03, 4.5901e-03, 1.8957e-02, 1.0648e-01, 8.7086e-03,
        3.9709e-02, 8.1774e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,249][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.1504, 0.1317, 0.0685, 0.1564, 0.0690, 0.1433, 0.1473, 0.1334],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,252][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([0.8043, 0.0091, 0.0173, 0.0155, 0.0167, 0.0205, 0.0468, 0.0698],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,256][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.4305, 0.0095, 0.0330, 0.0380, 0.0380, 0.0592, 0.1437, 0.2482],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,260][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.1582, 0.0076, 0.0130, 0.0355, 0.0149, 0.0621, 0.2316, 0.4770],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,262][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.4659, 0.0067, 0.0078, 0.0054, 0.0066, 0.0013, 0.4985, 0.0027, 0.0052],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,263][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0179, 0.0740, 0.0701, 0.1425, 0.0904, 0.1642, 0.1687, 0.1053, 0.1670],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,263][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0452, 0.1086, 0.0304, 0.1309, 0.1534, 0.0911, 0.1741, 0.1169, 0.1495],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,263][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0105, 0.0471, 0.0600, 0.1324, 0.0726, 0.2115, 0.1494, 0.2045, 0.1120],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,264][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0317, 0.1748, 0.1265, 0.1415, 0.1141, 0.1337, 0.1698, 0.0313, 0.0766],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,264][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.0469, 0.0952, 0.0688, 0.1031, 0.1083, 0.1523, 0.1611, 0.1415, 0.1227],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,264][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0160, 0.0947, 0.0335, 0.0926, 0.0577, 0.0369, 0.0730, 0.3528, 0.2428],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,265][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ of] are: tensor([1.6507e-04, 4.9669e-03, 6.9313e-03, 1.4231e-02, 7.8808e-02, 1.1330e-02,
        4.1111e-02, 7.7210e-01, 7.0360e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,265][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0999, 0.1262, 0.0715, 0.1474, 0.0665, 0.1202, 0.1254, 0.1045, 0.1385],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,265][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.7547, 0.0080, 0.0287, 0.0135, 0.0210, 0.0244, 0.0458, 0.0515, 0.0524],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,267][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ of] are: tensor([0.4168, 0.0093, 0.0357, 0.0341, 0.0267, 0.0651, 0.1379, 0.1705, 0.1039],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,270][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.1083, 0.0058, 0.0135, 0.0247, 0.0094, 0.0613, 0.1547, 0.4856, 0.1367],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,274][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.4072, 0.0111, 0.0072, 0.0068, 0.0054, 0.0015, 0.5425, 0.0047, 0.0062,
        0.0073], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,278][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0056, 0.0487, 0.0489, 0.0917, 0.0896, 0.1204, 0.1717, 0.1181, 0.1901,
        0.1152], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,280][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0301, 0.1102, 0.0316, 0.1268, 0.1901, 0.0834, 0.1353, 0.0852, 0.1214,
        0.0858], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,281][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.0129, 0.0192, 0.0417, 0.1096, 0.0413, 0.1252, 0.1561, 0.2149, 0.1363,
        0.1428], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,281][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0086, 0.0728, 0.0539, 0.1341, 0.0189, 0.1203, 0.4826, 0.0212, 0.0794,
        0.0080], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,281][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0486, 0.0864, 0.0602, 0.0934, 0.1037, 0.1311, 0.1347, 0.1234, 0.1178,
        0.1008], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,282][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0104, 0.0569, 0.0203, 0.0569, 0.0319, 0.0232, 0.0445, 0.1903, 0.1449,
        0.4207], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,282][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([2.1185e-04, 2.7401e-03, 3.7282e-03, 1.0606e-02, 6.7046e-02, 5.1056e-03,
        2.4140e-02, 4.1252e-01, 6.8270e-02, 4.0563e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,282][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.1129, 0.1222, 0.0519, 0.1298, 0.0514, 0.1189, 0.1149, 0.0930, 0.1307,
        0.0742], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,283][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([0.6541, 0.0047, 0.0140, 0.0099, 0.0155, 0.0208, 0.0431, 0.0670, 0.0597,
        0.1112], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,283][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.2813, 0.0068, 0.0240, 0.0296, 0.0282, 0.0611, 0.1272, 0.1360, 0.1114,
        0.1943], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,283][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0168, 0.0043, 0.0053, 0.0222, 0.0066, 0.0462, 0.2307, 0.3341, 0.1761,
        0.1578], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,285][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.2712, 0.0087, 0.0066, 0.0066, 0.0054, 0.0017, 0.6625, 0.0047, 0.0071,
        0.0079, 0.0176], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,287][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0099, 0.0569, 0.0508, 0.0926, 0.0927, 0.0924, 0.1608, 0.1357, 0.1419,
        0.1226, 0.0436], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,291][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0263, 0.1169, 0.0284, 0.1023, 0.1434, 0.0780, 0.1315, 0.0845, 0.1078,
        0.0863, 0.0946], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,295][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0058, 0.0368, 0.0355, 0.1036, 0.0566, 0.1231, 0.0797, 0.1463, 0.0762,
        0.2330, 0.1033], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,298][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0024, 0.7565, 0.0116, 0.0686, 0.0045, 0.0949, 0.0168, 0.0018, 0.0070,
        0.0025, 0.0334], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,298][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0312, 0.0760, 0.0477, 0.0717, 0.0721, 0.1221, 0.1248, 0.1075, 0.0936,
        0.0707, 0.1826], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,299][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ at] are: tensor([0.0055, 0.0701, 0.0221, 0.0647, 0.0278, 0.0200, 0.0360, 0.2047, 0.1296,
        0.3696, 0.0497], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,299][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0007, 0.0097, 0.0193, 0.0173, 0.1190, 0.0257, 0.0454, 0.3652, 0.0271,
        0.0896, 0.2809], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,300][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0624, 0.1183, 0.0597, 0.1249, 0.0534, 0.1107, 0.1047, 0.0883, 0.1175,
        0.0694, 0.0908], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,300][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ at] are: tensor([0.4819, 0.0094, 0.0170, 0.0160, 0.0143, 0.0342, 0.0760, 0.1002, 0.0812,
        0.1378, 0.0320], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,300][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.1932, 0.0103, 0.0218, 0.0274, 0.0163, 0.0689, 0.1480, 0.1583, 0.1064,
        0.1346, 0.1150], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,301][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0259, 0.0054, 0.0053, 0.0203, 0.0044, 0.0503, 0.1729, 0.3552, 0.1301,
        0.1472, 0.0830], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,301][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.2518, 0.0064, 0.0049, 0.0047, 0.0035, 0.0014, 0.3756, 0.0032, 0.0052,
        0.0050, 0.0131, 0.3251], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,303][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0099, 0.0467, 0.0496, 0.0826, 0.0835, 0.1031, 0.1157, 0.1379, 0.1336,
        0.1415, 0.0508, 0.0450], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,305][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0239, 0.0889, 0.0258, 0.0998, 0.1431, 0.0799, 0.1300, 0.0771, 0.1034,
        0.0774, 0.0851, 0.0656], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,309][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.0053, 0.0311, 0.0223, 0.0669, 0.0431, 0.0930, 0.0683, 0.1371, 0.0943,
        0.2184, 0.0996, 0.1206], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,313][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0149, 0.3342, 0.0392, 0.0635, 0.0085, 0.2238, 0.0290, 0.0028, 0.0112,
        0.0102, 0.0682, 0.1945], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,316][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0364, 0.0652, 0.0448, 0.0615, 0.0632, 0.1024, 0.1019, 0.0892, 0.0823,
        0.0603, 0.1603, 0.1325], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,316][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ the] are: tensor([0.0080, 0.0702, 0.0213, 0.0638, 0.0283, 0.0190, 0.0367, 0.1935, 0.1199,
        0.3574, 0.0475, 0.0344], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,317][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ the] are: tensor([6.7313e-04, 3.6228e-03, 6.2236e-03, 5.0972e-03, 3.8350e-02, 7.5093e-03,
        1.1365e-02, 7.7401e-02, 6.4329e-03, 2.4263e-02, 1.4411e-01, 6.7495e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,317][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0726, 0.1026, 0.0485, 0.1076, 0.0466, 0.0949, 0.0915, 0.0839, 0.1064,
        0.0648, 0.0854, 0.0953], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,317][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ the] are: tensor([0.3657, 0.0092, 0.0151, 0.0162, 0.0174, 0.0323, 0.0764, 0.0961, 0.1001,
        0.1696, 0.0370, 0.0648], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,318][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.2185, 0.0074, 0.0171, 0.0205, 0.0109, 0.0525, 0.1145, 0.1179, 0.0938,
        0.0938, 0.0876, 0.1655], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,318][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0155, 0.0045, 0.0037, 0.0143, 0.0031, 0.0402, 0.1616, 0.3611, 0.1242,
        0.1329, 0.0624, 0.0766], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,318][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.2111, 0.0085, 0.0057, 0.0059, 0.0034, 0.0012, 0.3695, 0.0027, 0.0056,
        0.0043, 0.0114, 0.3673, 0.0033], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,319][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0070, 0.0512, 0.0332, 0.0811, 0.0529, 0.0868, 0.1251, 0.0983, 0.1204,
        0.1144, 0.0448, 0.0608, 0.1239], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,321][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0324, 0.0824, 0.0269, 0.0828, 0.1467, 0.0718, 0.1006, 0.0676, 0.1076,
        0.0714, 0.0854, 0.0632, 0.0611], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,323][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.0028, 0.0133, 0.0167, 0.0654, 0.0202, 0.0713, 0.0669, 0.1585, 0.0770,
        0.1068, 0.0720, 0.0807, 0.2484], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,327][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0012, 0.1375, 0.0362, 0.0668, 0.0036, 0.0426, 0.0932, 0.0054, 0.0356,
        0.0096, 0.0674, 0.4883, 0.0125], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,331][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0379, 0.0589, 0.0347, 0.0537, 0.0570, 0.0914, 0.0958, 0.0751, 0.0715,
        0.0487, 0.1516, 0.1411, 0.0826], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,334][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ store] are: tensor([0.0086, 0.0528, 0.0187, 0.0478, 0.0262, 0.0175, 0.0341, 0.1545, 0.0982,
        0.2522, 0.0358, 0.0312, 0.2223], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,334][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ store] are: tensor([4.2009e-04, 5.6458e-04, 1.5558e-03, 1.1418e-03, 1.1867e-02, 1.2547e-03,
        2.4891e-03, 1.9673e-02, 2.7286e-03, 5.4115e-03, 2.9546e-02, 1.2924e-01,
        7.9411e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,335][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0828, 0.0915, 0.0395, 0.0941, 0.0390, 0.0861, 0.0897, 0.0725, 0.1009,
        0.0512, 0.0821, 0.0904, 0.0803], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,335][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ store] are: tensor([0.4182, 0.0098, 0.0172, 0.0153, 0.0145, 0.0246, 0.0611, 0.0737, 0.0757,
        0.1060, 0.0365, 0.0487, 0.0986], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,335][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.1545, 0.0052, 0.0145, 0.0155, 0.0092, 0.0370, 0.0856, 0.0810, 0.0732,
        0.0732, 0.0709, 0.1153, 0.2649], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,336][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0235, 0.0034, 0.0049, 0.0168, 0.0042, 0.0388, 0.2171, 0.2104, 0.1274,
        0.0763, 0.0822, 0.1124, 0.0827], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,336][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.2373, 0.0073, 0.0078, 0.0060, 0.0057, 0.0013, 0.3972, 0.0022, 0.0054,
        0.0043, 0.0111, 0.3096, 0.0027, 0.0020], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,336][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0041, 0.0389, 0.0332, 0.0579, 0.0549, 0.0858, 0.0954, 0.0786, 0.1045,
        0.1127, 0.0402, 0.0437, 0.1504, 0.0996], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,337][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0259, 0.0790, 0.0264, 0.0673, 0.1017, 0.0664, 0.1030, 0.0681, 0.0951,
        0.0608, 0.0777, 0.0625, 0.0543, 0.1117], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,339][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0003, 0.0096, 0.0068, 0.0410, 0.0141, 0.0523, 0.0415, 0.1103, 0.0656,
        0.1428, 0.0489, 0.0704, 0.3022, 0.0942], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,341][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [.] are: tensor([3.0471e-04, 5.3598e-02, 1.2938e-02, 1.2950e-02, 4.1570e-03, 2.1855e-02,
        5.3046e-02, 6.9780e-03, 1.5651e-02, 8.9066e-03, 9.5171e-02, 4.7129e-01,
        1.0551e-02, 2.3260e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,343][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0323, 0.0535, 0.0343, 0.0530, 0.0601, 0.0863, 0.0903, 0.0796, 0.0681,
        0.0528, 0.1401, 0.1313, 0.0752, 0.0432], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,348][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0063, 0.0445, 0.0147, 0.0376, 0.0246, 0.0145, 0.0251, 0.1515, 0.0867,
        0.2907, 0.0289, 0.0222, 0.2142, 0.0383], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,350][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [.] are: tensor([8.0383e-05, 3.8049e-04, 5.2429e-04, 5.2181e-04, 3.4460e-03, 5.0212e-04,
        8.4191e-04, 5.7407e-03, 8.6519e-04, 2.1624e-03, 3.4275e-02, 1.9376e-01,
        7.3971e-01, 1.7191e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,352][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0478, 0.0793, 0.0406, 0.0784, 0.0391, 0.0837, 0.0818, 0.0732, 0.0879,
        0.0549, 0.0732, 0.0871, 0.0903, 0.0828], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,352][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.5401, 0.0071, 0.0199, 0.0119, 0.0142, 0.0196, 0.0410, 0.0466, 0.0484,
        0.0900, 0.0254, 0.0376, 0.0507, 0.0474], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,353][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [.] are: tensor([0.1986, 0.0051, 0.0155, 0.0157, 0.0094, 0.0291, 0.0557, 0.0661, 0.0495,
        0.0596, 0.0423, 0.0802, 0.1884, 0.1848], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,353][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0444, 0.0029, 0.0055, 0.0123, 0.0049, 0.0336, 0.0995, 0.2054, 0.0803,
        0.1023, 0.0531, 0.0825, 0.1310, 0.1422], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,354][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.1714, 0.0122, 0.0060, 0.0070, 0.0054, 0.0018, 0.4501, 0.0026, 0.0066,
        0.0044, 0.0125, 0.3041, 0.0036, 0.0020, 0.0103], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,354][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0011, 0.0218, 0.0240, 0.0355, 0.0486, 0.0580, 0.0725, 0.1026, 0.0934,
        0.1107, 0.0374, 0.0417, 0.1728, 0.0787, 0.1010], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,354][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0240, 0.0821, 0.0185, 0.0667, 0.1364, 0.0531, 0.0788, 0.0595, 0.0838,
        0.0629, 0.0744, 0.0484, 0.0543, 0.0824, 0.0747], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,355][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0015, 0.0101, 0.0079, 0.0406, 0.0150, 0.0372, 0.0379, 0.0918, 0.0512,
        0.1177, 0.0590, 0.0799, 0.2636, 0.1052, 0.0814], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,355][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0048, 0.2810, 0.0105, 0.0674, 0.0038, 0.0218, 0.0370, 0.0015, 0.0091,
        0.0027, 0.0828, 0.3446, 0.0135, 0.1064, 0.0132], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,357][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.0343, 0.0548, 0.0348, 0.0522, 0.0528, 0.0805, 0.0766, 0.0603, 0.0651,
        0.0392, 0.1572, 0.1312, 0.0777, 0.0428, 0.0407], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,359][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0028, 0.0461, 0.0132, 0.0456, 0.0232, 0.0139, 0.0237, 0.1486, 0.0870,
        0.2993, 0.0272, 0.0197, 0.1939, 0.0379, 0.0178], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,362][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([4.6560e-04, 7.3546e-04, 1.0892e-03, 1.1951e-03, 8.5776e-03, 1.0998e-03,
        1.6292e-03, 9.9320e-03, 1.9833e-03, 3.7267e-03, 3.4840e-02, 1.5681e-01,
        6.3655e-01, 2.6065e-02, 1.1530e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,366][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.0265, 0.0870, 0.0332, 0.0888, 0.0342, 0.0900, 0.0821, 0.0682, 0.0900,
        0.0472, 0.0610, 0.0826, 0.0867, 0.0888, 0.0336], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,370][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.2644, 0.0106, 0.0183, 0.0188, 0.0204, 0.0345, 0.0519, 0.0859, 0.0757,
        0.1111, 0.0440, 0.0545, 0.0874, 0.0633, 0.0593], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,370][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.1017, 0.0098, 0.0192, 0.0178, 0.0134, 0.0389, 0.0515, 0.0471, 0.0378,
        0.0491, 0.0626, 0.0865, 0.2504, 0.1440, 0.0701], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,371][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0084, 0.0086, 0.0053, 0.0220, 0.0048, 0.0384, 0.1485, 0.1458, 0.1139,
        0.0484, 0.0823, 0.1306, 0.1089, 0.1192, 0.0150], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,371][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.1708, 0.0081, 0.0074, 0.0053, 0.0051, 0.0019, 0.4121, 0.0032, 0.0054,
        0.0061, 0.0127, 0.3402, 0.0038, 0.0023, 0.0083, 0.0074],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,372][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0059, 0.0311, 0.0298, 0.0519, 0.0479, 0.0788, 0.0967, 0.0768, 0.0947,
        0.0937, 0.0377, 0.0374, 0.1174, 0.0821, 0.0679, 0.0502],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,372][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0126, 0.0642, 0.0201, 0.0640, 0.1278, 0.0566, 0.0902, 0.0514, 0.0827,
        0.0544, 0.0748, 0.0585, 0.0428, 0.0828, 0.0733, 0.0436],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,372][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([0.0008, 0.0067, 0.0118, 0.0338, 0.0139, 0.0391, 0.0280, 0.0885, 0.0346,
        0.0685, 0.0329, 0.0419, 0.1602, 0.0491, 0.0495, 0.3408],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,373][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([1.6848e-03, 6.4645e-01, 4.1375e-03, 4.6153e-02, 1.2839e-03, 4.4011e-02,
        9.9859e-03, 4.8519e-04, 4.5724e-03, 1.3224e-03, 1.4579e-02, 1.5964e-01,
        7.6977e-03, 3.8072e-02, 2.2282e-03, 1.7694e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,373][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0262, 0.0522, 0.0328, 0.0435, 0.0461, 0.0818, 0.0817, 0.0712, 0.0625,
        0.0406, 0.1240, 0.1107, 0.0710, 0.0412, 0.0335, 0.0811],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,375][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([0.0027, 0.0321, 0.0128, 0.0344, 0.0205, 0.0143, 0.0228, 0.1306, 0.0759,
        0.2632, 0.0265, 0.0222, 0.1883, 0.0398, 0.0180, 0.0959],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,377][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([1.6438e-04, 6.9986e-04, 1.4019e-03, 1.0463e-03, 8.8023e-03, 1.4771e-03,
        2.1813e-03, 1.3783e-02, 1.4726e-03, 2.8314e-03, 1.7673e-02, 7.7138e-02,
        4.6962e-01, 8.8561e-03, 6.0381e-02, 3.3247e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,380][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0641, 0.0732, 0.0303, 0.0868, 0.0307, 0.0827, 0.0883, 0.0695, 0.1001,
        0.0409, 0.0600, 0.0727, 0.0585, 0.0695, 0.0250, 0.0476],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,384][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([0.4913, 0.0059, 0.0173, 0.0099, 0.0105, 0.0217, 0.0393, 0.0596, 0.0485,
        0.0700, 0.0192, 0.0262, 0.0604, 0.0428, 0.0327, 0.0446],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,388][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.1616, 0.0044, 0.0139, 0.0123, 0.0069, 0.0294, 0.0572, 0.0519, 0.0424,
        0.0431, 0.0365, 0.0567, 0.1748, 0.1312, 0.0335, 0.1442],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,389][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0176, 0.0030, 0.0049, 0.0130, 0.0046, 0.0355, 0.1302, 0.2758, 0.0828,
        0.0942, 0.0503, 0.0514, 0.0781, 0.1078, 0.0115, 0.0391],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,389][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2814, 0.0048, 0.0042, 0.0036, 0.0032, 0.0011, 0.3226, 0.0024, 0.0041,
        0.0036, 0.0104, 0.2314, 0.0024, 0.0017, 0.0077, 0.0044, 0.1111],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,389][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0030, 0.0294, 0.0268, 0.0402, 0.0517, 0.0560, 0.0587, 0.0858, 0.0843,
        0.0857, 0.0359, 0.0352, 0.1107, 0.0711, 0.1037, 0.0654, 0.0562],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,390][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0121, 0.0641, 0.0205, 0.0560, 0.0994, 0.0566, 0.0827, 0.0490, 0.0744,
        0.0499, 0.0788, 0.0603, 0.0410, 0.0953, 0.0758, 0.0476, 0.0362],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,390][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.2006e-04, 6.2255e-03, 4.3692e-03, 2.4956e-02, 1.2293e-02, 4.2518e-02,
        2.3126e-02, 8.0245e-02, 4.8974e-02, 1.3437e-01, 3.4878e-02, 5.5135e-02,
        1.8025e-01, 4.8020e-02, 4.6670e-02, 2.2362e-01, 3.4230e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,391][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0015, 0.3408, 0.0134, 0.0388, 0.0033, 0.0559, 0.0168, 0.0025, 0.0082,
        0.0042, 0.0305, 0.2726, 0.0132, 0.0425, 0.0082, 0.0361, 0.1115],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,391][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0248, 0.0441, 0.0317, 0.0429, 0.0481, 0.0777, 0.0744, 0.0732, 0.0629,
        0.0447, 0.1094, 0.0925, 0.0619, 0.0383, 0.0331, 0.0647, 0.0758],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,391][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0031, 0.0365, 0.0121, 0.0345, 0.0196, 0.0118, 0.0208, 0.1327, 0.0733,
        0.2754, 0.0251, 0.0189, 0.1679, 0.0371, 0.0176, 0.0810, 0.0326],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,393][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([9.1894e-05, 3.5239e-04, 7.9596e-04, 6.6431e-04, 6.5279e-03, 1.0594e-03,
        1.3780e-03, 1.4126e-02, 1.0985e-03, 3.6293e-03, 1.1476e-02, 5.2711e-02,
        5.1994e-01, 7.7572e-03, 5.4712e-02, 2.6696e-01, 5.6720e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,395][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0621, 0.0681, 0.0336, 0.0772, 0.0308, 0.0633, 0.0640, 0.0666, 0.0853,
        0.0502, 0.0585, 0.0622, 0.0668, 0.0680, 0.0309, 0.0515, 0.0609],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,398][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3386, 0.0046, 0.0098, 0.0109, 0.0095, 0.0179, 0.0462, 0.0660, 0.0694,
        0.1212, 0.0198, 0.0350, 0.0488, 0.0493, 0.0334, 0.0376, 0.0820],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,402][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1375, 0.0031, 0.0085, 0.0091, 0.0055, 0.0230, 0.0487, 0.0631, 0.0411,
        0.0494, 0.0269, 0.0494, 0.1255, 0.1358, 0.0388, 0.0903, 0.1442],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,407][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0141, 0.0023, 0.0026, 0.0093, 0.0032, 0.0263, 0.1009, 0.2690, 0.0755,
        0.1033, 0.0276, 0.0410, 0.0613, 0.1096, 0.0090, 0.0207, 0.1242],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,407][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.1734, 0.0080, 0.0056, 0.0044, 0.0043, 0.0012, 0.3058, 0.0028, 0.0043,
        0.0060, 0.0106, 0.3446, 0.0036, 0.0018, 0.0075, 0.0057, 0.1012, 0.0092],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,407][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.0013, 0.0217, 0.0191, 0.0309, 0.0366, 0.0438, 0.0706, 0.0879, 0.0719,
        0.0785, 0.0298, 0.0363, 0.0971, 0.0773, 0.0894, 0.0479, 0.0703, 0.0896],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,408][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0233, 0.0665, 0.0206, 0.0643, 0.1207, 0.0484, 0.0714, 0.0403, 0.0708,
        0.0495, 0.0679, 0.0501, 0.0377, 0.0792, 0.0765, 0.0392, 0.0248, 0.0489],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,408][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([1.3654e-04, 1.5960e-03, 3.4892e-03, 1.7390e-02, 4.9069e-03, 1.9988e-02,
        2.0305e-02, 6.5390e-02, 2.8900e-02, 3.9413e-02, 2.8938e-02, 4.5796e-02,
        1.1885e-01, 8.3265e-02, 3.6558e-02, 2.9621e-01, 1.0551e-01, 8.3355e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,409][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0003, 0.1627, 0.0157, 0.0454, 0.0031, 0.0151, 0.0628, 0.0036, 0.0158,
        0.0047, 0.0218, 0.2043, 0.0098, 0.0880, 0.0099, 0.0499, 0.2837, 0.0033],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,409][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0290, 0.0404, 0.0272, 0.0383, 0.0423, 0.0650, 0.0623, 0.0565, 0.0543,
        0.0380, 0.1117, 0.0982, 0.0617, 0.0363, 0.0361, 0.0710, 0.0776, 0.0542],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,409][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([0.0015, 0.0282, 0.0058, 0.0274, 0.0111, 0.0097, 0.0182, 0.0985, 0.0700,
        0.2259, 0.0240, 0.0194, 0.1717, 0.0359, 0.0111, 0.0851, 0.0340, 0.1225],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,410][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([5.3199e-05, 2.1183e-04, 3.7422e-04, 4.4966e-04, 4.2032e-03, 4.1143e-04,
        1.0127e-03, 8.2275e-03, 1.1873e-03, 2.5012e-03, 1.2081e-02, 6.3905e-02,
        3.4739e-01, 1.7239e-02, 8.0584e-02, 2.5164e-01, 7.0190e-02, 1.3834e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,412][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0298, 0.0636, 0.0322, 0.0645, 0.0285, 0.0649, 0.0730, 0.0663, 0.0729,
        0.0484, 0.0532, 0.0599, 0.0686, 0.0674, 0.0278, 0.0633, 0.0788, 0.0368],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,414][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([0.3457, 0.0060, 0.0127, 0.0115, 0.0091, 0.0159, 0.0381, 0.0454, 0.0444,
        0.0708, 0.0286, 0.0349, 0.0484, 0.0451, 0.0333, 0.0373, 0.0662, 0.1068],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,418][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.0569, 0.0026, 0.0068, 0.0082, 0.0053, 0.0179, 0.0307, 0.0408, 0.0287,
        0.0324, 0.0303, 0.0494, 0.1168, 0.1012, 0.0393, 0.1121, 0.1173, 0.2035],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,422][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0092, 0.0027, 0.0031, 0.0082, 0.0030, 0.0183, 0.0892, 0.1506, 0.0693,
        0.0864, 0.0564, 0.0563, 0.0556, 0.0998, 0.0108, 0.0359, 0.1726, 0.0727],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,425][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3107, 0.0037, 0.0041, 0.0033, 0.0031, 0.0010, 0.3027, 0.0021, 0.0038,
        0.0033, 0.0090, 0.2267, 0.0022, 0.0016, 0.0076, 0.0042, 0.0978, 0.0064,
        0.0067], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,425][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0031, 0.0196, 0.0169, 0.0360, 0.0334, 0.0462, 0.0613, 0.0522, 0.0738,
        0.0628, 0.0301, 0.0300, 0.1020, 0.0798, 0.0663, 0.0583, 0.0655, 0.0998,
        0.0632], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,426][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0161, 0.0582, 0.0193, 0.0534, 0.1010, 0.0482, 0.0682, 0.0420, 0.0633,
        0.0503, 0.0673, 0.0478, 0.0393, 0.0803, 0.0713, 0.0435, 0.0304, 0.0582,
        0.0420], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,426][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0003, 0.0067, 0.0045, 0.0326, 0.0120, 0.0439, 0.0190, 0.0699, 0.0248,
        0.0895, 0.0308, 0.0552, 0.1976, 0.0428, 0.0352, 0.1824, 0.0297, 0.0962,
        0.0272], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,427][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0016, 0.1542, 0.0351, 0.0171, 0.0048, 0.0433, 0.0296, 0.0010, 0.0017,
        0.0024, 0.0245, 0.2773, 0.0066, 0.0148, 0.0097, 0.0667, 0.2433, 0.0089,
        0.0575], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,427][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0264, 0.0394, 0.0259, 0.0356, 0.0393, 0.0651, 0.0628, 0.0576, 0.0505,
        0.0345, 0.0920, 0.0830, 0.0501, 0.0322, 0.0285, 0.0585, 0.0703, 0.0487,
        0.0994], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,427][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0022, 0.0314, 0.0054, 0.0289, 0.0110, 0.0083, 0.0169, 0.1049, 0.0657,
        0.2174, 0.0177, 0.0134, 0.1783, 0.0339, 0.0097, 0.0758, 0.0256, 0.1272,
        0.0263], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,428][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([6.3152e-05, 2.3222e-04, 5.1570e-04, 3.0613e-04, 3.1102e-03, 4.8212e-04,
        6.9989e-04, 5.6859e-03, 4.5672e-04, 1.1382e-03, 8.7190e-03, 4.1687e-02,
        3.6412e-01, 4.7271e-03, 3.4194e-02, 2.4425e-01, 5.0876e-02, 1.2207e-01,
        1.1666e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,430][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0422, 0.0600, 0.0314, 0.0712, 0.0302, 0.0616, 0.0595, 0.0549, 0.0755,
        0.0426, 0.0524, 0.0635, 0.0643, 0.0633, 0.0304, 0.0442, 0.0516, 0.0371,
        0.0641], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,432][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.3193, 0.0043, 0.0093, 0.0091, 0.0082, 0.0169, 0.0431, 0.0480, 0.0537,
        0.0809, 0.0156, 0.0306, 0.0374, 0.0402, 0.0254, 0.0287, 0.0631, 0.1306,
        0.0356], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,436][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1343, 0.0023, 0.0068, 0.0067, 0.0037, 0.0148, 0.0329, 0.0398, 0.0251,
        0.0278, 0.0201, 0.0356, 0.0886, 0.0984, 0.0239, 0.0697, 0.1091, 0.1720,
        0.0884], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,440][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0168, 0.0017, 0.0026, 0.0074, 0.0023, 0.0204, 0.0745, 0.2289, 0.0634,
        0.0813, 0.0263, 0.0339, 0.0638, 0.0837, 0.0071, 0.0200, 0.1141, 0.0915,
        0.0603], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,476][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:22,476][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,477][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,478][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,478][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,478][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,479][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,479][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,479][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,480][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,480][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,480][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,481][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,481][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9382, 0.0618], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,481][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0097, 0.9903], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,482][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.8949, 0.1051], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,482][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4679, 0.5321], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,482][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1041, 0.8959], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,483][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8740, 0.1260], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,483][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.6883, 0.3117], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,483][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.7000, 0.3000], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,484][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9666, 0.0334], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,484][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9455, 0.0545], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,484][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8107, 0.1893], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,485][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.4995, 0.5005], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,485][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.7322, 0.1708, 0.0970], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,485][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([0.0015, 0.9257, 0.0728], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,486][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.4984, 0.1833, 0.3184], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,486][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.1634, 0.6231, 0.2135], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,486][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.0623, 0.8005, 0.1372], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,487][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.6366, 0.1982, 0.1653], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,489][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.1943, 0.4021, 0.4035], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,490][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.1501, 0.4560, 0.3939], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,490][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.5666, 0.1660, 0.2674], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,490][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.6294, 0.1623, 0.2083], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,491][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.4565, 0.2320, 0.3115], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,494][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.0949, 0.6889, 0.2162], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,498][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8982, 0.0374, 0.0361, 0.0282], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,502][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0045, 0.3608, 0.0756, 0.5591], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,503][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6445, 0.0571, 0.1754, 0.1230], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,503][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2942, 0.2221, 0.1626, 0.3211], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,503][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0953, 0.1880, 0.0740, 0.6427], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,503][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7231, 0.0466, 0.1198, 0.1105], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,504][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.3438, 0.2394, 0.2048, 0.2120], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,504][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.3398, 0.0812, 0.2628, 0.3162], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,504][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9018, 0.0124, 0.0615, 0.0244], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,505][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.8080, 0.0459, 0.0900, 0.0561], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,505][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.6299, 0.0620, 0.1317, 0.1763], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,505][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.3763, 0.1261, 0.1029, 0.3947], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,509][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.7986, 0.0694, 0.0485, 0.0430, 0.0406], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,514][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0013, 0.5291, 0.0465, 0.3183, 0.1047], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,519][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.3797, 0.0696, 0.1548, 0.1809, 0.2150], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,519][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.1111, 0.2696, 0.1473, 0.3723, 0.0997], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,519][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.1083, 0.1864, 0.0730, 0.4818, 0.1504], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,519][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.7015, 0.0442, 0.0770, 0.1111, 0.0661], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,520][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.1051, 0.2630, 0.1922, 0.2587, 0.1809], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,520][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0905, 0.0915, 0.1817, 0.3377, 0.2987], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,520][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.5480, 0.0940, 0.1530, 0.1078, 0.0972], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,521][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.6958, 0.0490, 0.0857, 0.0767, 0.0928], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,521][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.4720, 0.0743, 0.1576, 0.1736, 0.1225], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,522][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0532, 0.2507, 0.1027, 0.5255, 0.0678], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,527][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.8432, 0.0385, 0.0431, 0.0315, 0.0344, 0.0094], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,533][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0047, 0.2725, 0.0616, 0.3881, 0.0728, 0.2003], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,535][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.3557, 0.0396, 0.1466, 0.1195, 0.1672, 0.1714], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,535][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1960, 0.1145, 0.1570, 0.1732, 0.1134, 0.2459], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,535][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0754, 0.0332, 0.0180, 0.1531, 0.0702, 0.6501], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,536][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.6922, 0.0076, 0.0341, 0.0342, 0.0375, 0.1943], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,536][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2534, 0.1583, 0.2420, 0.1055, 0.1503, 0.0905], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,536][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.2179, 0.0095, 0.0687, 0.0810, 0.1381, 0.4848], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,537][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.8611, 0.0072, 0.0499, 0.0147, 0.0331, 0.0340], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,537][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.8161, 0.0163, 0.0614, 0.0250, 0.0399, 0.0413], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,537][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.5077, 0.0254, 0.0919, 0.0890, 0.0625, 0.2235], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,538][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.1932, 0.0662, 0.0722, 0.1956, 0.0676, 0.4052], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,541][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4174, 0.0069, 0.0064, 0.0055, 0.0051, 0.0014, 0.5573],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,545][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0024, 0.1797, 0.0356, 0.2537, 0.0626, 0.1925, 0.2735],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,551][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.2842, 0.0293, 0.0915, 0.0963, 0.1330, 0.1360, 0.2297],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,552][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1199, 0.0889, 0.0840, 0.1497, 0.0793, 0.2007, 0.2775],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,552][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0603, 0.0069, 0.0067, 0.0585, 0.0381, 0.2084, 0.6211],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,552][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.6614, 0.0027, 0.0212, 0.0184, 0.0330, 0.1296, 0.1337],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,552][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3251, 0.0980, 0.1534, 0.0932, 0.0949, 0.0848, 0.1505],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,553][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0930, 0.0024, 0.0204, 0.0287, 0.0425, 0.1402, 0.6728],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,553][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.8783, 0.0049, 0.0300, 0.0130, 0.0257, 0.0266, 0.0216],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,553][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.7047, 0.0148, 0.0445, 0.0307, 0.0440, 0.0511, 0.1103],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,554][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.4493, 0.0156, 0.0551, 0.0550, 0.0444, 0.1264, 0.2542],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,554][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0903, 0.0274, 0.0276, 0.0926, 0.0243, 0.1923, 0.5455],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,554][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.4275, 0.0074, 0.0072, 0.0061, 0.0061, 0.0015, 0.5406, 0.0036],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,555][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0017, 0.1576, 0.0135, 0.1237, 0.0273, 0.0759, 0.3928, 0.2075],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,558][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.3748, 0.0233, 0.0547, 0.0760, 0.0930, 0.0945, 0.1535, 0.1303],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,562][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.1847, 0.0549, 0.0830, 0.1067, 0.0702, 0.1295, 0.1532, 0.2179],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,566][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([1.8093e-02, 7.6621e-04, 1.0060e-03, 7.2945e-03, 1.2047e-02, 2.2364e-02,
        8.8483e-02, 8.4995e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,568][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.5243, 0.0011, 0.0100, 0.0107, 0.0261, 0.0422, 0.0635, 0.3220],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,569][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.4030, 0.0661, 0.0916, 0.0700, 0.0658, 0.0452, 0.1202, 0.1379],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,569][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([2.9784e-02, 1.0083e-04, 2.0328e-03, 2.2729e-03, 7.5190e-03, 7.8063e-03,
        4.4152e-02, 9.0633e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,569][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.8754, 0.0022, 0.0137, 0.0054, 0.0150, 0.0088, 0.0111, 0.0684],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,570][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.8043, 0.0091, 0.0173, 0.0155, 0.0167, 0.0205, 0.0468, 0.0698],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,570][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.4305, 0.0095, 0.0330, 0.0380, 0.0380, 0.0592, 0.1437, 0.2482],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,570][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.1582, 0.0076, 0.0130, 0.0355, 0.0149, 0.0621, 0.2316, 0.4770],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,571][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.4659, 0.0067, 0.0078, 0.0054, 0.0066, 0.0013, 0.4985, 0.0027, 0.0052],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,574][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0017, 0.0768, 0.0167, 0.1113, 0.0219, 0.0916, 0.2278, 0.1642, 0.2880],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,578][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.3417, 0.0274, 0.0815, 0.0698, 0.0689, 0.0896, 0.1371, 0.1138, 0.0701],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,584][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.1933, 0.0504, 0.0802, 0.0958, 0.0502, 0.1171, 0.1293, 0.1817, 0.1021],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,584][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([2.1188e-02, 7.4099e-04, 1.3558e-03, 5.3207e-03, 6.0608e-03, 1.8251e-02,
        5.7124e-02, 8.0237e-01, 8.7591e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,585][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.3457, 0.0014, 0.0122, 0.0079, 0.0163, 0.0482, 0.0800, 0.3873, 0.1011],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,585][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.2813, 0.0644, 0.0910, 0.0556, 0.0558, 0.0545, 0.1282, 0.1765, 0.0927],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,585][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([2.2142e-02, 1.2188e-04, 2.4184e-03, 1.3430e-03, 4.2377e-03, 7.0721e-03,
        4.3020e-02, 8.0709e-01, 1.1255e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,586][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.8865, 0.0026, 0.0190, 0.0059, 0.0116, 0.0102, 0.0092, 0.0418, 0.0132],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,586][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.7547, 0.0080, 0.0287, 0.0135, 0.0210, 0.0244, 0.0458, 0.0515, 0.0524],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,586][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([0.4168, 0.0093, 0.0357, 0.0341, 0.0267, 0.0651, 0.1379, 0.1705, 0.1039],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,587][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.1083, 0.0058, 0.0135, 0.0247, 0.0094, 0.0613, 0.1547, 0.4856, 0.1367],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,587][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.4072, 0.0111, 0.0072, 0.0068, 0.0054, 0.0015, 0.5425, 0.0047, 0.0062,
        0.0073], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,587][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0005, 0.0761, 0.0089, 0.0806, 0.0159, 0.0714, 0.2276, 0.1437, 0.2844,
        0.0908], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,591][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.1433, 0.0278, 0.0456, 0.0741, 0.0580, 0.1050, 0.1795, 0.1502, 0.1050,
        0.1115], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,595][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.0583, 0.0390, 0.0514, 0.0656, 0.0527, 0.1193, 0.1511, 0.1767, 0.1314,
        0.1545], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,599][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([6.5998e-03, 3.5133e-04, 5.4100e-04, 4.4881e-03, 6.9110e-03, 9.0804e-03,
        4.5117e-02, 2.6811e-01, 8.0613e-02, 5.7819e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,601][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.4712, 0.0007, 0.0065, 0.0054, 0.0163, 0.0215, 0.0296, 0.1397, 0.0856,
        0.2233], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,602][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.1452, 0.0452, 0.0738, 0.0742, 0.0448, 0.0706, 0.1330, 0.1600, 0.1176,
        0.1355], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,602][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([4.9527e-03, 4.0762e-05, 6.7539e-04, 8.5002e-04, 3.6692e-03, 2.9025e-03,
        1.6981e-02, 2.1294e-01, 8.8377e-02, 6.6861e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,602][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.6732, 0.0043, 0.0163, 0.0099, 0.0159, 0.0183, 0.0205, 0.1100, 0.0436,
        0.0880], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,603][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.6541, 0.0047, 0.0140, 0.0099, 0.0155, 0.0208, 0.0431, 0.0670, 0.0597,
        0.1112], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,603][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.2813, 0.0068, 0.0240, 0.0296, 0.0282, 0.0611, 0.1272, 0.1360, 0.1114,
        0.1943], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,603][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0168, 0.0043, 0.0053, 0.0222, 0.0066, 0.0462, 0.2307, 0.3341, 0.1761,
        0.1578], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,604][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.2712, 0.0087, 0.0066, 0.0066, 0.0054, 0.0017, 0.6625, 0.0047, 0.0071,
        0.0079, 0.0176], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,604][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0006, 0.1102, 0.0123, 0.1088, 0.0276, 0.0488, 0.2023, 0.1265, 0.2240,
        0.0895, 0.0493], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,607][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0734, 0.0273, 0.0466, 0.0763, 0.0560, 0.0842, 0.1735, 0.1803, 0.0917,
        0.1116, 0.0791], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,612][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0712, 0.0441, 0.0408, 0.0712, 0.0268, 0.1014, 0.1420, 0.1756, 0.1302,
        0.1508, 0.0458], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,616][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([2.1277e-02, 5.8692e-04, 5.1220e-04, 1.6390e-03, 7.5344e-04, 1.8830e-02,
        5.7321e-02, 2.0935e-01, 4.2627e-02, 7.4281e-02, 5.7282e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,618][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.2602, 0.0008, 0.0037, 0.0023, 0.0024, 0.0316, 0.0342, 0.0724, 0.0367,
        0.0265, 0.5292], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,618][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([0.0517, 0.0582, 0.0475, 0.0621, 0.0430, 0.0498, 0.1267, 0.1948, 0.1447,
        0.0986, 0.1230], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,618][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([2.0078e-02, 6.3454e-05, 5.4635e-04, 2.3854e-04, 2.2225e-04, 5.4629e-03,
        1.8308e-02, 8.7387e-02, 2.4961e-02, 3.7557e-02, 8.0518e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,619][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.6893, 0.0032, 0.0133, 0.0066, 0.0094, 0.0185, 0.0168, 0.1296, 0.0271,
        0.0636, 0.0226], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,619][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.4819, 0.0094, 0.0170, 0.0160, 0.0143, 0.0342, 0.0760, 0.1002, 0.0812,
        0.1378, 0.0320], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,619][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.1932, 0.0103, 0.0218, 0.0274, 0.0163, 0.0689, 0.1480, 0.1583, 0.1064,
        0.1346, 0.1150], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,620][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([0.0259, 0.0054, 0.0053, 0.0203, 0.0044, 0.0503, 0.1729, 0.3552, 0.1301,
        0.1472, 0.0830], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,620][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.2518, 0.0064, 0.0049, 0.0047, 0.0035, 0.0014, 0.3756, 0.0032, 0.0052,
        0.0050, 0.0131, 0.3251], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,621][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0006, 0.0710, 0.0133, 0.0972, 0.0182, 0.0564, 0.1461, 0.1590, 0.2355,
        0.1004, 0.0512, 0.0512], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,622][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0956, 0.0215, 0.0456, 0.0734, 0.0628, 0.0819, 0.1576, 0.1645, 0.0870,
        0.0956, 0.0683, 0.0461], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,628][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.0578, 0.0303, 0.0332, 0.0578, 0.0299, 0.0894, 0.1343, 0.1960, 0.1292,
        0.1229, 0.0433, 0.0760], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,630][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([2.5471e-02, 3.5538e-04, 2.9392e-04, 1.0178e-03, 3.8098e-04, 1.0006e-02,
        2.2129e-02, 6.4750e-02, 1.9696e-02, 2.4773e-02, 3.4189e-01, 4.8924e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,634][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([3.3508e-01, 2.9569e-04, 1.7941e-03, 8.5861e-04, 8.2310e-04, 1.3367e-02,
        1.2009e-02, 2.4556e-02, 1.5457e-02, 8.5590e-03, 2.5739e-01, 3.2981e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,636][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([0.2112, 0.0452, 0.0805, 0.0564, 0.0418, 0.0317, 0.0877, 0.1153, 0.0907,
        0.0686, 0.1005, 0.0703], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,637][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([1.7440e-02, 3.4600e-05, 2.2430e-04, 1.1449e-04, 7.5394e-05, 1.8359e-03,
        4.8533e-03, 2.3951e-02, 1.2038e-02, 6.3729e-03, 3.7168e-01, 5.6138e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,637][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.6903, 0.0029, 0.0105, 0.0065, 0.0083, 0.0194, 0.0160, 0.1135, 0.0232,
        0.0718, 0.0223, 0.0152], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,637][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.3657, 0.0092, 0.0151, 0.0162, 0.0174, 0.0323, 0.0764, 0.0961, 0.1001,
        0.1696, 0.0370, 0.0648], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,638][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.2185, 0.0074, 0.0171, 0.0205, 0.0109, 0.0525, 0.1145, 0.1179, 0.0938,
        0.0938, 0.0876, 0.1655], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,638][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0155, 0.0045, 0.0037, 0.0143, 0.0031, 0.0402, 0.1616, 0.3611, 0.1242,
        0.1329, 0.0624, 0.0766], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:22,638][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.2111, 0.0085, 0.0057, 0.0059, 0.0034, 0.0012, 0.3695, 0.0027, 0.0056,
        0.0043, 0.0114, 0.3673, 0.0033], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,639][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0003, 0.1025, 0.0065, 0.0895, 0.0114, 0.0427, 0.1886, 0.0861, 0.2141,
        0.0693, 0.0445, 0.0959, 0.0486], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,639][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.1028, 0.0217, 0.0492, 0.0687, 0.0587, 0.0724, 0.1341, 0.1174, 0.0862,
        0.0841, 0.0578, 0.0488, 0.0979], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,642][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.0371, 0.0269, 0.0255, 0.0526, 0.0214, 0.0730, 0.1208, 0.1779, 0.1261,
        0.0979, 0.0517, 0.0798, 0.1094], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,645][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([8.2898e-03, 8.8648e-05, 1.1864e-04, 2.8863e-04, 1.5850e-04, 3.3625e-03,
        8.9972e-03, 1.8618e-02, 7.0184e-03, 6.8557e-03, 1.3491e-01, 2.8782e-01,
        5.2347e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,649][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([2.1912e-01, 1.6919e-04, 7.8874e-04, 4.7972e-04, 4.4092e-04, 4.9315e-03,
        5.4164e-03, 7.5875e-03, 7.1902e-03, 3.5211e-03, 1.0619e-01, 2.1945e-01,
        4.2471e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,653][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([0.0945, 0.0407, 0.0566, 0.0754, 0.0340, 0.0484, 0.1201, 0.0979, 0.1031,
        0.0628, 0.0849, 0.0798, 0.1019], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,653][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([8.4709e-03, 5.6325e-06, 7.6717e-05, 2.5588e-05, 3.3215e-05, 4.6940e-04,
        1.8025e-03, 4.4918e-03, 2.7688e-03, 1.6950e-03, 1.3599e-01, 2.6422e-01,
        5.7995e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,654][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.4522, 0.0048, 0.0142, 0.0102, 0.0116, 0.0297, 0.0344, 0.1046, 0.0453,
        0.0734, 0.0432, 0.0333, 0.1432], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,654][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.4182, 0.0098, 0.0172, 0.0153, 0.0145, 0.0246, 0.0611, 0.0737, 0.0757,
        0.1060, 0.0365, 0.0487, 0.0986], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,654][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.1545, 0.0052, 0.0145, 0.0155, 0.0092, 0.0370, 0.0856, 0.0810, 0.0732,
        0.0732, 0.0709, 0.1153, 0.2649], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,655][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([0.0235, 0.0034, 0.0049, 0.0168, 0.0042, 0.0388, 0.2171, 0.2104, 0.1274,
        0.0763, 0.0822, 0.1124, 0.0827], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:22,655][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.2373, 0.0073, 0.0078, 0.0060, 0.0057, 0.0013, 0.3972, 0.0022, 0.0054,
        0.0043, 0.0111, 0.3096, 0.0027, 0.0020], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,656][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0004, 0.0593, 0.0087, 0.0653, 0.0130, 0.0447, 0.1309, 0.0839, 0.2012,
        0.0920, 0.0443, 0.0689, 0.0712, 0.1162], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,660][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1356, 0.0236, 0.0604, 0.0737, 0.0630, 0.0754, 0.1130, 0.1170, 0.0715,
        0.0726, 0.0518, 0.0416, 0.0671, 0.0337], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,665][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0916, 0.0262, 0.0332, 0.0483, 0.0252, 0.0937, 0.0972, 0.1185, 0.1047,
        0.0961, 0.0332, 0.0579, 0.0787, 0.0953], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,669][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([8.5843e-03, 1.0482e-04, 2.1833e-04, 5.7606e-04, 5.6944e-04, 2.6616e-03,
        6.5270e-03, 3.7491e-02, 8.4510e-03, 2.3767e-02, 7.6729e-02, 1.5679e-01,
        5.4120e-01, 1.3633e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,669][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([1.7139e-01, 2.2567e-04, 1.7068e-03, 8.8790e-04, 1.3146e-03, 5.9456e-03,
        6.1664e-03, 1.9430e-02, 9.7684e-03, 1.1846e-02, 1.0026e-01, 1.8871e-01,
        3.8275e-01, 9.9592e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,669][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.1829, 0.0619, 0.0734, 0.0519, 0.0325, 0.0304, 0.0734, 0.0693, 0.0638,
        0.0482, 0.0747, 0.0696, 0.0806, 0.0875], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,670][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([5.5832e-03, 9.5313e-06, 1.5062e-04, 6.0036e-05, 1.1702e-04, 3.5795e-04,
        1.7470e-03, 1.2354e-02, 4.0190e-03, 1.0259e-02, 7.4195e-02, 1.7382e-01,
        6.3994e-01, 7.7390e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,670][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.7529, 0.0022, 0.0120, 0.0051, 0.0074, 0.0099, 0.0075, 0.0440, 0.0134,
        0.0303, 0.0127, 0.0102, 0.0673, 0.0252], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,671][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.5401, 0.0071, 0.0199, 0.0119, 0.0142, 0.0196, 0.0410, 0.0466, 0.0484,
        0.0900, 0.0254, 0.0376, 0.0507, 0.0474], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,671][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([0.1986, 0.0051, 0.0155, 0.0157, 0.0094, 0.0291, 0.0557, 0.0661, 0.0495,
        0.0596, 0.0423, 0.0802, 0.1884, 0.1848], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,671][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0444, 0.0029, 0.0055, 0.0123, 0.0049, 0.0336, 0.0995, 0.2054, 0.0803,
        0.1023, 0.0531, 0.0825, 0.1310, 0.1422], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:22,672][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.1714, 0.0122, 0.0060, 0.0070, 0.0054, 0.0018, 0.4501, 0.0026, 0.0066,
        0.0044, 0.0125, 0.3041, 0.0036, 0.0020, 0.0103], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,673][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([7.5774e-05, 6.2661e-02, 5.8169e-03, 4.9330e-02, 1.9800e-02, 4.0461e-02,
        1.2716e-01, 1.0245e-01, 1.9417e-01, 9.3867e-02, 4.1047e-02, 7.3094e-02,
        7.0806e-02, 8.9590e-02, 2.9660e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,677][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.0806, 0.0378, 0.0531, 0.0738, 0.0670, 0.0591, 0.1152, 0.0935, 0.0633,
        0.0817, 0.0715, 0.0462, 0.0922, 0.0289, 0.0361], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,683][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.0350, 0.0470, 0.0309, 0.0604, 0.0288, 0.0764, 0.0777, 0.1256, 0.0864,
        0.1146, 0.0393, 0.0614, 0.0852, 0.0922, 0.0390], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,685][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([4.6313e-03, 1.5565e-04, 1.5610e-04, 3.0467e-04, 1.1670e-04, 1.2228e-03,
        1.7355e-03, 2.0605e-03, 1.8685e-03, 1.6386e-03, 1.6071e-01, 2.6263e-01,
        4.8147e-01, 5.6701e-02, 2.4604e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,686][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.0888, 0.0004, 0.0013, 0.0007, 0.0005, 0.0040, 0.0022, 0.0016, 0.0043,
        0.0010, 0.2030, 0.2109, 0.3709, 0.0624, 0.0477], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,686][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.0395, 0.0943, 0.0503, 0.0672, 0.0454, 0.0377, 0.0702, 0.0887, 0.0764,
        0.0592, 0.0714, 0.0542, 0.1021, 0.0813, 0.0623], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,686][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([6.0403e-04, 1.4070e-05, 5.6192e-05, 2.6739e-05, 2.1302e-05, 1.7292e-04,
        3.2337e-04, 2.9709e-04, 6.3495e-04, 2.4664e-04, 1.4629e-01, 2.9015e-01,
        5.2508e-01, 2.0119e-02, 1.5961e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,687][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.3053, 0.0125, 0.0208, 0.0155, 0.0157, 0.0291, 0.0259, 0.1048, 0.0366,
        0.0407, 0.0416, 0.0381, 0.1645, 0.0818, 0.0670], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,687][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.2644, 0.0106, 0.0183, 0.0188, 0.0204, 0.0345, 0.0519, 0.0859, 0.0757,
        0.1111, 0.0440, 0.0545, 0.0874, 0.0633, 0.0593], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,688][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.1017, 0.0098, 0.0192, 0.0178, 0.0134, 0.0389, 0.0515, 0.0471, 0.0378,
        0.0491, 0.0626, 0.0865, 0.2504, 0.1440, 0.0701], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,691][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0084, 0.0086, 0.0053, 0.0220, 0.0048, 0.0384, 0.1485, 0.1458, 0.1139,
        0.0484, 0.0823, 0.1306, 0.1089, 0.1192, 0.0150], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:22,697][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.1708, 0.0081, 0.0074, 0.0053, 0.0051, 0.0019, 0.4121, 0.0032, 0.0054,
        0.0061, 0.0127, 0.3402, 0.0038, 0.0023, 0.0083, 0.0074],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,701][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0007, 0.0547, 0.0086, 0.0648, 0.0131, 0.0437, 0.1307, 0.0655, 0.1918,
        0.0852, 0.0492, 0.0582, 0.0681, 0.1212, 0.0201, 0.0246],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,702][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0759, 0.0230, 0.0466, 0.0597, 0.0550, 0.0667, 0.1276, 0.1195, 0.0641,
        0.0796, 0.0584, 0.0494, 0.0705, 0.0302, 0.0328, 0.0412],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,702][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([0.0736, 0.0242, 0.0392, 0.0493, 0.0367, 0.0659, 0.0876, 0.1222, 0.0851,
        0.0910, 0.0325, 0.0433, 0.0898, 0.0808, 0.0397, 0.0392],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,702][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([2.0618e-02, 8.1356e-05, 1.0681e-04, 1.5413e-04, 6.6167e-05, 2.4539e-03,
        5.1943e-03, 6.6125e-03, 2.7424e-03, 1.5585e-03, 3.2899e-02, 7.3262e-02,
        1.4748e-01, 5.4497e-02, 4.8540e-03, 6.4742e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,703][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([2.8794e-01, 1.3519e-04, 8.2463e-04, 2.0743e-04, 1.8800e-04, 3.5634e-03,
        2.9983e-03, 3.2965e-03, 2.0877e-03, 6.6012e-04, 2.5408e-02, 5.4792e-02,
        1.1030e-01, 3.2705e-02, 9.4497e-03, 4.6545e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,703][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([0.0942, 0.0569, 0.0619, 0.0620, 0.0347, 0.0385, 0.0764, 0.0965, 0.0652,
        0.0453, 0.0528, 0.0502, 0.0899, 0.0685, 0.0431, 0.0640],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,703][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([2.4727e-02, 7.3384e-06, 7.9818e-05, 1.5544e-05, 1.1647e-05, 4.0185e-04,
        9.1442e-04, 1.7739e-03, 8.3864e-04, 2.9903e-04, 2.6805e-02, 4.7651e-02,
        1.4766e-01, 2.7138e-02, 2.4749e-03, 7.1921e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,704][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.6670, 0.0023, 0.0117, 0.0037, 0.0061, 0.0137, 0.0114, 0.0580, 0.0137,
        0.0313, 0.0105, 0.0067, 0.0640, 0.0276, 0.0230, 0.0493],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,704][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([0.4913, 0.0059, 0.0173, 0.0099, 0.0105, 0.0217, 0.0393, 0.0596, 0.0485,
        0.0700, 0.0192, 0.0262, 0.0604, 0.0428, 0.0327, 0.0446],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,707][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.1616, 0.0044, 0.0139, 0.0123, 0.0069, 0.0294, 0.0572, 0.0519, 0.0424,
        0.0431, 0.0365, 0.0567, 0.1748, 0.1312, 0.0335, 0.1442],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,712][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([0.0176, 0.0030, 0.0049, 0.0130, 0.0046, 0.0355, 0.1302, 0.2758, 0.0828,
        0.0942, 0.0503, 0.0514, 0.0781, 0.1078, 0.0115, 0.0391],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:22,718][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2814, 0.0048, 0.0042, 0.0036, 0.0032, 0.0011, 0.3226, 0.0024, 0.0041,
        0.0036, 0.0104, 0.2314, 0.0024, 0.0017, 0.0077, 0.0044, 0.1111],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,718][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0003, 0.0651, 0.0124, 0.0662, 0.0219, 0.0453, 0.0833, 0.1262, 0.1834,
        0.0944, 0.0361, 0.0425, 0.0488, 0.0766, 0.0303, 0.0282, 0.0390],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,719][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0881, 0.0240, 0.0421, 0.0617, 0.0462, 0.0607, 0.1109, 0.1392, 0.0673,
        0.0760, 0.0583, 0.0383, 0.0582, 0.0296, 0.0258, 0.0394, 0.0344],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,719][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0472, 0.0221, 0.0234, 0.0401, 0.0282, 0.0643, 0.0910, 0.1448, 0.1033,
        0.1127, 0.0240, 0.0446, 0.0587, 0.0852, 0.0357, 0.0198, 0.0549],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,719][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([1.2710e-02, 2.2737e-05, 4.1127e-05, 9.2075e-05, 3.8523e-05, 1.1562e-03,
        2.1494e-03, 9.5683e-03, 2.0701e-03, 2.8417e-03, 1.5115e-02, 2.6112e-02,
        9.7392e-02, 3.8051e-02, 4.2301e-03, 3.1617e-01, 4.7224e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,720][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([2.0557e-01, 4.4770e-05, 5.4572e-04, 1.6043e-04, 2.1425e-04, 2.8046e-03,
        1.8182e-03, 5.7437e-03, 2.8219e-03, 1.5274e-03, 2.1337e-02, 2.7686e-02,
        9.6905e-02, 3.7862e-02, 1.4007e-02, 3.9293e-01, 1.8802e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,720][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1388, 0.0384, 0.0634, 0.0409, 0.0352, 0.0262, 0.0501, 0.0994, 0.0603,
        0.0553, 0.0556, 0.0451, 0.0681, 0.0645, 0.0601, 0.0477, 0.0509],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,721][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([9.0565e-03, 2.8821e-06, 3.5769e-05, 1.1525e-05, 7.9526e-06, 1.9406e-04,
        4.7040e-04, 3.4440e-03, 1.1730e-03, 7.3305e-04, 1.5093e-02, 2.0262e-02,
        1.0566e-01, 2.0292e-02, 2.7404e-03, 3.0599e-01, 5.1483e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,727][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.7089, 0.0011, 0.0059, 0.0028, 0.0049, 0.0090, 0.0074, 0.0672, 0.0121,
        0.0385, 0.0079, 0.0053, 0.0443, 0.0221, 0.0227, 0.0263, 0.0136],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,732][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3386, 0.0046, 0.0098, 0.0109, 0.0095, 0.0179, 0.0462, 0.0660, 0.0694,
        0.1212, 0.0198, 0.0350, 0.0488, 0.0493, 0.0334, 0.0376, 0.0820],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,733][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1375, 0.0031, 0.0085, 0.0091, 0.0055, 0.0230, 0.0487, 0.0631, 0.0411,
        0.0494, 0.0269, 0.0494, 0.1255, 0.1358, 0.0388, 0.0903, 0.1442],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,734][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0141, 0.0023, 0.0026, 0.0093, 0.0032, 0.0263, 0.1009, 0.2690, 0.0755,
        0.1033, 0.0276, 0.0410, 0.0613, 0.1096, 0.0090, 0.0207, 0.1242],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:22,734][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.1734, 0.0080, 0.0056, 0.0044, 0.0043, 0.0012, 0.3058, 0.0028, 0.0043,
        0.0060, 0.0106, 0.3446, 0.0036, 0.0018, 0.0075, 0.0057, 0.1012, 0.0092],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,735][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([8.9384e-05, 4.8078e-02, 4.8263e-03, 4.1436e-02, 1.2042e-02, 3.3065e-02,
        1.1240e-01, 1.0114e-01, 1.6738e-01, 7.9516e-02, 3.9132e-02, 6.4071e-02,
        4.6671e-02, 1.0156e-01, 2.2141e-02, 1.9600e-02, 7.0936e-02, 3.5914e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,735][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.0750, 0.0228, 0.0366, 0.0565, 0.0434, 0.0458, 0.1217, 0.0912, 0.0625,
        0.0736, 0.0512, 0.0504, 0.0653, 0.0319, 0.0323, 0.0382, 0.0459, 0.0554],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,735][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.0479, 0.0290, 0.0260, 0.0466, 0.0232, 0.0563, 0.0683, 0.1173, 0.0614,
        0.0903, 0.0286, 0.0431, 0.0641, 0.0834, 0.0325, 0.0229, 0.0486, 0.1105],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,736][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([2.7475e-03, 1.8102e-05, 2.4759e-05, 6.6278e-05, 3.5922e-05, 4.3290e-04,
        9.2610e-04, 2.4941e-03, 7.5648e-04, 1.2049e-03, 1.5786e-02, 2.5803e-02,
        7.9513e-02, 2.1477e-02, 5.7945e-03, 3.1689e-01, 4.1525e-01, 1.1078e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,736][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([9.2573e-02, 3.9739e-05, 3.3691e-04, 1.0937e-04, 1.5068e-04, 1.0280e-03,
        7.5161e-04, 1.1151e-03, 1.0359e-03, 5.5903e-04, 1.9312e-02, 3.2605e-02,
        7.6120e-02, 1.8363e-02, 1.6125e-02, 3.8594e-01, 1.5496e-01, 1.9888e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,739][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([0.0689, 0.0472, 0.0325, 0.0479, 0.0213, 0.0302, 0.0457, 0.0842, 0.0523,
        0.0410, 0.0563, 0.0406, 0.0726, 0.0632, 0.0351, 0.0527, 0.0516, 0.1569],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,742][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([9.1995e-04, 1.0884e-06, 8.7919e-06, 3.3950e-06, 4.2903e-06, 3.7324e-05,
        1.3850e-04, 3.8033e-04, 2.3370e-04, 1.7899e-04, 1.2129e-02, 2.0984e-02,
        6.0441e-02, 7.7687e-03, 3.0558e-03, 3.2283e-01, 4.1162e-01, 1.5926e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,747][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.3774, 0.0021, 0.0082, 0.0039, 0.0057, 0.0084, 0.0106, 0.0582, 0.0146,
        0.0330, 0.0119, 0.0135, 0.0949, 0.0276, 0.0348, 0.0516, 0.0324, 0.2110],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,749][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.3457, 0.0060, 0.0127, 0.0115, 0.0091, 0.0159, 0.0381, 0.0454, 0.0444,
        0.0708, 0.0286, 0.0349, 0.0484, 0.0451, 0.0333, 0.0373, 0.0662, 0.1068],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,750][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.0569, 0.0026, 0.0068, 0.0082, 0.0053, 0.0179, 0.0307, 0.0408, 0.0287,
        0.0324, 0.0303, 0.0494, 0.1168, 0.1012, 0.0393, 0.1121, 0.1173, 0.2035],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,750][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([0.0092, 0.0027, 0.0031, 0.0082, 0.0030, 0.0183, 0.0892, 0.1506, 0.0693,
        0.0864, 0.0564, 0.0563, 0.0556, 0.0998, 0.0108, 0.0359, 0.1726, 0.0727],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:22,751][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3107, 0.0037, 0.0041, 0.0033, 0.0031, 0.0010, 0.3027, 0.0021, 0.0038,
        0.0033, 0.0090, 0.2267, 0.0022, 0.0016, 0.0076, 0.0042, 0.0978, 0.0064,
        0.0067], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,751][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0002, 0.0364, 0.0073, 0.0623, 0.0125, 0.0382, 0.0982, 0.0673, 0.1665,
        0.0701, 0.0419, 0.0449, 0.0609, 0.0950, 0.0180, 0.0285, 0.0611, 0.0421,
        0.0486], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,752][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0688, 0.0197, 0.0413, 0.0582, 0.0585, 0.0463, 0.1073, 0.1141, 0.0623,
        0.0662, 0.0545, 0.0362, 0.0465, 0.0279, 0.0292, 0.0322, 0.0314, 0.0617,
        0.0378], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,752][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0727, 0.0174, 0.0261, 0.0386, 0.0199, 0.0608, 0.0624, 0.1384, 0.0648,
        0.0834, 0.0233, 0.0343, 0.0565, 0.0764, 0.0261, 0.0205, 0.0441, 0.1013,
        0.0330], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,755][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([9.4351e-03, 8.6740e-06, 1.9786e-05, 2.4865e-05, 1.3985e-05, 2.8560e-04,
        7.2519e-04, 1.8546e-03, 4.1841e-04, 4.4933e-04, 7.6406e-03, 1.0804e-02,
        5.1005e-02, 1.5344e-02, 1.6360e-03, 2.5433e-01, 3.4805e-01, 9.6596e-02,
        2.0135e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,757][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([7.2519e-02, 1.6174e-05, 2.0407e-04, 4.8855e-05, 7.4408e-05, 1.0438e-03,
        7.3764e-04, 1.4328e-03, 6.6017e-04, 3.3123e-04, 1.0123e-02, 1.8429e-02,
        4.2174e-02, 1.3881e-02, 5.8902e-03, 2.5447e-01, 1.4154e-01, 1.9482e-01,
        2.4162e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,763][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0905, 0.0369, 0.0306, 0.0340, 0.0218, 0.0176, 0.0422, 0.0830, 0.0539,
        0.0315, 0.0432, 0.0378, 0.0725, 0.0608, 0.0471, 0.0516, 0.0496, 0.1470,
        0.0486], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,765][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([4.7384e-03, 5.7795e-07, 1.0562e-05, 1.5633e-06, 1.3679e-06, 3.4481e-05,
        1.1356e-04, 3.1191e-04, 1.2144e-04, 5.6428e-05, 4.2426e-03, 8.2199e-03,
        3.3782e-02, 5.2249e-03, 6.6235e-04, 1.5139e-01, 2.8896e-01, 1.9841e-01,
        3.0372e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,765][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.6733, 0.0007, 0.0051, 0.0017, 0.0030, 0.0055, 0.0049, 0.0356, 0.0072,
        0.0195, 0.0056, 0.0039, 0.0376, 0.0171, 0.0172, 0.0231, 0.0138, 0.1194,
        0.0057], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,766][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.3193, 0.0043, 0.0093, 0.0091, 0.0082, 0.0169, 0.0431, 0.0480, 0.0537,
        0.0809, 0.0156, 0.0306, 0.0374, 0.0402, 0.0254, 0.0287, 0.0631, 0.1306,
        0.0356], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,766][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1343, 0.0023, 0.0068, 0.0067, 0.0037, 0.0148, 0.0329, 0.0398, 0.0251,
        0.0278, 0.0201, 0.0356, 0.0886, 0.0984, 0.0239, 0.0697, 0.1091, 0.1720,
        0.0884], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,767][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0168, 0.0017, 0.0026, 0.0074, 0.0023, 0.0204, 0.0745, 0.2289, 0.0634,
        0.0813, 0.0263, 0.0339, 0.0638, 0.0837, 0.0071, 0.0200, 0.1141, 0.0915,
        0.0603], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:22,768][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:22,769][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[4039],
        [4460],
        [3970],
        [ 508],
        [ 208],
        [  59],
        [  56],
        [ 106],
        [ 220],
        [ 261],
        [  36],
        [ 111],
        [  43],
        [ 106],
        [ 347],
        [ 168],
        [ 110],
        [  38],
        [ 118]], device='cuda:0')
[2024-07-24 10:27:22,770][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[ 5647],
        [12416],
        [15618],
        [ 1893],
        [ 1097],
        [  294],
        [  364],
        [  389],
        [ 1262],
        [ 1250],
        [  260],
        [  647],
        [  266],
        [  554],
        [ 1659],
        [  796],
        [  572],
        [  227],
        [  611]], device='cuda:0')
[2024-07-24 10:27:22,773][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[15267],
        [17326],
        [23148],
        [18948],
        [23283],
        [22296],
        [31613],
        [31541],
        [31126],
        [31703],
        [32913],
        [26173],
        [25869],
        [26761],
        [27774],
        [27224],
        [25390],
        [25062],
        [25342]], device='cuda:0')
[2024-07-24 10:27:22,775][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[34692],
        [38409],
        [49407],
        [47899],
        [47464],
        [46499],
        [45824],
        [45350],
        [44653],
        [43839],
        [43689],
        [43670],
        [44489],
        [44897],
        [44880],
        [44288],
        [44210],
        [44741],
        [44710]], device='cuda:0')
[2024-07-24 10:27:22,778][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[1542],
        [ 178],
        [ 218],
        [ 235],
        [ 234],
        [ 247],
        [ 187],
        [ 193],
        [ 163],
        [ 179],
        [ 155],
        [ 151],
        [ 154],
        [ 146],
        [ 155],
        [ 152],
        [ 143],
        [ 152],
        [ 147]], device='cuda:0')
[2024-07-24 10:27:22,781][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[29937],
        [15744],
        [15772],
        [23935],
        [23942],
        [22914],
        [21296],
        [21300],
        [20641],
        [20056],
        [20154],
        [19839],
        [21727],
        [21752],
        [21905],
        [19422],
        [19674],
        [19342],
        [20912]], device='cuda:0')
[2024-07-24 10:27:22,783][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[24879],
        [ 6997],
        [ 7313],
        [ 8094],
        [ 9114],
        [10376],
        [10188],
        [10033],
        [ 7707],
        [ 8353],
        [ 7212],
        [ 9146],
        [10750],
        [10738],
        [ 8838],
        [ 7872],
        [ 8194],
        [ 7911],
        [ 7823]], device='cuda:0')
[2024-07-24 10:27:22,786][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 6176],
        [ 5195],
        [ 7064],
        [ 8941],
        [ 9486],
        [ 9375],
        [ 9317],
        [ 9119],
        [ 9596],
        [ 9590],
        [10192],
        [10184],
        [10168],
        [10157],
        [10364],
        [10075],
        [10134],
        [ 9695],
        [ 9438]], device='cuda:0')
[2024-07-24 10:27:22,787][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[2260],
        [ 775],
        [1039],
        [ 891],
        [1048],
        [1178],
        [1235],
        [ 991],
        [ 988],
        [ 649],
        [ 677],
        [ 686],
        [ 700],
        [ 687],
        [ 687],
        [ 746],
        [ 756],
        [ 867],
        [ 882]], device='cuda:0')
[2024-07-24 10:27:22,788][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[28217],
        [15647],
        [18940],
        [17714],
        [22260],
        [21211],
        [19321],
        [13348],
        [12938],
        [14151],
        [13892],
        [14496],
        [15324],
        [15273],
        [15743],
        [15264],
        [15226],
        [14793],
        [14643]], device='cuda:0')
[2024-07-24 10:27:22,789][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[6554],
        [2014],
        [ 258],
        [ 269],
        [ 186],
        [ 182],
        [ 147],
        [ 293],
        [ 307],
        [ 385],
        [ 324],
        [ 338],
        [ 422],
        [ 395],
        [ 354],
        [ 266],
        [ 223],
        [ 225],
        [ 290]], device='cuda:0')
[2024-07-24 10:27:22,790][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[15413],
        [11240],
        [ 4929],
        [ 5262],
        [ 2771],
        [ 4315],
        [ 2910],
        [ 6579],
        [ 4505],
        [ 4152],
        [ 4185],
        [ 3837],
        [ 4799],
        [ 4612],
        [ 4547],
        [ 4977],
        [ 4859],
        [ 4368],
        [ 4195]], device='cuda:0')
[2024-07-24 10:27:22,793][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[43591],
        [49527],
        [40549],
        [45694],
        [45435],
        [46469],
        [44930],
        [49285],
        [48743],
        [49399],
        [49105],
        [49243],
        [49765],
        [49602],
        [49742],
        [49469],
        [49215],
        [49688],
        [49590]], device='cuda:0')
[2024-07-24 10:27:22,795][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[14161],
        [28011],
        [49171],
        [48663],
        [47328],
        [47515],
        [45853],
        [44543],
        [43986],
        [42301],
        [42483],
        [42133],
        [41057],
        [40578],
        [41154],
        [41839],
        [41554],
        [41317],
        [42351]], device='cuda:0')
[2024-07-24 10:27:22,798][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[1095],
        [2647],
        [  16],
        [8966],
        [ 806],
        [4683],
        [7770],
        [4726],
        [1023],
        [1725],
        [1258],
        [7054],
        [3222],
        [ 704],
        [ 625],
        [2515],
        [6451],
        [1050],
        [1618]], device='cuda:0')
[2024-07-24 10:27:22,800][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[29107],
        [16587],
        [ 5856],
        [13301],
        [ 9684],
        [11231],
        [13248],
        [13115],
        [12999],
        [12903],
        [12655],
        [10918],
        [10365],
        [11099],
        [11251],
        [10780],
        [11752],
        [10013],
        [11477]], device='cuda:0')
[2024-07-24 10:27:22,803][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 1485],
        [12920],
        [10714],
        [13976],
        [12597],
        [12244],
        [ 6593],
        [ 5035],
        [ 5036],
        [ 4626],
        [ 5010],
        [ 5399],
        [ 5104],
        [ 5358],
        [ 5445],
        [ 5306],
        [ 5843],
        [ 5056],
        [ 5156]], device='cuda:0')
[2024-07-24 10:27:22,806][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[36606],
        [39950],
        [43092],
        [43407],
        [43883],
        [42448],
        [42161],
        [42437],
        [42429],
        [40412],
        [40858],
        [41121],
        [40833],
        [41060],
        [40914],
        [40359],
        [40389],
        [40710],
        [40874]], device='cuda:0')
[2024-07-24 10:27:22,807][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 9010],
        [22391],
        [23024],
        [19577],
        [18898],
        [13354],
        [13003],
        [13348],
        [12774],
        [14294],
        [13945],
        [12778],
        [11504],
        [11392],
        [11868],
        [11599],
        [11635],
        [11510],
        [11461]], device='cuda:0')
[2024-07-24 10:27:22,808][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[35339],
        [17954],
        [18795],
        [24843],
        [25483],
        [ 8799],
        [14805],
        [10759],
        [10441],
        [ 5111],
        [10048],
        [ 8502],
        [ 7539],
        [ 6958],
        [ 7715],
        [ 6122],
        [ 9316],
        [ 8720],
        [11046]], device='cuda:0')
[2024-07-24 10:27:22,809][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[36294],
        [31324],
        [24848],
        [27742],
        [27851],
        [27514],
        [25291],
        [24620],
        [21432],
        [23605],
        [23817],
        [23286],
        [20581],
        [19331],
        [19588],
        [18356],
        [15364],
        [15413],
        [15295]], device='cuda:0')
[2024-07-24 10:27:22,810][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[28878],
        [20548],
        [21907],
        [21491],
        [22523],
        [21091],
        [20727],
        [24767],
        [26298],
        [29580],
        [28540],
        [26649],
        [26833],
        [25015],
        [26277],
        [25836],
        [25362],
        [26873],
        [25930]], device='cuda:0')
[2024-07-24 10:27:22,813][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 2102],
        [ 5147],
        [ 7139],
        [14675],
        [12576],
        [24299],
        [30518],
        [20474],
        [21295],
        [28392],
        [35199],
        [34751],
        [30840],
        [28452],
        [30719],
        [29816],
        [26824],
        [28183],
        [24967]], device='cuda:0')
[2024-07-24 10:27:22,815][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 8303],
        [ 7237],
        [14152],
        [ 5146],
        [17633],
        [ 5776],
        [ 6220],
        [10239],
        [ 8336],
        [15920],
        [16066],
        [15714],
        [17387],
        [13344],
        [18989],
        [15131],
        [14371],
        [19495],
        [15565]], device='cuda:0')
[2024-07-24 10:27:22,818][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[21563],
        [20943],
        [ 5895],
        [14235],
        [10207],
        [12214],
        [15947],
        [16216],
        [15684],
        [ 9065],
        [ 9108],
        [10013],
        [16756],
        [14243],
        [13982],
        [13184],
        [11151],
        [12690],
        [12296]], device='cuda:0')
[2024-07-24 10:27:22,820][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[3430],
        [ 429],
        [1457],
        [3481],
        [3259],
        [3452],
        [6033],
        [3463],
        [4483],
        [3476],
        [4367],
        [5361],
        [3557],
        [4086],
        [2901],
        [3304],
        [4442],
        [2780],
        [3599]], device='cuda:0')
[2024-07-24 10:27:22,823][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[17853],
        [16322],
        [12656],
        [ 5381],
        [ 5863],
        [ 7445],
        [ 6182],
        [ 4211],
        [ 3451],
        [ 2620],
        [ 2723],
        [ 2753],
        [ 2481],
        [ 2336],
        [ 2363],
        [ 2132],
        [ 2132],
        [ 2311],
        [ 2427]], device='cuda:0')
[2024-07-24 10:27:22,826][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[35834],
        [41322],
        [42393],
        [36463],
        [35629],
        [39987],
        [35341],
        [40198],
        [41213],
        [40870],
        [36900],
        [37540],
        [39179],
        [41104],
        [39679],
        [41809],
        [41967],
        [41297],
        [41949]], device='cuda:0')
[2024-07-24 10:27:22,827][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[49272],
        [37561],
        [49341],
        [32658],
        [46668],
        [43689],
        [41262],
        [44267],
        [47894],
        [48665],
        [47018],
        [39550],
        [45763],
        [49162],
        [48698],
        [46876],
        [43989],
        [48878],
        [47844]], device='cuda:0')
[2024-07-24 10:27:22,827][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473],
        [3473]], device='cuda:0')
[2024-07-24 10:27:22,872][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:22,873][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,874][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,874][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,874][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,875][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,875][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,875][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,876][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,877][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,877][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,877][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,877][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:22,878][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3760, 0.6240], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,878][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0049, 0.9951], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,878][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6203, 0.3797], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,879][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.8823, 0.1177], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,879][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0369, 0.9631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,879][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4757, 0.5243], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,885][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,885][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0404, 0.9596], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,885][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.6553, 0.3447], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,886][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([2.0772e-05, 9.9998e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,886][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2159, 0.7841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,886][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0026, 0.9974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:22,887][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.0330, 0.8397, 0.1273], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,887][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([3.3972e-04, 9.5610e-01, 4.3558e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,887][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.2750, 0.4153, 0.3098], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,888][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.4723, 0.4499, 0.0777], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,888][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.0302, 0.7542, 0.2155], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,888][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([0.1450, 0.2807, 0.5743], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,889][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([3.3205e-04, 9.4306e-01, 5.6608e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,889][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.0097, 0.9645, 0.0258], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,889][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.1245, 0.6179, 0.2576], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,890][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([1.4338e-05, 9.6244e-01, 3.7542e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,890][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.0184, 0.9296, 0.0520], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,890][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([6.6078e-04, 9.3969e-01, 5.9652e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:22,891][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4390, 0.2077, 0.0969, 0.2564], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,891][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0063, 0.6766, 0.0597, 0.2574], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,891][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7753, 0.0502, 0.0900, 0.0844], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,892][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.6030, 0.0680, 0.0991, 0.2299], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,892][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0671, 0.5256, 0.1933, 0.2140], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,892][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3831, 0.1257, 0.4360, 0.0552], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,893][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0025, 0.4860, 0.1103, 0.4013], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,893][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1988, 0.3390, 0.0616, 0.4005], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,898][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.2623, 0.1260, 0.1474, 0.4643], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,900][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([6.6264e-05, 7.4974e-01, 3.8454e-02, 2.1174e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,902][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2158, 0.2137, 0.0744, 0.4962], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,902][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0017, 0.2638, 0.0763, 0.6582], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:22,902][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0589, 0.4436, 0.1140, 0.3158, 0.0677], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,903][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.0014, 0.7298, 0.0406, 0.2008, 0.0275], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,903][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.3885, 0.1209, 0.1931, 0.1703, 0.1271], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,903][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.3691, 0.1655, 0.0472, 0.3575, 0.0607], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,903][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0202, 0.3390, 0.2125, 0.1271, 0.3012], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,904][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.2062, 0.1150, 0.3680, 0.0627, 0.2481], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,904][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([4.3542e-04, 4.9372e-01, 4.1580e-02, 2.6153e-01, 2.0273e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,904][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0403, 0.6297, 0.0342, 0.2789, 0.0169], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,905][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.0524, 0.1675, 0.0888, 0.4160, 0.2753], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,908][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([3.7778e-05, 2.7644e-01, 1.7297e-02, 1.5278e-01, 5.5345e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,914][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0538, 0.3824, 0.0454, 0.4225, 0.0960], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,918][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0006, 0.4527, 0.0350, 0.4175, 0.0942], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:22,918][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1236, 0.3217, 0.0988, 0.2118, 0.0521, 0.1921], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,918][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0047, 0.6355, 0.0456, 0.2220, 0.0261, 0.0661], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,919][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4377, 0.0885, 0.1713, 0.1003, 0.0842, 0.1181], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,919][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.5957, 0.0030, 0.0128, 0.0356, 0.0149, 0.3381], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,919][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0193, 0.4503, 0.1379, 0.1142, 0.1511, 0.1272], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,920][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.2795, 0.0711, 0.3172, 0.0331, 0.0903, 0.2087], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,920][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([3.4846e-04, 3.5555e-01, 3.4692e-02, 2.0934e-01, 1.3650e-01, 2.6356e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,920][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1069, 0.1371, 0.0416, 0.2106, 0.0391, 0.4648], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,924][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0565, 0.1035, 0.0826, 0.2359, 0.1001, 0.4214], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,927][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([2.1599e-05, 4.4927e-01, 1.8522e-02, 1.2552e-01, 1.8827e-01, 2.1840e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,932][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.3187, 0.0099, 0.0132, 0.0693, 0.0270, 0.5619], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,934][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0012, 0.2350, 0.0452, 0.4668, 0.0570, 0.1947], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:22,934][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2174, 0.1527, 0.0343, 0.1362, 0.0240, 0.0954, 0.3399],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,934][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0034, 0.2998, 0.0271, 0.1544, 0.0168, 0.0498, 0.4487],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,935][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.4587, 0.0441, 0.1123, 0.0787, 0.0636, 0.0822, 0.1602],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,935][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.6547e-01, 3.4760e-04, 3.5670e-03, 1.0614e-02, 6.5995e-03, 8.0870e-02,
        5.3253e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,935][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0237, 0.3468, 0.0938, 0.1159, 0.1522, 0.0978, 0.1698],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,936][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.3623, 0.0375, 0.2375, 0.0318, 0.0853, 0.1199, 0.1257],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,936][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.1597e-04, 1.6454e-01, 1.7765e-02, 1.0117e-01, 7.9766e-02, 1.1297e-01,
        5.2367e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,936][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1955, 0.0461, 0.0215, 0.1043, 0.0149, 0.1698, 0.4479],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,937][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0349, 0.0460, 0.0375, 0.1926, 0.0472, 0.3976, 0.2443],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,938][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([1.0167e-05, 1.9835e-01, 7.5272e-03, 7.1619e-02, 9.2731e-02, 1.1376e-01,
        5.1600e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,942][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0569, 0.0009, 0.0017, 0.0106, 0.0062, 0.0773, 0.8464],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,948][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0012, 0.1549, 0.0312, 0.2666, 0.0411, 0.1024, 0.4026],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:22,950][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0786, 0.1068, 0.0177, 0.0984, 0.0196, 0.0799, 0.2702, 0.3289],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,951][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0023, 0.3879, 0.0208, 0.0850, 0.0089, 0.0395, 0.3331, 0.1223],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,951][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.2963, 0.0245, 0.0439, 0.0398, 0.0297, 0.0506, 0.1435, 0.3717],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,951][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([2.7406e-01, 2.3654e-04, 6.9432e-03, 1.4711e-02, 3.0079e-02, 5.1491e-02,
        4.4145e-01, 1.8103e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,951][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.0096, 0.2537, 0.0951, 0.0900, 0.1701, 0.0953, 0.1797, 0.1066],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,952][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([0.1229, 0.0583, 0.1310, 0.0369, 0.1031, 0.1282, 0.1145, 0.3050],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,952][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([7.5531e-05, 1.5885e-01, 1.3046e-02, 7.0498e-02, 4.3048e-02, 7.9573e-02,
        4.8080e-01, 1.5411e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,952][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0496, 0.0272, 0.0078, 0.0850, 0.0089, 0.1309, 0.4372, 0.2535],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,954][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0314, 0.0523, 0.0308, 0.1426, 0.0567, 0.2281, 0.2757, 0.1824],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,958][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([2.1138e-05, 2.2807e-01, 3.7902e-03, 4.3245e-02, 4.1115e-02, 7.9459e-02,
        3.9258e-01, 2.1172e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,960][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([1.4783e-02, 5.4962e-04, 1.9901e-03, 1.5432e-02, 1.8681e-02, 7.1423e-02,
        6.1988e-01, 2.5727e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,964][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([1.0058e-04, 1.4440e-01, 1.0861e-02, 1.7141e-01, 3.3822e-02, 6.6646e-02,
        3.6864e-01, 2.0412e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:22,966][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.4337, 0.0453, 0.0257, 0.0389, 0.0111, 0.0475, 0.1325, 0.1506, 0.1146],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,966][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.0039, 0.1324, 0.0328, 0.0877, 0.0115, 0.0367, 0.3224, 0.2004, 0.1721],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,967][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.5384, 0.0144, 0.0658, 0.0247, 0.0290, 0.0349, 0.0825, 0.1460, 0.0642],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,967][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ of] are: tensor([2.5538e-01, 2.1879e-04, 3.5222e-03, 3.8139e-03, 6.0311e-03, 2.9943e-02,
        2.6734e-01, 1.2373e-01, 3.1003e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,967][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0173, 0.2946, 0.0806, 0.0886, 0.1005, 0.0808, 0.1166, 0.0688, 0.1522],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,968][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ of] are: tensor([0.3394, 0.0390, 0.2388, 0.0227, 0.0642, 0.0997, 0.0695, 0.0942, 0.0325],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,968][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ of] are: tensor([1.7024e-04, 6.1403e-02, 1.3215e-02, 5.4373e-02, 3.5971e-02, 6.3359e-02,
        3.5305e-01, 1.4793e-01, 2.7053e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,968][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.1424, 0.0203, 0.0165, 0.0460, 0.0100, 0.0779, 0.3295, 0.2306, 0.1268],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,969][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0546, 0.0242, 0.0410, 0.1013, 0.0405, 0.2151, 0.1774, 0.1284, 0.2176],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,969][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ of] are: tensor([8.3937e-06, 4.8354e-02, 2.9259e-03, 2.2944e-02, 2.4671e-02, 4.7983e-02,
        2.5414e-01, 1.5443e-01, 4.4454e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,970][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ of] are: tensor([5.9830e-02, 3.0612e-04, 1.4321e-03, 3.0978e-03, 6.4336e-03, 2.5792e-02,
        2.6398e-01, 1.7672e-01, 4.6241e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,975][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0010, 0.0421, 0.0147, 0.1178, 0.0236, 0.0612, 0.3696, 0.1395, 0.2304],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:22,981][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0131, 0.1293, 0.0093, 0.0587, 0.0109, 0.0513, 0.2114, 0.2283, 0.1963,
        0.0915], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,983][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.0003, 0.2474, 0.0117, 0.0819, 0.0077, 0.0459, 0.2653, 0.1154, 0.1442,
        0.0801], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,983][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0312, 0.0514, 0.0333, 0.0399, 0.0254, 0.0471, 0.1524, 0.1823, 0.1140,
        0.3231], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,983][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([1.5516e-01, 6.9028e-05, 2.1589e-03, 3.0532e-03, 8.6071e-03, 1.4257e-02,
        8.9962e-02, 2.1448e-02, 2.5245e-01, 4.5284e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,984][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.0043, 0.4099, 0.0519, 0.0576, 0.0730, 0.0559, 0.1228, 0.0521, 0.1143,
        0.0582], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,984][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([0.0999, 0.0571, 0.1170, 0.0232, 0.0522, 0.0856, 0.0961, 0.1072, 0.0442,
        0.3174], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,984][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([2.0201e-05, 5.1909e-02, 3.9455e-03, 3.2440e-02, 1.8594e-02, 4.5232e-02,
        2.7266e-01, 1.4447e-01, 2.0848e-01, 2.2225e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,985][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0088, 0.0203, 0.0052, 0.0354, 0.0066, 0.0759, 0.2906, 0.1473, 0.1700,
        0.2399], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,985][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0064, 0.0270, 0.0138, 0.0814, 0.0213, 0.1408, 0.2427, 0.1530, 0.1881,
        0.1256], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,986][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([3.9772e-06, 4.1885e-02, 1.2682e-03, 1.2090e-02, 1.5557e-02, 3.3851e-02,
        1.5846e-01, 1.1985e-01, 3.4014e-01, 2.7688e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,990][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([4.2787e-03, 9.0275e-05, 3.1108e-04, 1.8913e-03, 2.3453e-03, 8.7059e-03,
        7.1020e-02, 2.5471e-02, 2.6069e-01, 6.2519e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,995][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0003, 0.1402, 0.0130, 0.1308, 0.0406, 0.0595, 0.2318, 0.2161, 0.1391,
        0.0284], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:22,999][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0526, 0.0547, 0.0108, 0.0396, 0.0102, 0.0543, 0.1902, 0.1325, 0.1618,
        0.1439, 0.1494], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,999][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.0005, 0.1918, 0.0124, 0.0747, 0.0051, 0.0285, 0.2569, 0.1241, 0.1548,
        0.0707, 0.0805], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:22,999][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0894, 0.0327, 0.0295, 0.0487, 0.0173, 0.0371, 0.1466, 0.1322, 0.0957,
        0.2857, 0.0851], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,000][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ at] are: tensor([9.3844e-02, 5.4007e-06, 4.3964e-05, 2.1966e-05, 8.8778e-06, 9.5925e-04,
        8.0789e-03, 3.8049e-04, 5.8194e-03, 3.8233e-04, 8.9046e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,000][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0042, 0.3307, 0.0478, 0.0796, 0.0675, 0.0504, 0.1334, 0.0322, 0.1544,
        0.0421, 0.0578], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,000][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ at] are: tensor([0.0900, 0.0450, 0.0933, 0.0226, 0.0364, 0.0829, 0.0950, 0.1253, 0.0533,
        0.2372, 0.1190], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,001][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ at] are: tensor([1.7921e-05, 7.8302e-02, 5.9805e-03, 4.2740e-02, 2.3596e-02, 6.4215e-02,
        3.0137e-01, 7.8788e-02, 2.0701e-01, 1.4325e-01, 5.4742e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,001][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0180, 0.0190, 0.0046, 0.0278, 0.0023, 0.0613, 0.3033, 0.2124, 0.1240,
        0.1440, 0.0833], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,001][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0046, 0.0240, 0.0131, 0.0859, 0.0290, 0.1589, 0.1955, 0.1226, 0.1719,
        0.0912, 0.1035], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,002][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.5200e-06, 4.1656e-02, 1.4341e-03, 1.4587e-02, 2.6341e-02, 2.9621e-02,
        1.9148e-01, 7.2203e-02, 3.5605e-01, 1.7230e-01, 9.4328e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,003][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ at] are: tensor([5.6825e-03, 1.6497e-05, 1.5456e-05, 3.9409e-05, 8.2385e-06, 1.0365e-03,
        8.7140e-03, 1.0271e-03, 1.1471e-02, 1.0301e-03, 9.7096e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,007][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ at] are: tensor([1.9099e-04, 6.6810e-02, 8.6674e-03, 1.3516e-01, 1.9436e-02, 4.4528e-02,
        3.4238e-01, 1.3629e-01, 2.0255e-01, 1.7257e-02, 2.6732e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,011][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0444, 0.0665, 0.0061, 0.0446, 0.0054, 0.0340, 0.1802, 0.0978, 0.1803,
        0.1163, 0.1127, 0.1115], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,015][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.0003, 0.2525, 0.0100, 0.0738, 0.0037, 0.0187, 0.1745, 0.0863, 0.1533,
        0.0522, 0.0743, 0.1004], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,016][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0672, 0.0418, 0.0240, 0.0446, 0.0172, 0.0368, 0.1373, 0.1514, 0.0890,
        0.2506, 0.0681, 0.0720], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,016][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ the] are: tensor([7.6933e-02, 2.2655e-06, 2.1608e-05, 9.9676e-06, 4.3863e-06, 4.7174e-04,
        3.5153e-03, 1.5449e-04, 2.5156e-03, 8.1523e-05, 5.2270e-01, 3.9359e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,016][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0061, 0.1717, 0.0373, 0.0672, 0.0527, 0.0483, 0.1426, 0.0651, 0.2073,
        0.0418, 0.0905, 0.0693], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,017][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ the] are: tensor([0.0677, 0.0429, 0.0841, 0.0224, 0.0372, 0.0739, 0.0968, 0.0933, 0.0529,
        0.2265, 0.0969, 0.1053], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,017][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ the] are: tensor([9.7734e-06, 1.0052e-01, 6.5584e-03, 4.6526e-02, 2.1887e-02, 3.8202e-02,
        2.0186e-01, 7.2933e-02, 1.9904e-01, 1.5997e-01, 5.8746e-02, 9.3748e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,017][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0507, 0.0276, 0.0050, 0.0352, 0.0024, 0.0689, 0.2741, 0.1425, 0.1440,
        0.1289, 0.0603, 0.0604], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,018][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0025, 0.0335, 0.0089, 0.0863, 0.0162, 0.1390, 0.1510, 0.1131, 0.1334,
        0.0837, 0.1559, 0.0766], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,019][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ the] are: tensor([8.6895e-07, 6.1423e-02, 9.8650e-04, 1.6246e-02, 1.1241e-02, 2.0288e-02,
        1.3389e-01, 8.0839e-02, 3.7923e-01, 1.1651e-01, 7.1944e-02, 1.0741e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,023][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ the] are: tensor([3.2534e-03, 4.2009e-06, 5.8573e-06, 1.1794e-05, 2.2778e-06, 4.0285e-04,
        3.0316e-03, 2.9681e-04, 4.0493e-03, 2.9787e-04, 5.6586e-01, 4.2278e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,027][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0003, 0.0809, 0.0101, 0.1237, 0.0192, 0.0371, 0.2509, 0.1836, 0.1999,
        0.0352, 0.0337, 0.0254], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,031][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0073, 0.0617, 0.0044, 0.0387, 0.0052, 0.0363, 0.2098, 0.1014, 0.1519,
        0.0533, 0.1274, 0.1503, 0.0524], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,031][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ store] are: tensor([1.4241e-04, 2.5677e-01, 1.0949e-02, 5.8572e-02, 5.1795e-03, 1.8597e-02,
        1.9044e-01, 5.3997e-02, 1.5884e-01, 3.5587e-02, 7.2901e-02, 1.2554e-01,
        1.2493e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,032][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0077, 0.0325, 0.0159, 0.0283, 0.0149, 0.0386, 0.1398, 0.1170, 0.0788,
        0.1937, 0.0980, 0.0927, 0.1421], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,032][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ store] are: tensor([5.1411e-02, 2.4605e-06, 1.3960e-05, 8.0448e-06, 2.8148e-06, 3.5588e-04,
        1.8676e-03, 8.3874e-05, 1.3438e-03, 4.4401e-05, 2.8938e-01, 4.9138e-01,
        1.6411e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,033][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.0008, 0.1096, 0.0270, 0.0437, 0.0521, 0.0556, 0.0958, 0.0550, 0.1522,
        0.0345, 0.0905, 0.0996, 0.1837], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,033][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ store] are: tensor([0.0403, 0.0473, 0.0744, 0.0172, 0.0351, 0.0704, 0.0732, 0.0765, 0.0356,
        0.1813, 0.0981, 0.0755, 0.1750], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,033][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ store] are: tensor([3.8573e-06, 8.8999e-02, 2.6399e-03, 3.0143e-02, 1.5310e-02, 2.4919e-02,
        2.1694e-01, 5.8198e-02, 2.6354e-01, 1.1133e-01, 6.6430e-02, 1.1612e-01,
        5.4279e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,034][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0197, 0.0196, 0.0044, 0.0235, 0.0024, 0.0682, 0.2217, 0.1019, 0.1227,
        0.1168, 0.1064, 0.1037, 0.0890], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,034][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0024, 0.0271, 0.0059, 0.0550, 0.0131, 0.0848, 0.1328, 0.0769, 0.1638,
        0.0720, 0.1990, 0.1217, 0.0455], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,035][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ store] are: tensor([5.9262e-07, 5.3983e-02, 6.8994e-04, 1.5770e-02, 1.4818e-02, 1.9250e-02,
        1.4351e-01, 4.6458e-02, 3.9592e-01, 8.2639e-02, 8.6833e-02, 1.2742e-01,
        1.2705e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,038][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ store] are: tensor([1.4234e-03, 2.9477e-06, 4.5982e-06, 8.6038e-06, 1.6046e-06, 2.5088e-04,
        2.1327e-03, 1.1531e-04, 2.3100e-03, 1.4135e-04, 4.1874e-01, 4.1673e-01,
        1.5814e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,041][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ store] are: tensor([1.5105e-04, 9.8141e-02, 8.4403e-03, 1.1657e-01, 2.5451e-02, 5.0025e-02,
        2.4223e-01, 1.5972e-01, 1.8739e-01, 3.3770e-02, 3.8617e-02, 2.9821e-02,
        9.6763e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,046][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.1010, 0.0475, 0.0128, 0.0372, 0.0091, 0.0455, 0.1363, 0.1245, 0.1163,
        0.0653, 0.0835, 0.1052, 0.0452, 0.0706], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,048][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.0009, 0.1812, 0.0181, 0.0632, 0.0050, 0.0256, 0.1726, 0.0700, 0.1185,
        0.0513, 0.0822, 0.1064, 0.0126, 0.0926], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,048][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.1432, 0.0147, 0.0315, 0.0192, 0.0204, 0.0247, 0.0632, 0.1174, 0.0517,
        0.1566, 0.0484, 0.0572, 0.1443, 0.1076], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,049][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [.] are: tensor([7.6213e-02, 4.8363e-06, 1.0380e-04, 4.2031e-05, 6.0919e-05, 8.1198e-04,
        3.6314e-03, 5.6455e-04, 3.0718e-03, 1.5001e-03, 1.8284e-01, 2.2230e-01,
        2.5820e-01, 2.5065e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,049][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0035, 0.1770, 0.0427, 0.0568, 0.0606, 0.0480, 0.0685, 0.0294, 0.0874,
        0.0193, 0.0395, 0.0430, 0.0903, 0.2341], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,049][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [.] are: tensor([0.0946, 0.0346, 0.1009, 0.0182, 0.0438, 0.0740, 0.0577, 0.0964, 0.0334,
        0.1173, 0.0628, 0.0579, 0.1424, 0.0659], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,050][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [.] are: tensor([3.1753e-05, 5.8093e-02, 6.6272e-03, 3.6076e-02, 1.9193e-02, 3.4138e-02,
        1.8685e-01, 6.1457e-02, 1.8716e-01, 1.0970e-01, 5.9600e-02, 1.0675e-01,
        8.7374e-03, 1.2558e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,050][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0653, 0.0159, 0.0083, 0.0263, 0.0047, 0.0526, 0.1688, 0.1045, 0.0985,
        0.1336, 0.0594, 0.0571, 0.0736, 0.1314], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,053][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0127, 0.0216, 0.0187, 0.0608, 0.0275, 0.1021, 0.1071, 0.0956, 0.1203,
        0.0733, 0.1463, 0.0798, 0.0522, 0.0821], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,056][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [.] are: tensor([3.0557e-06, 3.9388e-02, 1.4433e-03, 1.4710e-02, 1.4549e-02, 2.2097e-02,
        1.2390e-01, 6.7307e-02, 2.8204e-01, 1.0064e-01, 9.9804e-02, 1.3469e-01,
        1.3390e-02, 8.6043e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,059][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [.] are: tensor([7.5392e-03, 8.4066e-06, 3.9331e-05, 6.0390e-05, 5.7560e-05, 6.3106e-04,
        5.4062e-03, 1.3900e-03, 7.7378e-03, 5.2077e-03, 2.8853e-01, 3.1631e-01,
        2.2459e-01, 1.4249e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,064][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0005, 0.0719, 0.0113, 0.1196, 0.0277, 0.0420, 0.2730, 0.1285, 0.1804,
        0.0326, 0.0367, 0.0250, 0.0069, 0.0439], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,064][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0100, 0.1145, 0.0194, 0.0724, 0.0163, 0.0449, 0.1290, 0.1262, 0.1299,
        0.0655, 0.0731, 0.0864, 0.0541, 0.0477, 0.0106], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,064][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([1.3806e-04, 2.5138e-01, 1.3940e-02, 7.6430e-02, 9.9414e-03, 2.6572e-02,
        1.8297e-01, 7.1246e-02, 1.3275e-01, 2.8479e-02, 4.8140e-02, 8.0433e-02,
        1.0248e-02, 6.2599e-02, 4.7362e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,065][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0274, 0.0268, 0.0318, 0.0267, 0.0333, 0.0384, 0.0717, 0.1484, 0.0608,
        0.1456, 0.0729, 0.0619, 0.1222, 0.0915, 0.0407], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,065][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([2.4419e-03, 3.0487e-05, 2.4173e-05, 2.1291e-05, 7.8253e-06, 1.7694e-04,
        2.9688e-04, 3.9341e-06, 2.6158e-04, 4.3429e-06, 4.3709e-01, 3.5450e-01,
        1.7463e-01, 2.4043e-02, 6.4636e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,065][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0015, 0.1703, 0.0475, 0.0498, 0.0757, 0.0272, 0.0479, 0.0526, 0.1048,
        0.0196, 0.0388, 0.0362, 0.0980, 0.1910, 0.0394], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,066][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([0.0400, 0.0372, 0.0829, 0.0172, 0.0573, 0.0645, 0.0592, 0.0541, 0.0266,
        0.1699, 0.0612, 0.0608, 0.1793, 0.0482, 0.0417], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,066][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([1.3115e-05, 1.1874e-01, 4.0547e-03, 3.7765e-02, 2.8618e-02, 3.0900e-02,
        1.2839e-01, 6.5382e-02, 1.6066e-01, 1.5751e-01, 4.9837e-02, 9.1820e-02,
        7.7851e-03, 1.0056e-01, 1.7962e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,067][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0178, 0.1744, 0.0189, 0.0546, 0.0062, 0.0553, 0.0976, 0.0579, 0.0607,
        0.0568, 0.1040, 0.0905, 0.1211, 0.0809, 0.0033], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,070][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.0009, 0.0367, 0.0080, 0.0454, 0.0293, 0.0749, 0.1038, 0.0952, 0.1215,
        0.0629, 0.2154, 0.0757, 0.0460, 0.0756, 0.0086], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,072][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([1.5193e-06, 5.2786e-02, 1.7028e-03, 2.3216e-02, 5.9720e-02, 3.9202e-02,
        1.2190e-01, 8.2778e-02, 2.5745e-01, 8.1520e-02, 5.5230e-02, 1.0226e-01,
        1.5232e-02, 5.9276e-02, 4.7730e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,076][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([1.3285e-04, 3.0945e-05, 9.3349e-06, 1.9132e-05, 5.0208e-06, 1.2469e-04,
        3.8530e-04, 1.9133e-05, 6.5068e-04, 2.1198e-05, 3.9048e-01, 4.0676e-01,
        1.8259e-01, 1.7673e-02, 1.1054e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,080][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0004, 0.2142, 0.0099, 0.1123, 0.0308, 0.0328, 0.1403, 0.1697, 0.1246,
        0.0304, 0.0287, 0.0215, 0.0125, 0.0567, 0.0151], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,081][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0185, 0.0667, 0.0076, 0.0273, 0.0090, 0.0423, 0.1512, 0.1185, 0.1214,
        0.0753, 0.0941, 0.1051, 0.0756, 0.0425, 0.0094, 0.0353],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,081][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.0004, 0.2611, 0.0153, 0.0768, 0.0060, 0.0287, 0.1684, 0.0568, 0.1136,
        0.0322, 0.0549, 0.0706, 0.0153, 0.0786, 0.0031, 0.0181],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,081][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0190, 0.0390, 0.0203, 0.0241, 0.0159, 0.0284, 0.0806, 0.1261, 0.0523,
        0.1370, 0.0470, 0.0548, 0.1486, 0.1014, 0.0196, 0.0860],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,082][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([1.4085e-01, 4.9019e-07, 5.5264e-06, 4.6613e-07, 1.8191e-07, 3.6066e-05,
        1.3172e-04, 3.6885e-06, 5.7314e-05, 6.0375e-07, 6.9145e-03, 7.8516e-03,
        7.8424e-03, 1.2205e-02, 9.5998e-05, 8.2401e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,082][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0032, 0.1267, 0.0473, 0.0452, 0.0751, 0.0390, 0.0823, 0.0392, 0.0980,
        0.0254, 0.0448, 0.0407, 0.0970, 0.1360, 0.0393, 0.0608],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,083][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([0.0920, 0.0391, 0.0806, 0.0152, 0.0336, 0.0723, 0.0546, 0.0745, 0.0229,
        0.1261, 0.0507, 0.0431, 0.1282, 0.0401, 0.0242, 0.1027],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,084][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([5.1987e-06, 9.2646e-02, 2.9446e-03, 3.7588e-02, 2.5042e-02, 3.4904e-02,
        2.0595e-01, 4.5454e-02, 2.3977e-01, 7.1742e-02, 5.3857e-02, 8.9554e-02,
        6.3612e-03, 7.3933e-02, 1.3172e-02, 7.0792e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,090][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0422, 0.0338, 0.0108, 0.0307, 0.0030, 0.0674, 0.2260, 0.0866, 0.0904,
        0.0651, 0.0470, 0.0427, 0.0544, 0.0757, 0.0015, 0.1226],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,094][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0024, 0.0276, 0.0073, 0.0512, 0.0152, 0.0838, 0.1512, 0.0598, 0.1373,
        0.0498, 0.1381, 0.1407, 0.0381, 0.0606, 0.0023, 0.0345],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,096][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([2.3768e-06, 8.7177e-02, 2.2488e-03, 1.7632e-02, 2.2830e-02, 3.4147e-02,
        1.3492e-01, 3.5499e-02, 2.5710e-01, 7.9311e-02, 1.0446e-01, 1.2395e-01,
        1.7872e-02, 5.2566e-02, 1.9007e-02, 1.1274e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,096][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([3.4487e-02, 3.6038e-06, 9.3467e-06, 4.3110e-06, 1.0028e-06, 2.3094e-04,
        9.8466e-04, 5.1052e-05, 6.3400e-04, 1.3584e-05, 4.9168e-02, 4.4250e-02,
        2.2276e-02, 2.2568e-02, 1.4239e-04, 8.2518e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,097][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.7907e-04, 1.2012e-01, 7.2989e-03, 1.5321e-01, 1.0985e-02, 3.7304e-02,
        2.1235e-01, 1.1239e-01, 1.9338e-01, 1.1727e-02, 2.6028e-02, 2.9006e-02,
        6.5926e-03, 6.8234e-02, 3.9437e-03, 7.2549e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,097][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0545, 0.0649, 0.0062, 0.0326, 0.0064, 0.0290, 0.1131, 0.1013, 0.1259,
        0.0873, 0.0722, 0.0780, 0.0631, 0.0462, 0.0075, 0.0173, 0.0944],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,098][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([2.1078e-04, 2.2256e-01, 1.0521e-02, 7.4982e-02, 5.0376e-03, 1.8543e-02,
        1.5275e-01, 8.1443e-02, 1.3245e-01, 4.3386e-02, 5.1005e-02, 5.8279e-02,
        8.4033e-03, 5.9931e-02, 3.0501e-03, 1.1453e-02, 6.6000e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,098][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0625, 0.0440, 0.0423, 0.0392, 0.0305, 0.0336, 0.0798, 0.1131, 0.0538,
        0.1309, 0.0425, 0.0335, 0.0885, 0.0710, 0.0400, 0.0428, 0.0517],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,098][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.1965e-02, 1.3998e-07, 3.3086e-06, 6.7193e-07, 3.0646e-07, 3.2817e-05,
        1.1357e-04, 1.1932e-05, 1.1076e-04, 2.9658e-06, 5.0780e-03, 2.5624e-03,
        5.7947e-03, 1.2525e-02, 1.6779e-04, 3.1320e-01, 5.8843e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,099][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0019, 0.2011, 0.0236, 0.0434, 0.0450, 0.0233, 0.0579, 0.0360, 0.1388,
        0.0169, 0.0420, 0.0505, 0.0588, 0.1565, 0.0355, 0.0242, 0.0446],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,101][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0760, 0.0296, 0.0655, 0.0155, 0.0289, 0.0536, 0.0630, 0.0710, 0.0279,
        0.1445, 0.0454, 0.0494, 0.0989, 0.0419, 0.0239, 0.0557, 0.1093],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,104][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([7.0092e-06, 9.8806e-02, 4.2788e-03, 4.4853e-02, 2.0603e-02, 3.2576e-02,
        1.4624e-01, 6.3800e-02, 1.6179e-01, 1.2859e-01, 4.8730e-02, 8.5507e-02,
        4.3005e-03, 8.9996e-02, 9.3918e-03, 8.6051e-03, 5.1936e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,109][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0515, 0.0193, 0.0075, 0.0274, 0.0036, 0.0540, 0.2104, 0.0894, 0.0956,
        0.0943, 0.0263, 0.0275, 0.0308, 0.1070, 0.0023, 0.0597, 0.0935],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,113][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0013, 0.0393, 0.0085, 0.0727, 0.0194, 0.0989, 0.1112, 0.1029, 0.0937,
        0.0581, 0.1249, 0.0790, 0.0443, 0.0748, 0.0029, 0.0223, 0.0458],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,113][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([8.2136e-07, 6.4427e-02, 1.2707e-03, 2.0855e-02, 1.9602e-02, 2.0261e-02,
        1.1051e-01, 5.8905e-02, 3.2056e-01, 8.8674e-02, 6.8486e-02, 9.0753e-02,
        7.9334e-03, 4.8667e-02, 1.9602e-02, 6.4132e-03, 5.3082e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,113][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.7616e-02, 1.2107e-06, 4.5570e-06, 3.6239e-06, 1.0260e-06, 1.1935e-04,
        6.5433e-04, 1.4588e-04, 1.3248e-03, 7.4250e-05, 3.4168e-02, 1.8983e-02,
        1.7866e-02, 2.2301e-02, 2.0027e-04, 2.7072e-01, 6.1581e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,114][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0004, 0.0886, 0.0126, 0.1273, 0.0172, 0.0375, 0.1597, 0.1992, 0.1559,
        0.0421, 0.0351, 0.0250, 0.0089, 0.0527, 0.0050, 0.0071, 0.0257],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,114][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0087, 0.0798, 0.0082, 0.0441, 0.0072, 0.0353, 0.0955, 0.1185, 0.0928,
        0.0471, 0.1015, 0.1039, 0.0514, 0.0344, 0.0065, 0.0305, 0.0951, 0.0396],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,115][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([1.3506e-04, 1.9465e-01, 9.1844e-03, 4.7519e-02, 4.3088e-03, 2.2308e-02,
        1.4352e-01, 6.3034e-02, 1.2051e-01, 4.1524e-02, 5.5761e-02, 7.4839e-02,
        1.0209e-02, 6.1346e-02, 2.7110e-03, 1.5622e-02, 1.0821e-01, 2.4607e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,115][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0187, 0.0502, 0.0230, 0.0297, 0.0175, 0.0263, 0.0662, 0.1092, 0.0602,
        0.0943, 0.0578, 0.0610, 0.1063, 0.0657, 0.0353, 0.0386, 0.0553, 0.0847],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,116][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([2.1201e-03, 1.9585e-07, 1.6163e-06, 4.1946e-07, 4.2904e-07, 6.5260e-06,
        2.4707e-05, 1.2302e-06, 1.7201e-05, 9.2976e-07, 4.0328e-03, 4.7046e-03,
        3.2808e-03, 1.7165e-03, 4.0278e-04, 4.7351e-01, 5.0144e-01, 8.7338e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,122][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0009, 0.1113, 0.0233, 0.0342, 0.0457, 0.0283, 0.0475, 0.0446, 0.0878,
        0.0283, 0.0474, 0.0427, 0.1129, 0.1524, 0.0383, 0.0518, 0.0345, 0.0680],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,127][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([0.0323, 0.0383, 0.0819, 0.0157, 0.0341, 0.0541, 0.0396, 0.0579, 0.0173,
        0.1238, 0.0471, 0.0422, 0.1114, 0.0257, 0.0197, 0.0747, 0.0616, 0.1225],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,128][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([4.4905e-06, 1.6486e-01, 3.1944e-03, 4.3104e-02, 1.3755e-02, 2.5360e-02,
        1.2240e-01, 4.0256e-02, 1.4507e-01, 8.5668e-02, 5.6399e-02, 7.8743e-02,
        5.2107e-03, 1.3263e-01, 6.2281e-03, 7.2867e-03, 5.8812e-02, 1.1014e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,129][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0199, 0.0275, 0.0096, 0.0259, 0.0061, 0.0514, 0.1084, 0.0484, 0.0526,
        0.0717, 0.0443, 0.0497, 0.0599, 0.0662, 0.0038, 0.1230, 0.1321, 0.0993],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,129][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0022, 0.0426, 0.0082, 0.0478, 0.0207, 0.0672, 0.1046, 0.0899, 0.0911,
        0.0624, 0.1292, 0.1004, 0.0359, 0.0537, 0.0047, 0.0336, 0.0684, 0.0375],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,130][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([3.1176e-07, 1.3621e-01, 9.7929e-04, 1.8690e-02, 1.4799e-02, 2.1641e-02,
        9.9775e-02, 4.7771e-02, 2.5785e-01, 7.8878e-02, 7.7964e-02, 9.1214e-02,
        9.4416e-03, 7.8428e-02, 9.2225e-03, 5.9190e-03, 4.5768e-02, 5.4527e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,130][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([2.2146e-04, 9.4422e-07, 1.9045e-06, 2.2685e-06, 1.0208e-06, 2.8333e-05,
        1.2336e-04, 1.3558e-05, 1.6327e-04, 1.9576e-05, 2.6639e-02, 2.2138e-02,
        9.5408e-03, 5.1810e-03, 2.6965e-04, 4.2357e-01, 4.9002e-01, 2.2058e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,130][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([1.1480e-04, 1.4803e-01, 5.4861e-03, 1.0693e-01, 1.7870e-02, 4.8463e-02,
        1.5194e-01, 1.6643e-01, 1.5661e-01, 2.3713e-02, 2.4929e-02, 1.8865e-02,
        6.3891e-03, 6.8847e-02, 6.2516e-03, 1.0064e-02, 3.2454e-02, 6.6125e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,131][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0562, 0.0370, 0.0064, 0.0244, 0.0064, 0.0243, 0.0848, 0.0644, 0.0835,
        0.0984, 0.0621, 0.0823, 0.0699, 0.0431, 0.0072, 0.0170, 0.0780, 0.0343,
        0.1203], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,131][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([1.3850e-04, 2.0356e-01, 1.1265e-02, 6.2777e-02, 3.3128e-03, 1.7547e-02,
        1.4123e-01, 4.3668e-02, 1.2921e-01, 3.5836e-02, 5.2467e-02, 5.7559e-02,
        7.0539e-03, 7.6678e-02, 2.0181e-03, 1.0126e-02, 7.4105e-02, 1.6137e-02,
        5.5311e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,134][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0408, 0.0355, 0.0254, 0.0290, 0.0194, 0.0278, 0.0764, 0.0743, 0.0471,
        0.0851, 0.0449, 0.0417, 0.0697, 0.0680, 0.0275, 0.0385, 0.0582, 0.1019,
        0.0888], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,137][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([1.4387e-02, 1.7445e-08, 3.5181e-07, 3.1861e-08, 2.1890e-08, 3.6534e-06,
        1.3841e-05, 3.4061e-07, 5.9256e-06, 9.2195e-08, 8.4552e-04, 6.9172e-04,
        1.0505e-03, 2.3628e-03, 1.7334e-05, 1.5189e-01, 3.9019e-01, 4.2739e-03,
        4.3427e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,142][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0030, 0.1227, 0.0231, 0.0337, 0.0486, 0.0230, 0.0632, 0.0330, 0.0754,
        0.0160, 0.0292, 0.0393, 0.0380, 0.1526, 0.0354, 0.0230, 0.0410, 0.0542,
        0.1456], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,146][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0739, 0.0204, 0.0584, 0.0119, 0.0219, 0.0418, 0.0424, 0.0641, 0.0193,
        0.0996, 0.0281, 0.0290, 0.0771, 0.0345, 0.0225, 0.0531, 0.0820, 0.1451,
        0.0750], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,147][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([5.7761e-06, 6.1345e-02, 3.4479e-03, 3.1600e-02, 2.0703e-02, 2.8882e-02,
        1.5987e-01, 4.2923e-02, 1.5375e-01, 8.8275e-02, 4.7191e-02, 7.0696e-02,
        3.8660e-03, 7.9141e-02, 9.8960e-03, 7.3071e-03, 5.7429e-02, 9.8664e-03,
        1.2380e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,147][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0384, 0.0089, 0.0033, 0.0145, 0.0013, 0.0367, 0.1789, 0.0621, 0.0608,
        0.0330, 0.0248, 0.0315, 0.0332, 0.0944, 0.0010, 0.0711, 0.1254, 0.0625,
        0.1183], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,148][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0019, 0.0274, 0.0108, 0.0440, 0.0236, 0.0780, 0.1114, 0.0920, 0.0890,
        0.0680, 0.1121, 0.0662, 0.0430, 0.0631, 0.0031, 0.0237, 0.0494, 0.0244,
        0.0688], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,148][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([8.1167e-07, 7.4632e-02, 1.1670e-03, 2.1291e-02, 1.2055e-02, 1.5846e-02,
        1.1480e-01, 3.6907e-02, 3.3401e-01, 5.2816e-02, 5.5903e-02, 6.4584e-02,
        4.2969e-03, 3.6465e-02, 9.4368e-03, 3.8455e-03, 4.5877e-02, 4.0612e-03,
        1.1200e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,148][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([6.6003e-03, 1.4324e-07, 6.4794e-07, 2.5132e-07, 7.7436e-08, 1.5705e-05,
        7.8305e-05, 6.0498e-06, 8.0954e-05, 2.6824e-06, 6.7513e-03, 4.3484e-03,
        3.7988e-03, 4.1270e-03, 1.8526e-05, 1.0036e-01, 2.5401e-01, 8.1192e-03,
        6.1168e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,149][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0003, 0.0698, 0.0078, 0.1055, 0.0111, 0.0299, 0.2210, 0.1406, 0.1676,
        0.0248, 0.0309, 0.0230, 0.0036, 0.0591, 0.0033, 0.0058, 0.0311, 0.0044,
        0.0602], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,202][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:23,206][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,208][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,210][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,211][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,211][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,211][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,212][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,212][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,212][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,213][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,213][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,213][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,215][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3760, 0.6240], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,220][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0049, 0.9951], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,225][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6203, 0.3797], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,227][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8823, 0.1177], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,227][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0369, 0.9631], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,227][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4757, 0.5243], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,228][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,228][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0404, 0.9596], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,228][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.6553, 0.3447], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,228][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.0772e-05, 9.9998e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,229][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2159, 0.7841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,229][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0026, 0.9974], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,229][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.0330, 0.8397, 0.1273], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,229][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([3.3972e-04, 9.5610e-01, 4.3558e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,233][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.2750, 0.4153, 0.3098], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,237][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.4723, 0.4499, 0.0777], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,243][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.0302, 0.7542, 0.2155], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,243][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.1450, 0.2807, 0.5743], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,243][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([3.3205e-04, 9.4306e-01, 5.6608e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,244][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.0097, 0.9645, 0.0258], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,244][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.1245, 0.6179, 0.2576], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,244][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([1.4338e-05, 9.6244e-01, 3.7542e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,244][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.0184, 0.9296, 0.0520], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,245][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([6.6078e-04, 9.3969e-01, 5.9652e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,245][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4390, 0.2077, 0.0969, 0.2564], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,245][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0063, 0.6766, 0.0597, 0.2574], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,246][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.7753, 0.0502, 0.0900, 0.0844], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,249][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6030, 0.0680, 0.0991, 0.2299], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,253][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0671, 0.5256, 0.1933, 0.2140], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,259][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3831, 0.1257, 0.4360, 0.0552], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,259][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0025, 0.4860, 0.1103, 0.4013], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,259][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1988, 0.3390, 0.0616, 0.4005], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,260][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2623, 0.1260, 0.1474, 0.4643], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,260][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([6.6264e-05, 7.4974e-01, 3.8454e-02, 2.1174e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,260][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2158, 0.2137, 0.0744, 0.4962], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,261][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0017, 0.2638, 0.0763, 0.6582], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,261][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.0589, 0.4436, 0.1140, 0.3158, 0.0677], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,261][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.0014, 0.7298, 0.0406, 0.2008, 0.0275], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,262][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.3885, 0.1209, 0.1931, 0.1703, 0.1271], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,262][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.3691, 0.1655, 0.0472, 0.3575, 0.0607], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,265][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0202, 0.3390, 0.2125, 0.1271, 0.3012], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,269][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.2062, 0.1150, 0.3680, 0.0627, 0.2481], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,273][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([4.3542e-04, 4.9372e-01, 4.1580e-02, 2.6153e-01, 2.0273e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,275][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0403, 0.6297, 0.0342, 0.2789, 0.0169], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,275][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.0524, 0.1675, 0.0888, 0.4160, 0.2753], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,276][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([3.7778e-05, 2.7644e-01, 1.7297e-02, 1.5278e-01, 5.5345e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,276][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.0538, 0.3824, 0.0454, 0.4225, 0.0960], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,276][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0006, 0.4527, 0.0350, 0.4175, 0.0942], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,277][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1236, 0.3217, 0.0988, 0.2118, 0.0521, 0.1921], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,277][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0047, 0.6355, 0.0456, 0.2220, 0.0261, 0.0661], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,277][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4377, 0.0885, 0.1713, 0.1003, 0.0842, 0.1181], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,278][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.5957, 0.0030, 0.0128, 0.0356, 0.0149, 0.3381], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,278][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0193, 0.4503, 0.1379, 0.1142, 0.1511, 0.1272], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,281][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2795, 0.0711, 0.3172, 0.0331, 0.0903, 0.2087], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,283][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([3.4846e-04, 3.5555e-01, 3.4692e-02, 2.0934e-01, 1.3650e-01, 2.6356e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,289][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1069, 0.1371, 0.0416, 0.2106, 0.0391, 0.4648], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,291][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0565, 0.1035, 0.0826, 0.2359, 0.1001, 0.4214], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,292][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([2.1599e-05, 4.4927e-01, 1.8522e-02, 1.2552e-01, 1.8827e-01, 2.1840e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,292][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.3187, 0.0099, 0.0132, 0.0693, 0.0270, 0.5619], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,292][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0012, 0.2350, 0.0452, 0.4668, 0.0570, 0.1947], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,292][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2174, 0.1527, 0.0343, 0.1362, 0.0240, 0.0954, 0.3399],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,293][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0034, 0.2998, 0.0271, 0.1544, 0.0168, 0.0498, 0.4487],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,293][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.4587, 0.0441, 0.1123, 0.0787, 0.0636, 0.0822, 0.1602],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,293][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([3.6547e-01, 3.4760e-04, 3.5670e-03, 1.0614e-02, 6.5995e-03, 8.0870e-02,
        5.3253e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,294][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0237, 0.3468, 0.0938, 0.1159, 0.1522, 0.0978, 0.1698],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,294][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3623, 0.0375, 0.2375, 0.0318, 0.0853, 0.1199, 0.1257],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,295][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.1597e-04, 1.6454e-01, 1.7765e-02, 1.0117e-01, 7.9766e-02, 1.1297e-01,
        5.2367e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,300][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1955, 0.0461, 0.0215, 0.1043, 0.0149, 0.1698, 0.4479],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,305][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0349, 0.0460, 0.0375, 0.1926, 0.0472, 0.3976, 0.2443],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,307][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.0167e-05, 1.9835e-01, 7.5272e-03, 7.1619e-02, 9.2731e-02, 1.1376e-01,
        5.1600e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,308][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0569, 0.0009, 0.0017, 0.0106, 0.0062, 0.0773, 0.8464],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,308][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0012, 0.1549, 0.0312, 0.2666, 0.0411, 0.1024, 0.4026],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,308][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.0786, 0.1068, 0.0177, 0.0984, 0.0196, 0.0799, 0.2702, 0.3289],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,309][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0023, 0.3879, 0.0208, 0.0850, 0.0089, 0.0395, 0.3331, 0.1223],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,309][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.2963, 0.0245, 0.0439, 0.0398, 0.0297, 0.0506, 0.1435, 0.3717],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,309][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([2.7406e-01, 2.3654e-04, 6.9432e-03, 1.4711e-02, 3.0079e-02, 5.1491e-02,
        4.4145e-01, 1.8103e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,310][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.0096, 0.2537, 0.0951, 0.0900, 0.1701, 0.0953, 0.1797, 0.1066],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,310][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.1229, 0.0583, 0.1310, 0.0369, 0.1031, 0.1282, 0.1145, 0.3050],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,310][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([7.5531e-05, 1.5885e-01, 1.3046e-02, 7.0498e-02, 4.3048e-02, 7.9573e-02,
        4.8080e-01, 1.5411e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,314][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0496, 0.0272, 0.0078, 0.0850, 0.0089, 0.1309, 0.4372, 0.2535],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,319][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0314, 0.0523, 0.0308, 0.1426, 0.0567, 0.2281, 0.2757, 0.1824],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,322][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([2.1138e-05, 2.2807e-01, 3.7902e-03, 4.3245e-02, 4.1115e-02, 7.9459e-02,
        3.9258e-01, 2.1172e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,324][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([1.4783e-02, 5.4962e-04, 1.9901e-03, 1.5432e-02, 1.8681e-02, 7.1423e-02,
        6.1988e-01, 2.5727e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,324][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([1.0058e-04, 1.4440e-01, 1.0861e-02, 1.7141e-01, 3.3822e-02, 6.6646e-02,
        3.6864e-01, 2.0412e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,324][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.4337, 0.0453, 0.0257, 0.0389, 0.0111, 0.0475, 0.1325, 0.1506, 0.1146],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,325][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.0039, 0.1324, 0.0328, 0.0877, 0.0115, 0.0367, 0.3224, 0.2004, 0.1721],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,325][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.5384, 0.0144, 0.0658, 0.0247, 0.0290, 0.0349, 0.0825, 0.1460, 0.0642],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,325][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([2.5538e-01, 2.1879e-04, 3.5222e-03, 3.8139e-03, 6.0311e-03, 2.9943e-02,
        2.6734e-01, 1.2373e-01, 3.1003e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,326][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0173, 0.2946, 0.0806, 0.0886, 0.1005, 0.0808, 0.1166, 0.0688, 0.1522],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,326][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.3394, 0.0390, 0.2388, 0.0227, 0.0642, 0.0997, 0.0695, 0.0942, 0.0325],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,326][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([1.7024e-04, 6.1403e-02, 1.3215e-02, 5.4373e-02, 3.5971e-02, 6.3359e-02,
        3.5305e-01, 1.4793e-01, 2.7053e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,326][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.1424, 0.0203, 0.0165, 0.0460, 0.0100, 0.0779, 0.3295, 0.2306, 0.1268],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,330][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0546, 0.0242, 0.0410, 0.1013, 0.0405, 0.2151, 0.1774, 0.1284, 0.2176],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,332][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([8.3937e-06, 4.8354e-02, 2.9259e-03, 2.2944e-02, 2.4671e-02, 4.7983e-02,
        2.5414e-01, 1.5443e-01, 4.4454e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,336][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([5.9830e-02, 3.0612e-04, 1.4321e-03, 3.0978e-03, 6.4336e-03, 2.5792e-02,
        2.6398e-01, 1.7672e-01, 4.6241e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,340][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.0010, 0.0421, 0.0147, 0.1178, 0.0236, 0.0612, 0.3696, 0.1395, 0.2304],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,340][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.0131, 0.1293, 0.0093, 0.0587, 0.0109, 0.0513, 0.2114, 0.2283, 0.1963,
        0.0915], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,341][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.0003, 0.2474, 0.0117, 0.0819, 0.0077, 0.0459, 0.2653, 0.1154, 0.1442,
        0.0801], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,341][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0312, 0.0514, 0.0333, 0.0399, 0.0254, 0.0471, 0.1524, 0.1823, 0.1140,
        0.3231], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,341][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([1.5516e-01, 6.9028e-05, 2.1589e-03, 3.0532e-03, 8.6071e-03, 1.4257e-02,
        8.9962e-02, 2.1448e-02, 2.5245e-01, 4.5284e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,342][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.0043, 0.4099, 0.0519, 0.0576, 0.0730, 0.0559, 0.1228, 0.0521, 0.1143,
        0.0582], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,342][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0999, 0.0571, 0.1170, 0.0232, 0.0522, 0.0856, 0.0961, 0.1072, 0.0442,
        0.3174], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,342][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([2.0201e-05, 5.1909e-02, 3.9455e-03, 3.2440e-02, 1.8594e-02, 4.5232e-02,
        2.7266e-01, 1.4447e-01, 2.0848e-01, 2.2225e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,343][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0088, 0.0203, 0.0052, 0.0354, 0.0066, 0.0759, 0.2906, 0.1473, 0.1700,
        0.2399], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,343][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0064, 0.0270, 0.0138, 0.0814, 0.0213, 0.1408, 0.2427, 0.1530, 0.1881,
        0.1256], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,346][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([3.9772e-06, 4.1885e-02, 1.2682e-03, 1.2090e-02, 1.5557e-02, 3.3851e-02,
        1.5846e-01, 1.1985e-01, 3.4014e-01, 2.7688e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,349][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([4.2787e-03, 9.0275e-05, 3.1108e-04, 1.8913e-03, 2.3453e-03, 8.7059e-03,
        7.1020e-02, 2.5471e-02, 2.6069e-01, 6.2519e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,354][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([0.0003, 0.1402, 0.0130, 0.1308, 0.0406, 0.0595, 0.2318, 0.2161, 0.1391,
        0.0284], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,356][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0526, 0.0547, 0.0108, 0.0396, 0.0102, 0.0543, 0.1902, 0.1325, 0.1618,
        0.1439, 0.1494], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,357][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.0005, 0.1918, 0.0124, 0.0747, 0.0051, 0.0285, 0.2569, 0.1241, 0.1548,
        0.0707, 0.0805], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,357][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0894, 0.0327, 0.0295, 0.0487, 0.0173, 0.0371, 0.1466, 0.1322, 0.0957,
        0.2857, 0.0851], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,358][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([9.3844e-02, 5.4007e-06, 4.3964e-05, 2.1966e-05, 8.8778e-06, 9.5925e-04,
        8.0789e-03, 3.8049e-04, 5.8194e-03, 3.8233e-04, 8.9046e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,358][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0042, 0.3307, 0.0478, 0.0796, 0.0675, 0.0504, 0.1334, 0.0322, 0.1544,
        0.0421, 0.0578], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,358][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0900, 0.0450, 0.0933, 0.0226, 0.0364, 0.0829, 0.0950, 0.1253, 0.0533,
        0.2372, 0.1190], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,359][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([1.7921e-05, 7.8302e-02, 5.9805e-03, 4.2740e-02, 2.3596e-02, 6.4215e-02,
        3.0137e-01, 7.8788e-02, 2.0701e-01, 1.4325e-01, 5.4742e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,359][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0180, 0.0190, 0.0046, 0.0278, 0.0023, 0.0613, 0.3033, 0.2124, 0.1240,
        0.1440, 0.0833], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,359][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0046, 0.0240, 0.0131, 0.0859, 0.0290, 0.1589, 0.1955, 0.1226, 0.1719,
        0.0912, 0.1035], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,360][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.5200e-06, 4.1656e-02, 1.4341e-03, 1.4587e-02, 2.6341e-02, 2.9621e-02,
        1.9148e-01, 7.2203e-02, 3.5605e-01, 1.7230e-01, 9.4328e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,363][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([5.6825e-03, 1.6497e-05, 1.5456e-05, 3.9409e-05, 8.2385e-06, 1.0365e-03,
        8.7140e-03, 1.0271e-03, 1.1471e-02, 1.0301e-03, 9.7096e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,365][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.9099e-04, 6.6810e-02, 8.6674e-03, 1.3516e-01, 1.9436e-02, 4.4528e-02,
        3.4238e-01, 1.3629e-01, 2.0255e-01, 1.7257e-02, 2.6732e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,371][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.0444, 0.0665, 0.0061, 0.0446, 0.0054, 0.0340, 0.1802, 0.0978, 0.1803,
        0.1163, 0.1127, 0.1115], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,373][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.0003, 0.2525, 0.0100, 0.0738, 0.0037, 0.0187, 0.1745, 0.0863, 0.1533,
        0.0522, 0.0743, 0.1004], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,374][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([0.0672, 0.0418, 0.0240, 0.0446, 0.0172, 0.0368, 0.1373, 0.1514, 0.0890,
        0.2506, 0.0681, 0.0720], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,374][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([7.6933e-02, 2.2655e-06, 2.1608e-05, 9.9676e-06, 4.3863e-06, 4.7174e-04,
        3.5153e-03, 1.5449e-04, 2.5156e-03, 8.1523e-05, 5.2270e-01, 3.9359e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,374][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0061, 0.1717, 0.0373, 0.0672, 0.0527, 0.0483, 0.1426, 0.0651, 0.2073,
        0.0418, 0.0905, 0.0693], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,375][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0677, 0.0429, 0.0841, 0.0224, 0.0372, 0.0739, 0.0968, 0.0933, 0.0529,
        0.2265, 0.0969, 0.1053], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,375][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([9.7734e-06, 1.0052e-01, 6.5584e-03, 4.6526e-02, 2.1887e-02, 3.8202e-02,
        2.0186e-01, 7.2933e-02, 1.9904e-01, 1.5997e-01, 5.8746e-02, 9.3748e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,375][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0507, 0.0276, 0.0050, 0.0352, 0.0024, 0.0689, 0.2741, 0.1425, 0.1440,
        0.1289, 0.0603, 0.0604], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,376][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0025, 0.0335, 0.0089, 0.0863, 0.0162, 0.1390, 0.1510, 0.1131, 0.1334,
        0.0837, 0.1559, 0.0766], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,376][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([8.6895e-07, 6.1423e-02, 9.8650e-04, 1.6246e-02, 1.1241e-02, 2.0288e-02,
        1.3389e-01, 8.0839e-02, 3.7923e-01, 1.1651e-01, 7.1944e-02, 1.0741e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,377][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([3.2534e-03, 4.2009e-06, 5.8573e-06, 1.1794e-05, 2.2778e-06, 4.0285e-04,
        3.0316e-03, 2.9681e-04, 4.0493e-03, 2.9787e-04, 5.6586e-01, 4.2278e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,382][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([0.0003, 0.0809, 0.0101, 0.1237, 0.0192, 0.0371, 0.2509, 0.1836, 0.1999,
        0.0352, 0.0337, 0.0254], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,388][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.0073, 0.0617, 0.0044, 0.0387, 0.0052, 0.0363, 0.2098, 0.1014, 0.1519,
        0.0533, 0.1274, 0.1503, 0.0524], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,390][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([1.4241e-04, 2.5677e-01, 1.0949e-02, 5.8572e-02, 5.1795e-03, 1.8597e-02,
        1.9044e-01, 5.3997e-02, 1.5884e-01, 3.5587e-02, 7.2901e-02, 1.2554e-01,
        1.2493e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,390][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([0.0077, 0.0325, 0.0159, 0.0283, 0.0149, 0.0386, 0.1398, 0.1170, 0.0788,
        0.1937, 0.0980, 0.0927, 0.1421], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,390][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([5.1411e-02, 2.4605e-06, 1.3960e-05, 8.0448e-06, 2.8148e-06, 3.5588e-04,
        1.8676e-03, 8.3874e-05, 1.3438e-03, 4.4401e-05, 2.8938e-01, 4.9138e-01,
        1.6411e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,391][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.0008, 0.1096, 0.0270, 0.0437, 0.0521, 0.0556, 0.0958, 0.0550, 0.1522,
        0.0345, 0.0905, 0.0996, 0.1837], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,391][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0403, 0.0473, 0.0744, 0.0172, 0.0351, 0.0704, 0.0732, 0.0765, 0.0356,
        0.1813, 0.0981, 0.0755, 0.1750], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,391][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([3.8573e-06, 8.8999e-02, 2.6399e-03, 3.0143e-02, 1.5310e-02, 2.4919e-02,
        2.1694e-01, 5.8198e-02, 2.6354e-01, 1.1133e-01, 6.6430e-02, 1.1612e-01,
        5.4279e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,392][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0197, 0.0196, 0.0044, 0.0235, 0.0024, 0.0682, 0.2217, 0.1019, 0.1227,
        0.1168, 0.1064, 0.1037, 0.0890], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,392][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0024, 0.0271, 0.0059, 0.0550, 0.0131, 0.0848, 0.1328, 0.0769, 0.1638,
        0.0720, 0.1990, 0.1217, 0.0455], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,393][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([5.9262e-07, 5.3983e-02, 6.8994e-04, 1.5770e-02, 1.4818e-02, 1.9250e-02,
        1.4351e-01, 4.6458e-02, 3.9592e-01, 8.2639e-02, 8.6833e-02, 1.2742e-01,
        1.2705e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,394][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([1.4234e-03, 2.9477e-06, 4.5982e-06, 8.6038e-06, 1.6046e-06, 2.5088e-04,
        2.1327e-03, 1.1531e-04, 2.3100e-03, 1.4135e-04, 4.1874e-01, 4.1673e-01,
        1.5814e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,396][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.5105e-04, 9.8141e-02, 8.4403e-03, 1.1657e-01, 2.5451e-02, 5.0025e-02,
        2.4223e-01, 1.5972e-01, 1.8739e-01, 3.3770e-02, 3.8617e-02, 2.9821e-02,
        9.6763e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,402][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.1010, 0.0475, 0.0128, 0.0372, 0.0091, 0.0455, 0.1363, 0.1245, 0.1163,
        0.0653, 0.0835, 0.1052, 0.0452, 0.0706], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,406][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.0009, 0.1812, 0.0181, 0.0632, 0.0050, 0.0256, 0.1726, 0.0700, 0.1185,
        0.0513, 0.0822, 0.1064, 0.0126, 0.0926], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,407][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.1432, 0.0147, 0.0315, 0.0192, 0.0204, 0.0247, 0.0632, 0.1174, 0.0517,
        0.1566, 0.0484, 0.0572, 0.1443, 0.1076], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,407][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([7.6213e-02, 4.8363e-06, 1.0380e-04, 4.2031e-05, 6.0919e-05, 8.1198e-04,
        3.6314e-03, 5.6455e-04, 3.0718e-03, 1.5001e-03, 1.8284e-01, 2.2230e-01,
        2.5820e-01, 2.5065e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,407][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0035, 0.1770, 0.0427, 0.0568, 0.0606, 0.0480, 0.0685, 0.0294, 0.0874,
        0.0193, 0.0395, 0.0430, 0.0903, 0.2341], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,408][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.0946, 0.0346, 0.1009, 0.0182, 0.0438, 0.0740, 0.0577, 0.0964, 0.0334,
        0.1173, 0.0628, 0.0579, 0.1424, 0.0659], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,408][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([3.1753e-05, 5.8093e-02, 6.6272e-03, 3.6076e-02, 1.9193e-02, 3.4138e-02,
        1.8685e-01, 6.1457e-02, 1.8716e-01, 1.0970e-01, 5.9600e-02, 1.0675e-01,
        8.7374e-03, 1.2558e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,408][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0653, 0.0159, 0.0083, 0.0263, 0.0047, 0.0526, 0.1688, 0.1045, 0.0985,
        0.1336, 0.0594, 0.0571, 0.0736, 0.1314], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,409][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0127, 0.0216, 0.0187, 0.0608, 0.0275, 0.1021, 0.1071, 0.0956, 0.1203,
        0.0733, 0.1463, 0.0798, 0.0522, 0.0821], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,409][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([3.0557e-06, 3.9388e-02, 1.4433e-03, 1.4710e-02, 1.4549e-02, 2.2097e-02,
        1.2390e-01, 6.7307e-02, 2.8204e-01, 1.0064e-01, 9.9804e-02, 1.3469e-01,
        1.3390e-02, 8.6043e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,411][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([7.5392e-03, 8.4066e-06, 3.9331e-05, 6.0390e-05, 5.7560e-05, 6.3106e-04,
        5.4062e-03, 1.3900e-03, 7.7378e-03, 5.2077e-03, 2.8853e-01, 3.1631e-01,
        2.2459e-01, 1.4249e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,416][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([0.0005, 0.0719, 0.0113, 0.1196, 0.0277, 0.0420, 0.2730, 0.1285, 0.1804,
        0.0326, 0.0367, 0.0250, 0.0069, 0.0439], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,421][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.0100, 0.1145, 0.0194, 0.0724, 0.0163, 0.0449, 0.1290, 0.1262, 0.1299,
        0.0655, 0.0731, 0.0864, 0.0541, 0.0477, 0.0106], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,423][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([1.3806e-04, 2.5138e-01, 1.3940e-02, 7.6430e-02, 9.9414e-03, 2.6572e-02,
        1.8297e-01, 7.1246e-02, 1.3275e-01, 2.8479e-02, 4.8140e-02, 8.0433e-02,
        1.0248e-02, 6.2599e-02, 4.7362e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,423][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.0274, 0.0268, 0.0318, 0.0267, 0.0333, 0.0384, 0.0717, 0.1484, 0.0608,
        0.1456, 0.0729, 0.0619, 0.1222, 0.0915, 0.0407], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,423][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([2.4419e-03, 3.0487e-05, 2.4173e-05, 2.1291e-05, 7.8253e-06, 1.7694e-04,
        2.9688e-04, 3.9341e-06, 2.6158e-04, 4.3429e-06, 4.3709e-01, 3.5450e-01,
        1.7463e-01, 2.4043e-02, 6.4636e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,424][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0015, 0.1703, 0.0475, 0.0498, 0.0757, 0.0272, 0.0479, 0.0526, 0.1048,
        0.0196, 0.0388, 0.0362, 0.0980, 0.1910, 0.0394], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,424][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.0400, 0.0372, 0.0829, 0.0172, 0.0573, 0.0645, 0.0592, 0.0541, 0.0266,
        0.1699, 0.0612, 0.0608, 0.1793, 0.0482, 0.0417], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,425][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([1.3115e-05, 1.1874e-01, 4.0547e-03, 3.7765e-02, 2.8618e-02, 3.0900e-02,
        1.2839e-01, 6.5382e-02, 1.6066e-01, 1.5751e-01, 4.9837e-02, 9.1820e-02,
        7.7851e-03, 1.0056e-01, 1.7962e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,425][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0178, 0.1744, 0.0189, 0.0546, 0.0062, 0.0553, 0.0976, 0.0579, 0.0607,
        0.0568, 0.1040, 0.0905, 0.1211, 0.0809, 0.0033], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,425][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.0009, 0.0367, 0.0080, 0.0454, 0.0293, 0.0749, 0.1038, 0.0952, 0.1215,
        0.0629, 0.2154, 0.0757, 0.0460, 0.0756, 0.0086], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,426][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([1.5193e-06, 5.2786e-02, 1.7028e-03, 2.3216e-02, 5.9720e-02, 3.9202e-02,
        1.2190e-01, 8.2778e-02, 2.5745e-01, 8.1520e-02, 5.5230e-02, 1.0226e-01,
        1.5232e-02, 5.9276e-02, 4.7730e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,427][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([1.3285e-04, 3.0945e-05, 9.3349e-06, 1.9132e-05, 5.0208e-06, 1.2469e-04,
        3.8530e-04, 1.9133e-05, 6.5068e-04, 2.1198e-05, 3.9048e-01, 4.0676e-01,
        1.8259e-01, 1.7673e-02, 1.1054e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,433][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0004, 0.2142, 0.0099, 0.1123, 0.0308, 0.0328, 0.1403, 0.1697, 0.1246,
        0.0304, 0.0287, 0.0215, 0.0125, 0.0567, 0.0151], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,438][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.0185, 0.0667, 0.0076, 0.0273, 0.0090, 0.0423, 0.1512, 0.1185, 0.1214,
        0.0753, 0.0941, 0.1051, 0.0756, 0.0425, 0.0094, 0.0353],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,439][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.0004, 0.2611, 0.0153, 0.0768, 0.0060, 0.0287, 0.1684, 0.0568, 0.1136,
        0.0322, 0.0549, 0.0706, 0.0153, 0.0786, 0.0031, 0.0181],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,440][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([0.0190, 0.0390, 0.0203, 0.0241, 0.0159, 0.0284, 0.0806, 0.1261, 0.0523,
        0.1370, 0.0470, 0.0548, 0.1486, 0.1014, 0.0196, 0.0860],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,440][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([1.4085e-01, 4.9019e-07, 5.5264e-06, 4.6613e-07, 1.8191e-07, 3.6066e-05,
        1.3172e-04, 3.6885e-06, 5.7314e-05, 6.0375e-07, 6.9145e-03, 7.8516e-03,
        7.8424e-03, 1.2205e-02, 9.5998e-05, 8.2401e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,440][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0032, 0.1267, 0.0473, 0.0452, 0.0751, 0.0390, 0.0823, 0.0392, 0.0980,
        0.0254, 0.0448, 0.0407, 0.0970, 0.1360, 0.0393, 0.0608],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,441][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0920, 0.0391, 0.0806, 0.0152, 0.0336, 0.0723, 0.0546, 0.0745, 0.0229,
        0.1261, 0.0507, 0.0431, 0.1282, 0.0401, 0.0242, 0.1027],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,441][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([5.1987e-06, 9.2646e-02, 2.9446e-03, 3.7588e-02, 2.5042e-02, 3.4904e-02,
        2.0595e-01, 4.5454e-02, 2.3977e-01, 7.1742e-02, 5.3857e-02, 8.9554e-02,
        6.3612e-03, 7.3933e-02, 1.3172e-02, 7.0792e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,442][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0422, 0.0338, 0.0108, 0.0307, 0.0030, 0.0674, 0.2260, 0.0866, 0.0904,
        0.0651, 0.0470, 0.0427, 0.0544, 0.0757, 0.0015, 0.1226],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,442][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0024, 0.0276, 0.0073, 0.0512, 0.0152, 0.0838, 0.1512, 0.0598, 0.1373,
        0.0498, 0.1381, 0.1407, 0.0381, 0.0606, 0.0023, 0.0345],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,443][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([2.3768e-06, 8.7177e-02, 2.2488e-03, 1.7632e-02, 2.2830e-02, 3.4147e-02,
        1.3492e-01, 3.5499e-02, 2.5710e-01, 7.9311e-02, 1.0446e-01, 1.2395e-01,
        1.7872e-02, 5.2566e-02, 1.9007e-02, 1.1274e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,446][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([3.4487e-02, 3.6038e-06, 9.3467e-06, 4.3110e-06, 1.0028e-06, 2.3094e-04,
        9.8466e-04, 5.1052e-05, 6.3400e-04, 1.3584e-05, 4.9168e-02, 4.4250e-02,
        2.2276e-02, 2.2568e-02, 1.4239e-04, 8.2518e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,449][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.7907e-04, 1.2012e-01, 7.2989e-03, 1.5321e-01, 1.0985e-02, 3.7304e-02,
        2.1235e-01, 1.1239e-01, 1.9338e-01, 1.1727e-02, 2.6028e-02, 2.9006e-02,
        6.5926e-03, 6.8234e-02, 3.9437e-03, 7.2549e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,454][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0545, 0.0649, 0.0062, 0.0326, 0.0064, 0.0290, 0.1131, 0.1013, 0.1259,
        0.0873, 0.0722, 0.0780, 0.0631, 0.0462, 0.0075, 0.0173, 0.0944],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,456][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([2.1078e-04, 2.2256e-01, 1.0521e-02, 7.4982e-02, 5.0376e-03, 1.8543e-02,
        1.5275e-01, 8.1443e-02, 1.3245e-01, 4.3386e-02, 5.1005e-02, 5.8279e-02,
        8.4033e-03, 5.9931e-02, 3.0501e-03, 1.1453e-02, 6.6000e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,456][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0625, 0.0440, 0.0423, 0.0392, 0.0305, 0.0336, 0.0798, 0.1131, 0.0538,
        0.1309, 0.0425, 0.0335, 0.0885, 0.0710, 0.0400, 0.0428, 0.0517],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,457][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.1965e-02, 1.3998e-07, 3.3086e-06, 6.7193e-07, 3.0646e-07, 3.2817e-05,
        1.1357e-04, 1.1932e-05, 1.1076e-04, 2.9658e-06, 5.0780e-03, 2.5624e-03,
        5.7947e-03, 1.2525e-02, 1.6779e-04, 3.1320e-01, 5.8843e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,457][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0019, 0.2011, 0.0236, 0.0434, 0.0450, 0.0233, 0.0579, 0.0360, 0.1388,
        0.0169, 0.0420, 0.0505, 0.0588, 0.1565, 0.0355, 0.0242, 0.0446],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,457][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0760, 0.0296, 0.0655, 0.0155, 0.0289, 0.0536, 0.0630, 0.0710, 0.0279,
        0.1445, 0.0454, 0.0494, 0.0989, 0.0419, 0.0239, 0.0557, 0.1093],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,458][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([7.0092e-06, 9.8806e-02, 4.2788e-03, 4.4853e-02, 2.0603e-02, 3.2576e-02,
        1.4624e-01, 6.3800e-02, 1.6179e-01, 1.2859e-01, 4.8730e-02, 8.5507e-02,
        4.3005e-03, 8.9996e-02, 9.3918e-03, 8.6051e-03, 5.1936e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,458][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0515, 0.0193, 0.0075, 0.0274, 0.0036, 0.0540, 0.2104, 0.0894, 0.0956,
        0.0943, 0.0263, 0.0275, 0.0308, 0.1070, 0.0023, 0.0597, 0.0935],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,459][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0013, 0.0393, 0.0085, 0.0727, 0.0194, 0.0989, 0.1112, 0.1029, 0.0937,
        0.0581, 0.1249, 0.0790, 0.0443, 0.0748, 0.0029, 0.0223, 0.0458],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,460][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.2136e-07, 6.4427e-02, 1.2707e-03, 2.0855e-02, 1.9602e-02, 2.0261e-02,
        1.1051e-01, 5.8905e-02, 3.2056e-01, 8.8674e-02, 6.8486e-02, 9.0753e-02,
        7.9334e-03, 4.8667e-02, 1.9602e-02, 6.4132e-03, 5.3082e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,462][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.7616e-02, 1.2107e-06, 4.5570e-06, 3.6239e-06, 1.0260e-06, 1.1935e-04,
        6.5433e-04, 1.4588e-04, 1.3248e-03, 7.4250e-05, 3.4168e-02, 1.8983e-02,
        1.7866e-02, 2.2301e-02, 2.0027e-04, 2.7072e-01, 6.1581e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,468][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0004, 0.0886, 0.0126, 0.1273, 0.0172, 0.0375, 0.1597, 0.1992, 0.1559,
        0.0421, 0.0351, 0.0250, 0.0089, 0.0527, 0.0050, 0.0071, 0.0257],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,472][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.0087, 0.0798, 0.0082, 0.0441, 0.0072, 0.0353, 0.0955, 0.1185, 0.0928,
        0.0471, 0.1015, 0.1039, 0.0514, 0.0344, 0.0065, 0.0305, 0.0951, 0.0396],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,473][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([1.3506e-04, 1.9465e-01, 9.1844e-03, 4.7519e-02, 4.3088e-03, 2.2308e-02,
        1.4352e-01, 6.3034e-02, 1.2051e-01, 4.1524e-02, 5.5761e-02, 7.4839e-02,
        1.0209e-02, 6.1346e-02, 2.7110e-03, 1.5622e-02, 1.0821e-01, 2.4607e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,473][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([0.0187, 0.0502, 0.0230, 0.0297, 0.0175, 0.0263, 0.0662, 0.1092, 0.0602,
        0.0943, 0.0578, 0.0610, 0.1063, 0.0657, 0.0353, 0.0386, 0.0553, 0.0847],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,474][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([2.1201e-03, 1.9585e-07, 1.6163e-06, 4.1946e-07, 4.2904e-07, 6.5260e-06,
        2.4707e-05, 1.2302e-06, 1.7201e-05, 9.2976e-07, 4.0328e-03, 4.7046e-03,
        3.2808e-03, 1.7165e-03, 4.0278e-04, 4.7351e-01, 5.0144e-01, 8.7338e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,474][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0009, 0.1113, 0.0233, 0.0342, 0.0457, 0.0283, 0.0475, 0.0446, 0.0878,
        0.0283, 0.0474, 0.0427, 0.1129, 0.1524, 0.0383, 0.0518, 0.0345, 0.0680],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,474][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0323, 0.0383, 0.0819, 0.0157, 0.0341, 0.0541, 0.0396, 0.0579, 0.0173,
        0.1238, 0.0471, 0.0422, 0.1114, 0.0257, 0.0197, 0.0747, 0.0616, 0.1225],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,475][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([4.4905e-06, 1.6486e-01, 3.1944e-03, 4.3104e-02, 1.3755e-02, 2.5360e-02,
        1.2240e-01, 4.0256e-02, 1.4507e-01, 8.5668e-02, 5.6399e-02, 7.8743e-02,
        5.2107e-03, 1.3263e-01, 6.2281e-03, 7.2867e-03, 5.8812e-02, 1.1014e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,475][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0199, 0.0275, 0.0096, 0.0259, 0.0061, 0.0514, 0.1084, 0.0484, 0.0526,
        0.0717, 0.0443, 0.0497, 0.0599, 0.0662, 0.0038, 0.1230, 0.1321, 0.0993],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,479][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.0022, 0.0426, 0.0082, 0.0478, 0.0207, 0.0672, 0.1046, 0.0899, 0.0911,
        0.0624, 0.1292, 0.1004, 0.0359, 0.0537, 0.0047, 0.0336, 0.0684, 0.0375],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,482][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([3.1176e-07, 1.3621e-01, 9.7929e-04, 1.8690e-02, 1.4799e-02, 2.1641e-02,
        9.9775e-02, 4.7771e-02, 2.5785e-01, 7.8878e-02, 7.7964e-02, 9.1214e-02,
        9.4416e-03, 7.8428e-02, 9.2225e-03, 5.9190e-03, 4.5768e-02, 5.4527e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,485][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([2.2146e-04, 9.4422e-07, 1.9045e-06, 2.2685e-06, 1.0208e-06, 2.8333e-05,
        1.2336e-04, 1.3558e-05, 1.6327e-04, 1.9576e-05, 2.6639e-02, 2.2138e-02,
        9.5408e-03, 5.1810e-03, 2.6965e-04, 4.2357e-01, 4.9002e-01, 2.2058e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,489][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([1.1480e-04, 1.4803e-01, 5.4861e-03, 1.0693e-01, 1.7870e-02, 4.8463e-02,
        1.5194e-01, 1.6643e-01, 1.5661e-01, 2.3713e-02, 2.4929e-02, 1.8865e-02,
        6.3891e-03, 6.8847e-02, 6.2516e-03, 1.0064e-02, 3.2454e-02, 6.6125e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,489][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0562, 0.0370, 0.0064, 0.0244, 0.0064, 0.0243, 0.0848, 0.0644, 0.0835,
        0.0984, 0.0621, 0.0823, 0.0699, 0.0431, 0.0072, 0.0170, 0.0780, 0.0343,
        0.1203], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,490][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([1.3850e-04, 2.0356e-01, 1.1265e-02, 6.2777e-02, 3.3128e-03, 1.7547e-02,
        1.4123e-01, 4.3668e-02, 1.2921e-01, 3.5836e-02, 5.2467e-02, 5.7559e-02,
        7.0539e-03, 7.6678e-02, 2.0181e-03, 1.0126e-02, 7.4105e-02, 1.6137e-02,
        5.5311e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,490][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0408, 0.0355, 0.0254, 0.0290, 0.0194, 0.0278, 0.0764, 0.0743, 0.0471,
        0.0851, 0.0449, 0.0417, 0.0697, 0.0680, 0.0275, 0.0385, 0.0582, 0.1019,
        0.0888], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,490][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([1.4387e-02, 1.7445e-08, 3.5181e-07, 3.1861e-08, 2.1890e-08, 3.6534e-06,
        1.3841e-05, 3.4061e-07, 5.9256e-06, 9.2195e-08, 8.4552e-04, 6.9172e-04,
        1.0505e-03, 2.3628e-03, 1.7334e-05, 1.5189e-01, 3.9019e-01, 4.2739e-03,
        4.3427e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,491][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0030, 0.1227, 0.0231, 0.0337, 0.0486, 0.0230, 0.0632, 0.0330, 0.0754,
        0.0160, 0.0292, 0.0393, 0.0380, 0.1526, 0.0354, 0.0230, 0.0410, 0.0542,
        0.1456], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,491][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0739, 0.0204, 0.0584, 0.0119, 0.0219, 0.0418, 0.0424, 0.0641, 0.0193,
        0.0996, 0.0281, 0.0290, 0.0771, 0.0345, 0.0225, 0.0531, 0.0820, 0.1451,
        0.0750], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,492][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([5.7761e-06, 6.1345e-02, 3.4479e-03, 3.1600e-02, 2.0703e-02, 2.8882e-02,
        1.5987e-01, 4.2923e-02, 1.5375e-01, 8.8275e-02, 4.7191e-02, 7.0696e-02,
        3.8660e-03, 7.9141e-02, 9.8960e-03, 7.3071e-03, 5.7429e-02, 9.8664e-03,
        1.2380e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,495][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0384, 0.0089, 0.0033, 0.0145, 0.0013, 0.0367, 0.1789, 0.0621, 0.0608,
        0.0330, 0.0248, 0.0315, 0.0332, 0.0944, 0.0010, 0.0711, 0.1254, 0.0625,
        0.1183], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,500][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0019, 0.0274, 0.0108, 0.0440, 0.0236, 0.0780, 0.1114, 0.0920, 0.0890,
        0.0680, 0.1121, 0.0662, 0.0430, 0.0631, 0.0031, 0.0237, 0.0494, 0.0244,
        0.0688], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,503][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([8.1167e-07, 7.4632e-02, 1.1670e-03, 2.1291e-02, 1.2055e-02, 1.5846e-02,
        1.1480e-01, 3.6907e-02, 3.3401e-01, 5.2816e-02, 5.5903e-02, 6.4584e-02,
        4.2969e-03, 3.6465e-02, 9.4368e-03, 3.8455e-03, 4.5877e-02, 4.0612e-03,
        1.1200e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,505][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([6.6003e-03, 1.4324e-07, 6.4794e-07, 2.5132e-07, 7.7436e-08, 1.5705e-05,
        7.8305e-05, 6.0498e-06, 8.0954e-05, 2.6824e-06, 6.7513e-03, 4.3484e-03,
        3.7988e-03, 4.1270e-03, 1.8526e-05, 1.0036e-01, 2.5401e-01, 8.1192e-03,
        6.1168e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,506][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0003, 0.0698, 0.0078, 0.1055, 0.0111, 0.0299, 0.2210, 0.1406, 0.1676,
        0.0248, 0.0309, 0.0230, 0.0036, 0.0591, 0.0033, 0.0058, 0.0311, 0.0044,
        0.0602], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,507][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:23,508][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2616],
        [1588],
        [  74],
        [ 189],
        [  10],
        [   7],
        [  13],
        [  18],
        [  63],
        [  18],
        [  13],
        [  16],
        [  16],
        [  28],
        [  14],
        [   7],
        [   7],
        [   3],
        [  15]], device='cuda:0')
[2024-07-24 10:27:23,509][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2041],
        [1181],
        [  66],
        [ 114],
        [  10],
        [   4],
        [   5],
        [  10],
        [  34],
        [  18],
        [   7],
        [  11],
        [   8],
        [  14],
        [  12],
        [   4],
        [   6],
        [   3],
        [  10]], device='cuda:0')
[2024-07-24 10:27:23,510][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[22151],
        [ 4605],
        [ 6314],
        [ 6888],
        [ 5123],
        [ 6561],
        [ 9749],
        [20286],
        [17372],
        [15833],
        [16830],
        [15589],
        [16876],
        [17791],
        [15361],
        [17718],
        [17498],
        [17739],
        [19264]], device='cuda:0')
[2024-07-24 10:27:23,513][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[15733],
        [ 8112],
        [ 8792],
        [12159],
        [11093],
        [11673],
        [18176],
        [18615],
        [23725],
        [17124],
        [18777],
        [16041],
        [15337],
        [16654],
        [16042],
        [15582],
        [16957],
        [16810],
        [15907]], device='cuda:0')
[2024-07-24 10:27:23,516][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[26986],
        [38684],
        [47801],
        [46007],
        [48951],
        [48221],
        [45268],
        [39954],
        [40996],
        [29524],
        [28599],
        [29188],
        [28797],
        [32423],
        [34689],
        [33523],
        [36070],
        [35904],
        [35430]], device='cuda:0')
[2024-07-24 10:27:23,518][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[33916],
        [32223],
        [27608],
        [32532],
        [30773],
        [35431],
        [37213],
        [38952],
        [37227],
        [42869],
        [35580],
        [36489],
        [38181],
        [41111],
        [38212],
        [44195],
        [43862],
        [44002],
        [43135]], device='cuda:0')
[2024-07-24 10:27:23,521][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[7680],
        [7792],
        [5216],
        [5536],
        [2411],
        [3863],
        [3848],
        [3744],
        [4066],
        [4762],
        [4715],
        [4515],
        [4333],
        [2567],
        [2433],
        [2522],
        [2595],
        [2436],
        [2291]], device='cuda:0')
[2024-07-24 10:27:23,524][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[38416],
        [28489],
        [22760],
        [24449],
        [35274],
        [37492],
        [39991],
        [44631],
        [40694],
        [44415],
        [44280],
        [44396],
        [44724],
        [44126],
        [44641],
        [44775],
        [45146],
        [43332],
        [43291]], device='cuda:0')
[2024-07-24 10:27:23,526][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[44820],
        [39347],
        [41758],
        [39222],
        [33565],
        [37286],
        [34672],
        [33844],
        [38346],
        [39257],
        [39111],
        [38830],
        [39119],
        [36343],
        [36594],
        [37465],
        [36632],
        [36065],
        [36648]], device='cuda:0')
[2024-07-24 10:27:23,527][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[8161],
        [7676],
        [7535],
        [8107],
        [8195],
        [5239],
        [3168],
        [2269],
        [2232],
        [3654],
        [3442],
        [3639],
        [4808],
        [5566],
        [6618],
        [4574],
        [4488],
        [4245],
        [3446]], device='cuda:0')
[2024-07-24 10:27:23,528][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[  893],
        [ 4503],
        [20512],
        [22373],
        [ 7997],
        [16043],
        [13212],
        [ 8155],
        [11528],
        [12804],
        [14779],
        [16780],
        [17220],
        [17829],
        [17721],
        [17112],
        [16141],
        [17169],
        [16929]], device='cuda:0')
[2024-07-24 10:27:23,529][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[48559],
        [49340],
        [49686],
        [50020],
        [50203],
        [50216],
        [50226],
        [50213],
        [50232],
        [50206],
        [50235],
        [50232],
        [50234],
        [50240],
        [50243],
        [50241],
        [50238],
        [50238],
        [50245]], device='cuda:0')
[2024-07-24 10:27:23,531][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[11393],
        [ 9393],
        [ 9739],
        [14908],
        [15423],
        [25083],
        [25034],
        [26770],
        [24019],
        [10626],
        [27775],
        [28986],
        [27681],
        [24686],
        [27204],
        [21816],
        [23121],
        [22753],
        [21602]], device='cuda:0')
[2024-07-24 10:27:23,533][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[13450],
        [33435],
        [36498],
        [29399],
        [33408],
        [31335],
        [32356],
        [32082],
        [29740],
        [31503],
        [29777],
        [30206],
        [30771],
        [31314],
        [32961],
        [30491],
        [31644],
        [31918],
        [31603]], device='cuda:0')
[2024-07-24 10:27:23,536][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[21334],
        [ 3905],
        [ 2271],
        [ 2395],
        [ 1455],
        [ 2724],
        [ 8867],
        [ 2661],
        [ 2486],
        [ 1352],
        [ 6350],
        [ 2490],
        [ 2443],
        [ 3863],
        [ 1525],
        [ 2277],
        [12995],
        [ 2645],
        [ 7795]], device='cuda:0')
[2024-07-24 10:27:23,538][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[ 4309],
        [39852],
        [40138],
        [39090],
        [39705],
        [40050],
        [39259],
        [41865],
        [41405],
        [39067],
        [35360],
        [34718],
        [35417],
        [37109],
        [37619],
        [36190],
        [35692],
        [36181],
        [35359]], device='cuda:0')
[2024-07-24 10:27:23,541][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14572],
        [21630],
        [20578],
        [16666],
        [18362],
        [17799],
        [18547],
        [16819],
        [16768],
        [19198],
        [19396],
        [20491],
        [21878],
        [21090],
        [20748],
        [21017],
        [21536],
        [23491],
        [23269]], device='cuda:0')
[2024-07-24 10:27:23,544][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[  635],
        [ 3047],
        [10596],
        [ 4958],
        [11603],
        [14258],
        [12910],
        [10620],
        [ 9234],
        [ 9654],
        [10058],
        [10433],
        [11067],
        [ 9702],
        [10766],
        [10662],
        [10542],
        [11062],
        [10836]], device='cuda:0')
[2024-07-24 10:27:23,546][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 590],
        [ 449],
        [ 807],
        [ 395],
        [ 764],
        [ 290],
        [ 813],
        [ 756],
        [1223],
        [ 972],
        [1644],
        [2412],
        [2194],
        [1289],
        [2002],
        [ 976],
        [1314],
        [1451],
        [1701]], device='cuda:0')
[2024-07-24 10:27:23,547][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15395],
        [ 7291],
        [ 9567],
        [12228],
        [19168],
        [16611],
        [19219],
        [24999],
        [23249],
        [20819],
        [23879],
        [32889],
        [38894],
        [34276],
        [35807],
        [38343],
        [34611],
        [40293],
        [37710]], device='cuda:0')
[2024-07-24 10:27:23,548][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[3272],
        [3462],
        [4721],
        [4171],
        [5261],
        [3689],
        [3369],
        [4539],
        [3672],
        [3913],
        [3509],
        [3430],
        [3601],
        [3835],
        [3957],
        [3953],
        [4069],
        [3965],
        [4140]], device='cuda:0')
[2024-07-24 10:27:23,549][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[22446],
        [ 4908],
        [ 3640],
        [ 2323],
        [ 2049],
        [ 1986],
        [ 3260],
        [ 4303],
        [ 3781],
        [ 3949],
        [ 3504],
        [ 3526],
        [ 3611],
        [ 4514],
        [ 3988],
        [ 3797],
        [ 3999],
        [ 4212],
        [ 3330]], device='cuda:0')
[2024-07-24 10:27:23,551][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[15015],
        [14578],
        [14571],
        [20261],
        [16908],
        [37177],
        [37894],
        [40152],
        [39511],
        [41107],
        [39731],
        [39503],
        [38753],
        [39399],
        [31996],
        [38179],
        [40063],
        [38303],
        [39266]], device='cuda:0')
[2024-07-24 10:27:23,553][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[18731],
        [31521],
        [27534],
        [24644],
        [23177],
        [20111],
        [16741],
        [16648],
        [16388],
        [17100],
        [17194],
        [18260],
        [18470],
        [16592],
        [17314],
        [16938],
        [16559],
        [16435],
        [16567]], device='cuda:0')
[2024-07-24 10:27:23,556][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[  698],
        [ 3924],
        [ 4331],
        [ 4734],
        [31510],
        [10749],
        [16777],
        [11799],
        [10051],
        [10903],
        [12885],
        [10713],
        [11586],
        [13278],
        [16737],
        [13522],
        [13125],
        [11057],
        [12468]], device='cuda:0')
[2024-07-24 10:27:23,558][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 2494],
        [33149],
        [34048],
        [12180],
        [16315],
        [ 5755],
        [ 6002],
        [11271],
        [14456],
        [15330],
        [28375],
        [28439],
        [26374],
        [23173],
        [25863],
        [27250],
        [14366],
        [16584],
        [13736]], device='cuda:0')
[2024-07-24 10:27:23,561][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[13391],
        [22297],
        [21313],
        [16373],
        [16865],
        [17754],
        [17121],
        [15285],
        [15677],
        [15609],
        [15907],
        [15796],
        [16045],
        [16167],
        [16055],
        [16411],
        [15837],
        [16025],
        [15426]], device='cuda:0')
[2024-07-24 10:27:23,564][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[49770],
        [47159],
        [44142],
        [47479],
        [43071],
        [45946],
        [45623],
        [43681],
        [44048],
        [44727],
        [43260],
        [41759],
        [40680],
        [41964],
        [40704],
        [41841],
        [42772],
        [41962],
        [42382]], device='cuda:0')
[2024-07-24 10:27:23,566][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31230],
        [48297],
        [44440],
        [49795],
        [46421],
        [47639],
        [40392],
        [48080],
        [48598],
        [47279],
        [46065],
        [46512],
        [47443],
        [47668],
        [44021],
        [46590],
        [39574],
        [46099],
        [42796]], device='cuda:0')
[2024-07-24 10:27:23,567][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011],
        [9011]], device='cuda:0')
[2024-07-24 10:27:23,614][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:23,617][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,621][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,621][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,621][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,622][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,622][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,622][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,623][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,623][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,623][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,624][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,624][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,626][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1631, 0.8369], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,627][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([4.6878e-05, 9.9995e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,636][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0124, 0.9876], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,636][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0034, 0.9966], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,641][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9793, 0.0207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,643][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9279, 0.0721], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,643][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0079, 0.9921], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,643][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1069, 0.8931], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,643][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0654, 0.9346], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,644][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7492, 0.2508], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,644][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4896, 0.5104], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,644][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0162, 0.9838], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,645][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.0276, 0.7385, 0.2339], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,645][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([2.4280e-05, 9.9071e-01, 9.2641e-03], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,645][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.0061, 0.8867, 0.1073], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,645][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.0019, 0.7277, 0.2704], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,646][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.9011, 0.0807, 0.0182], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,647][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([7.7425e-02, 9.2205e-01, 5.2520e-04], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,651][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.0103, 0.8336, 0.1561], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,657][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.0074, 0.4114, 0.5812], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,661][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.0050, 0.4499, 0.5452], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,661][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.8099, 0.0557, 0.1344], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,661][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.1231, 0.3296, 0.5474], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,662][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.0017, 0.8379, 0.1604], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,662][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0226, 0.0839, 0.0385, 0.8551], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,662][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.2901e-04, 7.1411e-01, 1.4010e-02, 2.7176e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,663][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0056, 0.1177, 0.0459, 0.8309], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,663][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0177, 0.3048, 0.3531, 0.3244], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,663][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.9199, 0.0228, 0.0121, 0.0451], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,664][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([6.6350e-01, 3.3401e-01, 6.3264e-05, 2.4265e-03], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,669][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0286, 0.4372, 0.0902, 0.4440], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,674][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0690, 0.2765, 0.4017, 0.2528], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,676][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0154, 0.1938, 0.2449, 0.5459], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,677][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3288, 0.0510, 0.4500, 0.1703], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,677][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([2.3311e-01, 1.3466e-02, 7.5303e-01, 3.9186e-04], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,677][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0163, 0.1643, 0.2917, 0.5278], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:23,677][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0051, 0.1072, 0.0340, 0.4877, 0.3659], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,678][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([2.8117e-05, 7.7524e-01, 4.2220e-03, 2.0409e-01, 1.6424e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,678][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0025, 0.2561, 0.0343, 0.6288, 0.0784], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,678][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0020, 0.5195, 0.1132, 0.2641, 0.1012], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,679][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.4843, 0.1462, 0.0351, 0.2454, 0.0890], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,679][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([4.3970e-02, 9.4070e-01, 6.8701e-04, 1.4566e-02, 8.0405e-05],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,679][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0087, 0.5367, 0.0489, 0.3351, 0.0706], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,683][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0102, 0.3506, 0.3025, 0.2337, 0.1030], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,688][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.0080, 0.1932, 0.1444, 0.3788, 0.2756], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,692][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.4496, 0.0033, 0.0105, 0.0095, 0.5271], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,693][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.0110, 0.0207, 0.2053, 0.0016, 0.7614], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,693][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0004, 0.4038, 0.1279, 0.3021, 0.1657], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:23,693][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0053, 0.0339, 0.0184, 0.2241, 0.2457, 0.4725], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,694][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([1.8740e-05, 6.9038e-01, 3.5691e-03, 2.2018e-01, 6.1667e-03, 7.9685e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,694][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0045, 0.1503, 0.0409, 0.6127, 0.0758, 0.1158], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,694][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0026, 0.4601, 0.1368, 0.2305, 0.0404, 0.1297], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,695][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.4627, 0.1772, 0.0465, 0.1735, 0.0727, 0.0674], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,695][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([9.9462e-01, 4.6746e-03, 8.5694e-06, 1.1324e-04, 1.1526e-06, 5.8620e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,698][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0047, 0.3872, 0.0327, 0.2307, 0.0193, 0.3254], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,702][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0128, 0.1919, 0.1966, 0.1177, 0.0340, 0.4470], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,708][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0070, 0.1131, 0.2064, 0.3231, 0.1718, 0.1786], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,708][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([3.5547e-02, 2.1473e-04, 4.0025e-03, 2.2831e-03, 9.4037e-01, 1.7582e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,709][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0031, 0.0199, 0.1057, 0.0046, 0.8588, 0.0078], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,709][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0012, 0.2249, 0.1653, 0.3053, 0.0889, 0.2143], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:23,709][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0016, 0.0065, 0.0033, 0.0494, 0.0489, 0.1137, 0.7766],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,710][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([7.4338e-06, 1.7502e-01, 1.5506e-03, 1.1507e-01, 5.8111e-03, 4.0264e-02,
        6.6227e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,710][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0026, 0.0858, 0.0282, 0.3927, 0.0664, 0.0773, 0.3470],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,710][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0011, 0.1019, 0.0602, 0.1543, 0.0333, 0.0845, 0.5648],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,711][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.8341, 0.0107, 0.0114, 0.0320, 0.0352, 0.0155, 0.0611],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,711][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.4967e-01, 2.4727e-02, 5.9118e-05, 1.3764e-03, 1.1637e-05, 4.5330e-03,
        1.9627e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,714][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0014, 0.1457, 0.0075, 0.1491, 0.0058, 0.1325, 0.5579],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,719][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0418, 0.1246, 0.1004, 0.0955, 0.0272, 0.1696, 0.4409],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,724][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0048, 0.0807, 0.1043, 0.2576, 0.1507, 0.1152, 0.2868],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,725][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([3.1957e-02, 3.4143e-04, 4.2875e-03, 2.2435e-03, 8.1695e-01, 1.4330e-02,
        1.2989e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,725][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([1.7335e-03, 4.2190e-04, 1.3623e-02, 2.0308e-05, 9.8379e-01, 2.9600e-04,
        1.1773e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,725][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([2.1756e-04, 1.9247e-02, 1.7309e-02, 4.5411e-02, 2.2451e-02, 2.9070e-02,
        8.6629e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:23,725][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.0048, 0.0074, 0.0051, 0.0434, 0.0396, 0.0553, 0.3350, 0.5094],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,726][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([7.2404e-06, 2.4896e-01, 1.2143e-03, 8.6041e-02, 4.2837e-03, 2.7502e-02,
        6.0389e-01, 2.8107e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,726][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([0.0011, 0.0663, 0.0152, 0.2968, 0.0364, 0.0536, 0.2442, 0.2864],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,726][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([2.2501e-04, 2.5090e-01, 2.2769e-02, 1.2952e-01, 1.0624e-02, 4.5394e-02,
        4.2635e-01, 1.1421e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,727][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([0.6375, 0.0542, 0.0367, 0.0776, 0.0606, 0.0149, 0.0570, 0.0615],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,728][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([9.3319e-01, 1.7359e-02, 1.4829e-04, 1.1644e-03, 2.3048e-05, 2.0485e-03,
        2.0339e-02, 2.5724e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,732][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([0.0007, 0.1584, 0.0040, 0.1019, 0.0032, 0.0820, 0.4854, 0.1643],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,738][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0066, 0.0927, 0.0709, 0.0650, 0.0130, 0.1220, 0.3124, 0.3174],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,740][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([0.0035, 0.0468, 0.0667, 0.1939, 0.1094, 0.0720, 0.2504, 0.2574],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,741][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([9.2853e-02, 1.4560e-07, 4.4351e-06, 2.3436e-06, 2.7582e-03, 2.6506e-06,
        9.3657e-05, 9.0429e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,741][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.0048, 0.0057, 0.0892, 0.0010, 0.8612, 0.0054, 0.0134, 0.0193],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,741][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([3.5938e-05, 6.6144e-02, 1.8654e-02, 5.1288e-02, 1.1796e-02, 2.3320e-02,
        7.7550e-01, 5.3265e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:23,741][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.0012, 0.0029, 0.0013, 0.0231, 0.0205, 0.0424, 0.3277, 0.3604, 0.2205],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,742][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ of] are: tensor([1.5336e-05, 6.9872e-02, 1.6425e-03, 4.0726e-02, 4.2280e-03, 2.4822e-02,
        4.4748e-01, 4.6351e-02, 3.6486e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,742][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ of] are: tensor([0.0012, 0.0400, 0.0128, 0.2246, 0.0326, 0.0372, 0.2018, 0.2567, 0.1932],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,742][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.0026, 0.0992, 0.0453, 0.0962, 0.0218, 0.0550, 0.4205, 0.1020, 0.1574],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,743][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.6881, 0.0095, 0.0082, 0.0236, 0.0171, 0.0152, 0.0359, 0.0772, 0.1253],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,743][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ of] are: tensor([8.7830e-01, 2.4510e-02, 4.4411e-05, 1.0308e-03, 1.8294e-05, 2.9642e-03,
        4.2267e-02, 3.5680e-02, 1.5190e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,746][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ of] are: tensor([0.0017, 0.0725, 0.0061, 0.0633, 0.0028, 0.0766, 0.2937, 0.1174, 0.3659],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,752][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0123, 0.0819, 0.0779, 0.0778, 0.0154, 0.1403, 0.2858, 0.1434, 0.1652],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,756][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ of] are: tensor([0.0081, 0.0549, 0.0703, 0.1271, 0.0926, 0.0519, 0.1677, 0.1873, 0.2400],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,757][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ of] are: tensor([9.6122e-04, 2.1214e-06, 2.5619e-05, 7.9658e-06, 2.9104e-03, 2.8384e-05,
        2.8056e-04, 9.9019e-01, 5.5970e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,757][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ of] are: tensor([3.5719e-03, 7.0696e-04, 4.2058e-02, 4.2521e-05, 9.4191e-01, 8.1326e-04,
        1.2730e-03, 8.6361e-03, 9.8684e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,757][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ of] are: tensor([5.4496e-04, 1.3253e-02, 2.2298e-02, 3.1754e-02, 7.2497e-03, 2.1992e-02,
        5.7049e-01, 5.1574e-02, 2.8084e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:23,758][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.0005, 0.0019, 0.0013, 0.0107, 0.0157, 0.0223, 0.1430, 0.3176, 0.1225,
        0.3646], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,758][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([6.0883e-06, 9.2000e-02, 9.0982e-04, 3.8807e-02, 2.5981e-03, 1.7026e-02,
        4.1841e-01, 3.6209e-02, 3.1044e-01, 8.3592e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,758][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0008, 0.0489, 0.0070, 0.1287, 0.0186, 0.0290, 0.1350, 0.2225, 0.1261,
        0.2834], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,759][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([1.4846e-04, 1.6796e-01, 2.1463e-02, 6.2026e-02, 1.4969e-02, 2.3903e-02,
        2.5855e-01, 1.0688e-01, 1.9290e-01, 1.5120e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,759][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([0.6148, 0.0371, 0.0159, 0.0405, 0.0270, 0.0143, 0.0443, 0.0552, 0.1407,
        0.0102], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,760][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([6.5802e-01, 1.1664e-01, 4.7829e-04, 4.3269e-03, 7.6015e-05, 1.2463e-02,
        9.9965e-02, 6.4926e-02, 3.4018e-02, 9.0885e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,766][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([0.0004, 0.0755, 0.0025, 0.0419, 0.0019, 0.0314, 0.1691, 0.0686, 0.3588,
        0.2498], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,771][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0044, 0.0810, 0.0502, 0.0499, 0.0150, 0.1533, 0.1892, 0.2499, 0.0858,
        0.1214], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,772][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([0.0013, 0.0335, 0.0292, 0.0900, 0.0628, 0.0700, 0.1377, 0.1505, 0.2079,
        0.2172], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,773][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([1.1248e-02, 9.1622e-08, 2.5559e-06, 1.2109e-06, 1.4190e-03, 1.6319e-06,
        5.6229e-05, 6.1696e-01, 4.0852e-03, 3.6622e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,773][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([2.3122e-05, 7.0698e-05, 3.5240e-04, 8.6667e-06, 7.0152e-03, 2.4399e-05,
        2.8684e-05, 9.5037e-05, 6.6226e-05, 9.9232e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,773][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([1.6435e-05, 3.0711e-02, 8.1363e-03, 1.5892e-02, 1.0944e-02, 9.8840e-03,
        3.6991e-01, 2.0753e-02, 3.9015e-01, 1.4360e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:23,774][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0004, 0.0010, 0.0009, 0.0087, 0.0113, 0.0183, 0.1316, 0.2166, 0.1040,
        0.3666, 0.1407], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,774][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ at] are: tensor([2.1150e-06, 5.9296e-02, 8.3115e-04, 3.6595e-02, 4.8761e-03, 2.0089e-02,
        4.4183e-01, 2.1545e-02, 2.5552e-01, 9.2263e-02, 6.7159e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,774][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ at] are: tensor([0.0003, 0.0224, 0.0056, 0.1493, 0.0171, 0.0287, 0.1311, 0.1962, 0.1377,
        0.2585, 0.0531], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,775][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.0005, 0.1100, 0.0238, 0.0983, 0.0113, 0.0323, 0.3054, 0.0868, 0.1819,
        0.0711, 0.0785], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,775][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.3136, 0.0282, 0.0100, 0.0582, 0.0227, 0.0255, 0.0970, 0.0989, 0.2526,
        0.0143, 0.0789], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,776][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ at] are: tensor([5.8198e-01, 1.0913e-01, 1.3467e-05, 4.3380e-04, 1.0012e-06, 3.7946e-03,
        1.8276e-02, 3.9273e-03, 3.0642e-03, 3.0149e-04, 2.7908e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,780][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ at] are: tensor([1.3445e-04, 5.0754e-02, 2.0344e-03, 3.6992e-02, 1.5530e-03, 4.0139e-02,
        2.3081e-01, 5.1575e-02, 2.6400e-01, 1.3843e-01, 1.8358e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,785][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0051, 0.0696, 0.0549, 0.0740, 0.0110, 0.1085, 0.2877, 0.1504, 0.0937,
        0.0476, 0.0974], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,788][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0039, 0.0350, 0.0503, 0.0945, 0.0434, 0.0412, 0.0963, 0.1081, 0.1737,
        0.1159, 0.2378], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,789][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.3205e-02, 3.1473e-06, 4.9371e-05, 4.7229e-06, 2.7213e-03, 3.5134e-05,
        2.1166e-04, 5.1055e-01, 2.3839e-03, 1.4811e-01, 3.2273e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,789][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ at] are: tensor([1.3191e-05, 5.1132e-06, 2.9030e-04, 5.2322e-07, 4.9793e-03, 9.7838e-06,
        2.4436e-05, 5.2811e-05, 9.5248e-06, 9.9461e-01, 2.4187e-06],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,789][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ at] are: tensor([1.6140e-04, 9.0113e-03, 3.1251e-03, 1.5750e-02, 4.1472e-03, 1.3551e-02,
        3.0935e-01, 2.5437e-02, 4.2630e-01, 8.3747e-02, 1.0941e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:23,790][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.0003, 0.0012, 0.0007, 0.0067, 0.0076, 0.0151, 0.0832, 0.1791, 0.0779,
        0.2890, 0.1112, 0.2281], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,790][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ the] are: tensor([1.8746e-06, 6.5280e-02, 6.0916e-04, 4.5496e-02, 1.8370e-03, 8.9064e-03,
        3.6413e-01, 2.0712e-02, 3.1446e-01, 3.0822e-02, 3.1719e-02, 1.1602e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,790][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ the] are: tensor([0.0004, 0.0289, 0.0077, 0.1739, 0.0149, 0.0289, 0.1342, 0.1713, 0.1357,
        0.2076, 0.0483, 0.0482], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,791][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ the] are: tensor([2.5855e-04, 1.0656e-01, 1.6195e-02, 1.0487e-01, 1.0351e-02, 2.0452e-02,
        2.9287e-01, 8.5666e-02, 1.8025e-01, 4.7140e-02, 5.3626e-02, 8.1772e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,794][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.3771, 0.0154, 0.0078, 0.0423, 0.0220, 0.0138, 0.1046, 0.0681, 0.2596,
        0.0068, 0.0617, 0.0207], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,796][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ the] are: tensor([8.1840e-01, 2.4745e-02, 2.3102e-06, 1.0167e-04, 1.0386e-07, 9.7741e-04,
        1.9566e-03, 4.6842e-04, 6.4064e-04, 2.9598e-05, 8.9970e-02, 6.2710e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,800][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ the] are: tensor([1.1525e-04, 6.5000e-02, 1.7720e-03, 5.0643e-02, 1.0359e-03, 2.7341e-02,
        1.9651e-01, 4.6043e-02, 3.0628e-01, 1.2224e-01, 1.1457e-01, 6.8455e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,804][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0035, 0.0568, 0.0387, 0.0635, 0.0095, 0.0810, 0.2883, 0.1546, 0.1509,
        0.0356, 0.0608, 0.0569], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,805][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0027, 0.0270, 0.0455, 0.0845, 0.0341, 0.0355, 0.0663, 0.0861, 0.1594,
        0.0913, 0.1533, 0.2143], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,805][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ the] are: tensor([2.4288e-02, 1.0530e-06, 1.4094e-05, 1.2488e-06, 8.3730e-04, 6.3571e-06,
        2.9935e-05, 6.5723e-02, 4.6696e-04, 1.6953e-02, 1.2871e-01, 7.6297e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,805][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ the] are: tensor([2.0157e-06, 2.9355e-06, 3.2046e-05, 9.2018e-08, 2.1209e-03, 1.2385e-06,
        5.4017e-07, 1.2441e-05, 1.9335e-06, 9.9783e-01, 2.5485e-07, 3.1338e-08],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,806][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ the] are: tensor([3.2295e-05, 1.0527e-02, 4.0842e-03, 1.9228e-02, 7.2955e-03, 8.3896e-03,
        3.3074e-01, 2.2497e-02, 4.1165e-01, 5.3902e-02, 8.0452e-02, 5.1204e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:23,806][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.0003, 0.0024, 0.0018, 0.0114, 0.0136, 0.0171, 0.1019, 0.1689, 0.0840,
        0.1691, 0.1032, 0.1734, 0.1528], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,806][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ store] are: tensor([1.4292e-06, 9.8185e-02, 6.7495e-04, 3.8526e-02, 2.4321e-03, 6.5663e-03,
        2.8396e-01, 1.1713e-02, 3.2885e-01, 2.9490e-02, 4.5580e-02, 1.4747e-01,
        6.5546e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,807][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ store] are: tensor([0.0003, 0.0323, 0.0072, 0.1146, 0.0133, 0.0243, 0.1159, 0.1998, 0.1463,
        0.1824, 0.0639, 0.0549, 0.0449], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,808][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ store] are: tensor([7.8699e-05, 2.2175e-01, 1.1351e-02, 7.6478e-02, 9.9583e-03, 1.0721e-02,
        2.0973e-01, 6.1030e-02, 1.4684e-01, 4.5354e-02, 9.8135e-02, 1.0237e-01,
        6.1947e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,814][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ store] are: tensor([0.1500, 0.0566, 0.0101, 0.0744, 0.0230, 0.0191, 0.1219, 0.0810, 0.3058,
        0.0097, 0.0826, 0.0466, 0.0193], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,816][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ store] are: tensor([5.4732e-01, 6.8299e-03, 2.4505e-06, 7.4953e-05, 8.5210e-08, 6.2466e-04,
        2.5022e-03, 9.0904e-04, 6.9621e-04, 4.6769e-05, 1.8683e-01, 1.9074e-01,
        6.3428e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,820][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ store] are: tensor([7.5059e-05, 6.3929e-02, 2.8418e-03, 3.6525e-02, 2.3857e-03, 2.9575e-02,
        1.3636e-01, 3.2125e-02, 3.0052e-01, 1.2306e-01, 2.0495e-01, 5.8031e-02,
        9.6137e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,820][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0036, 0.0394, 0.0452, 0.0402, 0.0084, 0.0670, 0.1938, 0.2242, 0.0849,
        0.0522, 0.0531, 0.0516, 0.1365], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,821][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ store] are: tensor([0.0021, 0.0244, 0.0344, 0.0623, 0.0238, 0.0375, 0.0669, 0.0766, 0.1264,
        0.0806, 0.1531, 0.2481, 0.0637], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,821][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ store] are: tensor([7.9088e-02, 2.1463e-08, 1.1152e-06, 1.1221e-07, 1.1682e-04, 1.5524e-07,
        2.3627e-06, 2.2508e-03, 8.4585e-05, 5.7102e-04, 3.5532e-03, 3.0807e-02,
        8.8352e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,821][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ store] are: tensor([7.6377e-06, 1.8112e-05, 3.5260e-04, 1.0367e-06, 5.4716e-03, 6.7653e-06,
        4.2759e-05, 1.7022e-05, 1.8015e-05, 9.2311e-01, 5.3287e-06, 1.7611e-06,
        7.0952e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,822][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ store] are: tensor([1.1713e-06, 1.3214e-02, 3.0748e-03, 1.0846e-02, 3.0077e-03, 5.2520e-03,
        4.0336e-01, 6.6525e-03, 3.4290e-01, 3.7829e-02, 9.3722e-02, 7.8773e-02,
        1.3650e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:23,822][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [.] are: tensor([2.1635e-04, 1.4168e-03, 7.3105e-04, 7.6726e-03, 9.3935e-03, 1.5211e-02,
        9.4939e-02, 1.2989e-01, 6.4028e-02, 1.5665e-01, 9.4434e-02, 2.1809e-01,
        1.2351e-01, 8.3830e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,822][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [.] are: tensor([2.4052e-05, 7.5520e-02, 1.7432e-03, 3.7666e-02, 4.2389e-03, 1.2304e-02,
        2.4918e-01, 2.5562e-02, 2.7370e-01, 3.6876e-02, 5.8171e-02, 1.0342e-01,
        1.0880e-02, 1.1071e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,826][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0004, 0.0218, 0.0062, 0.1422, 0.0123, 0.0242, 0.0984, 0.1128, 0.1032,
        0.1580, 0.0628, 0.0434, 0.0426, 0.1717], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,832][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [.] are: tensor([0.0020, 0.1231, 0.0345, 0.0878, 0.0217, 0.0212, 0.2147, 0.1133, 0.1368,
        0.0445, 0.0603, 0.0760, 0.0061, 0.0581], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,836][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.5935, 0.0167, 0.0104, 0.0309, 0.0296, 0.0123, 0.0477, 0.0688, 0.1400,
        0.0058, 0.0198, 0.0081, 0.0056, 0.0108], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,836][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [.] are: tensor([4.6234e-01, 2.8451e-03, 4.6601e-06, 4.3206e-05, 1.0877e-06, 3.9257e-04,
        9.3118e-04, 1.5597e-03, 2.6866e-04, 4.2347e-04, 4.9360e-02, 8.2812e-02,
        1.6000e-01, 2.3901e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,836][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0011, 0.0651, 0.0052, 0.0384, 0.0018, 0.0412, 0.1302, 0.0681, 0.2368,
        0.1158, 0.1588, 0.0582, 0.0065, 0.0728], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,837][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0039, 0.0539, 0.0517, 0.0572, 0.0057, 0.0941, 0.3118, 0.1390, 0.0854,
        0.0290, 0.0446, 0.0465, 0.0421, 0.0352], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,837][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0030, 0.0261, 0.0305, 0.0656, 0.0302, 0.0265, 0.0534, 0.0536, 0.0928,
        0.0574, 0.1275, 0.2694, 0.0508, 0.1133], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,838][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [.] are: tensor([5.1367e-04, 8.7104e-08, 8.3064e-07, 1.2397e-07, 4.3395e-05, 1.7022e-07,
        1.1263e-06, 6.7075e-04, 2.1101e-05, 3.0981e-04, 1.0321e-02, 1.2278e-01,
        8.5997e-01, 5.3625e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,838][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [.] are: tensor([2.0313e-05, 4.9861e-06, 1.3067e-04, 7.7099e-08, 3.3856e-03, 2.9309e-06,
        2.0677e-06, 2.0085e-05, 3.1412e-06, 9.2542e-01, 1.1861e-06, 1.5695e-07,
        7.0910e-02, 1.0121e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,838][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [.] are: tensor([2.2072e-04, 1.2347e-02, 1.1034e-02, 2.8182e-02, 5.3767e-03, 1.6186e-02,
        4.1932e-01, 2.6128e-02, 2.3140e-01, 6.0826e-02, 8.8148e-02, 6.7440e-02,
        2.1660e-03, 3.1218e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:23,839][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.0003, 0.0028, 0.0010, 0.0081, 0.0099, 0.0159, 0.0772, 0.2255, 0.0745,
        0.1265, 0.0951, 0.1760, 0.0961, 0.0541, 0.0370], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,840][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([3.3889e-06, 1.5705e-01, 1.4638e-03, 6.6273e-02, 7.4667e-03, 1.9851e-02,
        2.5093e-01, 3.3281e-02, 2.5881e-01, 4.6947e-02, 2.3368e-02, 7.0733e-02,
        5.7111e-03, 5.7403e-02, 7.0204e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,846][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0004, 0.0735, 0.0086, 0.2246, 0.0164, 0.0296, 0.0843, 0.1296, 0.1009,
        0.1085, 0.0432, 0.0348, 0.0347, 0.1028, 0.0082], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,850][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.0003, 0.2111, 0.0144, 0.0886, 0.0314, 0.0265, 0.1237, 0.1139, 0.1316,
        0.0898, 0.0640, 0.0623, 0.0087, 0.0288, 0.0048], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,852][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0992, 0.0785, 0.0221, 0.1203, 0.0637, 0.0192, 0.0796, 0.0602, 0.1952,
        0.0191, 0.0625, 0.0325, 0.0167, 0.0274, 0.1039], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,852][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([4.3907e-03, 1.8173e-02, 1.4868e-05, 1.5945e-04, 6.8297e-07, 6.7386e-04,
        8.7015e-04, 1.7508e-04, 2.0200e-04, 6.5137e-05, 2.3657e-01, 5.9039e-01,
        1.0094e-01, 4.7335e-02, 3.1578e-05], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,853][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([2.0353e-04, 7.7823e-02, 4.2991e-03, 4.5160e-02, 1.0322e-02, 3.4616e-02,
        1.0780e-01, 3.5944e-02, 3.0315e-01, 1.0198e-01, 1.5600e-01, 6.1894e-02,
        8.2165e-03, 5.0289e-02, 2.3079e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,853][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0008, 0.0409, 0.0443, 0.0402, 0.0171, 0.0963, 0.2191, 0.2268, 0.0717,
        0.0662, 0.0456, 0.0612, 0.0329, 0.0318, 0.0051], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,853][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([0.0014, 0.0167, 0.0172, 0.0431, 0.0245, 0.0353, 0.0335, 0.0672, 0.0853,
        0.0651, 0.1142, 0.3010, 0.0659, 0.0881, 0.0414], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,854][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([4.6837e-02, 1.1253e-07, 9.7730e-07, 1.4519e-07, 3.4505e-05, 8.5344e-08,
        6.2212e-07, 2.2612e-04, 2.1950e-05, 5.6419e-05, 3.7813e-03, 1.7121e-02,
        1.7832e-01, 2.5963e-03, 7.5100e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,854][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([3.0464e-05, 2.9173e-04, 1.1482e-03, 2.0555e-05, 7.3653e-03, 3.3973e-05,
        1.0323e-04, 3.7799e-04, 1.1841e-04, 9.2980e-01, 3.9935e-05, 1.0770e-05,
        5.7334e-02, 5.5265e-04, 2.7771e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,855][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([5.8491e-06, 4.2666e-02, 5.4923e-03, 2.2004e-02, 1.1967e-02, 1.4090e-02,
        2.4478e-01, 1.2345e-02, 2.9140e-01, 5.5293e-02, 1.4484e-01, 1.2029e-01,
        2.8513e-03, 3.0317e-02, 1.6605e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:23,860][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.0003, 0.0013, 0.0013, 0.0063, 0.0104, 0.0144, 0.0770, 0.1427, 0.0622,
        0.1522, 0.0778, 0.1448, 0.1231, 0.0613, 0.0676, 0.0571],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,863][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([1.7705e-06, 8.1352e-02, 1.0155e-03, 4.6638e-02, 5.1678e-03, 9.6269e-03,
        1.9707e-01, 1.5948e-02, 2.9901e-01, 2.2734e-02, 5.9053e-02, 1.6568e-01,
        1.2926e-02, 8.1592e-02, 8.6486e-04, 1.3102e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,868][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([0.0004, 0.0337, 0.0086, 0.1378, 0.0138, 0.0275, 0.1115, 0.1261, 0.1083,
        0.1316, 0.0511, 0.0458, 0.0411, 0.1122, 0.0168, 0.0338],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,868][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([7.4669e-05, 1.6977e-01, 1.0886e-02, 9.8407e-02, 1.1861e-02, 1.3372e-02,
        1.8008e-01, 8.2088e-02, 1.5816e-01, 4.0004e-02, 6.0404e-02, 1.0306e-01,
        1.1870e-02, 4.9825e-02, 2.2724e-03, 7.8646e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,868][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([0.0689, 0.0913, 0.0113, 0.1043, 0.0351, 0.0189, 0.1246, 0.0691, 0.2914,
        0.0069, 0.0564, 0.0320, 0.0122, 0.0247, 0.0491, 0.0039],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,869][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([7.9628e-01, 1.4955e-02, 3.9334e-06, 6.8739e-05, 6.0653e-08, 3.4537e-04,
        1.3267e-03, 2.3087e-04, 2.6753e-04, 1.0072e-05, 4.5954e-02, 3.7829e-02,
        1.4359e-02, 2.5135e-02, 2.4458e-06, 6.3227e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,869][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([4.7904e-05, 7.2379e-02, 2.3759e-03, 3.0286e-02, 2.4124e-03, 2.2458e-02,
        1.0862e-01, 5.3478e-02, 2.5263e-01, 8.8253e-02, 2.2837e-01, 7.1995e-02,
        1.0705e-02, 5.2425e-02, 8.8111e-04, 2.6851e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,869][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([0.0021, 0.0728, 0.0607, 0.0542, 0.0104, 0.1083, 0.1814, 0.1542, 0.0693,
        0.0390, 0.0602, 0.0449, 0.0447, 0.0325, 0.0031, 0.0622],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,870][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0003, 0.0193, 0.0204, 0.0602, 0.0223, 0.0457, 0.0658, 0.0518, 0.0964,
        0.0417, 0.1410, 0.2615, 0.0315, 0.0842, 0.0270, 0.0311],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,870][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([7.5519e-03, 1.0204e-08, 3.1174e-07, 1.7717e-08, 1.0791e-05, 4.1646e-08,
        3.4482e-07, 3.5546e-04, 5.3304e-06, 5.9379e-05, 4.8048e-04, 2.2082e-03,
        7.8023e-02, 2.2546e-04, 1.5189e-01, 7.5919e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,871][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([4.6468e-05, 4.4021e-04, 1.0029e-03, 6.3519e-05, 3.0429e-02, 1.7297e-04,
        3.5903e-04, 2.8495e-04, 2.9432e-04, 7.1190e-01, 1.4640e-04, 6.4554e-05,
        2.4372e-01, 3.6034e-03, 5.3926e-03, 2.0864e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,871][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([1.8101e-05, 2.2366e-02, 4.2021e-03, 1.9380e-02, 4.5618e-03, 1.3679e-02,
        3.0036e-01, 1.9248e-02, 3.6962e-01, 4.7065e-02, 8.4072e-02, 7.0747e-02,
        4.5692e-03, 3.2509e-02, 1.1126e-03, 6.4994e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:23,874][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0003, 0.0009, 0.0006, 0.0043, 0.0064, 0.0100, 0.0510, 0.1288, 0.0491,
        0.1514, 0.0700, 0.1345, 0.1050, 0.0557, 0.0422, 0.0546, 0.1351],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,878][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.1578e-06, 8.3723e-02, 5.8610e-04, 5.4213e-02, 3.4820e-03, 1.0147e-02,
        2.2231e-01, 3.0789e-02, 3.3714e-01, 3.0399e-02, 3.3366e-02, 8.2861e-02,
        3.8857e-03, 4.8388e-02, 4.8446e-04, 7.7147e-04, 5.7457e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,883][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0005, 0.0316, 0.0074, 0.1330, 0.0129, 0.0228, 0.0921, 0.1208, 0.0872,
        0.1729, 0.0422, 0.0405, 0.0245, 0.1164, 0.0149, 0.0288, 0.0515],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,884][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([1.5900e-04, 1.1807e-01, 1.1555e-02, 9.4200e-02, 1.3445e-02, 1.9002e-02,
        2.0117e-01, 1.2123e-01, 1.5402e-01, 6.7605e-02, 4.1262e-02, 7.9850e-02,
        5.0485e-03, 3.6811e-02, 2.1887e-03, 6.3224e-03, 2.8056e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,885][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.3544, 0.0202, 0.0097, 0.0457, 0.0379, 0.0124, 0.0696, 0.0828, 0.2050,
        0.0059, 0.0449, 0.0132, 0.0074, 0.0088, 0.0635, 0.0022, 0.0162],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,885][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([7.0574e-01, 4.5119e-03, 3.0835e-06, 6.7201e-05, 1.4210e-07, 2.6952e-04,
        5.1620e-04, 3.7431e-04, 2.4175e-04, 2.5722e-05, 1.6540e-02, 6.8697e-03,
        1.2800e-02, 3.4832e-02, 5.9884e-06, 6.7639e-02, 1.4957e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,885][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.1636e-04, 9.5593e-02, 2.9071e-03, 6.4629e-02, 2.3386e-03, 3.0446e-02,
        1.2848e-01, 4.5230e-02, 2.5871e-01, 9.8373e-02, 1.2216e-01, 5.8856e-02,
        5.1022e-03, 6.1298e-02, 6.8917e-04, 1.2821e-03, 2.3795e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,886][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0033, 0.0516, 0.0280, 0.0517, 0.0084, 0.0821, 0.2373, 0.1264, 0.1144,
        0.0332, 0.0584, 0.0427, 0.0388, 0.0391, 0.0027, 0.0201, 0.0620],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,886][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0007, 0.0144, 0.0163, 0.0446, 0.0248, 0.0232, 0.0469, 0.0503, 0.0938,
        0.0503, 0.1303, 0.2419, 0.0330, 0.0683, 0.0389, 0.0223, 0.1001],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,887][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([6.1889e-04, 9.5005e-10, 4.6152e-08, 2.3480e-09, 2.6398e-06, 7.7774e-09,
        4.3870e-08, 1.4154e-04, 1.1217e-06, 1.6735e-05, 1.1132e-04, 6.7966e-04,
        4.3972e-02, 8.0933e-05, 8.3091e-02, 2.8498e-01, 5.8630e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,888][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([6.8330e-06, 9.5084e-06, 9.1458e-05, 4.0598e-07, 9.4060e-03, 3.1765e-06,
        2.2549e-06, 2.6603e-05, 3.5542e-06, 9.3712e-01, 7.8405e-07, 1.2169e-07,
        5.1987e-02, 1.3085e-04, 1.0062e-03, 2.0070e-04, 1.0057e-06],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,890][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([9.1519e-06, 2.1859e-02, 5.3383e-03, 2.3163e-02, 6.5684e-03, 7.0635e-03,
        2.9732e-01, 1.4496e-02, 3.8957e-01, 4.7673e-02, 7.3229e-02, 2.2466e-02,
        9.7956e-04, 1.3241e-02, 1.6490e-03, 2.0420e-03, 7.3332e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:23,890][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.0003, 0.0013, 0.0009, 0.0054, 0.0089, 0.0108, 0.0713, 0.1062, 0.0547,
        0.1064, 0.0742, 0.1482, 0.0797, 0.0507, 0.0508, 0.0408, 0.1435, 0.0459],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,890][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([9.3717e-07, 1.5351e-01, 6.6119e-04, 6.4507e-02, 1.8179e-03, 6.4319e-03,
        1.6348e-01, 1.5752e-02, 3.3264e-01, 2.5630e-02, 3.0557e-02, 8.0833e-02,
        3.2503e-03, 6.8795e-02, 1.5329e-04, 4.9430e-04, 5.0516e-02, 9.6049e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,895][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([0.0003, 0.0475, 0.0087, 0.1317, 0.0160, 0.0296, 0.0985, 0.1295, 0.0786,
        0.1390, 0.0393, 0.0381, 0.0312, 0.0897, 0.0122, 0.0268, 0.0479, 0.0355],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,898][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([5.2647e-05, 2.0611e-01, 1.4141e-02, 7.7295e-02, 1.4307e-02, 1.3891e-02,
        1.3110e-01, 7.5938e-02, 1.1445e-01, 6.7479e-02, 4.9690e-02, 9.0631e-02,
        9.6095e-03, 3.7387e-02, 2.2129e-03, 9.6125e-03, 2.9891e-02, 5.6201e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,901][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.1102, 0.0631, 0.0093, 0.0991, 0.0354, 0.0090, 0.0606, 0.0649, 0.2858,
        0.0049, 0.0593, 0.0411, 0.0121, 0.0207, 0.0707, 0.0020, 0.0229, 0.0291],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,902][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([2.5958e-02, 2.8326e-03, 4.4214e-06, 5.0091e-05, 1.6593e-07, 3.9462e-04,
        9.8467e-04, 4.9664e-04, 3.7752e-04, 3.9352e-05, 8.7873e-02, 6.7989e-02,
        3.0532e-02, 8.5445e-02, 9.1378e-06, 2.0238e-01, 4.9419e-01, 4.4476e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,902][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([5.7215e-05, 1.1167e-01, 2.8874e-03, 4.8371e-02, 2.3419e-03, 1.5487e-02,
        8.0431e-02, 2.8781e-02, 2.3987e-01, 1.0222e-01, 1.6580e-01, 8.2869e-02,
        7.9686e-03, 6.7595e-02, 8.9122e-04, 1.3566e-03, 3.0591e-02, 1.0812e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,902][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([0.0013, 0.0765, 0.0276, 0.0516, 0.0068, 0.0816, 0.1837, 0.1093, 0.0924,
        0.0366, 0.0685, 0.0474, 0.0482, 0.0631, 0.0018, 0.0382, 0.0446, 0.0206],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,903][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([0.0006, 0.0119, 0.0117, 0.0334, 0.0318, 0.0261, 0.0550, 0.0505, 0.0891,
        0.0477, 0.0974, 0.2644, 0.0336, 0.0591, 0.0404, 0.0191, 0.1139, 0.0143],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,903][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([3.8259e-03, 3.2486e-10, 9.8119e-09, 8.7103e-10, 5.3525e-07, 7.7048e-10,
        1.0276e-08, 7.8433e-06, 3.4837e-07, 1.5082e-06, 1.5860e-05, 1.0582e-04,
        2.2037e-03, 3.3253e-05, 9.5320e-03, 1.8481e-02, 4.0794e-02, 9.2500e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,904][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([2.4710e-05, 4.6583e-05, 1.7916e-04, 1.6840e-06, 1.1160e-02, 6.6275e-06,
        9.0483e-06, 3.6447e-05, 8.8229e-06, 7.9507e-01, 6.3202e-06, 1.0524e-06,
        1.7254e-01, 6.3231e-04, 2.8512e-03, 7.4330e-04, 1.3277e-05, 1.6665e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,904][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([7.2453e-07, 6.3122e-02, 3.3398e-03, 2.5289e-02, 3.5795e-03, 9.9793e-03,
        2.8354e-01, 1.5933e-02, 3.5513e-01, 2.8898e-02, 8.8861e-02, 5.3813e-02,
        9.8770e-04, 1.7711e-02, 2.4318e-04, 2.5421e-03, 4.5991e-02, 1.0356e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:23,907][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0002, 0.0007, 0.0004, 0.0038, 0.0047, 0.0078, 0.0462, 0.0798, 0.0460,
        0.1108, 0.0570, 0.1211, 0.0746, 0.0466, 0.0284, 0.0399, 0.1195, 0.0420,
        0.1703], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,910][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([7.6846e-07, 4.2181e-02, 4.0425e-04, 3.3510e-02, 3.0768e-03, 6.9528e-03,
        1.8215e-01, 1.6859e-02, 2.3103e-01, 2.4931e-02, 2.9238e-02, 5.8547e-02,
        3.6880e-03, 3.7380e-02, 4.2662e-04, 4.8886e-04, 3.8707e-02, 1.1251e-03,
        2.8931e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,916][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0005, 0.0230, 0.0056, 0.1151, 0.0117, 0.0190, 0.0852, 0.0831, 0.0816,
        0.1270, 0.0303, 0.0291, 0.0229, 0.1179, 0.0164, 0.0202, 0.0427, 0.0332,
        0.1356], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,918][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0003, 0.1123, 0.0163, 0.0904, 0.0166, 0.0139, 0.1948, 0.0929, 0.1169,
        0.0397, 0.0518, 0.0651, 0.0046, 0.0452, 0.0043, 0.0079, 0.0339, 0.0446,
        0.0484], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,918][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.3353, 0.0156, 0.0051, 0.0406, 0.0261, 0.0119, 0.0699, 0.0590, 0.2083,
        0.0045, 0.0524, 0.0194, 0.0075, 0.0137, 0.0516, 0.0018, 0.0168, 0.0118,
        0.0490], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,918][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([3.6608e-01, 3.7360e-03, 9.8061e-07, 1.5354e-05, 4.6347e-08, 1.0717e-04,
        3.3992e-04, 1.0307e-04, 4.9507e-05, 1.2539e-05, 8.2532e-03, 1.1553e-02,
        5.9092e-03, 1.5196e-02, 2.7717e-06, 9.1994e-02, 2.5134e-01, 1.8041e-04,
        2.4512e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,919][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([9.3152e-05, 6.4839e-02, 2.1618e-03, 4.3782e-02, 1.7233e-03, 2.4514e-02,
        1.1304e-01, 2.5646e-02, 2.2313e-01, 7.5847e-02, 1.2336e-01, 3.8679e-02,
        2.8831e-03, 4.4372e-02, 5.5002e-04, 8.7510e-04, 2.1055e-02, 1.1138e-02,
        1.8232e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,919][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0009, 0.0655, 0.0338, 0.0693, 0.0078, 0.0969, 0.2024, 0.0838, 0.1057,
        0.0195, 0.0572, 0.0486, 0.0462, 0.0460, 0.0022, 0.0279, 0.0510, 0.0068,
        0.0286], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,920][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0009, 0.0165, 0.0174, 0.0447, 0.0217, 0.0165, 0.0436, 0.0398, 0.0948,
        0.0415, 0.1222, 0.1918, 0.0232, 0.0613, 0.0301, 0.0191, 0.0848, 0.0097,
        0.1203], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,920][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.3877e-05, 2.2098e-10, 1.1084e-08, 3.7664e-10, 3.1352e-07, 1.2246e-09,
        5.6767e-09, 4.4939e-06, 7.2714e-08, 6.6248e-07, 1.5074e-05, 1.0238e-04,
        2.4774e-03, 3.6032e-06, 4.0102e-03, 2.6385e-02, 3.8508e-02, 8.9757e-01,
        3.0829e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,921][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([9.1120e-06, 5.5604e-06, 1.3963e-04, 1.5496e-07, 5.8400e-03, 3.7458e-06,
        6.8158e-06, 1.8865e-05, 4.4182e-06, 9.3243e-01, 1.0444e-06, 2.2104e-07,
        5.3054e-02, 1.1804e-04, 6.5001e-04, 3.7420e-04, 3.9406e-06, 7.3360e-03,
        1.0571e-06], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,925][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.1496e-05, 1.7424e-02, 3.2532e-03, 1.5105e-02, 2.0805e-03, 4.9608e-03,
        2.1700e-01, 1.6011e-02, 2.6032e-01, 3.6053e-02, 4.7424e-02, 1.5969e-02,
        8.9793e-04, 9.0172e-03, 6.0110e-04, 7.4813e-04, 6.6606e-02, 9.5316e-04,
        2.8556e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:23,972][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:23,973][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,973][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,974][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,974][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,974][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,975][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,975][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,975][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,975][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,976][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,976][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,976][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:23,977][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0117, 0.9883], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,977][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([4.6878e-05, 9.9995e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,977][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0055, 0.9945], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,978][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0034, 0.9966], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,978][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9793, 0.0207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,978][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.7984, 0.2016], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,979][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0079, 0.9921], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,979][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0271, 0.9729], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,979][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0225, 0.9775], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,980][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1505, 0.8495], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,982][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([3.2018e-04, 9.9968e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,994][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0162, 0.9838], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:23,995][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.0072, 0.9002, 0.0926], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:23,998][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([2.4280e-05, 9.9071e-01, 9.2641e-03], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,003][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.0050, 0.9630, 0.0321], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,007][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.0019, 0.7277, 0.2704], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,008][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.9011, 0.0807, 0.0182], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,008][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.3361, 0.6442, 0.0197], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,008][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.0103, 0.8336, 0.1561], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,009][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.0065, 0.3136, 0.6799], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,009][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.0060, 0.8245, 0.1695], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,009][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.0026, 0.9941, 0.0033], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,010][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([4.7703e-04, 9.9413e-01, 5.3927e-03], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,013][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.0017, 0.8379, 0.1604], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,019][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0225, 0.3534, 0.0459, 0.5782], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,021][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.2901e-04, 7.1411e-01, 1.4010e-02, 2.7176e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,023][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0159, 0.3870, 0.0374, 0.5597], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,023][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0177, 0.3048, 0.3531, 0.3244], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,024][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.9199, 0.0228, 0.0121, 0.0451], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,024][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.8283, 0.0855, 0.0118, 0.0744], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,024][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0286, 0.4372, 0.0902, 0.4440], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,025][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0373, 0.3018, 0.5126, 0.1482], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,025][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0102, 0.1591, 0.1821, 0.6486], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,028][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0598, 0.4387, 0.0124, 0.4891], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,034][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0019, 0.8368, 0.0060, 0.1553], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,038][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0163, 0.1643, 0.2917, 0.5278], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,039][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.0070, 0.4634, 0.0230, 0.4221, 0.0845], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,039][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([2.8117e-05, 7.7524e-01, 4.2220e-03, 2.0409e-01, 1.6424e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,039][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.0042, 0.5820, 0.0146, 0.3810, 0.0182], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,040][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.0020, 0.5195, 0.1132, 0.2641, 0.1012], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,040][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.4843, 0.1462, 0.0351, 0.2454, 0.0890], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,040][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.0772, 0.6729, 0.0206, 0.2200, 0.0093], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,042][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.0087, 0.5367, 0.0489, 0.3351, 0.0706], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,048][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0043, 0.2861, 0.3784, 0.1136, 0.2175], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,052][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.0091, 0.2258, 0.0651, 0.5947, 0.1052], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,054][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.0020, 0.7488, 0.0056, 0.2426, 0.0011], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,054][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([4.0401e-04, 8.8299e-01, 3.1008e-03, 1.1337e-01, 1.3395e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,055][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0004, 0.4038, 0.1279, 0.3021, 0.1657], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,055][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0016, 0.3518, 0.0101, 0.2328, 0.0301, 0.3736], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,055][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([1.8740e-05, 6.9038e-01, 3.5691e-03, 2.2018e-01, 6.1667e-03, 7.9685e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,056][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0020, 0.5284, 0.0196, 0.3924, 0.0145, 0.0432], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,056][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0026, 0.4601, 0.1368, 0.2305, 0.0404, 0.1297], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,056][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.4627, 0.1772, 0.0465, 0.1735, 0.0727, 0.0674], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,060][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.8239, 0.0175, 0.0036, 0.0214, 0.0018, 0.1318], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,064][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0047, 0.3872, 0.0327, 0.2307, 0.0193, 0.3254], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,070][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0023, 0.2850, 0.3478, 0.0953, 0.0499, 0.2196], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,070][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0040, 0.1323, 0.1017, 0.4688, 0.0383, 0.2549], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,070][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([5.3919e-02, 4.4636e-02, 4.8197e-03, 1.1284e-01, 7.4675e-04, 7.8304e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,071][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([1.6489e-04, 7.9967e-01, 2.4253e-03, 1.1274e-01, 1.5968e-04, 8.4840e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,071][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0012, 0.2249, 0.1653, 0.3053, 0.0889, 0.2143], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,072][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0010, 0.1142, 0.0029, 0.1433, 0.0090, 0.1470, 0.5825],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,072][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([7.4338e-06, 1.7502e-01, 1.5506e-03, 1.1507e-01, 5.8111e-03, 4.0264e-02,
        6.6227e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,072][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0018, 0.3326, 0.0202, 0.4330, 0.0182, 0.0370, 0.1572],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,074][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0011, 0.1019, 0.0602, 0.1543, 0.0333, 0.0845, 0.5648],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,080][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.8341, 0.0107, 0.0114, 0.0320, 0.0352, 0.0155, 0.0611],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,084][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.4340, 0.0054, 0.0020, 0.0149, 0.0014, 0.1283, 0.4141],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,086][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0014, 0.1457, 0.0075, 0.1491, 0.0058, 0.1325, 0.5579],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,086][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0078, 0.1904, 0.2384, 0.1342, 0.0878, 0.1796, 0.1618],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,087][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0021, 0.0567, 0.0358, 0.2231, 0.0344, 0.1103, 0.5377],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,087][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([2.4826e-02, 6.9665e-03, 1.2144e-03, 2.9158e-02, 3.2080e-04, 2.4596e-01,
        6.9155e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,087][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([1.2621e-04, 6.0465e-01, 1.1190e-03, 8.9956e-02, 6.3913e-05, 5.6154e-02,
        2.4793e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,088][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.1756e-04, 1.9247e-02, 1.7309e-02, 4.5411e-02, 2.2451e-02, 2.9070e-02,
        8.6629e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,088][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([2.0458e-04, 2.1780e-01, 2.7458e-03, 1.4357e-01, 5.7560e-03, 8.3738e-02,
        4.1489e-01, 1.3130e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,088][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([7.2404e-06, 2.4896e-01, 1.2143e-03, 8.6041e-02, 4.2837e-03, 2.7502e-02,
        6.0389e-01, 2.8107e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,092][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([0.0006, 0.4002, 0.0092, 0.3852, 0.0074, 0.0292, 0.1026, 0.0656],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,094][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([2.2501e-04, 2.5090e-01, 2.2769e-02, 1.2952e-01, 1.0624e-02, 4.5394e-02,
        4.2635e-01, 1.1421e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,100][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([0.6375, 0.0542, 0.0367, 0.0776, 0.0606, 0.0149, 0.0570, 0.0615],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,102][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0435, 0.0354, 0.0068, 0.0909, 0.0076, 0.1791, 0.6071, 0.0296],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,102][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([0.0007, 0.1584, 0.0040, 0.1019, 0.0032, 0.0820, 0.4854, 0.1643],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,103][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0025, 0.3934, 0.1306, 0.1357, 0.0576, 0.0842, 0.1175, 0.0783],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,103][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0012, 0.0779, 0.0230, 0.1818, 0.0213, 0.0870, 0.4397, 0.1683],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,103][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([0.0007, 0.0362, 0.0023, 0.0950, 0.0013, 0.2155, 0.6328, 0.0162],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,104][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([9.1253e-05, 4.9572e-01, 1.2795e-03, 1.1431e-01, 9.0978e-05, 3.4218e-02,
        3.4250e-01, 1.1789e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,104][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([3.5938e-05, 6.6144e-02, 1.8654e-02, 5.1288e-02, 1.1796e-02, 2.3320e-02,
        7.7550e-01, 5.3265e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,107][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.0006, 0.0628, 0.0018, 0.0673, 0.0047, 0.0826, 0.3907, 0.1172, 0.2723],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,111][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([1.5336e-05, 6.9872e-02, 1.6425e-03, 4.0726e-02, 4.2280e-03, 2.4822e-02,
        4.4748e-01, 4.6351e-02, 3.6486e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,116][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([0.0027, 0.1810, 0.0143, 0.2249, 0.0154, 0.0291, 0.1587, 0.1554, 0.2186],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,117][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.0026, 0.0992, 0.0453, 0.0962, 0.0218, 0.0550, 0.4205, 0.1020, 0.1574],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,118][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.6881, 0.0095, 0.0082, 0.0236, 0.0171, 0.0152, 0.0359, 0.0772, 0.1253],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,118][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.2854, 0.0073, 0.0022, 0.0117, 0.0013, 0.1123, 0.4276, 0.0246, 0.1276],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,119][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([0.0017, 0.0725, 0.0061, 0.0633, 0.0028, 0.0766, 0.2937, 0.1174, 0.3659],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,119][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0060, 0.1976, 0.2027, 0.0895, 0.0866, 0.1189, 0.1090, 0.0566, 0.1332],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,119][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0033, 0.0231, 0.0211, 0.0767, 0.0196, 0.0542, 0.3399, 0.1335, 0.3286],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,120][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([1.0434e-02, 7.8259e-03, 9.3548e-04, 2.1091e-02, 1.8585e-04, 1.4900e-01,
        4.9589e-01, 1.7061e-02, 2.9758e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,121][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([2.0546e-04, 3.1310e-01, 1.4878e-03, 6.9290e-02, 8.2142e-05, 6.4861e-02,
        3.6552e-01, 1.1355e-02, 1.7410e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,125][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([5.4496e-04, 1.3253e-02, 2.2298e-02, 3.1754e-02, 7.2497e-03, 2.1992e-02,
        5.7049e-01, 5.1574e-02, 2.8084e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,127][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([1.0431e-04, 6.1707e-02, 1.4024e-03, 6.6728e-02, 6.5648e-03, 8.8511e-02,
        2.9466e-01, 1.0114e-01, 3.1978e-01, 5.9403e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,131][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([6.0883e-06, 9.2000e-02, 9.0982e-04, 3.8807e-02, 2.5981e-03, 1.7026e-02,
        4.1841e-01, 3.6209e-02, 3.1044e-01, 8.3592e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,133][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0008, 0.2412, 0.0056, 0.1949, 0.0051, 0.0180, 0.0709, 0.0584, 0.2720,
        0.1330], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,134][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([1.4846e-04, 1.6796e-01, 2.1463e-02, 6.2026e-02, 1.4969e-02, 2.3903e-02,
        2.5855e-01, 1.0688e-01, 1.9290e-01, 1.5120e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,134][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([0.6148, 0.0371, 0.0159, 0.0405, 0.0270, 0.0143, 0.0443, 0.0552, 0.1407,
        0.0102], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,134][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0753, 0.0130, 0.0107, 0.0407, 0.0116, 0.1358, 0.4077, 0.0050, 0.1465,
        0.1538], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,135][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0004, 0.0755, 0.0025, 0.0419, 0.0019, 0.0314, 0.1691, 0.0686, 0.3588,
        0.2498], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,135][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0021, 0.2940, 0.1983, 0.0730, 0.0500, 0.1188, 0.1045, 0.0220, 0.0807,
        0.0566], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,136][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0006, 0.0873, 0.0065, 0.1897, 0.0072, 0.0667, 0.2063, 0.0698, 0.2623,
        0.1036], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,136][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0007, 0.0231, 0.0029, 0.0681, 0.0015, 0.1454, 0.2957, 0.0025, 0.4230,
        0.0370], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,137][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([9.1060e-05, 5.1987e-01, 8.4283e-04, 5.4461e-02, 5.3041e-05, 2.6709e-02,
        1.9282e-01, 6.8751e-03, 1.4405e-01, 5.4234e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,140][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([1.6435e-05, 3.0711e-02, 8.1363e-03, 1.5892e-02, 1.0944e-02, 9.8840e-03,
        3.6991e-01, 2.0753e-02, 3.9015e-01, 1.4360e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,143][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([9.1808e-05, 7.1740e-02, 1.4606e-03, 6.3577e-02, 5.1701e-03, 1.0511e-01,
        3.1540e-01, 6.1541e-02, 2.6331e-01, 5.9694e-02, 5.2904e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,146][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([2.1150e-06, 5.9296e-02, 8.3115e-04, 3.6595e-02, 4.8761e-03, 2.0089e-02,
        4.4183e-01, 2.1545e-02, 2.5552e-01, 9.2263e-02, 6.7159e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,152][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([0.0006, 0.1734, 0.0032, 0.1932, 0.0036, 0.0188, 0.1159, 0.0971, 0.2505,
        0.0880, 0.0559], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,152][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.0005, 0.1100, 0.0238, 0.0983, 0.0113, 0.0323, 0.3054, 0.0868, 0.1819,
        0.0711, 0.0785], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,153][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.3136, 0.0282, 0.0100, 0.0582, 0.0227, 0.0255, 0.0970, 0.0989, 0.2526,
        0.0143, 0.0789], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,153][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([1.9080e-01, 2.5073e-03, 2.3699e-04, 1.3329e-03, 3.6091e-05, 3.7324e-02,
        2.3004e-01, 3.0112e-03, 6.7338e-02, 4.7683e-03, 4.6260e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,153][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([1.3445e-04, 5.0754e-02, 2.0344e-03, 3.6992e-02, 1.5530e-03, 4.0139e-02,
        2.3081e-01, 5.1575e-02, 2.6400e-01, 1.3843e-01, 1.8358e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,154][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0029, 0.2005, 0.2107, 0.0927, 0.0593, 0.0904, 0.1133, 0.0249, 0.1220,
        0.0319, 0.0514], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,154][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0009, 0.0416, 0.0117, 0.0978, 0.0098, 0.0418, 0.2619, 0.1214, 0.2671,
        0.0713, 0.0746], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,155][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([1.2373e-02, 2.7431e-03, 1.0140e-04, 1.3825e-03, 3.1931e-06, 4.7967e-02,
        1.9362e-01, 1.7637e-03, 8.6697e-02, 6.2058e-04, 6.5273e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,156][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([7.3432e-05, 3.6625e-01, 8.5539e-04, 6.0425e-02, 7.2220e-05, 5.2704e-02,
        2.6672e-01, 7.0317e-03, 1.6570e-01, 4.8565e-02, 3.1602e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,160][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([1.6140e-04, 9.0113e-03, 3.1251e-03, 1.5750e-02, 4.1472e-03, 1.3551e-02,
        3.0935e-01, 2.5437e-02, 4.2630e-01, 8.3747e-02, 1.0941e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,162][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([5.9660e-05, 1.4180e-01, 1.1388e-03, 9.2459e-02, 2.9867e-03, 5.0056e-02,
        2.2935e-01, 4.6279e-02, 2.5974e-01, 3.7232e-02, 3.9632e-02, 9.9273e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,166][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([1.8746e-06, 6.5280e-02, 6.0916e-04, 4.5496e-02, 1.8370e-03, 8.9064e-03,
        3.6413e-01, 2.0712e-02, 3.1446e-01, 3.0822e-02, 3.1719e-02, 1.1602e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,168][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([2.2099e-04, 1.9052e-01, 2.9160e-03, 1.7551e-01, 2.7421e-03, 1.1188e-02,
        9.6802e-02, 8.4657e-02, 2.9472e-01, 6.5878e-02, 4.4053e-02, 3.0794e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,169][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([2.5855e-04, 1.0656e-01, 1.6195e-02, 1.0487e-01, 1.0351e-02, 2.0452e-02,
        2.9287e-01, 8.5666e-02, 1.8025e-01, 4.7140e-02, 5.3626e-02, 8.1772e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,169][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.3771, 0.0154, 0.0078, 0.0423, 0.0220, 0.0138, 0.1046, 0.0681, 0.2596,
        0.0068, 0.0617, 0.0207], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,170][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([2.3963e-01, 1.1074e-03, 1.0564e-04, 6.6616e-04, 1.7140e-05, 2.8103e-02,
        1.1233e-01, 2.5351e-03, 4.6070e-02, 3.2591e-03, 2.1135e-01, 3.5483e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,170][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.1525e-04, 6.5000e-02, 1.7720e-03, 5.0643e-02, 1.0359e-03, 2.7341e-02,
        1.9651e-01, 4.6043e-02, 3.0628e-01, 1.2224e-01, 1.1457e-01, 6.8455e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,170][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0022, 0.1817, 0.1272, 0.1115, 0.0285, 0.0712, 0.1417, 0.0209, 0.2094,
        0.0264, 0.0451, 0.0343], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,171][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([1.6101e-04, 3.9981e-02, 1.1498e-02, 9.8871e-02, 9.9810e-03, 2.9256e-02,
        1.9422e-01, 9.4875e-02, 3.5629e-01, 3.8589e-02, 7.1001e-02, 5.5275e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,171][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([3.9349e-03, 9.0340e-04, 1.9183e-05, 3.9154e-04, 7.1450e-07, 1.7065e-02,
        9.0875e-02, 9.9053e-04, 5.8903e-02, 3.2721e-04, 2.9894e-01, 5.2765e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,173][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([3.5192e-05, 4.9316e-01, 5.3835e-04, 5.7666e-02, 4.1535e-05, 2.2593e-02,
        1.6516e-01, 4.2189e-03, 1.4552e-01, 2.0359e-02, 2.1748e-02, 6.8957e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,176][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([3.2295e-05, 1.0527e-02, 4.0842e-03, 1.9228e-02, 7.2955e-03, 8.3896e-03,
        3.3074e-01, 2.2497e-02, 4.1165e-01, 5.3902e-02, 8.0452e-02, 5.1204e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,179][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([2.1319e-05, 1.2744e-01, 1.0145e-03, 7.2898e-02, 4.2884e-03, 4.5275e-02,
        2.0250e-01, 4.8274e-02, 2.4762e-01, 3.0715e-02, 7.1865e-02, 1.3560e-01,
        1.2491e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,183][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([1.4292e-06, 9.8185e-02, 6.7495e-04, 3.8526e-02, 2.4321e-03, 6.5663e-03,
        2.8396e-01, 1.1713e-02, 3.2885e-01, 2.9490e-02, 4.5580e-02, 1.4747e-01,
        6.5546e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,185][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([1.0909e-04, 2.2082e-01, 2.9860e-03, 1.6164e-01, 2.9854e-03, 1.3555e-02,
        9.5649e-02, 4.4664e-02, 2.6516e-01, 6.4294e-02, 8.6164e-02, 3.9824e-02,
        2.1484e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,185][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([7.8699e-05, 2.2175e-01, 1.1351e-02, 7.6478e-02, 9.9583e-03, 1.0721e-02,
        2.0973e-01, 6.1030e-02, 1.4684e-01, 4.5354e-02, 9.8135e-02, 1.0237e-01,
        6.1947e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,186][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([0.1500, 0.0566, 0.0101, 0.0744, 0.0230, 0.0191, 0.1219, 0.0810, 0.3058,
        0.0097, 0.0826, 0.0466, 0.0193], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,186][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([3.5458e-02, 1.5787e-03, 1.0875e-04, 8.1649e-04, 2.0310e-05, 1.4611e-02,
        6.3237e-02, 6.4879e-04, 2.9781e-02, 8.6360e-04, 3.2445e-01, 4.3594e-01,
        9.2490e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,186][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([7.5059e-05, 6.3929e-02, 2.8418e-03, 3.6525e-02, 2.3857e-03, 2.9575e-02,
        1.3636e-01, 3.2125e-02, 3.0052e-01, 1.2306e-01, 2.0495e-01, 5.8031e-02,
        9.6137e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,187][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0015, 0.1728, 0.1479, 0.0788, 0.0332, 0.0730, 0.1312, 0.0187, 0.1587,
        0.0398, 0.0442, 0.0246, 0.0753], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,187][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([1.9164e-04, 1.0292e-01, 7.0621e-03, 1.8470e-01, 5.8417e-03, 4.8685e-02,
        1.4574e-01, 6.0968e-02, 2.6071e-01, 4.8478e-02, 8.6674e-02, 4.5282e-02,
        2.7456e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,188][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([3.3263e-04, 1.1073e-03, 6.6372e-06, 2.3975e-04, 3.5371e-07, 6.3303e-03,
        3.5106e-02, 2.5796e-04, 2.4293e-02, 6.2883e-05, 2.4228e-01, 6.7610e-01,
        1.3879e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,189][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([3.2012e-05, 5.0052e-01, 6.3900e-04, 4.2898e-02, 4.1892e-05, 1.8912e-02,
        1.7976e-01, 3.8102e-03, 1.3495e-01, 2.9391e-02, 2.4739e-02, 6.2523e-02,
        1.7759e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,193][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([1.1713e-06, 1.3214e-02, 3.0748e-03, 1.0846e-02, 3.0077e-03, 5.2520e-03,
        4.0336e-01, 6.6525e-03, 3.4290e-01, 3.7829e-02, 9.3722e-02, 7.8773e-02,
        1.3650e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,198][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.0008, 0.0705, 0.0029, 0.0603, 0.0086, 0.0632, 0.1754, 0.0640, 0.2323,
        0.0290, 0.0543, 0.1020, 0.0077, 0.1291], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,201][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([2.4052e-05, 7.5520e-02, 1.7432e-03, 3.7666e-02, 4.2389e-03, 1.2304e-02,
        2.4918e-01, 2.5562e-02, 2.7370e-01, 3.6876e-02, 5.8171e-02, 1.0342e-01,
        1.0880e-02, 1.1071e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,202][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0023, 0.1461, 0.0051, 0.1744, 0.0047, 0.0144, 0.0829, 0.0983, 0.2222,
        0.0879, 0.0731, 0.0300, 0.0027, 0.0558], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,202][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([0.0020, 0.1231, 0.0345, 0.0878, 0.0217, 0.0212, 0.2147, 0.1133, 0.1368,
        0.0445, 0.0603, 0.0760, 0.0061, 0.0581], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,203][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.5935, 0.0167, 0.0104, 0.0309, 0.0296, 0.0123, 0.0477, 0.0688, 0.1400,
        0.0058, 0.0198, 0.0081, 0.0056, 0.0108], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,203][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([3.3399e-01, 9.4054e-04, 3.4595e-04, 1.2058e-03, 1.9934e-04, 1.7686e-02,
        6.7858e-02, 5.8462e-03, 2.5943e-02, 1.9309e-02, 3.3847e-02, 2.7851e-02,
        1.7652e-02, 4.4733e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,204][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0011, 0.0651, 0.0052, 0.0384, 0.0018, 0.0412, 0.1302, 0.0681, 0.2368,
        0.1158, 0.1588, 0.0582, 0.0065, 0.0728], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,204][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0080, 0.1608, 0.2461, 0.0807, 0.0501, 0.0681, 0.0853, 0.0149, 0.1161,
        0.0183, 0.0396, 0.0177, 0.0155, 0.0789], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,207][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.0017, 0.0439, 0.0180, 0.1246, 0.0142, 0.0459, 0.1659, 0.0705, 0.2339,
        0.0466, 0.0941, 0.0465, 0.0031, 0.0912], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,210][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([1.9803e-02, 2.1180e-03, 1.8889e-04, 2.4037e-03, 1.2091e-05, 2.3421e-02,
        7.0495e-02, 7.1693e-03, 3.9944e-02, 5.1912e-03, 1.7369e-02, 2.7596e-02,
        3.2455e-03, 7.8104e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,214][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([3.4974e-04, 3.1445e-01, 1.1590e-03, 3.4791e-02, 7.8321e-05, 2.7638e-02,
        1.2450e-01, 6.4884e-03, 1.1586e-01, 2.8808e-02, 2.4546e-02, 5.0232e-02,
        1.4093e-03, 2.6970e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,216][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([2.2072e-04, 1.2347e-02, 1.1034e-02, 2.8182e-02, 5.3767e-03, 1.6186e-02,
        4.1932e-01, 2.6128e-02, 2.3140e-01, 6.0826e-02, 8.8148e-02, 6.7440e-02,
        2.1660e-03, 3.1218e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,218][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([8.9539e-05, 1.1108e-01, 3.4330e-03, 8.6279e-02, 1.8950e-02, 7.0071e-02,
        1.2974e-01, 8.4705e-02, 2.1574e-01, 5.1232e-02, 6.0050e-02, 1.0794e-01,
        1.1384e-02, 4.6779e-02, 2.5357e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,218][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([3.3889e-06, 1.5705e-01, 1.4638e-03, 6.6273e-02, 7.4667e-03, 1.9851e-02,
        2.5093e-01, 3.3281e-02, 2.5881e-01, 4.6947e-02, 2.3368e-02, 7.0733e-02,
        5.7111e-03, 5.7403e-02, 7.0204e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,219][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.0004, 0.3488, 0.0042, 0.1934, 0.0083, 0.0218, 0.0509, 0.0474, 0.1765,
        0.0452, 0.0454, 0.0224, 0.0030, 0.0313, 0.0009], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,219][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.0003, 0.2111, 0.0144, 0.0886, 0.0314, 0.0265, 0.1237, 0.1139, 0.1316,
        0.0898, 0.0640, 0.0623, 0.0087, 0.0288, 0.0048], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,220][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0992, 0.0785, 0.0221, 0.1203, 0.0637, 0.0192, 0.0796, 0.0602, 0.1952,
        0.0191, 0.0625, 0.0325, 0.0167, 0.0274, 0.1039], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,220][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([1.7224e-03, 6.6738e-03, 2.9195e-04, 1.0134e-03, 8.5886e-05, 3.8171e-03,
        8.0571e-03, 1.3918e-04, 5.9665e-03, 1.2394e-04, 2.2941e-01, 3.8937e-01,
        1.7497e-01, 1.7725e-01, 1.1052e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,221][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([2.0353e-04, 7.7823e-02, 4.2991e-03, 4.5160e-02, 1.0322e-02, 3.4616e-02,
        1.0780e-01, 3.5944e-02, 3.0315e-01, 1.0198e-01, 1.5600e-01, 6.1894e-02,
        8.2165e-03, 5.0289e-02, 2.3079e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,224][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0014, 0.1625, 0.1596, 0.0737, 0.0651, 0.0643, 0.1101, 0.0184, 0.1414,
        0.0299, 0.0400, 0.0263, 0.0248, 0.0790, 0.0036], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,229][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.0014, 0.0685, 0.0138, 0.1144, 0.0288, 0.1006, 0.1221, 0.0744, 0.1845,
        0.0791, 0.0629, 0.0395, 0.0061, 0.0904, 0.0137], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,232][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([6.1648e-05, 5.0772e-03, 3.5881e-05, 4.3148e-04, 2.0003e-06, 1.5225e-03,
        2.4574e-03, 1.8452e-05, 3.2724e-03, 8.2750e-06, 2.0253e-01, 5.9867e-01,
        5.7138e-02, 1.2873e-01, 4.3739e-05], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,234][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([8.9391e-05, 5.4295e-01, 1.2306e-03, 5.9335e-02, 1.2115e-04, 1.8746e-02,
        1.1742e-01, 4.3720e-03, 1.0117e-01, 1.9567e-02, 1.2249e-02, 2.7364e-02,
        9.5792e-04, 9.4420e-02, 8.6823e-06], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,235][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([5.8491e-06, 4.2666e-02, 5.4923e-03, 2.2004e-02, 1.1967e-02, 1.4090e-02,
        2.4478e-01, 1.2345e-02, 2.9140e-01, 5.5293e-02, 1.4484e-01, 1.2029e-01,
        2.8513e-03, 3.0317e-02, 1.6605e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,235][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([3.5374e-05, 1.4669e-01, 9.8449e-04, 6.2788e-02, 6.3922e-03, 4.8329e-02,
        1.3861e-01, 4.7503e-02, 2.3182e-01, 2.7230e-02, 5.5902e-02, 1.3504e-01,
        1.0141e-02, 8.3744e-02, 1.6600e-03, 3.1263e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,236][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([1.7705e-06, 8.1352e-02, 1.0155e-03, 4.6638e-02, 5.1678e-03, 9.6269e-03,
        1.9707e-01, 1.5948e-02, 2.9901e-01, 2.2734e-02, 5.9053e-02, 1.6568e-01,
        1.2926e-02, 8.1592e-02, 8.6486e-04, 1.3102e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,236][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([1.0522e-04, 2.0199e-01, 3.2857e-03, 1.5489e-01, 5.2676e-03, 1.4654e-02,
        7.6019e-02, 6.9580e-02, 2.3502e-01, 5.1690e-02, 6.8366e-02, 4.1963e-02,
        5.5597e-03, 6.0349e-02, 1.0567e-03, 1.0203e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,237][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([7.4669e-05, 1.6977e-01, 1.0886e-02, 9.8407e-02, 1.1861e-02, 1.3372e-02,
        1.8008e-01, 8.2088e-02, 1.5816e-01, 4.0004e-02, 6.0404e-02, 1.0306e-01,
        1.1870e-02, 4.9825e-02, 2.2724e-03, 7.8646e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,237][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([0.0689, 0.0913, 0.0113, 0.1043, 0.0351, 0.0189, 0.1246, 0.0691, 0.2914,
        0.0069, 0.0564, 0.0320, 0.0122, 0.0247, 0.0491, 0.0039],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,238][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([7.2625e-02, 4.1113e-04, 2.6272e-05, 5.7779e-05, 2.3263e-06, 2.6133e-03,
        8.9251e-03, 2.3726e-04, 2.9769e-03, 6.4190e-05, 1.6142e-02, 4.7877e-02,
        1.4777e-02, 6.7806e-01, 6.6116e-05, 1.5514e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,241][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([4.7904e-05, 7.2379e-02, 2.3759e-03, 3.0286e-02, 2.4124e-03, 2.2458e-02,
        1.0862e-01, 5.3478e-02, 2.5263e-01, 8.8253e-02, 2.2837e-01, 7.1995e-02,
        1.0705e-02, 5.2425e-02, 8.8111e-04, 2.6851e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,247][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0011, 0.2300, 0.1879, 0.0658, 0.0370, 0.0917, 0.0912, 0.0126, 0.1106,
        0.0157, 0.0384, 0.0195, 0.0236, 0.0435, 0.0024, 0.0291],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,249][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([1.1470e-04, 8.6443e-02, 7.9434e-03, 1.1025e-01, 7.3846e-03, 3.5728e-02,
        1.5536e-01, 8.1035e-02, 2.4697e-01, 4.1308e-02, 9.6046e-02, 4.1784e-02,
        3.2494e-03, 7.2940e-02, 3.3173e-03, 1.0120e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,251][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.5326e-03, 1.2529e-04, 3.0432e-06, 1.6477e-05, 5.0187e-08, 1.1498e-03,
        4.4054e-03, 4.5755e-05, 2.3778e-03, 1.7044e-06, 1.1452e-02, 4.0348e-02,
        2.1075e-03, 8.5796e-01, 1.8348e-06, 7.8469e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,252][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([3.9702e-05, 4.6081e-01, 9.8415e-04, 4.7171e-02, 2.1122e-04, 2.4241e-02,
        1.4339e-01, 4.7564e-03, 1.2458e-01, 1.2722e-02, 2.5433e-02, 4.8964e-02,
        1.9591e-03, 9.9534e-02, 1.4881e-05, 5.1894e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,252][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([1.8101e-05, 2.2366e-02, 4.2021e-03, 1.9380e-02, 4.5618e-03, 1.3679e-02,
        3.0036e-01, 1.9248e-02, 3.6962e-01, 4.7065e-02, 8.4072e-02, 7.0747e-02,
        4.5692e-03, 3.2509e-02, 1.1126e-03, 6.4994e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,252][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([6.1124e-05, 1.3072e-01, 1.5038e-03, 9.5068e-02, 7.2189e-03, 4.9476e-02,
        1.5463e-01, 5.3051e-02, 2.4824e-01, 3.3495e-02, 3.8983e-02, 9.1854e-02,
        5.3567e-03, 6.1568e-02, 1.2900e-03, 1.0200e-03, 2.6455e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,253][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([1.1578e-06, 8.3723e-02, 5.8610e-04, 5.4213e-02, 3.4820e-03, 1.0147e-02,
        2.2231e-01, 3.0789e-02, 3.3714e-01, 3.0399e-02, 3.3366e-02, 8.2861e-02,
        3.8857e-03, 4.8388e-02, 4.8446e-04, 7.7147e-04, 5.7457e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,253][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([1.5021e-04, 2.3959e-01, 3.5666e-03, 2.2500e-01, 4.6075e-03, 1.0717e-02,
        5.8053e-02, 8.4731e-02, 1.7593e-01, 7.7757e-02, 4.7463e-02, 2.5382e-02,
        1.4017e-03, 3.1345e-02, 5.9879e-04, 4.7222e-03, 8.9781e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,254][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([1.5900e-04, 1.1807e-01, 1.1555e-02, 9.4200e-02, 1.3445e-02, 1.9002e-02,
        2.0117e-01, 1.2123e-01, 1.5402e-01, 6.7605e-02, 4.1262e-02, 7.9850e-02,
        5.0485e-03, 3.6811e-02, 2.1887e-03, 6.3224e-03, 2.8056e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,257][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.3544, 0.0202, 0.0097, 0.0457, 0.0379, 0.0124, 0.0696, 0.0828, 0.2050,
        0.0059, 0.0449, 0.0132, 0.0074, 0.0088, 0.0635, 0.0022, 0.0162],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,260][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.5034e-01, 5.4681e-04, 4.8625e-05, 1.9672e-04, 7.6015e-06, 5.2921e-03,
        2.2456e-02, 1.5426e-03, 9.2226e-03, 9.3336e-04, 9.7763e-03, 1.4780e-02,
        6.1590e-03, 4.7976e-01, 7.7123e-05, 3.4022e-02, 2.6484e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,263][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([1.1636e-04, 9.5593e-02, 2.9071e-03, 6.4629e-02, 2.3386e-03, 3.0446e-02,
        1.2848e-01, 4.5230e-02, 2.5871e-01, 9.8373e-02, 1.2216e-01, 5.8856e-02,
        5.1022e-03, 6.1298e-02, 6.8917e-04, 1.2821e-03, 2.3795e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,268][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0018, 0.2177, 0.1343, 0.1025, 0.0427, 0.0935, 0.1138, 0.0189, 0.1118,
        0.0129, 0.0295, 0.0211, 0.0122, 0.0436, 0.0035, 0.0102, 0.0300],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,268][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0003, 0.0342, 0.0087, 0.0903, 0.0107, 0.0303, 0.1644, 0.0782, 0.2524,
        0.0546, 0.0790, 0.0423, 0.0030, 0.0544, 0.0075, 0.0067, 0.0831],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,269][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([4.2660e-03, 2.6322e-04, 7.3671e-06, 8.9243e-05, 2.3978e-07, 3.0090e-03,
        1.1195e-02, 3.0501e-04, 9.0183e-03, 7.6485e-05, 7.1059e-03, 1.0647e-02,
        6.9574e-04, 7.3362e-01, 3.2999e-06, 1.2354e-02, 2.0734e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,269][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([4.4011e-05, 4.7074e-01, 5.1976e-04, 4.3590e-02, 7.2587e-05, 1.6105e-02,
        9.5279e-02, 4.0621e-03, 1.0809e-01, 1.2501e-02, 1.3579e-02, 3.0139e-02,
        4.7732e-04, 1.0513e-01, 4.0165e-06, 4.3735e-03, 9.5303e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,270][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([9.1519e-06, 2.1859e-02, 5.3383e-03, 2.3163e-02, 6.5684e-03, 7.0635e-03,
        2.9732e-01, 1.4496e-02, 3.8957e-01, 4.7673e-02, 7.3229e-02, 2.2466e-02,
        9.7956e-04, 1.3241e-02, 1.6490e-03, 2.0420e-03, 7.3332e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,270][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([3.6152e-05, 1.4352e-01, 1.5416e-03, 9.3287e-02, 1.0161e-02, 3.7314e-02,
        1.0604e-01, 5.6950e-02, 1.5274e-01, 3.0609e-02, 6.8514e-02, 1.4746e-01,
        1.6791e-02, 8.3301e-02, 2.8694e-03, 2.4477e-03, 3.9050e-02, 7.3631e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,270][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([9.3717e-07, 1.5351e-01, 6.6119e-04, 6.4507e-02, 1.8179e-03, 6.4319e-03,
        1.6348e-01, 1.5752e-02, 3.3264e-01, 2.5630e-02, 3.0557e-02, 8.0833e-02,
        3.2503e-03, 6.8795e-02, 1.5329e-04, 4.9430e-04, 5.0516e-02, 9.6049e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,272][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([8.6741e-05, 3.1839e-01, 3.4611e-03, 2.0824e-01, 6.3766e-03, 1.1286e-02,
        4.7236e-02, 3.7795e-02, 1.8494e-01, 5.6266e-02, 4.2335e-02, 2.6484e-02,
        2.1258e-03, 3.8661e-02, 6.4496e-04, 4.8979e-03, 8.1861e-03, 2.5821e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,276][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([5.2647e-05, 2.0611e-01, 1.4141e-02, 7.7295e-02, 1.4307e-02, 1.3891e-02,
        1.3110e-01, 7.5938e-02, 1.1445e-01, 6.7479e-02, 4.9690e-02, 9.0631e-02,
        9.6095e-03, 3.7387e-02, 2.2129e-03, 9.6125e-03, 2.9891e-02, 5.6201e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,280][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.1102, 0.0631, 0.0093, 0.0991, 0.0354, 0.0090, 0.0606, 0.0649, 0.2858,
        0.0049, 0.0593, 0.0411, 0.0121, 0.0207, 0.0707, 0.0020, 0.0229, 0.0291],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,284][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([7.2959e-03, 1.0401e-03, 1.6078e-04, 4.5772e-04, 6.5973e-05, 2.9686e-03,
        8.7506e-03, 2.0955e-04, 4.1082e-03, 3.6321e-04, 5.1258e-02, 4.9966e-02,
        2.1315e-02, 1.5477e-01, 7.1311e-04, 3.4038e-01, 3.4948e-01, 6.6918e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,284][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([5.7215e-05, 1.1167e-01, 2.8874e-03, 4.8371e-02, 2.3419e-03, 1.5487e-02,
        8.0431e-02, 2.8781e-02, 2.3987e-01, 1.0222e-01, 1.6580e-01, 8.2869e-02,
        7.9686e-03, 6.7595e-02, 8.9122e-04, 1.3566e-03, 3.0591e-02, 1.0812e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,285][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0009, 0.2931, 0.1569, 0.0814, 0.0322, 0.0550, 0.0692, 0.0213, 0.0898,
        0.0132, 0.0398, 0.0293, 0.0150, 0.0502, 0.0029, 0.0128, 0.0245, 0.0126],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,285][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([1.4618e-04, 4.4092e-02, 5.7304e-03, 1.0249e-01, 1.3232e-02, 2.8161e-02,
        1.4470e-01, 5.4551e-02, 2.4020e-01, 4.7999e-02, 8.6447e-02, 4.5727e-02,
        2.4256e-03, 7.6644e-02, 7.3159e-03, 6.4509e-03, 8.2466e-02, 1.1227e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,286][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([2.1789e-04, 1.3230e-03, 2.4075e-05, 2.8254e-04, 1.8381e-06, 1.8210e-03,
        4.7423e-03, 9.7564e-05, 3.4478e-03, 3.6951e-05, 3.1551e-02, 8.8664e-02,
        6.0762e-03, 1.4627e-01, 2.7709e-05, 1.7761e-01, 5.3676e-01, 1.0492e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,286][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([3.4351e-05, 5.7511e-01, 5.6514e-04, 4.1964e-02, 3.3099e-05, 9.8208e-03,
        5.7131e-02, 2.0336e-03, 5.5115e-02, 9.1224e-03, 1.3140e-02, 2.6474e-02,
        8.1822e-04, 1.2171e-01, 1.7221e-06, 4.2574e-03, 8.2472e-02, 2.0646e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,287][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([7.2453e-07, 6.3122e-02, 3.3398e-03, 2.5289e-02, 3.5795e-03, 9.9793e-03,
        2.8354e-01, 1.5933e-02, 3.5513e-01, 2.8898e-02, 8.8861e-02, 5.3813e-02,
        9.8770e-04, 1.7711e-02, 2.4318e-04, 2.5421e-03, 4.5991e-02, 1.0356e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,288][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([6.3211e-05, 1.3100e-01, 1.5372e-03, 8.8259e-02, 5.9943e-03, 4.6096e-02,
        1.6483e-01, 4.6350e-02, 2.3456e-01, 2.9215e-02, 4.1078e-02, 7.7134e-02,
        4.5099e-03, 6.4357e-02, 1.1685e-03, 1.0301e-03, 3.0112e-02, 3.1115e-03,
        2.9589e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,291][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([7.6846e-07, 4.2181e-02, 4.0425e-04, 3.3510e-02, 3.0768e-03, 6.9528e-03,
        1.8215e-01, 1.6859e-02, 2.3103e-01, 2.4931e-02, 2.9238e-02, 5.8547e-02,
        3.6880e-03, 3.7380e-02, 4.2662e-04, 4.8886e-04, 3.8707e-02, 1.1251e-03,
        2.8931e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,296][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0003, 0.2103, 0.0025, 0.1537, 0.0042, 0.0144, 0.0794, 0.0729, 0.2307,
        0.0552, 0.0477, 0.0235, 0.0012, 0.0256, 0.0009, 0.0032, 0.0120, 0.0032,
        0.0592], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,301][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0003, 0.1123, 0.0163, 0.0904, 0.0166, 0.0139, 0.1948, 0.0929, 0.1169,
        0.0397, 0.0518, 0.0651, 0.0046, 0.0452, 0.0043, 0.0079, 0.0339, 0.0446,
        0.0484], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,301][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3353, 0.0156, 0.0051, 0.0406, 0.0261, 0.0119, 0.0699, 0.0590, 0.2083,
        0.0045, 0.0524, 0.0194, 0.0075, 0.0137, 0.0516, 0.0018, 0.0168, 0.0118,
        0.0490], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,302][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([6.3956e-02, 1.5666e-04, 9.1866e-06, 2.6356e-05, 1.0468e-06, 1.6574e-03,
        8.1903e-03, 2.3977e-04, 2.1547e-03, 1.3248e-04, 5.2946e-03, 1.4653e-02,
        4.2928e-03, 5.0948e-01, 2.5315e-05, 2.6410e-02, 2.8870e-01, 2.3657e-03,
        7.2253e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,302][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([9.3152e-05, 6.4839e-02, 2.1618e-03, 4.3782e-02, 1.7233e-03, 2.4514e-02,
        1.1304e-01, 2.5646e-02, 2.2313e-01, 7.5847e-02, 1.2336e-01, 3.8679e-02,
        2.8831e-03, 4.4372e-02, 5.5002e-04, 8.7510e-04, 2.1055e-02, 1.1138e-02,
        1.8232e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,303][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0036, 0.2514, 0.1545, 0.0881, 0.0520, 0.0494, 0.0786, 0.0195, 0.0926,
        0.0093, 0.0333, 0.0206, 0.0076, 0.0471, 0.0044, 0.0077, 0.0291, 0.0136,
        0.0379], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,303][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0003, 0.0223, 0.0053, 0.0689, 0.0077, 0.0171, 0.1402, 0.0511, 0.2478,
        0.0361, 0.0879, 0.0351, 0.0017, 0.0494, 0.0076, 0.0041, 0.0773, 0.0079,
        0.1323], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,304][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.9911e-03, 1.0655e-04, 1.7822e-06, 1.5699e-05, 2.5143e-08, 9.2101e-04,
        2.7745e-03, 3.8945e-05, 1.4008e-03, 4.8867e-06, 2.1428e-03, 7.3076e-03,
        4.5253e-04, 6.3588e-01, 5.0984e-07, 1.0031e-02, 1.8306e-01, 1.8078e-04,
        1.5268e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,305][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([4.0367e-05, 3.0110e-01, 4.3525e-04, 4.2920e-02, 7.4121e-05, 1.8240e-02,
        1.2501e-01, 3.3768e-03, 1.2251e-01, 1.4329e-02, 1.9866e-02, 4.0453e-02,
        4.1649e-04, 1.3759e-01, 3.8142e-06, 4.0687e-03, 1.2340e-01, 1.7844e-04,
        4.5984e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,309][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([2.1496e-05, 1.7424e-02, 3.2532e-03, 1.5105e-02, 2.0805e-03, 4.9608e-03,
        2.1700e-01, 1.6011e-02, 2.6032e-01, 3.6053e-02, 4.7424e-02, 1.5969e-02,
        8.9793e-04, 9.0172e-03, 6.0110e-04, 7.4813e-04, 6.6606e-02, 9.5316e-04,
        2.8556e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,310][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:24,313][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[1022],
        [ 191],
        [  25],
        [  40],
        [   8],
        [   1],
        [   5],
        [   2],
        [  12],
        [   7],
        [   1],
        [  17],
        [  11],
        [  11],
        [  16],
        [   6],
        [   4],
        [   2],
        [   4]], device='cuda:0')
[2024-07-24 10:27:24,316][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[655],
        [218],
        [  5],
        [ 15],
        [  5],
        [  1],
        [  4],
        [  2],
        [ 12],
        [  7],
        [  1],
        [ 17],
        [  8],
        [ 18],
        [ 16],
        [  5],
        [  6],
        [  5],
        [  6]], device='cuda:0')
[2024-07-24 10:27:24,319][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[49263],
        [10490],
        [36916],
        [27773],
        [11765],
        [10811],
        [15741],
        [ 9005],
        [ 8059],
        [ 2752],
        [ 2493],
        [ 2425],
        [ 2776],
        [ 2664],
        [ 2657],
        [ 2053],
        [ 2110],
        [ 2440],
        [ 2650]], device='cuda:0')
[2024-07-24 10:27:24,321][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[28453],
        [23320],
        [23645],
        [31280],
        [29436],
        [31471],
        [44034],
        [43194],
        [45392],
        [45429],
        [45293],
        [43887],
        [42766],
        [43039],
        [43003],
        [41856],
        [43562],
        [42393],
        [42448]], device='cuda:0')
[2024-07-24 10:27:24,322][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 4056],
        [19225],
        [23736],
        [ 7382],
        [ 9020],
        [ 8106],
        [ 4929],
        [ 3223],
        [ 4774],
        [ 3371],
        [ 4096],
        [ 5027],
        [ 5509],
        [ 6687],
        [ 6598],
        [ 6335],
        [ 6067],
        [ 6365],
        [ 9343]], device='cuda:0')
[2024-07-24 10:27:24,323][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[10106],
        [24439],
        [28093],
        [29228],
        [25483],
        [25839],
        [24096],
        [22346],
        [22792],
        [21568],
        [23582],
        [23858],
        [25013],
        [23825],
        [23104],
        [24095],
        [23141],
        [23613],
        [24013]], device='cuda:0')
[2024-07-24 10:27:24,324][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[43291],
        [42432],
        [38546],
        [39648],
        [22455],
        [22793],
        [41043],
        [33364],
        [34225],
        [31012],
        [25962],
        [26635],
        [23233],
        [31224],
        [23389],
        [22468],
        [27208],
        [22745],
        [25434]], device='cuda:0')
[2024-07-24 10:27:24,327][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[15699],
        [25641],
        [38776],
        [37053],
        [38899],
        [16414],
        [23003],
        [23312],
        [28002],
        [35557],
        [31956],
        [29829],
        [33976],
        [37689],
        [37310],
        [35233],
        [35435],
        [37890],
        [34603]], device='cuda:0')
[2024-07-24 10:27:24,330][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[24444],
        [29056],
        [33771],
        [31995],
        [30283],
        [33157],
        [33862],
        [36159],
        [35992],
        [32451],
        [34656],
        [33636],
        [34054],
        [34526],
        [33913],
        [34659],
        [33876],
        [33679],
        [35770]], device='cuda:0')
[2024-07-24 10:27:24,332][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[47501],
        [28473],
        [49277],
        [46925],
        [43096],
        [38738],
        [36331],
        [27439],
        [30100],
        [24139],
        [27297],
        [25908],
        [23284],
        [27583],
        [23886],
        [26924],
        [25749],
        [25301],
        [26689]], device='cuda:0')
[2024-07-24 10:27:24,335][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[24283],
        [ 8105],
        [ 8946],
        [11071],
        [12138],
        [10699],
        [10777],
        [13196],
        [13772],
        [12988],
        [12681],
        [12204],
        [11427],
        [10819],
        [10932],
        [10923],
        [10811],
        [10681],
        [10928]], device='cuda:0')
[2024-07-24 10:27:24,338][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[24049],
        [26070],
        [21485],
        [15486],
        [12486],
        [ 9857],
        [ 9195],
        [ 7052],
        [ 6788],
        [ 7012],
        [ 7029],
        [14535],
        [14385],
        [14287],
        [17975],
        [ 8359],
        [ 9627],
        [ 8289],
        [ 8239]], device='cuda:0')
[2024-07-24 10:27:24,340][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[42922],
        [44087],
        [50211],
        [50234],
        [46433],
        [42703],
        [36757],
        [41895],
        [38783],
        [23283],
        [23241],
        [23163],
        [23782],
        [23727],
        [23892],
        [26291],
        [23701],
        [25249],
        [23817]], device='cuda:0')
[2024-07-24 10:27:24,341][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[36370],
        [22011],
        [23157],
        [20760],
        [23108],
        [21645],
        [23725],
        [23636],
        [21879],
        [21950],
        [20674],
        [20822],
        [21106],
        [21863],
        [21093],
        [20887],
        [20203],
        [20303],
        [18508]], device='cuda:0')
[2024-07-24 10:27:24,342][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[13839],
        [ 7329],
        [15561],
        [ 6777],
        [ 4650],
        [13965],
        [ 7978],
        [10598],
        [ 5965],
        [14321],
        [ 8505],
        [ 6399],
        [16592],
        [ 3706],
        [ 3866],
        [12802],
        [ 8548],
        [ 2329],
        [ 4784]], device='cuda:0')
[2024-07-24 10:27:24,344][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[20692],
        [27386],
        [27384],
        [30079],
        [29957],
        [30486],
        [20823],
        [22266],
        [20507],
        [21113],
        [20852],
        [21676],
        [21629],
        [20300],
        [22530],
        [21337],
        [21253],
        [21539],
        [20579]], device='cuda:0')
[2024-07-24 10:27:24,346][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[38232],
        [33703],
        [33964],
        [36408],
        [36213],
        [36588],
        [39640],
        [39059],
        [34472],
        [33775],
        [35051],
        [34528],
        [34052],
        [34483],
        [34836],
        [34204],
        [33477],
        [33571],
        [34990]], device='cuda:0')
[2024-07-24 10:27:24,349][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[37775],
        [ 7771],
        [ 7835],
        [ 8958],
        [ 8621],
        [ 8887],
        [ 9758],
        [ 9831],
        [13734],
        [14296],
        [14262],
        [14192],
        [13429],
        [14118],
        [11852],
        [13563],
        [12995],
        [12137],
        [13408]], device='cuda:0')
[2024-07-24 10:27:24,352][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[31955],
        [26847],
        [24638],
        [21672],
        [20699],
        [21316],
        [24070],
        [25768],
        [26953],
        [27054],
        [27890],
        [27621],
        [27430],
        [27513],
        [26581],
        [27228],
        [27687],
        [26206],
        [26933]], device='cuda:0')
[2024-07-24 10:27:24,355][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[19897],
        [18702],
        [13902],
        [15016],
        [11177],
        [ 9995],
        [10945],
        [ 8710],
        [ 8408],
        [ 8162],
        [ 6990],
        [ 6945],
        [ 7043],
        [ 7880],
        [ 9460],
        [ 7995],
        [ 8836],
        [ 8663],
        [ 9052]], device='cuda:0')
[2024-07-24 10:27:24,357][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[11953],
        [17079],
        [13549],
        [16509],
        [12779],
        [21227],
        [15608],
        [14202],
        [12419],
        [11673],
        [11549],
        [ 8889],
        [ 9027],
        [ 9623],
        [ 9083],
        [ 7867],
        [ 7456],
        [ 7021],
        [ 6792]], device='cuda:0')
[2024-07-24 10:27:24,359][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[15618],
        [27960],
        [26690],
        [24892],
        [24913],
        [25785],
        [24226],
        [23447],
        [19749],
        [20653],
        [20284],
        [20600],
        [20154],
        [20172],
        [20022],
        [19902],
        [20725],
        [20761],
        [20508]], device='cuda:0')
[2024-07-24 10:27:24,360][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13474],
        [ 7885],
        [ 5950],
        [ 5181],
        [ 5675],
        [ 3918],
        [ 3625],
        [ 4529],
        [ 3346],
        [ 3861],
        [ 3710],
        [ 3549],
        [ 3889],
        [ 4142],
        [ 4145],
        [ 3967],
        [ 3801],
        [ 4459],
        [ 4197]], device='cuda:0')
[2024-07-24 10:27:24,362][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[13582],
        [19009],
        [18519],
        [14998],
        [14641],
        [13741],
        [16949],
        [15641],
        [14682],
        [13955],
        [13751],
        [13219],
        [13054],
        [13126],
        [12928],
        [13036],
        [13642],
        [13554],
        [14033]], device='cuda:0')
[2024-07-24 10:27:24,363][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[18952],
        [10305],
        [10797],
        [13044],
        [11631],
        [17835],
        [ 5651],
        [ 5671],
        [ 5705],
        [ 6570],
        [ 5884],
        [ 3662],
        [ 3372],
        [ 2962],
        [ 3257],
        [ 3060],
        [ 2382],
        [ 2188],
        [ 2131]], device='cuda:0')
[2024-07-24 10:27:24,366][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[20052],
        [16521],
        [16503],
        [16748],
        [16687],
        [16135],
        [15471],
        [15294],
        [14212],
        [14782],
        [14211],
        [14817],
        [14829],
        [15351],
        [15490],
        [15086],
        [16000],
        [16488],
        [15955]], device='cuda:0')
[2024-07-24 10:27:24,368][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 7112],
        [15343],
        [14157],
        [14936],
        [14971],
        [15764],
        [15711],
        [15287],
        [14528],
        [11713],
        [12619],
        [13246],
        [13701],
        [13090],
        [12930],
        [12983],
        [12711],
        [13274],
        [12695]], device='cuda:0')
[2024-07-24 10:27:24,371][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[15444],
        [21589],
        [24895],
        [24033],
        [24833],
        [22988],
        [29142],
        [28879],
        [33260],
        [33374],
        [33215],
        [35117],
        [34578],
        [35530],
        [34049],
        [35315],
        [36361],
        [36155],
        [35697]], device='cuda:0')
[2024-07-24 10:27:24,374][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[32772],
        [24801],
        [16644],
        [22524],
        [33711],
        [20168],
        [28300],
        [38784],
        [30536],
        [28714],
        [35066],
        [37211],
        [33019],
        [34012],
        [43513],
        [32899],
        [34732],
        [40691],
        [44661]], device='cuda:0')
[2024-07-24 10:27:24,377][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459],
        [16459]], device='cuda:0')
[2024-07-24 10:27:24,431][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:24,432][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,432][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,433][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,433][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,433][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,433][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,434][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,434][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,434][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,435][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,435][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,435][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,436][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6143, 0.3857], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,436][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5480, 0.4520], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,436][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0048, 0.9952], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,437][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9963, 0.0037], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,437][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,437][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.6828e-04, 9.9983e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,438][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0012, 0.9988], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,438][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0208, 0.9792], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,438][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0112, 0.9888], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,439][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0020, 0.9980], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,439][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([9.9996e-01, 3.9947e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,439][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3511, 0.6489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,440][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Andrea] are: tensor([0.3379, 0.1502, 0.5119], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,440][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Andrea] are: tensor([0.8498, 0.1013, 0.0489], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,440][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Andrea] are: tensor([0.0115, 0.9455, 0.0429], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,441][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Andrea] are: tensor([0.8177, 0.1266, 0.0557], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,441][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Andrea] are: tensor([0.0047, 0.8871, 0.1082], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,441][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Andrea] are: tensor([2.2255e-04, 9.5182e-01, 4.7955e-02], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,442][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Andrea] are: tensor([0.0185, 0.5561, 0.4253], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,442][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Andrea] are: tensor([0.0027, 0.7355, 0.2618], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,442][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Andrea] are: tensor([0.0040, 0.7229, 0.2732], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,443][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Andrea] are: tensor([0.0014, 0.7506, 0.2480], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,444][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Andrea] are: tensor([0.9405, 0.0017, 0.0578], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,444][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Andrea] are: tensor([0.0309, 0.6595, 0.3096], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,444][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4137, 0.0935, 0.4229, 0.0698], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,448][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.8676, 0.0397, 0.0393, 0.0534], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,451][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0069, 0.5007, 0.0379, 0.4545], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,455][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9756, 0.0052, 0.0100, 0.0092], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,456][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0053, 0.6547, 0.0602, 0.2798], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,456][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.1940e-04, 3.4073e-01, 2.3758e-02, 6.3540e-01], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,456][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0011, 0.1149, 0.0355, 0.8485], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,457][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0026, 0.3204, 0.1364, 0.5407], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,457][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0112, 0.0571, 0.1648, 0.7669], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,457][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0006, 0.4570, 0.1504, 0.3920], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,458][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([9.9975e-01, 2.0527e-06, 2.0892e-04, 3.8905e-05], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,458][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0476, 0.4920, 0.1941, 0.2664], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,458][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.2312, 0.2622, 0.3473, 0.0806, 0.0786], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,460][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.6988, 0.0875, 0.0761, 0.1208, 0.0168], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,463][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([0.0074, 0.7857, 0.0175, 0.1842, 0.0052], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,467][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.6248, 0.1863, 0.0576, 0.1143, 0.0170], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,471][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0035, 0.6686, 0.0549, 0.2384, 0.0347], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,473][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([4.6574e-05, 2.0930e-01, 8.6583e-03, 7.7578e-01, 6.2183e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,473][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([0.0106, 0.2606, 0.0769, 0.6465, 0.0055], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,474][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0024, 0.3154, 0.0994, 0.3913, 0.1915], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,474][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([6.1173e-04, 6.1047e-02, 4.5783e-02, 2.6302e-01, 6.2954e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,475][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0011, 0.4409, 0.1304, 0.3323, 0.0953], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,475][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.9761, 0.0020, 0.0134, 0.0029, 0.0056], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,475][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0079, 0.3848, 0.1390, 0.3885, 0.0798], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,476][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.2727, 0.0793, 0.2785, 0.0406, 0.0375, 0.2913], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,476][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.4037, 0.1138, 0.0333, 0.1710, 0.0062, 0.2720], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,477][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0006, 0.4173, 0.0117, 0.4251, 0.0019, 0.1434], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,478][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.6326, 0.0195, 0.0244, 0.0410, 0.0099, 0.2726], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,482][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0005, 0.3719, 0.0263, 0.3181, 0.0143, 0.2689], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,484][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([7.2468e-06, 2.2602e-01, 7.1254e-03, 6.2871e-01, 3.3900e-03, 1.3474e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,486][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([2.2801e-04, 8.3039e-02, 8.2402e-03, 4.8887e-01, 6.2164e-04, 4.1901e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,489][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0006, 0.2045, 0.0724, 0.4245, 0.1262, 0.1718], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,491][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0034, 0.0302, 0.0708, 0.2141, 0.2176, 0.4639], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,492][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([2.1353e-04, 4.0268e-01, 6.6527e-02, 3.4166e-01, 3.7288e-02, 1.5163e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,492][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([9.5216e-01, 7.0915e-04, 1.5121e-02, 5.4018e-03, 3.4254e-03, 2.3178e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,492][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0331, 0.2415, 0.0771, 0.1195, 0.0387, 0.4900], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,493][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2832, 0.0659, 0.2493, 0.0489, 0.0577, 0.2049, 0.0900],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,493][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4733, 0.0294, 0.0253, 0.0913, 0.0066, 0.1438, 0.2304],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,493][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([3.5697e-04, 2.3334e-01, 5.9744e-03, 2.0535e-01, 1.7181e-03, 7.5874e-02,
        4.7739e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,494][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.5416, 0.0080, 0.0072, 0.0176, 0.0031, 0.1937, 0.2288],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,494][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0007, 0.2552, 0.0101, 0.1715, 0.0139, 0.1684, 0.3802],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,495][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([2.4371e-05, 6.3641e-02, 3.6998e-03, 1.9646e-01, 2.2163e-03, 1.0220e-01,
        6.3176e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,496][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([7.8658e-05, 2.9425e-02, 3.2455e-03, 2.8516e-01, 2.8716e-04, 1.6514e-01,
        5.1666e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,500][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0008, 0.1172, 0.0399, 0.2268, 0.0849, 0.1041, 0.4263],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,503][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0009, 0.0022, 0.0192, 0.0544, 0.1091, 0.2636, 0.5506],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,505][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.4339e-04, 2.7030e-01, 5.9320e-02, 2.4086e-01, 4.5585e-02, 1.4156e-01,
        2.4213e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,507][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([9.6739e-01, 1.6823e-04, 4.0871e-03, 2.7096e-03, 3.6103e-03, 6.2121e-03,
        1.5819e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,509][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0263, 0.1628, 0.0478, 0.0865, 0.0463, 0.3755, 0.2549],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,510][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ lot] are: tensor([0.2017, 0.2150, 0.1812, 0.0776, 0.0504, 0.1485, 0.0679, 0.0577],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,510][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ lot] are: tensor([0.0508, 0.1765, 0.0395, 0.2558, 0.0030, 0.1259, 0.3170, 0.0314],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,510][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ lot] are: tensor([6.1249e-05, 2.8226e-01, 6.0046e-03, 2.0098e-01, 1.5175e-03, 5.4158e-02,
        4.5420e-01, 8.1564e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,511][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ lot] are: tensor([0.1951, 0.0502, 0.0293, 0.0836, 0.0188, 0.1033, 0.5113, 0.0085],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,511][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ lot] are: tensor([3.9588e-04, 4.7228e-01, 1.1693e-02, 1.6575e-01, 5.2782e-03, 7.0193e-02,
        2.4289e-01, 3.1512e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,512][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ lot] are: tensor([8.8784e-06, 6.0742e-02, 3.5050e-03, 2.6543e-01, 1.2366e-03, 5.7987e-02,
        5.7301e-01, 3.8080e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,512][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ lot] are: tensor([3.1036e-05, 9.0464e-02, 4.4123e-03, 3.0710e-01, 2.8625e-04, 7.2561e-02,
        5.2229e-01, 2.8583e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,513][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ lot] are: tensor([0.0006, 0.1239, 0.0316, 0.2388, 0.0682, 0.0955, 0.3745, 0.0668],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,515][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ lot] are: tensor([3.9391e-04, 2.0111e-02, 1.7201e-02, 1.1030e-01, 9.7281e-02, 1.1985e-01,
        4.6437e-01, 1.7050e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,516][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ lot] are: tensor([3.1678e-04, 3.4922e-01, 5.7448e-02, 2.0982e-01, 4.3207e-02, 1.0187e-01,
        1.9317e-01, 4.4945e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,520][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ lot] are: tensor([0.4020, 0.0195, 0.0648, 0.0811, 0.0389, 0.0399, 0.2319, 0.1220],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,524][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ lot] are: tensor([0.0169, 0.2919, 0.0362, 0.0822, 0.0179, 0.1956, 0.2700, 0.0894],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,527][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ of] are: tensor([0.2107, 0.0603, 0.1500, 0.0455, 0.0256, 0.2031, 0.0864, 0.0590, 0.1594],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,527][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ of] are: tensor([0.4727, 0.0417, 0.0328, 0.1001, 0.0029, 0.1165, 0.1845, 0.0227, 0.0261],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,528][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ of] are: tensor([2.0758e-04, 2.4212e-01, 9.3472e-03, 1.8202e-01, 2.1482e-03, 5.1681e-02,
        4.5151e-01, 1.4263e-03, 5.9534e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,528][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ of] are: tensor([0.5109, 0.0084, 0.0044, 0.0230, 0.0012, 0.1659, 0.2366, 0.0105, 0.0391],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,529][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ of] are: tensor([0.0020, 0.2683, 0.0204, 0.1131, 0.0112, 0.0862, 0.3089, 0.0313, 0.1587],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,529][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ of] are: tensor([1.4667e-05, 2.5262e-02, 2.3893e-03, 9.1337e-02, 1.3802e-03, 5.0368e-02,
        3.8559e-01, 3.9097e-02, 4.0456e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,529][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ of] are: tensor([1.3368e-04, 5.7279e-02, 6.0438e-03, 2.5265e-01, 2.2617e-04, 9.0798e-02,
        5.2173e-01, 3.2903e-03, 6.7848e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,530][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ of] are: tensor([0.0010, 0.0732, 0.0207, 0.1126, 0.0516, 0.0629, 0.2656, 0.0540, 0.3583],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,530][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ of] are: tensor([3.3413e-04, 1.9892e-03, 1.5173e-02, 3.9322e-02, 1.0679e-01, 1.3992e-01,
        3.7856e-01, 2.9493e-01, 2.2992e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,532][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ of] are: tensor([0.0002, 0.2009, 0.0537, 0.1666, 0.0415, 0.1054, 0.1919, 0.0509, 0.1889],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,534][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ of] are: tensor([9.8226e-01, 1.1149e-04, 2.4796e-03, 1.5621e-03, 9.8232e-04, 2.5084e-03,
        5.6450e-03, 3.5580e-03, 8.9210e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,537][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ of] are: tensor([0.0247, 0.0983, 0.0234, 0.0493, 0.0320, 0.3474, 0.2230, 0.0507, 0.1512],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,541][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ fun] are: tensor([0.3197, 0.0904, 0.1307, 0.0468, 0.0174, 0.2141, 0.0418, 0.0432, 0.0332,
        0.0628], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,545][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ fun] are: tensor([0.2131, 0.1125, 0.0247, 0.0734, 0.0045, 0.0784, 0.2108, 0.0442, 0.0901,
        0.1484], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,546][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ fun] are: tensor([0.0006, 0.4043, 0.0093, 0.1084, 0.0022, 0.0509, 0.3557, 0.0019, 0.0540,
        0.0127], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,546][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ fun] are: tensor([0.4782, 0.0261, 0.0157, 0.0461, 0.0156, 0.1082, 0.1926, 0.0064, 0.1016,
        0.0095], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,546][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ fun] are: tensor([3.6591e-04, 3.9713e-01, 2.7934e-02, 1.2556e-01, 4.8009e-03, 6.3278e-02,
        1.8491e-01, 2.0371e-02, 1.5837e-01, 1.7287e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,547][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ fun] are: tensor([2.6068e-06, 1.5794e-02, 1.1339e-03, 6.2145e-02, 5.3571e-04, 1.6975e-02,
        2.8595e-01, 4.4656e-02, 4.3000e-01, 1.4281e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,547][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ fun] are: tensor([5.5073e-05, 5.1912e-02, 8.7142e-03, 2.2561e-01, 7.5232e-04, 1.2362e-01,
        4.9423e-01, 4.5729e-03, 6.6513e-02, 2.4021e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,548][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ fun] are: tensor([0.0004, 0.0640, 0.0182, 0.1004, 0.0407, 0.0520, 0.2053, 0.0478, 0.2609,
        0.2103], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,548][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ fun] are: tensor([2.0642e-04, 1.2148e-02, 2.1093e-02, 6.3104e-02, 1.0143e-01, 1.3022e-01,
        3.2583e-01, 1.6490e-01, 1.6255e-02, 1.6482e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,548][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ fun] are: tensor([1.6264e-04, 2.3658e-01, 5.2704e-02, 1.5505e-01, 4.0782e-02, 8.3627e-02,
        1.5078e-01, 3.8547e-02, 1.7928e-01, 6.2486e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,550][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ fun] are: tensor([0.1928, 0.0498, 0.1117, 0.0678, 0.0172, 0.1891, 0.2761, 0.0377, 0.0361,
        0.0216], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,553][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ fun] are: tensor([0.0085, 0.2546, 0.0334, 0.0900, 0.0075, 0.1826, 0.1938, 0.0715, 0.1105,
        0.0476], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,557][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ at] are: tensor([0.0895, 0.0773, 0.2558, 0.0438, 0.0568, 0.1384, 0.0588, 0.0642, 0.0786,
        0.1055, 0.0314], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,561][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ at] are: tensor([0.1627, 0.0580, 0.0367, 0.0829, 0.0048, 0.1336, 0.1650, 0.0164, 0.0333,
        0.2231, 0.0834], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,563][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ at] are: tensor([2.6420e-04, 2.1843e-01, 1.0942e-02, 1.6883e-01, 2.0043e-03, 7.5920e-02,
        4.4326e-01, 1.8481e-03, 4.3565e-02, 2.3900e-02, 1.1042e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,564][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ at] are: tensor([0.3906, 0.0057, 0.0028, 0.0237, 0.0013, 0.0872, 0.2828, 0.0093, 0.1270,
        0.0065, 0.0631], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,564][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ at] are: tensor([0.0004, 0.3897, 0.0326, 0.1291, 0.0062, 0.0786, 0.1721, 0.0143, 0.1467,
        0.0090, 0.0212], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,565][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ at] are: tensor([1.8524e-06, 9.4009e-03, 6.6082e-04, 7.1966e-02, 5.9552e-04, 4.9947e-02,
        3.5001e-01, 2.0873e-02, 2.7712e-01, 9.3337e-02, 1.2610e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,565][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ at] are: tensor([4.0041e-05, 5.0684e-02, 7.3288e-03, 3.0127e-01, 1.9298e-04, 1.0120e-01,
        4.7642e-01, 2.0232e-03, 4.4058e-02, 1.1468e-02, 5.3194e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,566][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ at] are: tensor([0.0007, 0.0372, 0.0071, 0.0651, 0.0186, 0.0370, 0.1543, 0.0258, 0.1732,
        0.1209, 0.3602], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,566][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ at] are: tensor([0.0006, 0.0025, 0.0105, 0.0481, 0.0634, 0.1119, 0.4016, 0.1528, 0.0337,
        0.1329, 0.0421], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,566][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ at] are: tensor([1.5065e-04, 1.6572e-01, 4.0621e-02, 1.4268e-01, 3.4494e-02, 9.0650e-02,
        1.5501e-01, 3.8043e-02, 1.7460e-01, 6.5153e-02, 9.2883e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,568][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ at] are: tensor([0.7828, 0.0028, 0.0289, 0.0196, 0.0046, 0.0200, 0.0778, 0.0273, 0.0178,
        0.0034, 0.0151], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,571][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ at] are: tensor([0.0091, 0.1561, 0.0255, 0.0585, 0.0185, 0.3130, 0.1609, 0.0524, 0.0817,
        0.0663, 0.0580], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:24,575][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ the] are: tensor([0.1364, 0.0810, 0.1558, 0.0393, 0.0511, 0.1294, 0.0829, 0.0594, 0.1114,
        0.1012, 0.0246, 0.0274], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,579][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ the] are: tensor([0.1059, 0.0597, 0.0256, 0.1274, 0.0050, 0.0545, 0.2729, 0.0166, 0.0692,
        0.1442, 0.0381, 0.0808], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,582][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ the] are: tensor([9.1494e-05, 1.9511e-01, 3.8023e-03, 1.2242e-01, 1.5081e-03, 2.5195e-02,
        4.9520e-01, 7.9998e-04, 8.1325e-02, 9.3886e-03, 7.4433e-03, 5.7720e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,582][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ the] are: tensor([0.4433, 0.0068, 0.0013, 0.0173, 0.0011, 0.0445, 0.2754, 0.0146, 0.1345,
        0.0060, 0.0309, 0.0243], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,582][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ the] are: tensor([0.0006, 0.3674, 0.0130, 0.0978, 0.0061, 0.0547, 0.2203, 0.0197, 0.1651,
        0.0062, 0.0117, 0.0373], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,583][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ the] are: tensor([9.0527e-07, 1.4486e-02, 7.8537e-04, 8.6582e-02, 5.1027e-04, 2.7182e-02,
        2.8738e-01, 1.4509e-02, 2.5334e-01, 6.2984e-02, 6.0833e-02, 1.9140e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,583][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ the] are: tensor([1.7575e-05, 5.2029e-02, 2.4166e-03, 3.8120e-01, 1.5095e-04, 3.5773e-02,
        4.2649e-01, 1.7816e-03, 6.1553e-02, 4.8282e-03, 2.7451e-03, 3.1011e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,584][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ the] are: tensor([0.0006, 0.0438, 0.0076, 0.0612, 0.0161, 0.0300, 0.1152, 0.0174, 0.1681,
        0.0829, 0.2844, 0.1727], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,584][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ the] are: tensor([0.0011, 0.0024, 0.0098, 0.0255, 0.0585, 0.0916, 0.2647, 0.1941, 0.0304,
        0.1428, 0.0207, 0.1584], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,585][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ the] are: tensor([8.3799e-05, 1.9035e-01, 3.3533e-02, 1.4326e-01, 3.2142e-02, 6.2777e-02,
        1.4319e-01, 3.3332e-02, 1.6325e-01, 5.3739e-02, 8.0278e-02, 6.4067e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,586][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ the] are: tensor([0.5967, 0.0034, 0.0188, 0.0231, 0.0141, 0.0237, 0.1629, 0.0481, 0.0351,
        0.0149, 0.0207, 0.0385], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,589][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ the] are: tensor([0.0087, 0.1227, 0.0171, 0.0566, 0.0148, 0.2579, 0.1636, 0.0373, 0.1071,
        0.0417, 0.0552, 0.1173], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:24,593][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ store] are: tensor([0.3620, 0.0902, 0.1205, 0.0254, 0.0338, 0.0708, 0.0357, 0.0591, 0.0404,
        0.0408, 0.0187, 0.0134, 0.0892], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,597][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ store] are: tensor([0.0662, 0.1098, 0.0369, 0.1140, 0.0039, 0.0765, 0.2217, 0.0404, 0.0945,
        0.1072, 0.0512, 0.0512, 0.0266], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,600][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ store] are: tensor([2.5425e-04, 2.9762e-01, 5.9691e-03, 8.1018e-02, 2.2027e-03, 4.8266e-02,
        4.4807e-01, 2.9489e-03, 5.6013e-02, 1.5799e-02, 7.1751e-03, 3.3078e-02,
        1.5923e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,600][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ store] are: tensor([0.1271, 0.0452, 0.0040, 0.0598, 0.0041, 0.0522, 0.2601, 0.0084, 0.2661,
        0.0062, 0.1151, 0.0438, 0.0079], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,601][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ store] are: tensor([3.6186e-04, 4.4108e-01, 2.9140e-02, 9.6644e-02, 6.4500e-03, 4.3719e-02,
        1.5293e-01, 2.7287e-02, 1.3741e-01, 1.0251e-02, 1.8102e-02, 3.4963e-02,
        1.6633e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,601][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ store] are: tensor([9.4689e-07, 9.5644e-03, 5.0889e-04, 5.9632e-02, 4.5385e-04, 2.1437e-02,
        2.5661e-01, 2.8880e-02, 3.3354e-01, 6.3374e-02, 5.8299e-02, 1.4971e-01,
        1.7996e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,601][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ store] are: tensor([3.9287e-05, 8.7283e-02, 8.0805e-03, 3.4129e-01, 3.7375e-04, 1.0211e-01,
        3.7138e-01, 3.2743e-03, 4.8779e-02, 1.2155e-02, 5.0404e-03, 1.9540e-02,
        6.5454e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,602][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ store] are: tensor([0.0004, 0.0405, 0.0058, 0.0551, 0.0127, 0.0284, 0.1137, 0.0205, 0.1554,
        0.0733, 0.2677, 0.1710, 0.0556], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,602][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ store] are: tensor([1.4907e-04, 1.1356e-02, 6.8752e-03, 4.3520e-02, 6.3970e-02, 7.8423e-02,
        2.4160e-01, 1.2559e-01, 1.5840e-02, 8.2099e-02, 1.3048e-02, 1.6051e-01,
        1.5701e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,603][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ store] are: tensor([9.3229e-05, 2.0384e-01, 3.3579e-02, 1.4838e-01, 3.4850e-02, 6.6726e-02,
        1.1943e-01, 3.2877e-02, 1.6747e-01, 4.3436e-02, 7.3610e-02, 5.3348e-02,
        2.2363e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,604][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ store] are: tensor([0.0883, 0.0314, 0.0970, 0.0475, 0.0282, 0.0395, 0.3141, 0.0449, 0.0799,
        0.0444, 0.0662, 0.0447, 0.0741], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,607][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ store] are: tensor([0.0051, 0.1767, 0.0242, 0.0589, 0.0063, 0.1744, 0.1558, 0.0534, 0.0829,
        0.0485, 0.0433, 0.1318, 0.0387], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:24,611][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [.] are: tensor([0.6187, 0.0299, 0.0705, 0.0121, 0.0107, 0.0352, 0.0164, 0.0224, 0.0295,
        0.0385, 0.0078, 0.0047, 0.0547, 0.0491], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,615][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [.] are: tensor([0.5701, 0.0353, 0.0553, 0.0365, 0.0044, 0.0428, 0.0626, 0.0236, 0.0182,
        0.0857, 0.0198, 0.0152, 0.0061, 0.0243], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,618][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [.] are: tensor([0.0117, 0.2590, 0.0185, 0.0981, 0.0055, 0.0483, 0.3669, 0.0049, 0.0748,
        0.0182, 0.0133, 0.0415, 0.0013, 0.0379], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,618][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [.] are: tensor([9.8950e-01, 9.2430e-05, 2.1937e-04, 3.2952e-04, 1.5427e-04, 1.6407e-03,
        3.5849e-03, 7.2766e-04, 1.3950e-03, 2.8867e-04, 3.2545e-04, 8.2193e-05,
        2.1354e-05, 1.6375e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,619][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [.] are: tensor([0.0044, 0.3722, 0.0409, 0.0859, 0.0105, 0.0755, 0.1740, 0.0295, 0.1426,
        0.0059, 0.0135, 0.0214, 0.0007, 0.0230], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,619][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [.] are: tensor([8.2513e-06, 1.7014e-02, 1.2437e-03, 7.9342e-02, 6.3926e-04, 2.5931e-02,
        1.7988e-01, 1.9378e-02, 2.4547e-01, 6.2169e-02, 7.3004e-02, 1.8158e-01,
        1.0641e-02, 1.0370e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,620][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [.] are: tensor([0.0011, 0.0890, 0.0129, 0.2098, 0.0006, 0.0722, 0.4396, 0.0092, 0.0624,
        0.0131, 0.0060, 0.0294, 0.0005, 0.0542], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,620][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [.] are: tensor([0.0008, 0.0319, 0.0060, 0.0416, 0.0115, 0.0196, 0.0769, 0.0139, 0.1166,
        0.0662, 0.2100, 0.1376, 0.0475, 0.2200], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,620][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [.] are: tensor([0.0008, 0.0040, 0.0112, 0.0276, 0.1050, 0.0504, 0.1463, 0.2110, 0.0135,
        0.1485, 0.0105, 0.0614, 0.1066, 0.1031], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,621][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [.] are: tensor([0.0002, 0.1658, 0.0375, 0.1236, 0.0333, 0.0580, 0.1083, 0.0333, 0.1544,
        0.0507, 0.0834, 0.0564, 0.0222, 0.0730], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,622][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [.] are: tensor([9.8902e-01, 8.9378e-05, 2.2000e-03, 5.5982e-04, 4.7967e-04, 6.2521e-04,
        2.4037e-03, 1.8576e-03, 5.9276e-04, 2.8109e-04, 4.1617e-04, 2.2520e-04,
        1.6417e-04, 1.0858e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,625][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [.] are: tensor([0.0071, 0.1044, 0.0120, 0.0429, 0.0099, 0.2250, 0.1443, 0.0384, 0.0742,
        0.0592, 0.0557, 0.1124, 0.0629, 0.0514], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:24,629][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Samantha] are: tensor([0.1878, 0.1011, 0.1031, 0.0220, 0.0348, 0.0386, 0.0235, 0.0290, 0.0369,
        0.0185, 0.0163, 0.0228, 0.2180, 0.1228, 0.0249], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,633][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Samantha] are: tensor([0.1400, 0.0727, 0.1212, 0.1034, 0.0361, 0.1085, 0.1359, 0.0740, 0.0470,
        0.0877, 0.0305, 0.0151, 0.0086, 0.0176, 0.0016], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,636][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Samantha] are: tensor([2.3703e-03, 3.5128e-01, 1.8150e-02, 7.6341e-02, 1.5319e-02, 5.9253e-02,
        2.9218e-01, 8.0840e-03, 9.3236e-02, 2.3264e-02, 1.5432e-02, 2.4344e-02,
        1.5411e-03, 1.8900e-02, 3.0602e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,636][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Samantha] are: tensor([0.1275, 0.0820, 0.0104, 0.0399, 0.0116, 0.0305, 0.0742, 0.0133, 0.1015,
        0.0060, 0.1671, 0.0799, 0.0271, 0.2272, 0.0019], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,637][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Samantha] are: tensor([0.0008, 0.3282, 0.0385, 0.1266, 0.0177, 0.0926, 0.1839, 0.0327, 0.1114,
        0.0142, 0.0198, 0.0179, 0.0012, 0.0133, 0.0010], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,637][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Samantha] are: tensor([1.9160e-06, 1.5874e-02, 7.6330e-04, 1.1934e-01, 9.1003e-04, 2.5585e-02,
        1.9667e-01, 2.5382e-02, 3.3054e-01, 6.9686e-02, 4.0080e-02, 1.1275e-01,
        1.5807e-02, 4.6414e-02, 1.9063e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,638][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Samantha] are: tensor([9.7837e-04, 1.2208e-01, 3.8445e-02, 3.0757e-01, 3.3777e-03, 1.5205e-01,
        2.6125e-01, 9.3693e-03, 4.7141e-02, 1.8861e-02, 7.3876e-03, 9.3875e-03,
        5.5251e-04, 2.1481e-02, 7.3892e-05], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,638][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Samantha] are: tensor([0.0005, 0.0596, 0.0081, 0.0636, 0.0237, 0.0321, 0.1167, 0.0206, 0.1433,
        0.0694, 0.1711, 0.1142, 0.0310, 0.1343, 0.0118], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,638][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Samantha] are: tensor([1.8454e-04, 4.3655e-03, 4.5151e-03, 1.3742e-02, 1.0209e-01, 1.6344e-02,
        5.8702e-02, 5.0163e-02, 6.0537e-03, 1.5621e-02, 1.2292e-02, 9.0558e-02,
        8.7496e-02, 5.1685e-02, 4.8619e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,639][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Samantha] are: tensor([0.0002, 0.1653, 0.0392, 0.1139, 0.0473, 0.0626, 0.1095, 0.0299, 0.1567,
        0.0444, 0.0730, 0.0475, 0.0249, 0.0632, 0.0225], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,641][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Samantha] are: tensor([0.1528, 0.0261, 0.0733, 0.0235, 0.0412, 0.0198, 0.1294, 0.0433, 0.0552,
        0.0329, 0.1122, 0.0625, 0.1195, 0.0966, 0.0117], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,643][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Samantha] are: tensor([0.0003, 0.0715, 0.0114, 0.0665, 0.0063, 0.1862, 0.1140, 0.0264, 0.0803,
        0.0341, 0.0433, 0.1966, 0.0997, 0.0611, 0.0023], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:24,647][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ gave] are: tensor([0.2558, 0.0197, 0.0292, 0.0046, 0.0090, 0.0126, 0.0044, 0.0089, 0.0082,
        0.0194, 0.0077, 0.0045, 0.0594, 0.0399, 0.0045, 0.5122],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,651][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ gave] are: tensor([0.1503, 0.0986, 0.0576, 0.0785, 0.0091, 0.0579, 0.1364, 0.0516, 0.0362,
        0.1024, 0.0676, 0.0572, 0.0284, 0.0481, 0.0011, 0.0189],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,654][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ gave] are: tensor([2.5937e-04, 2.2483e-01, 8.8324e-03, 1.4302e-01, 4.7472e-03, 4.1722e-02,
        3.7337e-01, 5.0522e-03, 8.4257e-02, 1.4089e-02, 1.5475e-02, 5.0517e-02,
        1.6513e-03, 3.1590e-02, 8.6987e-05, 5.0439e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,655][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ gave] are: tensor([7.8184e-01, 1.3698e-03, 4.6763e-04, 3.2025e-03, 9.3355e-04, 5.8192e-03,
        2.3551e-02, 4.0863e-03, 2.3560e-02, 1.2313e-03, 1.4671e-02, 7.5739e-03,
        3.9719e-03, 1.2554e-01, 1.1488e-03, 1.0360e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,655][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ gave] are: tensor([1.5197e-04, 3.5167e-01, 1.9408e-02, 1.1183e-01, 5.5165e-03, 4.6620e-02,
        1.5901e-01, 2.4244e-02, 1.9963e-01, 4.4498e-03, 1.7317e-02, 3.8484e-02,
        5.7751e-04, 2.0049e-02, 3.0477e-04, 7.4048e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,655][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ gave] are: tensor([5.3078e-07, 9.5907e-03, 3.5242e-04, 6.5044e-02, 2.6845e-04, 1.5168e-02,
        2.2266e-01, 1.6251e-02, 2.9127e-01, 4.4097e-02, 5.4016e-02, 2.0388e-01,
        1.1131e-02, 5.5107e-02, 1.5402e-04, 1.1012e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,656][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ gave] are: tensor([1.0621e-04, 5.9741e-02, 7.3330e-03, 3.0282e-01, 7.7995e-04, 6.4116e-02,
        4.0043e-01, 5.4328e-03, 6.9212e-02, 1.0725e-02, 5.5542e-03, 2.3545e-02,
        5.2704e-04, 4.8018e-02, 2.7406e-05, 1.6360e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,656][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ gave] are: tensor([1.8446e-04, 3.1480e-02, 3.2297e-03, 4.5250e-02, 9.9592e-03, 1.9943e-02,
        1.0836e-01, 1.4953e-02, 1.5258e-01, 4.5651e-02, 2.0947e-01, 1.3452e-01,
        3.7003e-02, 1.4497e-01, 1.3755e-02, 2.8682e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,657][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ gave] are: tensor([0.0010, 0.0094, 0.0084, 0.0222, 0.0618, 0.0210, 0.1041, 0.0431, 0.0095,
        0.0438, 0.0132, 0.1087, 0.1780, 0.1760, 0.1610, 0.0389],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,658][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ gave] are: tensor([7.0837e-05, 1.6525e-01, 2.5757e-02, 1.1305e-01, 3.0218e-02, 5.3610e-02,
        1.0843e-01, 3.0520e-02, 1.6048e-01, 4.5630e-02, 8.2402e-02, 5.8796e-02,
        2.6099e-02, 6.9433e-02, 1.7363e-02, 1.2897e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,660][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ gave] are: tensor([0.5326, 0.0081, 0.0393, 0.0132, 0.0179, 0.0259, 0.1292, 0.0368, 0.0212,
        0.0110, 0.0201, 0.0247, 0.0280, 0.0778, 0.0076, 0.0067],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,663][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ gave] are: tensor([0.0060, 0.1142, 0.0269, 0.0381, 0.0133, 0.1095, 0.1355, 0.0572, 0.0670,
        0.0517, 0.0530, 0.1394, 0.0657, 0.0582, 0.0089, 0.0555],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:24,667][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.2912, 0.0382, 0.0962, 0.0130, 0.0387, 0.0322, 0.0151, 0.0238, 0.0198,
        0.0416, 0.0105, 0.0094, 0.0561, 0.0529, 0.0107, 0.2280, 0.0228],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,670][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1775, 0.0567, 0.0339, 0.0619, 0.0171, 0.0539, 0.1215, 0.0298, 0.0317,
        0.1995, 0.0343, 0.0600, 0.0129, 0.0435, 0.0013, 0.0197, 0.0449],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,672][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([7.5204e-04, 2.2746e-01, 7.3694e-03, 9.4938e-02, 5.5522e-03, 4.9777e-02,
        3.6343e-01, 4.8257e-03, 8.3131e-02, 3.2194e-02, 1.4747e-02, 7.4750e-02,
        1.6259e-03, 2.7424e-02, 1.2399e-04, 5.9372e-04, 1.1313e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,673][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([7.6268e-01, 5.1387e-03, 9.9855e-04, 6.9457e-03, 1.2678e-03, 9.7458e-03,
        4.9622e-02, 1.6022e-02, 3.7789e-02, 3.8146e-03, 1.3087e-02, 7.4253e-03,
        1.2782e-03, 7.3873e-02, 3.5689e-04, 2.4306e-04, 9.7145e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,673][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([3.6036e-04, 3.7231e-01, 7.8740e-03, 8.8298e-02, 1.0675e-02, 5.4648e-02,
        1.9074e-01, 2.3559e-02, 1.5241e-01, 6.5715e-03, 1.2505e-02, 3.4529e-02,
        4.7657e-04, 2.2007e-02, 8.7717e-04, 6.6699e-04, 2.1490e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,674][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([1.1507e-06, 1.0929e-02, 4.0232e-04, 7.1015e-02, 4.9049e-04, 1.9394e-02,
        2.1970e-01, 1.5855e-02, 1.7143e-01, 5.8242e-02, 4.5857e-02, 1.4233e-01,
        6.0360e-03, 6.4014e-02, 2.2962e-04, 6.1222e-03, 1.6794e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,674][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([1.0201e-04, 6.9041e-02, 4.3431e-03, 2.9414e-01, 1.1400e-03, 6.1832e-02,
        3.7920e-01, 5.7300e-03, 6.5334e-02, 6.5748e-03, 4.8819e-03, 2.9449e-02,
        2.9378e-04, 5.5514e-02, 4.1178e-05, 1.0681e-03, 2.1314e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,675][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0004, 0.0303, 0.0052, 0.0450, 0.0134, 0.0197, 0.0910, 0.0124, 0.1058,
        0.0515, 0.1680, 0.1096, 0.0319, 0.1560, 0.0179, 0.0205, 0.1216],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,675][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0018, 0.0017, 0.0067, 0.0145, 0.0416, 0.0389, 0.1334, 0.0896, 0.0143,
        0.0601, 0.0115, 0.0875, 0.1151, 0.0979, 0.1631, 0.0325, 0.0898],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,676][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([7.5761e-05, 1.4986e-01, 2.9341e-02, 1.1688e-01, 3.0231e-02, 5.4543e-02,
        1.2446e-01, 2.8722e-02, 1.4203e-01, 4.1636e-02, 7.6631e-02, 5.1327e-02,
        2.1553e-02, 7.0066e-02, 1.5262e-02, 1.1394e-02, 3.5982e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,679][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.5736, 0.0068, 0.0156, 0.0238, 0.0198, 0.0178, 0.0987, 0.0474, 0.0296,
        0.0184, 0.0125, 0.0251, 0.0148, 0.0498, 0.0073, 0.0013, 0.0378],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,682][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0046, 0.0968, 0.0158, 0.0455, 0.0165, 0.2126, 0.0976, 0.0379, 0.0663,
        0.0332, 0.0452, 0.0662, 0.0714, 0.0387, 0.0070, 0.0596, 0.0851],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:24,686][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ bone] are: tensor([0.1872, 0.0374, 0.0463, 0.0106, 0.0164, 0.0330, 0.0168, 0.0225, 0.0152,
        0.0181, 0.0121, 0.0113, 0.0640, 0.0291, 0.0089, 0.4193, 0.0294, 0.0224],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,690][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ bone] are: tensor([0.2404, 0.0772, 0.0342, 0.0484, 0.0094, 0.0417, 0.0960, 0.0447, 0.0322,
        0.0858, 0.0595, 0.0810, 0.0322, 0.0445, 0.0018, 0.0203, 0.0465, 0.0045],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,692][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ bone] are: tensor([5.2278e-04, 2.5200e-01, 1.8696e-02, 8.4292e-02, 1.4533e-02, 3.9273e-02,
        3.7209e-01, 7.8348e-03, 7.1812e-02, 2.3660e-02, 1.0765e-02, 5.6950e-02,
        3.8487e-03, 3.1347e-02, 3.1743e-04, 7.8662e-04, 1.0804e-02, 4.6757e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,693][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ bone] are: tensor([0.3536, 0.0369, 0.0061, 0.0351, 0.0125, 0.0200, 0.0827, 0.0109, 0.0828,
        0.0080, 0.0675, 0.0405, 0.0113, 0.1768, 0.0027, 0.0020, 0.0478, 0.0027],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,693][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ bone] are: tensor([0.0007, 0.4231, 0.0281, 0.0724, 0.0250, 0.0412, 0.1385, 0.0558, 0.1090,
        0.0112, 0.0191, 0.0300, 0.0021, 0.0195, 0.0018, 0.0011, 0.0155, 0.0061],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,694][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ bone] are: tensor([2.4695e-06, 1.4400e-02, 6.0943e-04, 6.8652e-02, 4.3474e-04, 1.3960e-02,
        1.7604e-01, 2.1559e-02, 2.7754e-01, 4.0998e-02, 4.0714e-02, 1.2459e-01,
        1.2794e-02, 5.9521e-02, 2.5834e-04, 4.7039e-03, 1.3095e-01, 1.2269e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,694][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ bone] are: tensor([3.0338e-04, 1.4467e-01, 8.5770e-03, 3.0402e-01, 1.5302e-03, 7.4380e-02,
        2.9229e-01, 1.0535e-02, 4.6916e-02, 1.2003e-02, 7.7499e-03, 2.6062e-02,
        7.5571e-04, 4.4302e-02, 4.9022e-05, 1.2146e-03, 2.4459e-02, 1.8458e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,695][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ bone] are: tensor([1.4072e-04, 2.6512e-02, 5.6313e-03, 4.3822e-02, 1.5471e-02, 2.1001e-02,
        8.9534e-02, 1.5385e-02, 1.2364e-01, 5.1302e-02, 1.6500e-01, 1.0124e-01,
        3.1001e-02, 1.2633e-01, 1.5435e-02, 2.3729e-02, 1.1795e-01, 2.6872e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,696][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ bone] are: tensor([4.3882e-05, 7.2596e-03, 3.1365e-03, 3.3786e-02, 5.2262e-02, 2.1248e-02,
        1.4416e-01, 6.1261e-02, 8.8901e-03, 3.7754e-02, 1.0605e-02, 1.7442e-01,
        8.5796e-02, 8.2898e-02, 1.2197e-01, 2.4189e-02, 9.9612e-02, 3.0706e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,697][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ bone] are: tensor([1.1917e-04, 1.9828e-01, 3.5594e-02, 1.1175e-01, 3.8473e-02, 4.8902e-02,
        8.4487e-02, 2.8899e-02, 1.4088e-01, 4.0211e-02, 6.8097e-02, 4.4133e-02,
        2.0137e-02, 6.3743e-02, 1.6695e-02, 9.6781e-03, 2.3057e-02, 2.6860e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,701][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ bone] are: tensor([0.1352, 0.0215, 0.0857, 0.0195, 0.0450, 0.0305, 0.1521, 0.0522, 0.0391,
        0.0424, 0.0536, 0.0484, 0.1094, 0.0725, 0.0152, 0.0069, 0.0566, 0.0142],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,704][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ bone] are: tensor([0.0012, 0.0943, 0.0133, 0.0381, 0.0044, 0.1663, 0.1223, 0.0379, 0.0576,
        0.0212, 0.0397, 0.1241, 0.0334, 0.0437, 0.0018, 0.0352, 0.1489, 0.0166],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:24,708][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.3051, 0.0386, 0.0791, 0.0116, 0.0260, 0.0260, 0.0134, 0.0294, 0.0261,
        0.0368, 0.0110, 0.0091, 0.0631, 0.0455, 0.0074, 0.2167, 0.0218, 0.0219,
        0.0113], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,710][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1007, 0.0841, 0.0565, 0.0753, 0.0147, 0.0418, 0.1765, 0.0323, 0.0519,
        0.0986, 0.0582, 0.0685, 0.0084, 0.0606, 0.0009, 0.0056, 0.0331, 0.0017,
        0.0306], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,711][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.9433e-04, 2.4055e-01, 8.6255e-03, 8.2377e-02, 8.0485e-03, 4.0659e-02,
        3.9938e-01, 4.7141e-03, 1.0504e-01, 1.7733e-02, 1.3956e-02, 4.6319e-02,
        1.0207e-03, 1.7056e-02, 1.2333e-04, 3.5952e-04, 7.4868e-03, 2.3019e-04,
        6.0265e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,711][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([8.1687e-01, 3.4777e-03, 8.8508e-04, 6.9934e-03, 5.2397e-04, 4.4707e-03,
        3.1891e-02, 8.2735e-03, 3.7028e-02, 9.1806e-04, 8.7367e-03, 5.0190e-03,
        4.5559e-04, 6.2791e-02, 2.1629e-04, 1.3882e-04, 7.1118e-03, 2.7838e-04,
        3.9166e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,712][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0011, 0.3836, 0.0131, 0.0554, 0.0114, 0.0389, 0.1997, 0.0290, 0.1447,
        0.0058, 0.0192, 0.0312, 0.0008, 0.0188, 0.0010, 0.0006, 0.0226, 0.0027,
        0.0206], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,712][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([8.8779e-07, 8.0021e-03, 4.7975e-04, 8.0797e-02, 3.8985e-04, 1.7738e-02,
        2.3429e-01, 9.7163e-03, 1.6375e-01, 3.0727e-02, 3.2126e-02, 1.1512e-01,
        3.9965e-03, 5.4266e-02, 1.8434e-04, 4.8573e-03, 1.7729e-01, 3.7888e-03,
        6.2485e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,712][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([2.0391e-04, 7.4903e-02, 8.0097e-03, 2.4387e-01, 3.1994e-03, 4.3038e-02,
        3.6082e-01, 1.0446e-02, 8.6888e-02, 1.1422e-02, 1.3989e-02, 4.6839e-02,
        9.9859e-04, 5.0561e-02, 1.9096e-04, 1.4813e-03, 2.6617e-02, 3.5526e-04,
        1.6165e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,713][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0005, 0.0274, 0.0042, 0.0396, 0.0114, 0.0172, 0.0757, 0.0094, 0.0991,
        0.0410, 0.1238, 0.0844, 0.0251, 0.1313, 0.0167, 0.0171, 0.1062, 0.0232,
        0.1467], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,715][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0016, 0.0014, 0.0039, 0.0095, 0.0294, 0.0285, 0.1081, 0.1004, 0.0104,
        0.0454, 0.0088, 0.0607, 0.0677, 0.0791, 0.1247, 0.0203, 0.0672, 0.1140,
        0.1189], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,717][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.1398e-04, 1.5439e-01, 2.9881e-02, 1.0337e-01, 3.5736e-02, 4.9932e-02,
        1.0633e-01, 2.7578e-02, 1.3294e-01, 4.0466e-02, 6.9523e-02, 4.7308e-02,
        1.9528e-02, 5.9680e-02, 1.8154e-02, 1.0844e-02, 3.1122e-02, 2.7986e-02,
        3.5120e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,719][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([8.5726e-01, 1.9372e-03, 4.8288e-03, 7.0152e-03, 5.2312e-03, 5.0921e-03,
        2.7184e-02, 1.8528e-02, 1.2272e-02, 3.0784e-03, 4.3021e-03, 5.7266e-03,
        6.5266e-03, 1.4889e-02, 2.5329e-03, 2.7894e-04, 1.2517e-02, 3.8464e-03,
        6.9499e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,722][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0023, 0.0796, 0.0114, 0.0482, 0.0131, 0.2809, 0.0915, 0.0193, 0.0628,
        0.0295, 0.0332, 0.0723, 0.0403, 0.0286, 0.0042, 0.0389, 0.0609, 0.0162,
        0.0670], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:24,776][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:27:24,776][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,777][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,778][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,779][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,779][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,782][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,782][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,783][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,784][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,784][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,785][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,786][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:27:24,786][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.6143, 0.3857], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,787][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.5480, 0.4520], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,788][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0048, 0.9952], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,789][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9963, 0.0037], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,789][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,790][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2902, 0.7098], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,793][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0025, 0.9975], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,796][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0227, 0.9773], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,800][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9812, 0.0188], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,803][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0040, 0.9960], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,805][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([9.9995e-01, 5.4435e-05], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,805][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3519, 0.6481], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:27:24,806][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Andrea] are: tensor([0.3379, 0.1502, 0.5119], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,807][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Andrea] are: tensor([0.8498, 0.1013, 0.0489], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,807][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Andrea] are: tensor([0.0115, 0.9455, 0.0429], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,810][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Andrea] are: tensor([0.8177, 0.1266, 0.0557], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,812][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Andrea] are: tensor([0.0047, 0.8871, 0.1082], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,816][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Andrea] are: tensor([0.6760, 0.2667, 0.0574], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,820][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Andrea] are: tensor([0.0855, 0.6838, 0.2307], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,822][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Andrea] are: tensor([0.2979, 0.4421, 0.2600], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,823][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Andrea] are: tensor([0.0360, 0.6361, 0.3280], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,824][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Andrea] are: tensor([0.0134, 0.7526, 0.2340], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,825][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Andrea] are: tensor([0.9284, 0.0016, 0.0699], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,826][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Andrea] are: tensor([0.9183, 0.0251, 0.0566], device='cuda:0') for source tokens [Then, Andrea]
[2024-07-24 10:27:24,829][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.4137, 0.0935, 0.4229, 0.0698], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,833][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.8676, 0.0397, 0.0393, 0.0534], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,836][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0069, 0.5007, 0.0379, 0.4545], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,840][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.9756, 0.0052, 0.0100, 0.0092], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,841][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0053, 0.6547, 0.0602, 0.2798], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,841][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7245, 0.0909, 0.0146, 0.1700], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,842][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0151, 0.2977, 0.0328, 0.6544], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,843][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2971, 0.1472, 0.1384, 0.4173], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,845][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6775, 0.0288, 0.1879, 0.1057], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,847][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0605, 0.4238, 0.0478, 0.4679], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,849][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([9.9951e-01, 3.2358e-06, 4.1647e-04, 6.5608e-05], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,853][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8844, 0.0531, 0.0458, 0.0167], device='cuda:0') for source tokens [Then, Andrea and]
[2024-07-24 10:27:24,857][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.2312, 0.2622, 0.3473, 0.0806, 0.0786], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,858][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.6988, 0.0875, 0.0761, 0.1208, 0.0168], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,859][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([0.0074, 0.7857, 0.0175, 0.1842, 0.0052], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,860][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.6248, 0.1863, 0.0576, 0.1143, 0.0170], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,860][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0035, 0.6686, 0.0549, 0.2384, 0.0347], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,862][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.7023, 0.1662, 0.0175, 0.0978, 0.0162], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,865][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([0.0407, 0.4442, 0.0531, 0.4595, 0.0025], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,869][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.1100, 0.3818, 0.1064, 0.3390, 0.0628], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,873][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([0.0038, 0.1023, 0.0668, 0.1143, 0.7128], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,875][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.0114, 0.5250, 0.0784, 0.3732, 0.0121], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,876][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.9719, 0.0019, 0.0166, 0.0031, 0.0065], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,877][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.4463, 0.2876, 0.1723, 0.0889, 0.0050], device='cuda:0') for source tokens [Then, Andrea and Samantha]
[2024-07-24 10:27:24,878][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.2727, 0.0793, 0.2785, 0.0406, 0.0375, 0.2913], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,878][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.4037, 0.1138, 0.0333, 0.1710, 0.0062, 0.2720], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,880][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0006, 0.4173, 0.0117, 0.4251, 0.0019, 0.1434], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,883][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.6326, 0.0195, 0.0244, 0.0410, 0.0099, 0.2726], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,887][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0005, 0.3719, 0.0263, 0.3181, 0.0143, 0.2689], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,891][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2558, 0.1226, 0.0059, 0.1205, 0.0027, 0.4924], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,893][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([2.2013e-03, 2.3232e-01, 7.8730e-03, 4.3378e-01, 3.7560e-04, 3.2346e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,894][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0157, 0.1357, 0.0261, 0.3622, 0.0104, 0.4499], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,895][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1269, 0.0359, 0.1728, 0.0989, 0.2217, 0.3438], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,895][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.7187e-03, 2.1209e-01, 3.4841e-03, 3.0958e-01, 3.3169e-04, 4.7280e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,896][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.9279, 0.0010, 0.0259, 0.0080, 0.0055, 0.0317], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,898][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.3468, 0.0815, 0.0576, 0.0182, 0.0008, 0.4951], device='cuda:0') for source tokens [Then, Andrea and Samantha had]
[2024-07-24 10:27:24,900][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2832, 0.0659, 0.2493, 0.0489, 0.0577, 0.2049, 0.0900],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,904][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.4733, 0.0294, 0.0253, 0.0913, 0.0066, 0.1438, 0.2304],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,907][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([3.5697e-04, 2.3334e-01, 5.9744e-03, 2.0535e-01, 1.7181e-03, 7.5874e-02,
        4.7739e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,911][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5416, 0.0080, 0.0072, 0.0176, 0.0031, 0.1937, 0.2288],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,911][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0007, 0.2552, 0.0101, 0.1715, 0.0139, 0.1684, 0.3802],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,912][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2422, 0.0195, 0.0016, 0.0389, 0.0019, 0.2774, 0.4185],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,913][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([8.8559e-04, 1.1163e-01, 3.8913e-03, 2.9295e-01, 2.2853e-04, 1.4672e-01,
        4.4370e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,914][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0100, 0.0414, 0.0171, 0.2121, 0.0133, 0.2646, 0.4414],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,916][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0438, 0.0038, 0.0464, 0.0224, 0.1136, 0.2023, 0.5677],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,918][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.5896e-03, 3.8757e-02, 2.0682e-03, 6.9283e-02, 5.5392e-04, 2.1899e-01,
        6.6876e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,920][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([9.5155e-01, 2.3191e-04, 7.0299e-03, 4.0511e-03, 5.8435e-03, 8.7227e-03,
        2.2568e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,924][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2773, 0.0474, 0.0251, 0.0221, 0.0010, 0.4141, 0.2132],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a]
[2024-07-24 10:27:24,927][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ lot] are: tensor([0.2017, 0.2150, 0.1812, 0.0776, 0.0504, 0.1485, 0.0679, 0.0577],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,929][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ lot] are: tensor([0.0508, 0.1765, 0.0395, 0.2558, 0.0030, 0.1259, 0.3170, 0.0314],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,930][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ lot] are: tensor([6.1249e-05, 2.8226e-01, 6.0046e-03, 2.0098e-01, 1.5175e-03, 5.4158e-02,
        4.5420e-01, 8.1564e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,931][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ lot] are: tensor([0.1951, 0.0502, 0.0293, 0.0836, 0.0188, 0.1033, 0.5113, 0.0085],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,931][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ lot] are: tensor([3.9588e-04, 4.7228e-01, 1.1693e-02, 1.6575e-01, 5.2782e-03, 7.0193e-02,
        2.4289e-01, 3.1512e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,933][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ lot] are: tensor([0.0630, 0.0913, 0.0085, 0.0894, 0.0024, 0.2077, 0.5069, 0.0309],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,935][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ lot] are: tensor([1.7901e-04, 2.8048e-01, 3.6928e-03, 3.0286e-01, 1.5113e-04, 5.5674e-02,
        3.5385e-01, 3.1162e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,940][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ lot] are: tensor([0.0039, 0.1495, 0.0107, 0.2602, 0.0092, 0.1261, 0.3682, 0.0721],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,943][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ lot] are: tensor([0.0194, 0.0180, 0.0411, 0.0584, 0.1035, 0.0888, 0.5723, 0.0985],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,945][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ lot] are: tensor([4.9021e-04, 1.6592e-01, 6.2062e-03, 1.6250e-01, 5.0279e-04, 1.0987e-01,
        5.3579e-01, 1.8727e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,947][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ lot] are: tensor([0.3304, 0.0205, 0.0843, 0.0941, 0.0481, 0.0418, 0.2540, 0.1269],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,948][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ lot] are: tensor([0.0435, 0.2593, 0.0715, 0.0475, 0.0014, 0.2625, 0.2829, 0.0314],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot]
[2024-07-24 10:27:24,949][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ of] are: tensor([0.2107, 0.0603, 0.1500, 0.0455, 0.0256, 0.2031, 0.0864, 0.0590, 0.1594],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,949][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ of] are: tensor([0.4727, 0.0417, 0.0328, 0.1001, 0.0029, 0.1165, 0.1845, 0.0227, 0.0261],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,950][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ of] are: tensor([2.0758e-04, 2.4212e-01, 9.3472e-03, 1.8202e-01, 2.1482e-03, 5.1681e-02,
        4.5151e-01, 1.4263e-03, 5.9534e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,953][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ of] are: tensor([0.5109, 0.0084, 0.0044, 0.0230, 0.0012, 0.1659, 0.2366, 0.0105, 0.0391],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,958][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ of] are: tensor([0.0020, 0.2683, 0.0204, 0.1131, 0.0112, 0.0862, 0.3089, 0.0313, 0.1587],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,961][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ of] are: tensor([0.1955, 0.0161, 0.0015, 0.0248, 0.0013, 0.1605, 0.3935, 0.1082, 0.0985],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,963][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ of] are: tensor([1.2349e-03, 1.5800e-01, 5.6133e-03, 2.5870e-01, 1.3595e-04, 8.9599e-02,
        4.1263e-01, 3.9767e-03, 7.0103e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,965][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ of] are: tensor([0.0274, 0.0398, 0.0211, 0.1512, 0.0095, 0.1742, 0.3637, 0.0589, 0.1541],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,966][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ of] are: tensor([0.0274, 0.0032, 0.0469, 0.0166, 0.1388, 0.1096, 0.4303, 0.1913, 0.0358],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,967][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ of] are: tensor([0.0030, 0.0425, 0.0044, 0.0598, 0.0007, 0.2061, 0.5488, 0.0882, 0.0465],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,967][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ of] are: tensor([9.7026e-01, 1.7595e-04, 4.8095e-03, 2.6363e-03, 1.7557e-03, 3.9087e-03,
        9.1727e-03, 5.7162e-03, 1.5692e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,970][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ of] are: tensor([0.3438, 0.0958, 0.0417, 0.0213, 0.0005, 0.2996, 0.1426, 0.0273, 0.0273],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of]
[2024-07-24 10:27:24,973][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ fun] are: tensor([0.3197, 0.0904, 0.1307, 0.0468, 0.0174, 0.2141, 0.0418, 0.0432, 0.0332,
        0.0628], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,976][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ fun] are: tensor([0.2131, 0.1125, 0.0247, 0.0734, 0.0045, 0.0784, 0.2108, 0.0442, 0.0901,
        0.1484], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,980][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ fun] are: tensor([0.0006, 0.4043, 0.0093, 0.1084, 0.0022, 0.0509, 0.3557, 0.0019, 0.0540,
        0.0127], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,983][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ fun] are: tensor([0.4782, 0.0261, 0.0157, 0.0461, 0.0156, 0.1082, 0.1926, 0.0064, 0.1016,
        0.0095], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,983][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ fun] are: tensor([3.6591e-04, 3.9713e-01, 2.7934e-02, 1.2556e-01, 4.8009e-03, 6.3278e-02,
        1.8491e-01, 2.0371e-02, 1.5837e-01, 1.7287e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,984][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ fun] are: tensor([0.0360, 0.0584, 0.0065, 0.0304, 0.0022, 0.0929, 0.4102, 0.0830, 0.2240,
        0.0563], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,985][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ fun] are: tensor([0.0009, 0.1883, 0.0088, 0.2143, 0.0005, 0.1053, 0.3593, 0.0067, 0.0861,
        0.0297], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,987][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ fun] are: tensor([0.0134, 0.1693, 0.0121, 0.1080, 0.0066, 0.0852, 0.2267, 0.1083, 0.1471,
        0.1234], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,991][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ fun] are: tensor([0.0029, 0.0198, 0.0547, 0.0388, 0.1260, 0.1011, 0.4148, 0.1286, 0.0288,
        0.0845], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,994][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ fun] are: tensor([0.0012, 0.1262, 0.0103, 0.1015, 0.0012, 0.1444, 0.4213, 0.0476, 0.1050,
        0.0413], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:24,998][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ fun] are: tensor([0.1545, 0.0492, 0.1350, 0.0719, 0.0194, 0.1863, 0.2862, 0.0369, 0.0395,
        0.0210], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:25,000][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ fun] are: tensor([2.7871e-01, 1.9673e-02, 3.0617e-02, 9.2549e-03, 1.6800e-04, 4.2351e-01,
        1.1345e-01, 3.8861e-02, 5.3424e-02, 3.2329e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun]
[2024-07-24 10:27:25,001][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ at] are: tensor([0.0895, 0.0773, 0.2558, 0.0438, 0.0568, 0.1384, 0.0588, 0.0642, 0.0786,
        0.1055, 0.0314], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,002][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ at] are: tensor([0.1627, 0.0580, 0.0367, 0.0829, 0.0048, 0.1336, 0.1650, 0.0164, 0.0333,
        0.2231, 0.0834], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,003][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ at] are: tensor([2.6420e-04, 2.1843e-01, 1.0942e-02, 1.6883e-01, 2.0043e-03, 7.5920e-02,
        4.4326e-01, 1.8481e-03, 4.3565e-02, 2.3900e-02, 1.1042e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,005][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ at] are: tensor([0.3906, 0.0057, 0.0028, 0.0237, 0.0013, 0.0872, 0.2828, 0.0093, 0.1270,
        0.0065, 0.0631], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,008][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ at] are: tensor([0.0004, 0.3897, 0.0326, 0.1291, 0.0062, 0.0786, 0.1721, 0.0143, 0.1467,
        0.0090, 0.0212], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,012][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ at] are: tensor([0.0613, 0.0264, 0.0032, 0.0304, 0.0021, 0.1898, 0.3581, 0.1292, 0.1277,
        0.0584, 0.0132], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,014][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ at] are: tensor([3.6416e-04, 1.6182e-01, 7.2539e-03, 2.9709e-01, 1.3185e-04, 9.6353e-02,
        3.6207e-01, 2.7452e-03, 5.4801e-02, 1.2235e-02, 5.1357e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,018][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ at] are: tensor([0.0100, 0.0746, 0.0146, 0.1073, 0.0079, 0.1587, 0.1346, 0.0646, 0.1015,
        0.1704, 0.1558], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,019][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ at] are: tensor([0.0386, 0.0043, 0.0223, 0.0277, 0.0656, 0.0826, 0.5079, 0.0943, 0.0531,
        0.0682, 0.0355], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,020][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ at] are: tensor([0.0014, 0.0312, 0.0045, 0.0737, 0.0005, 0.1748, 0.3922, 0.0697, 0.0874,
        0.1256, 0.0391], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,020][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ at] are: tensor([0.7260, 0.0034, 0.0426, 0.0251, 0.0060, 0.0228, 0.0947, 0.0317, 0.0234,
        0.0039, 0.0203], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,021][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ at] are: tensor([4.4448e-01, 1.6827e-02, 8.0917e-03, 8.6245e-03, 7.1132e-05, 2.7952e-01,
        1.1918e-01, 3.8688e-02, 4.6439e-02, 3.2839e-02, 5.2395e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at]
[2024-07-24 10:27:25,023][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ the] are: tensor([0.1364, 0.0810, 0.1558, 0.0393, 0.0511, 0.1294, 0.0829, 0.0594, 0.1114,
        0.1012, 0.0246, 0.0274], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,027][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ the] are: tensor([0.1059, 0.0597, 0.0256, 0.1274, 0.0050, 0.0545, 0.2729, 0.0166, 0.0692,
        0.1442, 0.0381, 0.0808], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,029][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ the] are: tensor([9.1494e-05, 1.9511e-01, 3.8023e-03, 1.2242e-01, 1.5081e-03, 2.5195e-02,
        4.9520e-01, 7.9998e-04, 8.1325e-02, 9.3886e-03, 7.4433e-03, 5.7720e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,033][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ the] are: tensor([0.4433, 0.0068, 0.0013, 0.0173, 0.0011, 0.0445, 0.2754, 0.0146, 0.1345,
        0.0060, 0.0309, 0.0243], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,037][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ the] are: tensor([0.0006, 0.3674, 0.0130, 0.0978, 0.0061, 0.0547, 0.2203, 0.0197, 0.1651,
        0.0062, 0.0117, 0.0373], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,037][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ the] are: tensor([0.0182, 0.0271, 0.0017, 0.0326, 0.0020, 0.0707, 0.5080, 0.0881, 0.1612,
        0.0284, 0.0066, 0.0554], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,038][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ the] are: tensor([1.4609e-04, 2.0832e-01, 2.3788e-03, 3.2852e-01, 8.7654e-05, 3.0941e-02,
        3.0483e-01, 2.2955e-03, 7.4830e-02, 4.4766e-03, 2.3469e-03, 4.0825e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,039][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ the] are: tensor([0.0025, 0.0373, 0.0084, 0.0620, 0.0058, 0.0603, 0.1912, 0.0213, 0.1167,
        0.0668, 0.0789, 0.3487], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,041][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ the] are: tensor([0.0926, 0.0020, 0.0180, 0.0099, 0.0618, 0.0705, 0.3073, 0.1353, 0.0494,
        0.0775, 0.0162, 0.1596], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,045][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ the] are: tensor([0.0008, 0.0739, 0.0034, 0.0807, 0.0008, 0.0566, 0.4788, 0.0675, 0.0734,
        0.0653, 0.0152, 0.0837], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,048][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ the] are: tensor([0.5295, 0.0036, 0.0250, 0.0270, 0.0171, 0.0253, 0.1863, 0.0520, 0.0431,
        0.0165, 0.0259, 0.0486], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,050][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ the] are: tensor([1.3076e-01, 5.5569e-02, 8.6147e-03, 2.0412e-02, 1.7249e-04, 2.2065e-01,
        2.9335e-01, 4.3904e-02, 9.2561e-02, 5.0677e-02, 1.0009e-02, 7.3327e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the]
[2024-07-24 10:27:25,054][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ store] are: tensor([0.3620, 0.0902, 0.1205, 0.0254, 0.0338, 0.0708, 0.0357, 0.0591, 0.0404,
        0.0408, 0.0187, 0.0134, 0.0892], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,055][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ store] are: tensor([0.0662, 0.1098, 0.0369, 0.1140, 0.0039, 0.0765, 0.2217, 0.0404, 0.0945,
        0.1072, 0.0512, 0.0512, 0.0266], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,056][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ store] are: tensor([2.5425e-04, 2.9762e-01, 5.9691e-03, 8.1018e-02, 2.2027e-03, 4.8266e-02,
        4.4807e-01, 2.9489e-03, 5.6013e-02, 1.5799e-02, 7.1751e-03, 3.3078e-02,
        1.5923e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,057][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ store] are: tensor([0.1271, 0.0452, 0.0040, 0.0598, 0.0041, 0.0522, 0.2601, 0.0084, 0.2661,
        0.0062, 0.1151, 0.0438, 0.0079], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,058][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ store] are: tensor([3.6186e-04, 4.4108e-01, 2.9140e-02, 9.6644e-02, 6.4500e-03, 4.3719e-02,
        1.5293e-01, 2.7287e-02, 1.3741e-01, 1.0251e-02, 1.8102e-02, 3.4963e-02,
        1.6633e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,061][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ store] are: tensor([0.0324, 0.0505, 0.0120, 0.0362, 0.0062, 0.1021, 0.3598, 0.1144, 0.1951,
        0.0242, 0.0115, 0.0351, 0.0204], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,064][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ store] are: tensor([4.7520e-04, 2.7777e-01, 7.7924e-03, 2.6613e-01, 2.2035e-04, 7.6438e-02,
        2.5068e-01, 5.0742e-03, 6.7643e-02, 1.4606e-02, 5.1412e-03, 2.7092e-02,
        9.3272e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,068][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ store] are: tensor([0.0053, 0.1033, 0.0092, 0.0553, 0.0043, 0.0530, 0.1540, 0.0620, 0.1077,
        0.0635, 0.0963, 0.1041, 0.1820], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,072][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ store] are: tensor([0.0064, 0.0290, 0.0155, 0.0281, 0.0817, 0.0633, 0.3081, 0.0942, 0.0280,
        0.0410, 0.0087, 0.1650, 0.1312], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,073][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ store] are: tensor([0.0009, 0.1387, 0.0091, 0.1323, 0.0023, 0.1183, 0.3222, 0.0788, 0.1129,
        0.0274, 0.0132, 0.0381, 0.0057], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,074][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ store] are: tensor([0.0697, 0.0301, 0.1120, 0.0486, 0.0304, 0.0364, 0.3125, 0.0415, 0.0847,
        0.0422, 0.0713, 0.0482, 0.0723], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,075][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ store] are: tensor([6.7511e-02, 2.6068e-02, 8.5331e-03, 1.3003e-02, 6.2772e-05, 2.7423e-01,
        3.1566e-01, 4.5600e-02, 1.2050e-01, 4.4487e-02, 1.3757e-02, 6.6424e-02,
        4.1719e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store]
[2024-07-24 10:27:25,075][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [.] are: tensor([0.6187, 0.0299, 0.0705, 0.0121, 0.0107, 0.0352, 0.0164, 0.0224, 0.0295,
        0.0385, 0.0078, 0.0047, 0.0547, 0.0491], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,078][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [.] are: tensor([0.5701, 0.0353, 0.0553, 0.0365, 0.0044, 0.0428, 0.0626, 0.0236, 0.0182,
        0.0857, 0.0198, 0.0152, 0.0061, 0.0243], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,081][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [.] are: tensor([0.0117, 0.2590, 0.0185, 0.0981, 0.0055, 0.0483, 0.3669, 0.0049, 0.0748,
        0.0182, 0.0133, 0.0415, 0.0013, 0.0379], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,084][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [.] are: tensor([9.8950e-01, 9.2430e-05, 2.1937e-04, 3.2952e-04, 1.5427e-04, 1.6407e-03,
        3.5849e-03, 7.2766e-04, 1.3950e-03, 2.8867e-04, 3.2545e-04, 8.2193e-05,
        2.1354e-05, 1.6375e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,087][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [.] are: tensor([0.0044, 0.3722, 0.0409, 0.0859, 0.0105, 0.0755, 0.1740, 0.0295, 0.1426,
        0.0059, 0.0135, 0.0214, 0.0007, 0.0230], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,091][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [.] are: tensor([0.3207, 0.0536, 0.0082, 0.0254, 0.0052, 0.0845, 0.2495, 0.1075, 0.0653,
        0.0343, 0.0066, 0.0230, 0.0052, 0.0109], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,092][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [.] are: tensor([0.0095, 0.2179, 0.0135, 0.1956, 0.0004, 0.0704, 0.2988, 0.0116, 0.0716,
        0.0117, 0.0051, 0.0313, 0.0005, 0.0621], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,093][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [.] are: tensor([0.0353, 0.0524, 0.0227, 0.0322, 0.0115, 0.0812, 0.1115, 0.0372, 0.0792,
        0.1045, 0.0505, 0.1049, 0.1107, 0.1663], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,093][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [.] are: tensor([0.1037, 0.0041, 0.0325, 0.0106, 0.1759, 0.0357, 0.1459, 0.1483, 0.0206,
        0.0741, 0.0059, 0.0424, 0.0783, 0.1222], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,096][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [.] are: tensor([0.0346, 0.1223, 0.0108, 0.0562, 0.0023, 0.1347, 0.2780, 0.1436, 0.0575,
        0.0648, 0.0185, 0.0449, 0.0052, 0.0265], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,098][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [.] are: tensor([9.8421e-01, 1.1943e-04, 3.6146e-03, 7.9609e-04, 7.2181e-04, 7.9931e-04,
        3.2035e-03, 2.4124e-03, 8.6566e-04, 3.7207e-04, 6.2811e-04, 3.2980e-04,
        2.1788e-04, 1.7130e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,100][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [.] are: tensor([5.8984e-01, 9.3576e-03, 8.7237e-03, 5.7179e-03, 2.9335e-04, 1.5262e-01,
        7.9221e-02, 2.9303e-02, 3.5730e-02, 2.7316e-02, 1.8165e-03, 1.3481e-02,
        1.7229e-03, 4.4853e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store.]
[2024-07-24 10:27:25,104][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Samantha] are: tensor([0.1878, 0.1011, 0.1031, 0.0220, 0.0348, 0.0386, 0.0235, 0.0290, 0.0369,
        0.0185, 0.0163, 0.0228, 0.2180, 0.1228, 0.0249], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,109][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Samantha] are: tensor([0.1400, 0.0727, 0.1212, 0.1034, 0.0361, 0.1085, 0.1359, 0.0740, 0.0470,
        0.0877, 0.0305, 0.0151, 0.0086, 0.0176, 0.0016], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,110][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Samantha] are: tensor([2.3703e-03, 3.5128e-01, 1.8150e-02, 7.6341e-02, 1.5319e-02, 5.9253e-02,
        2.9218e-01, 8.0840e-03, 9.3236e-02, 2.3264e-02, 1.5432e-02, 2.4344e-02,
        1.5411e-03, 1.8900e-02, 3.0602e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,111][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Samantha] are: tensor([0.1275, 0.0820, 0.0104, 0.0399, 0.0116, 0.0305, 0.0742, 0.0133, 0.1015,
        0.0060, 0.1671, 0.0799, 0.0271, 0.2272, 0.0019], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,111][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Samantha] are: tensor([0.0008, 0.3282, 0.0385, 0.1266, 0.0177, 0.0926, 0.1839, 0.0327, 0.1114,
        0.0142, 0.0198, 0.0179, 0.0012, 0.0133, 0.0010], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,114][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Samantha] are: tensor([0.1099, 0.0735, 0.0164, 0.0382, 0.0200, 0.0858, 0.2265, 0.1307, 0.2122,
        0.0317, 0.0146, 0.0216, 0.0096, 0.0074, 0.0021], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,115][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Samantha] are: tensor([5.1466e-03, 2.7098e-01, 3.0931e-02, 2.4675e-01, 2.1329e-03, 1.1726e-01,
        1.9368e-01, 1.1842e-02, 5.3733e-02, 1.8067e-02, 7.2570e-03, 1.3687e-02,
        8.2798e-04, 2.7623e-02, 7.6728e-05], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,120][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Samantha] are: tensor([0.0137, 0.1803, 0.0293, 0.0852, 0.0255, 0.0920, 0.1650, 0.0822, 0.1351,
        0.0362, 0.0404, 0.0354, 0.0317, 0.0442, 0.0038], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,122][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Samantha] are: tensor([5.4008e-04, 2.5524e-03, 3.3219e-03, 2.9009e-03, 9.2108e-02, 3.6164e-03,
        2.1906e-02, 1.8342e-02, 4.3897e-03, 2.5773e-03, 4.0257e-03, 4.8156e-02,
        4.1112e-02, 4.4127e-02, 7.1032e-01], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,126][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Samantha] are: tensor([0.0041, 0.1710, 0.0472, 0.0953, 0.0201, 0.1436, 0.2329, 0.1036, 0.0931,
        0.0424, 0.0131, 0.0140, 0.0050, 0.0121, 0.0025], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,127][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Samantha] are: tensor([0.1528, 0.0227, 0.0801, 0.0233, 0.0438, 0.0178, 0.1256, 0.0386, 0.0565,
        0.0292, 0.1173, 0.0648, 0.1103, 0.1029, 0.0143], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,128][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Samantha] are: tensor([0.0223, 0.0482, 0.0183, 0.0260, 0.0010, 0.1053, 0.1222, 0.0780, 0.2033,
        0.0566, 0.0337, 0.1433, 0.0371, 0.1040, 0.0007], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha]
[2024-07-24 10:27:25,129][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ gave] are: tensor([0.2558, 0.0197, 0.0292, 0.0046, 0.0090, 0.0126, 0.0044, 0.0089, 0.0082,
        0.0194, 0.0077, 0.0045, 0.0594, 0.0399, 0.0045, 0.5122],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,132][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ gave] are: tensor([0.1503, 0.0986, 0.0576, 0.0785, 0.0091, 0.0579, 0.1364, 0.0516, 0.0362,
        0.1024, 0.0676, 0.0572, 0.0284, 0.0481, 0.0011, 0.0189],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,135][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ gave] are: tensor([2.5937e-04, 2.2483e-01, 8.8324e-03, 1.4302e-01, 4.7472e-03, 4.1722e-02,
        3.7337e-01, 5.0522e-03, 8.4257e-02, 1.4089e-02, 1.5475e-02, 5.0517e-02,
        1.6513e-03, 3.1590e-02, 8.6987e-05, 5.0439e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,137][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ gave] are: tensor([7.8184e-01, 1.3698e-03, 4.6763e-04, 3.2025e-03, 9.3355e-04, 5.8192e-03,
        2.3551e-02, 4.0863e-03, 2.3560e-02, 1.2313e-03, 1.4671e-02, 7.5739e-03,
        3.9719e-03, 1.2554e-01, 1.1488e-03, 1.0360e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,140][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ gave] are: tensor([1.5197e-04, 3.5167e-01, 1.9408e-02, 1.1183e-01, 5.5165e-03, 4.6620e-02,
        1.5901e-01, 2.4244e-02, 1.9963e-01, 4.4498e-03, 1.7317e-02, 3.8484e-02,
        5.7751e-04, 2.0049e-02, 3.0477e-04, 7.4048e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,143][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ gave] are: tensor([0.0404, 0.0609, 0.0047, 0.0402, 0.0041, 0.0881, 0.3184, 0.0942, 0.1850,
        0.0266, 0.0172, 0.0798, 0.0133, 0.0171, 0.0005, 0.0095],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,144][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ gave] are: tensor([5.8222e-04, 1.6855e-01, 7.1577e-03, 2.8292e-01, 5.2417e-04, 6.1406e-02,
        2.8285e-01, 7.7072e-03, 7.9006e-02, 1.1290e-02, 5.0624e-03, 3.1458e-02,
        7.2612e-04, 5.9896e-02, 2.1949e-05, 8.3091e-04], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,145][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ gave] are: tensor([0.0046, 0.1522, 0.0072, 0.0751, 0.0050, 0.0618, 0.1274, 0.1073, 0.0817,
        0.0457, 0.0960, 0.0880, 0.0586, 0.0627, 0.0012, 0.0253],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,146][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ gave] are: tensor([0.0531, 0.0037, 0.0108, 0.0063, 0.0652, 0.0087, 0.0780, 0.0181, 0.0105,
        0.0150, 0.0093, 0.1026, 0.1616, 0.2369, 0.2078, 0.0124],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,148][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ gave] are: tensor([1.9942e-03, 1.3016e-01, 4.0583e-03, 8.8870e-02, 1.8413e-03, 8.9066e-02,
        3.2729e-01, 8.3135e-02, 9.4645e-02, 3.0104e-02, 2.2436e-02, 7.1763e-02,
        6.7374e-03, 4.3329e-02, 2.8685e-04, 4.2819e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,151][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ gave] are: tensor([0.4898, 0.0079, 0.0474, 0.0142, 0.0200, 0.0246, 0.1351, 0.0348, 0.0239,
        0.0105, 0.0233, 0.0284, 0.0283, 0.0936, 0.0101, 0.0081],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,153][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ gave] are: tensor([4.3802e-01, 1.4920e-02, 1.0174e-02, 4.2752e-03, 1.3947e-04, 1.6271e-01,
        8.8754e-02, 5.0225e-02, 4.1547e-02, 3.0473e-02, 4.9371e-03, 5.6331e-02,
        9.5021e-03, 8.5108e-02, 3.9501e-04, 2.4849e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave]
[2024-07-24 10:27:25,157][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.2912, 0.0382, 0.0962, 0.0130, 0.0387, 0.0322, 0.0151, 0.0238, 0.0198,
        0.0416, 0.0105, 0.0094, 0.0561, 0.0529, 0.0107, 0.2280, 0.0228],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,162][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1775, 0.0567, 0.0339, 0.0619, 0.0171, 0.0539, 0.1215, 0.0298, 0.0317,
        0.1995, 0.0343, 0.0600, 0.0129, 0.0435, 0.0013, 0.0197, 0.0449],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,163][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([7.5204e-04, 2.2746e-01, 7.3694e-03, 9.4938e-02, 5.5522e-03, 4.9777e-02,
        3.6343e-01, 4.8257e-03, 8.3131e-02, 3.2194e-02, 1.4747e-02, 7.4750e-02,
        1.6259e-03, 2.7424e-02, 1.2399e-04, 5.9372e-04, 1.1313e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,163][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([7.6268e-01, 5.1387e-03, 9.9855e-04, 6.9457e-03, 1.2678e-03, 9.7458e-03,
        4.9622e-02, 1.6022e-02, 3.7789e-02, 3.8146e-03, 1.3087e-02, 7.4253e-03,
        1.2782e-03, 7.3873e-02, 3.5689e-04, 2.4306e-04, 9.7145e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,164][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([3.6036e-04, 3.7231e-01, 7.8740e-03, 8.8298e-02, 1.0675e-02, 5.4648e-02,
        1.9074e-01, 2.3559e-02, 1.5241e-01, 6.5715e-03, 1.2505e-02, 3.4529e-02,
        4.7657e-04, 2.2007e-02, 8.7717e-04, 6.6699e-04, 2.1490e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,167][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0353, 0.0550, 0.0029, 0.0479, 0.0045, 0.0977, 0.3206, 0.1788, 0.1369,
        0.0276, 0.0069, 0.0440, 0.0060, 0.0128, 0.0004, 0.0033, 0.0193],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,169][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([5.4983e-04, 2.1274e-01, 4.3040e-03, 2.4393e-01, 7.3665e-04, 5.3741e-02,
        2.6888e-01, 8.2518e-03, 7.9073e-02, 6.0895e-03, 4.4745e-03, 3.6401e-02,
        3.6303e-04, 5.7171e-02, 2.8191e-05, 4.8546e-04, 2.2778e-02],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,173][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0030, 0.0526, 0.0077, 0.0702, 0.0074, 0.0610, 0.1310, 0.0714, 0.0949,
        0.0849, 0.0652, 0.1228, 0.0623, 0.0782, 0.0018, 0.0163, 0.0693],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,177][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1661, 0.0007, 0.0093, 0.0038, 0.0365, 0.0211, 0.1121, 0.0412, 0.0177,
        0.0206, 0.0077, 0.0744, 0.0958, 0.1084, 0.2162, 0.0099, 0.0585],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,179][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([1.2478e-03, 5.4593e-02, 2.9849e-03, 5.0156e-02, 1.2631e-03, 5.3893e-02,
        3.5116e-01, 6.0742e-02, 6.1468e-02, 2.4061e-02, 1.8385e-02, 6.2095e-02,
        3.2364e-03, 3.4798e-02, 2.7585e-04, 4.3448e-03, 2.1530e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,180][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5109, 0.0071, 0.0197, 0.0270, 0.0234, 0.0181, 0.1093, 0.0480, 0.0351,
        0.0194, 0.0149, 0.0302, 0.0158, 0.0629, 0.0100, 0.0016, 0.0465],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,181][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([2.2489e-01, 2.1846e-02, 4.4660e-03, 9.5911e-03, 1.5308e-04, 1.1560e-01,
        1.0670e-01, 1.2123e-01, 1.0129e-01, 5.5121e-02, 4.3487e-03, 4.0905e-02,
        2.8827e-03, 5.7387e-02, 2.2663e-04, 5.9301e-04, 1.3276e-01],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a]
[2024-07-24 10:27:25,183][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ bone] are: tensor([0.1872, 0.0374, 0.0463, 0.0106, 0.0164, 0.0330, 0.0168, 0.0225, 0.0152,
        0.0181, 0.0121, 0.0113, 0.0640, 0.0291, 0.0089, 0.4193, 0.0294, 0.0224],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,186][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ bone] are: tensor([0.2404, 0.0772, 0.0342, 0.0484, 0.0094, 0.0417, 0.0960, 0.0447, 0.0322,
        0.0858, 0.0595, 0.0810, 0.0322, 0.0445, 0.0018, 0.0203, 0.0465, 0.0045],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,188][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ bone] are: tensor([5.2278e-04, 2.5200e-01, 1.8696e-02, 8.4292e-02, 1.4533e-02, 3.9273e-02,
        3.7209e-01, 7.8348e-03, 7.1812e-02, 2.3660e-02, 1.0765e-02, 5.6950e-02,
        3.8487e-03, 3.1347e-02, 3.1743e-04, 7.8662e-04, 1.0804e-02, 4.6757e-04],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,192][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ bone] are: tensor([0.3536, 0.0369, 0.0061, 0.0351, 0.0125, 0.0200, 0.0827, 0.0109, 0.0828,
        0.0080, 0.0675, 0.0405, 0.0113, 0.1768, 0.0027, 0.0020, 0.0478, 0.0027],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,197][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ bone] are: tensor([0.0007, 0.4231, 0.0281, 0.0724, 0.0250, 0.0412, 0.1385, 0.0558, 0.1090,
        0.0112, 0.0191, 0.0300, 0.0021, 0.0195, 0.0018, 0.0011, 0.0155, 0.0061],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,198][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ bone] are: tensor([0.0400, 0.0777, 0.0110, 0.0511, 0.0097, 0.0567, 0.2381, 0.1097, 0.2338,
        0.0134, 0.0125, 0.0867, 0.0141, 0.0177, 0.0013, 0.0046, 0.0202, 0.0015],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,199][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ bone] are: tensor([1.7715e-03, 3.5860e-01, 7.5633e-03, 2.2122e-01, 7.7100e-04, 5.1035e-02,
        1.7785e-01, 1.3765e-02, 5.0927e-02, 1.1595e-02, 5.7926e-03, 2.9173e-02,
        8.4757e-04, 4.5110e-02, 2.9413e-05, 4.9659e-04, 2.3381e-02, 8.2983e-05],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,199][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ bone] are: tensor([0.0071, 0.1353, 0.0088, 0.0828, 0.0073, 0.0494, 0.1596, 0.1167, 0.1089,
        0.0266, 0.0645, 0.0807, 0.0558, 0.0387, 0.0014, 0.0121, 0.0421, 0.0027],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,202][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ bone] are: tensor([0.0008, 0.0107, 0.0050, 0.0180, 0.0622, 0.0108, 0.1442, 0.0363, 0.0144,
        0.0119, 0.0061, 0.1965, 0.0594, 0.1331, 0.1866, 0.0072, 0.0785, 0.0185],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,205][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ bone] are: tensor([0.0007, 0.1804, 0.0152, 0.1026, 0.0069, 0.0563, 0.2213, 0.0918, 0.1379,
        0.0292, 0.0237, 0.0443, 0.0046, 0.0348, 0.0007, 0.0016, 0.0463, 0.0016],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,208][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ bone] are: tensor([0.1223, 0.0197, 0.0952, 0.0196, 0.0478, 0.0272, 0.1489, 0.0454, 0.0413,
        0.0386, 0.0580, 0.0518, 0.1031, 0.0792, 0.0185, 0.0075, 0.0602, 0.0157],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,211][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ bone] are: tensor([2.7260e-01, 2.1435e-02, 1.2383e-02, 8.6470e-03, 9.3705e-05, 1.2969e-01,
        9.1722e-02, 6.7943e-02, 5.3907e-02, 3.2985e-02, 7.5417e-03, 5.0234e-02,
        6.3507e-03, 3.7358e-02, 2.1597e-04, 2.2327e-03, 1.9923e-01, 5.4252e-03],
       device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone]
[2024-07-24 10:27:25,215][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.3051, 0.0386, 0.0791, 0.0116, 0.0260, 0.0260, 0.0134, 0.0294, 0.0261,
        0.0368, 0.0110, 0.0091, 0.0631, 0.0455, 0.0074, 0.2167, 0.0218, 0.0219,
        0.0113], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,216][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1007, 0.0841, 0.0565, 0.0753, 0.0147, 0.0418, 0.1765, 0.0323, 0.0519,
        0.0986, 0.0582, 0.0685, 0.0084, 0.0606, 0.0009, 0.0056, 0.0331, 0.0017,
        0.0306], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,217][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([2.9433e-04, 2.4055e-01, 8.6255e-03, 8.2377e-02, 8.0485e-03, 4.0659e-02,
        3.9938e-01, 4.7141e-03, 1.0504e-01, 1.7733e-02, 1.3956e-02, 4.6319e-02,
        1.0207e-03, 1.7056e-02, 1.2333e-04, 3.5952e-04, 7.4868e-03, 2.3019e-04,
        6.0265e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,218][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([8.1687e-01, 3.4777e-03, 8.8508e-04, 6.9934e-03, 5.2397e-04, 4.4707e-03,
        3.1891e-02, 8.2735e-03, 3.7028e-02, 9.1806e-04, 8.7367e-03, 5.0190e-03,
        4.5559e-04, 6.2791e-02, 2.1629e-04, 1.3882e-04, 7.1118e-03, 2.7838e-04,
        3.9166e-03], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,221][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0011, 0.3836, 0.0131, 0.0554, 0.0114, 0.0389, 0.1997, 0.0290, 0.1447,
        0.0058, 0.0192, 0.0312, 0.0008, 0.0188, 0.0010, 0.0006, 0.0226, 0.0027,
        0.0206], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,223][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([2.9377e-02, 5.8115e-02, 3.2866e-03, 4.2445e-02, 5.6271e-03, 8.9600e-02,
        3.6496e-01, 1.6038e-01, 1.2889e-01, 2.2176e-02, 8.0149e-03, 3.2843e-02,
        4.4543e-03, 8.8496e-03, 3.5450e-04, 2.0163e-03, 1.5150e-02, 5.8018e-04,
        2.2885e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,226][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([6.8359e-04, 1.8962e-01, 5.9890e-03, 2.1662e-01, 1.3433e-03, 3.4763e-02,
        2.8166e-01, 1.1370e-02, 9.5341e-02, 8.2125e-03, 9.0279e-03, 5.0759e-02,
        7.7841e-04, 4.9428e-02, 6.6404e-05, 4.4859e-04, 2.5974e-02, 1.0608e-04,
        1.7815e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,230][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0047, 0.0467, 0.0046, 0.0446, 0.0054, 0.0275, 0.0796, 0.0379, 0.1054,
        0.0320, 0.0586, 0.1279, 0.0462, 0.0779, 0.0033, 0.0138, 0.0832, 0.0038,
        0.1969], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,234][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.3877, 0.0006, 0.0058, 0.0020, 0.0250, 0.0128, 0.0712, 0.0389, 0.0118,
        0.0134, 0.0051, 0.0371, 0.0377, 0.0641, 0.1333, 0.0044, 0.0319, 0.0642,
        0.0530], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,235][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0013, 0.0539, 0.0040, 0.0344, 0.0029, 0.0367, 0.3051, 0.0770, 0.0604,
        0.0354, 0.0252, 0.0540, 0.0044, 0.0204, 0.0005, 0.0026, 0.1537, 0.0015,
        0.1266], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,236][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([8.0965e-01, 2.2774e-03, 6.9566e-03, 9.1375e-03, 6.9982e-03, 5.8008e-03,
        3.4223e-02, 2.1112e-02, 1.7071e-02, 3.6407e-03, 6.0561e-03, 8.0468e-03,
        8.1232e-03, 2.2262e-02, 4.0773e-03, 4.0640e-04, 1.7977e-02, 5.9203e-03,
        1.0266e-02], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,237][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1808, 0.0335, 0.0054, 0.0113, 0.0003, 0.1044, 0.1122, 0.0920, 0.0800,
        0.0444, 0.0080, 0.0498, 0.0036, 0.0814, 0.0005, 0.0007, 0.1473, 0.0108,
        0.0338], device='cuda:0') for source tokens [Then, Andrea and Samantha had a lot of fun at the store. Samantha gave a bone to]
[2024-07-24 10:27:25,240][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:27:25,242][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[85],
        [11],
        [ 4],
        [ 1],
        [ 2],
        [ 1],
        [ 1],
        [ 2],
        [ 4],
        [ 2],
        [ 4],
        [19],
        [10],
        [ 5],
        [ 2],
        [ 2],
        [ 1],
        [ 3],
        [ 1]], device='cuda:0')
[2024-07-24 10:27:25,245][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[158],
        [ 15],
        [  6],
        [  2],
        [  3],
        [  1],
        [  1],
        [  8],
        [  9],
        [ 10],
        [  4],
        [ 15],
        [ 10],
        [  2],
        [  4],
        [  6],
        [  1],
        [  9],
        [  2]], device='cuda:0')
[2024-07-24 10:27:25,248][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[11624],
        [ 3401],
        [ 1450],
        [ 1685],
        [ 1634],
        [ 2159],
        [ 2183],
        [ 2234],
        [ 2648],
        [ 2809],
        [ 2276],
        [ 2575],
        [ 2631],
        [ 3733],
        [ 2558],
        [ 5287],
        [ 3463],
        [ 4400],
        [ 3711]], device='cuda:0')
[2024-07-24 10:27:25,250][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 1369],
        [20695],
        [ 8324],
        [ 7776],
        [21634],
        [23004],
        [23858],
        [33056],
        [23886],
        [30976],
        [34257],
        [37985],
        [36469],
        [28054],
        [35185],
        [38227],
        [38814],
        [38690],
        [39674]], device='cuda:0')
[2024-07-24 10:27:25,253][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[36833],
        [50243],
        [50244],
        [50250],
        [50246],
        [50250],
        [50252],
        [50252],
        [50253],
        [50252],
        [50253],
        [50253],
        [50253],
        [50254],
        [50253],
        [50254],
        [50254],
        [50254],
        [50254]], device='cuda:0')
[2024-07-24 10:27:25,256][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[42265],
        [42144],
        [34844],
        [41933],
        [29599],
        [38196],
        [33323],
        [28147],
        [31884],
        [29632],
        [28104],
        [27442],
        [25735],
        [42082],
        [29015],
        [33689],
        [33620],
        [30114],
        [34411]], device='cuda:0')
[2024-07-24 10:27:25,257][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[33952],
        [36533],
        [36153],
        [31981],
        [32418],
        [27971],
        [26498],
        [29898],
        [26360],
        [28169],
        [27858],
        [27408],
        [28730],
        [27703],
        [27117],
        [26627],
        [27223],
        [28673],
        [27376]], device='cuda:0')
[2024-07-24 10:27:25,259][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[26769],
        [ 7005],
        [ 6919],
        [ 5386],
        [ 5194],
        [ 4350],
        [ 2498],
        [ 2752],
        [ 2522],
        [ 2463],
        [ 2184],
        [ 1967],
        [ 2009],
        [ 1872],
        [ 2165],
        [ 1894],
        [ 1634],
        [ 1775],
        [ 1629]], device='cuda:0')
[2024-07-24 10:27:25,261][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 9153],
        [ 3666],
        [ 5877],
        [ 9959],
        [ 8320],
        [10063],
        [10859],
        [10109],
        [10781],
        [10720],
        [10736],
        [10850],
        [10315],
        [10772],
        [ 9869],
        [11013],
        [11166],
        [10079],
        [11467]], device='cuda:0')
[2024-07-24 10:27:25,263][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[48890],
        [25177],
        [26519],
        [25527],
        [27743],
        [27346],
        [24454],
        [25236],
        [26635],
        [25219],
        [22200],
        [20697],
        [20725],
        [19121],
        [20965],
        [20253],
        [19454],
        [19778],
        [18967]], device='cuda:0')
[2024-07-24 10:27:25,266][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11763],
        [22422],
        [18404],
        [20023],
        [18100],
        [20152],
        [23649],
        [21922],
        [20738],
        [20761],
        [21650],
        [21518],
        [21559],
        [20419],
        [19093],
        [21141],
        [21352],
        [22343],
        [21278]], device='cuda:0')
[2024-07-24 10:27:25,268][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[12566],
        [16369],
        [17226],
        [17570],
        [18553],
        [20361],
        [23159],
        [22227],
        [23571],
        [23086],
        [24780],
        [24566],
        [24350],
        [25675],
        [25701],
        [25739],
        [25985],
        [25464],
        [26285]], device='cuda:0')
[2024-07-24 10:27:25,271][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[40807],
        [40805],
        [30079],
        [40770],
        [37849],
        [35230],
        [37664],
        [16403],
        [39356],
        [12603],
        [22363],
        [19292],
        [15161],
        [39940],
        [18648],
        [19735],
        [20744],
        [18345],
        [30821]], device='cuda:0')
[2024-07-24 10:27:25,274][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[22045],
        [ 1602],
        [  487],
        [  874],
        [ 1083],
        [ 2551],
        [ 3347],
        [ 2890],
        [ 4437],
        [ 3059],
        [ 3616],
        [ 3846],
        [ 3106],
        [ 3764],
        [ 3672],
        [ 3355],
        [ 3725],
        [ 4008],
        [ 4207]], device='cuda:0')
[2024-07-24 10:27:25,276][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[13977],
        [ 9494],
        [ 7586],
        [ 8605],
        [ 7841],
        [ 9481],
        [ 6690],
        [ 9627],
        [ 9468],
        [ 7939],
        [ 7910],
        [ 8946],
        [11296],
        [12616],
        [ 9738],
        [ 7329],
        [ 7572],
        [ 9951],
        [10301]], device='cuda:0')
[2024-07-24 10:27:25,278][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[21738],
        [32692],
        [24002],
        [24638],
        [25857],
        [24372],
        [23983],
        [26346],
        [24112],
        [25679],
        [23479],
        [23901],
        [25731],
        [27447],
        [24859],
        [20541],
        [22278],
        [21153],
        [22747]], device='cuda:0')
[2024-07-24 10:27:25,280][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[18692],
        [24323],
        [22340],
        [24098],
        [28291],
        [31161],
        [30272],
        [31940],
        [30158],
        [28232],
        [27800],
        [28930],
        [29057],
        [26826],
        [29940],
        [28316],
        [26922],
        [27151],
        [28614]], device='cuda:0')
[2024-07-24 10:27:25,281][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[29553],
        [11921],
        [12306],
        [16745],
        [13724],
        [18636],
        [22512],
        [21616],
        [22549],
        [20151],
        [23264],
        [23562],
        [22302],
        [22778],
        [21591],
        [23050],
        [23410],
        [23125],
        [23326]], device='cuda:0')
[2024-07-24 10:27:25,284][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11571],
        [11421],
        [ 9660],
        [10853],
        [ 9670],
        [12059],
        [10647],
        [ 9989],
        [10777],
        [10985],
        [11715],
        [11616],
        [12365],
        [11117],
        [13110],
        [12517],
        [12182],
        [12822],
        [12055]], device='cuda:0')
[2024-07-24 10:27:25,287][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[9817],
        [8537],
        [8386],
        [8117],
        [8184],
        [8214],
        [7966],
        [7668],
        [7738],
        [7513],
        [7533],
        [7374],
        [7406],
        [7497],
        [7768],
        [7384],
        [7387],
        [7567],
        [7362]], device='cuda:0')
[2024-07-24 10:27:25,289][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8404],
        [12205],
        [11821],
        [10184],
        [11146],
        [ 9043],
        [ 9893],
        [ 9970],
        [ 8862],
        [ 9544],
        [ 8800],
        [ 9593],
        [ 9165],
        [ 9185],
        [ 8806],
        [ 9232],
        [ 8427],
        [ 8913],
        [ 8696]], device='cuda:0')
[2024-07-24 10:27:25,292][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[19239],
        [27028],
        [27616],
        [28673],
        [28502],
        [29943],
        [22787],
        [23595],
        [23013],
        [23656],
        [23753],
        [23527],
        [24674],
        [23157],
        [25769],
        [23564],
        [23051],
        [24618],
        [22237]], device='cuda:0')
[2024-07-24 10:27:25,295][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[29619],
        [25474],
        [28027],
        [27848],
        [27588],
        [27250],
        [26373],
        [27624],
        [26298],
        [25463],
        [22379],
        [21299],
        [23135],
        [20063],
        [25632],
        [23673],
        [21390],
        [24465],
        [21362]], device='cuda:0')
[2024-07-24 10:27:25,297][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[20577],
        [20562],
        [16326],
        [20357],
        [14785],
        [11428],
        [12706],
        [13445],
        [13024],
        [13409],
        [12565],
        [21913],
        [13913],
        [16639],
        [18719],
        [18170],
        [13376],
        [14190],
        [19364]], device='cuda:0')
[2024-07-24 10:27:25,299][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[11144],
        [19930],
        [16886],
        [13799],
        [14617],
        [12539],
        [15194],
        [15962],
        [14731],
        [16095],
        [15434],
        [16395],
        [16013],
        [15560],
        [15465],
        [16612],
        [20525],
        [17775],
        [20758]], device='cuda:0')
[2024-07-24 10:27:25,301][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15542],
        [15536],
        [ 9602],
        [15492],
        [12813],
        [ 9396],
        [11365],
        [ 9747],
        [12620],
        [ 9976],
        [ 8217],
        [ 9220],
        [ 9553],
        [13931],
        [ 8832],
        [ 8923],
        [ 8993],
        [ 8705],
        [ 6898]], device='cuda:0')
[2024-07-24 10:27:25,302][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 6599],
        [ 8624],
        [ 5300],
        [ 6221],
        [ 8802],
        [10189],
        [10885],
        [11187],
        [10557],
        [10499],
        [10313],
        [11353],
        [11279],
        [ 9692],
        [10636],
        [10118],
        [11072],
        [11075],
        [10829]], device='cuda:0')
[2024-07-24 10:27:25,305][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[24058],
        [25575],
        [30047],
        [26885],
        [27457],
        [25485],
        [24410],
        [24069],
        [24874],
        [25758],
        [26402],
        [24641],
        [24769],
        [26799],
        [24086],
        [25549],
        [25590],
        [24966],
        [25751]], device='cuda:0')
[2024-07-24 10:27:25,306][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[31027],
        [34080],
        [34525],
        [34642],
        [31267],
        [31131],
        [35910],
        [31067],
        [30428],
        [31496],
        [31661],
        [31905],
        [29629],
        [25849],
        [29813],
        [30830],
        [34259],
        [28264],
        [30821]], device='cuda:0')
[2024-07-24 10:27:25,309][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483],
        [12483]], device='cuda:0')
