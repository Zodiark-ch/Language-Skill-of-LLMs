[2024-07-24 10:20:14,037][explain_satisfiability.py][line:287][INFO] ############ CASE TEXT isThen, Angela and Tiffany had a long argument, and afterwards Tiffany said to
[2024-07-24 10:20:14,037][explain_satisfiability.py][line:288][INFO] ############ CASE Prediction is  Angela
[2024-07-24 10:20:14,037][explain_satisfiability.py][line:289][INFO] ############ Refined Forward Graph
[2024-07-24 10:20:14,037][explain_satisfiability.py][line:290][INFO] ****** Layer 1
[2024-07-24 10:20:14,037][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 0
[2024-07-24 10:20:14,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,037][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 1
[2024-07-24 10:20:14,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,037][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 2
[2024-07-24 10:20:14,037][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 3
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 4
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 5
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 6
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit3', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 7
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 8
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 9
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 10
[2024-07-24 10:20:14,038][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 11
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 12
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 13
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 14
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit5', 'circuit16', 'circuit17', 'circuit22', 'circuit24']
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 15
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 16
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit12', 'circuit27']
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 17
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11']
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 18
[2024-07-24 10:20:14,039][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 19
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit26']
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 20
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit13']
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 21
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 22
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 23
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 24
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 25
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 26
[2024-07-24 10:20:14,040][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 27
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:296][INFO] Layer 1 and circuit 28
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 0
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 1
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 2
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit6', 'circuit7', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 3
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,041][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 4
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 5
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit21']
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 6
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit24']
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 7
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 8
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit27']
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 9
[2024-07-24 10:20:14,042][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit17', 'circuit19', 'circuit27']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 10
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 11
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 12
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 13
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 14
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,043][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 15
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit27']
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 16
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 17
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 18
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 19
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,044][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 20
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 21
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 22
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 23
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 24
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit18', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 25
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,045][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 26
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 27
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:296][INFO] Layer 2 and circuit 28
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 0
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 1
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,046][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit1', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit27']
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit23', 'circuit27']
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 2
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20']
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit2', 'circuit8', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 3
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit21', 'circuit22']
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 4
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit18']
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 5
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,047][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 6
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 7
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 8
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 9
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,048][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 10
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 11
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 12
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 13
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,049][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 14
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 15
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 16
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 17
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,050][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 18
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 19
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 20
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 21
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,051][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 22
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 23
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 24
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 25
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,052][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 26
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 27
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:296][INFO] Layer 3 and circuit 28
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 0
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,053][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 1
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 2
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit15', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 3
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,054][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 4
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 5
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit20', 'circuit22']
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 6
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 7
[2024-07-24 10:20:14,055][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 8
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 9
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit23']
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit23', 'circuit26']
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 10
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,056][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 11
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 12
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 13
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit4', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,057][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 14
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 15
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 16
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit27']
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit17', 'circuit22']
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,058][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 17
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 18
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 19
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 20
[2024-07-24 10:20:14,059][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit24']
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 21
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 22
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23']
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 23
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,060][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 24
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 25
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 26
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,061][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 27
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:296][INFO] Layer 4 and circuit 28
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 0
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,062][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 1
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 2
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit27']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit13']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit26']
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 3
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,063][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 4
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 5
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit22']
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,064][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 6
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 7
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 8
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:14,065][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 9
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit24']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 10
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit6', 'circuit14', 'circuit16', 'circuit17', 'circuit20']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 11
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,066][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit19', 'circuit25']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit23']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 12
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit16', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 13
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit7', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit3', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,067][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 14
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit9', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 15
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit18']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit7', 'circuit9', 'circuit10', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 16
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit24']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:20:14,068][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 17
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit22', 'circuit25']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 18
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit21', 'circuit22']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit1', 'circuit5', 'circuit14', 'circuit15', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit25']
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 19
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,069][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 20
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit25']
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 21
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit26']
[2024-07-24 10:20:14,070][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 22
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 23
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 24
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit24']
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,071][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit16']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 25
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit20', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 26
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 27
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,072][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:296][INFO] Layer 5 and circuit 28
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 0
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,073][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit6', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 1
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit9', 'circuit11', 'circuit17']
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit27']
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 2
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit17', 'circuit23']
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 3
[2024-07-24 10:20:14,074][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit3', 'circuit5', 'circuit6', 'circuit8', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 4
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit18']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit7', 'circuit9']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 5
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit1', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,075][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit17', 'circuit19', 'circuit24']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit18', 'circuit20']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit7', 'circuit9', 'circuit13', 'circuit16']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit21', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 6
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit16', 'circuit18']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 7
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit24', 'circuit27']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,076][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 8
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit4', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit15', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 9
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit17']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit20', 'circuit21', 'circuit22', 'circuit23']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit24']
[2024-07-24 10:20:14,077][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 10
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit9', 'circuit12', 'circuit14', 'circuit17', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 11
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit2', 'circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit26']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit2', 'circuit3', 'circuit6', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 12
[2024-07-24 10:20:14,078][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit27']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit10', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 13
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit8', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 14
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,079][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 15
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 16
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit20', 'circuit21']
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23']
[2024-07-24 10:20:14,080][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 17
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit27']
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 18
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit26']
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,081][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 19
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit22']
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit10', 'circuit16', 'circuit17', 'circuit18', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit14', 'circuit16', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 20
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit9', 'circuit11', 'circuit27']
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 21
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,082][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit11', 'circuit16']
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 22
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 23
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,083][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit11', 'circuit13', 'circuit26']
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 24
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 25
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,084][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 26
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 27
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:296][INFO] Layer 6 and circuit 28
[2024-07-24 10:20:14,085][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 0
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit8', 'circuit9', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit2', 'circuit8', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit2', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 1
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,086][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 2
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 3
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,087][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18']
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 4
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit24']
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 5
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,088][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit14']
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 6
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit20', 'circuit21', 'circuit22', 'circuit24']
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 7
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit21', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,089][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit15', 'circuit16', 'circuit18']
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit13', 'circuit15', 'circuit17', 'circuit19', 'circuit24']
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit21', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21']
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 8
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit4']
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit6']
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 9
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,090][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 10
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit18', 'circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 11
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit5', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit27']
[2024-07-24 10:20:14,091][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit19', 'circuit20', 'circuit23']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 12
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit5', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit6', 'circuit9', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 13
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,092][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit9', 'circuit13', 'circuit15', 'circuit16', 'circuit19', 'circuit21', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit18', 'circuit26']
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit13']
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 14
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 15
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,093][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 16
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 17
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,094][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 18
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 19
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,095][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 20
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 21
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,096][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 22
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 23
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,097][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 24
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 25
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,098][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 26
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 27
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,099][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:296][INFO] Layer 7 and circuit 28
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 0
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,100][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit8', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit6', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 1
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit5', 'circuit11', 'circuit13', 'circuit14', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit1', 'circuit2', 'circuit5', 'circuit7', 'circuit8']
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 2
[2024-07-24 10:20:14,101][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit22', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22']
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit18', 'circuit19', 'circuit20']
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit23', 'circuit25']
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit23', 'circuit24']
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 3
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14']
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,102][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 4
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit20', 'circuit21', 'circuit24']
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 5
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,103][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 6
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 7
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,104][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 8
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 9
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,105][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 10
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 11
[2024-07-24 10:20:14,106][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit19', 'circuit24']
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 12
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,107][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 13
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit7', 'circuit8', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit26']
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 14
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,108][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 15
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 16
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,109][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 17
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 18
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,110][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 19
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 20
[2024-07-24 10:20:14,111][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 21
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,112][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 22
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 23
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,113][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 24
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 25
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,114][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 26
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 27
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,115][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:296][INFO] Layer 8 and circuit 28
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,116][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 0
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit6', 'circuit9', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit7', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit9', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit2', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 1
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit20', 'circuit22', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit19']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit15', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,117][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23']
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit19', 'circuit22', 'circuit23']
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit13', 'circuit20']
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 2
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit8', 'circuit10', 'circuit11', 'circuit13', 'circuit15', 'circuit18']
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 3
[2024-07-24 10:20:14,118][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 4
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit2', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit13', 'circuit14', 'circuit20', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,119][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 5
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit7', 'circuit10']
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit27']
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit17']
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 6
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit16', 'circuit24']
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,120][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 7
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,121][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 8
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 9
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,122][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit24']
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 10
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit19']
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 11
[2024-07-24 10:20:14,123][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 12
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22']
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,124][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 13
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit26']
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit17', 'circuit22', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit25']
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit15', 'circuit17', 'circuit18', 'circuit21', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 14
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,125][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 15
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,126][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 16
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 17
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,127][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 18
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 19
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,128][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 20
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,129][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 21
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 22
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,130][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 23
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,131][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 24
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 25
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,132][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 26
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 27
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,133][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:296][INFO] Layer 9 and circuit 28
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,134][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 0
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit18', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit5', 'circuit6', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit8', 'circuit11', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit2', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit11', 'circuit12', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit21', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit7', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26', 'circuit27']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit8', 'circuit13', 'circuit14', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 1
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,135][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 2
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,136][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 3
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 4
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,137][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 5
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,138][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 6
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 7
[2024-07-24 10:20:14,139][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 8
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,140][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 9
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 10
[2024-07-24 10:20:14,141][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 11
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,142][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 12
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,143][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 13
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit13']
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit21', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19']
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 14
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,144][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 15
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,145][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 16
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 17
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,146][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 18
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,147][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 19
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 20
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,148][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 21
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,149][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 22
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 23
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,150][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 24
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,151][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 25
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 26
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,152][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 27
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,153][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:296][INFO] Layer 10 and circuit 28
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 0
[2024-07-24 10:20:14,154][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit14', 'circuit15', 'circuit16', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit20', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit20', 'circuit22', 'circuit23', 'circuit24', 'circuit26']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit13', 'circuit15', 'circuit16', 'circuit17', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit7', 'circuit13', 'circuit14', 'circuit15', 'circuit17', 'circuit18', 'circuit19', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit13', 'circuit16', 'circuit17', 'circuit19', 'circuit20', 'circuit23', 'circuit26']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit13', 'circuit14', 'circuit15', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit25', 'circuit27']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit8', 'circuit9', 'circuit10', 'circuit12', 'circuit13', 'circuit14', 'circuit18', 'circuit19', 'circuit20', 'circuit22', 'circuit23', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit13', 'circuit21', 'circuit22', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 1
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,155][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 2
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,156][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 3
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit23']
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit23']
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit18', 'circuit21']
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 4
[2024-07-24 10:20:14,157][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 5
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit24']
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26']
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,158][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit19', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 6
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,159][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit14']
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 7
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 8
[2024-07-24 10:20:14,160][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 9
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,161][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 10
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,162][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 11
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit16', 'circuit19', 'circuit23', 'circuit24']
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit24', 'circuit25']
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 12
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,163][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit11', 'circuit27']
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit1', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit10', 'circuit11', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit14', 'circuit19', 'circuit25']
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit21', 'circuit24']
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 13
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit19', 'circuit22', 'circuit23', 'circuit25']
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,164][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit19', 'circuit22', 'circuit24', 'circuit25']
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0']
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 14
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,165][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 15
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 16
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,166][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 17
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,167][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 18
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,168][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 19
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 20
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,169][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 21
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,170][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 22
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,171][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 23
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 24
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,172][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 25
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are []
[2024-07-24 10:20:14,173][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are []
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are []
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are []
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are []
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are []
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 26
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,174][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 27
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:296][INFO] Layer 11 and circuit 28
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 0, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,175][explain_satisfiability.py][line:302][INFO] for Layer 1, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,176][explain_satisfiability.py][line:302][INFO] for Layer 2, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,176][explain_satisfiability.py][line:302][INFO] for Layer 3, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,176][explain_satisfiability.py][line:302][INFO] for Layer 4, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,176][explain_satisfiability.py][line:302][INFO] for Layer 5, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,176][explain_satisfiability.py][line:302][INFO] for Layer 6, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,176][explain_satisfiability.py][line:302][INFO] for Layer 7, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,176][explain_satisfiability.py][line:302][INFO] for Layer 8, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,176][explain_satisfiability.py][line:302][INFO] for Layer 9, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:14,176][explain_satisfiability.py][line:302][INFO] for Layer 10, the reserve circuits are ['circuit0', 'circuit1', 'circuit2', 'circuit3', 'circuit4', 'circuit5', 'circuit6', 'circuit7', 'circuit8', 'circuit9', 'circuit10', 'circuit11', 'circuit12', 'circuit13', 'circuit14', 'circuit15', 'circuit16', 'circuit17', 'circuit18', 'circuit19', 'circuit20', 'circuit21', 'circuit22', 'circuit23', 'circuit24', 'circuit25', 'circuit26', 'circuit27', 'circuit28']
[2024-07-24 10:20:15,877][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:15,878][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,878][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,878][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,879][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,879][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,879][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,880][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,881][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,882][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,883][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,885][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,886][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:15,886][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,886][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,887][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,887][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,887][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,888][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,888][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,888][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,889][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,891][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,892][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,894][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:15,895][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.4094, 0.3126, 0.2780], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,896][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([8.7950e-06, 3.4348e-05, 9.9996e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,896][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.4714, 0.3598, 0.1687], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,897][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([2.4317e-02, 1.8604e-04, 9.7550e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,897][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.0790, 0.0053, 0.9157], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,897][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([6.0700e-03, 3.6070e-06, 9.9393e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,898][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.4414, 0.2322, 0.3264], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,898][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.5661, 0.3073, 0.1267], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,898][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.6098, 0.2641, 0.1260], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,899][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.6542, 0.2942, 0.0516], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,899][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.4079, 0.2434, 0.3487], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,901][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.3639, 0.4236, 0.2125], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:15,903][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.6580, 0.0745, 0.2094, 0.0581], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,904][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0023, 0.0392, 0.0010, 0.9574], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,906][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2392, 0.1791, 0.0308, 0.5510], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,906][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1115, 0.3811, 0.0412, 0.4662], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,907][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3555, 0.1611, 0.1918, 0.2917], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,907][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1230, 0.1969, 0.0077, 0.6724], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,907][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.5829, 0.0279, 0.3681, 0.0211], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,908][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2159, 0.1642, 0.3726, 0.2472], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,908][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0672, 0.4704, 0.0213, 0.4411], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,908][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4355, 0.2432, 0.0953, 0.2259], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,909][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4168, 0.3105, 0.0678, 0.2048], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,910][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.4500, 0.1965, 0.0967, 0.2568], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:15,911][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.1562, 0.2447, 0.3154, 0.1965, 0.0872], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,913][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([3.8292e-05, 1.1477e-04, 9.9064e-04, 6.9460e-05, 9.9879e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,914][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.3684, 0.2395, 0.0373, 0.1443, 0.2105], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,915][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([4.4476e-03, 5.4548e-05, 1.9041e-02, 1.0941e-04, 9.7635e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,916][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0310, 0.0064, 0.0552, 0.0074, 0.9000], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,917][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([7.6660e-03, 3.7438e-07, 3.5393e-04, 9.4553e-08, 9.9198e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,917][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.2326, 0.3150, 0.1643, 0.2047, 0.0833], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,917][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.2217, 0.2684, 0.1135, 0.3511, 0.0453], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,918][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.2522, 0.1711, 0.0868, 0.1448, 0.3450], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,918][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.3996, 0.2260, 0.1556, 0.1874, 0.0315], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,918][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.2976, 0.2016, 0.0947, 0.1245, 0.2816], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,919][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.1876, 0.2423, 0.1167, 0.2668, 0.1866], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:15,919][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3966, 0.0349, 0.1404, 0.0347, 0.0880, 0.3055], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,921][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ had] are: tensor([3.2188e-04, 1.6739e-03, 1.1462e-03, 2.8592e-03, 1.8505e-04, 9.9381e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,922][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.4944, 0.1261, 0.0300, 0.1492, 0.0526, 0.1477], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,924][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0049, 0.0054, 0.0019, 0.0115, 0.0019, 0.9743], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,925][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2237, 0.0636, 0.0486, 0.1152, 0.0737, 0.4751], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,926][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ had] are: tensor([3.9811e-02, 1.8578e-03, 3.5600e-04, 1.2916e-03, 2.8074e-04, 9.5640e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,927][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2294, 0.0171, 0.3755, 0.0161, 0.3389, 0.0230], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,927][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1220, 0.0950, 0.1195, 0.2205, 0.1687, 0.2743], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,927][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0945, 0.2654, 0.0495, 0.3486, 0.0264, 0.2157], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,928][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3110, 0.1875, 0.0809, 0.1932, 0.0968, 0.1306], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,928][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2539, 0.1958, 0.0578, 0.1434, 0.0376, 0.3114], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,928][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.4276, 0.1428, 0.0611, 0.1781, 0.1003, 0.0900], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:15,929][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3749, 0.0432, 0.1261, 0.0326, 0.3405, 0.0538, 0.0289],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,929][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ a] are: tensor([8.5479e-04, 4.2958e-03, 2.5495e-03, 4.2937e-03, 3.5824e-04, 4.6785e-04,
        9.8718e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,931][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3047, 0.1890, 0.0424, 0.2228, 0.0679, 0.1262, 0.0471],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,933][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0286, 0.0175, 0.0081, 0.0323, 0.0388, 0.1747, 0.7000],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,934][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1416, 0.0311, 0.0470, 0.0439, 0.0795, 0.4427, 0.2142],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,936][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0559, 0.1295, 0.0057, 0.0969, 0.0016, 0.0447, 0.6657],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,937][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3035, 0.0101, 0.2648, 0.0086, 0.3586, 0.0446, 0.0099],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,939][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0952, 0.0572, 0.0624, 0.1279, 0.1471, 0.2147, 0.2955],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,941][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0239, 0.1303, 0.0073, 0.1935, 0.0150, 0.1414, 0.4887],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,942][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2660, 0.1703, 0.0669, 0.1728, 0.0804, 0.1072, 0.1363],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,942][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.2248, 0.1917, 0.0756, 0.1625, 0.0375, 0.0832, 0.2247],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,943][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3294, 0.1320, 0.0763, 0.1418, 0.1260, 0.0851, 0.1092],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:15,943][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.2642, 0.0632, 0.1951, 0.0586, 0.1502, 0.1088, 0.0830, 0.0770],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,944][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ long] are: tensor([2.8414e-04, 9.8762e-04, 1.9105e-03, 1.4089e-03, 8.3703e-04, 3.2470e-03,
        9.3696e-04, 9.9039e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,944][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.2931, 0.1511, 0.0981, 0.1528, 0.0841, 0.1066, 0.0763, 0.0380],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,944][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ long] are: tensor([6.5181e-03, 4.5996e-04, 2.1087e-04, 8.0342e-04, 4.7529e-04, 9.1051e-03,
        7.2535e-03, 9.7517e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,945][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1021, 0.0233, 0.0331, 0.0305, 0.0258, 0.1525, 0.0807, 0.5520],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,945][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ long] are: tensor([5.4037e-03, 1.8789e-04, 2.1754e-04, 1.0304e-04, 3.1546e-05, 1.9182e-04,
        8.2364e-05, 9.9378e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,947][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.2151, 0.0232, 0.2472, 0.0161, 0.3839, 0.0356, 0.0166, 0.0623],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,948][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1086, 0.0472, 0.0305, 0.0990, 0.0301, 0.1990, 0.3675, 0.1180],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,950][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1157, 0.1158, 0.0674, 0.1472, 0.0790, 0.1425, 0.2896, 0.0428],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,951][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2395, 0.1566, 0.0868, 0.1516, 0.0749, 0.0925, 0.1329, 0.0652],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,953][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2221, 0.1573, 0.0479, 0.1102, 0.0440, 0.0764, 0.0864, 0.2556],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,953][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.3820, 0.1028, 0.0516, 0.1279, 0.0965, 0.0633, 0.0648, 0.1111],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:15,953][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.3460, 0.0828, 0.1347, 0.0652, 0.1178, 0.0706, 0.0555, 0.0705, 0.0569],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,954][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([1.8437e-03, 3.0551e-04, 8.2141e-03, 2.0765e-04, 9.1898e-04, 3.4634e-04,
        1.9382e-04, 3.4096e-05, 9.8794e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,954][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.3163, 0.1075, 0.0436, 0.0788, 0.0700, 0.1036, 0.1213, 0.1003, 0.0587],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,954][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([3.3878e-03, 4.0916e-05, 3.3387e-04, 9.1341e-05, 2.4496e-04, 2.4713e-04,
        6.3007e-04, 4.3089e-03, 9.9071e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,955][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1328, 0.0060, 0.0152, 0.0051, 0.0045, 0.0161, 0.0136, 0.1780, 0.6286],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,955][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([1.2028e-02, 1.5134e-05, 6.5559e-05, 4.1249e-06, 6.3670e-06, 2.0254e-06,
        1.5989e-06, 6.3677e-07, 9.8788e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,956][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1638, 0.0426, 0.2335, 0.0372, 0.2335, 0.0281, 0.0302, 0.0676, 0.1636],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,956][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0900, 0.0516, 0.0232, 0.0961, 0.0370, 0.1325, 0.2114, 0.2545, 0.1035],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,958][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.2424, 0.0936, 0.0509, 0.1096, 0.0875, 0.2286, 0.1170, 0.0632, 0.0073],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,960][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2309, 0.1345, 0.0764, 0.1260, 0.0875, 0.1095, 0.1127, 0.0813, 0.0412],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,961][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2180, 0.1358, 0.0498, 0.1147, 0.0307, 0.0783, 0.0757, 0.0397, 0.2574],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,963][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.3031, 0.1344, 0.0669, 0.0973, 0.1336, 0.0385, 0.0372, 0.0821, 0.1069],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:15,964][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.3681, 0.0126, 0.0979, 0.0147, 0.2501, 0.0652, 0.0282, 0.0523, 0.1002,
        0.0107], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,964][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8439e-03, 4.4343e-01, 3.6724e-04, 1.1167e-02, 1.5134e-04, 3.9659e-04,
        1.7956e-04, 5.1689e-05, 7.8224e-06, 5.4241e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,964][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1995, 0.3140, 0.0117, 0.0768, 0.0249, 0.0366, 0.0075, 0.0102, 0.0101,
        0.3088], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,965][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0331, 0.0077, 0.0019, 0.0077, 0.0052, 0.0605, 0.0497, 0.0550, 0.0863,
        0.6928], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,965][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2540, 0.0246, 0.0273, 0.0212, 0.1164, 0.1227, 0.0300, 0.1049, 0.0440,
        0.2548], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,966][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0970, 0.3428, 0.0130, 0.1237, 0.0091, 0.0688, 0.1018, 0.0300, 0.0101,
        0.2036], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,966][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2483, 0.0073, 0.2125, 0.0071, 0.3120, 0.0232, 0.0091, 0.0599, 0.1158,
        0.0049], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,967][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0361, 0.0137, 0.0329, 0.0371, 0.0794, 0.0677, 0.1080, 0.1416, 0.1353,
        0.3482], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,969][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0191, 0.1645, 0.0068, 0.1848, 0.0073, 0.0641, 0.1657, 0.0291, 0.0075,
        0.3510], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,970][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2162, 0.1237, 0.0538, 0.1285, 0.0638, 0.0867, 0.0945, 0.0706, 0.0570,
        0.1052], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,972][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1752, 0.1612, 0.0639, 0.1481, 0.0491, 0.0959, 0.0928, 0.0595, 0.0425,
        0.1117], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,973][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2367, 0.0916, 0.0630, 0.1038, 0.1188, 0.0660, 0.0629, 0.0768, 0.0715,
        0.1088], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:15,974][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.3170, 0.0258, 0.0972, 0.0222, 0.1875, 0.0623, 0.0376, 0.0828, 0.1151,
        0.0254, 0.0270], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,974][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.0614e-03, 1.2476e-02, 1.9353e-04, 5.1184e-01, 3.4088e-05, 6.9040e-04,
        2.3419e-04, 1.8325e-04, 8.4965e-06, 7.4674e-03, 4.6582e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,975][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0824, 0.0616, 0.0184, 0.3085, 0.0302, 0.0429, 0.0172, 0.0147, 0.0230,
        0.0547, 0.3464], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,975][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0820e-02, 6.0642e-03, 3.2755e-04, 3.9880e-03, 4.7102e-04, 7.8462e-03,
        1.3923e-02, 1.5637e-02, 7.4087e-03, 4.9299e-01, 4.4052e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,976][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0352, 0.0129, 0.0080, 0.0244, 0.0246, 0.1607, 0.0652, 0.1189, 0.1764,
        0.1207, 0.2530], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,976][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0326, 0.0873, 0.0036, 0.3881, 0.0024, 0.0543, 0.1212, 0.0254, 0.0037,
        0.0307, 0.2507], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,977][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2118, 0.0086, 0.2089, 0.0081, 0.2922, 0.0269, 0.0099, 0.0749, 0.1433,
        0.0065, 0.0090], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,978][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0322, 0.0117, 0.0276, 0.0195, 0.0507, 0.0412, 0.0619, 0.0774, 0.0953,
        0.2382, 0.3445], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,979][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0115, 0.1002, 0.0045, 0.1176, 0.0048, 0.0610, 0.2001, 0.0256, 0.0109,
        0.2628, 0.2011], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,981][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1766, 0.1101, 0.0524, 0.1111, 0.0564, 0.0769, 0.0883, 0.0594, 0.0581,
        0.0974, 0.1132], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,983][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1456, 0.1319, 0.0508, 0.1402, 0.0375, 0.0985, 0.0995, 0.0529, 0.0356,
        0.0956, 0.1120], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,984][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2111, 0.0861, 0.0529, 0.0991, 0.0984, 0.0515, 0.0457, 0.0592, 0.0755,
        0.1088, 0.1117], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:15,985][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2299, 0.0418, 0.1076, 0.0464, 0.1152, 0.1221, 0.0476, 0.0334, 0.1467,
        0.0363, 0.0554, 0.0177], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,985][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([1.7413e-03, 4.1763e-04, 8.1677e-04, 1.5601e-04, 1.2086e-03, 1.7379e-04,
        9.0210e-05, 1.4345e-04, 6.0612e-04, 9.2372e-05, 7.0782e-05, 9.9448e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,985][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2610, 0.0853, 0.0288, 0.0810, 0.0788, 0.1647, 0.0676, 0.0596, 0.0344,
        0.0541, 0.0651, 0.0196], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,986][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.2694e-02, 5.1810e-05, 1.4377e-04, 7.2026e-05, 1.4250e-04, 1.1421e-03,
        2.1227e-04, 3.4370e-03, 1.4252e-03, 2.2500e-03, 4.8172e-03, 9.7361e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,986][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0420, 0.0034, 0.0058, 0.0070, 0.0039, 0.0113, 0.0109, 0.0294, 0.0153,
        0.0127, 0.0438, 0.8144], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,987][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.2454e-02, 4.3741e-06, 7.1628e-05, 1.6933e-06, 1.4972e-04, 4.4307e-06,
        4.7551e-07, 4.6484e-06, 5.0049e-06, 9.8435e-08, 2.7243e-07, 9.0730e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,987][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1421, 0.0595, 0.1669, 0.0442, 0.1074, 0.0371, 0.0631, 0.0553, 0.1277,
        0.0525, 0.0487, 0.0956], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,989][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0531, 0.0191, 0.0056, 0.0294, 0.0145, 0.0338, 0.0717, 0.0492, 0.0278,
        0.1934, 0.3939, 0.1087], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,991][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0987, 0.1114, 0.0139, 0.1411, 0.0201, 0.0399, 0.1233, 0.0370, 0.1010,
        0.1314, 0.1693, 0.0130], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,992][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1793, 0.1013, 0.0542, 0.0931, 0.0604, 0.0772, 0.0679, 0.0582, 0.0880,
        0.0859, 0.0935, 0.0411], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,994][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1938, 0.0942, 0.0390, 0.0901, 0.0412, 0.0844, 0.0560, 0.0524, 0.0392,
        0.0671, 0.0698, 0.1728], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,994][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1725, 0.1367, 0.0510, 0.0907, 0.1007, 0.0312, 0.0399, 0.0402, 0.0367,
        0.1563, 0.0973, 0.0469], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:15,995][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0868, 0.1087, 0.1639, 0.0925, 0.0578, 0.0134, 0.0622, 0.0556, 0.0831,
        0.0914, 0.0856, 0.0379, 0.0611], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:15,995][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([1.8231e-05, 3.0804e-05, 2.6199e-04, 2.1431e-05, 5.3755e-01, 4.9275e-06,
        1.8762e-05, 8.1144e-06, 3.6177e-06, 5.5883e-06, 8.5344e-06, 9.9288e-06,
        4.6206e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:15,996][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.1653, 0.0953, 0.0235, 0.0729, 0.1366, 0.0943, 0.0758, 0.0446, 0.0141,
        0.0538, 0.0571, 0.0340, 0.1327], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:15,996][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([2.0459e-04, 3.1337e-07, 9.7567e-05, 2.7961e-07, 5.2113e-03, 3.7222e-06,
        1.0797e-05, 1.0773e-04, 1.1993e-04, 2.1509e-05, 3.0244e-05, 1.9691e-04,
        9.9400e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:15,997][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([5.3281e-03, 7.0163e-04, 4.5905e-03, 6.7303e-04, 8.5552e-02, 6.1403e-04,
        8.6010e-04, 9.0158e-04, 4.0499e-03, 3.7533e-03, 4.7027e-03, 1.4607e-02,
        8.7367e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:15,997][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([1.8359e-03, 6.7206e-08, 1.2123e-04, 1.8022e-08, 5.9745e-01, 1.5472e-07,
        3.0103e-09, 2.1853e-07, 8.9991e-08, 9.2672e-10, 2.4692e-09, 2.1375e-06,
        4.0059e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:15,998][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.1208, 0.1518, 0.1003, 0.1124, 0.0579, 0.0226, 0.0682, 0.0279, 0.0589,
        0.1107, 0.0966, 0.0172, 0.0547], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,000][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0712, 0.0342, 0.0127, 0.0360, 0.0050, 0.0467, 0.0907, 0.0250, 0.0400,
        0.1977, 0.3540, 0.0392, 0.0477], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,001][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.1061, 0.0654, 0.0419, 0.0640, 0.2063, 0.0344, 0.0429, 0.0364, 0.0226,
        0.0533, 0.0584, 0.0279, 0.2404], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,003][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.1992, 0.1149, 0.0984, 0.1001, 0.0192, 0.0560, 0.0680, 0.0511, 0.0433,
        0.0873, 0.0937, 0.0500, 0.0190], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,004][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.1042, 0.0728, 0.0556, 0.0633, 0.2556, 0.0395, 0.0451, 0.0306, 0.0137,
        0.0446, 0.0444, 0.0176, 0.2131], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,005][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0555, 0.0723, 0.0400, 0.0692, 0.0727, 0.0814, 0.0887, 0.0685, 0.0904,
        0.0735, 0.0938, 0.0906, 0.1034], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,005][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.2896, 0.0251, 0.1078, 0.0145, 0.0944, 0.0528, 0.0154, 0.0383, 0.0369,
        0.0247, 0.0154, 0.0839, 0.1368, 0.0644], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,006][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ said] are: tensor([1.4433e-03, 3.5479e-03, 2.3715e-03, 1.1997e-03, 3.8089e-04, 8.4822e-03,
        1.4033e-03, 4.5737e-05, 1.5904e-03, 1.5492e-03, 7.2151e-04, 1.1227e-04,
        2.6353e-04, 9.7689e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,006][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2307, 0.0515, 0.0195, 0.0445, 0.0195, 0.1061, 0.0350, 0.0257, 0.0504,
        0.0426, 0.0415, 0.0417, 0.0194, 0.2718], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,007][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ said] are: tensor([1.9934e-03, 7.3730e-05, 1.3541e-05, 5.4886e-05, 8.5287e-05, 3.0897e-04,
        4.2926e-04, 4.8796e-04, 1.2579e-03, 2.5472e-03, 3.5607e-03, 1.3213e-03,
        6.9296e-03, 9.8094e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,007][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0860, 0.0131, 0.0043, 0.0187, 0.0049, 0.0267, 0.0217, 0.0252, 0.0428,
        0.0564, 0.1199, 0.0242, 0.0342, 0.5217], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,008][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ said] are: tensor([1.2077e-02, 2.4346e-03, 8.3819e-05, 8.9067e-04, 1.6749e-04, 8.6986e-03,
        2.0764e-04, 2.9481e-05, 6.7257e-04, 2.4887e-04, 2.8124e-04, 6.2023e-06,
        6.3414e-05, 9.7414e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,009][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1691, 0.0083, 0.1391, 0.0083, 0.1736, 0.0111, 0.0067, 0.0303, 0.0798,
        0.0063, 0.0082, 0.1159, 0.2270, 0.0164], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,011][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0286, 0.0054, 0.0059, 0.0091, 0.0166, 0.0123, 0.0260, 0.0113, 0.0178,
        0.0946, 0.1478, 0.1523, 0.3225, 0.1496], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,013][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0519, 0.1074, 0.0120, 0.1054, 0.0187, 0.1026, 0.1388, 0.0316, 0.0280,
        0.1777, 0.1390, 0.0252, 0.0242, 0.0377], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,014][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1510, 0.0812, 0.0432, 0.0833, 0.0449, 0.0667, 0.0635, 0.0471, 0.0554,
        0.0755, 0.0863, 0.0560, 0.0495, 0.0965], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,015][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1032, 0.0744, 0.0381, 0.0784, 0.0323, 0.0808, 0.0606, 0.0254, 0.0485,
        0.0629, 0.0677, 0.0289, 0.0275, 0.2714], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,015][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.2267, 0.0539, 0.0471, 0.0721, 0.0867, 0.0345, 0.0289, 0.0520, 0.0618,
        0.0572, 0.0732, 0.0759, 0.0939, 0.0363], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,016][circuit_model.py][line:2294][INFO] ##0-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2447, 0.0237, 0.0463, 0.0198, 0.0951, 0.0639, 0.0213, 0.0345, 0.0681,
        0.0237, 0.0243, 0.0789, 0.1384, 0.1016, 0.0157], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,016][circuit_model.py][line:2297][INFO] ##0-th layer ##Weight##: The head2 weight for token [ to] are: tensor([4.1195e-03, 1.1774e-02, 5.5456e-04, 3.4302e-02, 1.1666e-04, 3.0521e-04,
        1.4486e-03, 1.7840e-04, 5.7908e-05, 8.2810e-03, 3.0194e-02, 2.4495e-04,
        8.0493e-05, 1.4509e-04, 9.0820e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,017][circuit_model.py][line:2300][INFO] ##0-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1577, 0.0693, 0.0214, 0.0952, 0.0347, 0.0579, 0.0249, 0.0372, 0.0303,
        0.0592, 0.0938, 0.0385, 0.0359, 0.0737, 0.1704], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,017][circuit_model.py][line:2303][INFO] ##0-th layer ##Weight##: The head4 weight for token [ to] are: tensor([2.9355e-03, 2.6500e-04, 6.9351e-05, 1.8160e-04, 8.2497e-05, 7.2685e-04,
        1.2022e-03, 2.4175e-04, 1.1445e-03, 7.1776e-03, 1.1902e-02, 1.6523e-02,
        6.7648e-03, 2.9247e-01, 6.5832e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,017][circuit_model.py][line:2306][INFO] ##0-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0361, 0.0023, 0.0016, 0.0038, 0.0011, 0.0341, 0.0104, 0.0264, 0.0576,
        0.0124, 0.0318, 0.0737, 0.0098, 0.4189, 0.2797], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,018][circuit_model.py][line:2309][INFO] ##0-th layer ##Weight##: The head6 weight for token [ to] are: tensor([4.3377e-02, 6.1278e-02, 2.2281e-03, 7.8456e-02, 8.2573e-04, 3.1249e-02,
        2.2679e-01, 3.4402e-02, 4.7678e-03, 2.1222e-02, 4.1328e-02, 7.4611e-04,
        3.7853e-04, 3.2672e-02, 4.2028e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,020][circuit_model.py][line:2312][INFO] ##0-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1145, 0.0055, 0.0749, 0.0047, 0.0948, 0.0160, 0.0045, 0.0296, 0.0511,
        0.0041, 0.0060, 0.1041, 0.1557, 0.0307, 0.3038], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,022][circuit_model.py][line:2315][INFO] ##0-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0215, 0.0041, 0.0057, 0.0067, 0.0089, 0.0087, 0.0116, 0.0179, 0.0262,
        0.0479, 0.0776, 0.0910, 0.1539, 0.2517, 0.2665], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,023][circuit_model.py][line:2318][INFO] ##0-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0080, 0.0595, 0.0023, 0.1036, 0.0050, 0.0466, 0.1311, 0.0198, 0.0089,
        0.1508, 0.1814, 0.0048, 0.0075, 0.0338, 0.2369], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,025][circuit_model.py][line:2321][INFO] ##0-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1211, 0.0750, 0.0356, 0.0825, 0.0383, 0.0551, 0.0702, 0.0482, 0.0433,
        0.0708, 0.0866, 0.0465, 0.0426, 0.0841, 0.0998], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,025][circuit_model.py][line:2324][INFO] ##0-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1029, 0.0845, 0.0340, 0.1012, 0.0290, 0.0750, 0.0862, 0.0506, 0.0336,
        0.0767, 0.0935, 0.0278, 0.0259, 0.0647, 0.1144], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,026][circuit_model.py][line:2327][INFO] ##0-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1711, 0.0676, 0.0408, 0.0694, 0.0708, 0.0482, 0.0438, 0.0514, 0.0515,
        0.0695, 0.0660, 0.0711, 0.0737, 0.0353, 0.0698], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,037][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:16,039][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,039][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,040][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,040][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,040][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,041][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,041][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,041][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,042][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,042][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,042][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,042][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,043][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9675, 0.0325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,043][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0065, 0.9935], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,043][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.6358, 0.3642], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,044][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6853, 0.3147], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,044][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9772, 0.0228], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,044][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.7461], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,045][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9881, 0.0119], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,045][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.9119, 0.0881], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,045][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3215, 0.6785], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,046][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7118, 0.2882], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,046][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7102, 0.2898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,046][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.6916, 0.3084], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,047][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.4094, 0.3126, 0.2780], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,047][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([8.7950e-06, 3.4348e-05, 9.9996e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,047][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.4714, 0.3598, 0.1687], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,048][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([2.4317e-02, 1.8604e-04, 9.7550e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,048][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.0790, 0.0053, 0.9157], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,048][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([6.0700e-03, 3.6070e-06, 9.9393e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,049][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.4414, 0.2322, 0.3264], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,049][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.5661, 0.3073, 0.1267], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,049][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.6098, 0.2641, 0.1260], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,050][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.6542, 0.2942, 0.0516], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,050][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.4079, 0.2434, 0.3487], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,050][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.3639, 0.4236, 0.2125], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,051][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.6580, 0.0745, 0.2094, 0.0581], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,051][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0023, 0.0392, 0.0010, 0.9574], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,051][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2392, 0.1791, 0.0308, 0.5510], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,052][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1115, 0.3811, 0.0412, 0.4662], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,052][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3555, 0.1611, 0.1918, 0.2917], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,052][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1230, 0.1969, 0.0077, 0.6724], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,053][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.5829, 0.0279, 0.3681, 0.0211], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,053][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2159, 0.1642, 0.3726, 0.2472], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,054][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0672, 0.4704, 0.0213, 0.4411], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,054][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4355, 0.2432, 0.0953, 0.2259], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,054][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4168, 0.3105, 0.0678, 0.2048], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,055][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.4500, 0.1965, 0.0967, 0.2568], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,056][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.1562, 0.2447, 0.3154, 0.1965, 0.0872], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,057][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([3.8292e-05, 1.1477e-04, 9.9064e-04, 6.9460e-05, 9.9879e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,058][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.3684, 0.2395, 0.0373, 0.1443, 0.2105], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,059][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([4.4476e-03, 5.4548e-05, 1.9041e-02, 1.0941e-04, 9.7635e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,059][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0310, 0.0064, 0.0552, 0.0074, 0.9000], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,060][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([7.6660e-03, 3.7438e-07, 3.5393e-04, 9.4553e-08, 9.9198e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,060][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.2326, 0.3150, 0.1643, 0.2047, 0.0833], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,060][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.2217, 0.2684, 0.1135, 0.3511, 0.0453], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,061][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.2522, 0.1711, 0.0868, 0.1448, 0.3450], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,061][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.3996, 0.2260, 0.1556, 0.1874, 0.0315], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,061][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.2976, 0.2016, 0.0947, 0.1245, 0.2816], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,061][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.1876, 0.2423, 0.1167, 0.2668, 0.1866], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,062][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3966, 0.0349, 0.1404, 0.0347, 0.0880, 0.3055], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,062][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([3.2188e-04, 1.6739e-03, 1.1462e-03, 2.8592e-03, 1.8505e-04, 9.9381e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,063][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.4944, 0.1261, 0.0300, 0.1492, 0.0526, 0.1477], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,065][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0049, 0.0054, 0.0019, 0.0115, 0.0019, 0.9743], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,066][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2237, 0.0636, 0.0486, 0.1152, 0.0737, 0.4751], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,067][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([3.9811e-02, 1.8578e-03, 3.5600e-04, 1.2916e-03, 2.8074e-04, 9.5640e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,069][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2294, 0.0171, 0.3755, 0.0161, 0.3389, 0.0230], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,069][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1220, 0.0950, 0.1195, 0.2205, 0.1687, 0.2743], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,070][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0945, 0.2654, 0.0495, 0.3486, 0.0264, 0.2157], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,070][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3110, 0.1875, 0.0809, 0.1932, 0.0968, 0.1306], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,070][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2539, 0.1958, 0.0578, 0.1434, 0.0376, 0.3114], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,071][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4276, 0.1428, 0.0611, 0.1781, 0.1003, 0.0900], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,071][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3749, 0.0432, 0.1261, 0.0326, 0.3405, 0.0538, 0.0289],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,071][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([8.5479e-04, 4.2958e-03, 2.5495e-03, 4.2937e-03, 3.5824e-04, 4.6785e-04,
        9.8718e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,072][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3047, 0.1890, 0.0424, 0.2228, 0.0679, 0.1262, 0.0471],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,072][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0286, 0.0175, 0.0081, 0.0323, 0.0388, 0.1747, 0.7000],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,073][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1416, 0.0311, 0.0470, 0.0439, 0.0795, 0.4427, 0.2142],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,074][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0559, 0.1295, 0.0057, 0.0969, 0.0016, 0.0447, 0.6657],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,076][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.3035, 0.0101, 0.2648, 0.0086, 0.3586, 0.0446, 0.0099],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,077][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0952, 0.0572, 0.0624, 0.1279, 0.1471, 0.2147, 0.2955],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,079][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0239, 0.1303, 0.0073, 0.1935, 0.0150, 0.1414, 0.4887],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,080][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2660, 0.1703, 0.0669, 0.1728, 0.0804, 0.1072, 0.1363],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,080][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2248, 0.1917, 0.0756, 0.1625, 0.0375, 0.0832, 0.2247],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,080][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3294, 0.1320, 0.0763, 0.1418, 0.1260, 0.0851, 0.1092],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,081][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.2642, 0.0632, 0.1951, 0.0586, 0.1502, 0.1088, 0.0830, 0.0770],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,081][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([2.8414e-04, 9.8762e-04, 1.9105e-03, 1.4089e-03, 8.3703e-04, 3.2470e-03,
        9.3696e-04, 9.9039e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,081][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.2931, 0.1511, 0.0981, 0.1528, 0.0841, 0.1066, 0.0763, 0.0380],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,082][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([6.5181e-03, 4.5996e-04, 2.1087e-04, 8.0342e-04, 4.7529e-04, 9.1051e-03,
        7.2535e-03, 9.7517e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,082][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1021, 0.0233, 0.0331, 0.0305, 0.0258, 0.1525, 0.0807, 0.5520],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,082][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([5.4037e-03, 1.8789e-04, 2.1754e-04, 1.0304e-04, 3.1546e-05, 1.9182e-04,
        8.2364e-05, 9.9378e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,083][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2151, 0.0232, 0.2472, 0.0161, 0.3839, 0.0356, 0.0166, 0.0623],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,085][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1086, 0.0472, 0.0305, 0.0990, 0.0301, 0.1990, 0.3675, 0.1180],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,086][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1157, 0.1158, 0.0674, 0.1472, 0.0790, 0.1425, 0.2896, 0.0428],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,088][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2395, 0.1566, 0.0868, 0.1516, 0.0749, 0.0925, 0.1329, 0.0652],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,089][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2221, 0.1573, 0.0479, 0.1102, 0.0440, 0.0764, 0.0864, 0.2556],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,090][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3820, 0.1028, 0.0516, 0.1279, 0.0965, 0.0633, 0.0648, 0.1111],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,090][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.3460, 0.0828, 0.1347, 0.0652, 0.1178, 0.0706, 0.0555, 0.0705, 0.0569],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,091][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([1.8437e-03, 3.0551e-04, 8.2141e-03, 2.0765e-04, 9.1898e-04, 3.4634e-04,
        1.9382e-04, 3.4096e-05, 9.8794e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,091][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.3163, 0.1075, 0.0436, 0.0788, 0.0700, 0.1036, 0.1213, 0.1003, 0.0587],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,091][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.3878e-03, 4.0916e-05, 3.3387e-04, 9.1341e-05, 2.4496e-04, 2.4713e-04,
        6.3007e-04, 4.3089e-03, 9.9071e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,092][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1328, 0.0060, 0.0152, 0.0051, 0.0045, 0.0161, 0.0136, 0.1780, 0.6286],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,092][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([1.2028e-02, 1.5134e-05, 6.5559e-05, 4.1249e-06, 6.3670e-06, 2.0254e-06,
        1.5989e-06, 6.3677e-07, 9.8788e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,092][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1638, 0.0426, 0.2335, 0.0372, 0.2335, 0.0281, 0.0302, 0.0676, 0.1636],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,093][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0900, 0.0516, 0.0232, 0.0961, 0.0370, 0.1325, 0.2114, 0.2545, 0.1035],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,093][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2424, 0.0936, 0.0509, 0.1096, 0.0875, 0.2286, 0.1170, 0.0632, 0.0073],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,095][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.2309, 0.1345, 0.0764, 0.1260, 0.0875, 0.1095, 0.1127, 0.0813, 0.0412],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,097][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2180, 0.1358, 0.0498, 0.1147, 0.0307, 0.0783, 0.0757, 0.0397, 0.2574],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,098][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.3031, 0.1344, 0.0669, 0.0973, 0.1336, 0.0385, 0.0372, 0.0821, 0.1069],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,100][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3681, 0.0126, 0.0979, 0.0147, 0.2501, 0.0652, 0.0282, 0.0523, 0.1002,
        0.0107], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,100][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([1.8439e-03, 4.4343e-01, 3.6724e-04, 1.1167e-02, 1.5134e-04, 3.9659e-04,
        1.7956e-04, 5.1689e-05, 7.8224e-06, 5.4241e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,101][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1995, 0.3140, 0.0117, 0.0768, 0.0249, 0.0366, 0.0075, 0.0102, 0.0101,
        0.3088], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,101][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0331, 0.0077, 0.0019, 0.0077, 0.0052, 0.0605, 0.0497, 0.0550, 0.0863,
        0.6928], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,101][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.2540, 0.0246, 0.0273, 0.0212, 0.1164, 0.1227, 0.0300, 0.1049, 0.0440,
        0.2548], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,102][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0970, 0.3428, 0.0130, 0.1237, 0.0091, 0.0688, 0.1018, 0.0300, 0.0101,
        0.2036], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,102][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2483, 0.0073, 0.2125, 0.0071, 0.3120, 0.0232, 0.0091, 0.0599, 0.1158,
        0.0049], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,102][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0361, 0.0137, 0.0329, 0.0371, 0.0794, 0.0677, 0.1080, 0.1416, 0.1353,
        0.3482], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,103][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0191, 0.1645, 0.0068, 0.1848, 0.0073, 0.0641, 0.1657, 0.0291, 0.0075,
        0.3510], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,103][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2162, 0.1237, 0.0538, 0.1285, 0.0638, 0.0867, 0.0945, 0.0706, 0.0570,
        0.1052], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,105][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1752, 0.1612, 0.0639, 0.1481, 0.0491, 0.0959, 0.0928, 0.0595, 0.0425,
        0.1117], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,106][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2367, 0.0916, 0.0630, 0.1038, 0.1188, 0.0660, 0.0629, 0.0768, 0.0715,
        0.1088], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,108][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3170, 0.0258, 0.0972, 0.0222, 0.1875, 0.0623, 0.0376, 0.0828, 0.1151,
        0.0254, 0.0270], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,109][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([1.0614e-03, 1.2476e-02, 1.9353e-04, 5.1184e-01, 3.4088e-05, 6.9040e-04,
        2.3419e-04, 1.8325e-04, 8.4965e-06, 7.4674e-03, 4.6582e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,110][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0824, 0.0616, 0.0184, 0.3085, 0.0302, 0.0429, 0.0172, 0.0147, 0.0230,
        0.0547, 0.3464], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,111][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([1.0820e-02, 6.0642e-03, 3.2755e-04, 3.9880e-03, 4.7102e-04, 7.8462e-03,
        1.3923e-02, 1.5637e-02, 7.4087e-03, 4.9299e-01, 4.4052e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,111][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0352, 0.0129, 0.0080, 0.0244, 0.0246, 0.1607, 0.0652, 0.1189, 0.1764,
        0.1207, 0.2530], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,111][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0326, 0.0873, 0.0036, 0.3881, 0.0024, 0.0543, 0.1212, 0.0254, 0.0037,
        0.0307, 0.2507], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,112][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2118, 0.0086, 0.2089, 0.0081, 0.2922, 0.0269, 0.0099, 0.0749, 0.1433,
        0.0065, 0.0090], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,112][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0322, 0.0117, 0.0276, 0.0195, 0.0507, 0.0412, 0.0619, 0.0774, 0.0953,
        0.2382, 0.3445], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,112][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0115, 0.1002, 0.0045, 0.1176, 0.0048, 0.0610, 0.2001, 0.0256, 0.0109,
        0.2628, 0.2011], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,113][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1766, 0.1101, 0.0524, 0.1111, 0.0564, 0.0769, 0.0883, 0.0594, 0.0581,
        0.0974, 0.1132], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,113][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1456, 0.1319, 0.0508, 0.1402, 0.0375, 0.0985, 0.0995, 0.0529, 0.0356,
        0.0956, 0.1120], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,114][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2111, 0.0861, 0.0529, 0.0991, 0.0984, 0.0515, 0.0457, 0.0592, 0.0755,
        0.1088, 0.1117], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,116][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.2299, 0.0418, 0.1076, 0.0464, 0.1152, 0.1221, 0.0476, 0.0334, 0.1467,
        0.0363, 0.0554, 0.0177], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,117][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.7413e-03, 4.1763e-04, 8.1677e-04, 1.5601e-04, 1.2086e-03, 1.7379e-04,
        9.0210e-05, 1.4345e-04, 6.0612e-04, 9.2372e-05, 7.0782e-05, 9.9448e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,118][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.2610, 0.0853, 0.0288, 0.0810, 0.0788, 0.1647, 0.0676, 0.0596, 0.0344,
        0.0541, 0.0651, 0.0196], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,119][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.2694e-02, 5.1810e-05, 1.4377e-04, 7.2026e-05, 1.4250e-04, 1.1421e-03,
        2.1227e-04, 3.4370e-03, 1.4252e-03, 2.2500e-03, 4.8172e-03, 9.7361e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,120][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0420, 0.0034, 0.0058, 0.0070, 0.0039, 0.0113, 0.0109, 0.0294, 0.0153,
        0.0127, 0.0438, 0.8144], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,121][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([9.2454e-02, 4.3741e-06, 7.1628e-05, 1.6933e-06, 1.4972e-04, 4.4307e-06,
        4.7551e-07, 4.6484e-06, 5.0049e-06, 9.8435e-08, 2.7243e-07, 9.0730e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,121][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1421, 0.0595, 0.1669, 0.0442, 0.1074, 0.0371, 0.0631, 0.0553, 0.1277,
        0.0525, 0.0487, 0.0956], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,122][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0531, 0.0191, 0.0056, 0.0294, 0.0145, 0.0338, 0.0717, 0.0492, 0.0278,
        0.1934, 0.3939, 0.1087], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,122][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0987, 0.1114, 0.0139, 0.1411, 0.0201, 0.0399, 0.1233, 0.0370, 0.1010,
        0.1314, 0.1693, 0.0130], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,122][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1793, 0.1013, 0.0542, 0.0931, 0.0604, 0.0772, 0.0679, 0.0582, 0.0880,
        0.0859, 0.0935, 0.0411], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,123][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1938, 0.0942, 0.0390, 0.0901, 0.0412, 0.0844, 0.0560, 0.0524, 0.0392,
        0.0671, 0.0698, 0.1728], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,123][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.1725, 0.1367, 0.0510, 0.0907, 0.1007, 0.0312, 0.0399, 0.0402, 0.0367,
        0.1563, 0.0973, 0.0469], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,123][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0868, 0.1087, 0.1639, 0.0925, 0.0578, 0.0134, 0.0622, 0.0556, 0.0831,
        0.0914, 0.0856, 0.0379, 0.0611], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,124][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([1.8231e-05, 3.0804e-05, 2.6199e-04, 2.1431e-05, 5.3755e-01, 4.9275e-06,
        1.8762e-05, 8.1144e-06, 3.6177e-06, 5.5883e-06, 8.5344e-06, 9.9288e-06,
        4.6206e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,126][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.1653, 0.0953, 0.0235, 0.0729, 0.1366, 0.0943, 0.0758, 0.0446, 0.0141,
        0.0538, 0.0571, 0.0340, 0.1327], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,127][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([2.0459e-04, 3.1337e-07, 9.7567e-05, 2.7961e-07, 5.2113e-03, 3.7222e-06,
        1.0797e-05, 1.0773e-04, 1.1993e-04, 2.1509e-05, 3.0244e-05, 1.9691e-04,
        9.9400e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,128][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([5.3281e-03, 7.0163e-04, 4.5905e-03, 6.7303e-04, 8.5552e-02, 6.1403e-04,
        8.6010e-04, 9.0158e-04, 4.0499e-03, 3.7533e-03, 4.7027e-03, 1.4607e-02,
        8.7367e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,129][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([1.8359e-03, 6.7206e-08, 1.2123e-04, 1.8022e-08, 5.9745e-01, 1.5472e-07,
        3.0103e-09, 2.1853e-07, 8.9991e-08, 9.2672e-10, 2.4692e-09, 2.1375e-06,
        4.0059e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,130][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.1208, 0.1518, 0.1003, 0.1124, 0.0579, 0.0226, 0.0682, 0.0279, 0.0589,
        0.1107, 0.0966, 0.0172, 0.0547], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,131][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0712, 0.0342, 0.0127, 0.0360, 0.0050, 0.0467, 0.0907, 0.0250, 0.0400,
        0.1977, 0.3540, 0.0392, 0.0477], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,132][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.1061, 0.0654, 0.0419, 0.0640, 0.2063, 0.0344, 0.0429, 0.0364, 0.0226,
        0.0533, 0.0584, 0.0279, 0.2404], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,132][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.1992, 0.1149, 0.0984, 0.1001, 0.0192, 0.0560, 0.0680, 0.0511, 0.0433,
        0.0873, 0.0937, 0.0500, 0.0190], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,132][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.1042, 0.0728, 0.0556, 0.0633, 0.2556, 0.0395, 0.0451, 0.0306, 0.0137,
        0.0446, 0.0444, 0.0176, 0.2131], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,133][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0555, 0.0723, 0.0400, 0.0692, 0.0727, 0.0814, 0.0887, 0.0685, 0.0904,
        0.0735, 0.0938, 0.0906, 0.1034], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,133][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.2896, 0.0251, 0.1078, 0.0145, 0.0944, 0.0528, 0.0154, 0.0383, 0.0369,
        0.0247, 0.0154, 0.0839, 0.1368, 0.0644], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,133][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([1.4433e-03, 3.5479e-03, 2.3715e-03, 1.1997e-03, 3.8089e-04, 8.4822e-03,
        1.4033e-03, 4.5737e-05, 1.5904e-03, 1.5492e-03, 7.2151e-04, 1.1227e-04,
        2.6353e-04, 9.7689e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,134][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.2307, 0.0515, 0.0195, 0.0445, 0.0195, 0.1061, 0.0350, 0.0257, 0.0504,
        0.0426, 0.0415, 0.0417, 0.0194, 0.2718], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,134][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.9934e-03, 7.3730e-05, 1.3541e-05, 5.4886e-05, 8.5287e-05, 3.0897e-04,
        4.2926e-04, 4.8796e-04, 1.2579e-03, 2.5472e-03, 3.5607e-03, 1.3213e-03,
        6.9296e-03, 9.8094e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,136][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0860, 0.0131, 0.0043, 0.0187, 0.0049, 0.0267, 0.0217, 0.0252, 0.0428,
        0.0564, 0.1199, 0.0242, 0.0342, 0.5217], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,137][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([1.2077e-02, 2.4346e-03, 8.3819e-05, 8.9067e-04, 1.6749e-04, 8.6986e-03,
        2.0764e-04, 2.9481e-05, 6.7257e-04, 2.4887e-04, 2.8124e-04, 6.2023e-06,
        6.3414e-05, 9.7414e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,139][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1691, 0.0083, 0.1391, 0.0083, 0.1736, 0.0111, 0.0067, 0.0303, 0.0798,
        0.0063, 0.0082, 0.1159, 0.2270, 0.0164], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,140][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0286, 0.0054, 0.0059, 0.0091, 0.0166, 0.0123, 0.0260, 0.0113, 0.0178,
        0.0946, 0.1478, 0.1523, 0.3225, 0.1496], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,142][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0519, 0.1074, 0.0120, 0.1054, 0.0187, 0.1026, 0.1388, 0.0316, 0.0280,
        0.1777, 0.1390, 0.0252, 0.0242, 0.0377], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,142][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1510, 0.0812, 0.0432, 0.0833, 0.0449, 0.0667, 0.0635, 0.0471, 0.0554,
        0.0755, 0.0863, 0.0560, 0.0495, 0.0965], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,142][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1032, 0.0744, 0.0381, 0.0784, 0.0323, 0.0808, 0.0606, 0.0254, 0.0485,
        0.0629, 0.0677, 0.0289, 0.0275, 0.2714], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,143][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.2267, 0.0539, 0.0471, 0.0721, 0.0867, 0.0345, 0.0289, 0.0520, 0.0618,
        0.0572, 0.0732, 0.0759, 0.0939, 0.0363], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,143][circuit_model.py][line:2332][INFO] ##0-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2447, 0.0237, 0.0463, 0.0198, 0.0951, 0.0639, 0.0213, 0.0345, 0.0681,
        0.0237, 0.0243, 0.0789, 0.1384, 0.1016, 0.0157], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,143][circuit_model.py][line:2335][INFO] ##0-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([4.1195e-03, 1.1774e-02, 5.5456e-04, 3.4302e-02, 1.1666e-04, 3.0521e-04,
        1.4486e-03, 1.7840e-04, 5.7908e-05, 8.2810e-03, 3.0194e-02, 2.4495e-04,
        8.0493e-05, 1.4509e-04, 9.0820e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,144][circuit_model.py][line:2338][INFO] ##0-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.1577, 0.0693, 0.0214, 0.0952, 0.0347, 0.0579, 0.0249, 0.0372, 0.0303,
        0.0592, 0.0938, 0.0385, 0.0359, 0.0737, 0.1704], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,144][circuit_model.py][line:2341][INFO] ##0-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([2.9355e-03, 2.6500e-04, 6.9351e-05, 1.8160e-04, 8.2497e-05, 7.2685e-04,
        1.2022e-03, 2.4175e-04, 1.1445e-03, 7.1776e-03, 1.1902e-02, 1.6523e-02,
        6.7648e-03, 2.9247e-01, 6.5832e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,145][circuit_model.py][line:2344][INFO] ##0-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0361, 0.0023, 0.0016, 0.0038, 0.0011, 0.0341, 0.0104, 0.0264, 0.0576,
        0.0124, 0.0318, 0.0737, 0.0098, 0.4189, 0.2797], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,146][circuit_model.py][line:2347][INFO] ##0-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([4.3377e-02, 6.1278e-02, 2.2281e-03, 7.8456e-02, 8.2573e-04, 3.1249e-02,
        2.2679e-01, 3.4402e-02, 4.7678e-03, 2.1222e-02, 4.1328e-02, 7.4611e-04,
        3.7853e-04, 3.2672e-02, 4.2028e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,148][circuit_model.py][line:2350][INFO] ##0-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1145, 0.0055, 0.0749, 0.0047, 0.0948, 0.0160, 0.0045, 0.0296, 0.0511,
        0.0041, 0.0060, 0.1041, 0.1557, 0.0307, 0.3038], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,149][circuit_model.py][line:2353][INFO] ##0-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0215, 0.0041, 0.0057, 0.0067, 0.0089, 0.0087, 0.0116, 0.0179, 0.0262,
        0.0479, 0.0776, 0.0910, 0.1539, 0.2517, 0.2665], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,151][circuit_model.py][line:2356][INFO] ##0-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0080, 0.0595, 0.0023, 0.1036, 0.0050, 0.0466, 0.1311, 0.0198, 0.0089,
        0.1508, 0.1814, 0.0048, 0.0075, 0.0338, 0.2369], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,152][circuit_model.py][line:2359][INFO] ##0-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1211, 0.0750, 0.0356, 0.0825, 0.0383, 0.0551, 0.0702, 0.0482, 0.0433,
        0.0708, 0.0866, 0.0465, 0.0426, 0.0841, 0.0998], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,152][circuit_model.py][line:2362][INFO] ##0-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1029, 0.0845, 0.0340, 0.1012, 0.0290, 0.0750, 0.0862, 0.0506, 0.0336,
        0.0767, 0.0935, 0.0278, 0.0259, 0.0647, 0.1144], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,153][circuit_model.py][line:2365][INFO] ##0-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1711, 0.0676, 0.0408, 0.0694, 0.0708, 0.0482, 0.0438, 0.0514, 0.0515,
        0.0695, 0.0660, 0.0711, 0.0737, 0.0353, 0.0698], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,154][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:16,155][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[33458],
        [ 8689],
        [    2],
        [14087],
        [18516],
        [ 9505],
        [27866],
        [36963],
        [19625],
        [ 9474],
        [18406],
        [32848],
        [25723],
        [ 1004],
        [15310]], device='cuda:0')
[2024-07-24 10:20:16,156][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[20575],
        [12371],
        [    1],
        [13027],
        [  842],
        [26974],
        [11717],
        [37182],
        [21090],
        [21956],
        [20551],
        [28239],
        [ 1475],
        [21297],
        [28080]], device='cuda:0')
[2024-07-24 10:20:16,158][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[1993],
        [1816],
        [2488],
        [2264],
        [3867],
        [ 399],
        [ 894],
        [ 817],
        [1073],
        [ 946],
        [1167],
        [1464],
        [3587],
        [ 662],
        [ 895]], device='cuda:0')
[2024-07-24 10:20:16,159][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[28287],
        [ 7404],
        [15027],
        [25697],
        [ 8091],
        [21005],
        [46967],
        [27500],
        [26226],
        [ 7666],
        [26579],
        [40898],
        [ 8241],
        [31672],
        [34583]], device='cuda:0')
[2024-07-24 10:20:16,161][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[14482],
        [21168],
        [19492],
        [38194],
        [28262],
        [28661],
        [33629],
        [29472],
        [25470],
        [34110],
        [41346],
        [32900],
        [33858],
        [29779],
        [38941]], device='cuda:0')
[2024-07-24 10:20:16,162][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[44600],
        [43443],
        [ 7516],
        [29892],
        [29944],
        [10136],
        [24854],
        [  516],
        [27514],
        [17369],
        [20067],
        [22123],
        [27671],
        [ 1790],
        [13845]], device='cuda:0')
[2024-07-24 10:20:16,163][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[11694],
        [11755],
        [ 4310],
        [ 9875],
        [ 8577],
        [14405],
        [13778],
        [ 7645],
        [36860],
        [12037],
        [20519],
        [36065],
        [ 8989],
        [21987],
        [20636]], device='cuda:0')
[2024-07-24 10:20:16,164][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[12390],
        [20000],
        [  282],
        [19141],
        [ 1440],
        [33353],
        [24223],
        [19667],
        [ 7112],
        [22550],
        [22999],
        [42244],
        [ 1590],
        [13834],
        [22317]], device='cuda:0')
[2024-07-24 10:20:16,165][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[45908],
        [46130],
        [34253],
        [22984],
        [40443],
        [ 8552],
        [14483],
        [16246],
        [16287],
        [15061],
        [15154],
        [35913],
        [40515],
        [16443],
        [24345]], device='cuda:0')
[2024-07-24 10:20:16,166][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[37358],
        [35822],
        [24333],
        [15812],
        [26748],
        [30747],
        [44008],
        [46048],
        [43158],
        [26815],
        [33425],
        [37697],
        [36738],
        [21127],
        [34907]], device='cuda:0')
[2024-07-24 10:20:16,168][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15188],
        [ 1514],
        [ 9147],
        [ 3347],
        [24448],
        [ 4557],
        [ 5883],
        [ 7200],
        [10577],
        [ 2781],
        [ 3539],
        [ 3082],
        [30745],
        [ 3518],
        [ 2224]], device='cuda:0')
[2024-07-24 10:20:16,169][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[30139],
        [38802],
        [37922],
        [41296],
        [38075],
        [40325],
        [39831],
        [39232],
        [38833],
        [42053],
        [43398],
        [42568],
        [41914],
        [42941],
        [44280]], device='cuda:0')
[2024-07-24 10:20:16,171][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[16175],
        [ 6913],
        [35989],
        [ 3687],
        [38294],
        [ 1082],
        [ 6546],
        [ 7634],
        [ 4952],
        [ 3243],
        [ 2291],
        [ 6305],
        [47819],
        [ 1623],
        [ 1966]], device='cuda:0')
[2024-07-24 10:20:16,172][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31322],
        [24131],
        [16570],
        [23524],
        [22958],
        [26666],
        [28315],
        [32428],
        [29951],
        [30066],
        [30076],
        [27160],
        [31393],
        [33807],
        [32280]], device='cuda:0')
[2024-07-24 10:20:16,173][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[49647],
        [31570],
        [    5],
        [47670],
        [38349],
        [41239],
        [49696],
        [49301],
        [30448],
        [32841],
        [47372],
        [45582],
        [38449],
        [10402],
        [44912]], device='cuda:0')
[2024-07-24 10:20:16,174][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[32117],
        [31686],
        [19317],
        [22940],
        [20693],
        [35252],
        [36373],
        [29326],
        [28051],
        [34692],
        [30729],
        [27291],
        [21352],
        [32569],
        [30438]], device='cuda:0')
[2024-07-24 10:20:16,175][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[20127],
        [ 9143],
        [18606],
        [ 4453],
        [31012],
        [10731],
        [ 2430],
        [17244],
        [17670],
        [ 8235],
        [ 4108],
        [ 9760],
        [28057],
        [12020],
        [ 3023]], device='cuda:0')
[2024-07-24 10:20:16,176][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[42123],
        [37584],
        [34599],
        [46916],
        [39049],
        [43452],
        [43678],
        [42911],
        [43500],
        [36140],
        [48189],
        [44595],
        [42750],
        [47049],
        [43865]], device='cuda:0')
[2024-07-24 10:20:16,177][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[24363],
        [19077],
        [30954],
        [36301],
        [14035],
        [28770],
        [37196],
        [38086],
        [30153],
        [33660],
        [41160],
        [20204],
        [20370],
        [33887],
        [39239]], device='cuda:0')
[2024-07-24 10:20:16,179][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[12915],
        [13379],
        [32100],
        [18859],
        [42510],
        [17780],
        [16150],
        [21151],
        [17412],
        [22652],
        [15209],
        [39726],
        [42731],
        [16624],
        [12079]], device='cuda:0')
[2024-07-24 10:20:16,180][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23330],
        [33276],
        [38324],
        [35945],
        [45754],
        [30596],
        [37994],
        [28833],
        [33991],
        [34980],
        [36586],
        [ 8359],
        [45531],
        [33927],
        [35253]], device='cuda:0')
[2024-07-24 10:20:16,182][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[45053],
        [45031],
        [22894],
        [29759],
        [24202],
        [11238],
        [19474],
        [16866],
        [19760],
        [24054],
        [23607],
        [18186],
        [25075],
        [27840],
        [38106]], device='cuda:0')
[2024-07-24 10:20:16,183][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[23724],
        [22381],
        [11538],
        [ 5629],
        [ 6956],
        [ 6034],
        [ 8290],
        [ 8886],
        [ 6901],
        [ 6068],
        [ 6529],
        [ 9685],
        [ 8647],
        [ 9936],
        [ 3122]], device='cuda:0')
[2024-07-24 10:20:16,184][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10173],
        [ 6697],
        [10459],
        [23302],
        [25394],
        [29696],
        [24512],
        [27093],
        [25806],
        [18934],
        [22627],
        [21575],
        [28399],
        [22981],
        [19622]], device='cuda:0')
[2024-07-24 10:20:16,185][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[39426],
        [32557],
        [32698],
        [33623],
        [34366],
        [34586],
        [34625],
        [35332],
        [35746],
        [34337],
        [34525],
        [34735],
        [34475],
        [34556],
        [34325]], device='cuda:0')
[2024-07-24 10:20:16,186][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[47867],
        [49590],
        [49604],
        [49691],
        [49488],
        [49837],
        [49146],
        [49019],
        [49646],
        [49555],
        [49264],
        [49668],
        [49207],
        [49817],
        [49564]], device='cuda:0')
[2024-07-24 10:20:16,187][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 5934],
        [15593],
        [49440],
        [46135],
        [49398],
        [47662],
        [49191],
        [46547],
        [48926],
        [49514],
        [49541],
        [49807],
        [49551],
        [48989],
        [49521]], device='cuda:0')
[2024-07-24 10:20:16,189][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[5428],
        [4717],
        [5705],
        [4562],
        [4042],
        [5732],
        [5647],
        [5456],
        [4314],
        [4614],
        [4462],
        [4449],
        [3903],
        [3881],
        [4714]], device='cuda:0')
[2024-07-24 10:20:16,190][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[  623],
        [15893],
        [50246],
        [ 1948],
        [10591],
        [ 8059],
        [  387],
        [  811],
        [17802],
        [14777],
        [ 2022],
        [ 4718],
        [10434],
        [36840],
        [ 4040]], device='cuda:0')
[2024-07-24 10:20:16,192][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420],
        [22420]], device='cuda:0')
[2024-07-24 10:20:16,217][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:16,217][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,217][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,218][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,218][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,218][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,219][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,219][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,219][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,220][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,220][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,220][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,221][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,221][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2344, 0.7656], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,221][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.8603, 0.1397], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,221][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9759, 0.0241], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,222][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5128, 0.4872], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,222][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.3961, 0.6039], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,222][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5740, 0.4260], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,224][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7172, 0.2828], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,225][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1778, 0.8222], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,227][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9096, 0.0904], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,228][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.7523, 0.2477], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,229][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2038, 0.7962], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,229][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.6672, 0.3328], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,229][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.0324, 0.5609, 0.4067], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,230][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.2164, 0.5389, 0.2447], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,230][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.8249, 0.1023, 0.0728], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,230][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.4728, 0.2968, 0.2304], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,231][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.2244, 0.3505, 0.4251], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,231][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.7291, 0.2605, 0.0104], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,231][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.3879, 0.3757, 0.2364], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,232][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.1492, 0.4891, 0.3617], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,234][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.7448, 0.1114, 0.1438], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,236][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.5474, 0.2255, 0.2271], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,237][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.1135, 0.3861, 0.5004], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,239][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.0136, 0.0180, 0.9684], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,239][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0213, 0.2336, 0.3890, 0.3561], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,239][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1295, 0.2150, 0.6468, 0.0087], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,240][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4428, 0.0893, 0.0778, 0.3901], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,240][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.3790, 0.1619, 0.3049, 0.1543], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,240][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1598, 0.2457, 0.3140, 0.2805], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,241][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([4.1559e-02, 2.1638e-01, 1.6250e-04, 7.4190e-01], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,241][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3445, 0.1776, 0.1344, 0.3436], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,241][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0753, 0.3114, 0.1857, 0.4277], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,242][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.7711, 0.0989, 0.1101, 0.0198], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,244][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5391, 0.1628, 0.1539, 0.1443], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,245][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0813, 0.2782, 0.3991, 0.2414], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,247][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0715, 0.1337, 0.0036, 0.7912], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,248][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0079, 0.1702, 0.2198, 0.3028, 0.2993], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,249][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0817, 0.2383, 0.3367, 0.3020, 0.0413], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,250][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.3476, 0.1051, 0.0589, 0.3428, 0.1455], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,250][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.3404, 0.1676, 0.2203, 0.1345, 0.1371], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,250][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.1188, 0.1923, 0.2319, 0.2226, 0.2344], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,251][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.3211, 0.1672, 0.2541, 0.1555, 0.1021], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,251][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.2202, 0.2161, 0.0449, 0.4336, 0.0852], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,251][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0441, 0.0956, 0.1171, 0.3458, 0.3975], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,252][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.6440, 0.1107, 0.1535, 0.0198, 0.0720], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,252][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.3430, 0.1505, 0.1515, 0.2160, 0.1390], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,254][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0715, 0.2248, 0.2896, 0.1917, 0.2224], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,255][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([2.1025e-03, 4.2412e-03, 3.5363e-04, 1.8707e-03, 9.9143e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,257][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0188, 0.0798, 0.1012, 0.1819, 0.1484, 0.4699], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,258][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0712, 0.2140, 0.3127, 0.2241, 0.1564, 0.0216], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,259][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.2524, 0.0785, 0.0624, 0.2320, 0.1574, 0.2173], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,260][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2725, 0.1321, 0.1940, 0.0999, 0.1408, 0.1608], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,260][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0969, 0.1511, 0.1890, 0.1740, 0.1929, 0.1962], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,260][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0592, 0.3846, 0.0013, 0.4828, 0.0023, 0.0698], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,261][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2710, 0.0896, 0.0742, 0.2850, 0.0809, 0.1992], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,261][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0227, 0.1880, 0.0579, 0.1357, 0.3995, 0.1961], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,262][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.6926, 0.0962, 0.1191, 0.0175, 0.0539, 0.0207], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,262][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3833, 0.1191, 0.1084, 0.1135, 0.0933, 0.1824], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,263][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0487, 0.1806, 0.2444, 0.1510, 0.1986, 0.1767], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,265][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0157, 0.1165, 0.0014, 0.0676, 0.0074, 0.7914], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,266][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0033, 0.0358, 0.0265, 0.0799, 0.0972, 0.5509, 0.2064],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,268][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1605, 0.1321, 0.2328, 0.0704, 0.2592, 0.1358, 0.0093],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,269][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2015, 0.0696, 0.0503, 0.1919, 0.1258, 0.1675, 0.1935],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,270][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2623, 0.1059, 0.1701, 0.0884, 0.1178, 0.1346, 0.1208],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,270][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0797, 0.1242, 0.1560, 0.1431, 0.1585, 0.1608, 0.1775],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,271][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.1007, 0.1971, 0.0011, 0.6030, 0.0065, 0.0613, 0.0303],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,271][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1554, 0.0640, 0.0522, 0.1438, 0.0479, 0.0935, 0.4432],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,271][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0204, 0.1077, 0.0550, 0.0927, 0.3973, 0.1924, 0.1344],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,272][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.6521, 0.0929, 0.1149, 0.0173, 0.0548, 0.0208, 0.0473],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,272][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3681, 0.1121, 0.0982, 0.1000, 0.0840, 0.1647, 0.0730],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,273][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0447, 0.1524, 0.2167, 0.1313, 0.1715, 0.1513, 0.1322],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,274][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ a] are: tensor([3.6041e-03, 1.0142e-02, 2.6596e-04, 7.9088e-03, 1.7389e-04, 2.8203e-04,
        9.7762e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,276][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0011, 0.0161, 0.0229, 0.0425, 0.0636, 0.3837, 0.3462, 0.1238],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,278][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0529, 0.1145, 0.3953, 0.0872, 0.1417, 0.0687, 0.1346, 0.0051],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,279][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1802, 0.0688, 0.0461, 0.1816, 0.1091, 0.1484, 0.1620, 0.1038],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,281][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.2111, 0.0881, 0.2111, 0.0787, 0.1377, 0.1393, 0.0926, 0.0413],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,282][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0665, 0.1049, 0.1274, 0.1212, 0.1289, 0.1352, 0.1517, 0.1641],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,283][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ long] are: tensor([1.5097e-01, 2.2997e-01, 1.8348e-04, 5.2475e-01, 3.8082e-04, 3.1062e-02,
        4.1803e-02, 2.0873e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,285][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1758, 0.0667, 0.0230, 0.1541, 0.0161, 0.1014, 0.4050, 0.0578],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,285][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0194, 0.0871, 0.0602, 0.0821, 0.4823, 0.1416, 0.1032, 0.0241],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,286][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.6430, 0.0837, 0.1068, 0.0161, 0.0497, 0.0173, 0.0399, 0.0435],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,286][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2903, 0.1030, 0.0990, 0.1108, 0.0881, 0.1639, 0.0700, 0.0749],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,286][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0389, 0.1353, 0.1859, 0.1139, 0.1500, 0.1307, 0.1152, 0.1302],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,287][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ long] are: tensor([2.5003e-02, 5.5688e-02, 3.7441e-04, 2.7149e-02, 9.1772e-04, 1.8470e-03,
        1.6533e-03, 8.8737e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,287][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0006, 0.0179, 0.0183, 0.0466, 0.0539, 0.3059, 0.2568, 0.2339, 0.0663],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,288][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.1663, 0.1849, 0.2403, 0.1220, 0.0989, 0.0968, 0.0688, 0.0158, 0.0062],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,288][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1436, 0.0628, 0.0442, 0.1627, 0.1005, 0.1370, 0.1442, 0.0877, 0.1174],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,290][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.2100, 0.0893, 0.1875, 0.0798, 0.1209, 0.1284, 0.0883, 0.0391, 0.0567],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,292][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0566, 0.0905, 0.1086, 0.1039, 0.1101, 0.1158, 0.1313, 0.1411, 0.1420],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,293][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0927, 0.1019, 0.0046, 0.6748, 0.0247, 0.0368, 0.0477, 0.0064, 0.0102],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,295][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1702, 0.0820, 0.0246, 0.1820, 0.0118, 0.0917, 0.3447, 0.0378, 0.0552],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,296][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0135, 0.0558, 0.0516, 0.0815, 0.3871, 0.1796, 0.1504, 0.0264, 0.0541],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,296][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.5581, 0.0847, 0.1194, 0.0170, 0.0607, 0.0204, 0.0469, 0.0504, 0.0423],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,296][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.2392, 0.0912, 0.0943, 0.1124, 0.0848, 0.1620, 0.0648, 0.0699, 0.0812],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,297][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0343, 0.1155, 0.1609, 0.0964, 0.1270, 0.1101, 0.0975, 0.1104, 0.1478],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,297][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([1.5566e-02, 2.2285e-02, 4.3711e-04, 1.2258e-02, 1.4620e-04, 2.0842e-04,
        1.1934e-03, 6.1241e-05, 9.4785e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,298][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0047, 0.0222, 0.0441, 0.0513, 0.0672, 0.1607, 0.2259, 0.1516, 0.1737,
        0.0985], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,298][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0652, 0.0116, 0.1930, 0.0979, 0.1718, 0.3120, 0.0333, 0.0665, 0.0398,
        0.0088], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,298][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0936, 0.0504, 0.0348, 0.1149, 0.0789, 0.1116, 0.1065, 0.0706, 0.1006,
        0.2382], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,299][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2163, 0.0770, 0.1304, 0.0768, 0.1030, 0.1082, 0.0789, 0.0533, 0.0742,
        0.0819], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,299][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0504, 0.0778, 0.0978, 0.0884, 0.0998, 0.0994, 0.1093, 0.1243, 0.1257,
        0.1269], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,301][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0182, 0.3918, 0.0009, 0.2435, 0.0009, 0.0790, 0.0267, 0.0130, 0.0126,
        0.2134], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,303][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0949, 0.0574, 0.0450, 0.1029, 0.0249, 0.0863, 0.2991, 0.0597, 0.0360,
        0.1939], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,304][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0199, 0.0975, 0.0459, 0.0808, 0.2615, 0.1640, 0.1158, 0.0278, 0.0490,
        0.1377], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,306][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5840, 0.0900, 0.0995, 0.0164, 0.0470, 0.0198, 0.0438, 0.0495, 0.0389,
        0.0112], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,307][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3191, 0.0937, 0.0863, 0.0789, 0.0726, 0.1303, 0.0581, 0.0677, 0.0589,
        0.0344], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,307][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0298, 0.1030, 0.1458, 0.0879, 0.1188, 0.1024, 0.0865, 0.1028, 0.1367,
        0.0863], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,307][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0592, 0.1513, 0.0468, 0.1691, 0.0400, 0.0335, 0.0953, 0.0119, 0.0402,
        0.3526], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,308][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0020, 0.0242, 0.0385, 0.0358, 0.0547, 0.1505, 0.2324, 0.1706, 0.1408,
        0.1091, 0.0415], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,308][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0725, 0.0974, 0.3265, 0.0025, 0.1983, 0.1722, 0.0395, 0.0326, 0.0134,
        0.0443, 0.0007], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,309][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0758, 0.0456, 0.0323, 0.0991, 0.0658, 0.0945, 0.0889, 0.0586, 0.0872,
        0.1897, 0.1625], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,309][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.2123, 0.0695, 0.1149, 0.0756, 0.0972, 0.0929, 0.0670, 0.0491, 0.0710,
        0.0769, 0.0736], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,310][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0449, 0.0690, 0.0882, 0.0789, 0.0902, 0.0891, 0.0978, 0.1117, 0.1133,
        0.1132, 0.1036], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,312][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0177, 0.1831, 0.0005, 0.3825, 0.0014, 0.0159, 0.0221, 0.0047, 0.0029,
        0.1735, 0.1957], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,313][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0828, 0.0464, 0.0374, 0.0829, 0.0189, 0.0765, 0.3239, 0.0500, 0.0296,
        0.1649, 0.0866], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,315][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0154, 0.0671, 0.0406, 0.0686, 0.1876, 0.1546, 0.1063, 0.0274, 0.0445,
        0.1150, 0.1729], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,316][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5540, 0.0892, 0.1074, 0.0181, 0.0522, 0.0216, 0.0476, 0.0510, 0.0420,
        0.0126, 0.0044], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,317][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.3163, 0.0911, 0.0814, 0.0740, 0.0680, 0.1260, 0.0560, 0.0646, 0.0543,
        0.0330, 0.0352], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,317][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0281, 0.0926, 0.1348, 0.0814, 0.1100, 0.0938, 0.0790, 0.0954, 0.1270,
        0.0788, 0.0791], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,318][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ and] are: tensor([8.0352e-03, 5.6179e-02, 1.0996e-03, 2.1937e-01, 7.2883e-04, 9.2159e-03,
        3.2835e-03, 2.9345e-04, 1.7921e-03, 1.8001e-01, 5.2000e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,318][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0010, 0.0184, 0.0123, 0.0433, 0.0403, 0.2585, 0.1166, 0.2174, 0.0758,
        0.1058, 0.0490, 0.0615], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,319][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0741, 0.1650, 0.1843, 0.2262, 0.0809, 0.0409, 0.0213, 0.0190, 0.0159,
        0.0917, 0.0786, 0.0021], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,319][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0860, 0.0451, 0.0311, 0.0910, 0.0583, 0.0823, 0.0815, 0.0554, 0.0778,
        0.1780, 0.1363, 0.0771], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,319][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1776, 0.0665, 0.1243, 0.0651, 0.0845, 0.0963, 0.0712, 0.0366, 0.0528,
        0.0842, 0.0659, 0.0750], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,320][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0405, 0.0636, 0.0775, 0.0729, 0.0789, 0.0822, 0.0918, 0.1004, 0.1003,
        0.1066, 0.0986, 0.0868], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,321][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([1.3645e-02, 1.0637e-01, 1.2858e-02, 2.9203e-02, 1.6167e-05, 4.3453e-01,
        1.9667e-02, 2.9716e-01, 5.7580e-02, 1.2667e-02, 1.6277e-02, 2.1398e-05],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,323][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0884, 0.0571, 0.0184, 0.1341, 0.0069, 0.0704, 0.1842, 0.0397, 0.0127,
        0.2353, 0.1194, 0.0335], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,324][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0112, 0.0208, 0.0400, 0.0641, 0.1486, 0.2035, 0.1259, 0.0342, 0.0577,
        0.1100, 0.1748, 0.0090], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,326][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.5868, 0.0822, 0.0969, 0.0154, 0.0470, 0.0179, 0.0397, 0.0437, 0.0362,
        0.0107, 0.0037, 0.0198], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,327][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.2284, 0.0808, 0.0763, 0.0877, 0.0665, 0.1267, 0.0538, 0.0581, 0.0607,
        0.0362, 0.0410, 0.0838], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,328][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0269, 0.0883, 0.1182, 0.0742, 0.0964, 0.0837, 0.0748, 0.0833, 0.1110,
        0.0725, 0.0712, 0.0995], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,328][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([3.2891e-03, 1.7383e-03, 2.9599e-04, 1.3853e-03, 3.9846e-05, 4.7907e-05,
        1.9617e-05, 4.7170e-04, 6.7022e-04, 1.5657e-03, 1.1136e-03, 9.8936e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,328][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0008, 0.0187, 0.0231, 0.0324, 0.0331, 0.1335, 0.2713, 0.0701, 0.1144,
        0.1322, 0.0424, 0.0911, 0.0369], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,329][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0297, 0.0667, 0.1048, 0.0854, 0.0139, 0.1028, 0.1199, 0.0556, 0.0521,
        0.0934, 0.0838, 0.1778, 0.0141], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,329][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0690, 0.0527, 0.0259, 0.0907, 0.0476, 0.0851, 0.0772, 0.0447, 0.0716,
        0.1606, 0.1284, 0.0698, 0.0767], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,330][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.1793, 0.0755, 0.0981, 0.0658, 0.0633, 0.0933, 0.0596, 0.0381, 0.0601,
        0.0696, 0.0597, 0.0730, 0.0647], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,331][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0351, 0.0575, 0.0694, 0.0667, 0.0707, 0.0748, 0.0859, 0.0901, 0.0907,
        0.1013, 0.0941, 0.0785, 0.0852], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,332][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0512, 0.1160, 0.2778, 0.0787, 0.0265, 0.0295, 0.0168, 0.0141, 0.0815,
        0.1389, 0.1140, 0.0349, 0.0202], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,334][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0594, 0.0630, 0.0118, 0.1270, 0.0231, 0.0528, 0.2085, 0.0119, 0.0104,
        0.2494, 0.1411, 0.0227, 0.0188], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,336][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0058, 0.0124, 0.0214, 0.0593, 0.0618, 0.1534, 0.1116, 0.0208, 0.0433,
        0.1111, 0.2233, 0.0070, 0.1689], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,337][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.5011, 0.0941, 0.1185, 0.0162, 0.0579, 0.0188, 0.0452, 0.0438, 0.0396,
        0.0126, 0.0039, 0.0216, 0.0267], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,338][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.1455, 0.0700, 0.0679, 0.1067, 0.0645, 0.1347, 0.0508, 0.0500, 0.0663,
        0.0388, 0.0474, 0.0898, 0.0677], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,338][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0274, 0.0823, 0.1068, 0.0707, 0.0817, 0.0778, 0.0683, 0.0763, 0.0999,
        0.0687, 0.0684, 0.0913, 0.0804], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,339][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([1.7950e-05, 1.9247e-03, 2.1988e-04, 1.4600e-04, 7.4569e-01, 2.1777e-05,
        3.4036e-05, 5.5862e-06, 2.8468e-06, 6.3351e-03, 2.8308e-04, 8.6405e-06,
        2.4531e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,339][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0021, 0.0204, 0.0131, 0.0417, 0.0732, 0.2065, 0.1222, 0.1215, 0.0452,
        0.0883, 0.0506, 0.0628, 0.0773, 0.0749], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,339][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0993, 0.3458, 0.0969, 0.0924, 0.0337, 0.0262, 0.0172, 0.0167, 0.0024,
        0.2051, 0.0280, 0.0117, 0.0231, 0.0015], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,340][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0596, 0.0430, 0.0328, 0.0674, 0.0534, 0.0663, 0.0634, 0.0449, 0.0644,
        0.1248, 0.1005, 0.0670, 0.0809, 0.1317], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,341][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1652, 0.0569, 0.1072, 0.0515, 0.0751, 0.0818, 0.0529, 0.0296, 0.0462,
        0.0629, 0.0510, 0.0715, 0.0797, 0.0685], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,343][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0337, 0.0529, 0.0653, 0.0612, 0.0662, 0.0689, 0.0765, 0.0844, 0.0845,
        0.0888, 0.0815, 0.0725, 0.0757, 0.0879], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,344][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0137, 0.2577, 0.0053, 0.2012, 0.0014, 0.0929, 0.0406, 0.0210, 0.0129,
        0.1380, 0.0901, 0.0565, 0.0006, 0.0681], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,346][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1005, 0.0469, 0.0214, 0.1016, 0.0195, 0.0504, 0.1936, 0.0224, 0.0322,
        0.1725, 0.1195, 0.0390, 0.0141, 0.0664], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,347][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0069, 0.0302, 0.0224, 0.0277, 0.1412, 0.0550, 0.0417, 0.0098, 0.0206,
        0.0461, 0.0762, 0.0180, 0.4727, 0.0314], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,348][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.5783, 0.0771, 0.0905, 0.0140, 0.0439, 0.0163, 0.0349, 0.0412, 0.0329,
        0.0097, 0.0032, 0.0177, 0.0174, 0.0229], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,348][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1978, 0.0651, 0.0609, 0.0645, 0.0531, 0.1010, 0.0426, 0.0466, 0.0453,
        0.0268, 0.0297, 0.0642, 0.0586, 0.1438], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,349][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0206, 0.0711, 0.1012, 0.0609, 0.0816, 0.0709, 0.0603, 0.0714, 0.0952,
        0.0598, 0.0590, 0.0883, 0.0796, 0.0801], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,349][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ said] are: tensor([7.8142e-03, 3.7021e-02, 4.3024e-04, 1.7275e-02, 3.0348e-04, 4.9691e-04,
        4.7748e-03, 8.3163e-05, 1.1675e-02, 8.3597e-02, 1.8466e-02, 1.0064e-03,
        9.6190e-05, 8.1696e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,350][circuit_model.py][line:2294][INFO] ##1-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0015, 0.0163, 0.0199, 0.0297, 0.0302, 0.2327, 0.1214, 0.1107, 0.0863,
        0.0780, 0.0317, 0.0632, 0.0279, 0.1345, 0.0160], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,350][circuit_model.py][line:2297][INFO] ##1-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.1060, 0.0680, 0.2519, 0.0768, 0.0925, 0.1072, 0.0521, 0.0145, 0.0068,
        0.0433, 0.0303, 0.0188, 0.0766, 0.0547, 0.0004], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,351][circuit_model.py][line:2300][INFO] ##1-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0401, 0.0407, 0.0268, 0.0541, 0.0441, 0.0600, 0.0532, 0.0395, 0.0586,
        0.1013, 0.0812, 0.0637, 0.0714, 0.1244, 0.1410], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,353][circuit_model.py][line:2303][INFO] ##1-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1665, 0.0478, 0.0933, 0.0458, 0.0699, 0.0816, 0.0543, 0.0292, 0.0484,
        0.0603, 0.0471, 0.0673, 0.0758, 0.0655, 0.0471], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,354][circuit_model.py][line:2306][INFO] ##1-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0320, 0.0490, 0.0610, 0.0557, 0.0624, 0.0626, 0.0689, 0.0779, 0.0785,
        0.0796, 0.0730, 0.0674, 0.0707, 0.0794, 0.0818], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,355][circuit_model.py][line:2309][INFO] ##1-th layer ##Weight##: The head6 weight for token [ to] are: tensor([1.6798e-02, 2.0164e-01, 1.1452e-03, 1.5693e-01, 3.9908e-04, 7.2486e-02,
        5.5185e-02, 2.3866e-02, 2.7907e-03, 7.0377e-02, 4.5468e-02, 5.1859e-02,
        1.3024e-04, 1.5828e-02, 2.8510e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,357][circuit_model.py][line:2312][INFO] ##1-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1164, 0.0369, 0.0238, 0.0799, 0.0109, 0.0608, 0.2498, 0.0345, 0.0180,
        0.1161, 0.0795, 0.0320, 0.0074, 0.0676, 0.0665], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,358][circuit_model.py][line:2315][INFO] ##1-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0033, 0.0121, 0.0180, 0.0355, 0.0560, 0.1157, 0.0727, 0.0192, 0.0285,
        0.0725, 0.1052, 0.0083, 0.1386, 0.0671, 0.2473], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,358][circuit_model.py][line:2318][INFO] ##1-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.5685, 0.0759, 0.0900, 0.0144, 0.0432, 0.0169, 0.0353, 0.0418, 0.0342,
        0.0096, 0.0032, 0.0181, 0.0159, 0.0220, 0.0111], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,358][circuit_model.py][line:2321][INFO] ##1-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.2275, 0.0672, 0.0578, 0.0570, 0.0485, 0.0925, 0.0407, 0.0458, 0.0387,
        0.0243, 0.0261, 0.0590, 0.0549, 0.1262, 0.0339], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,359][circuit_model.py][line:2324][INFO] ##1-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0197, 0.0674, 0.0975, 0.0571, 0.0770, 0.0664, 0.0573, 0.0669, 0.0903,
        0.0566, 0.0551, 0.0817, 0.0753, 0.0760, 0.0557], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,359][circuit_model.py][line:2327][INFO] ##1-th layer ##Weight##: The head12 weight for token [ to] are: tensor([2.6767e-03, 1.5887e-02, 8.5379e-05, 2.7000e-02, 9.7398e-05, 3.0536e-04,
        3.7037e-03, 3.2665e-05, 2.5512e-04, 5.9527e-02, 3.9991e-02, 7.6854e-04,
        1.0224e-04, 1.2802e-03, 8.4829e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,374][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:16,374][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,375][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,375][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,375][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,376][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,378][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,379][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,380][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,381][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,382][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,382][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,382][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,383][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2830, 0.7170], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,383][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.9935e-01, 6.5292e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,383][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.5270, 0.4730], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,384][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.7173, 0.2827], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,384][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.5004, 0.4996], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,384][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4738, 0.5262], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,385][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9471, 0.0529], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,386][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.4143, 0.5857], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,386][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9982, 0.0018], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,387][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0134, 0.9866], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,387][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2270, 0.7730], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,387][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7340, 0.2660], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,388][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.0915, 0.3125, 0.5960], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,388][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([9.9993e-01, 6.1904e-05, 8.9339e-06], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,388][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.2925, 0.4534, 0.2541], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,389][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.5982, 0.2943, 0.1075], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,389][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.3338, 0.3332, 0.3331], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,389][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.3836, 0.4303, 0.1861], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,390][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.1019, 0.2065, 0.6916], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,390][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.1661, 0.3973, 0.4366], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,390][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.8250, 0.0030, 0.1720], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,392][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.0137, 0.9336, 0.0527], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,394][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.1309, 0.3929, 0.4762], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,395][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.2014, 0.2167, 0.5819], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,397][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0445, 0.1199, 0.2500, 0.5856], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,397][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9916e-01, 3.7550e-04, 5.6420e-05, 4.1108e-04], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,397][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2257, 0.2822, 0.2803, 0.2118], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,398][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6325, 0.1900, 0.0869, 0.0906], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,398][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.2504, 0.2499, 0.2499, 0.2499], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,398][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3235, 0.3151, 0.1549, 0.2065], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,399][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.7303, 0.0615, 0.1705, 0.0377], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,399][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1229, 0.1974, 0.4632, 0.2166], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,399][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.9370, 0.0021, 0.0497, 0.0112], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,400][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0051, 0.9066, 0.0521, 0.0362], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,402][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0949, 0.2819, 0.3752, 0.2480], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,404][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2468, 0.3049, 0.1774, 0.2708], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,405][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0198, 0.0707, 0.1459, 0.5479, 0.2158], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,406][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([9.9994e-01, 2.6443e-05, 3.7934e-06, 2.6054e-05, 6.9575e-07],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,407][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.1499, 0.2957, 0.1870, 0.1649, 0.2025], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,407][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.5012, 0.2255, 0.0836, 0.1413, 0.0484], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,407][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.2003, 0.1999, 0.1999, 0.1999, 0.1999], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,408][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.3220, 0.3393, 0.1262, 0.1759, 0.0367], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,408][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0395, 0.1208, 0.0136, 0.1599, 0.6662], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,409][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0832, 0.2393, 0.3995, 0.1891, 0.0890], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,409][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([2.0846e-02, 6.7058e-05, 6.4668e-03, 2.4268e-04, 9.7238e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,409][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0130, 0.8986, 0.0300, 0.0460, 0.0124], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,410][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0803, 0.2270, 0.2753, 0.1977, 0.2196], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,412][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.1210, 0.1539, 0.0768, 0.0919, 0.5564], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,413][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0169, 0.0508, 0.1177, 0.2631, 0.1536, 0.3978], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,414][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([9.9978e-01, 9.4549e-05, 1.2685e-05, 9.4623e-05, 1.9399e-06, 1.6459e-05],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,416][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1086, 0.2361, 0.1714, 0.1212, 0.1982, 0.1645], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,417][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.6011, 0.1437, 0.0856, 0.0672, 0.0461, 0.0562], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,417][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1669, 0.1666, 0.1666, 0.1666, 0.1666, 0.1666], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,418][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2904, 0.2964, 0.1076, 0.1888, 0.0311, 0.0856], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,418][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.4099, 0.0077, 0.0284, 0.0318, 0.3317, 0.1905], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,419][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0918, 0.1423, 0.3332, 0.1648, 0.1099, 0.1579], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,419][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([4.2229e-02, 4.6119e-04, 1.3246e-02, 1.0190e-03, 9.4243e-01, 6.1216e-04],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,419][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0020, 0.6756, 0.0490, 0.0060, 0.0834, 0.1839], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,420][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0562, 0.1821, 0.2292, 0.1548, 0.1934, 0.1842], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,421][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.4793, 0.1436, 0.0043, 0.0499, 0.0131, 0.3098], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,422][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0120, 0.0335, 0.0702, 0.1589, 0.1001, 0.2433, 0.3820],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,424][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([9.9960e-01, 1.2682e-04, 1.8192e-05, 1.2426e-04, 3.1399e-06, 2.5800e-05,
        1.0511e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,425][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1203, 0.1877, 0.1431, 0.1168, 0.1720, 0.1195, 0.1405],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,426][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.5847, 0.1332, 0.0796, 0.0605, 0.0418, 0.0496, 0.0508],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,427][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1431, 0.1428, 0.1428, 0.1428, 0.1428, 0.1428, 0.1429],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,428][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2980, 0.2687, 0.0972, 0.1633, 0.0280, 0.0735, 0.0714],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,428][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1245, 0.0056, 0.0514, 0.0095, 0.6763, 0.0904, 0.0423],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,428][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0859, 0.1101, 0.2532, 0.1232, 0.1091, 0.1434, 0.1751],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,429][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([2.2999e-01, 4.4781e-04, 1.1411e-02, 1.9236e-03, 7.5565e-01, 4.8115e-04,
        1.0418e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,429][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0031, 0.6234, 0.0186, 0.0098, 0.0472, 0.0800, 0.2179],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,430][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0516, 0.1537, 0.2031, 0.1347, 0.1676, 0.1577, 0.1315],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,432][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.1489, 0.0422, 0.0244, 0.0245, 0.0834, 0.2160, 0.4606],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,433][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0062, 0.0212, 0.0475, 0.1340, 0.0653, 0.2170, 0.3735, 0.1353],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,434][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([9.9963e-01, 1.0260e-04, 1.5843e-05, 1.1004e-04, 2.8425e-06, 2.1231e-05,
        9.3821e-05, 1.9580e-05], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,436][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1005, 0.1708, 0.1403, 0.0914, 0.1543, 0.1088, 0.1020, 0.1319],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,437][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.5573, 0.1384, 0.0605, 0.0628, 0.0305, 0.0497, 0.0527, 0.0480],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,437][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1252, 0.1250, 0.1249, 0.1249, 0.1250, 0.1250, 0.1251, 0.1249],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,438][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2616, 0.2603, 0.0942, 0.1528, 0.0273, 0.0718, 0.0690, 0.0630],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,438][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1793, 0.0128, 0.0022, 0.0209, 0.0045, 0.3221, 0.2310, 0.2273],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,438][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0532, 0.0782, 0.2837, 0.0937, 0.0825, 0.1487, 0.1675, 0.0925],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,439][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([1.0789e-02, 2.1293e-04, 6.1456e-03, 6.8246e-04, 3.4434e-01, 1.5835e-04,
        5.5406e-05, 6.3761e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,439][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0011, 0.6909, 0.0327, 0.0141, 0.0859, 0.0354, 0.1388, 0.0010],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,440][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0457, 0.1372, 0.1763, 0.1175, 0.1473, 0.1362, 0.1141, 0.1256],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,440][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.3856, 0.1131, 0.0036, 0.0360, 0.0160, 0.2040, 0.2037, 0.0381],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,441][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0035, 0.0136, 0.0307, 0.1154, 0.0432, 0.2010, 0.4130, 0.1166, 0.0631],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,442][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([9.9988e-01, 3.2299e-05, 4.3712e-06, 3.4008e-05, 7.5954e-07, 5.9703e-06,
        3.0128e-05, 6.3726e-06, 1.5745e-06], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,444][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0861, 0.1575, 0.1162, 0.0842, 0.1322, 0.0986, 0.0916, 0.1071, 0.1264],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,445][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.4777, 0.1401, 0.0534, 0.0735, 0.0283, 0.0654, 0.0668, 0.0597, 0.0350],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,447][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1113, 0.1111, 0.1110, 0.1110, 0.1111, 0.1111, 0.1112, 0.1111, 0.1112],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,448][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.2562, 0.2702, 0.0923, 0.1382, 0.0272, 0.0606, 0.0574, 0.0560, 0.0419],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,448][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.2030, 0.0269, 0.0031, 0.1128, 0.0037, 0.0943, 0.2111, 0.0122, 0.3329],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,449][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0487, 0.0778, 0.2111, 0.0737, 0.0878, 0.1405, 0.0982, 0.1310, 0.1312],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,449][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([1.5356e-02, 4.8774e-05, 3.0529e-03, 1.4794e-04, 3.4256e-01, 1.3299e-04,
        1.9791e-05, 6.1822e-01, 2.0460e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,449][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0010, 0.5058, 0.0478, 0.0062, 0.0702, 0.0736, 0.2926, 0.0016, 0.0011],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,450][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0403, 0.1183, 0.1530, 0.1008, 0.1252, 0.1162, 0.0976, 0.1070, 0.1416],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,450][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0836, 0.0469, 0.0137, 0.0692, 0.0320, 0.1757, 0.3068, 0.0165, 0.2555],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,451][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0067, 0.0192, 0.0386, 0.0982, 0.0571, 0.1536, 0.2575, 0.1020, 0.0719,
        0.1952], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,452][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([9.9924e-01, 1.7294e-04, 2.7315e-05, 1.8462e-04, 5.0881e-06, 4.1919e-05,
        1.7141e-04, 3.7667e-05, 1.0603e-05, 1.1114e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,453][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0781, 0.1143, 0.1117, 0.0708, 0.1324, 0.0934, 0.0859, 0.1143, 0.1416,
        0.0575], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,455][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5190, 0.1196, 0.0639, 0.0548, 0.0332, 0.0459, 0.0465, 0.0441, 0.0325,
        0.0405], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,456][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1001, 0.1000, 0.0999, 0.0999, 0.1000, 0.1000, 0.1001, 0.1000, 0.1001,
        0.1000], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,458][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2539, 0.2253, 0.0907, 0.1217, 0.0242, 0.0578, 0.0562, 0.0510, 0.0374,
        0.0816], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,458][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1792, 0.0176, 0.0323, 0.0109, 0.0844, 0.4210, 0.1002, 0.0762, 0.0423,
        0.0360], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,459][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0428, 0.0714, 0.1625, 0.0875, 0.0744, 0.0871, 0.1208, 0.1071, 0.1425,
        0.1039], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,459][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([3.5271e-02, 7.0061e-05, 4.0116e-03, 1.7753e-04, 2.8632e-01, 1.3950e-04,
        1.9708e-05, 6.5532e-01, 1.8655e-02, 1.0588e-05], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,460][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0028, 0.4740, 0.0143, 0.0141, 0.0253, 0.0313, 0.1712, 0.0026, 0.0007,
        0.2637], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,460][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0353, 0.1046, 0.1378, 0.0910, 0.1170, 0.1076, 0.0868, 0.0999, 0.1307,
        0.0892], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,460][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0718, 0.0665, 0.0573, 0.0273, 0.1084, 0.2888, 0.1343, 0.0548, 0.1045,
        0.0863], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,461][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0071, 0.0183, 0.0380, 0.0801, 0.0553, 0.1221, 0.1935, 0.0840, 0.0639,
        0.1541, 0.1835], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,462][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([9.9922e-01, 1.7356e-04, 2.5374e-05, 1.5791e-04, 4.9275e-06, 3.7161e-05,
        1.5795e-04, 3.5198e-05, 1.0196e-05, 1.1509e-04, 6.0212e-05],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,464][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0729, 0.1028, 0.1063, 0.0755, 0.1227, 0.0856, 0.0788, 0.0974, 0.1381,
        0.0525, 0.0673], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,466][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5295, 0.1098, 0.0625, 0.0471, 0.0321, 0.0377, 0.0383, 0.0369, 0.0289,
        0.0334, 0.0437], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,467][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0910, 0.0909, 0.0909, 0.0909, 0.0909, 0.0909, 0.0910, 0.0909, 0.0910,
        0.0909, 0.0909], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,468][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2360, 0.2198, 0.0869, 0.1170, 0.0236, 0.0544, 0.0539, 0.0491, 0.0346,
        0.0759, 0.0486], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,469][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1569, 0.0126, 0.0330, 0.0072, 0.0587, 0.4630, 0.1442, 0.0416, 0.0496,
        0.0255, 0.0076], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,469][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0457, 0.0687, 0.1428, 0.0797, 0.0643, 0.0860, 0.1194, 0.0915, 0.1196,
        0.1076, 0.0748], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,470][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([4.6087e-02, 1.2529e-04, 2.9594e-03, 5.9385e-04, 2.4176e-01, 1.5943e-04,
        2.3905e-05, 6.9336e-01, 1.4035e-02, 2.4103e-05, 8.7206e-04],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,470][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0025, 0.4241, 0.0277, 0.0179, 0.0411, 0.0253, 0.2319, 0.0031, 0.0011,
        0.2129, 0.0123], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,470][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0330, 0.0938, 0.1266, 0.0839, 0.1081, 0.0986, 0.0790, 0.0920, 0.1211,
        0.0814, 0.0824], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,471][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0258, 0.0373, 0.0530, 0.0268, 0.0869, 0.3501, 0.1066, 0.0660, 0.1345,
        0.0700, 0.0431], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,472][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0042, 0.0123, 0.0273, 0.0717, 0.0361, 0.1142, 0.2119, 0.0781, 0.0485,
        0.1605, 0.2033, 0.0319], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,473][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([9.9956e-01, 9.4437e-05, 1.3944e-05, 8.9339e-05, 2.8925e-06, 1.8890e-05,
        8.4249e-05, 2.0172e-05, 5.7798e-06, 6.9047e-05, 3.9922e-05, 5.0526e-06],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,475][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0805, 0.1273, 0.0985, 0.0666, 0.0984, 0.0747, 0.0748, 0.0925, 0.1081,
        0.0509, 0.0548, 0.0730], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,476][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.4235, 0.1322, 0.0444, 0.0626, 0.0225, 0.0489, 0.0524, 0.0505, 0.0268,
        0.0444, 0.0581, 0.0335], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,478][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0835, 0.0833, 0.0833, 0.0833, 0.0833, 0.0833, 0.0834, 0.0833, 0.0834,
        0.0833, 0.0834, 0.0833], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,479][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.2048, 0.2171, 0.0798, 0.1166, 0.0236, 0.0522, 0.0509, 0.0479, 0.0349,
        0.0818, 0.0543, 0.0361], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,479][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1298, 0.0427, 0.0052, 0.0669, 0.0020, 0.1772, 0.0508, 0.1747, 0.0077,
        0.1437, 0.0763, 0.1230], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,479][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0352, 0.0605, 0.1519, 0.0582, 0.0592, 0.1082, 0.0959, 0.0870, 0.1467,
        0.0744, 0.0484, 0.0744], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,480][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([3.0570e-03, 1.1831e-05, 1.3588e-03, 2.6193e-05, 2.5639e-01, 1.6606e-05,
        3.8526e-06, 7.1973e-01, 1.7742e-02, 1.2718e-06, 3.7725e-05, 1.6242e-03],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,480][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0020, 0.2550, 0.0227, 0.0056, 0.0189, 0.2497, 0.2670, 0.0013, 0.0007,
        0.1685, 0.0034, 0.0052], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,481][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0314, 0.0897, 0.1127, 0.0768, 0.0950, 0.0873, 0.0739, 0.0805, 0.1063,
        0.0746, 0.0738, 0.0981], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,481][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0159, 0.0340, 0.0247, 0.0317, 0.0269, 0.2961, 0.1094, 0.1574, 0.1810,
        0.0504, 0.0293, 0.0433], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,482][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0022, 0.0082, 0.0170, 0.0665, 0.0257, 0.1200, 0.2286, 0.0738, 0.0388,
        0.1530, 0.2229, 0.0250, 0.0182], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,483][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([9.9984e-01, 2.9125e-05, 4.7437e-06, 2.9060e-05, 1.0396e-06, 6.5089e-06,
        3.0216e-05, 7.6755e-06, 2.1728e-06, 3.0495e-05, 1.9001e-05, 2.5905e-06,
        1.3659e-06], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,485][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0603, 0.1249, 0.0781, 0.0684, 0.0851, 0.0779, 0.0631, 0.0818, 0.1033,
        0.0498, 0.0561, 0.0765, 0.0748], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,486][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.2813, 0.1165, 0.0447, 0.0746, 0.0263, 0.0689, 0.0756, 0.0656, 0.0334,
        0.0639, 0.0842, 0.0447, 0.0203], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,488][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0770, 0.0769, 0.0769, 0.0769, 0.0769, 0.0769, 0.0770, 0.0769, 0.0770,
        0.0769, 0.0769, 0.0769, 0.0768], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,489][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.2112, 0.2232, 0.0772, 0.1187, 0.0228, 0.0487, 0.0460, 0.0455, 0.0341,
        0.0753, 0.0489, 0.0328, 0.0157], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,489][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([1.5529e-02, 4.9691e-02, 4.9631e-03, 6.4410e-02, 2.7660e-01, 2.6734e-02,
        6.5272e-02, 2.1254e-04, 3.7518e-03, 1.1898e-01, 6.9540e-02, 1.1901e-02,
        2.9241e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,490][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0274, 0.0830, 0.1365, 0.0666, 0.0308, 0.0940, 0.0959, 0.0678, 0.1648,
        0.0764, 0.0504, 0.0812, 0.0250], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,490][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([4.8024e-03, 1.7084e-05, 1.5170e-03, 5.2956e-05, 2.4286e-01, 1.9740e-05,
        4.6158e-06, 5.0289e-01, 1.4148e-02, 2.0565e-06, 7.5877e-05, 2.2632e-03,
        2.3135e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,491][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0040, 0.2811, 0.0105, 0.0136, 0.0039, 0.0528, 0.3978, 0.0061, 0.0018,
        0.2127, 0.0088, 0.0039, 0.0030], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,491][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0306, 0.0832, 0.1015, 0.0729, 0.0809, 0.0810, 0.0675, 0.0738, 0.0955,
        0.0705, 0.0709, 0.0900, 0.0816], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,491][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0331, 0.0653, 0.0221, 0.0292, 0.1575, 0.1793, 0.1761, 0.0222, 0.0493,
        0.1313, 0.0606, 0.0047, 0.0694], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,493][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0042, 0.0125, 0.0274, 0.0653, 0.0375, 0.1041, 0.1854, 0.0750, 0.0481,
        0.1433, 0.1724, 0.0315, 0.0312, 0.0620], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,494][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([9.9939e-01, 1.2463e-04, 1.8421e-05, 1.3033e-04, 3.0957e-06, 2.7861e-05,
        1.1620e-04, 2.6088e-05, 7.0602e-06, 8.3935e-05, 4.8268e-05, 6.2484e-06,
        2.7456e-06, 1.4056e-05], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,496][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0559, 0.0997, 0.0875, 0.0506, 0.0950, 0.0686, 0.0634, 0.0718, 0.0995,
        0.0440, 0.0431, 0.0651, 0.0851, 0.0705], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,497][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.4188, 0.0990, 0.0550, 0.0489, 0.0304, 0.0434, 0.0438, 0.0407, 0.0306,
        0.0390, 0.0519, 0.0337, 0.0289, 0.0360], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,499][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0715, 0.0714, 0.0714, 0.0714, 0.0714, 0.0714, 0.0715, 0.0714, 0.0715,
        0.0714, 0.0714, 0.0714, 0.0713, 0.0714], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,499][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.2059, 0.2155, 0.0814, 0.1100, 0.0219, 0.0495, 0.0462, 0.0462, 0.0333,
        0.0738, 0.0454, 0.0309, 0.0148, 0.0253], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,500][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1376, 0.0082, 0.0062, 0.0171, 0.0714, 0.0752, 0.0034, 0.0017, 0.2833,
        0.0110, 0.0217, 0.0596, 0.0731, 0.2304], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,500][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0325, 0.0531, 0.1481, 0.0574, 0.0648, 0.0697, 0.0696, 0.0819, 0.0921,
        0.0645, 0.0478, 0.0740, 0.0509, 0.0936], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,500][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([3.4303e-02, 6.2424e-05, 3.2722e-03, 1.6142e-04, 2.5835e-01, 1.5051e-04,
        2.3520e-05, 4.3007e-01, 2.2555e-02, 8.3764e-06, 2.1961e-04, 3.0010e-03,
        2.4389e-01, 3.9360e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,501][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0036, 0.2075, 0.0269, 0.0026, 0.0610, 0.1053, 0.2088, 0.0028, 0.0058,
        0.0907, 0.0016, 0.0047, 0.0492, 0.2294], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,501][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0242, 0.0725, 0.0954, 0.0632, 0.0797, 0.0745, 0.0600, 0.0686, 0.0908,
        0.0617, 0.0617, 0.0867, 0.0801, 0.0810], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,502][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0644, 0.0523, 0.0104, 0.0262, 0.0316, 0.2829, 0.1472, 0.0556, 0.1729,
        0.0604, 0.0338, 0.0035, 0.0188, 0.0401], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,503][circuit_model.py][line:2332][INFO] ##1-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0054, 0.0139, 0.0313, 0.0613, 0.0428, 0.0903, 0.1453, 0.0675, 0.0506,
        0.1190, 0.1382, 0.0328, 0.0372, 0.0610, 0.1035], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,504][circuit_model.py][line:2335][INFO] ##1-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.9880e-01, 2.2252e-04, 3.4696e-05, 2.3964e-04, 7.0544e-06, 5.6742e-05,
        2.2073e-04, 5.1487e-05, 1.5443e-05, 1.5707e-04, 9.0391e-05, 1.2000e-05,
        6.1574e-06, 3.0338e-05, 5.4031e-05], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,506][circuit_model.py][line:2338][INFO] ##1-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0509, 0.0799, 0.0768, 0.0445, 0.0864, 0.0628, 0.0611, 0.0842, 0.0991,
        0.0387, 0.0386, 0.0748, 0.0786, 0.0604, 0.0634], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,508][circuit_model.py][line:2341][INFO] ##1-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.4704, 0.0972, 0.0526, 0.0420, 0.0270, 0.0337, 0.0347, 0.0338, 0.0253,
        0.0303, 0.0402, 0.0290, 0.0244, 0.0251, 0.0342], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,509][circuit_model.py][line:2344][INFO] ##1-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0668, 0.0666, 0.0666, 0.0666, 0.0666, 0.0666, 0.0667, 0.0666, 0.0667,
        0.0666, 0.0667, 0.0667, 0.0666, 0.0667, 0.0667], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,510][circuit_model.py][line:2347][INFO] ##1-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2122, 0.2097, 0.0730, 0.1042, 0.0227, 0.0448, 0.0438, 0.0414, 0.0313,
        0.0631, 0.0419, 0.0305, 0.0154, 0.0219, 0.0442], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,510][circuit_model.py][line:2350][INFO] ##1-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.4583, 0.0018, 0.0069, 0.0065, 0.0047, 0.1087, 0.0563, 0.0152, 0.0089,
        0.0040, 0.0085, 0.0338, 0.0052, 0.2781, 0.0030], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,511][circuit_model.py][line:2353][INFO] ##1-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0339, 0.0494, 0.1078, 0.0580, 0.0548, 0.0616, 0.0875, 0.0654, 0.1019,
        0.0784, 0.0550, 0.0629, 0.0438, 0.0822, 0.0575], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,511][circuit_model.py][line:2356][INFO] ##1-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([2.0933e-02, 4.7135e-05, 1.9003e-03, 1.2391e-04, 1.8256e-01, 8.5917e-05,
        1.2575e-05, 5.9824e-01, 9.5083e-03, 7.0549e-06, 1.7556e-04, 4.5232e-03,
        1.6645e-01, 1.8450e-03, 1.3588e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,511][circuit_model.py][line:2359][INFO] ##1-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0021, 0.2643, 0.0127, 0.0067, 0.0187, 0.0335, 0.3416, 0.0032, 0.0005,
        0.1644, 0.0042, 0.0047, 0.0143, 0.0325, 0.0966], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,512][circuit_model.py][line:2362][INFO] ##1-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0229, 0.0681, 0.0915, 0.0588, 0.0755, 0.0695, 0.0567, 0.0643, 0.0858,
        0.0583, 0.0573, 0.0804, 0.0760, 0.0764, 0.0585], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,514][circuit_model.py][line:2365][INFO] ##1-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0550, 0.0448, 0.0251, 0.0258, 0.0531, 0.3047, 0.1264, 0.0835, 0.1090,
        0.0539, 0.0318, 0.0058, 0.0451, 0.0167, 0.0192], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,515][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:16,517][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[16806],
        [12303],
        [  652],
        [22310],
        [16468],
        [16535],
        [24266],
        [24976],
        [20409],
        [23398],
        [25463],
        [26243],
        [25707],
        [14687],
        [19748]], device='cuda:0')
[2024-07-24 10:20:16,518][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[36337],
        [19230],
        [    2],
        [29838],
        [31787],
        [25595],
        [31753],
        [44943],
        [25530],
        [30729],
        [31398],
        [33091],
        [35161],
        [ 5239],
        [29343]], device='cuda:0')
[2024-07-24 10:20:16,520][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[19948],
        [23745],
        [25824],
        [29957],
        [30178],
        [22942],
        [21577],
        [22039],
        [21844],
        [24888],
        [24763],
        [22639],
        [26428],
        [23236],
        [22330]], device='cuda:0')
[2024-07-24 10:20:16,521][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[33933],
        [36728],
        [37366],
        [14301],
        [28273],
        [25059],
        [26232],
        [28153],
        [35634],
        [32996],
        [25185],
        [35466],
        [37482],
        [41854],
        [27375]], device='cuda:0')
[2024-07-24 10:20:16,522][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[26260],
        [26612],
        [28255],
        [17836],
        [ 8714],
        [ 9730],
        [ 8224],
        [ 5480],
        [ 6224],
        [ 4429],
        [ 2584],
        [ 1677],
        [ 1077],
        [  438],
        [  451]], device='cuda:0')
[2024-07-24 10:20:16,523][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[21120],
        [40428],
        [37553],
        [39745],
        [39834],
        [40602],
        [40726],
        [40218],
        [40819],
        [42126],
        [43007],
        [42939],
        [42794],
        [42781],
        [43004]], device='cuda:0')
[2024-07-24 10:20:16,525][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[3535],
        [3064],
        [2672],
        [2736],
        [2737],
        [2680],
        [2732],
        [2583],
        [2530],
        [2473],
        [2511],
        [2491],
        [2603],
        [2574],
        [2657]], device='cuda:0')
[2024-07-24 10:20:16,526][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[14933],
        [15653],
        [15772],
        [20446],
        [30128],
        [18785],
        [19143],
        [19314],
        [19597],
        [16593],
        [17950],
        [21803],
        [30506],
        [15701],
        [15212]], device='cuda:0')
[2024-07-24 10:20:16,528][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[40437],
        [40263],
        [31648],
        [39094],
        [40988],
        [39983],
        [39961],
        [41487],
        [41326],
        [41163],
        [42013],
        [43044],
        [42977],
        [41647],
        [41796]], device='cuda:0')
[2024-07-24 10:20:16,529][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[25625],
        [27982],
        [33231],
        [42289],
        [42232],
        [40742],
        [42192],
        [41203],
        [43139],
        [43792],
        [44872],
        [45306],
        [45397],
        [40510],
        [42046]], device='cuda:0')
[2024-07-24 10:20:16,531][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11165],
        [10650],
        [10435],
        [10365],
        [ 9614],
        [ 9697],
        [ 9260],
        [ 9219],
        [ 8731],
        [ 8792],
        [ 8589],
        [ 8616],
        [ 8179],
        [ 8599],
        [ 8528]], device='cuda:0')
[2024-07-24 10:20:16,532][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[6467],
        [5402],
        [4492],
        [4406],
        [3635],
        [3961],
        [3894],
        [3587],
        [3381],
        [3623],
        [3618],
        [3334],
        [3095],
        [3258],
        [3343]], device='cuda:0')
[2024-07-24 10:20:16,533][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[1445],
        [1758],
        [1844],
        [1757],
        [1780],
        [1822],
        [1674],
        [1563],
        [1544],
        [1559],
        [1550],
        [1423],
        [1475],
        [1400],
        [1401]], device='cuda:0')
[2024-07-24 10:20:16,534][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[ 7762],
        [ 5420],
        [37314],
        [ 9772],
        [41007],
        [19415],
        [30476],
        [24698],
        [10822],
        [ 6982],
        [10916],
        [17503],
        [43440],
        [23119],
        [15210]], device='cuda:0')
[2024-07-24 10:20:16,535][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[18346],
        [17634],
        [16788],
        [12753],
        [10795],
        [29247],
        [32002],
        [33909],
        [15011],
        [18317],
        [20909],
        [40469],
        [14348],
        [24598],
        [15084]], device='cuda:0')
[2024-07-24 10:20:16,537][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[15522],
        [24976],
        [22748],
        [24977],
        [25715],
        [26057],
        [27132],
        [28054],
        [28306],
        [28296],
        [27888],
        [28066],
        [27959],
        [28312],
        [28498]], device='cuda:0')
[2024-07-24 10:20:16,538][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[2053],
        [2052],
        [2053],
        [2052],
        [2053],
        [2053],
        [2053],
        [2053],
        [2053],
        [2052],
        [2052],
        [2053],
        [2053],
        [2053],
        [2052]], device='cuda:0')
[2024-07-24 10:20:16,540][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[1675],
        [1713],
        [1857],
        [1938],
        [1960],
        [2076],
        [2068],
        [2083],
        [2202],
        [2218],
        [2211],
        [2151],
        [2155],
        [2068],
        [2133]], device='cuda:0')
[2024-07-24 10:20:16,541][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[2633],
        [1886],
        [1535],
        [1523],
        [1543],
        [1513],
        [1498],
        [1501],
        [1613],
        [1552],
        [1540],
        [1838],
        [2581],
        [1874],
        [1714]], device='cuda:0')
[2024-07-24 10:20:16,542][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[5735],
        [5729],
        [5731],
        [5735],
        [5735],
        [5732],
        [5737],
        [5731],
        [5734],
        [5737],
        [5735],
        [5733],
        [5734],
        [5734],
        [5733]], device='cuda:0')
[2024-07-24 10:20:16,543][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[21233],
        [21579],
        [22527],
        [23564],
        [23280],
        [23663],
        [23745],
        [24046],
        [24131],
        [24496],
        [24666],
        [24877],
        [24704],
        [24775],
        [24748]], device='cuda:0')
[2024-07-24 10:20:16,544][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[16367],
        [16601],
        [23000],
        [14234],
        [28798],
        [25103],
        [28642],
        [23104],
        [14325],
        [24774],
        [22848],
        [18336],
        [27346],
        [24963],
        [19413]], device='cuda:0')
[2024-07-24 10:20:16,546][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[35175],
        [33771],
        [43337],
        [42577],
        [41804],
        [41725],
        [40273],
        [40192],
        [38995],
        [36984],
        [36468],
        [36727],
        [36467],
        [36914],
        [35837]], device='cuda:0')
[2024-07-24 10:20:16,547][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[16154],
        [16181],
        [14894],
        [15755],
        [27467],
        [27137],
        [24131],
        [ 8214],
        [ 8544],
        [ 7725],
        [ 7250],
        [ 7527],
        [10983],
        [12195],
        [ 8329]], device='cuda:0')
[2024-07-24 10:20:16,549][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[10116],
        [ 8340],
        [ 8523],
        [ 8610],
        [ 8634],
        [10270],
        [12194],
        [10768],
        [12947],
        [11652],
        [12548],
        [13474],
        [13944],
        [11055],
        [13522]], device='cuda:0')
[2024-07-24 10:20:16,550][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[9913],
        [6931],
        [7757],
        [7574],
        [7554],
        [7537],
        [7469],
        [7630],
        [7642],
        [7543],
        [7524],
        [7646],
        [7645],
        [7722],
        [7690]], device='cuda:0')
[2024-07-24 10:20:16,552][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[33510],
        [31783],
        [14336],
        [12719],
        [16089],
        [20287],
        [11747],
        [15498],
        [11339],
        [11592],
        [10934],
        [10919],
        [11137],
        [11272],
        [11387]], device='cuda:0')
[2024-07-24 10:20:16,553][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[48881],
        [49404],
        [49479],
        [49606],
        [48494],
        [48849],
        [48918],
        [49334],
        [49513],
        [49332],
        [49391],
        [49205],
        [48540],
        [49293],
        [49354]], device='cuda:0')
[2024-07-24 10:20:16,554][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[13270],
        [21726],
        [26212],
        [28929],
        [18548],
        [ 9854],
        [11502],
        [ 4292],
        [19985],
        [25404],
        [23118],
        [ 2647],
        [12470],
        [15850],
        [22008]], device='cuda:0')
[2024-07-24 10:20:16,555][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918],
        [32918]], device='cuda:0')
[2024-07-24 10:20:16,583][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:16,584][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,584][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,584][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,585][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,585][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,585][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,585][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,586][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,586][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,587][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,588][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,590][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,591][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1035, 0.8965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,592][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.8635e-04, 9.9981e-01], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,593][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,594][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0677, 0.9323], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,594][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.8190, 0.1810], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,595][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([1.0000e+00, 2.8019e-12], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,595][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6793, 0.3207], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,595][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5696, 0.4304], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,596][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9953, 0.0047], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,596][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9975, 0.0025], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,596][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8728, 0.1272], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,597][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.4208, 0.5792], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,597][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.0348, 0.4181, 0.5471], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,597][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([1.8445e-04, 9.4830e-01, 5.1516e-02], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,598][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([6.9331e-06, 2.9677e-01, 7.0323e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,598][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.0027, 0.3349, 0.6625], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,598][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.2059, 0.7651, 0.0290], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,599][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([1.0000e+00, 9.7694e-13, 3.3796e-10], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,599][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.0815, 0.2012, 0.7174], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,599][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.3183, 0.2530, 0.4288], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,600][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.9924, 0.0052, 0.0024], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,600][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([9.9460e-01, 4.8977e-03, 5.0549e-04], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,600][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.7923, 0.1005, 0.1072], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,601][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.1815, 0.2743, 0.5442], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,601][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0377, 0.2363, 0.3312, 0.3947], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,601][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.5341e-05, 2.6003e-01, 2.7485e-02, 7.1247e-01], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,602][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.0181e-06, 8.5508e-03, 2.0681e-01, 7.8464e-01], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,602][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0007, 0.0541, 0.3210, 0.6241], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,602][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0652, 0.7431, 0.1645, 0.0272], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,603][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([1.0000e+00, 1.5295e-12, 1.9404e-10, 2.1061e-07], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,603][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0768, 0.0896, 0.2819, 0.5518], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,604][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1690, 0.1115, 0.2962, 0.4233], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,606][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.9840, 0.0054, 0.0025, 0.0081], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,607][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([9.9359e-01, 5.3926e-04, 3.9972e-03, 1.8688e-03], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,608][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.6936, 0.0899, 0.1323, 0.0842], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,609][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1538, 0.2187, 0.3927, 0.2348], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,609][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0205, 0.1649, 0.2232, 0.3332, 0.2581], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,609][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0008, 0.4579, 0.0191, 0.5040, 0.0182], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,610][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([9.0082e-08, 4.3030e-04, 6.7014e-03, 1.3920e-01, 8.5367e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,610][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([8.8875e-05, 8.3673e-03, 4.7983e-02, 2.3060e-01, 7.1296e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,610][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0320, 0.3994, 0.3103, 0.2527, 0.0057], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,611][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([1.0000e+00, 1.1464e-13, 1.6422e-10, 9.5031e-09, 1.6918e-09],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,611][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0281, 0.0458, 0.1391, 0.3100, 0.4769], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,611][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.1091, 0.0949, 0.1474, 0.4035, 0.2450], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,612][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.9849, 0.0038, 0.0017, 0.0058, 0.0038], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,614][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.4135, 0.0106, 0.0079, 0.5479, 0.0201], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,615][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.6903, 0.0865, 0.0868, 0.0655, 0.0710], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,617][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0845, 0.1332, 0.2700, 0.1482, 0.3641], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,618][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0142, 0.0991, 0.1513, 0.1904, 0.2033, 0.3417], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,619][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ had] are: tensor([1.6573e-04, 1.6059e-01, 1.0408e-02, 5.0010e-01, 8.2796e-03, 3.2045e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,619][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ had] are: tensor([4.7412e-09, 4.1288e-05, 1.0369e-03, 3.1254e-02, 8.8844e-01, 7.9231e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,620][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ had] are: tensor([4.2207e-05, 4.6928e-03, 2.0471e-02, 9.4472e-02, 7.4641e-01, 1.3391e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,620][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.3792, 0.2125, 0.0098, 0.3178, 0.0448, 0.0358], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,621][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ had] are: tensor([9.9999e-01, 2.9367e-11, 4.5017e-09, 4.2750e-06, 1.7637e-07, 6.9826e-06],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,621][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0185, 0.0395, 0.0803, 0.2117, 0.4454, 0.2046], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,621][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0840, 0.0914, 0.1476, 0.3059, 0.2431, 0.1280], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,622][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.9662, 0.0052, 0.0023, 0.0078, 0.0054, 0.0132], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,622][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.6186, 0.0025, 0.0037, 0.1230, 0.2247, 0.0275], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,622][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.4751, 0.1060, 0.1353, 0.0880, 0.1163, 0.0792], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,623][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0922, 0.1305, 0.2326, 0.1380, 0.2951, 0.1116], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,625][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0128, 0.0871, 0.1204, 0.1448, 0.1501, 0.2636, 0.2213],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,626][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ a] are: tensor([1.3143e-04, 1.4362e-01, 7.0406e-03, 4.5853e-01, 5.9656e-03, 3.4193e-01,
        4.2785e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,627][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ a] are: tensor([6.1819e-09, 1.2858e-05, 2.3915e-04, 1.6442e-02, 3.2758e-01, 4.7939e-01,
        1.7633e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,628][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ a] are: tensor([3.8217e-05, 1.9681e-03, 9.0472e-03, 5.1675e-02, 5.3967e-01, 1.2924e-01,
        2.6836e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,629][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1881, 0.2371, 0.0061, 0.2888, 0.1200, 0.1317, 0.0282],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,630][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ a] are: tensor([9.9988e-01, 4.0136e-12, 8.8233e-10, 6.2728e-07, 3.2942e-08, 1.3074e-06,
        1.1831e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,631][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0129, 0.0206, 0.0560, 0.1270, 0.3189, 0.1369, 0.3277],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,631][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0798, 0.0677, 0.1224, 0.2508, 0.2252, 0.0948, 0.1593],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,631][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.9417, 0.0049, 0.0023, 0.0074, 0.0052, 0.0127, 0.0259],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,632][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.5655, 0.0016, 0.0023, 0.0480, 0.2048, 0.1158, 0.0619],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,632][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.4678, 0.0763, 0.1035, 0.0802, 0.0880, 0.0702, 0.1140],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,632][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0799, 0.1141, 0.2030, 0.1216, 0.2597, 0.0990, 0.1227],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,633][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0093, 0.0642, 0.0861, 0.1163, 0.1111, 0.2096, 0.2102, 0.1932],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,633][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ long] are: tensor([1.4343e-04, 1.3882e-01, 6.3772e-03, 4.4669e-01, 5.2389e-03, 3.4072e-01,
        4.9779e-02, 1.2223e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,635][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ long] are: tensor([7.9711e-10, 7.3939e-07, 2.4791e-05, 5.2323e-04, 2.5211e-02, 4.7306e-02,
        2.0772e-01, 7.1921e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,635][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ long] are: tensor([4.3277e-06, 2.7943e-04, 2.4983e-03, 1.1318e-02, 1.1266e-01, 3.8513e-02,
        4.3869e-01, 3.9604e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,637][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0811, 0.1564, 0.0063, 0.3152, 0.0217, 0.1643, 0.2510, 0.0039],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,638][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ long] are: tensor([9.9999e-01, 2.0104e-13, 2.3622e-10, 2.4257e-08, 4.1089e-09, 5.7126e-08,
        4.5396e-06, 4.7947e-07], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,640][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0106, 0.0169, 0.0262, 0.0799, 0.1361, 0.1012, 0.2290, 0.4003],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,640][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0713, 0.0788, 0.0976, 0.2728, 0.1800, 0.0826, 0.1252, 0.0916],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,641][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.9406, 0.0041, 0.0018, 0.0059, 0.0041, 0.0103, 0.0232, 0.0100],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,641][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0517, 0.0012, 0.0018, 0.0945, 0.0254, 0.3624, 0.3847, 0.0784],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,642][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.4369, 0.0784, 0.0844, 0.0717, 0.0776, 0.0654, 0.0915, 0.0941],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,642][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0661, 0.0972, 0.1620, 0.1029, 0.2030, 0.0861, 0.1037, 0.1791],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,642][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0050, 0.0424, 0.0560, 0.0882, 0.0773, 0.1926, 0.2006, 0.1720, 0.1659],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,643][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([3.9571e-05, 1.4125e-01, 3.6499e-03, 5.0391e-01, 2.4285e-03, 2.9689e-01,
        3.9433e-02, 9.3409e-03, 3.0566e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,643][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([7.5077e-11, 9.4374e-08, 1.5621e-06, 7.1611e-05, 3.2272e-03, 2.7900e-03,
        1.6765e-02, 4.6913e-01, 5.0801e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,644][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([2.8017e-06, 2.1039e-04, 1.1858e-03, 6.6934e-03, 6.0816e-02, 3.6231e-02,
        1.3998e-01, 4.4101e-01, 3.1387e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,646][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0128, 0.1014, 0.0568, 0.1420, 0.2763, 0.2729, 0.1121, 0.0227, 0.0032],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,647][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([9.9958e-01, 1.2680e-13, 9.8241e-11, 1.0793e-08, 1.5479e-09, 1.8127e-08,
        1.3312e-06, 1.4285e-07, 4.2075e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,648][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0080, 0.0086, 0.0215, 0.0528, 0.1057, 0.0544, 0.1783, 0.3216, 0.2492],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,650][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0658, 0.0605, 0.0919, 0.2460, 0.1433, 0.0889, 0.1344, 0.0854, 0.0838],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,651][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.9029, 0.0037, 0.0017, 0.0053, 0.0035, 0.0089, 0.0185, 0.0087, 0.0468],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,651][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0345, 0.0018, 0.0030, 0.0529, 0.0716, 0.2653, 0.4136, 0.1343, 0.0229],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,651][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.3194, 0.0766, 0.0870, 0.0654, 0.0857, 0.0664, 0.0910, 0.0904, 0.1180],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,652][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0503, 0.0760, 0.1355, 0.0802, 0.1730, 0.0663, 0.0806, 0.1482, 0.1898],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,652][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0082, 0.0436, 0.0596, 0.0760, 0.0749, 0.1489, 0.1346, 0.1468, 0.1660,
        0.1416], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,653][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.5317e-04, 2.0357e-01, 8.3635e-03, 4.4036e-01, 5.7068e-03, 2.6309e-01,
        3.8669e-02, 1.1742e-02, 5.1204e-03, 2.3228e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,653][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [,] are: tensor([7.3422e-11, 3.0743e-09, 5.5743e-07, 2.3025e-05, 1.0855e-03, 5.6570e-04,
        2.5501e-03, 8.1593e-02, 2.0061e-01, 7.1357e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,653][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.6361e-06, 2.9075e-05, 3.9942e-04, 1.9865e-03, 1.8270e-02, 1.0348e-02,
        5.5649e-02, 1.5394e-01, 1.8476e-01, 5.7462e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,655][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1173, 0.0336, 0.1682, 0.0671, 0.3036, 0.0230, 0.2156, 0.0088, 0.0352,
        0.0276], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,656][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [,] are: tensor([9.9618e-01, 3.3458e-14, 1.0407e-11, 6.5565e-09, 4.2070e-10, 1.3648e-08,
        1.2722e-06, 8.2569e-08, 3.7462e-04, 3.4433e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,658][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0057, 0.0060, 0.0174, 0.0544, 0.0818, 0.0622, 0.1266, 0.2335, 0.1950,
        0.2174], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,659][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0524, 0.0382, 0.0776, 0.1591, 0.1342, 0.0643, 0.0941, 0.0588, 0.0749,
        0.2463], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,661][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8866, 0.0032, 0.0014, 0.0048, 0.0034, 0.0088, 0.0187, 0.0083, 0.0518,
        0.0130], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,661][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [,] are: tensor([6.7920e-02, 6.1343e-06, 4.6148e-05, 2.7446e-03, 4.4291e-03, 1.3448e-02,
        1.7956e-01, 1.1022e-01, 5.0260e-01, 1.1902e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,661][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4068, 0.0486, 0.0716, 0.0488, 0.0630, 0.0478, 0.0730, 0.0746, 0.1018,
        0.0639], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,662][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0479, 0.0678, 0.1213, 0.0711, 0.1563, 0.0582, 0.0721, 0.1326, 0.1728,
        0.0999], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,662][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0073, 0.0406, 0.0544, 0.0639, 0.0669, 0.1235, 0.1038, 0.1289, 0.1496,
        0.1213, 0.1397], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,663][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ and] are: tensor([7.6394e-05, 1.4396e-01, 6.0921e-03, 4.5730e-01, 4.5281e-03, 2.8768e-01,
        3.9520e-02, 1.1863e-02, 4.7957e-03, 2.1672e-02, 2.2505e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,663][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.9542e-11, 7.8550e-10, 4.7533e-08, 1.0123e-07, 8.2716e-05, 1.4708e-05,
        1.1804e-04, 2.2084e-03, 8.0246e-03, 1.6994e-01, 8.1962e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,663][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.4846e-07, 1.1003e-05, 9.3448e-05, 1.4596e-04, 5.2918e-03, 1.9826e-03,
        1.3133e-02, 3.2232e-02, 4.9247e-02, 2.3080e-01, 6.6707e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,665][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0134, 0.2916, 0.0673, 0.0106, 0.3314, 0.0080, 0.0992, 0.0014, 0.0010,
        0.1701, 0.0060], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,666][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ and] are: tensor([9.8792e-01, 3.0333e-14, 1.2183e-11, 4.3330e-09, 3.6980e-10, 8.6189e-09,
        6.9997e-07, 5.3990e-08, 2.4328e-04, 2.0884e-03, 9.7457e-03],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,668][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0042, 0.0049, 0.0118, 0.0253, 0.0477, 0.0362, 0.0694, 0.1109, 0.1111,
        0.1294, 0.4492], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,669][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0399, 0.0276, 0.0726, 0.1126, 0.1130, 0.0508, 0.0733, 0.0399, 0.0616,
        0.1815, 0.2273], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,671][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.8322, 0.0044, 0.0021, 0.0066, 0.0047, 0.0115, 0.0230, 0.0107, 0.0598,
        0.0167, 0.0282], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,671][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ and] are: tensor([2.1273e-01, 2.1455e-05, 1.9944e-04, 1.9390e-04, 1.2828e-02, 1.5055e-02,
        4.6420e-02, 1.2455e-01, 3.8147e-01, 1.8935e-01, 1.7194e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,672][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.3562, 0.0454, 0.0701, 0.0451, 0.0613, 0.0476, 0.0715, 0.0659, 0.0989,
        0.0598, 0.0781], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,672][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0428, 0.0618, 0.1139, 0.0652, 0.1482, 0.0528, 0.0658, 0.1216, 0.1617,
        0.0924, 0.0740], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,672][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0045, 0.0301, 0.0387, 0.0558, 0.0489, 0.1177, 0.1062, 0.1138, 0.1259,
        0.1154, 0.1465, 0.0965], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,673][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([2.8793e-04, 9.6219e-02, 9.0038e-03, 3.4091e-01, 8.6371e-03, 3.4884e-01,
        6.4535e-02, 2.5839e-02, 9.7981e-03, 3.8120e-02, 4.2557e-02, 1.5253e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,673][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([6.3158e-12, 1.7876e-10, 3.2990e-09, 1.2105e-07, 2.5598e-06, 1.8506e-06,
        2.0950e-05, 9.4518e-05, 1.0469e-03, 2.3582e-02, 7.9159e-01, 1.8366e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,674][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([2.9073e-07, 6.8986e-06, 4.3370e-05, 1.1389e-04, 2.7208e-03, 8.8873e-04,
        4.6363e-03, 8.1548e-03, 1.7280e-02, 1.2380e-01, 4.7375e-01, 3.6861e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,675][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([1.5459e-03, 2.2138e-02, 2.5416e-04, 2.1628e-02, 1.0042e-03, 4.3255e-02,
        1.3853e-03, 8.7554e-01, 1.2646e-04, 2.3886e-02, 8.7941e-03, 4.4086e-04],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,676][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([9.8139e-01, 1.3517e-13, 1.4455e-10, 8.8917e-09, 1.7945e-09, 1.4748e-08,
        8.4963e-07, 1.1715e-07, 4.0278e-04, 2.4116e-03, 1.2290e-02, 3.5067e-03],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,678][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0019, 0.0028, 0.0078, 0.0176, 0.0398, 0.0271, 0.0515, 0.0757, 0.0788,
        0.0983, 0.3266, 0.2720], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,679][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0290, 0.0298, 0.0454, 0.1095, 0.0706, 0.0465, 0.0565, 0.0395, 0.0408,
        0.2397, 0.2236, 0.0692], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,681][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.7799, 0.0053, 0.0027, 0.0072, 0.0048, 0.0109, 0.0214, 0.0110, 0.0503,
        0.0170, 0.0285, 0.0610], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,681][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([9.1769e-03, 6.6068e-05, 6.8270e-05, 3.9716e-03, 2.0271e-03, 2.7845e-02,
        3.2798e-02, 4.1596e-02, 7.7699e-02, 4.7435e-01, 3.0612e-01, 2.4290e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,682][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.3602, 0.0424, 0.0514, 0.0327, 0.0408, 0.0380, 0.0532, 0.0516, 0.0918,
        0.0572, 0.0622, 0.1184], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,682][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0368, 0.0547, 0.0989, 0.0584, 0.1271, 0.0477, 0.0585, 0.1080, 0.1385,
        0.0813, 0.0650, 0.1251], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,683][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0033, 0.0245, 0.0325, 0.0491, 0.0378, 0.1168, 0.1048, 0.1025, 0.1113,
        0.1100, 0.1517, 0.0919, 0.0637], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,683][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([2.0765e-04, 2.3405e-01, 6.5536e-03, 2.8797e-01, 5.0765e-03, 3.2940e-01,
        3.6551e-02, 1.7037e-02, 6.1455e-03, 3.1679e-02, 2.6811e-02, 1.3857e-02,
        4.6591e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,683][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([1.3578e-12, 3.3559e-11, 9.3716e-10, 9.7501e-09, 1.5284e-07, 2.8137e-07,
        2.0386e-06, 1.0010e-05, 9.6204e-05, 2.5080e-03, 5.2492e-02, 1.4814e-01,
        7.9675e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,684][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([7.4398e-08, 1.0084e-06, 6.8695e-06, 2.5775e-05, 1.2038e-04, 1.5415e-04,
        1.3006e-03, 3.8091e-03, 7.2542e-03, 2.8635e-02, 1.3263e-01, 2.7310e-01,
        5.5296e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,686][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0126, 0.1785, 0.1183, 0.1152, 0.0025, 0.1497, 0.0782, 0.0009, 0.0460,
        0.1947, 0.0677, 0.0336, 0.0019], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,687][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([9.9910e-01, 1.6966e-15, 5.4806e-12, 1.8761e-10, 5.7289e-11, 4.2002e-10,
        2.7192e-08, 4.3976e-09, 2.0841e-05, 7.7922e-05, 5.0523e-04, 2.8366e-04,
        8.8043e-06], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,689][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0014, 0.0020, 0.0046, 0.0130, 0.0178, 0.0180, 0.0337, 0.0470, 0.0531,
        0.0873, 0.2277, 0.2218, 0.2726], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,690][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0283, 0.0240, 0.0371, 0.1068, 0.0606, 0.0450, 0.0563, 0.0300, 0.0366,
        0.1928, 0.2230, 0.0787, 0.0809], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,691][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.7833, 0.0040, 0.0019, 0.0058, 0.0036, 0.0089, 0.0178, 0.0086, 0.0432,
        0.0135, 0.0232, 0.0513, 0.0349], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,692][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([7.0613e-03, 5.3309e-05, 6.2368e-05, 4.8154e-03, 1.7721e-04, 1.7473e-02,
        5.3050e-02, 2.9268e-02, 1.3944e-01, 3.2757e-01, 3.5171e-01, 6.8162e-02,
        1.1625e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,692][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.3211, 0.0391, 0.0454, 0.0322, 0.0384, 0.0321, 0.0485, 0.0517, 0.0777,
        0.0509, 0.0598, 0.1151, 0.0879], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,692][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0258, 0.0420, 0.0877, 0.0469, 0.1192, 0.0369, 0.0471, 0.0945, 0.1267,
        0.0679, 0.0538, 0.1123, 0.1391], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,693][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0038, 0.0249, 0.0357, 0.0478, 0.0460, 0.0908, 0.0891, 0.0867, 0.0964,
        0.0929, 0.1175, 0.0860, 0.0766, 0.1058], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,693][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ said] are: tensor([4.9467e-05, 1.9738e-01, 3.6948e-03, 4.6835e-01, 2.2199e-03, 2.3688e-01,
        3.2224e-02, 7.3199e-03, 2.3288e-03, 1.9478e-02, 1.9185e-02, 3.7052e-03,
        1.3741e-03, 5.8109e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,694][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ said] are: tensor([1.6484e-13, 2.8453e-12, 2.9550e-11, 1.7384e-09, 6.8829e-08, 8.3833e-08,
        1.5941e-07, 1.5791e-06, 1.7534e-05, 6.7930e-04, 2.1282e-02, 6.2637e-02,
        6.5014e-01, 2.6524e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,694][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ said] are: tensor([5.7376e-08, 7.4321e-07, 2.5161e-06, 1.9627e-05, 1.1651e-04, 2.0259e-05,
        2.6240e-04, 1.1235e-03, 1.8141e-03, 1.7842e-02, 1.0789e-01, 1.6141e-01,
        5.1618e-01, 1.9333e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,696][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ said] are: tensor([5.0157e-01, 1.0144e-01, 2.6812e-03, 4.5480e-02, 7.5954e-03, 6.1439e-02,
        2.6982e-02, 4.0944e-02, 5.2835e-04, 7.6790e-02, 4.2749e-02, 8.5846e-02,
        5.4819e-03, 4.7144e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,697][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ said] are: tensor([9.5651e-01, 5.7203e-14, 3.0696e-11, 6.4227e-09, 7.4922e-10, 1.0233e-08,
        7.8347e-07, 7.1741e-08, 3.0643e-04, 2.4936e-03, 1.2002e-02, 2.2994e-03,
        8.6588e-05, 2.6301e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,698][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0012, 0.0016, 0.0034, 0.0099, 0.0173, 0.0124, 0.0269, 0.0374, 0.0325,
        0.0508, 0.1841, 0.2322, 0.2503, 0.1398], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,700][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0244, 0.0197, 0.0450, 0.0797, 0.0738, 0.0368, 0.0522, 0.0340, 0.0392,
        0.1710, 0.1798, 0.0924, 0.1006, 0.0514], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,701][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.7231, 0.0042, 0.0020, 0.0058, 0.0039, 0.0093, 0.0182, 0.0090, 0.0443,
        0.0138, 0.0230, 0.0518, 0.0354, 0.0561], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,702][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ said] are: tensor([2.8715e-02, 2.6730e-05, 7.8281e-05, 3.9432e-03, 4.7396e-03, 6.1039e-03,
        2.7089e-02, 1.9402e-02, 6.2948e-02, 3.7263e-01, 3.3744e-01, 9.4411e-02,
        3.8417e-02, 4.0616e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,702][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1728, 0.0425, 0.0604, 0.0387, 0.0548, 0.0381, 0.0611, 0.0617, 0.0734,
        0.0584, 0.0664, 0.1107, 0.1022, 0.0589], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,703][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0308, 0.0450, 0.0820, 0.0473, 0.1041, 0.0385, 0.0475, 0.0876, 0.1136,
        0.0658, 0.0523, 0.1022, 0.1194, 0.0638], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,703][circuit_model.py][line:2294][INFO] ##2-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0047, 0.0268, 0.0356, 0.0436, 0.0448, 0.0733, 0.0680, 0.0806, 0.0968,
        0.0801, 0.0926, 0.0786, 0.0720, 0.0969, 0.1056], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,704][circuit_model.py][line:2297][INFO] ##2-th layer ##Weight##: The head2 weight for token [ to] are: tensor([5.8671e-05, 1.4828e-01, 4.9031e-03, 4.6518e-01, 3.2652e-03, 2.6869e-01,
        3.5178e-02, 9.4214e-03, 3.8299e-03, 2.0085e-02, 2.0405e-02, 5.2428e-03,
        2.3597e-03, 7.0359e-03, 6.0742e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,704][circuit_model.py][line:2300][INFO] ##2-th layer ##Weight##: The head3 weight for token [ to] are: tensor([1.4035e-13, 3.8068e-13, 6.3491e-12, 1.6141e-10, 3.4088e-09, 9.1896e-09,
        2.5459e-08, 4.3928e-07, 3.4113e-06, 4.4483e-05, 1.4561e-03, 3.4184e-03,
        2.3265e-02, 3.3137e-01, 6.4045e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,705][circuit_model.py][line:2303][INFO] ##2-th layer ##Weight##: The head4 weight for token [ to] are: tensor([3.7919e-08, 1.9429e-07, 8.3327e-07, 3.0292e-06, 5.4652e-05, 8.2332e-06,
        1.0208e-04, 2.3905e-04, 3.9991e-04, 3.6216e-03, 1.4262e-02, 3.2523e-02,
        2.2340e-01, 3.6204e-01, 3.6334e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,706][circuit_model.py][line:2306][INFO] ##2-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0400, 0.0569, 0.0083, 0.0701, 0.0475, 0.1794, 0.0288, 0.0235, 0.3119,
        0.0668, 0.0405, 0.0151, 0.0364, 0.0652, 0.0096], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,708][circuit_model.py][line:2309][INFO] ##2-th layer ##Weight##: The head6 weight for token [ to] are: tensor([6.0717e-01, 1.0197e-14, 4.8661e-12, 1.2935e-09, 1.3631e-10, 2.1387e-09,
        1.6459e-07, 1.3833e-08, 7.4927e-05, 6.3452e-04, 2.9838e-03, 5.6099e-04,
        1.7795e-05, 6.9534e-03, 3.8160e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,709][circuit_model.py][line:2312][INFO] ##2-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0012, 0.0013, 0.0024, 0.0063, 0.0113, 0.0080, 0.0192, 0.0216, 0.0253,
        0.0372, 0.1058, 0.1143, 0.1329, 0.1393, 0.3736], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,711][circuit_model.py][line:2315][INFO] ##2-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0221, 0.0160, 0.0332, 0.0703, 0.0573, 0.0293, 0.0414, 0.0237, 0.0290,
        0.1327, 0.1505, 0.0919, 0.0784, 0.0573, 0.1669], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,712][circuit_model.py][line:2318][INFO] ##2-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.7021, 0.0033, 0.0016, 0.0049, 0.0034, 0.0081, 0.0161, 0.0077, 0.0411,
        0.0121, 0.0203, 0.0467, 0.0326, 0.0541, 0.0460], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,712][circuit_model.py][line:2321][INFO] ##2-th layer ##Weight##: The head10 weight for token [ to] are: tensor([5.0343e-02, 1.0213e-05, 8.4259e-05, 4.8632e-04, 7.8564e-03, 2.5572e-03,
        3.4766e-02, 5.2361e-02, 1.8433e-01, 1.2666e-01, 7.0744e-02, 1.3032e-01,
        8.8949e-02, 1.6635e-01, 8.4181e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,713][circuit_model.py][line:2324][INFO] ##2-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.2250, 0.0365, 0.0457, 0.0373, 0.0398, 0.0340, 0.0520, 0.0479, 0.0673,
        0.0520, 0.0644, 0.0990, 0.0823, 0.0603, 0.0566], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,713][circuit_model.py][line:2327][INFO] ##2-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0295, 0.0422, 0.0766, 0.0442, 0.0983, 0.0359, 0.0445, 0.0818, 0.1064,
        0.0614, 0.0492, 0.0958, 0.1119, 0.0598, 0.0625], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,742][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:16,744][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,745][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,747][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,747][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,748][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,748][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,748][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,749][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,749][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,749][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,750][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,750][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,751][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4549, 0.5451], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,752][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0093, 0.9907], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,752][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0030, 0.9970], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,753][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5325, 0.4675], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,753][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0763, 0.9237], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,753][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0236, 0.9764], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,754][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3395, 0.6605], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,754][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3061, 0.6939], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,754][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1159, 0.8841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,755][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0037, 0.9963], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,755][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2522, 0.7478], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,764][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.3667, 0.6333], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,766][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.0992, 0.5933, 0.3075], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,767][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([2.2009e-04, 1.2180e-01, 8.7798e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,768][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([6.9331e-06, 2.9677e-01, 7.0323e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,770][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.2580, 0.4999, 0.2421], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,771][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.0084, 0.1768, 0.8148], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,771][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.0014, 0.6222, 0.3764], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,772][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.1132, 0.2612, 0.6256], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,772][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.1984, 0.4808, 0.3209], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,772][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.0047, 0.4013, 0.5940], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,773][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([1.8088e-04, 6.9606e-01, 3.0375e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,773][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.0629, 0.2537, 0.6834], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,773][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.1788, 0.4001, 0.4212], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,774][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0414, 0.1572, 0.2570, 0.5444], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,774][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.3573e-05, 5.8914e-03, 9.9394e-01, 1.2757e-04], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,775][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.0181e-06, 8.5508e-03, 2.0681e-01, 7.8464e-01], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,777][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2137, 0.3508, 0.2933, 0.1422], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,778][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0076, 0.0879, 0.5854, 0.3191], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,779][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([3.6704e-04, 6.8893e-02, 1.2376e-01, 8.0698e-01], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,781][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1001, 0.2043, 0.4101, 0.2854], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,781][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1557, 0.3454, 0.2562, 0.2428], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,782][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0025, 0.1253, 0.2066, 0.6655], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,782][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.5533e-05, 3.9562e-02, 1.7465e-01, 7.8576e-01], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,782][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0542, 0.1816, 0.3889, 0.3753], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,783][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1243, 0.2694, 0.2911, 0.3151], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:16,783][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0207, 0.0674, 0.1739, 0.5173, 0.2207], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,783][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([4.3017e-04, 3.3255e-02, 3.6916e-01, 3.7183e-03, 5.9344e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,784][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([9.0082e-08, 4.3030e-04, 6.7014e-03, 1.3920e-01, 8.5367e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,784][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1073, 0.2486, 0.3128, 0.2127, 0.1185], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,786][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0029, 0.0586, 0.2549, 0.2214, 0.4623], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,787][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([4.8248e-05, 1.1061e-02, 2.1378e-02, 5.3266e-01, 4.3486e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,789][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0385, 0.0951, 0.2287, 0.1239, 0.5138], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,790][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.1283, 0.3035, 0.2032, 0.2310, 0.1340], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,791][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([2.0886e-04, 1.0521e-02, 3.9136e-02, 2.1648e-01, 7.3366e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,791][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([4.3944e-06, 1.6470e-02, 4.3995e-02, 5.1487e-01, 4.2466e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,792][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0259, 0.0962, 0.2569, 0.2379, 0.3831], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,792][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0795, 0.2072, 0.2276, 0.2562, 0.2295], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:16,792][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0079, 0.0443, 0.0343, 0.2897, 0.2754, 0.3484], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,793][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([2.8879e-05, 4.8847e-04, 3.4730e-02, 1.9371e-04, 6.7304e-02, 8.9725e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,793][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([4.7412e-09, 4.1288e-05, 1.0369e-03, 3.1254e-02, 8.8844e-01, 7.9231e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,794][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1658, 0.2084, 0.1627, 0.1501, 0.2612, 0.0519], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,794][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0034, 0.0430, 0.2387, 0.1576, 0.4192, 0.1382], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,795][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([1.2687e-05, 3.2313e-03, 7.7218e-03, 1.1459e-01, 6.4588e-01, 2.2857e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,796][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0411, 0.0902, 0.1754, 0.1290, 0.3404, 0.2238], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,798][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1051, 0.2497, 0.1712, 0.1751, 0.1111, 0.1878], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,799][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([7.6904e-05, 7.3445e-03, 1.0207e-02, 9.0115e-02, 6.4239e-01, 2.4987e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,800][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([1.2703e-06, 2.4436e-03, 8.3122e-03, 9.0417e-02, 5.9898e-01, 2.9985e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,801][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0198, 0.0824, 0.1771, 0.1883, 0.2675, 0.2649], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,802][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0712, 0.1694, 0.1929, 0.2082, 0.2044, 0.1539], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:16,802][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0088, 0.0344, 0.0298, 0.1739, 0.2148, 0.2704, 0.2679],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,802][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([3.4365e-06, 1.2447e-04, 5.3604e-02, 1.1192e-04, 8.0871e-02, 8.6501e-01,
        2.7111e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,803][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([6.1819e-09, 1.2858e-05, 2.3915e-04, 1.6442e-02, 3.2758e-01, 4.7939e-01,
        1.7633e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,803][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1015, 0.1593, 0.1340, 0.1584, 0.2279, 0.1068, 0.1120],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,804][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0024, 0.0367, 0.2314, 0.1348, 0.3770, 0.1235, 0.0942],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,804][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([1.5336e-05, 1.7042e-03, 4.0546e-03, 6.5202e-02, 2.6795e-01, 3.3155e-01,
        3.2952e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,804][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0346, 0.0739, 0.1507, 0.1093, 0.2949, 0.1900, 0.1466],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,805][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0914, 0.2052, 0.1446, 0.1484, 0.0955, 0.1535, 0.1613],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,806][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([5.0278e-05, 2.2379e-03, 6.6874e-03, 5.0519e-02, 2.2312e-01, 5.6362e-01,
        1.5377e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,807][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([8.3189e-07, 1.0332e-03, 3.5178e-03, 3.4685e-02, 2.8799e-01, 3.2810e-01,
        3.4467e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,809][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0174, 0.0692, 0.1529, 0.1592, 0.2264, 0.2218, 0.1532],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,810][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0585, 0.1410, 0.1603, 0.1766, 0.1673, 0.1286, 0.1676],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:16,812][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0047, 0.0199, 0.0121, 0.0843, 0.1215, 0.1064, 0.2302, 0.4209],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,812][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([8.1908e-04, 2.5239e-03, 4.0226e-02, 3.1597e-03, 4.1643e-02, 8.4797e-01,
        5.7198e-03, 5.7936e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,812][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([7.9711e-10, 7.3939e-07, 2.4791e-05, 5.2323e-04, 2.5211e-02, 4.7306e-02,
        2.0772e-01, 7.1921e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,813][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0558, 0.0873, 0.1370, 0.1063, 0.1792, 0.1345, 0.2733, 0.0267],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,813][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0022, 0.0311, 0.1273, 0.1049, 0.2036, 0.0942, 0.0784, 0.3583],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,814][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([1.7912e-06, 3.0639e-04, 8.3535e-04, 1.5701e-02, 6.3177e-02, 1.1324e-01,
        2.9857e-01, 5.0817e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,814][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0290, 0.0598, 0.1194, 0.0829, 0.2229, 0.1478, 0.1194, 0.2188],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,814][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0746, 0.1788, 0.1174, 0.1309, 0.0783, 0.1355, 0.1377, 0.1468],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,815][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([2.2867e-05, 9.2658e-04, 2.5135e-03, 1.1694e-02, 9.0464e-02, 1.5503e-01,
        1.7824e-01, 5.6111e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,816][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([1.6899e-07, 1.3684e-04, 5.9066e-04, 6.3057e-03, 3.9458e-02, 7.9056e-02,
        1.8964e-01, 6.8481e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,818][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0164, 0.0542, 0.1177, 0.1154, 0.1624, 0.1580, 0.1110, 0.2649],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,819][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0467, 0.1192, 0.1360, 0.1490, 0.1434, 0.1087, 0.1411, 0.1560],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:16,821][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0032, 0.0112, 0.0070, 0.0601, 0.1007, 0.0937, 0.1503, 0.4746, 0.0992],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,821][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([3.3433e-05, 4.3141e-04, 5.9958e-02, 1.1681e-04, 2.3171e-02, 7.7363e-01,
        6.9263e-04, 1.1869e-02, 1.3010e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,822][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([7.5077e-11, 9.4374e-08, 1.5621e-06, 7.1611e-05, 3.2272e-03, 2.7900e-03,
        1.6765e-02, 4.6913e-01, 5.0801e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,822][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0868, 0.1004, 0.1249, 0.0850, 0.0924, 0.1812, 0.2011, 0.1087, 0.0195],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,823][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0015, 0.0214, 0.0808, 0.0761, 0.1388, 0.0718, 0.0628, 0.2668, 0.2801],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,823][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([9.6698e-07, 1.0785e-04, 2.8646e-04, 4.5458e-03, 3.8700e-02, 2.1736e-02,
        7.9746e-02, 4.3601e-01, 4.1887e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,824][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0192, 0.0458, 0.0943, 0.0635, 0.1901, 0.1131, 0.0939, 0.1802, 0.1998],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,824][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0629, 0.1538, 0.1036, 0.1161, 0.0670, 0.1229, 0.1241, 0.1325, 0.1171],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,824][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([9.7571e-06, 4.7674e-04, 1.2287e-03, 8.7336e-03, 6.1405e-02, 1.4172e-01,
        1.1529e-01, 4.3491e-01, 2.3623e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,825][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([3.3938e-08, 5.3551e-05, 2.0231e-04, 2.3217e-03, 2.7242e-02, 2.2972e-02,
        4.2702e-02, 6.5831e-01, 2.4620e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,826][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0113, 0.0393, 0.0925, 0.0881, 0.1285, 0.1258, 0.0869, 0.2112, 0.2164],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,828][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0346, 0.1014, 0.1193, 0.1330, 0.1244, 0.0975, 0.1303, 0.1394, 0.1202],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:16,830][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0040, 0.0039, 0.0101, 0.0540, 0.0542, 0.0882, 0.1234, 0.1989, 0.1729,
        0.2903], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,830][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([5.8944e-06, 9.7303e-05, 2.0699e-02, 2.9838e-05, 2.6310e-02, 7.5476e-01,
        3.8106e-04, 2.7640e-02, 1.6935e-01, 7.1977e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,831][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([7.3422e-11, 3.0743e-09, 5.5743e-07, 2.3025e-05, 1.0855e-03, 5.6570e-04,
        2.5501e-03, 8.1593e-02, 2.0061e-01, 7.1357e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,832][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0697, 0.0550, 0.0742, 0.0646, 0.1108, 0.2080, 0.2161, 0.1182, 0.0526,
        0.0307], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,833][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0014, 0.0167, 0.1010, 0.0639, 0.1481, 0.0515, 0.0421, 0.2122, 0.2992,
        0.0638], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,833][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([3.6960e-07, 5.3259e-06, 2.4078e-05, 8.0980e-04, 2.6232e-03, 4.9050e-03,
        1.8683e-02, 5.6842e-02, 1.6784e-01, 7.4827e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,833][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0208, 0.0434, 0.0825, 0.0633, 0.1573, 0.1093, 0.0855, 0.1575, 0.1810,
        0.0995], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,834][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0625, 0.1371, 0.0996, 0.1011, 0.0656, 0.1083, 0.1115, 0.1150, 0.1069,
        0.0925], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,834][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([9.7358e-06, 7.2889e-05, 2.5178e-04, 3.2400e-03, 9.0270e-03, 3.6859e-02,
        4.3528e-02, 1.1641e-01, 3.0203e-01, 4.8857e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,835][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.4530e-08, 3.5239e-06, 5.0267e-05, 4.6973e-04, 4.6142e-03, 4.6780e-03,
        1.8971e-02, 7.8750e-02, 2.7215e-01, 6.2031e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,835][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0111, 0.0387, 0.0804, 0.0822, 0.1138, 0.1110, 0.0775, 0.1861, 0.1892,
        0.1100], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,837][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0327, 0.0884, 0.1072, 0.1170, 0.1110, 0.0855, 0.1132, 0.1235, 0.1053,
        0.1162], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:16,839][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0021, 0.0026, 0.0050, 0.0106, 0.0218, 0.0358, 0.0452, 0.0545, 0.0741,
        0.1975, 0.5508], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,840][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([4.8835e-06, 1.7413e-04, 3.2358e-02, 1.5109e-05, 4.3304e-02, 6.0447e-01,
        2.2423e-04, 1.0451e-02, 3.0787e-01, 1.0676e-03, 5.4572e-05],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,841][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.9542e-11, 7.8550e-10, 4.7533e-08, 1.0123e-07, 8.2716e-05, 1.4708e-05,
        1.1804e-04, 2.2084e-03, 8.0246e-03, 1.6994e-01, 8.1962e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,842][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0699, 0.0890, 0.0844, 0.0320, 0.1332, 0.1265, 0.2328, 0.0952, 0.0582,
        0.0533, 0.0255], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,843][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0013, 0.0141, 0.0997, 0.0531, 0.1539, 0.0461, 0.0375, 0.1938, 0.2822,
        0.0569, 0.0613], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,843][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([1.1628e-07, 1.5708e-06, 4.9617e-06, 2.4114e-05, 4.8570e-04, 7.0211e-04,
        3.7844e-03, 8.4700e-03, 3.3583e-02, 3.6175e-01, 5.9120e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,843][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0198, 0.0403, 0.0772, 0.0588, 0.1505, 0.1016, 0.0782, 0.1448, 0.1687,
        0.0918, 0.0684], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,844][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0593, 0.1256, 0.0980, 0.0922, 0.0631, 0.1012, 0.1035, 0.1031, 0.1006,
        0.0839, 0.0695], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,844][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([5.3470e-06, 3.7549e-05, 6.0858e-05, 2.4258e-04, 2.6865e-03, 9.6892e-03,
        1.0017e-02, 2.8361e-02, 5.5686e-02, 2.7740e-01, 6.1582e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,845][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([9.4314e-09, 1.4389e-06, 9.6917e-06, 3.2695e-05, 8.9811e-04, 1.0700e-03,
        3.2187e-03, 1.6717e-02, 5.1077e-02, 2.7105e-01, 6.5593e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,845][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0095, 0.0351, 0.0708, 0.0750, 0.1023, 0.0997, 0.0699, 0.1726, 0.1755,
        0.1028, 0.0867], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,847][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0298, 0.0804, 0.0953, 0.1016, 0.0997, 0.0774, 0.1007, 0.1104, 0.0948,
        0.1062, 0.1036], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:16,849][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0008, 0.0014, 0.0015, 0.0091, 0.0106, 0.0135, 0.0166, 0.0373, 0.0587,
        0.1233, 0.4926, 0.2347], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,850][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([1.3154e-05, 7.8657e-04, 2.5732e-02, 3.0600e-03, 4.6422e-02, 7.3608e-01,
        9.1592e-04, 4.6615e-02, 8.1869e-02, 9.5635e-03, 2.2822e-02, 2.6119e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,851][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([6.3158e-12, 1.7876e-10, 3.2990e-09, 1.2105e-07, 2.5598e-06, 1.8506e-06,
        2.0950e-05, 9.4518e-05, 1.0469e-03, 2.3582e-02, 7.9159e-01, 1.8366e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,852][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0456, 0.0866, 0.0693, 0.0669, 0.1532, 0.0914, 0.2727, 0.0523, 0.0459,
        0.0533, 0.0492, 0.0136], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,853][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0013, 0.0163, 0.0662, 0.0556, 0.1010, 0.0430, 0.0352, 0.1750, 0.2211,
        0.0563, 0.0597, 0.1693], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,853][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([3.7988e-08, 7.1504e-07, 2.6013e-06, 2.8453e-05, 2.5166e-04, 1.9705e-04,
        8.0462e-04, 2.1938e-03, 9.6026e-03, 1.2464e-01, 6.4274e-01, 2.1954e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,854][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0169, 0.0344, 0.0700, 0.0475, 0.1339, 0.0844, 0.0687, 0.1318, 0.1500,
        0.0821, 0.0603, 0.1201], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,854][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0483, 0.1216, 0.0811, 0.0888, 0.0537, 0.0975, 0.0952, 0.1011, 0.0910,
        0.0879, 0.0680, 0.0658], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,854][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([9.0613e-07, 2.3464e-05, 2.5501e-05, 2.3195e-04, 9.5571e-04, 2.0067e-03,
        3.1482e-03, 9.2626e-03, 2.0519e-02, 1.2794e-01, 5.9319e-01, 2.4269e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,855][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([2.4180e-09, 8.5692e-07, 2.0736e-06, 2.5434e-05, 2.3585e-04, 3.1437e-04,
        1.0244e-03, 6.1260e-03, 1.5212e-02, 1.0739e-01, 4.9815e-01, 3.7152e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,856][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0104, 0.0312, 0.0675, 0.0655, 0.0924, 0.0918, 0.0646, 0.1517, 0.1518,
        0.0856, 0.0718, 0.1157], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,857][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0222, 0.0690, 0.0836, 0.0903, 0.0877, 0.0703, 0.0919, 0.1025, 0.0906,
        0.1006, 0.0959, 0.0955], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:16,859][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0009, 0.0010, 0.0027, 0.0079, 0.0033, 0.0117, 0.0204, 0.0227, 0.0273,
        0.0966, 0.4399, 0.2215, 0.1442], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,860][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([7.8617e-05, 7.4724e-03, 1.2160e-01, 7.8926e-04, 1.9820e-01, 5.5611e-02,
        9.0439e-04, 3.7708e-03, 8.0604e-02, 6.4266e-03, 3.1716e-03, 7.9989e-02,
        4.4138e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,861][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([1.3578e-12, 3.3559e-11, 9.3716e-10, 9.7501e-09, 1.5284e-07, 2.8137e-07,
        2.0386e-06, 1.0010e-05, 9.6204e-05, 2.5080e-03, 5.2492e-02, 1.4814e-01,
        7.9675e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,862][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0395, 0.0654, 0.0671, 0.0513, 0.0287, 0.0899, 0.2385, 0.2021, 0.0564,
        0.0476, 0.0410, 0.0477, 0.0247], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,863][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0005, 0.0102, 0.0467, 0.0421, 0.0862, 0.0276, 0.0253, 0.1199, 0.2108,
        0.0431, 0.0464, 0.1585, 0.1828], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,863][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([7.0116e-09, 1.3177e-07, 3.4425e-07, 6.6311e-06, 8.0699e-06, 4.5136e-05,
        2.5485e-04, 1.0197e-03, 4.5545e-03, 3.0206e-02, 1.7473e-01, 5.8300e-01,
        2.0618e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,864][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0094, 0.0238, 0.0591, 0.0312, 0.1366, 0.0601, 0.0473, 0.1153, 0.1385,
        0.0608, 0.0398, 0.1161, 0.1619], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,864][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0482, 0.1102, 0.0766, 0.0867, 0.0507, 0.0935, 0.0919, 0.0909, 0.0891,
        0.0848, 0.0671, 0.0668, 0.0433], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,865][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([4.1695e-07, 2.6342e-06, 1.1438e-05, 5.5112e-05, 2.0846e-04, 5.7322e-04,
        1.1271e-03, 2.7790e-03, 4.8353e-03, 2.8636e-02, 1.4510e-01, 3.2996e-01,
        4.8671e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,865][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([1.5254e-09, 4.1680e-07, 1.5559e-06, 1.1598e-05, 1.7399e-05, 1.2827e-04,
        4.4271e-04, 1.6257e-03, 6.0527e-03, 4.5439e-02, 2.0893e-01, 4.2465e-01,
        3.1271e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,866][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0049, 0.0194, 0.0535, 0.0517, 0.0840, 0.0793, 0.0518, 0.1526, 0.1545,
        0.0743, 0.0622, 0.1186, 0.0932], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,868][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0191, 0.0604, 0.0755, 0.0821, 0.0769, 0.0654, 0.0840, 0.0914, 0.0837,
        0.0929, 0.0900, 0.0904, 0.0883], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:16,870][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0004, 0.0008, 0.0010, 0.0047, 0.0032, 0.0148, 0.0112, 0.0169, 0.0259,
        0.0639, 0.2750, 0.2789, 0.1127, 0.1907], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,871][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([2.7045e-06, 3.4236e-04, 1.0814e-01, 2.0339e-05, 5.8443e-02, 2.0448e-01,
        2.3987e-05, 1.2169e-02, 9.4147e-02, 7.4345e-04, 8.2426e-05, 9.3241e-02,
        1.2376e-01, 3.0441e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,871][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([1.6484e-13, 2.8453e-12, 2.9550e-11, 1.7384e-09, 6.8829e-08, 8.3833e-08,
        1.5941e-07, 1.5791e-06, 1.7534e-05, 6.7930e-04, 2.1282e-02, 6.2637e-02,
        6.5014e-01, 2.6524e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,873][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1213, 0.0977, 0.0554, 0.0807, 0.0818, 0.0467, 0.0877, 0.0711, 0.0628,
        0.0669, 0.0753, 0.0500, 0.0806, 0.0220], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,873][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0007, 0.0088, 0.0471, 0.0342, 0.0840, 0.0289, 0.0245, 0.1305, 0.1733,
        0.0373, 0.0397, 0.1326, 0.1846, 0.0737], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,873][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([9.2269e-09, 1.5899e-07, 2.0951e-07, 4.6248e-06, 2.2251e-05, 1.4549e-05,
        1.0577e-04, 4.7856e-04, 4.9665e-04, 2.6374e-02, 1.2893e-01, 1.0008e-01,
        5.1852e-01, 2.2498e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,874][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0120, 0.0266, 0.0546, 0.0385, 0.1063, 0.0695, 0.0556, 0.1060, 0.1196,
        0.0638, 0.0479, 0.0969, 0.1201, 0.0826], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,874][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0450, 0.1017, 0.0767, 0.0758, 0.0504, 0.0847, 0.0852, 0.0896, 0.0830,
        0.0746, 0.0588, 0.0645, 0.0435, 0.0664], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,875][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([4.4403e-07, 4.1903e-06, 5.0498e-06, 3.9543e-05, 1.8659e-04, 2.6851e-04,
        3.8758e-04, 1.8631e-03, 2.4424e-03, 3.3653e-02, 1.0139e-01, 1.3360e-01,
        3.7399e-01, 3.5217e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,875][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([5.2075e-10, 6.5147e-08, 3.6985e-07, 2.9198e-06, 2.5761e-05, 1.3910e-05,
        6.0361e-05, 2.7340e-04, 1.2698e-03, 1.7530e-02, 7.6497e-02, 9.6071e-02,
        6.1401e-01, 1.9425e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,876][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0067, 0.0241, 0.0514, 0.0537, 0.0747, 0.0721, 0.0504, 0.1285, 0.1294,
        0.0715, 0.0603, 0.1013, 0.0797, 0.0962], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,878][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0195, 0.0591, 0.0730, 0.0794, 0.0760, 0.0617, 0.0813, 0.0881, 0.0765,
        0.0885, 0.0837, 0.0842, 0.0763, 0.0527], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:16,879][circuit_model.py][line:2332][INFO] ##2-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([2.5296e-04, 2.6672e-04, 2.5259e-04, 1.6550e-03, 1.2910e-03, 2.3085e-03,
        3.0467e-03, 5.2127e-03, 8.3406e-03, 2.3489e-02, 1.0276e-01, 1.5555e-01,
        5.2345e-02, 1.7343e-01, 4.6980e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,880][circuit_model.py][line:2335][INFO] ##2-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([9.9902e-06, 4.4097e-04, 4.7649e-02, 1.7467e-04, 6.1977e-02, 3.4982e-01,
        7.2851e-04, 1.4560e-02, 1.7185e-01, 6.8536e-03, 6.9267e-04, 1.1364e-01,
        1.3227e-01, 9.8562e-02, 7.7333e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,881][circuit_model.py][line:2338][INFO] ##2-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.4035e-13, 3.8068e-13, 6.3491e-12, 1.6141e-10, 3.4088e-09, 9.1896e-09,
        2.5459e-08, 4.3928e-07, 3.4113e-06, 4.4483e-05, 1.4561e-03, 3.4184e-03,
        2.3265e-02, 3.3137e-01, 6.4045e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,883][circuit_model.py][line:2341][INFO] ##2-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0733, 0.0762, 0.0412, 0.0563, 0.0724, 0.0662, 0.1675, 0.0744, 0.0421,
        0.0464, 0.0515, 0.0375, 0.0658, 0.1089, 0.0202], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,883][circuit_model.py][line:2344][INFO] ##2-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0009, 0.0099, 0.0602, 0.0344, 0.0890, 0.0275, 0.0222, 0.1148, 0.1737,
        0.0333, 0.0343, 0.1096, 0.1892, 0.0712, 0.0298], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,884][circuit_model.py][line:2347][INFO] ##2-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([5.4500e-09, 2.7140e-08, 5.5532e-08, 9.3247e-07, 3.6227e-06, 5.1552e-06,
        1.6471e-05, 7.0305e-05, 1.4687e-04, 3.6805e-03, 2.3244e-02, 2.6773e-02,
        8.3299e-02, 1.6426e-01, 6.9850e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,884][circuit_model.py][line:2350][INFO] ##2-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0129, 0.0266, 0.0516, 0.0388, 0.0998, 0.0662, 0.0504, 0.0945, 0.1108,
        0.0603, 0.0445, 0.0895, 0.1151, 0.0774, 0.0615], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,884][circuit_model.py][line:2353][INFO] ##2-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0454, 0.0981, 0.0719, 0.0734, 0.0477, 0.0788, 0.0796, 0.0811, 0.0765,
        0.0684, 0.0555, 0.0605, 0.0408, 0.0648, 0.0576], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,885][circuit_model.py][line:2356][INFO] ##2-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.4296e-07, 7.1507e-07, 9.2046e-07, 5.6006e-06, 3.1444e-05, 8.3596e-05,
        6.4453e-05, 6.3544e-05, 4.8766e-04, 4.6547e-03, 1.8187e-02, 2.4039e-02,
        4.9557e-02, 6.5631e-01, 2.4652e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,885][circuit_model.py][line:2359][INFO] ##2-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([2.8433e-10, 1.7788e-08, 7.6915e-08, 4.3912e-07, 6.9653e-06, 2.8388e-06,
        1.3350e-05, 9.8789e-05, 2.4370e-04, 2.3580e-03, 9.8982e-03, 3.2086e-02,
        1.2934e-01, 2.0491e-01, 6.2105e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,886][circuit_model.py][line:2362][INFO] ##2-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0068, 0.0241, 0.0482, 0.0509, 0.0690, 0.0670, 0.0471, 0.1175, 0.1184,
        0.0686, 0.0578, 0.0936, 0.0751, 0.0896, 0.0662], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,888][circuit_model.py][line:2365][INFO] ##2-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0200, 0.0564, 0.0690, 0.0757, 0.0726, 0.0576, 0.0754, 0.0822, 0.0707,
        0.0802, 0.0785, 0.0777, 0.0718, 0.0490, 0.0631], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:16,889][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:16,891][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[17655],
        [33236],
        [ 3867],
        [23029],
        [14643],
        [18697],
        [18788],
        [23842],
        [20371],
        [23854],
        [28453],
        [32129],
        [18345],
        [18105],
        [20711]], device='cuda:0')
[2024-07-24 10:20:16,893][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[21811],
        [23611],
        [ 2458],
        [35403],
        [27632],
        [30472],
        [36796],
        [38010],
        [34118],
        [38159],
        [38899],
        [37840],
        [37184],
        [28948],
        [35593]], device='cuda:0')
[2024-07-24 10:20:16,894][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[26777],
        [25947],
        [31645],
        [28683],
        [29667],
        [26878],
        [25701],
        [24283],
        [24013],
        [24051],
        [23330],
        [23463],
        [23968],
        [24044],
        [23905]], device='cuda:0')
[2024-07-24 10:20:16,895][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[18740],
        [23307],
        [23109],
        [36366],
        [32374],
        [38670],
        [39298],
        [39540],
        [39509],
        [38528],
        [39561],
        [40461],
        [38133],
        [38738],
        [39579]], device='cuda:0')
[2024-07-24 10:20:16,896][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[40403],
        [31959],
        [21476],
        [18679],
        [ 6488],
        [ 6334],
        [ 6206],
        [ 5426],
        [ 1719],
        [27456],
        [23213],
        [20418],
        [ 4967],
        [ 4812],
        [14606]], device='cuda:0')
[2024-07-24 10:20:16,897][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[47798],
        [33828],
        [39952],
        [43916],
        [43547],
        [41827],
        [41108],
        [32903],
        [38125],
        [33420],
        [40977],
        [44409],
        [45790],
        [46467],
        [42408]], device='cuda:0')
[2024-07-24 10:20:16,899][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[37918],
        [39757],
        [43682],
        [44091],
        [44336],
        [43421],
        [44293],
        [40291],
        [44033],
        [42093],
        [43535],
        [48714],
        [42271],
        [41858],
        [41149]], device='cuda:0')
[2024-07-24 10:20:16,901][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[15140],
        [15140],
        [15140],
        [15140],
        [15140],
        [15140],
        [15138],
        [15140],
        [15135],
        [15064],
        [14969],
        [14908],
        [15133],
        [14772],
        [11522]], device='cuda:0')
[2024-07-24 10:20:16,902][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[45062],
        [35709],
        [ 3170],
        [ 7521],
        [ 7009],
        [ 3014],
        [ 3100],
        [ 2544],
        [ 3817],
        [ 3508],
        [ 8775],
        [ 9197],
        [ 5943],
        [ 3840],
        [ 3872]], device='cuda:0')
[2024-07-24 10:20:16,904][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[31921],
        [30804],
        [13821],
        [19412],
        [22189],
        [19653],
        [18954],
        [19834],
        [18608],
        [20512],
        [22316],
        [24223],
        [23975],
        [22525],
        [21102]], device='cuda:0')
[2024-07-24 10:20:16,904][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21475],
        [21484],
        [21492],
        [21533],
        [21527],
        [21622],
        [21647],
        [21628],
        [21695],
        [21726],
        [21820],
        [21907],
        [21932],
        [22024],
        [22043]], device='cuda:0')
[2024-07-24 10:20:16,905][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[22174],
        [22191],
        [22242],
        [22391],
        [26174],
        [34220],
        [35281],
        [36215],
        [37401],
        [30392],
        [31719],
        [34024],
        [33691],
        [35375],
        [40156]], device='cuda:0')
[2024-07-24 10:20:16,906][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[ 419],
        [ 335],
        [ 957],
        [1015],
        [ 877],
        [2542],
        [3529],
        [3049],
        [3848],
        [2906],
        [3084],
        [2814],
        [2834],
        [4617],
        [4119]], device='cuda:0')
[2024-07-24 10:20:16,908][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[45736],
        [45184],
        [43582],
        [43113],
        [42537],
        [42319],
        [42127],
        [41372],
        [41244],
        [41046],
        [40906],
        [40624],
        [40895],
        [40853],
        [40913]], device='cuda:0')
[2024-07-24 10:20:16,910][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[14266],
        [23748],
        [ 7924],
        [17291],
        [ 9105],
        [17396],
        [12140],
        [22920],
        [17586],
        [12542],
        [14304],
        [16674],
        [ 4798],
        [14967],
        [12045]], device='cuda:0')
[2024-07-24 10:20:16,911][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[39719],
        [37978],
        [37084],
        [35468],
        [35837],
        [36472],
        [35117],
        [36134],
        [34599],
        [33851],
        [32249],
        [32257],
        [32962],
        [32341],
        [34360]], device='cuda:0')
[2024-07-24 10:20:16,913][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[14785],
        [21380],
        [ 3983],
        [ 4293],
        [ 1346],
        [20795],
        [21286],
        [21423],
        [25191],
        [25675],
        [27962],
        [24550],
        [ 1920],
        [16081],
        [22522]], device='cuda:0')
[2024-07-24 10:20:16,914][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[15301],
        [24621],
        [28450],
        [21548],
        [ 8063],
        [ 8832],
        [20050],
        [13286],
        [26637],
        [20828],
        [16822],
        [17163],
        [13717],
        [13625],
        [34364]], device='cuda:0')
[2024-07-24 10:20:16,915][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[5325],
        [7892],
        [7559],
        [7433],
        [7050],
        [6553],
        [6228],
        [4798],
        [5692],
        [5627],
        [5180],
        [5080],
        [5210],
        [6348],
        [5917]], device='cuda:0')
[2024-07-24 10:20:16,916][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[10313],
        [15355],
        [12111],
        [13948],
        [12808],
        [12643],
        [12554],
        [12771],
        [13150],
        [13168],
        [13158],
        [13590],
        [12943],
        [13072],
        [12966]], device='cuda:0')
[2024-07-24 10:20:16,917][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 7146],
        [14718],
        [15084],
        [ 6811],
        [ 9986],
        [10490],
        [ 3293],
        [ 9665],
        [14153],
        [ 8771],
        [ 4088],
        [ 4638],
        [10075],
        [ 6168],
        [ 3002]], device='cuda:0')
[2024-07-24 10:20:16,918][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[9132],
        [8802],
        [7165],
        [7040],
        [7515],
        [7196],
        [7043],
        [7136],
        [7428],
        [7167],
        [7148],
        [7443],
        [7679],
        [7451],
        [7427]], device='cuda:0')
[2024-07-24 10:20:16,920][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[2706],
        [2670],
        [3107],
        [3294],
        [3447],
        [3629],
        [3623],
        [3622],
        [3699],
        [3735],
        [3735],
        [3687],
        [3737],
        [3639],
        [3576]], device='cuda:0')
[2024-07-24 10:20:16,921][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[19861],
        [23178],
        [25459],
        [24589],
        [17016],
        [14518],
        [14388],
        [17706],
        [18799],
        [24661],
        [24036],
        [22126],
        [17105],
        [16277],
        [17164]], device='cuda:0')
[2024-07-24 10:20:16,923][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[12614],
        [11561],
        [ 9754],
        [10308],
        [ 8930],
        [ 5984],
        [ 9377],
        [11481],
        [13294],
        [14678],
        [11850],
        [10844],
        [ 9201],
        [ 8002],
        [12499]], device='cuda:0')
[2024-07-24 10:20:16,924][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[17797],
        [15873],
        [18957],
        [16542],
        [17843],
        [16415],
        [15978],
        [16707],
        [17051],
        [16695],
        [16353],
        [16495],
        [16909],
        [16658],
        [16398]], device='cuda:0')
[2024-07-24 10:20:16,925][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 9238],
        [ 9004],
        [ 9856],
        [ 9847],
        [10711],
        [10945],
        [11018],
        [11233],
        [11453],
        [11571],
        [11616],
        [11811],
        [12220],
        [12300],
        [12319]], device='cuda:0')
[2024-07-24 10:20:16,926][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[34013],
        [27001],
        [29340],
        [33289],
        [37884],
        [36351],
        [35344],
        [33255],
        [29082],
        [27869],
        [31880],
        [32688],
        [38436],
        [37375],
        [32127]], device='cuda:0')
[2024-07-24 10:20:16,927][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[41486],
        [33837],
        [46286],
        [42306],
        [44060],
        [36433],
        [39508],
        [34782],
        [32342],
        [37879],
        [40689],
        [40919],
        [36368],
        [29294],
        [34438]], device='cuda:0')
[2024-07-24 10:20:16,928][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427],
        [31427]], device='cuda:0')
[2024-07-24 10:20:16,974][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:16,974][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,975][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,976][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,977][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,978][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,980][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,981][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,981][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,981][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,982][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,982][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,982][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:16,983][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.6567, 0.3433], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,983][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4632, 0.5368], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,983][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3264, 0.6736], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,984][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0525, 0.9475], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,985][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0022, 0.9978], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,986][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8179, 0.1821], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,988][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.9511, 0.0489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,989][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8788, 0.1212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,991][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.8385, 0.1615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,991][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9217, 0.0783], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,992][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9597, 0.0403], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,992][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.8266, 0.1734], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:16,992][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.4776, 0.2507, 0.2716], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,993][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.3008, 0.3406, 0.3586], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,993][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.1877, 0.3704, 0.4420], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,993][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.1755, 0.1086, 0.7160], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,994][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([4.4645e-04, 2.5169e-01, 7.4786e-01], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,994][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.2228, 0.3975, 0.3796], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,996][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.6848, 0.1684, 0.1469], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,997][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.5872, 0.3324, 0.0804], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:16,999][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.7794, 0.1866, 0.0340], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,000][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.6118, 0.1434, 0.2447], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,001][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.7458, 0.0645, 0.1897], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,002][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.6688, 0.2333, 0.0978], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,002][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1876, 0.1494, 0.1321, 0.5308], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,002][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2230, 0.2561, 0.2713, 0.2495], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,003][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.1270, 0.2572, 0.3136, 0.3023], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,003][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0691e-01, 4.0892e-04, 1.5789e-02, 8.7689e-01], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,003][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([3.1090e-04, 1.5304e-01, 5.2933e-01, 3.1731e-01], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,004][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5291, 0.1615, 0.0858, 0.2237], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,004][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.8663, 0.0110, 0.0357, 0.0870], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,005][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6052, 0.0068, 0.0291, 0.3589], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,006][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6943, 0.0508, 0.0265, 0.2284], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,008][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.5309, 0.0957, 0.0915, 0.2819], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,010][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7140, 0.0483, 0.0588, 0.1789], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,011][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.5323, 0.0784, 0.0318, 0.3575], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,012][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.1349, 0.0737, 0.0897, 0.3992, 0.3024], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,012][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.1778, 0.2024, 0.2142, 0.1990, 0.2066], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,012][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0927, 0.1863, 0.2254, 0.2304, 0.2653], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,013][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([7.9310e-02, 4.3345e-05, 4.7079e-04, 5.6532e-02, 8.6364e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,013][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0008, 0.0783, 0.4755, 0.1752, 0.2703], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,013][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.1828, 0.2138, 0.2103, 0.3153, 0.0778], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,014][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.3875, 0.0529, 0.0703, 0.2677, 0.2217], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,014][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.1587, 0.0254, 0.0296, 0.7268, 0.0595], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,015][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.2939, 0.0365, 0.0121, 0.6309, 0.0266], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,017][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.2928, 0.0432, 0.1202, 0.3527, 0.1911], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,018][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.5557, 0.0296, 0.0661, 0.1979, 0.1507], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,020][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.2571, 0.0825, 0.0384, 0.5818, 0.0402], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,021][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0459, 0.0313, 0.0356, 0.1556, 0.1564, 0.5752], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,022][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1475, 0.1661, 0.1779, 0.1664, 0.1746, 0.1675], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,022][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0683, 0.1481, 0.1883, 0.1905, 0.2279, 0.1770], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,023][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ had] are: tensor([2.4891e-03, 1.9569e-06, 2.3384e-05, 1.2369e-02, 6.7939e-01, 3.0572e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,023][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0007, 0.0853, 0.3307, 0.1617, 0.2935, 0.1281], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,023][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.1930, 0.1541, 0.0681, 0.3304, 0.0381, 0.2164], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,024][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.3733, 0.0219, 0.0380, 0.1574, 0.1432, 0.2661], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,024][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1885, 0.0034, 0.0042, 0.1422, 0.0405, 0.6212], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,024][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3920, 0.0354, 0.0055, 0.2877, 0.0251, 0.2544], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,025][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3261, 0.1108, 0.0256, 0.2471, 0.0470, 0.2435], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,027][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.5089, 0.0324, 0.0259, 0.1067, 0.0664, 0.2597], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,029][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.3928, 0.0463, 0.0114, 0.2545, 0.0217, 0.2733], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,030][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0473, 0.0452, 0.0400, 0.1463, 0.1284, 0.2757, 0.3170],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,031][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1272, 0.1437, 0.1537, 0.1426, 0.1500, 0.1440, 0.1388],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,032][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0602, 0.1265, 0.1614, 0.1567, 0.1886, 0.1516, 0.1550],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,033][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.8230e-03, 1.2757e-06, 4.1661e-05, 4.2812e-03, 3.0389e-01, 4.2549e-01,
        2.5648e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,033][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0017, 0.0814, 0.2480, 0.1456, 0.2356, 0.1370, 0.1508],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,033][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.2140, 0.1229, 0.0538, 0.2269, 0.0282, 0.1560, 0.1982],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,034][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.5074, 0.0085, 0.0116, 0.0652, 0.0597, 0.1590, 0.1886],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,034][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1538, 0.0025, 0.0024, 0.0656, 0.0143, 0.4450, 0.3165],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,034][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4029, 0.0187, 0.0032, 0.1376, 0.0102, 0.1636, 0.2639],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,035][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2818, 0.0402, 0.0289, 0.1920, 0.0291, 0.2403, 0.1878],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,036][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.5145, 0.0258, 0.0178, 0.0830, 0.0397, 0.1673, 0.1520],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,037][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.3815, 0.0293, 0.0071, 0.1419, 0.0123, 0.1809, 0.2471],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,039][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0165, 0.0154, 0.0152, 0.0848, 0.0868, 0.2379, 0.4602, 0.0832],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,041][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1105, 0.1263, 0.1345, 0.1253, 0.1307, 0.1265, 0.1215, 0.1246],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,042][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0536, 0.1102, 0.1364, 0.1361, 0.1595, 0.1287, 0.1343, 0.1412],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,043][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ long] are: tensor([8.9999e-04, 4.2638e-08, 4.4781e-07, 3.5409e-04, 7.3804e-03, 2.2635e-02,
        3.0573e-02, 9.3816e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,043][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0009, 0.0529, 0.1878, 0.1119, 0.1960, 0.1172, 0.1228, 0.2104],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,043][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.2655, 0.0810, 0.0402, 0.1528, 0.0205, 0.1087, 0.1612, 0.1702],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,044][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.4709, 0.0024, 0.0027, 0.0226, 0.0128, 0.0713, 0.1297, 0.2876],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,044][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ long] are: tensor([1.2805e-01, 3.8207e-04, 4.1389e-04, 1.8582e-02, 3.3628e-03, 1.5713e-01,
        1.7498e-01, 5.1709e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,045][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.2740, 0.0057, 0.0007, 0.0463, 0.0021, 0.0923, 0.1398, 0.4390],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,045][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1533, 0.0113, 0.0039, 0.0638, 0.0064, 0.0885, 0.1106, 0.5622],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,046][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.5419, 0.0106, 0.0066, 0.0491, 0.0142, 0.1040, 0.0821, 0.1915],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,048][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.2607, 0.0080, 0.0016, 0.0451, 0.0027, 0.0514, 0.1328, 0.4976],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,049][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0187, 0.0120, 0.0152, 0.0863, 0.0710, 0.2351, 0.4593, 0.0700, 0.0324],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,051][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0980, 0.1118, 0.1196, 0.1115, 0.1162, 0.1126, 0.1081, 0.1113, 0.1109],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,052][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0489, 0.0970, 0.1198, 0.1199, 0.1432, 0.1152, 0.1207, 0.1260, 0.1092],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,053][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([9.0970e-04, 1.9686e-08, 7.0964e-08, 2.6792e-05, 3.1603e-03, 2.9699e-03,
        3.6752e-03, 8.5729e-01, 1.3197e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,053][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0025, 0.0546, 0.1265, 0.0989, 0.1539, 0.1013, 0.1142, 0.1849, 0.1633],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,054][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.1388, 0.0837, 0.0522, 0.1774, 0.0297, 0.1123, 0.1385, 0.1482, 0.1191],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,054][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1912, 0.0026, 0.0024, 0.0164, 0.0119, 0.0449, 0.0985, 0.5142, 0.1179],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,054][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([4.9339e-02, 1.6691e-04, 1.5388e-04, 3.7304e-03, 1.1376e-03, 3.7402e-02,
        3.6081e-02, 7.2792e-01, 1.4407e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,055][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([1.2545e-01, 2.3498e-03, 4.3923e-04, 1.6646e-02, 1.9526e-03, 3.6876e-02,
        5.4069e-02, 6.2933e-01, 1.3288e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,055][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1589, 0.0071, 0.0083, 0.0481, 0.0108, 0.0868, 0.0624, 0.4266, 0.1911],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,056][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.4788, 0.0151, 0.0098, 0.0466, 0.0229, 0.0780, 0.0784, 0.1435, 0.1269],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,057][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([9.9288e-02, 3.2912e-03, 7.1448e-04, 1.8817e-02, 2.5790e-03, 2.1671e-02,
        5.3550e-02, 7.1499e-01, 8.5103e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,059][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0254, 0.0240, 0.0246, 0.0906, 0.0772, 0.1910, 0.2468, 0.0732, 0.0465,
        0.2008], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,060][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0882, 0.1005, 0.1072, 0.0986, 0.1027, 0.0994, 0.0969, 0.1001, 0.0998,
        0.1066], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,062][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0441, 0.0960, 0.1172, 0.1094, 0.1277, 0.0937, 0.0967, 0.1110, 0.1026,
        0.1015], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,063][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [,] are: tensor([2.9697e-05, 3.1991e-10, 3.0566e-08, 2.5780e-06, 1.4653e-03, 5.4902e-04,
        1.9505e-03, 9.2645e-01, 6.8388e-02, 1.1699e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,063][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0007, 0.0421, 0.1361, 0.0827, 0.1234, 0.0806, 0.0821, 0.1391, 0.1648,
        0.1484], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,063][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2032, 0.0708, 0.0290, 0.1409, 0.0148, 0.0962, 0.1193, 0.1402, 0.0981,
        0.0874], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,064][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3463, 0.0011, 0.0024, 0.0129, 0.0098, 0.0364, 0.0760, 0.2946, 0.1216,
        0.0989], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,064][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [,] are: tensor([6.3566e-02, 4.2557e-05, 9.5455e-05, 2.1128e-03, 6.6345e-04, 2.6164e-02,
        2.8982e-02, 5.0356e-01, 2.0502e-01, 1.6979e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,065][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [,] are: tensor([1.4881e-01, 1.1055e-03, 2.1053e-04, 1.0513e-02, 5.1864e-04, 2.3359e-02,
        6.5574e-02, 2.7796e-01, 2.5220e-01, 2.1975e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,066][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.2401, 0.0049, 0.0129, 0.0430, 0.0098, 0.0248, 0.0566, 0.3835, 0.1408,
        0.0835], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,067][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.3958, 0.0139, 0.0092, 0.0360, 0.0219, 0.0826, 0.0741, 0.1367, 0.0983,
        0.1314], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,069][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1027, 0.0032, 0.0013, 0.0260, 0.0022, 0.0276, 0.0649, 0.5092, 0.1438,
        0.1191], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,071][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0294, 0.0288, 0.0303, 0.0922, 0.0682, 0.1441, 0.1807, 0.0649, 0.0437,
        0.1392, 0.1785], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,072][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0809, 0.0917, 0.0973, 0.0895, 0.0929, 0.0897, 0.0872, 0.0906, 0.0902,
        0.0966, 0.0934], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,073][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0417, 0.0851, 0.1034, 0.0991, 0.1135, 0.0869, 0.0909, 0.1004, 0.0912,
        0.0910, 0.0968], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,073][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ and] are: tensor([1.0868e-03, 1.4457e-09, 3.4234e-08, 3.4502e-06, 3.1161e-03, 6.6824e-04,
        1.3735e-03, 7.5184e-01, 5.3963e-02, 2.3823e-03, 1.8556e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,073][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0009, 0.0350, 0.0959, 0.0670, 0.0979, 0.0720, 0.0734, 0.1207, 0.1382,
        0.1305, 0.1684], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,074][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.1916, 0.0624, 0.0251, 0.1049, 0.0117, 0.0788, 0.1076, 0.1207, 0.0739,
        0.0806, 0.1426], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,074][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4932, 0.0006, 0.0012, 0.0044, 0.0058, 0.0210, 0.0440, 0.1323, 0.0526,
        0.0656, 0.1795], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,075][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ and] are: tensor([1.0219e-01, 2.8882e-05, 6.5617e-05, 1.3582e-03, 4.8475e-04, 1.6477e-02,
        1.5459e-02, 2.4405e-01, 1.0826e-01, 1.0529e-01, 4.0634e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,075][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ and] are: tensor([1.7201e-01, 5.0877e-04, 1.4344e-04, 3.1232e-03, 2.5272e-04, 1.0304e-02,
        2.4550e-02, 1.3569e-01, 8.9197e-02, 1.4156e-01, 4.2266e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,075][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2212, 0.0059, 0.0029, 0.0191, 0.0031, 0.0220, 0.0377, 0.1990, 0.0880,
        0.0956, 0.3055], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,076][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4068, 0.0123, 0.0086, 0.0301, 0.0165, 0.0688, 0.0567, 0.0934, 0.0679,
        0.0956, 0.1434], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,078][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1518, 0.0026, 0.0007, 0.0136, 0.0013, 0.0227, 0.0449, 0.2864, 0.0993,
        0.0821, 0.2944], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,080][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0209, 0.0162, 0.0186, 0.0701, 0.0569, 0.1337, 0.2146, 0.0499, 0.0273,
        0.1458, 0.1877, 0.0582], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,081][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0738, 0.0835, 0.0886, 0.0817, 0.0846, 0.0819, 0.0795, 0.0828, 0.0825,
        0.0877, 0.0852, 0.0882], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,082][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0415, 0.0742, 0.0897, 0.0889, 0.0997, 0.0776, 0.0837, 0.0902, 0.0803,
        0.0783, 0.0860, 0.1100], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,083][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([1.7451e-03, 2.9870e-09, 2.0737e-09, 3.0300e-06, 7.9262e-05, 1.9771e-04,
        1.3407e-04, 4.7305e-02, 1.4370e-03, 2.1380e-04, 1.4122e-02, 9.3476e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,083][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0033, 0.0391, 0.0696, 0.0633, 0.0732, 0.0605, 0.0745, 0.1202, 0.1253,
        0.1108, 0.1403, 0.1199], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,084][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.2374, 0.0296, 0.0360, 0.0766, 0.0203, 0.0758, 0.1014, 0.1119, 0.0562,
        0.0553, 0.1304, 0.0691], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,084][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.3034, 0.0006, 0.0006, 0.0047, 0.0024, 0.0201, 0.0236, 0.0966, 0.0269,
        0.0307, 0.1436, 0.3468], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,085][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([2.2658e-02, 2.9961e-05, 1.8948e-05, 9.7812e-04, 2.0204e-04, 8.1784e-03,
        8.0074e-03, 8.8164e-02, 2.3609e-02, 3.9885e-02, 1.9855e-01, 6.0972e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,085][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([1.2564e-01, 3.5903e-04, 5.5904e-05, 4.5743e-03, 2.3033e-04, 7.4280e-03,
        8.3321e-03, 5.4269e-02, 2.2706e-02, 7.5994e-02, 3.6937e-01, 3.3104e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,085][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1971, 0.0021, 0.0023, 0.0125, 0.0037, 0.0162, 0.0165, 0.1544, 0.0366,
        0.0321, 0.1510, 0.3756], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,086][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.3737, 0.0077, 0.0038, 0.0297, 0.0088, 0.0419, 0.0354, 0.0602, 0.0331,
        0.0524, 0.1329, 0.2203], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,088][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([1.1452e-01, 1.1909e-03, 3.4820e-04, 7.3695e-03, 1.0962e-03, 9.9902e-03,
        1.9474e-02, 1.9682e-01, 3.7461e-02, 2.5737e-02, 1.1614e-01, 4.6986e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,090][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0274, 0.0168, 0.0213, 0.0760, 0.0485, 0.1362, 0.1859, 0.0541, 0.0285,
        0.1296, 0.1656, 0.0532, 0.0569], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,091][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0685, 0.0761, 0.0798, 0.0756, 0.0776, 0.0755, 0.0736, 0.0756, 0.0752,
        0.0792, 0.0783, 0.0812, 0.0839], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,093][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0344, 0.0657, 0.0787, 0.0820, 0.0931, 0.0766, 0.0822, 0.0848, 0.0725,
        0.0692, 0.0774, 0.1023, 0.0810], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,093][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([4.6850e-03, 1.1199e-09, 7.6261e-09, 1.4104e-06, 3.9436e-05, 4.5921e-05,
        8.6496e-05, 2.5451e-03, 4.7592e-03, 6.7452e-05, 1.0544e-02, 6.4822e-01,
        3.2901e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,093][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0020, 0.0360, 0.0856, 0.0564, 0.0574, 0.0515, 0.0678, 0.1023, 0.1014,
        0.1012, 0.1237, 0.1014, 0.1133], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,094][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0855, 0.0504, 0.0567, 0.0854, 0.0215, 0.0906, 0.0955, 0.0915, 0.0589,
        0.0650, 0.1010, 0.1660, 0.0321], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,094][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0954, 0.0005, 0.0008, 0.0037, 0.0021, 0.0095, 0.0193, 0.0788, 0.0352,
        0.0406, 0.1794, 0.4204, 0.1144], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,095][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([2.5491e-03, 4.8986e-06, 4.4662e-06, 1.4043e-04, 7.0417e-06, 1.8164e-03,
        1.9786e-03, 4.0851e-02, 1.3182e-02, 1.2799e-02, 6.2186e-02, 8.6036e-01,
        4.1200e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,095][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([1.3656e-02, 5.6472e-05, 1.3986e-05, 1.1504e-03, 2.3745e-05, 2.3692e-03,
        4.9414e-03, 3.6818e-02, 1.9218e-02, 2.8093e-02, 1.5855e-01, 7.2954e-01,
        5.5727e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,096][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0626, 0.0008, 0.0015, 0.0090, 0.0026, 0.0072, 0.0174, 0.0854, 0.0257,
        0.0380, 0.1939, 0.4928, 0.0632], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,097][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.2586, 0.0060, 0.0084, 0.0245, 0.0178, 0.0452, 0.0381, 0.0630, 0.0647,
        0.0620, 0.1497, 0.1433, 0.1187], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,098][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([3.3225e-02, 6.4432e-04, 2.5295e-04, 6.7793e-03, 3.7857e-04, 1.2963e-02,
        1.8903e-02, 7.4257e-02, 4.0175e-02, 2.6913e-02, 1.4444e-01, 6.3083e-01,
        1.0242e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,100][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0160, 0.0137, 0.0135, 0.0584, 0.0497, 0.1163, 0.1508, 0.0415, 0.0274,
        0.1118, 0.1520, 0.0533, 0.0610, 0.1345], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,101][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0629, 0.0700, 0.0743, 0.0703, 0.0731, 0.0704, 0.0685, 0.0699, 0.0688,
        0.0728, 0.0723, 0.0752, 0.0782, 0.0732], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,103][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0291, 0.0585, 0.0736, 0.0750, 0.0889, 0.0707, 0.0775, 0.0788, 0.0662,
        0.0619, 0.0707, 0.0968, 0.0781, 0.0740], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,103][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ said] are: tensor([2.9508e-04, 1.0405e-11, 1.9038e-10, 5.2712e-08, 6.9138e-06, 1.4671e-06,
        2.9503e-06, 5.3522e-04, 5.1041e-05, 2.6864e-06, 7.2123e-04, 2.9501e-01,
        7.0491e-02, 6.3288e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,104][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0029, 0.0353, 0.0619, 0.0544, 0.0676, 0.0528, 0.0560, 0.0915, 0.0943,
        0.0903, 0.1086, 0.0949, 0.1070, 0.0825], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,104][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0869, 0.0307, 0.0148, 0.0736, 0.0096, 0.0725, 0.0878, 0.0813, 0.0660,
        0.0533, 0.1209, 0.1157, 0.0139, 0.1731], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,104][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ said] are: tensor([2.4670e-01, 3.0471e-04, 4.1657e-04, 3.3632e-03, 1.0222e-03, 4.7266e-03,
        9.3790e-03, 3.9177e-02, 1.3044e-02, 1.5856e-02, 9.5573e-02, 1.7284e-01,
        2.6278e-02, 3.7133e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,105][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ said] are: tensor([2.9752e-02, 5.0878e-06, 2.7752e-06, 2.0531e-04, 1.0249e-05, 7.0176e-04,
        1.4786e-03, 4.3492e-03, 3.6450e-03, 6.5537e-03, 3.4120e-02, 1.2521e-01,
        1.9926e-03, 7.9197e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,105][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ said] are: tensor([2.2585e-01, 1.8327e-04, 2.3691e-05, 1.9020e-03, 5.2825e-05, 2.1852e-03,
        3.1253e-03, 1.7936e-02, 9.0311e-03, 2.0952e-02, 1.3408e-01, 1.0968e-01,
        4.1308e-03, 4.7086e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,106][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1204, 0.0015, 0.0005, 0.0096, 0.0012, 0.0068, 0.0094, 0.0482, 0.0118,
        0.0214, 0.1083, 0.3179, 0.0159, 0.3272], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,107][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.3906, 0.0076, 0.0048, 0.0175, 0.0085, 0.0374, 0.0273, 0.0333, 0.0292,
        0.0357, 0.0748, 0.0936, 0.0345, 0.2052], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,108][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ said] are: tensor([9.8562e-02, 7.6707e-04, 1.2595e-04, 6.3106e-03, 1.4507e-04, 6.7147e-03,
        1.0495e-02, 7.0953e-02, 1.8025e-02, 1.3627e-02, 9.4134e-02, 4.0658e-01,
        2.5653e-03, 2.7099e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,110][circuit_model.py][line:2294][INFO] ##3-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0164, 0.0156, 0.0170, 0.0567, 0.0462, 0.0994, 0.1367, 0.0414, 0.0269,
        0.0960, 0.1223, 0.0497, 0.0548, 0.1024, 0.1185], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,112][circuit_model.py][line:2297][INFO] ##3-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0581, 0.0657, 0.0700, 0.0648, 0.0677, 0.0655, 0.0633, 0.0651, 0.0648,
        0.0689, 0.0673, 0.0701, 0.0742, 0.0687, 0.0658], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,113][circuit_model.py][line:2300][INFO] ##3-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0294, 0.0561, 0.0693, 0.0685, 0.0775, 0.0632, 0.0654, 0.0694, 0.0622,
        0.0604, 0.0663, 0.0867, 0.0750, 0.0688, 0.0819], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,114][circuit_model.py][line:2303][INFO] ##3-th layer ##Weight##: The head4 weight for token [ to] are: tensor([6.0192e-05, 3.7305e-12, 2.1003e-11, 8.3481e-09, 6.8706e-07, 1.2758e-06,
        2.4135e-06, 1.5673e-04, 6.1203e-05, 4.9368e-07, 9.3959e-05, 1.8896e-02,
        1.2543e-02, 9.4795e-01, 2.0235e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,114][circuit_model.py][line:2306][INFO] ##3-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0018, 0.0272, 0.0590, 0.0457, 0.0610, 0.0482, 0.0525, 0.0810, 0.0854,
        0.0784, 0.0985, 0.0859, 0.1021, 0.0746, 0.0986], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,114][circuit_model.py][line:2309][INFO] ##3-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.1745, 0.0276, 0.0112, 0.0607, 0.0055, 0.0384, 0.0558, 0.0604, 0.0413,
        0.0474, 0.0874, 0.0717, 0.0078, 0.1246, 0.1857], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,115][circuit_model.py][line:2312][INFO] ##3-th layer ##Weight##: The head7 weight for token [ to] are: tensor([3.3456e-01, 1.2183e-04, 1.3548e-04, 1.1209e-03, 4.9766e-04, 2.8385e-03,
        5.5178e-03, 1.4450e-02, 5.6244e-03, 7.2795e-03, 3.0909e-02, 7.7487e-02,
        1.3844e-02, 1.9711e-01, 3.0850e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,115][circuit_model.py][line:2315][INFO] ##3-th layer ##Weight##: The head8 weight for token [ to] are: tensor([2.5990e-02, 1.6022e-06, 9.7224e-07, 4.0579e-05, 5.6546e-06, 2.4343e-04,
        3.8065e-04, 3.4355e-03, 1.6789e-03, 1.7277e-03, 7.4471e-03, 3.5699e-02,
        1.5030e-03, 4.9363e-01, 4.2822e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,116][circuit_model.py][line:2318][INFO] ##3-th layer ##Weight##: The head9 weight for token [ to] are: tensor([1.3026e-01, 5.2815e-05, 5.3561e-06, 4.7703e-04, 1.7867e-05, 6.5028e-04,
        1.1534e-03, 5.9668e-03, 2.7425e-03, 5.4041e-03, 2.7139e-02, 6.6484e-02,
        1.7204e-03, 3.1605e-01, 4.4188e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,116][circuit_model.py][line:2321][INFO] ##3-th layer ##Weight##: The head10 weight for token [ to] are: tensor([9.2984e-02, 9.5413e-04, 4.1143e-04, 5.1339e-03, 3.3359e-04, 4.1870e-03,
        5.8564e-03, 2.1803e-02, 2.0834e-02, 1.2958e-02, 6.2070e-02, 8.5259e-02,
        5.7611e-03, 5.5398e-01, 1.2748e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,118][circuit_model.py][line:2324][INFO] ##3-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3630, 0.0039, 0.0022, 0.0112, 0.0045, 0.0255, 0.0191, 0.0259, 0.0259,
        0.0303, 0.0497, 0.0702, 0.0230, 0.1626, 0.1828], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,120][circuit_model.py][line:2327][INFO] ##3-th layer ##Weight##: The head12 weight for token [ to] are: tensor([1.1723e-01, 5.5113e-04, 1.7528e-04, 3.7413e-03, 2.6307e-04, 2.9265e-03,
        8.7583e-03, 5.4728e-02, 1.7525e-02, 1.2124e-02, 5.8754e-02, 1.3142e-01,
        6.0210e-03, 2.6617e-01, 3.1961e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,154][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:17,155][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,156][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,157][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,158][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,158][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,159][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,159][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,159][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,159][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,160][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,160][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,160][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,161][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4436, 0.5564], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,162][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6771, 0.3229], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,163][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.9425, 0.0575], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,163][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5441, 0.4559], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,163][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3106, 0.6894], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,175][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8179, 0.1821], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,177][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9511, 0.0489], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,178][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8788, 0.1212], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,179][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.8385, 0.1615], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,180][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9217, 0.0783], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,180][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9597, 0.0403], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,180][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8266, 0.1734], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,181][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.0029, 0.0124, 0.9847], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,181][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([0.3775, 0.4811, 0.1414], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,181][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.7246, 0.1665, 0.1088], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,182][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.3244, 0.6020, 0.0736], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,182][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.0461, 0.8921, 0.0619], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,183][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.2228, 0.3975, 0.3796], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,185][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.6848, 0.1684, 0.1469], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,186][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.5872, 0.3324, 0.0804], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,188][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.7794, 0.1866, 0.0340], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,189][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.6118, 0.1434, 0.2447], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,190][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.7458, 0.0645, 0.1897], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,190][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.6688, 0.2333, 0.0978], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,190][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0636, 0.2366, 0.5639, 0.1359], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,191][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4978, 0.1532, 0.0739, 0.2751], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,191][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6811, 0.0366, 0.0599, 0.2224], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,191][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5122, 0.0466, 0.0156, 0.4257], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,192][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0806, 0.2791, 0.0614, 0.5789], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,192][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5291, 0.1615, 0.0858, 0.2237], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,194][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.8663, 0.0110, 0.0357, 0.0870], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,195][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6052, 0.0068, 0.0291, 0.3589], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,197][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6943, 0.0508, 0.0265, 0.2284], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,198][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.5309, 0.0957, 0.0915, 0.2819], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,200][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7140, 0.0483, 0.0588, 0.1789], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,200][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5323, 0.0784, 0.0318, 0.3575], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,200][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0032, 0.0275, 0.0249, 0.0317, 0.9126], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,201][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.1376, 0.1269, 0.0435, 0.5820, 0.1100], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,201][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.3656, 0.0351, 0.0259, 0.5008, 0.0726], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,201][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1435, 0.0369, 0.0145, 0.6652, 0.1399], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,202][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([7.2017e-03, 2.5555e-01, 8.0106e-02, 6.5668e-01, 4.5464e-04],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,202][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.1828, 0.2138, 0.2103, 0.3153, 0.0778], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,203][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.3875, 0.0529, 0.0703, 0.2677, 0.2217], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,205][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.1587, 0.0254, 0.0296, 0.7268, 0.0595], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,206][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.2939, 0.0365, 0.0121, 0.6309, 0.0266], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,208][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.2928, 0.0432, 0.1202, 0.3527, 0.1911], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,209][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.5557, 0.0296, 0.0661, 0.1979, 0.1507], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,210][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.2571, 0.0825, 0.0384, 0.5818, 0.0402], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,210][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0264, 0.2212, 0.1722, 0.1463, 0.0443, 0.3896], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,211][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.2371, 0.0930, 0.0190, 0.2870, 0.0480, 0.3158], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,211][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.5608, 0.0257, 0.0181, 0.1919, 0.0700, 0.1335], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,212][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1358, 0.0069, 0.0016, 0.1264, 0.0365, 0.6929], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,212][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0128, 0.3232, 0.0335, 0.5798, 0.0027, 0.0480], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,212][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1930, 0.1541, 0.0681, 0.3304, 0.0381, 0.2164], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,213][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.3733, 0.0219, 0.0380, 0.1574, 0.1432, 0.2661], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,213][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1885, 0.0034, 0.0042, 0.1422, 0.0405, 0.6212], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,215][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3920, 0.0354, 0.0055, 0.2877, 0.0251, 0.2544], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,217][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3261, 0.1108, 0.0256, 0.2471, 0.0470, 0.2435], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,218][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.5089, 0.0324, 0.0259, 0.1067, 0.0664, 0.2597], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,219][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.3928, 0.0463, 0.0114, 0.2545, 0.0217, 0.2733], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,220][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0218, 0.2873, 0.3235, 0.1783, 0.0257, 0.0669, 0.0966],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,221][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2208, 0.0692, 0.0189, 0.1859, 0.0404, 0.2190, 0.2457],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,221][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.3895, 0.0106, 0.0072, 0.0998, 0.0293, 0.2223, 0.2414],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,221][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0909, 0.0028, 0.0007, 0.0383, 0.0075, 0.6287, 0.2312],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,222][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0296, 0.2314, 0.0299, 0.5770, 0.0035, 0.0831, 0.0454],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,222][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2140, 0.1229, 0.0538, 0.2269, 0.0282, 0.1560, 0.1982],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,223][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.5074, 0.0085, 0.0116, 0.0652, 0.0597, 0.1590, 0.1886],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,223][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1538, 0.0025, 0.0024, 0.0656, 0.0143, 0.4450, 0.3165],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,224][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4029, 0.0187, 0.0032, 0.1376, 0.0102, 0.1636, 0.2639],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,226][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2818, 0.0402, 0.0289, 0.1920, 0.0291, 0.2403, 0.1878],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,227][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.5145, 0.0258, 0.0178, 0.0830, 0.0397, 0.1673, 0.1520],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,229][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.3815, 0.0293, 0.0071, 0.1419, 0.0123, 0.1809, 0.2471],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,230][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0445, 0.2353, 0.0858, 0.1776, 0.0396, 0.0849, 0.0420, 0.2903],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,231][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.2447, 0.0321, 0.0063, 0.1007, 0.0152, 0.1341, 0.1845, 0.2824],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,231][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.2494, 0.0020, 0.0008, 0.0252, 0.0019, 0.0575, 0.1818, 0.4813],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,232][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([3.6485e-02, 5.6254e-04, 7.3803e-05, 1.2475e-02, 8.7692e-04, 1.5163e-01,
        9.4838e-02, 7.0306e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,232][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0424, 0.2123, 0.0343, 0.6007, 0.0028, 0.0533, 0.0374, 0.0169],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,232][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2655, 0.0810, 0.0402, 0.1528, 0.0205, 0.1087, 0.1612, 0.1702],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,233][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.4709, 0.0024, 0.0027, 0.0226, 0.0128, 0.0713, 0.1297, 0.2876],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,233][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([1.2805e-01, 3.8207e-04, 4.1389e-04, 1.8582e-02, 3.3628e-03, 1.5713e-01,
        1.7498e-01, 5.1709e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,234][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.2740, 0.0057, 0.0007, 0.0463, 0.0021, 0.0923, 0.1398, 0.4390],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,236][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.1533, 0.0113, 0.0039, 0.0638, 0.0064, 0.0885, 0.1106, 0.5622],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,237][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.5419, 0.0106, 0.0066, 0.0491, 0.0142, 0.1040, 0.0821, 0.1915],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,239][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.2607, 0.0080, 0.0016, 0.0451, 0.0027, 0.0514, 0.1328, 0.4976],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,240][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0129, 0.2076, 0.1337, 0.1663, 0.0443, 0.0378, 0.0313, 0.0268, 0.3392],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,241][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.1381, 0.0203, 0.0083, 0.0724, 0.0179, 0.0927, 0.1194, 0.3080, 0.2230],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,243][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([1.4171e-01, 7.8677e-04, 5.2638e-04, 9.7542e-03, 1.9963e-03, 3.9589e-02,
        7.7768e-02, 5.8334e-01, 1.4453e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,244][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([3.3539e-02, 3.1203e-04, 2.9078e-05, 3.1570e-03, 5.2066e-04, 4.6320e-02,
        2.5489e-02, 6.6355e-01, 2.2708e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,245][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0308, 0.2272, 0.0317, 0.5485, 0.0056, 0.0644, 0.0521, 0.0241, 0.0156],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,246][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1388, 0.0837, 0.0522, 0.1774, 0.0297, 0.1123, 0.1385, 0.1482, 0.1191],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,246][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1912, 0.0026, 0.0024, 0.0164, 0.0119, 0.0449, 0.0985, 0.5142, 0.1179],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,247][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([4.9339e-02, 1.6691e-04, 1.5388e-04, 3.7304e-03, 1.1376e-03, 3.7402e-02,
        3.6081e-02, 7.2792e-01, 1.4407e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,247][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([1.2545e-01, 2.3498e-03, 4.3923e-04, 1.6646e-02, 1.9526e-03, 3.6876e-02,
        5.4069e-02, 6.2933e-01, 1.3288e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,247][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1589, 0.0071, 0.0083, 0.0481, 0.0108, 0.0868, 0.0624, 0.4266, 0.1911],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,248][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.4788, 0.0151, 0.0098, 0.0466, 0.0229, 0.0780, 0.0784, 0.1435, 0.1269],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,248][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([9.9288e-02, 3.2912e-03, 7.1448e-04, 1.8817e-02, 2.5790e-03, 2.1671e-02,
        5.3550e-02, 7.1499e-01, 8.5103e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,248][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0148, 0.2200, 0.2550, 0.1157, 0.0905, 0.0709, 0.0357, 0.0416, 0.0709,
        0.0849], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,249][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1183, 0.0084, 0.0049, 0.0387, 0.0092, 0.0509, 0.0895, 0.2092, 0.2131,
        0.2579], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,249][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([1.5941e-01, 3.2603e-04, 4.6759e-04, 7.1849e-03, 1.3604e-03, 1.8631e-02,
        5.4013e-02, 4.5341e-01, 2.1948e-01, 8.5711e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,250][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([3.4690e-02, 5.6581e-05, 2.6250e-05, 1.1096e-03, 3.9487e-04, 1.8125e-02,
        1.9832e-02, 6.7853e-01, 1.1693e-01, 1.3031e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,252][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0208, 0.2280, 0.0283, 0.5164, 0.0018, 0.0564, 0.0281, 0.0141, 0.0252,
        0.0809], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,254][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2032, 0.0708, 0.0290, 0.1409, 0.0148, 0.0962, 0.1193, 0.1402, 0.0981,
        0.0874], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,255][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3463, 0.0011, 0.0024, 0.0129, 0.0098, 0.0364, 0.0760, 0.2946, 0.1216,
        0.0989], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,256][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([6.3566e-02, 4.2557e-05, 9.5455e-05, 2.1128e-03, 6.6345e-04, 2.6164e-02,
        2.8982e-02, 5.0356e-01, 2.0502e-01, 1.6979e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,257][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([1.4881e-01, 1.1055e-03, 2.1053e-04, 1.0513e-02, 5.1864e-04, 2.3359e-02,
        6.5574e-02, 2.7796e-01, 2.5220e-01, 2.1975e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,257][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.2401, 0.0049, 0.0129, 0.0430, 0.0098, 0.0248, 0.0566, 0.3835, 0.1408,
        0.0835], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,258][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.3958, 0.0139, 0.0092, 0.0360, 0.0219, 0.0826, 0.0741, 0.1367, 0.0983,
        0.1314], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,258][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1027, 0.0032, 0.0013, 0.0260, 0.0022, 0.0276, 0.0649, 0.5092, 0.1438,
        0.1191], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,258][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0129, 0.1990, 0.2640, 0.1188, 0.0529, 0.0678, 0.0289, 0.0315, 0.0489,
        0.0937, 0.0818], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,259][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1453, 0.0078, 0.0033, 0.0142, 0.0060, 0.0302, 0.0475, 0.1349, 0.1380,
        0.1785, 0.2943], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,259][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([1.6172e-01, 3.6141e-04, 2.9259e-04, 2.2591e-03, 8.6293e-04, 1.1822e-02,
        2.8815e-02, 2.5262e-01, 1.2430e-01, 1.0522e-01, 3.1172e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,260][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([4.3753e-02, 7.4612e-05, 1.2591e-05, 6.8354e-04, 3.6366e-04, 1.1203e-02,
        8.6046e-03, 3.6627e-01, 6.5185e-02, 1.1731e-01, 3.8653e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,262][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0189, 0.1812, 0.0221, 0.4954, 0.0018, 0.0535, 0.0253, 0.0121, 0.0203,
        0.0751, 0.0944], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,264][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1916, 0.0624, 0.0251, 0.1049, 0.0117, 0.0788, 0.1076, 0.1207, 0.0739,
        0.0806, 0.1426], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,265][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4932, 0.0006, 0.0012, 0.0044, 0.0058, 0.0210, 0.0440, 0.1323, 0.0526,
        0.0656, 0.1795], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,266][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([1.0219e-01, 2.8882e-05, 6.5617e-05, 1.3582e-03, 4.8475e-04, 1.6477e-02,
        1.5459e-02, 2.4405e-01, 1.0826e-01, 1.0529e-01, 4.0634e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,267][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([1.7201e-01, 5.0877e-04, 1.4344e-04, 3.1232e-03, 2.5272e-04, 1.0304e-02,
        2.4550e-02, 1.3569e-01, 8.9197e-02, 1.4156e-01, 4.2266e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,267][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2212, 0.0059, 0.0029, 0.0191, 0.0031, 0.0220, 0.0377, 0.1990, 0.0880,
        0.0956, 0.3055], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,268][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4068, 0.0123, 0.0086, 0.0301, 0.0165, 0.0688, 0.0567, 0.0934, 0.0679,
        0.0956, 0.1434], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,268][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1518, 0.0026, 0.0007, 0.0136, 0.0013, 0.0227, 0.0449, 0.2864, 0.0993,
        0.0821, 0.2944], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,269][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0205, 0.1975, 0.0788, 0.1303, 0.0110, 0.0502, 0.0343, 0.1294, 0.0546,
        0.0890, 0.0717, 0.1326], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,269][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.1684, 0.0056, 0.0029, 0.0190, 0.0069, 0.0281, 0.0459, 0.1306, 0.0715,
        0.1106, 0.2701, 0.1404], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,270][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([1.3012e-01, 2.0079e-04, 8.0519e-05, 2.9567e-03, 2.4541e-04, 4.5112e-03,
        1.1208e-02, 7.8836e-02, 3.1757e-02, 2.9410e-02, 2.5762e-01, 4.5306e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,270][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([1.9207e-02, 2.7383e-05, 1.6994e-06, 4.7913e-04, 4.6298e-05, 4.7337e-03,
        1.8177e-03, 7.9193e-02, 7.7753e-03, 2.4977e-02, 1.5585e-01, 7.0589e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,272][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0483, 0.1202, 0.0172, 0.4233, 0.0027, 0.0493, 0.0395, 0.0265, 0.0367,
        0.0737, 0.1269, 0.0358], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,274][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.2374, 0.0296, 0.0360, 0.0766, 0.0203, 0.0758, 0.1014, 0.1119, 0.0562,
        0.0553, 0.1304, 0.0691], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,275][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.3034, 0.0006, 0.0006, 0.0047, 0.0024, 0.0201, 0.0236, 0.0966, 0.0269,
        0.0307, 0.1436, 0.3468], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,276][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([2.2658e-02, 2.9961e-05, 1.8948e-05, 9.7812e-04, 2.0204e-04, 8.1784e-03,
        8.0074e-03, 8.8164e-02, 2.3609e-02, 3.9885e-02, 1.9855e-01, 6.0972e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,277][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([1.2564e-01, 3.5903e-04, 5.5904e-05, 4.5743e-03, 2.3033e-04, 7.4280e-03,
        8.3321e-03, 5.4269e-02, 2.2706e-02, 7.5994e-02, 3.6937e-01, 3.3104e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,278][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1971, 0.0021, 0.0023, 0.0125, 0.0037, 0.0162, 0.0165, 0.1544, 0.0366,
        0.0321, 0.1510, 0.3756], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,278][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.3737, 0.0077, 0.0038, 0.0297, 0.0088, 0.0419, 0.0354, 0.0602, 0.0331,
        0.0524, 0.1329, 0.2203], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,278][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([1.1452e-01, 1.1909e-03, 3.4820e-04, 7.3695e-03, 1.0962e-03, 9.9902e-03,
        1.9474e-02, 1.9682e-01, 3.7461e-02, 2.5737e-02, 1.1614e-01, 4.6986e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,279][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([5.5753e-04, 2.1529e-02, 8.2803e-03, 1.7668e-02, 5.3186e-01, 3.7711e-03,
        2.1730e-03, 2.5083e-03, 3.6693e-03, 1.3014e-02, 8.4801e-03, 4.9391e-04,
        3.8600e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,279][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0132, 0.0022, 0.0007, 0.0125, 0.0014, 0.0223, 0.0291, 0.0568, 0.0633,
        0.1209, 0.2807, 0.3396, 0.0576], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,280][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([3.0307e-02, 4.5838e-05, 2.7174e-05, 1.1318e-03, 9.2926e-05, 4.3270e-03,
        9.5341e-03, 5.5240e-02, 2.1696e-02, 2.4002e-02, 1.7120e-01, 6.6189e-01,
        2.0507e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,280][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([5.1487e-03, 9.0155e-06, 2.5671e-06, 2.1529e-04, 1.9462e-05, 2.5169e-03,
        2.0590e-03, 2.1722e-02, 2.0233e-02, 2.3531e-02, 1.8183e-01, 7.1431e-01,
        2.8401e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,282][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0055, 0.2271, 0.0631, 0.4588, 0.0005, 0.0218, 0.0296, 0.0122, 0.0131,
        0.0706, 0.0837, 0.0134, 0.0007], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,284][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0855, 0.0504, 0.0567, 0.0854, 0.0215, 0.0906, 0.0955, 0.0915, 0.0589,
        0.0650, 0.1010, 0.1660, 0.0321], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,286][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0954, 0.0005, 0.0008, 0.0037, 0.0021, 0.0095, 0.0193, 0.0788, 0.0352,
        0.0406, 0.1794, 0.4204, 0.1144], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,286][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([2.5491e-03, 4.8986e-06, 4.4662e-06, 1.4043e-04, 7.0417e-06, 1.8164e-03,
        1.9786e-03, 4.0851e-02, 1.3182e-02, 1.2799e-02, 6.2186e-02, 8.6036e-01,
        4.1200e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,287][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([1.3656e-02, 5.6472e-05, 1.3986e-05, 1.1504e-03, 2.3745e-05, 2.3692e-03,
        4.9414e-03, 3.6818e-02, 1.9218e-02, 2.8093e-02, 1.5855e-01, 7.2954e-01,
        5.5727e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,288][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0626, 0.0008, 0.0015, 0.0090, 0.0026, 0.0072, 0.0174, 0.0854, 0.0257,
        0.0380, 0.1939, 0.4928, 0.0632], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,288][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.2586, 0.0060, 0.0084, 0.0245, 0.0178, 0.0452, 0.0381, 0.0630, 0.0647,
        0.0620, 0.1497, 0.1433, 0.1187], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,289][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([3.3225e-02, 6.4432e-04, 2.5295e-04, 6.7793e-03, 3.7857e-04, 1.2963e-02,
        1.8903e-02, 7.4257e-02, 4.0175e-02, 2.6913e-02, 1.4444e-01, 6.3083e-01,
        1.0242e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,289][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0076, 0.1849, 0.0644, 0.1170, 0.0287, 0.0481, 0.0268, 0.0338, 0.0672,
        0.1202, 0.0891, 0.0221, 0.0266, 0.1635], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,290][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([9.6597e-02, 2.4898e-03, 3.7311e-04, 1.0541e-02, 1.1821e-03, 1.0315e-02,
        1.2817e-02, 3.8496e-02, 1.4971e-02, 5.0521e-02, 1.7770e-01, 1.2764e-01,
        3.0534e-02, 4.2583e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,290][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([1.5597e-01, 7.1706e-05, 2.5115e-05, 7.4750e-04, 6.6984e-05, 1.1111e-03,
        2.2885e-03, 1.1440e-02, 5.9263e-03, 8.0795e-03, 5.7414e-02, 1.0701e-01,
        5.7282e-03, 6.4412e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,291][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([1.0750e-02, 4.1098e-06, 4.8001e-07, 7.5789e-05, 4.7544e-06, 3.3281e-04,
        2.4369e-04, 4.3292e-03, 6.4352e-04, 3.6563e-03, 2.3907e-02, 1.0723e-01,
        1.9696e-03, 8.4685e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,292][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0153, 0.1988, 0.0181, 0.4182, 0.0031, 0.0438, 0.0212, 0.0140, 0.0178,
        0.0648, 0.0912, 0.0313, 0.0029, 0.0593], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,294][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0869, 0.0307, 0.0148, 0.0736, 0.0096, 0.0725, 0.0878, 0.0813, 0.0660,
        0.0533, 0.1209, 0.1157, 0.0139, 0.1731], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,295][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([2.4670e-01, 3.0471e-04, 4.1657e-04, 3.3632e-03, 1.0222e-03, 4.7266e-03,
        9.3790e-03, 3.9177e-02, 1.3044e-02, 1.5856e-02, 9.5573e-02, 1.7284e-01,
        2.6278e-02, 3.7133e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,296][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([2.9752e-02, 5.0878e-06, 2.7752e-06, 2.0531e-04, 1.0249e-05, 7.0176e-04,
        1.4786e-03, 4.3492e-03, 3.6450e-03, 6.5537e-03, 3.4120e-02, 1.2521e-01,
        1.9926e-03, 7.9197e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,297][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([2.2585e-01, 1.8327e-04, 2.3691e-05, 1.9020e-03, 5.2825e-05, 2.1852e-03,
        3.1253e-03, 1.7936e-02, 9.0311e-03, 2.0952e-02, 1.3408e-01, 1.0968e-01,
        4.1308e-03, 4.7086e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,298][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1204, 0.0015, 0.0005, 0.0096, 0.0012, 0.0068, 0.0094, 0.0482, 0.0118,
        0.0214, 0.1083, 0.3179, 0.0159, 0.3272], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,298][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.3906, 0.0076, 0.0048, 0.0175, 0.0085, 0.0374, 0.0273, 0.0333, 0.0292,
        0.0357, 0.0748, 0.0936, 0.0345, 0.2052], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,299][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([9.8562e-02, 7.6707e-04, 1.2595e-04, 6.3106e-03, 1.4507e-04, 6.7147e-03,
        1.0495e-02, 7.0953e-02, 1.8025e-02, 1.3627e-02, 9.4134e-02, 4.0658e-01,
        2.5653e-03, 2.7099e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,299][circuit_model.py][line:2332][INFO] ##3-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0152, 0.1670, 0.0936, 0.1245, 0.0508, 0.0446, 0.0345, 0.0389, 0.0529,
        0.0853, 0.0718, 0.0254, 0.0427, 0.0755, 0.0774], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,299][circuit_model.py][line:2335][INFO] ##3-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1075, 0.0017, 0.0005, 0.0054, 0.0008, 0.0067, 0.0095, 0.0178, 0.0155,
        0.0233, 0.0686, 0.0461, 0.0171, 0.3343, 0.3453], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,300][circuit_model.py][line:2338][INFO] ##3-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.4749e-01, 1.8344e-05, 8.6905e-06, 2.5935e-04, 3.0782e-05, 4.6915e-04,
        1.3618e-03, 8.6145e-03, 3.3055e-03, 2.8788e-03, 2.1926e-02, 5.2540e-02,
        3.9361e-03, 4.2126e-01, 3.3590e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,300][circuit_model.py][line:2341][INFO] ##3-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([6.8141e-03, 1.0198e-06, 1.1275e-07, 1.4917e-05, 7.1803e-07, 1.8613e-04,
        1.3800e-04, 1.3117e-03, 9.4013e-04, 7.1992e-04, 3.9609e-03, 1.7475e-02,
        3.9256e-04, 7.3892e-01, 2.2912e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,302][circuit_model.py][line:2344][INFO] ##3-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0406, 0.1313, 0.0231, 0.4006, 0.0025, 0.0516, 0.0294, 0.0150, 0.0220,
        0.0606, 0.0900, 0.0287, 0.0021, 0.0454, 0.0571], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,304][circuit_model.py][line:2347][INFO] ##3-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.1745, 0.0276, 0.0112, 0.0607, 0.0055, 0.0384, 0.0558, 0.0604, 0.0413,
        0.0474, 0.0874, 0.0717, 0.0078, 0.1246, 0.1857], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,305][circuit_model.py][line:2350][INFO] ##3-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([3.3456e-01, 1.2183e-04, 1.3548e-04, 1.1209e-03, 4.9766e-04, 2.8385e-03,
        5.5178e-03, 1.4450e-02, 5.6244e-03, 7.2795e-03, 3.0909e-02, 7.7487e-02,
        1.3844e-02, 1.9711e-01, 3.0850e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,306][circuit_model.py][line:2353][INFO] ##3-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([2.5990e-02, 1.6022e-06, 9.7224e-07, 4.0579e-05, 5.6546e-06, 2.4343e-04,
        3.8065e-04, 3.4355e-03, 1.6789e-03, 1.7277e-03, 7.4471e-03, 3.5699e-02,
        1.5030e-03, 4.9363e-01, 4.2822e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,307][circuit_model.py][line:2356][INFO] ##3-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([1.3026e-01, 5.2815e-05, 5.3561e-06, 4.7703e-04, 1.7867e-05, 6.5028e-04,
        1.1534e-03, 5.9668e-03, 2.7425e-03, 5.4041e-03, 2.7139e-02, 6.6484e-02,
        1.7204e-03, 3.1605e-01, 4.4188e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,308][circuit_model.py][line:2359][INFO] ##3-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([9.2984e-02, 9.5413e-04, 4.1143e-04, 5.1339e-03, 3.3359e-04, 4.1870e-03,
        5.8564e-03, 2.1803e-02, 2.0834e-02, 1.2958e-02, 6.2070e-02, 8.5259e-02,
        5.7611e-03, 5.5398e-01, 1.2748e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,308][circuit_model.py][line:2362][INFO] ##3-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3630, 0.0039, 0.0022, 0.0112, 0.0045, 0.0255, 0.0191, 0.0259, 0.0259,
        0.0303, 0.0497, 0.0702, 0.0230, 0.1626, 0.1828], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,308][circuit_model.py][line:2365][INFO] ##3-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([1.1723e-01, 5.5113e-04, 1.7528e-04, 3.7413e-03, 2.6307e-04, 2.9265e-03,
        8.7583e-03, 5.4728e-02, 1.7525e-02, 1.2124e-02, 5.8754e-02, 1.3142e-01,
        6.0210e-03, 2.6617e-01, 3.1961e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,310][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:17,311][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[15790],
        [27808],
        [ 3215],
        [11294],
        [ 4862],
        [ 7019],
        [ 5721],
        [ 9120],
        [ 8435],
        [13782],
        [14888],
        [12887],
        [ 6783],
        [ 7522],
        [10250]], device='cuda:0')
[2024-07-24 10:20:17,313][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[17889],
        [41115],
        [ 9128],
        [21453],
        [12825],
        [19804],
        [14570],
        [23371],
        [19148],
        [23801],
        [24355],
        [21749],
        [11310],
        [15423],
        [18352]], device='cuda:0')
[2024-07-24 10:20:17,314][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[5476],
        [3577],
        [3129],
        [2862],
        [2428],
        [2038],
        [2099],
        [2092],
        [2103],
        [2402],
        [2585],
        [2578],
        [2545],
        [2515],
        [2325]], device='cuda:0')
[2024-07-24 10:20:17,316][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[28673],
        [28444],
        [27305],
        [27483],
        [27406],
        [27027],
        [27019],
        [26853],
        [26507],
        [26540],
        [26744],
        [26944],
        [26809],
        [26664],
        [26742]], device='cuda:0')
[2024-07-24 10:20:17,317][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[30191],
        [29749],
        [27977],
        [28758],
        [27336],
        [26603],
        [27006],
        [26877],
        [26673],
        [27029],
        [27276],
        [27110],
        [26315],
        [26098],
        [26260]], device='cuda:0')
[2024-07-24 10:20:17,319][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[32350],
        [23195],
        [17595],
        [30611],
        [13544],
        [17946],
        [27207],
        [25300],
        [24329],
        [24714],
        [25203],
        [21091],
        [17180],
        [33756],
        [39191]], device='cuda:0')
[2024-07-24 10:20:17,320][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[  816],
        [ 6615],
        [ 5285],
        [ 4682],
        [ 7978],
        [ 9500],
        [10381],
        [11010],
        [11306],
        [10912],
        [11036],
        [10904],
        [11133],
        [11503],
        [11596]], device='cuda:0')
[2024-07-24 10:20:17,321][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[23998],
        [16435],
        [24519],
        [21574],
        [24951],
        [17875],
        [16940],
        [13955],
        [15798],
        [14984],
        [16839],
        [18490],
        [19615],
        [19909],
        [20207]], device='cuda:0')
[2024-07-24 10:20:17,321][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[11391],
        [12450],
        [22572],
        [14052],
        [20773],
        [19169],
        [15073],
        [16570],
        [18174],
        [14821],
        [11774],
        [16075],
        [14110],
        [12828],
        [ 9201]], device='cuda:0')
[2024-07-24 10:20:17,323][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[19256],
        [17656],
        [17107],
        [14685],
        [12976],
        [14301],
        [11270],
        [10047],
        [ 9503],
        [ 9633],
        [10399],
        [19957],
        [24581],
        [22639],
        [17273]], device='cuda:0')
[2024-07-24 10:20:17,325][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[ 9698],
        [ 9258],
        [ 9517],
        [ 7994],
        [ 7512],
        [ 7318],
        [ 9274],
        [19615],
        [26062],
        [21147],
        [13268],
        [19896],
        [30420],
        [16191],
        [18302]], device='cuda:0')
[2024-07-24 10:20:17,326][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[15160],
        [17548],
        [17556],
        [26597],
        [23474],
        [27154],
        [27130],
        [26278],
        [20765],
        [21396],
        [24383],
        [18295],
        [17018],
        [20191],
        [21444]], device='cuda:0')
[2024-07-24 10:20:17,328][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[28173],
        [26465],
        [26237],
        [25138],
        [23632],
        [19867],
        [20426],
        [24157],
        [25187],
        [24533],
        [25787],
        [26690],
        [27372],
        [25314],
        [24497]], device='cuda:0')
[2024-07-24 10:20:17,329][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[31634],
        [32353],
        [34499],
        [33406],
        [33910],
        [30661],
        [21014],
        [17251],
        [17713],
        [20829],
        [26306],
        [35169],
        [38290],
        [33864],
        [33525]], device='cuda:0')
[2024-07-24 10:20:17,330][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[26323],
        [35256],
        [28878],
        [34859],
        [25388],
        [19500],
        [21386],
        [15604],
        [19768],
        [33078],
        [32369],
        [23977],
        [27493],
        [24579],
        [24397]], device='cuda:0')
[2024-07-24 10:20:17,331][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[42522],
        [36186],
        [39283],
        [38049],
        [43162],
        [36957],
        [37367],
        [33283],
        [34424],
        [37081],
        [36552],
        [33471],
        [43841],
        [33880],
        [34973]], device='cuda:0')
[2024-07-24 10:20:17,332][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[11031],
        [15237],
        [12437],
        [11139],
        [11565],
        [10953],
        [ 9255],
        [13554],
        [17311],
        [16832],
        [15958],
        [15246],
        [15639],
        [19047],
        [17410]], device='cuda:0')
[2024-07-24 10:20:17,334][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[17411],
        [16132],
        [12205],
        [12322],
        [10951],
        [13528],
        [10791],
        [16763],
        [17514],
        [15528],
        [16947],
        [19872],
        [23198],
        [10923],
        [11918]], device='cuda:0')
[2024-07-24 10:20:17,335][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1584],
        [1771],
        [2921],
        [1601],
        [1292],
        [2112],
        [3626],
        [1003],
        [ 951],
        [ 984],
        [ 749],
        [3095],
        [3406],
        [4049],
        [3366]], device='cuda:0')
[2024-07-24 10:20:17,337][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31960],
        [18548],
        [15909],
        [13285],
        [12385],
        [13252],
        [12847],
        [12787],
        [12527],
        [12646],
        [12609],
        [12255],
        [12102],
        [12253],
        [12149]], device='cuda:0')
[2024-07-24 10:20:17,338][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[24302],
        [21678],
        [10928],
        [19464],
        [13604],
        [19491],
        [19933],
        [21372],
        [20434],
        [20869],
        [21307],
        [20997],
        [18633],
        [16967],
        [17052]], device='cuda:0')
[2024-07-24 10:20:17,340][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[26681],
        [26606],
        [28902],
        [27346],
        [26612],
        [27356],
        [27865],
        [28737],
        [29348],
        [27340],
        [26243],
        [26768],
        [23639],
        [30365],
        [28072]], device='cuda:0')
[2024-07-24 10:20:17,341][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 3610],
        [ 4913],
        [ 7663],
        [ 8717],
        [13043],
        [14690],
        [18106],
        [20095],
        [21100],
        [20342],
        [14788],
        [19882],
        [19769],
        [ 9030],
        [ 9647]], device='cuda:0')
[2024-07-24 10:20:17,342][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[39114],
        [37703],
        [36706],
        [33228],
        [26846],
        [28477],
        [25383],
        [20817],
        [19462],
        [23670],
        [26696],
        [23154],
        [23068],
        [19224],
        [21603]], device='cuda:0')
[2024-07-24 10:20:17,343][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 5219],
        [ 4873],
        [ 4781],
        [ 4325],
        [ 3094],
        [ 5347],
        [ 5916],
        [13073],
        [ 9486],
        [ 8381],
        [ 5230],
        [12425],
        [12772],
        [10769],
        [ 8241]], device='cuda:0')
[2024-07-24 10:20:17,344][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[14862],
        [15220],
        [24924],
        [ 9161],
        [10640],
        [ 7287],
        [ 5159],
        [ 5490],
        [ 5308],
        [ 5296],
        [ 3562],
        [ 7510],
        [ 8555],
        [10261],
        [ 8907]], device='cuda:0')
[2024-07-24 10:20:17,346][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[5985],
        [6236],
        [6338],
        [6274],
        [6553],
        [4709],
        [3970],
        [5372],
        [6362],
        [6052],
        [6126],
        [7166],
        [7577],
        [5909],
        [6178]], device='cuda:0')
[2024-07-24 10:20:17,347][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[31500],
        [36132],
        [37004],
        [38081],
        [38636],
        [37509],
        [38202],
        [35722],
        [35985],
        [36943],
        [38487],
        [33229],
        [32905],
        [37724],
        [37956]], device='cuda:0')
[2024-07-24 10:20:17,349][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[26417],
        [19022],
        [15224],
        [22534],
        [25614],
        [30682],
        [28830],
        [35336],
        [34521],
        [22327],
        [23375],
        [31064],
        [18104],
        [25964],
        [27870]], device='cuda:0')
[2024-07-24 10:20:17,350][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304],
        [23304]], device='cuda:0')
[2024-07-24 10:20:17,377][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:17,378][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,379][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,380][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,381][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,382][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,382][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,382][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,382][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,383][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,383][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,383][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,384][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,384][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.9461, 0.0539], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,385][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0905, 0.9095], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,386][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.9490, 0.0510], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,386][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9300, 0.0700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,386][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2052, 0.7948], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,387][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.1152, 0.8848], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,387][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4131, 0.5869], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,387][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.5398, 0.4602], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,388][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.9660, 0.0340], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,388][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.9598, 0.0402], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,389][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8566, 0.1434], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,389][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([9.9930e-01, 6.9850e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,390][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.6041, 0.1657, 0.2302], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,390][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.0415, 0.4634, 0.4951], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,390][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.6484, 0.0805, 0.2712], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,391][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.5841, 0.2235, 0.1924], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,392][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.1222, 0.4408, 0.4370], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,393][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.0485, 0.4792, 0.4723], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,395][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.2582, 0.3737, 0.3680], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,396][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.1301, 0.3613, 0.5086], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,397][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.6449, 0.0221, 0.3330], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,397][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.7092, 0.0734, 0.2174], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,397][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.5435, 0.1906, 0.2659], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,398][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.0230, 0.9745, 0.0025], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,398][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7096, 0.0418, 0.0728, 0.1759], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,399][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0287, 0.3029, 0.3244, 0.3440], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,399][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.7873, 0.0604, 0.0774, 0.0748], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,399][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5726, 0.0701, 0.0799, 0.2774], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,399][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0888, 0.3004, 0.3152, 0.2957], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,400][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0405, 0.3282, 0.3159, 0.3153], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,402][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1889, 0.2701, 0.2689, 0.2721], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,403][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0630, 0.1443, 0.1175, 0.6751], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,405][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.5987, 0.0191, 0.3333, 0.0490], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,406][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.7350, 0.0324, 0.0986, 0.1340], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,407][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5163, 0.1040, 0.1510, 0.2287], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,407][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.8484, 0.0014, 0.0111, 0.1392], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,408][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.2607, 0.0918, 0.0911, 0.3423, 0.2142], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,408][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0242, 0.2222, 0.2419, 0.2602, 0.2515], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,408][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.4741, 0.1385, 0.1360, 0.2192, 0.0322], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,409][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.2666, 0.1145, 0.1041, 0.3370, 0.1778], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,409][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0622, 0.2402, 0.2439, 0.2199, 0.2338], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,409][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0191, 0.2533, 0.2540, 0.2489, 0.2247], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,409][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.1497, 0.2121, 0.2096, 0.2150, 0.2136], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,410][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0460, 0.0716, 0.1260, 0.4002, 0.3562], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,410][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.5700, 0.0098, 0.2968, 0.0348, 0.0887], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,412][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.4253, 0.0397, 0.1413, 0.2222, 0.1715], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,414][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.3809, 0.1279, 0.1661, 0.2042, 0.1209], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,415][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0104, 0.0911, 0.0041, 0.8826, 0.0119], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,417][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3052, 0.0567, 0.0464, 0.1813, 0.0974, 0.3129], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,417][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0171, 0.1763, 0.1944, 0.2086, 0.2010, 0.2025], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,418][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.5531, 0.0488, 0.0391, 0.1276, 0.1960, 0.0353], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,418][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1376, 0.0816, 0.0738, 0.2936, 0.1044, 0.3090], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,418][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0416, 0.1786, 0.1989, 0.1846, 0.1921, 0.2041], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,419][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0146, 0.2027, 0.1984, 0.1996, 0.1858, 0.1989], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,419][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1229, 0.1732, 0.1707, 0.1748, 0.1741, 0.1844], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,419][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0265, 0.0579, 0.0574, 0.2711, 0.1441, 0.4430], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,419][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3874, 0.0122, 0.4002, 0.0426, 0.1307, 0.0269], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,420][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.3770, 0.0396, 0.0916, 0.1407, 0.1194, 0.2317], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,420][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.3133, 0.1062, 0.1428, 0.2089, 0.0659, 0.1629], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,422][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0474, 0.0038, 0.0021, 0.2161, 0.0205, 0.7102], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,423][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1604, 0.0478, 0.0397, 0.1255, 0.0633, 0.2688, 0.2946],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,425][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0149, 0.1479, 0.1622, 0.1719, 0.1675, 0.1698, 0.1659],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,426][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.5188, 0.0354, 0.0475, 0.0762, 0.1789, 0.0860, 0.0573],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,428][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.1810, 0.0467, 0.0483, 0.1725, 0.0817, 0.1933, 0.2765],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,428][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0360, 0.1472, 0.1615, 0.1554, 0.1553, 0.1698, 0.1747],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,428][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0177, 0.1662, 0.1623, 0.1609, 0.1473, 0.1595, 0.1861],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,429][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1044, 0.1480, 0.1454, 0.1485, 0.1491, 0.1572, 0.1472],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,429][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0268, 0.0673, 0.0484, 0.1900, 0.1155, 0.3045, 0.2475],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,429][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4392, 0.0104, 0.2929, 0.0376, 0.1002, 0.0363, 0.0835],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,429][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.3477, 0.0253, 0.0623, 0.0989, 0.0901, 0.1661, 0.2096],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,430][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3133, 0.0867, 0.1325, 0.1784, 0.0625, 0.1242, 0.1024],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,430][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ a] are: tensor([1.5418e-02, 4.6216e-04, 1.1905e-03, 2.6531e-02, 7.0321e-03, 2.9405e-01,
        6.5531e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,430][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1242, 0.0221, 0.0181, 0.0831, 0.0353, 0.1853, 0.2106, 0.3214],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,432][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0122, 0.1283, 0.1400, 0.1490, 0.1419, 0.1480, 0.1450, 0.1357],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,434][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.3292, 0.0457, 0.0439, 0.1414, 0.0777, 0.1584, 0.1388, 0.0649],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,435][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1107, 0.0298, 0.0261, 0.1320, 0.0461, 0.1452, 0.2265, 0.2836],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,436][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0367, 0.1289, 0.1362, 0.1296, 0.1287, 0.1393, 0.1464, 0.1541],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,438][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0136, 0.1485, 0.1385, 0.1426, 0.1242, 0.1372, 0.1634, 0.1320],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,438][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0893, 0.1273, 0.1254, 0.1286, 0.1289, 0.1368, 0.1291, 0.1345],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,439][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0160, 0.0314, 0.0296, 0.1408, 0.0766, 0.2132, 0.1600, 0.3325],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,439][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.4180, 0.0113, 0.2731, 0.0424, 0.1017, 0.0291, 0.0953, 0.0290],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,439][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.2185, 0.0205, 0.0393, 0.0783, 0.0636, 0.1431, 0.1874, 0.2493],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,439][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.2621, 0.0774, 0.1279, 0.1691, 0.0519, 0.1228, 0.0959, 0.0928],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,440][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ long] are: tensor([2.9632e-03, 1.4192e-05, 9.3445e-05, 4.8430e-03, 8.6674e-04, 3.5456e-02,
        2.0439e-01, 7.5138e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,440][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0599, 0.0225, 0.0157, 0.0569, 0.0245, 0.1395, 0.1493, 0.3211, 0.2106],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,440][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0086, 0.1113, 0.1234, 0.1313, 0.1271, 0.1320, 0.1264, 0.1210, 0.1188],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,441][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.2295, 0.0593, 0.1021, 0.1117, 0.0386, 0.1283, 0.1442, 0.1225, 0.0637],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,443][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0822, 0.0331, 0.0291, 0.1102, 0.0437, 0.1151, 0.1720, 0.2595, 0.1552],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,445][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0355, 0.1161, 0.1170, 0.1112, 0.1136, 0.1217, 0.1282, 0.1330, 0.1235],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,446][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0106, 0.1310, 0.1217, 0.1253, 0.1112, 0.1257, 0.1480, 0.1226, 0.1040],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,447][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0766, 0.1125, 0.1114, 0.1146, 0.1149, 0.1222, 0.1152, 0.1211, 0.1114],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,448][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0109, 0.0372, 0.0293, 0.1079, 0.0622, 0.1605, 0.1193, 0.2797, 0.1931],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,449][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.4328, 0.0076, 0.2439, 0.0330, 0.0998, 0.0257, 0.0915, 0.0297, 0.0361],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,449][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1767, 0.0140, 0.0363, 0.0614, 0.0591, 0.1059, 0.1561, 0.2539, 0.1367],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,449][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2460, 0.0710, 0.1206, 0.1463, 0.0591, 0.0985, 0.0962, 0.0867, 0.0757],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,450][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([4.1471e-04, 8.9559e-05, 3.7484e-05, 1.3310e-03, 2.9453e-04, 1.3846e-02,
        5.9005e-02, 8.9944e-01, 2.5538e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,450][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0869, 0.0143, 0.0164, 0.0452, 0.0296, 0.0953, 0.1252, 0.2457, 0.1711,
        0.1702], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,450][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0090, 0.1020, 0.1061, 0.1132, 0.1119, 0.1168, 0.1118, 0.1057, 0.1009,
        0.1226], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,451][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.7643, 0.0080, 0.0366, 0.0387, 0.0254, 0.0262, 0.0193, 0.0333, 0.0412,
        0.0070], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,451][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1150, 0.0167, 0.0202, 0.0741, 0.0376, 0.0960, 0.1473, 0.2278, 0.1212,
        0.1441], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,451][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0288, 0.1004, 0.1043, 0.1017, 0.0987, 0.1081, 0.1119, 0.1188, 0.1124,
        0.1149], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,453][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0148, 0.1163, 0.1100, 0.1108, 0.1002, 0.1098, 0.1257, 0.1084, 0.0933,
        0.1107], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,455][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0705, 0.1014, 0.1008, 0.1021, 0.1041, 0.1090, 0.1025, 0.1089, 0.1002,
        0.1005], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,456][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0113, 0.0346, 0.0249, 0.0901, 0.0520, 0.1203, 0.0978, 0.2445, 0.1419,
        0.1826], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,458][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4041, 0.0095, 0.2757, 0.0333, 0.1000, 0.0269, 0.0879, 0.0296, 0.0258,
        0.0073], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,458][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1836, 0.0123, 0.0335, 0.0538, 0.0522, 0.0973, 0.1231, 0.2002, 0.1269,
        0.1172], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,459][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2022, 0.0767, 0.1064, 0.1499, 0.0420, 0.0992, 0.0814, 0.0782, 0.0666,
        0.0974], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,459][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [,] are: tensor([1.6844e-03, 2.5670e-05, 5.4503e-05, 3.6871e-04, 2.6781e-04, 5.8945e-03,
        3.9715e-02, 8.9635e-01, 3.3179e-02, 2.2457e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,460][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0838, 0.0123, 0.0129, 0.0365, 0.0231, 0.0819, 0.1061, 0.1914, 0.1284,
        0.1499, 0.1738], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,460][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0084, 0.0905, 0.0951, 0.1016, 0.1000, 0.1033, 0.0993, 0.0931, 0.0893,
        0.1093, 0.1102], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,460][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4811, 0.0263, 0.0617, 0.0482, 0.0577, 0.0300, 0.0352, 0.1125, 0.0691,
        0.0258, 0.0524], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,461][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1104, 0.0152, 0.0171, 0.0593, 0.0314, 0.0826, 0.1305, 0.1868, 0.0953,
        0.1233, 0.1482], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,461][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0244, 0.0882, 0.0947, 0.0915, 0.0904, 0.0985, 0.1019, 0.1084, 0.1029,
        0.1035, 0.0956], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,462][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0137, 0.1056, 0.0993, 0.0998, 0.0893, 0.0970, 0.1124, 0.0967, 0.0826,
        0.1008, 0.1029], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,463][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0649, 0.0926, 0.0918, 0.0929, 0.0943, 0.0988, 0.0929, 0.0989, 0.0912,
        0.0919, 0.0899], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,465][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0106, 0.0270, 0.0195, 0.0844, 0.0420, 0.0970, 0.0835, 0.2015, 0.1120,
        0.1477, 0.1748], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,467][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3673, 0.0102, 0.2994, 0.0310, 0.0997, 0.0284, 0.0899, 0.0289, 0.0236,
        0.0076, 0.0140], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,468][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1911, 0.0125, 0.0284, 0.0459, 0.0436, 0.0826, 0.1080, 0.1640, 0.1004,
        0.1088, 0.1148], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,469][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.2053, 0.0689, 0.0962, 0.1365, 0.0390, 0.0835, 0.0728, 0.0666, 0.0594,
        0.0874, 0.0843], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,469][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ and] are: tensor([6.0484e-03, 2.6018e-05, 8.2710e-05, 7.7791e-04, 3.7091e-04, 4.1889e-03,
        3.9451e-02, 7.3484e-01, 3.1031e-02, 4.7144e-02, 1.3604e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,469][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0442, 0.0121, 0.0082, 0.0319, 0.0164, 0.0674, 0.0769, 0.1482, 0.1015,
        0.1185, 0.1455, 0.2292], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,470][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0077, 0.0801, 0.0856, 0.0916, 0.0894, 0.0926, 0.0895, 0.0849, 0.0814,
        0.1000, 0.1011, 0.0962], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,470][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.1016, 0.0647, 0.0201, 0.0678, 0.0377, 0.0929, 0.1059, 0.1075, 0.1253,
        0.0886, 0.1094, 0.0785], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,471][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0400, 0.0135, 0.0129, 0.0541, 0.0238, 0.0625, 0.0978, 0.1536, 0.0939,
        0.1050, 0.1459, 0.1971], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,471][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0260, 0.0855, 0.0878, 0.0825, 0.0830, 0.0872, 0.0908, 0.0968, 0.0915,
        0.0921, 0.0846, 0.0922], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,471][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0116, 0.0945, 0.0862, 0.0893, 0.0809, 0.0903, 0.1032, 0.0877, 0.0737,
        0.0915, 0.0928, 0.0982], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,472][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0598, 0.0837, 0.0828, 0.0849, 0.0850, 0.0903, 0.0857, 0.0898, 0.0825,
        0.0846, 0.0829, 0.0881], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,474][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0086, 0.0186, 0.0165, 0.0570, 0.0393, 0.0937, 0.0688, 0.1553, 0.0951,
        0.1257, 0.1312, 0.1902], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,475][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.3896, 0.0105, 0.2532, 0.0354, 0.1146, 0.0274, 0.0752, 0.0213, 0.0275,
        0.0115, 0.0170, 0.0167], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,477][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.1345, 0.0114, 0.0274, 0.0445, 0.0366, 0.0762, 0.1065, 0.1385, 0.0939,
        0.0920, 0.1051, 0.1334], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,478][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1998, 0.0600, 0.0942, 0.1206, 0.0422, 0.0825, 0.0699, 0.0684, 0.0596,
        0.0792, 0.0726, 0.0510], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,479][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([2.0680e-03, 2.6276e-05, 1.8205e-05, 1.2405e-03, 1.8119e-04, 1.2248e-02,
        2.8017e-02, 1.9493e-01, 1.8888e-02, 4.0103e-02, 2.5024e-01, 4.5204e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,479][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0327, 0.0081, 0.0078, 0.0291, 0.0158, 0.0605, 0.0849, 0.1257, 0.1107,
        0.1070, 0.1449, 0.1769, 0.0959], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,480][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0081, 0.0725, 0.0792, 0.0851, 0.0815, 0.0836, 0.0820, 0.0783, 0.0763,
        0.0915, 0.0936, 0.0897, 0.0786], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,480][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.1887, 0.0426, 0.0630, 0.0709, 0.0140, 0.0934, 0.0431, 0.0355, 0.1906,
        0.0414, 0.1188, 0.0789, 0.0190], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,481][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0567, 0.0133, 0.0133, 0.0454, 0.0231, 0.0566, 0.0841, 0.1263, 0.0759,
        0.0929, 0.1285, 0.1928, 0.0912], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,481][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0220, 0.0814, 0.0816, 0.0758, 0.0805, 0.0813, 0.0826, 0.0870, 0.0832,
        0.0835, 0.0764, 0.0855, 0.0793], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,481][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0087, 0.0860, 0.0798, 0.0828, 0.0728, 0.0828, 0.0951, 0.0816, 0.0679,
        0.0844, 0.0862, 0.0906, 0.0812], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,483][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0537, 0.0770, 0.0761, 0.0784, 0.0779, 0.0833, 0.0791, 0.0833, 0.0767,
        0.0788, 0.0770, 0.0820, 0.0768], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,485][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0078, 0.0121, 0.0180, 0.0448, 0.0470, 0.0805, 0.0697, 0.1352, 0.0956,
        0.1005, 0.1119, 0.1515, 0.1254], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,486][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.4260, 0.0088, 0.2488, 0.0291, 0.0668, 0.0246, 0.0557, 0.0174, 0.0246,
        0.0067, 0.0134, 0.0297, 0.0485], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,487][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0991, 0.0073, 0.0243, 0.0427, 0.0313, 0.0618, 0.0855, 0.1413, 0.0876,
        0.0844, 0.1034, 0.1402, 0.0911], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,489][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.1663, 0.0687, 0.0858, 0.1038, 0.0599, 0.0688, 0.0666, 0.0743, 0.0602,
        0.0706, 0.0662, 0.0516, 0.0574], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,489][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([8.0778e-05, 5.1344e-05, 5.3599e-06, 6.6140e-04, 1.6570e-05, 1.0127e-02,
        1.7127e-02, 1.5753e-01, 1.4390e-02, 2.8305e-02, 1.2765e-01, 6.3785e-01,
        6.2000e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,489][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0658, 0.0048, 0.0056, 0.0194, 0.0100, 0.0390, 0.0559, 0.1005, 0.0614,
        0.0786, 0.1000, 0.1253, 0.0532, 0.2807], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,490][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0056, 0.0671, 0.0729, 0.0794, 0.0756, 0.0775, 0.0769, 0.0722, 0.0682,
        0.0847, 0.0882, 0.0833, 0.0725, 0.0760], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,490][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.1816, 0.0180, 0.0241, 0.1133, 0.0364, 0.0641, 0.0317, 0.0811, 0.1083,
        0.0165, 0.1473, 0.0659, 0.0443, 0.0675], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,491][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0304, 0.0096, 0.0121, 0.0480, 0.0174, 0.0509, 0.0722, 0.1042, 0.0670,
        0.0865, 0.1118, 0.1487, 0.0511, 0.1901], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,491][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0188, 0.0691, 0.0740, 0.0714, 0.0698, 0.0770, 0.0799, 0.0825, 0.0783,
        0.0802, 0.0746, 0.0781, 0.0691, 0.0772], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,491][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0064, 0.0848, 0.0769, 0.0803, 0.0671, 0.0757, 0.0893, 0.0735, 0.0602,
        0.0760, 0.0795, 0.0841, 0.0731, 0.0731], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,492][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0515, 0.0723, 0.0705, 0.0724, 0.0720, 0.0769, 0.0728, 0.0764, 0.0694,
        0.0722, 0.0708, 0.0755, 0.0708, 0.0765], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,494][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0064, 0.0127, 0.0122, 0.0392, 0.0274, 0.0752, 0.0520, 0.1131, 0.0738,
        0.0892, 0.0888, 0.1323, 0.0614, 0.2164], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,495][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.2907, 0.0079, 0.2776, 0.0271, 0.0973, 0.0220, 0.0612, 0.0183, 0.0270,
        0.0068, 0.0128, 0.0232, 0.0655, 0.0625], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,497][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1169, 0.0064, 0.0184, 0.0312, 0.0233, 0.0499, 0.0708, 0.1050, 0.0814,
        0.0718, 0.0801, 0.1256, 0.0684, 0.1509], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,498][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1765, 0.0568, 0.0823, 0.1101, 0.0393, 0.0719, 0.0658, 0.0606, 0.0544,
        0.0748, 0.0631, 0.0440, 0.0359, 0.0645], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,499][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ said] are: tensor([2.9716e-04, 1.8434e-05, 4.3934e-06, 2.4718e-04, 1.2370e-05, 9.4224e-04,
        2.5564e-03, 2.2164e-02, 1.9081e-03, 4.7660e-03, 2.5432e-02, 7.5584e-02,
        1.9502e-03, 8.6412e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,499][circuit_model.py][line:2294][INFO] ##4-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0537, 0.0048, 0.0054, 0.0165, 0.0075, 0.0309, 0.0440, 0.0675, 0.0521,
        0.0570, 0.0720, 0.0970, 0.0412, 0.2551, 0.1952], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,500][circuit_model.py][line:2297][INFO] ##4-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0055, 0.0640, 0.0684, 0.0729, 0.0706, 0.0726, 0.0710, 0.0659, 0.0631,
        0.0783, 0.0802, 0.0752, 0.0673, 0.0694, 0.0756], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,500][circuit_model.py][line:2300][INFO] ##4-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1808, 0.0158, 0.0353, 0.0653, 0.0925, 0.0219, 0.0266, 0.0654, 0.0668,
        0.0217, 0.0794, 0.1293, 0.1000, 0.0087, 0.0906], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,500][circuit_model.py][line:2303][INFO] ##4-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0658, 0.0076, 0.0085, 0.0318, 0.0151, 0.0378, 0.0630, 0.0800, 0.0463,
        0.0614, 0.0789, 0.1163, 0.0471, 0.1486, 0.1918], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,501][circuit_model.py][line:2306][INFO] ##4-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0176, 0.0650, 0.0697, 0.0666, 0.0669, 0.0701, 0.0721, 0.0767, 0.0740,
        0.0737, 0.0682, 0.0739, 0.0664, 0.0711, 0.0680], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,501][circuit_model.py][line:2309][INFO] ##4-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0090, 0.0763, 0.0707, 0.0722, 0.0633, 0.0698, 0.0807, 0.0676, 0.0572,
        0.0716, 0.0732, 0.0757, 0.0693, 0.0693, 0.0740], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,502][circuit_model.py][line:2312][INFO] ##4-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0479, 0.0673, 0.0661, 0.0676, 0.0682, 0.0719, 0.0675, 0.0713, 0.0654,
        0.0667, 0.0656, 0.0700, 0.0668, 0.0714, 0.0664], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,502][circuit_model.py][line:2315][INFO] ##4-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0063, 0.0115, 0.0097, 0.0367, 0.0231, 0.0548, 0.0461, 0.0966, 0.0601,
        0.0794, 0.0828, 0.1095, 0.0554, 0.1448, 0.1833], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,503][circuit_model.py][line:2318][INFO] ##4-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.3346, 0.0075, 0.2437, 0.0283, 0.0737, 0.0201, 0.0698, 0.0208, 0.0190,
        0.0052, 0.0114, 0.0241, 0.0504, 0.0709, 0.0207], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,504][circuit_model.py][line:2321][INFO] ##4-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1348, 0.0065, 0.0167, 0.0277, 0.0230, 0.0388, 0.0570, 0.0808, 0.0516,
        0.0533, 0.0616, 0.0875, 0.0627, 0.1340, 0.1640], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,506][circuit_model.py][line:2324][INFO] ##4-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1555, 0.0564, 0.0824, 0.1024, 0.0352, 0.0667, 0.0609, 0.0557, 0.0500,
        0.0692, 0.0625, 0.0426, 0.0331, 0.0607, 0.0669], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,507][circuit_model.py][line:2327][INFO] ##4-th layer ##Weight##: The head12 weight for token [ to] are: tensor([4.3685e-04, 6.3017e-07, 3.0754e-06, 4.5809e-05, 1.4401e-05, 3.5090e-04,
        2.4582e-03, 2.4326e-02, 1.8115e-03, 1.5421e-03, 5.7520e-03, 3.7019e-02,
        2.8268e-03, 4.0316e-01, 5.2026e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,528][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:17,530][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,531][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,532][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,533][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,534][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,534][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,534][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,535][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,535][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,535][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,535][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,536][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,536][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9461, 0.0539], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,536][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.8730, 0.1270], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,537][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.7370, 0.2630], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,538][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.9300, 0.0700], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,539][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.9883, 0.0117], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,539][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8774, 0.1226], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,539][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.9260, 0.0740], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,550][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5398, 0.4602], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,551][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0995, 0.9005], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,551][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9598, 0.0402], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,551][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8537, 0.1463], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,552][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([9.9930e-01, 6.9850e-04], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,553][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.6041, 0.1657, 0.2302], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,555][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([0.2922, 0.3778, 0.3300], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,556][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.7242, 0.1673, 0.1085], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,558][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.5841, 0.2235, 0.1924], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,559][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.8135, 0.0501, 0.1363], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,559][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.5055, 0.2269, 0.2676], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,559][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.6257, 0.3080, 0.0663], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,560][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.1301, 0.3613, 0.5086], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,560][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.0796, 0.4923, 0.4282], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,560][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.7092, 0.0734, 0.2174], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,560][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.4632, 0.2678, 0.2691], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,561][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.0230, 0.9745, 0.0025], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,561][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7096, 0.0418, 0.0728, 0.1759], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,561][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2845, 0.1706, 0.1437, 0.4013], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,562][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.6930, 0.1314, 0.0802, 0.0954], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,562][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5726, 0.0701, 0.0799, 0.2774], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,564][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7280, 0.0337, 0.0764, 0.1620], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,566][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5565, 0.0674, 0.1008, 0.2752], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,567][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.6846, 0.1037, 0.1161, 0.0956], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,568][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0630, 0.1443, 0.1175, 0.6751], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,570][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0564, 0.3291, 0.2782, 0.3364], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,572][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7350, 0.0324, 0.0986, 0.1340], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,573][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4954, 0.1133, 0.1190, 0.2722], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,575][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8484, 0.0014, 0.0111, 0.1392], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,575][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.2607, 0.0918, 0.0911, 0.3423, 0.2142], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,575][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.1172, 0.1331, 0.1022, 0.4697, 0.1777], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,576][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.6192, 0.1308, 0.0918, 0.1067, 0.0515], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,576][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.2666, 0.1145, 0.1041, 0.3370, 0.1778], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,576][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.5245, 0.0463, 0.1008, 0.1790, 0.1494], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,577][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.2395, 0.1062, 0.1447, 0.3362, 0.1734], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,577][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.3740, 0.2174, 0.0749, 0.3145, 0.0192], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,577][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0460, 0.0716, 0.1260, 0.4002, 0.3562], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,578][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0306, 0.2462, 0.2594, 0.2557, 0.2080], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,578][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.4253, 0.0397, 0.1413, 0.2222, 0.1715], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,578][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.3147, 0.1642, 0.1483, 0.2784, 0.0944], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,578][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0104, 0.0911, 0.0041, 0.8826, 0.0119], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,579][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3052, 0.0567, 0.0464, 0.1813, 0.0974, 0.3129], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,581][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1297, 0.1135, 0.0980, 0.3160, 0.1319, 0.2108], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,582][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.6490, 0.1049, 0.0756, 0.0770, 0.0471, 0.0464], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,584][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.1376, 0.0816, 0.0738, 0.2936, 0.1044, 0.3090], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,585][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.5366, 0.0394, 0.0773, 0.1627, 0.1063, 0.0776], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,586][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.2351, 0.0877, 0.0857, 0.2546, 0.1000, 0.2369], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,586][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.4645, 0.1140, 0.0936, 0.1732, 0.1043, 0.0504], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,587][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0265, 0.0579, 0.0574, 0.2711, 0.1441, 0.4430], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,587][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0310, 0.1567, 0.1618, 0.1706, 0.1481, 0.3318], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,587][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.3770, 0.0396, 0.0916, 0.1407, 0.1194, 0.2317], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,588][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2709, 0.1414, 0.1281, 0.2820, 0.0449, 0.1328], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,588][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0474, 0.0038, 0.0021, 0.2161, 0.0205, 0.7102], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,588][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1604, 0.0478, 0.0397, 0.1255, 0.0633, 0.2688, 0.2946],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,588][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1212, 0.0715, 0.0697, 0.2183, 0.0931, 0.2024, 0.2237],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,589][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.7323, 0.0740, 0.0503, 0.0547, 0.0305, 0.0345, 0.0237],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,591][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1810, 0.0467, 0.0483, 0.1725, 0.0817, 0.1933, 0.2765],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,593][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.5271, 0.0365, 0.0726, 0.1511, 0.0958, 0.0619, 0.0549],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,594][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.2348, 0.0723, 0.0669, 0.1821, 0.0680, 0.1709, 0.2051],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,595][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.4484, 0.0972, 0.0625, 0.1730, 0.0426, 0.1268, 0.0495],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,596][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0268, 0.0673, 0.0484, 0.1900, 0.1155, 0.3045, 0.2475],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,597][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0301, 0.1359, 0.1244, 0.1332, 0.1133, 0.3111, 0.1520],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,597][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3477, 0.0253, 0.0623, 0.0989, 0.0901, 0.1661, 0.2096],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,597][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2844, 0.1118, 0.1261, 0.2388, 0.0454, 0.1022, 0.0915],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,597][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([1.5418e-02, 4.6216e-04, 1.1905e-03, 2.6531e-02, 7.0321e-03, 2.9405e-01,
        6.5531e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,598][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1242, 0.0221, 0.0181, 0.0831, 0.0353, 0.1853, 0.2106, 0.3214],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,598][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0924, 0.0586, 0.0363, 0.1861, 0.0484, 0.1337, 0.1880, 0.2563],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,598][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.6411, 0.0825, 0.0631, 0.0630, 0.0397, 0.0480, 0.0345, 0.0280],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,599][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1107, 0.0298, 0.0261, 0.1320, 0.0461, 0.1452, 0.2265, 0.2836],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,600][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.5203, 0.0402, 0.0582, 0.1435, 0.0838, 0.0531, 0.0492, 0.0517],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,601][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1585, 0.0355, 0.0331, 0.1333, 0.0408, 0.1431, 0.1931, 0.2627],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,603][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.4496, 0.0836, 0.0633, 0.1513, 0.0270, 0.0626, 0.1113, 0.0515],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,605][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0160, 0.0314, 0.0296, 0.1408, 0.0766, 0.2132, 0.1600, 0.3325],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,606][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0193, 0.1107, 0.1061, 0.1234, 0.1089, 0.2658, 0.1395, 0.1264],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,606][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.2185, 0.0205, 0.0393, 0.0783, 0.0636, 0.1431, 0.1874, 0.2493],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,607][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2475, 0.1124, 0.1284, 0.2222, 0.0377, 0.1009, 0.0849, 0.0660],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,607][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([2.9632e-03, 1.4192e-05, 9.3445e-05, 4.8430e-03, 8.6674e-04, 3.5456e-02,
        2.0439e-01, 7.5138e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,607][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0599, 0.0225, 0.0157, 0.0569, 0.0245, 0.1395, 0.1493, 0.3211, 0.2106],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,608][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0459, 0.0369, 0.0263, 0.1057, 0.0463, 0.1189, 0.1299, 0.2795, 0.2106],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,608][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.6714, 0.0781, 0.0550, 0.0540, 0.0281, 0.0389, 0.0273, 0.0242, 0.0231],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,608][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0822, 0.0331, 0.0291, 0.1102, 0.0437, 0.1151, 0.1720, 0.2595, 0.1552],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,609][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.4675, 0.0359, 0.0540, 0.1328, 0.0875, 0.0536, 0.0511, 0.0490, 0.0686],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,609][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1030, 0.0375, 0.0327, 0.1055, 0.0359, 0.1055, 0.1304, 0.2639, 0.1855],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,611][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.2197, 0.0955, 0.0434, 0.1536, 0.0438, 0.1793, 0.0798, 0.1393, 0.0456],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,613][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0109, 0.0372, 0.0293, 0.1079, 0.0622, 0.1605, 0.1193, 0.2797, 0.1931],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,614][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0128, 0.0931, 0.0984, 0.1044, 0.0955, 0.2230, 0.1202, 0.1092, 0.1433],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,616][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1767, 0.0140, 0.0363, 0.0614, 0.0591, 0.1059, 0.1561, 0.2539, 0.1367],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,616][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2429, 0.0984, 0.1217, 0.1919, 0.0475, 0.0728, 0.0912, 0.0679, 0.0658],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,617][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([4.1471e-04, 8.9559e-05, 3.7484e-05, 1.3310e-03, 2.9453e-04, 1.3846e-02,
        5.9005e-02, 8.9944e-01, 2.5538e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,617][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0869, 0.0143, 0.0164, 0.0452, 0.0296, 0.0953, 0.1252, 0.2457, 0.1711,
        0.1702], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,618][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0660, 0.0287, 0.0267, 0.0959, 0.0415, 0.0825, 0.1043, 0.1961, 0.1755,
        0.1829], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,618][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4884, 0.0930, 0.0684, 0.0713, 0.0425, 0.0547, 0.0380, 0.0326, 0.0372,
        0.0738], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,618][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1150, 0.0167, 0.0202, 0.0741, 0.0376, 0.0960, 0.1473, 0.2278, 0.1212,
        0.1441], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,619][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4302, 0.0339, 0.0546, 0.1266, 0.0693, 0.0413, 0.0367, 0.0404, 0.0523,
        0.1146], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,619][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1500, 0.0272, 0.0283, 0.0883, 0.0307, 0.0761, 0.1049, 0.2077, 0.1555,
        0.1314], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,619][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3727, 0.0430, 0.0543, 0.0860, 0.0343, 0.0933, 0.0772, 0.1027, 0.0997,
        0.0368], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,621][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0113, 0.0346, 0.0249, 0.0901, 0.0520, 0.1203, 0.0978, 0.2445, 0.1419,
        0.1826], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,622][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0151, 0.0918, 0.0854, 0.0984, 0.0865, 0.1942, 0.1090, 0.1033, 0.1102,
        0.1061], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,624][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1836, 0.0123, 0.0335, 0.0538, 0.0522, 0.0973, 0.1231, 0.2002, 0.1269,
        0.1172], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,625][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2063, 0.1031, 0.1100, 0.1931, 0.0331, 0.0781, 0.0783, 0.0605, 0.0575,
        0.0800], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,626][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([1.6844e-03, 2.5670e-05, 5.4503e-05, 3.6871e-04, 2.6781e-04, 5.8945e-03,
        3.9715e-02, 8.9635e-01, 3.3179e-02, 2.2457e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,627][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0838, 0.0123, 0.0129, 0.0365, 0.0231, 0.0819, 0.1061, 0.1914, 0.1284,
        0.1499, 0.1738], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,627][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0586, 0.0321, 0.0208, 0.0709, 0.0247, 0.0649, 0.0773, 0.1325, 0.1242,
        0.1702, 0.2238], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,627][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.4804, 0.0837, 0.0567, 0.0667, 0.0376, 0.0481, 0.0361, 0.0300, 0.0339,
        0.0684, 0.0584], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,628][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1104, 0.0152, 0.0171, 0.0593, 0.0314, 0.0826, 0.1305, 0.1868, 0.0953,
        0.1233, 0.1482], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,628][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3902, 0.0295, 0.0493, 0.1210, 0.0659, 0.0347, 0.0331, 0.0357, 0.0453,
        0.1035, 0.0917], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,628][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1437, 0.0228, 0.0228, 0.0611, 0.0252, 0.0666, 0.0949, 0.1679, 0.1265,
        0.1250, 0.1434], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,629][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2439, 0.0643, 0.0530, 0.0460, 0.0337, 0.0905, 0.0837, 0.1376, 0.1332,
        0.0577, 0.0564], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,629][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0106, 0.0270, 0.0195, 0.0844, 0.0420, 0.0970, 0.0835, 0.2015, 0.1120,
        0.1477, 0.1748], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,630][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0124, 0.0843, 0.0755, 0.0880, 0.0786, 0.1844, 0.0976, 0.0955, 0.1033,
        0.0996, 0.0810], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,632][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1911, 0.0125, 0.0284, 0.0459, 0.0436, 0.0826, 0.1080, 0.1640, 0.1004,
        0.1088, 0.1148], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,633][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2160, 0.0933, 0.1004, 0.1821, 0.0293, 0.0649, 0.0665, 0.0491, 0.0498,
        0.0722, 0.0765], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,634][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([6.0484e-03, 2.6018e-05, 8.2710e-05, 7.7791e-04, 3.7091e-04, 4.1889e-03,
        3.9451e-02, 7.3484e-01, 3.1031e-02, 4.7144e-02, 1.3604e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,636][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0442, 0.0121, 0.0082, 0.0319, 0.0164, 0.0674, 0.0769, 0.1482, 0.1015,
        0.1185, 0.1455, 0.2292], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,637][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0302, 0.0150, 0.0133, 0.0490, 0.0215, 0.0598, 0.0628, 0.1336, 0.0954,
        0.1280, 0.1935, 0.1979], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,637][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.5207, 0.0760, 0.0505, 0.0573, 0.0346, 0.0416, 0.0270, 0.0231, 0.0262,
        0.0558, 0.0480, 0.0393], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,638][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0400, 0.0135, 0.0129, 0.0541, 0.0238, 0.0625, 0.0978, 0.1536, 0.0939,
        0.1050, 0.1459, 0.1971], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,638][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.3676, 0.0377, 0.0451, 0.1120, 0.0583, 0.0370, 0.0316, 0.0386, 0.0427,
        0.0977, 0.0865, 0.0451], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,638][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0640, 0.0259, 0.0190, 0.0487, 0.0237, 0.0617, 0.0764, 0.1315, 0.1069,
        0.1077, 0.1235, 0.2110], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,639][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1365, 0.0719, 0.0398, 0.0777, 0.0170, 0.1030, 0.0716, 0.1244, 0.1463,
        0.0748, 0.1090, 0.0280], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,639][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0086, 0.0186, 0.0165, 0.0570, 0.0393, 0.0937, 0.0688, 0.1553, 0.0951,
        0.1257, 0.1312, 0.1902], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,639][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0117, 0.0732, 0.0736, 0.0798, 0.0781, 0.1811, 0.0925, 0.0766, 0.0975,
        0.0936, 0.0766, 0.0657], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,640][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.1345, 0.0114, 0.0274, 0.0445, 0.0366, 0.0762, 0.1065, 0.1385, 0.0939,
        0.0920, 0.1051, 0.1334], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,642][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.2165, 0.0799, 0.0936, 0.1579, 0.0331, 0.0668, 0.0655, 0.0550, 0.0523,
        0.0681, 0.0683, 0.0429], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,643][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([2.0680e-03, 2.6276e-05, 1.8205e-05, 1.2405e-03, 1.8119e-04, 1.2248e-02,
        2.8017e-02, 1.9493e-01, 1.8888e-02, 4.0103e-02, 2.5024e-01, 4.5204e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,645][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0327, 0.0081, 0.0078, 0.0291, 0.0158, 0.0605, 0.0849, 0.1257, 0.1107,
        0.1070, 0.1449, 0.1769, 0.0959], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,646][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0214, 0.0115, 0.0102, 0.0479, 0.0165, 0.0486, 0.0595, 0.1096, 0.1007,
        0.1081, 0.1774, 0.2182, 0.0704], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,647][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.3816, 0.0823, 0.0585, 0.0703, 0.0376, 0.0469, 0.0350, 0.0296, 0.0348,
        0.0668, 0.0586, 0.0463, 0.0518], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,648][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0567, 0.0133, 0.0133, 0.0454, 0.0231, 0.0566, 0.0841, 0.1263, 0.0759,
        0.0929, 0.1285, 0.1928, 0.0912], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,648][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.2530, 0.0290, 0.0491, 0.1018, 0.0744, 0.0319, 0.0293, 0.0325, 0.0463,
        0.0896, 0.0757, 0.0384, 0.1491], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,648][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0522, 0.0159, 0.0171, 0.0490, 0.0194, 0.0561, 0.0681, 0.1377, 0.1001,
        0.1051, 0.1221, 0.1872, 0.0701], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,649][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.1193, 0.0715, 0.0216, 0.0978, 0.0051, 0.1498, 0.0348, 0.1212, 0.1146,
        0.0851, 0.1186, 0.0547, 0.0060], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,649][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0078, 0.0121, 0.0180, 0.0448, 0.0470, 0.0805, 0.0697, 0.1352, 0.0956,
        0.1005, 0.1119, 0.1515, 0.1254], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,649][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0073, 0.0698, 0.0809, 0.0730, 0.0641, 0.1744, 0.0856, 0.0711, 0.0882,
        0.0792, 0.0702, 0.0796, 0.0567], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,650][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0991, 0.0073, 0.0243, 0.0427, 0.0313, 0.0618, 0.0855, 0.1413, 0.0876,
        0.0844, 0.1034, 0.1402, 0.0911], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,651][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.1612, 0.0949, 0.0842, 0.1430, 0.0500, 0.0630, 0.0651, 0.0634, 0.0549,
        0.0646, 0.0655, 0.0449, 0.0454], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,652][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([8.0778e-05, 5.1344e-05, 5.3599e-06, 6.6140e-04, 1.6570e-05, 1.0127e-02,
        1.7127e-02, 1.5753e-01, 1.4390e-02, 2.8305e-02, 1.2765e-01, 6.3785e-01,
        6.2000e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,653][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0658, 0.0048, 0.0056, 0.0194, 0.0100, 0.0390, 0.0559, 0.1005, 0.0614,
        0.0786, 0.1000, 0.1253, 0.0532, 0.2807], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,655][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0336, 0.0106, 0.0081, 0.0353, 0.0107, 0.0296, 0.0368, 0.0684, 0.0539,
        0.0939, 0.1432, 0.1673, 0.0445, 0.2641], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,656][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.4928, 0.0720, 0.0413, 0.0534, 0.0262, 0.0345, 0.0251, 0.0224, 0.0228,
        0.0529, 0.0459, 0.0332, 0.0380, 0.0396], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,658][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0304, 0.0096, 0.0121, 0.0480, 0.0174, 0.0509, 0.0722, 0.1042, 0.0670,
        0.0865, 0.1118, 0.1487, 0.0511, 0.1901], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,658][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.2785, 0.0249, 0.0397, 0.0900, 0.0550, 0.0377, 0.0291, 0.0309, 0.0453,
        0.0854, 0.0739, 0.0346, 0.1046, 0.0702], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,658][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0751, 0.0160, 0.0124, 0.0451, 0.0127, 0.0399, 0.0521, 0.0972, 0.0807,
        0.0781, 0.1013, 0.1525, 0.0408, 0.1962], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,659][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.2094, 0.0644, 0.0382, 0.0702, 0.0249, 0.0696, 0.0465, 0.1108, 0.0664,
        0.0676, 0.0972, 0.0744, 0.0366, 0.0237], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,659][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0064, 0.0127, 0.0122, 0.0392, 0.0274, 0.0752, 0.0520, 0.1131, 0.0738,
        0.0892, 0.0888, 0.1323, 0.0614, 0.2164], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,659][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0106, 0.0611, 0.0677, 0.0628, 0.0675, 0.1554, 0.0740, 0.0667, 0.0875,
        0.0674, 0.0596, 0.0680, 0.0596, 0.0920], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,660][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1169, 0.0064, 0.0184, 0.0312, 0.0233, 0.0499, 0.0708, 0.1050, 0.0814,
        0.0718, 0.0801, 0.1256, 0.0684, 0.1509], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,660][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1926, 0.0796, 0.0819, 0.1509, 0.0321, 0.0613, 0.0617, 0.0492, 0.0485,
        0.0654, 0.0596, 0.0388, 0.0273, 0.0510], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,661][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([2.9716e-04, 1.8434e-05, 4.3934e-06, 2.4718e-04, 1.2370e-05, 9.4224e-04,
        2.5564e-03, 2.2164e-02, 1.9081e-03, 4.7660e-03, 2.5432e-02, 7.5584e-02,
        1.9502e-03, 8.6412e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,663][circuit_model.py][line:2332][INFO] ##4-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0537, 0.0048, 0.0054, 0.0165, 0.0075, 0.0309, 0.0440, 0.0675, 0.0521,
        0.0570, 0.0720, 0.0970, 0.0412, 0.2551, 0.1952], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,664][circuit_model.py][line:2335][INFO] ##4-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0401, 0.0103, 0.0102, 0.0352, 0.0122, 0.0282, 0.0366, 0.0547, 0.0549,
        0.0650, 0.1008, 0.1040, 0.0432, 0.2282, 0.1764], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,666][circuit_model.py][line:2338][INFO] ##4-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.4322, 0.0715, 0.0451, 0.0561, 0.0334, 0.0350, 0.0262, 0.0222, 0.0257,
        0.0537, 0.0475, 0.0345, 0.0425, 0.0359, 0.0384], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,667][circuit_model.py][line:2341][INFO] ##4-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0658, 0.0076, 0.0085, 0.0318, 0.0151, 0.0378, 0.0630, 0.0800, 0.0463,
        0.0614, 0.0789, 0.1163, 0.0471, 0.1486, 0.1918], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,668][circuit_model.py][line:2344][INFO] ##4-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.3166, 0.0233, 0.0370, 0.0910, 0.0486, 0.0274, 0.0269, 0.0266, 0.0388,
        0.0762, 0.0668, 0.0316, 0.0874, 0.0559, 0.0459], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,668][circuit_model.py][line:2347][INFO] ##4-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0882, 0.0134, 0.0119, 0.0385, 0.0121, 0.0356, 0.0457, 0.0753, 0.0636,
        0.0591, 0.0772, 0.1088, 0.0375, 0.1736, 0.1595], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,669][circuit_model.py][line:2350][INFO] ##4-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1930, 0.0507, 0.0358, 0.0986, 0.0186, 0.0933, 0.0479, 0.0654, 0.0662,
        0.0468, 0.1208, 0.0453, 0.0260, 0.0536, 0.0380], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,669][circuit_model.py][line:2353][INFO] ##4-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0063, 0.0115, 0.0097, 0.0367, 0.0231, 0.0548, 0.0461, 0.0966, 0.0601,
        0.0794, 0.0828, 0.1095, 0.0554, 0.1448, 0.1833], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,669][circuit_model.py][line:2356][INFO] ##4-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0093, 0.0628, 0.0554, 0.0669, 0.0555, 0.1417, 0.0708, 0.0708, 0.0778,
        0.0727, 0.0613, 0.0657, 0.0483, 0.0804, 0.0603], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,670][circuit_model.py][line:2359][INFO] ##4-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1348, 0.0065, 0.0167, 0.0277, 0.0230, 0.0388, 0.0570, 0.0808, 0.0516,
        0.0533, 0.0616, 0.0875, 0.0627, 0.1340, 0.1640], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,670][circuit_model.py][line:2362][INFO] ##4-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1749, 0.0772, 0.0880, 0.1363, 0.0290, 0.0563, 0.0595, 0.0437, 0.0442,
        0.0601, 0.0596, 0.0368, 0.0260, 0.0485, 0.0600], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,670][circuit_model.py][line:2365][INFO] ##4-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([4.3685e-04, 6.3017e-07, 3.0754e-06, 4.5809e-05, 1.4401e-05, 3.5090e-04,
        2.4582e-03, 2.4326e-02, 1.8115e-03, 1.5421e-03, 5.7520e-03, 3.7019e-02,
        2.8268e-03, 4.0316e-01, 5.2026e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,671][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:17,673][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[14274],
        [15439],
        [ 2992],
        [ 4813],
        [ 2144],
        [ 3229],
        [ 3088],
        [ 3644],
        [ 3718],
        [ 5325],
        [ 6484],
        [ 3017],
        [ 3333],
        [ 1782],
        [ 2722]], device='cuda:0')
[2024-07-24 10:20:17,675][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15854],
        [29490],
        [10843],
        [11013],
        [ 6643],
        [ 8829],
        [ 6948],
        [10966],
        [10384],
        [16194],
        [16092],
        [10023],
        [ 8533],
        [ 7853],
        [10029]], device='cuda:0')
[2024-07-24 10:20:17,676][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[ 5426],
        [ 6546],
        [13755],
        [12021],
        [19491],
        [24179],
        [26122],
        [31599],
        [32188],
        [30831],
        [29557],
        [29497],
        [27425],
        [24246],
        [23919]], device='cuda:0')
[2024-07-24 10:20:17,678][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[5080],
        [6914],
        [6870],
        [6506],
        [7042],
        [6637],
        [6635],
        [6705],
        [6840],
        [6834],
        [6729],
        [6699],
        [6784],
        [6866],
        [6910]], device='cuda:0')
[2024-07-24 10:20:17,679][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[23794],
        [22598],
        [ 4171],
        [12658],
        [11628],
        [17976],
        [17788],
        [16441],
        [11914],
        [15190],
        [11859],
        [12998],
        [10077],
        [12025],
        [10933]], device='cuda:0')
[2024-07-24 10:20:17,680][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[1717],
        [1387],
        [6162],
        [4213],
        [9375],
        [6249],
        [5722],
        [3938],
        [4985],
        [4761],
        [4921],
        [5462],
        [6544],
        [5385],
        [5738]], device='cuda:0')
[2024-07-24 10:20:17,681][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 9631],
        [16493],
        [15794],
        [17954],
        [19141],
        [19829],
        [19603],
        [20265],
        [20580],
        [20855],
        [20923],
        [21125],
        [21258],
        [21588],
        [21691]], device='cuda:0')
[2024-07-24 10:20:17,682][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[24615],
        [19852],
        [18777],
        [19333],
        [19504],
        [19223],
        [18563],
        [17579],
        [17360],
        [17654],
        [18211],
        [18937],
        [19132],
        [19786],
        [19696]], device='cuda:0')
[2024-07-24 10:20:17,683][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[15280],
        [15357],
        [15907],
        [15961],
        [15865],
        [16037],
        [16497],
        [16391],
        [15830],
        [15820],
        [15975],
        [16000],
        [15755],
        [15796],
        [15995]], device='cuda:0')
[2024-07-24 10:20:17,684][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[4705],
        [6541],
        [6512],
        [5922],
        [5660],
        [5753],
        [5813],
        [5466],
        [5469],
        [5704],
        [5853],
        [5675],
        [5719],
        [5562],
        [5713]], device='cuda:0')
[2024-07-24 10:20:17,686][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[21207],
        [20971],
        [16906],
        [16651],
        [16555],
        [15440],
        [16096],
        [16094],
        [16071],
        [15889],
        [15683],
        [15942],
        [16083],
        [14833],
        [15205]], device='cuda:0')
[2024-07-24 10:20:17,688][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[36447],
        [36339],
        [37032],
        [35589],
        [32732],
        [35162],
        [33403],
        [30802],
        [30957],
        [31173],
        [31550],
        [29390],
        [29386],
        [28632],
        [29955]], device='cuda:0')
[2024-07-24 10:20:17,689][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[20483],
        [22226],
        [24243],
        [25984],
        [26329],
        [28557],
        [26752],
        [27656],
        [26215],
        [24859],
        [23963],
        [23562],
        [23306],
        [22160],
        [21082]], device='cuda:0')
[2024-07-24 10:20:17,690][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[7788],
        [7780],
        [4572],
        [6256],
        [2879],
        [2046],
        [1398],
        [3309],
        [3992],
        [4027],
        [3434],
        [3147],
        [3886],
        [4281],
        [2884]], device='cuda:0')
[2024-07-24 10:20:17,691][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[8762],
        [7843],
        [2068],
        [8015],
        [2269],
        [5012],
        [7310],
        [4424],
        [7743],
        [4959],
        [7646],
        [2825],
        [3586],
        [3276],
        [4310]], device='cuda:0')
[2024-07-24 10:20:17,692][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[5304],
        [4139],
        [4255],
        [3524],
        [4726],
        [2068],
        [2407],
        [3877],
        [4348],
        [4743],
        [5302],
        [7727],
        [7421],
        [5993],
        [5605]], device='cuda:0')
[2024-07-24 10:20:17,693][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[10613],
        [ 9973],
        [13117],
        [12526],
        [12734],
        [11576],
        [12220],
        [10649],
        [10982],
        [11189],
        [12097],
        [11004],
        [10233],
        [11196],
        [ 9723]], device='cuda:0')
[2024-07-24 10:20:17,694][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 6577],
        [ 9595],
        [10101],
        [11327],
        [10095],
        [10300],
        [10231],
        [11614],
        [12114],
        [13561],
        [13782],
        [12991],
        [12662],
        [12333],
        [12364]], device='cuda:0')
[2024-07-24 10:20:17,696][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[ 850],
        [ 857],
        [ 939],
        [ 815],
        [ 895],
        [ 627],
        [ 839],
        [ 817],
        [ 922],
        [ 953],
        [1047],
        [ 910],
        [1008],
        [ 950],
        [ 999]], device='cuda:0')
[2024-07-24 10:20:17,697][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[31182],
        [30178],
        [18513],
        [14513],
        [12890],
        [12258],
        [11824],
        [11190],
        [10591],
        [ 9874],
        [10259],
        [10866],
        [11085],
        [10814],
        [11346]], device='cuda:0')
[2024-07-24 10:20:17,699][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[15876],
        [22014],
        [17644],
        [14823],
        [14315],
        [20256],
        [20317],
        [24532],
        [24953],
        [26227],
        [24667],
        [22848],
        [22589],
        [21473],
        [21558]], device='cuda:0')
[2024-07-24 10:20:17,700][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[5682],
        [4628],
        [2503],
        [2378],
        [ 981],
        [1309],
        [2157],
        [2377],
        [2286],
        [2290],
        [1898],
        [1621],
        [1731],
        [1670],
        [1660]], device='cuda:0')
[2024-07-24 10:20:17,701][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[9036],
        [3694],
        [3844],
        [3860],
        [3587],
        [4188],
        [4496],
        [5594],
        [5312],
        [5228],
        [5252],
        [5557],
        [5394],
        [5989],
        [6009]], device='cuda:0')
[2024-07-24 10:20:17,702][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[10223],
        [ 7933],
        [ 9471],
        [ 8980],
        [ 9502],
        [ 7859],
        [ 7732],
        [ 8084],
        [ 7828],
        [ 7823],
        [ 7691],
        [ 7764],
        [ 7986],
        [ 8158],
        [ 8237]], device='cuda:0')
[2024-07-24 10:20:17,703][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[18181],
        [18858],
        [22095],
        [18885],
        [18005],
        [15871],
        [14566],
        [16102],
        [15686],
        [15404],
        [15446],
        [14533],
        [13122],
        [12164],
        [10626]], device='cuda:0')
[2024-07-24 10:20:17,704][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[15855],
        [19400],
        [23293],
        [19757],
        [19620],
        [19062],
        [20320],
        [21078],
        [22001],
        [22116],
        [22899],
        [23301],
        [22684],
        [23380],
        [24370]], device='cuda:0')
[2024-07-24 10:20:17,706][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[47496],
        [47499],
        [18872],
        [47736],
        [28360],
        [45281],
        [45630],
        [43010],
        [41809],
        [41619],
        [41723],
        [43934],
        [44256],
        [44694],
        [43085]], device='cuda:0')
[2024-07-24 10:20:17,707][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[43928],
        [43196],
        [44187],
        [44919],
        [45408],
        [45172],
        [44296],
        [43330],
        [42992],
        [42946],
        [42597],
        [42313],
        [42572],
        [43299],
        [43677]], device='cuda:0')
[2024-07-24 10:20:17,709][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[39869],
        [44246],
        [48318],
        [43726],
        [49154],
        [47453],
        [46175],
        [47457],
        [46079],
        [46887],
        [45974],
        [48801],
        [48937],
        [48694],
        [48226]], device='cuda:0')
[2024-07-24 10:20:17,710][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106],
        [14106]], device='cuda:0')
[2024-07-24 10:20:17,732][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:17,733][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,734][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,736][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,737][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,738][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,738][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,738][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,739][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,739][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,739][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,740][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,740][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,740][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.5593, 0.4407], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,741][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.7017, 0.2983], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,742][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0178, 0.9822], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,743][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9604, 0.0396], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,743][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2562, 0.7438], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,743][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2616, 0.7384], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,744][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.7324, 0.2676], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,754][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2392, 0.7608], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,755][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0207, 0.9793], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,755][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3106, 0.6894], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,756][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1696, 0.8304], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,757][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1115, 0.8885], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,759][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.3454, 0.3992, 0.2554], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,760][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.7998, 0.1363, 0.0639], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,762][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.0072, 0.4981, 0.4946], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,763][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.6132, 0.1212, 0.2656], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,763][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.1305, 0.5161, 0.3534], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,763][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.0541, 0.2779, 0.6680], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,764][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.2417, 0.5951, 0.1632], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,764][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.1292, 0.4593, 0.4114], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,764][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.0094, 0.5687, 0.4219], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,764][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.1852, 0.4482, 0.3666], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,765][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.0573, 0.4636, 0.4791], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,765][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.0620, 0.4540, 0.4840], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,765][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2143, 0.3145, 0.1451, 0.3261], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,766][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5774, 0.1708, 0.0937, 0.1581], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,768][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0056, 0.3248, 0.3198, 0.3497], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,769][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9105, 0.0222, 0.0403, 0.0270], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,771][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1274, 0.3484, 0.2296, 0.2946], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,772][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0735, 0.1802, 0.5033, 0.2430], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,773][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4908, 0.1890, 0.1272, 0.1929], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,773][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1178, 0.3138, 0.2513, 0.3171], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,774][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0062, 0.3925, 0.2897, 0.3117], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,774][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1359, 0.3297, 0.2700, 0.2644], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,774][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0585, 0.3437, 0.3187, 0.2792], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,775][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0417, 0.3103, 0.3288, 0.3192], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,775][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.1597, 0.3019, 0.2004, 0.1910, 0.1470], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,775][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.4515, 0.1540, 0.0920, 0.1551, 0.1475], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,775][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0036, 0.2385, 0.2329, 0.2596, 0.2654], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,776][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.4427, 0.0790, 0.2183, 0.1589, 0.1012], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,776][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0564, 0.3186, 0.2062, 0.3265, 0.0923], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,778][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0214, 0.1388, 0.4419, 0.1795, 0.2183], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,780][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.1585, 0.3113, 0.1424, 0.2352, 0.1526], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,781][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0613, 0.2272, 0.2086, 0.2425, 0.2604], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,783][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0043, 0.3060, 0.2239, 0.2413, 0.2246], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,783][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.1100, 0.2586, 0.2129, 0.2080, 0.2105], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,784][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0255, 0.2580, 0.2360, 0.1985, 0.2820], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,784][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0323, 0.2338, 0.2488, 0.2403, 0.2448], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,784][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1709, 0.2547, 0.1287, 0.1782, 0.1108, 0.1567], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,785][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.4791, 0.1184, 0.0578, 0.1002, 0.1047, 0.1398], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,785][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0029, 0.1898, 0.1861, 0.2071, 0.2119, 0.2022], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,785][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.5019, 0.0375, 0.0680, 0.0556, 0.0514, 0.2855], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,785][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0546, 0.2766, 0.1707, 0.2578, 0.0805, 0.1598], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,786][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0473, 0.1207, 0.2637, 0.1684, 0.2251, 0.1748], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,786][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.1816, 0.1903, 0.0860, 0.1751, 0.0929, 0.2741], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,788][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0442, 0.2092, 0.1648, 0.2172, 0.2035, 0.1612], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,789][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0035, 0.2469, 0.1817, 0.1949, 0.1818, 0.1911], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,791][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0892, 0.2153, 0.1766, 0.1724, 0.1749, 0.1716], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,792][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0225, 0.2268, 0.1968, 0.1802, 0.1987, 0.1750], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,794][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0261, 0.1882, 0.2009, 0.1930, 0.1974, 0.1944], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,794][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1711, 0.2319, 0.0991, 0.1422, 0.0971, 0.1273, 0.1313],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,794][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.4306, 0.1042, 0.0501, 0.0891, 0.0908, 0.1210, 0.1143],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,795][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0030, 0.1591, 0.1546, 0.1694, 0.1740, 0.1656, 0.1742],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,795][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.5460, 0.0164, 0.0325, 0.0308, 0.0358, 0.2685, 0.0700],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,795][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0513, 0.2583, 0.1461, 0.2298, 0.0623, 0.1437, 0.1086],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,795][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0319, 0.0918, 0.2373, 0.1251, 0.2040, 0.1638, 0.1461],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,796][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1899, 0.1170, 0.0786, 0.1197, 0.0848, 0.2154, 0.1946],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,796][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0599, 0.1818, 0.1325, 0.1786, 0.1817, 0.1423, 0.1231],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,797][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0033, 0.2050, 0.1519, 0.1627, 0.1518, 0.1597, 0.1655],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,798][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0757, 0.1796, 0.1491, 0.1455, 0.1474, 0.1453, 0.1573],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,800][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0312, 0.1706, 0.1716, 0.1396, 0.1830, 0.1419, 0.1621],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,802][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0228, 0.1559, 0.1658, 0.1598, 0.1638, 0.1610, 0.1707],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,803][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1172, 0.1767, 0.0667, 0.1034, 0.0715, 0.1269, 0.1279, 0.2096],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,804][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.4641, 0.0881, 0.0391, 0.0742, 0.0735, 0.0974, 0.0902, 0.0734],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,804][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0021, 0.1371, 0.1325, 0.1465, 0.1504, 0.1436, 0.1519, 0.1358],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,805][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.4274, 0.0198, 0.0475, 0.0434, 0.0381, 0.2275, 0.1156, 0.0807],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,805][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0562, 0.2206, 0.1263, 0.2028, 0.0581, 0.1377, 0.1102, 0.0881],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,805][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0260, 0.0668, 0.1961, 0.1052, 0.1801, 0.1398, 0.1436, 0.1424],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,806][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1187, 0.0977, 0.0541, 0.1116, 0.0540, 0.2162, 0.1866, 0.1610],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,806][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0414, 0.1673, 0.1158, 0.1746, 0.1439, 0.1111, 0.1199, 0.1261],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,806][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0025, 0.1773, 0.1307, 0.1400, 0.1309, 0.1373, 0.1427, 0.1385],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,807][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0651, 0.1605, 0.1309, 0.1276, 0.1291, 0.1269, 0.1382, 0.1216],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,807][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0176, 0.1647, 0.1483, 0.1294, 0.1526, 0.1182, 0.1395, 0.1297],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,809][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0193, 0.1355, 0.1452, 0.1383, 0.1422, 0.1395, 0.1479, 0.1322],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,811][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1007, 0.1471, 0.0659, 0.0821, 0.0718, 0.1196, 0.0993, 0.1834, 0.1302],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,812][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.4463, 0.0787, 0.0316, 0.0692, 0.0645, 0.0892, 0.0830, 0.0666, 0.0708],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,813][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0015, 0.1213, 0.1173, 0.1322, 0.1351, 0.1296, 0.1371, 0.1223, 0.1035],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,814][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.2675, 0.0151, 0.0274, 0.0444, 0.0420, 0.2388, 0.1358, 0.1359, 0.0932],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,815][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0476, 0.2025, 0.1189, 0.1863, 0.0560, 0.1312, 0.1061, 0.0918, 0.0596],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,815][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0132, 0.0437, 0.1410, 0.0700, 0.1811, 0.1229, 0.1119, 0.2018, 0.1145],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,815][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0881, 0.1311, 0.0469, 0.0880, 0.0506, 0.1727, 0.1497, 0.1537, 0.1191],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,816][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0504, 0.1346, 0.1182, 0.1370, 0.1438, 0.0942, 0.1063, 0.1146, 0.1009],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,816][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0018, 0.1605, 0.1171, 0.1256, 0.1171, 0.1229, 0.1278, 0.1243, 0.1029],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,816][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0572, 0.1470, 0.1187, 0.1156, 0.1171, 0.1149, 0.1256, 0.1100, 0.0939],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,817][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0151, 0.1548, 0.1285, 0.1184, 0.1347, 0.1069, 0.1304, 0.1070, 0.1042],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,817][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0146, 0.1214, 0.1314, 0.1243, 0.1279, 0.1249, 0.1332, 0.1176, 0.1047],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,818][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1265, 0.1722, 0.0661, 0.0890, 0.0877, 0.0972, 0.0933, 0.1127, 0.0854,
        0.0698], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,819][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4099, 0.0775, 0.0354, 0.0645, 0.0650, 0.0824, 0.0772, 0.0611, 0.0661,
        0.0608], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,821][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0016, 0.1083, 0.1052, 0.1173, 0.1211, 0.1137, 0.1230, 0.1088, 0.0919,
        0.1090], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,823][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.3788, 0.0109, 0.0294, 0.0216, 0.0248, 0.2249, 0.0953, 0.0879, 0.1127,
        0.0137], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,824][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0482, 0.1674, 0.1112, 0.1519, 0.0589, 0.1156, 0.0968, 0.0869, 0.0612,
        0.1019], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,825][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0188, 0.0447, 0.1248, 0.0776, 0.1393, 0.1113, 0.1115, 0.1491, 0.1681,
        0.0549], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,825][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1422, 0.0760, 0.0512, 0.0612, 0.0518, 0.1197, 0.1210, 0.1474, 0.1048,
        0.1247], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,825][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0491, 0.1142, 0.0987, 0.1191, 0.1125, 0.0843, 0.0963, 0.1104, 0.0970,
        0.1184], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,826][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0022, 0.1404, 0.1046, 0.1116, 0.1050, 0.1093, 0.1135, 0.1103, 0.0928,
        0.1103], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,826][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0529, 0.1311, 0.1070, 0.1045, 0.1054, 0.1037, 0.1127, 0.0996, 0.0855,
        0.0975], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,826][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0160, 0.1362, 0.1199, 0.1055, 0.1247, 0.0987, 0.1161, 0.0987, 0.0800,
        0.1044], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,827][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0143, 0.1095, 0.1161, 0.1122, 0.1144, 0.1109, 0.1185, 0.1050, 0.0933,
        0.1058], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,827][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0678, 0.1383, 0.0550, 0.1009, 0.0747, 0.0831, 0.0773, 0.1040, 0.0847,
        0.0645, 0.1498], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,828][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.3227, 0.0769, 0.0395, 0.0679, 0.0677, 0.0828, 0.0777, 0.0637, 0.0684,
        0.0626, 0.0701], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,830][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0016, 0.0977, 0.0942, 0.1042, 0.1078, 0.1015, 0.1097, 0.0973, 0.0822,
        0.0982, 0.1056], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,831][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4169, 0.0147, 0.0260, 0.0190, 0.0261, 0.1947, 0.1023, 0.0806, 0.0894,
        0.0187, 0.0115], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,833][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0464, 0.1557, 0.1002, 0.1365, 0.0508, 0.1025, 0.0844, 0.0747, 0.0526,
        0.0914, 0.1049], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,834][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0159, 0.0443, 0.1160, 0.0583, 0.1106, 0.1135, 0.1081, 0.1546, 0.1674,
        0.0571, 0.0542], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,835][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1329, 0.0716, 0.0425, 0.0546, 0.0440, 0.1115, 0.1112, 0.1276, 0.0878,
        0.1158, 0.1004], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,835][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0375, 0.1054, 0.0830, 0.1059, 0.0997, 0.0813, 0.0842, 0.0926, 0.0830,
        0.1102, 0.1171], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,835][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0020, 0.1265, 0.0938, 0.1001, 0.0941, 0.0979, 0.1020, 0.0992, 0.0833,
        0.0994, 0.1017], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,836][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0482, 0.1187, 0.0971, 0.0946, 0.0957, 0.0940, 0.1025, 0.0906, 0.0779,
        0.0888, 0.0919], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,836][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0151, 0.1208, 0.1083, 0.0948, 0.1165, 0.0902, 0.1052, 0.0906, 0.0735,
        0.0946, 0.0903], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,836][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0120, 0.0987, 0.1046, 0.1018, 0.1037, 0.1010, 0.1079, 0.0949, 0.0839,
        0.0954, 0.0960], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,837][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0377, 0.0676, 0.0415, 0.0461, 0.0494, 0.0614, 0.0619, 0.0994, 0.0848,
        0.0589, 0.0956, 0.2958], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,837][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.2947, 0.0702, 0.0311, 0.0626, 0.0605, 0.0796, 0.0732, 0.0602, 0.0637,
        0.0585, 0.0650, 0.0808], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,839][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0013, 0.0876, 0.0839, 0.0938, 0.0967, 0.0920, 0.0993, 0.0881, 0.0741,
        0.0891, 0.0962, 0.0979], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,840][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.1761, 0.0176, 0.0270, 0.0275, 0.0190, 0.2597, 0.1563, 0.1314, 0.1125,
        0.0283, 0.0230, 0.0218], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,842][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0435, 0.1525, 0.0868, 0.1357, 0.0435, 0.0963, 0.0762, 0.0623, 0.0427,
        0.0861, 0.1025, 0.0718], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,843][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0120, 0.0443, 0.1053, 0.0647, 0.1023, 0.1009, 0.1010, 0.1322, 0.1376,
        0.0549, 0.0645, 0.0803], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,845][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0836, 0.0827, 0.0379, 0.0582, 0.0389, 0.1094, 0.0938, 0.0975, 0.0787,
        0.1102, 0.0990, 0.1101], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,845][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0316, 0.0904, 0.0727, 0.0960, 0.0960, 0.0687, 0.0790, 0.0837, 0.0672,
        0.0987, 0.1066, 0.1093], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,845][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0016, 0.1151, 0.0852, 0.0910, 0.0853, 0.0889, 0.0928, 0.0905, 0.0758,
        0.0907, 0.0931, 0.0900], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,846][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0446, 0.1095, 0.0892, 0.0869, 0.0879, 0.0863, 0.0940, 0.0832, 0.0715,
        0.0815, 0.0844, 0.0810], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,846][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0084, 0.1138, 0.0991, 0.0880, 0.1071, 0.0814, 0.1014, 0.0798, 0.0644,
        0.0873, 0.0827, 0.0866], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,846][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0108, 0.0904, 0.0958, 0.0925, 0.0943, 0.0924, 0.0985, 0.0867, 0.0763,
        0.0875, 0.0878, 0.0870], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,847][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0351, 0.1166, 0.0783, 0.0782, 0.0726, 0.0935, 0.0708, 0.0781, 0.0697,
        0.0547, 0.0740, 0.1023, 0.0762], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,847][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.2324, 0.0640, 0.0335, 0.0640, 0.0607, 0.0769, 0.0722, 0.0609, 0.0653,
        0.0574, 0.0634, 0.0772, 0.0720], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,848][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0013, 0.0785, 0.0759, 0.0858, 0.0866, 0.0839, 0.0896, 0.0804, 0.0677,
        0.0814, 0.0882, 0.0887, 0.0921], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,849][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.1035, 0.0178, 0.0450, 0.0372, 0.0202, 0.2698, 0.1013, 0.1477, 0.1380,
        0.0262, 0.0281, 0.0437, 0.0214], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,851][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0267, 0.1279, 0.0836, 0.1334, 0.0437, 0.0940, 0.0789, 0.0702, 0.0465,
        0.0805, 0.1014, 0.0751, 0.0381], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,853][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0049, 0.0342, 0.1070, 0.0453, 0.0520, 0.0984, 0.0793, 0.1469, 0.1807,
        0.0408, 0.0446, 0.1210, 0.0450], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,854][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0468, 0.0815, 0.0364, 0.0584, 0.0380, 0.0958, 0.0936, 0.0951, 0.0829,
        0.0951, 0.0952, 0.1212, 0.0601], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,855][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0258, 0.0802, 0.0748, 0.0842, 0.0911, 0.0571, 0.0654, 0.0741, 0.0684,
        0.0864, 0.0916, 0.0987, 0.1024], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,855][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0014, 0.1072, 0.0786, 0.0847, 0.0785, 0.0823, 0.0863, 0.0842, 0.0698,
        0.0838, 0.0865, 0.0836, 0.0730], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,856][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0426, 0.0999, 0.0818, 0.0798, 0.0807, 0.0795, 0.0861, 0.0769, 0.0666,
        0.0752, 0.0777, 0.0746, 0.0783], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,856][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0100, 0.0937, 0.0867, 0.0721, 0.1069, 0.0744, 0.0870, 0.0726, 0.0623,
        0.0748, 0.0713, 0.0780, 0.1101], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,856][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0109, 0.0829, 0.0892, 0.0850, 0.0871, 0.0850, 0.0905, 0.0801, 0.0715,
        0.0799, 0.0801, 0.0789, 0.0789], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:17,857][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0431, 0.0859, 0.0467, 0.0414, 0.0501, 0.0626, 0.0534, 0.0896, 0.0679,
        0.0429, 0.0716, 0.1714, 0.0822, 0.0912], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,857][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.2451, 0.0612, 0.0293, 0.0553, 0.0560, 0.0683, 0.0653, 0.0548, 0.0596,
        0.0514, 0.0564, 0.0707, 0.0672, 0.0595], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,857][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0010, 0.0723, 0.0696, 0.0790, 0.0801, 0.0773, 0.0826, 0.0737, 0.0616,
        0.0748, 0.0812, 0.0823, 0.0853, 0.0792], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,858][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.2951, 0.0088, 0.0211, 0.0186, 0.0261, 0.2016, 0.0998, 0.0825, 0.0713,
        0.0178, 0.0189, 0.0344, 0.0308, 0.0732], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,860][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0333, 0.1340, 0.0766, 0.1227, 0.0353, 0.0801, 0.0629, 0.0589, 0.0409,
        0.0787, 0.0936, 0.0671, 0.0351, 0.0808], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,862][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0117, 0.0360, 0.1128, 0.0524, 0.0810, 0.0777, 0.0699, 0.1252, 0.1109,
        0.0453, 0.0504, 0.1037, 0.0764, 0.0467], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,863][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0866, 0.0645, 0.0308, 0.0520, 0.0323, 0.0885, 0.0762, 0.0784, 0.0627,
        0.0903, 0.0847, 0.0954, 0.0451, 0.1123], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,865][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0249, 0.0825, 0.0629, 0.0833, 0.0799, 0.0606, 0.0619, 0.0682, 0.0642,
        0.0859, 0.0921, 0.0846, 0.0886, 0.0603], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,865][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0013, 0.0998, 0.0733, 0.0782, 0.0731, 0.0767, 0.0797, 0.0781, 0.0649,
        0.0780, 0.0804, 0.0779, 0.0682, 0.0705], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,866][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0376, 0.0950, 0.0767, 0.0748, 0.0756, 0.0742, 0.0811, 0.0716, 0.0612,
        0.0701, 0.0726, 0.0697, 0.0735, 0.0662], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,866][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0103, 0.0906, 0.0840, 0.0685, 0.0914, 0.0694, 0.0816, 0.0645, 0.0622,
        0.0670, 0.0640, 0.0694, 0.0914, 0.0856], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,866][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0105, 0.0767, 0.0827, 0.0789, 0.0812, 0.0790, 0.0840, 0.0744, 0.0663,
        0.0738, 0.0743, 0.0728, 0.0731, 0.0725], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:17,867][circuit_model.py][line:2294][INFO] ##5-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0329, 0.0793, 0.0305, 0.0451, 0.0432, 0.0486, 0.0425, 0.0693, 0.0514,
        0.0348, 0.0700, 0.1838, 0.0715, 0.0778, 0.1194], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,867][circuit_model.py][line:2297][INFO] ##5-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.2186, 0.0579, 0.0309, 0.0521, 0.0525, 0.0657, 0.0630, 0.0531, 0.0562,
        0.0506, 0.0553, 0.0639, 0.0602, 0.0530, 0.0668], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,868][circuit_model.py][line:2300][INFO] ##5-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0011, 0.0687, 0.0658, 0.0728, 0.0746, 0.0707, 0.0756, 0.0677, 0.0570,
        0.0693, 0.0743, 0.0752, 0.0793, 0.0721, 0.0756], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,868][circuit_model.py][line:2303][INFO] ##5-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.3404, 0.0114, 0.0178, 0.0177, 0.0205, 0.1710, 0.0825, 0.0743, 0.0722,
        0.0166, 0.0122, 0.0230, 0.0214, 0.0669, 0.0520], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,870][circuit_model.py][line:2306][INFO] ##5-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0366, 0.1247, 0.0737, 0.1111, 0.0354, 0.0767, 0.0636, 0.0554, 0.0369,
        0.0695, 0.0819, 0.0601, 0.0331, 0.0726, 0.0686], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,872][circuit_model.py][line:2309][INFO] ##5-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0127, 0.0332, 0.0721, 0.0494, 0.0800, 0.0825, 0.0789, 0.1034, 0.1170,
        0.0433, 0.0484, 0.0812, 0.0766, 0.0756, 0.0457], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,873][circuit_model.py][line:2312][INFO] ##5-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0933, 0.0497, 0.0321, 0.0407, 0.0318, 0.0794, 0.0704, 0.0840, 0.0602,
        0.0732, 0.0666, 0.0835, 0.0438, 0.0964, 0.0950], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,875][circuit_model.py][line:2315][INFO] ##5-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0253, 0.0754, 0.0569, 0.0751, 0.0706, 0.0550, 0.0585, 0.0644, 0.0582,
        0.0774, 0.0839, 0.0760, 0.0780, 0.0635, 0.0820], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,875][circuit_model.py][line:2318][INFO] ##5-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0013, 0.0917, 0.0681, 0.0725, 0.0684, 0.0711, 0.0738, 0.0723, 0.0604,
        0.0720, 0.0739, 0.0718, 0.0638, 0.0652, 0.0736], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,876][circuit_model.py][line:2321][INFO] ##5-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0357, 0.0876, 0.0716, 0.0697, 0.0705, 0.0693, 0.0754, 0.0669, 0.0575,
        0.0656, 0.0679, 0.0654, 0.0686, 0.0623, 0.0660], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,876][circuit_model.py][line:2324][INFO] ##5-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0105, 0.0847, 0.0767, 0.0660, 0.0842, 0.0659, 0.0762, 0.0637, 0.0547,
        0.0652, 0.0617, 0.0660, 0.0854, 0.0715, 0.0677], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,876][circuit_model.py][line:2327][INFO] ##5-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0090, 0.0722, 0.0765, 0.0740, 0.0756, 0.0734, 0.0783, 0.0692, 0.0612,
        0.0690, 0.0694, 0.0681, 0.0675, 0.0672, 0.0695], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:17,898][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:17,898][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,899][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,899][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,899][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,900][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,902][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,903][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,904][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,905][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,906][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,906][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,906][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:17,907][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1345, 0.8655], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,907][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2342, 0.7658], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,907][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.1673, 0.8327], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,908][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2666, 0.7334], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,908][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1144, 0.8856], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,908][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6427, 0.3573], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,909][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3470, 0.6530], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,910][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.8849, 0.1151], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,910][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2931, 0.7069], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,911][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.9512, 0.0488], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,911][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.9649, 0.0351], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,911][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1273, 0.8727], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:17,912][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.1361, 0.4879, 0.3759], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,912][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([0.1700, 0.8003, 0.0297], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,912][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.0963, 0.4973, 0.4064], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,913][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.1449, 0.4342, 0.4210], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,913][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.0533, 0.3808, 0.5659], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,913][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.4534, 0.2208, 0.3259], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,914][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.1664, 0.4515, 0.3821], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,914][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.2687, 0.1275, 0.6038], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,914][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.4553, 0.2176, 0.3271], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,916][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.8194, 0.1291, 0.0515], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,917][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.9229, 0.0078, 0.0693], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,919][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.0523, 0.4684, 0.4793], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:17,920][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0555, 0.2985, 0.2522, 0.3938], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,921][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.1205, 0.5826, 0.0328, 0.2641], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,921][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0563, 0.3515, 0.2880, 0.3042], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,921][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0996, 0.3079, 0.2992, 0.2932], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,922][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0353, 0.1577, 0.2353, 0.5717], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,922][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3903, 0.1390, 0.3144, 0.1562], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,923][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1424, 0.2618, 0.2888, 0.3071], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,923][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1130, 0.0523, 0.2684, 0.5664], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,923][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.5068, 0.0590, 0.1717, 0.2624], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,925][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.7073, 0.0355, 0.2085, 0.0487], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,926][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.9744, 0.0071, 0.0146, 0.0038], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,928][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0433, 0.3295, 0.3326, 0.2946], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:17,929][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.1074, 0.2509, 0.1937, 0.3064, 0.1417], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,931][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.1686, 0.6191, 0.0146, 0.1895, 0.0082], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,931][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0470, 0.2685, 0.2175, 0.2370, 0.2301], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,931][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0757, 0.2403, 0.2348, 0.2328, 0.2165], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,932][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0182, 0.1119, 0.1606, 0.5699, 0.1394], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,932][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.2308, 0.1566, 0.2390, 0.2402, 0.1333], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,932][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0651, 0.2185, 0.2067, 0.3263, 0.1833], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,932][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0833, 0.0360, 0.1737, 0.5797, 0.1274], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,933][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.2297, 0.0734, 0.1231, 0.3531, 0.2207], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,933][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.5483, 0.0544, 0.2989, 0.0798, 0.0186], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,933][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.7313, 0.0331, 0.0438, 0.0070, 0.1847], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,934][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0258, 0.2480, 0.2526, 0.2206, 0.2530], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:17,936][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0709, 0.1948, 0.1928, 0.2565, 0.1172, 0.1677], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,937][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1105, 0.5809, 0.0213, 0.1983, 0.0129, 0.0762], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,939][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0349, 0.2216, 0.1762, 0.1902, 0.1855, 0.1917], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,940][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0587, 0.1969, 0.1912, 0.1886, 0.1770, 0.1876], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,941][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0106, 0.0850, 0.1363, 0.5483, 0.1147, 0.1051], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,941][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1563, 0.2289, 0.1818, 0.1581, 0.1247, 0.1502], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,942][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0874, 0.1935, 0.1624, 0.2317, 0.1782, 0.1468], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,942][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1283, 0.0289, 0.1373, 0.4301, 0.0943, 0.1812], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,942][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2147, 0.0386, 0.0802, 0.1631, 0.1434, 0.3601], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,942][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2782, 0.0918, 0.3850, 0.0865, 0.0804, 0.0780], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,943][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.8711, 0.0274, 0.0257, 0.0111, 0.0152, 0.0496], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,943][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0225, 0.2005, 0.2031, 0.1808, 0.2016, 0.1915], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:17,943][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0587, 0.1707, 0.1536, 0.2133, 0.1175, 0.1370, 0.1493],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,944][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1221, 0.5165, 0.0217, 0.2013, 0.0121, 0.0723, 0.0541],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,946][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0335, 0.1898, 0.1505, 0.1605, 0.1567, 0.1619, 0.1470],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,948][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0515, 0.1648, 0.1608, 0.1583, 0.1487, 0.1568, 0.1591],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,949][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0098, 0.0771, 0.1233, 0.4787, 0.1065, 0.0941, 0.1106],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,950][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1437, 0.1729, 0.1849, 0.1435, 0.1140, 0.1305, 0.1104],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,951][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0605, 0.1517, 0.1627, 0.1900, 0.1738, 0.1458, 0.1155],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,951][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0932, 0.0376, 0.1179, 0.3177, 0.0942, 0.1525, 0.1870],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,952][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.1792, 0.0262, 0.0509, 0.1087, 0.0987, 0.2725, 0.2639],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,952][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.3592, 0.1046, 0.1582, 0.0946, 0.0584, 0.0878, 0.1373],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,952][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.8646, 0.0145, 0.0391, 0.0028, 0.0670, 0.0084, 0.0035],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,953][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0205, 0.1650, 0.1659, 0.1489, 0.1661, 0.1584, 0.1753],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:17,953][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0518, 0.1549, 0.1286, 0.1848, 0.0893, 0.1199, 0.1353, 0.1354],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,953][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.1511, 0.5032, 0.0139, 0.1699, 0.0081, 0.0608, 0.0528, 0.0403],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,954][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0337, 0.1596, 0.1264, 0.1362, 0.1303, 0.1397, 0.1267, 0.1473],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,954][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0463, 0.1407, 0.1370, 0.1350, 0.1265, 0.1367, 0.1382, 0.1396],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,956][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0157, 0.0721, 0.1079, 0.3601, 0.0936, 0.0878, 0.1024, 0.1603],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,958][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1393, 0.1585, 0.1624, 0.1036, 0.0968, 0.1251, 0.1287, 0.0856],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,959][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0555, 0.1373, 0.1192, 0.1850, 0.1264, 0.1368, 0.1361, 0.1037],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,961][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0863, 0.0236, 0.0924, 0.3427, 0.0655, 0.1265, 0.1768, 0.0863],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,961][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0685, 0.0221, 0.0400, 0.0977, 0.0759, 0.3077, 0.2726, 0.1156],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,962][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.1653, 0.1021, 0.1843, 0.1293, 0.0759, 0.1897, 0.1376, 0.0157],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,962][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.5037, 0.0486, 0.0475, 0.0166, 0.0567, 0.0195, 0.0075, 0.2999],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,962][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0179, 0.1422, 0.1432, 0.1272, 0.1436, 0.1357, 0.1494, 0.1409],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:17,963][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0411, 0.1311, 0.1142, 0.1505, 0.0781, 0.1124, 0.1124, 0.1160, 0.1441],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,963][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.1656, 0.5430, 0.0101, 0.1513, 0.0056, 0.0454, 0.0401, 0.0283, 0.0106],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,963][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0273, 0.1365, 0.1109, 0.1213, 0.1141, 0.1261, 0.1114, 0.1328, 0.1196],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,964][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0402, 0.1226, 0.1194, 0.1182, 0.1104, 0.1219, 0.1228, 0.1234, 0.1212],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,964][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0139, 0.0565, 0.0810, 0.2707, 0.0741, 0.0777, 0.0903, 0.1375, 0.1984],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,965][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1350, 0.1085, 0.1389, 0.1071, 0.1019, 0.1190, 0.1028, 0.0903, 0.0965],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,966][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0378, 0.1147, 0.1063, 0.1596, 0.1217, 0.1044, 0.1218, 0.1110, 0.1226],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,968][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0703, 0.0296, 0.0942, 0.2390, 0.0644, 0.1076, 0.1354, 0.0770, 0.1825],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,969][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0923, 0.0126, 0.0297, 0.0626, 0.0664, 0.2430, 0.2385, 0.1192, 0.1358],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,971][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1295, 0.1132, 0.1302, 0.0600, 0.2632, 0.1178, 0.0259, 0.1331, 0.0271],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,972][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.6413, 0.0125, 0.0125, 0.0028, 0.0159, 0.0079, 0.0015, 0.0174, 0.2881],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,972][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0143, 0.1252, 0.1270, 0.1120, 0.1267, 0.1195, 0.1318, 0.1234, 0.1200],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:17,972][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0343, 0.1425, 0.1051, 0.1388, 0.0624, 0.0861, 0.0972, 0.0879, 0.1168,
        0.1289], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,973][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1053, 0.4356, 0.0177, 0.1630, 0.0101, 0.0542, 0.0423, 0.0343, 0.0173,
        0.1202], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,973][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0234, 0.1251, 0.0974, 0.1058, 0.1037, 0.1079, 0.1010, 0.1201, 0.1080,
        0.1075], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,973][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0349, 0.1093, 0.1065, 0.1055, 0.0995, 0.1065, 0.1080, 0.1113, 0.1092,
        0.1094], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,974][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0116, 0.0462, 0.0730, 0.2064, 0.0652, 0.0584, 0.0676, 0.1067, 0.1550,
        0.2099], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,974][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1198, 0.0863, 0.1306, 0.1041, 0.1030, 0.1066, 0.0926, 0.0811, 0.0913,
        0.0846], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,974][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0496, 0.0915, 0.1045, 0.1150, 0.1121, 0.0988, 0.1026, 0.0929, 0.1217,
        0.1115], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,976][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0866, 0.0266, 0.0955, 0.2055, 0.0595, 0.0908, 0.1144, 0.0576, 0.1490,
        0.1146], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,978][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1160, 0.0122, 0.0287, 0.0521, 0.0643, 0.1768, 0.1786, 0.0964, 0.1525,
        0.1224], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,979][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3417, 0.0406, 0.1083, 0.0511, 0.0656, 0.0469, 0.0722, 0.0978, 0.1423,
        0.0336], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,980][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.7855, 0.0243, 0.0358, 0.0093, 0.0405, 0.0168, 0.0052, 0.0414, 0.0281,
        0.0131], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,982][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0144, 0.1120, 0.1123, 0.0993, 0.1107, 0.1040, 0.1149, 0.1090, 0.1060,
        0.1174], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:17,982][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0284, 0.1203, 0.0896, 0.1344, 0.0534, 0.0768, 0.0841, 0.0781, 0.1022,
        0.1160, 0.1165], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,982][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0855, 0.3489, 0.0168, 0.1545, 0.0103, 0.0593, 0.0426, 0.0362, 0.0184,
        0.1148, 0.1127], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,983][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0195, 0.1130, 0.0886, 0.0950, 0.0935, 0.0973, 0.0907, 0.1086, 0.0979,
        0.0985, 0.0973], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,983][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0328, 0.0992, 0.0970, 0.0953, 0.0897, 0.0952, 0.0970, 0.1000, 0.0983,
        0.0988, 0.0966], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,983][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0096, 0.0409, 0.0635, 0.1739, 0.0552, 0.0459, 0.0515, 0.0880, 0.1281,
        0.1701, 0.1735], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,984][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1183, 0.0765, 0.1319, 0.0893, 0.1072, 0.1028, 0.0821, 0.0709, 0.0835,
        0.0724, 0.0651], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,984][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0436, 0.0841, 0.0912, 0.0991, 0.0983, 0.0989, 0.0844, 0.0812, 0.1150,
        0.1025, 0.1017], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,985][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0646, 0.0259, 0.0821, 0.1863, 0.0596, 0.0827, 0.0971, 0.0502, 0.1270,
        0.1011, 0.1236], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,986][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2272, 0.0116, 0.0278, 0.0371, 0.0624, 0.1349, 0.1323, 0.0658, 0.1027,
        0.0880, 0.1102], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,988][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.3575, 0.0329, 0.1280, 0.0422, 0.0831, 0.0439, 0.0460, 0.0712, 0.1355,
        0.0259, 0.0337], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,989][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.7898, 0.0187, 0.0310, 0.0087, 0.0463, 0.0169, 0.0040, 0.0373, 0.0199,
        0.0091, 0.0184], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,991][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0123, 0.1002, 0.1004, 0.0893, 0.0983, 0.0932, 0.1034, 0.0974, 0.0946,
        0.1053, 0.1055], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:17,992][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0312, 0.1244, 0.0876, 0.1289, 0.0492, 0.0711, 0.0791, 0.0707, 0.0922,
        0.0979, 0.0988, 0.0688], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,992][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0992, 0.3984, 0.0092, 0.1412, 0.0061, 0.0452, 0.0380, 0.0280, 0.0114,
        0.0956, 0.0967, 0.0309], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,993][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0188, 0.1013, 0.0793, 0.0869, 0.0836, 0.0919, 0.0829, 0.0985, 0.0876,
        0.0893, 0.0890, 0.0910], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,993][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0321, 0.0895, 0.0874, 0.0863, 0.0803, 0.0869, 0.0884, 0.0897, 0.0878,
        0.0900, 0.0884, 0.0932], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,993][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0100, 0.0364, 0.0524, 0.1530, 0.0455, 0.0418, 0.0490, 0.0761, 0.1079,
        0.1535, 0.1578, 0.1167], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,994][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0811, 0.1112, 0.0911, 0.0912, 0.0807, 0.0914, 0.0852, 0.0633, 0.0783,
        0.0804, 0.0749, 0.0712], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,994][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0216, 0.0813, 0.0740, 0.1172, 0.0742, 0.0872, 0.0919, 0.0716, 0.0879,
        0.1135, 0.1228, 0.0569], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,994][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0497, 0.0225, 0.0702, 0.1565, 0.0534, 0.0747, 0.0818, 0.0457, 0.1085,
        0.0910, 0.1070, 0.1390], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,995][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0759, 0.0119, 0.0202, 0.0523, 0.0450, 0.1365, 0.1457, 0.0662, 0.0925,
        0.1018, 0.1498, 0.1022], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,997][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.2379, 0.0533, 0.1613, 0.0462, 0.1001, 0.0519, 0.0393, 0.0694, 0.1846,
        0.0212, 0.0213, 0.0134], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:17,999][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.4763, 0.0410, 0.0467, 0.0194, 0.0661, 0.0207, 0.0164, 0.0673, 0.0442,
        0.0439, 0.0790, 0.0790], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,000][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0110, 0.0903, 0.0915, 0.0802, 0.0902, 0.0839, 0.0931, 0.0876, 0.0850,
        0.0939, 0.0945, 0.0989], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,001][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0294, 0.1172, 0.0810, 0.1115, 0.0454, 0.0686, 0.0784, 0.0730, 0.0983,
        0.0921, 0.0924, 0.0670, 0.0456], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,002][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.1462, 0.3990, 0.0094, 0.1274, 0.0049, 0.0323, 0.0353, 0.0253, 0.0099,
        0.0933, 0.0891, 0.0213, 0.0065], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,003][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0174, 0.0896, 0.0744, 0.0812, 0.0773, 0.0834, 0.0744, 0.0911, 0.0825,
        0.0832, 0.0822, 0.0849, 0.0785], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,003][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0279, 0.0814, 0.0799, 0.0802, 0.0741, 0.0804, 0.0816, 0.0838, 0.0825,
        0.0829, 0.0816, 0.0882, 0.0755], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,003][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0049, 0.0298, 0.0466, 0.1460, 0.0388, 0.0389, 0.0436, 0.0742, 0.1113,
        0.1518, 0.1526, 0.1181, 0.0434], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,004][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0880, 0.0529, 0.0965, 0.1042, 0.0609, 0.0772, 0.0792, 0.0658, 0.0841,
        0.0752, 0.0731, 0.0854, 0.0575], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,004][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0215, 0.0767, 0.0684, 0.1157, 0.0611, 0.0711, 0.0799, 0.0658, 0.0890,
        0.1073, 0.1193, 0.0570, 0.0673], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,004][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0376, 0.0167, 0.0557, 0.1611, 0.0403, 0.0598, 0.0766, 0.0384, 0.1057,
        0.0899, 0.1136, 0.1384, 0.0663], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,005][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0432, 0.0102, 0.0154, 0.0405, 0.0288, 0.1004, 0.1253, 0.0859, 0.0966,
        0.1076, 0.1471, 0.1380, 0.0612], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,006][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.1868, 0.0234, 0.1115, 0.0329, 0.0071, 0.0920, 0.0305, 0.0440, 0.3700,
        0.0171, 0.0168, 0.0614, 0.0065], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,007][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.4762, 0.0266, 0.0323, 0.0049, 0.1478, 0.0145, 0.0083, 0.0479, 0.0187,
        0.0113, 0.0199, 0.0259, 0.1657], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,009][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0088, 0.0824, 0.0844, 0.0732, 0.0840, 0.0759, 0.0849, 0.0789, 0.0777,
        0.0848, 0.0856, 0.0887, 0.0907], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,010][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0281, 0.0807, 0.0702, 0.0943, 0.0498, 0.0680, 0.0712, 0.0727, 0.0895,
        0.0773, 0.0859, 0.0715, 0.0580, 0.0828], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,012][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.1479, 0.4533, 0.0085, 0.1153, 0.0045, 0.0356, 0.0285, 0.0180, 0.0076,
        0.0761, 0.0713, 0.0199, 0.0057, 0.0079], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,013][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0170, 0.0856, 0.0684, 0.0742, 0.0708, 0.0755, 0.0680, 0.0829, 0.0740,
        0.0761, 0.0758, 0.0790, 0.0717, 0.0811], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,013][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0236, 0.0764, 0.0743, 0.0738, 0.0681, 0.0732, 0.0744, 0.0768, 0.0757,
        0.0768, 0.0752, 0.0813, 0.0699, 0.0805], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,013][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0073, 0.0276, 0.0399, 0.1346, 0.0336, 0.0328, 0.0384, 0.0638, 0.0898,
        0.1338, 0.1422, 0.1089, 0.0396, 0.1078], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,014][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0937, 0.0694, 0.0875, 0.0696, 0.0710, 0.0763, 0.0694, 0.0559, 0.0680,
        0.0689, 0.0625, 0.0635, 0.0671, 0.0770], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,014][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0236, 0.0757, 0.0634, 0.0978, 0.0649, 0.0610, 0.0696, 0.0636, 0.0779,
        0.0999, 0.1045, 0.0564, 0.0731, 0.0688], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,014][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0288, 0.0224, 0.0532, 0.1510, 0.0386, 0.0698, 0.0720, 0.0403, 0.0875,
        0.0895, 0.1068, 0.1041, 0.0580, 0.0779], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,015][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1121, 0.0045, 0.0140, 0.0255, 0.0298, 0.0760, 0.0952, 0.0403, 0.0535,
        0.0592, 0.1080, 0.0978, 0.0672, 0.2169], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,015][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0562, 0.0552, 0.1307, 0.0182, 0.0443, 0.1155, 0.0312, 0.0293, 0.2757,
        0.0264, 0.0107, 0.0489, 0.0341, 0.1236], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,016][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.6050, 0.0196, 0.0180, 0.0034, 0.0372, 0.0161, 0.0047, 0.0377, 0.0861,
        0.0091, 0.0087, 0.0190, 0.0584, 0.0770], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,018][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0083, 0.0745, 0.0756, 0.0672, 0.0758, 0.0712, 0.0791, 0.0740, 0.0723,
        0.0785, 0.0794, 0.0818, 0.0811, 0.0811], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,019][circuit_model.py][line:2332][INFO] ##5-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0301, 0.0845, 0.0691, 0.0855, 0.0474, 0.0638, 0.0673, 0.0636, 0.0794,
        0.0776, 0.0774, 0.0608, 0.0473, 0.0725, 0.0737], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,021][circuit_model.py][line:2335][INFO] ##5-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1241, 0.4202, 0.0097, 0.1236, 0.0050, 0.0353, 0.0301, 0.0192, 0.0094,
        0.0836, 0.0790, 0.0251, 0.0060, 0.0089, 0.0208], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,022][circuit_model.py][line:2338][INFO] ##5-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0148, 0.0815, 0.0640, 0.0690, 0.0664, 0.0697, 0.0637, 0.0773, 0.0695,
        0.0709, 0.0700, 0.0735, 0.0671, 0.0742, 0.0685], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,023][circuit_model.py][line:2341][INFO] ##5-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0231, 0.0717, 0.0700, 0.0689, 0.0640, 0.0678, 0.0694, 0.0716, 0.0703,
        0.0713, 0.0697, 0.0748, 0.0653, 0.0737, 0.0687], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,023][circuit_model.py][line:2344][INFO] ##5-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0053, 0.0251, 0.0385, 0.1233, 0.0328, 0.0283, 0.0341, 0.0579, 0.0866,
        0.1243, 0.1297, 0.0902, 0.0349, 0.0924, 0.0966], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,024][circuit_model.py][line:2347][INFO] ##5-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0845, 0.0744, 0.1002, 0.0696, 0.0690, 0.0737, 0.0643, 0.0522, 0.0629,
        0.0568, 0.0518, 0.0534, 0.0619, 0.0744, 0.0510], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,024][circuit_model.py][line:2350][INFO] ##5-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0251, 0.0625, 0.0645, 0.0768, 0.0687, 0.0651, 0.0673, 0.0619, 0.0808,
        0.0789, 0.0788, 0.0571, 0.0748, 0.0730, 0.0647], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,024][circuit_model.py][line:2353][INFO] ##5-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0366, 0.0233, 0.0561, 0.1197, 0.0410, 0.0639, 0.0684, 0.0392, 0.0815,
        0.0746, 0.0843, 0.0933, 0.0602, 0.0659, 0.0921], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,025][circuit_model.py][line:2356][INFO] ##5-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1553, 0.0053, 0.0141, 0.0204, 0.0317, 0.0621, 0.0675, 0.0324, 0.0517,
        0.0410, 0.0672, 0.0575, 0.0666, 0.1751, 0.1521], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,025][circuit_model.py][line:2359][INFO] ##5-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.2222, 0.0511, 0.1323, 0.0324, 0.0475, 0.0470, 0.0490, 0.0295, 0.1738,
        0.0281, 0.0221, 0.0331, 0.0431, 0.0633, 0.0255], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,025][circuit_model.py][line:2362][INFO] ##5-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.6909, 0.0249, 0.0294, 0.0068, 0.0331, 0.0118, 0.0044, 0.0391, 0.0210,
        0.0109, 0.0115, 0.0353, 0.0434, 0.0239, 0.0135], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,027][circuit_model.py][line:2365][INFO] ##5-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0081, 0.0705, 0.0704, 0.0624, 0.0702, 0.0653, 0.0729, 0.0683, 0.0666,
        0.0735, 0.0740, 0.0764, 0.0754, 0.0745, 0.0716], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,028][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:18,030][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[13440],
        [15419],
        [ 9047],
        [ 3095],
        [ 2635],
        [ 2274],
        [ 1940],
        [ 4005],
        [ 3878],
        [ 3780],
        [ 4320],
        [ 2791],
        [ 5118],
        [ 2430],
        [ 2009]], device='cuda:0')
[2024-07-24 10:20:18,031][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[15520],
        [23753],
        [22640],
        [ 9737],
        [ 9956],
        [ 9222],
        [ 7758],
        [11394],
        [11186],
        [12790],
        [13556],
        [ 7471],
        [15195],
        [ 7859],
        [ 8237]], device='cuda:0')
[2024-07-24 10:20:18,033][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[36299],
        [43758],
        [41932],
        [43322],
        [41673],
        [41859],
        [41640],
        [40504],
        [39729],
        [40682],
        [41094],
        [41792],
        [41125],
        [40930],
        [41528]], device='cuda:0')
[2024-07-24 10:20:18,034][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[3742],
        [2888],
        [3113],
        [2935],
        [3149],
        [3169],
        [3340],
        [3272],
        [3255],
        [3237],
        [3259],
        [3331],
        [3371],
        [3345],
        [3400]], device='cuda:0')
[2024-07-24 10:20:18,035][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[15109],
        [18900],
        [17801],
        [19190],
        [20261],
        [20392],
        [20570],
        [20617],
        [20818],
        [20728],
        [20846],
        [20885],
        [20934],
        [20957],
        [21038]], device='cuda:0')
[2024-07-24 10:20:18,036][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[27670],
        [28250],
        [20944],
        [25284],
        [20353],
        [21032],
        [20962],
        [20781],
        [20959],
        [21163],
        [21237],
        [20795],
        [20939],
        [21277],
        [21942]], device='cuda:0')
[2024-07-24 10:20:18,037][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[1341],
        [1846],
        [2411],
        [1842],
        [1962],
        [1976],
        [1877],
        [1819],
        [1819],
        [1779],
        [1665],
        [1653],
        [1708],
        [1760],
        [1795]], device='cuda:0')
[2024-07-24 10:20:18,038][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[17439],
        [23450],
        [ 8602],
        [11652],
        [12079],
        [16216],
        [16515],
        [17982],
        [19528],
        [20087],
        [20726],
        [20833],
        [20780],
        [19943],
        [20801]], device='cuda:0')
[2024-07-24 10:20:18,040][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[37937],
        [37777],
        [31872],
        [34753],
        [31239],
        [30144],
        [31868],
        [31930],
        [32533],
        [33761],
        [33136],
        [34253],
        [34228],
        [34890],
        [35272]], device='cuda:0')
[2024-07-24 10:20:18,041][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[24997],
        [25524],
        [22233],
        [24943],
        [26765],
        [27817],
        [27178],
        [27491],
        [28069],
        [27948],
        [28126],
        [27920],
        [28601],
        [29072],
        [29408]], device='cuda:0')
[2024-07-24 10:20:18,043][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[5884],
        [5472],
        [5008],
        [5207],
        [4749],
        [4559],
        [4560],
        [4728],
        [4729],
        [4865],
        [5007],
        [5065],
        [5071],
        [5140],
        [5169]], device='cuda:0')
[2024-07-24 10:20:18,044][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[6902],
        [7603],
        [8278],
        [8573],
        [8664],
        [8764],
        [8926],
        [9061],
        [9096],
        [9171],
        [9279],
        [9331],
        [9369],
        [9370],
        [9349]], device='cuda:0')
[2024-07-24 10:20:18,045][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[14547],
        [27532],
        [21788],
        [24858],
        [20041],
        [22425],
        [23620],
        [24803],
        [24638],
        [24886],
        [25296],
        [24569],
        [21806],
        [21804],
        [22336]], device='cuda:0')
[2024-07-24 10:20:18,046][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24647],
        [21249],
        [16799],
        [17196],
        [16194],
        [16277],
        [16054],
        [16595],
        [16868],
        [16976],
        [17112],
        [17151],
        [17127],
        [17069],
        [16881]], device='cuda:0')
[2024-07-24 10:20:18,047][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[38350],
        [25073],
        [ 3206],
        [ 9210],
        [ 6705],
        [ 8989],
        [ 9059],
        [ 8906],
        [10880],
        [ 8739],
        [ 8904],
        [ 9449],
        [ 6034],
        [ 9682],
        [ 5330]], device='cuda:0')
[2024-07-24 10:20:18,048][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[28927],
        [19652],
        [23071],
        [21898],
        [23134],
        [22981],
        [23242],
        [24001],
        [24394],
        [24104],
        [23359],
        [22857],
        [23027],
        [23384],
        [23176]], device='cuda:0')
[2024-07-24 10:20:18,049][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[39324],
        [18673],
        [18919],
        [18539],
        [18353],
        [18726],
        [18094],
        [17527],
        [17605],
        [17192],
        [16600],
        [16467],
        [16099],
        [16523],
        [16355]], device='cuda:0')
[2024-07-24 10:20:18,051][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[37919],
        [28826],
        [30962],
        [30112],
        [30856],
        [31015],
        [31321],
        [32190],
        [32710],
        [32399],
        [32104],
        [32076],
        [31944],
        [32062],
        [32040]], device='cuda:0')
[2024-07-24 10:20:18,052][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[10912],
        [16182],
        [19515],
        [20928],
        [22303],
        [22781],
        [22873],
        [22826],
        [22758],
        [22696],
        [22931],
        [23498],
        [24130],
        [24438],
        [24602]], device='cuda:0')
[2024-07-24 10:20:18,054][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[47324],
        [43593],
        [39389],
        [40725],
        [40425],
        [40008],
        [40030],
        [39933],
        [39576],
        [39608],
        [39620],
        [39590],
        [39689],
        [39519],
        [39263]], device='cuda:0')
[2024-07-24 10:20:18,055][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[32822],
        [37522],
        [33483],
        [31687],
        [31911],
        [33099],
        [32421],
        [33221],
        [33175],
        [33048],
        [33051],
        [34805],
        [34115],
        [34464],
        [34575]], device='cuda:0')
[2024-07-24 10:20:18,056][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[41895],
        [43359],
        [46032],
        [45421],
        [44109],
        [43680],
        [42666],
        [40325],
        [40041],
        [40512],
        [40764],
        [40993],
        [41064],
        [40456],
        [40409]], device='cuda:0')
[2024-07-24 10:20:18,057][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22926],
        [22672],
        [20921],
        [21832],
        [22554],
        [23450],
        [23983],
        [24314],
        [24951],
        [24813],
        [24858],
        [24929],
        [24876],
        [24857],
        [24851]], device='cuda:0')
[2024-07-24 10:20:18,058][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[36938],
        [24897],
        [23299],
        [22075],
        [23826],
        [24012],
        [24814],
        [25849],
        [24194],
        [23669],
        [23165],
        [24572],
        [24642],
        [23470],
        [23391]], device='cuda:0')
[2024-07-24 10:20:18,059][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[24106],
        [23821],
        [22010],
        [15425],
        [12504],
        [ 9460],
        [ 5922],
        [ 2907],
        [ 3892],
        [ 5181],
        [ 6280],
        [ 4760],
        [ 4342],
        [ 3626],
        [ 4491]], device='cuda:0')
[2024-07-24 10:20:18,061][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[23336],
        [16739],
        [13223],
        [19017],
        [ 9851],
        [ 7282],
        [ 9305],
        [ 7950],
        [ 9516],
        [ 8274],
        [ 8052],
        [ 6615],
        [ 9937],
        [ 7443],
        [ 7447]], device='cuda:0')
[2024-07-24 10:20:18,062][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10101],
        [12284],
        [10673],
        [12211],
        [11920],
        [12969],
        [13851],
        [14311],
        [14586],
        [14643],
        [14737],
        [14612],
        [14207],
        [14504],
        [14720]], device='cuda:0')
[2024-07-24 10:20:18,064][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 9674],
        [17320],
        [18989],
        [18358],
        [21773],
        [21600],
        [22827],
        [24782],
        [23167],
        [23880],
        [23503],
        [24411],
        [23557],
        [23971],
        [24106]], device='cuda:0')
[2024-07-24 10:20:18,065][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[ 4988],
        [20245],
        [39858],
        [34636],
        [35914],
        [32618],
        [31450],
        [31983],
        [31688],
        [30973],
        [31510],
        [33029],
        [35050],
        [33760],
        [36693]], device='cuda:0')
[2024-07-24 10:20:18,066][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876],
        [34876]], device='cuda:0')
[2024-07-24 10:20:18,099][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:18,100][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,100][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,100][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,101][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,101][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,101][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,102][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,102][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,104][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,105][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,106][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,107][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,109][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8818, 0.1182], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,109][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.5502, 0.4498], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,110][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6514, 0.3486], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,110][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5336, 0.4664], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,110][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0179, 0.9821], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,111][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.2173, 0.7827], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,111][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6673, 0.3327], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,111][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.8102, 0.1898], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,111][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3035, 0.6965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,112][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0292, 0.9708], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,112][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.9450, 0.0550], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,112][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1292, 0.8708], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,114][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.8323, 0.0875, 0.0802], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,116][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.5859, 0.1575, 0.2567], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,117][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.5269, 0.2737, 0.1994], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,119][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.7112, 0.2361, 0.0527], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,120][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.0071, 0.5007, 0.4922], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,120][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.1161, 0.4750, 0.4088], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,120][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.6718, 0.2128, 0.1154], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,120][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.5713, 0.2143, 0.2144], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,121][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.1731, 0.4389, 0.3881], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,121][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.0191, 0.5045, 0.4764], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,121][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.7324, 0.0599, 0.2077], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,122][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.1108, 0.6077, 0.2816], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,122][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.9210, 0.0311, 0.0270, 0.0208], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,122][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4692, 0.0676, 0.1202, 0.3430], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,123][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.4439, 0.2191, 0.1685, 0.1685], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,125][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4600, 0.2219, 0.0597, 0.2584], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,126][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0078, 0.3142, 0.3043, 0.3736], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,128][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0848, 0.3279, 0.2830, 0.3042], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,129][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.7606, 0.1397, 0.0619, 0.0378], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,130][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.5637, 0.1558, 0.1596, 0.1209], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,130][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1343, 0.2837, 0.2669, 0.3151], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,131][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0125, 0.3178, 0.3000, 0.3697], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,131][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4502, 0.0465, 0.1840, 0.3193], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,131][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0617, 0.5150, 0.2016, 0.2217], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,131][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.5683, 0.0804, 0.0838, 0.0998, 0.1676], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,132][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.2577, 0.0430, 0.0919, 0.3799, 0.2276], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,132][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.4288, 0.1853, 0.1391, 0.1331, 0.1137], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,132][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.4263, 0.2771, 0.0408, 0.2458, 0.0101], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,133][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0041, 0.2285, 0.2253, 0.2732, 0.2688], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,133][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0634, 0.2562, 0.2213, 0.2467, 0.2125], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,135][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.6261, 0.1478, 0.0695, 0.0424, 0.1143], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,137][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.4616, 0.1362, 0.1349, 0.1133, 0.1539], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,138][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0663, 0.2473, 0.2000, 0.3112, 0.1752], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,139][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0064, 0.2442, 0.2322, 0.2953, 0.2220], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,140][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.5529, 0.0320, 0.1091, 0.1996, 0.1064], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,141][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0375, 0.5030, 0.1917, 0.1900, 0.0778], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,141][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.5843, 0.0608, 0.0566, 0.0625, 0.1195, 0.1164], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,141][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.1533, 0.0389, 0.0636, 0.2697, 0.1131, 0.3613], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,142][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.3799, 0.1659, 0.1217, 0.1176, 0.1001, 0.1148], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,142][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.4372, 0.2105, 0.0265, 0.3016, 0.0085, 0.0157], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,142][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0042, 0.1840, 0.1862, 0.2240, 0.2185, 0.1831], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,142][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0633, 0.2004, 0.1684, 0.1917, 0.1690, 0.2072], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,143][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.4702, 0.1432, 0.0702, 0.0464, 0.1109, 0.1592], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,143][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.4105, 0.1154, 0.1175, 0.0947, 0.1382, 0.1236], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,144][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0765, 0.1840, 0.1558, 0.2184, 0.1504, 0.2148], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,145][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0045, 0.2055, 0.1927, 0.2450, 0.1793, 0.1730], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,147][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.3971, 0.0346, 0.1121, 0.1623, 0.1187, 0.1752], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,148][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0423, 0.4541, 0.1397, 0.1793, 0.0646, 0.1200], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,150][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.5972, 0.0476, 0.0445, 0.0442, 0.0853, 0.0770, 0.1044],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,151][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.1807, 0.0250, 0.0461, 0.1637, 0.0820, 0.2347, 0.2678],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,151][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.3323, 0.1491, 0.1109, 0.1077, 0.0915, 0.1039, 0.1046],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,151][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.5502, 0.1439, 0.0206, 0.2467, 0.0083, 0.0149, 0.0154],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,152][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0049, 0.1532, 0.1538, 0.1760, 0.1793, 0.1610, 0.1718],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,152][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0489, 0.1668, 0.1455, 0.1555, 0.1477, 0.1750, 0.1605],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,152][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.3711, 0.1263, 0.0651, 0.0432, 0.1026, 0.1438, 0.1479],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,153][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3660, 0.0986, 0.1020, 0.0787, 0.1247, 0.1058, 0.1241],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,153][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0503, 0.1565, 0.1356, 0.1904, 0.1378, 0.2012, 0.1281],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,154][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0055, 0.1607, 0.1525, 0.1898, 0.1497, 0.1446, 0.1972],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,156][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3076, 0.0302, 0.1006, 0.1300, 0.1149, 0.1428, 0.1739],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,157][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0358, 0.4451, 0.1270, 0.1502, 0.0593, 0.0991, 0.0836],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,159][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.5020, 0.0401, 0.0391, 0.0444, 0.0936, 0.0770, 0.1132, 0.0905],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,160][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0983, 0.0131, 0.0335, 0.1346, 0.0588, 0.2033, 0.2509, 0.2075],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,161][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.2826, 0.1360, 0.1031, 0.1009, 0.0841, 0.0966, 0.0975, 0.0992],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,161][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.5012, 0.1611, 0.0152, 0.2780, 0.0059, 0.0124, 0.0172, 0.0090],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,162][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0032, 0.1311, 0.1357, 0.1622, 0.1437, 0.1301, 0.1635, 0.1306],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,162][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0412, 0.1453, 0.1200, 0.1389, 0.1194, 0.1507, 0.1382, 0.1463],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,162][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.4376, 0.1065, 0.0484, 0.0288, 0.0776, 0.1068, 0.1103, 0.0839],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,163][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.3453, 0.0848, 0.0931, 0.0700, 0.1054, 0.0909, 0.1073, 0.1032],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,163][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0678, 0.1417, 0.1115, 0.1572, 0.1034, 0.1542, 0.1288, 0.1355],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,163][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0036, 0.1419, 0.1354, 0.1693, 0.1266, 0.1228, 0.1725, 0.1279],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,164][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.4544, 0.0117, 0.0604, 0.0971, 0.0654, 0.1001, 0.1440, 0.0669],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,166][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0349, 0.3979, 0.1106, 0.1439, 0.0516, 0.0758, 0.0628, 0.1224],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,168][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.4217, 0.0362, 0.0366, 0.0376, 0.0784, 0.0749, 0.1085, 0.0973, 0.1088],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,169][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0993, 0.0126, 0.0286, 0.1031, 0.0626, 0.1448, 0.1840, 0.1994, 0.1656],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,170][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.2596, 0.1252, 0.0944, 0.0923, 0.0768, 0.0878, 0.0888, 0.0905, 0.0846],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,171][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.5881, 0.1325, 0.0144, 0.1993, 0.0062, 0.0130, 0.0207, 0.0091, 0.0166],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,172][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0019, 0.1118, 0.1175, 0.1370, 0.1248, 0.1162, 0.1439, 0.1199, 0.1271],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,172][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0298, 0.1289, 0.1045, 0.1212, 0.1066, 0.1316, 0.1213, 0.1349, 0.1210],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,172][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.5160, 0.0954, 0.0368, 0.0199, 0.0635, 0.0855, 0.0895, 0.0677, 0.0258],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,173][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.3526, 0.0809, 0.0865, 0.0610, 0.0909, 0.0764, 0.0923, 0.0893, 0.0701],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,173][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0564, 0.1222, 0.0996, 0.1444, 0.0935, 0.1349, 0.1108, 0.1332, 0.1049],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,173][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0040, 0.1225, 0.1172, 0.1447, 0.1136, 0.1095, 0.1492, 0.1133, 0.1261],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,174][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.2429, 0.0217, 0.0867, 0.1039, 0.0946, 0.1005, 0.1213, 0.0772, 0.1511],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,175][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0239, 0.3726, 0.1016, 0.1142, 0.0480, 0.0680, 0.0549, 0.1314, 0.0854],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,176][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4872, 0.0332, 0.0322, 0.0286, 0.0731, 0.0537, 0.0756, 0.0715, 0.0835,
        0.0613], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,178][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0641, 0.0126, 0.0276, 0.1029, 0.0520, 0.1433, 0.1778, 0.1832, 0.1364,
        0.1001], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,180][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2415, 0.1138, 0.0867, 0.0848, 0.0710, 0.0810, 0.0816, 0.0833, 0.0779,
        0.0783], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,181][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5277, 0.1361, 0.0158, 0.2229, 0.0074, 0.0152, 0.0190, 0.0101, 0.0236,
        0.0221], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,182][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0029, 0.1020, 0.1007, 0.1200, 0.1127, 0.1020, 0.1169, 0.1014, 0.1068,
        0.1346], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,182][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0310, 0.1115, 0.0947, 0.1044, 0.0929, 0.1184, 0.1077, 0.1175, 0.1085,
        0.1135], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,182][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.4946, 0.0980, 0.0340, 0.0196, 0.0615, 0.0889, 0.0906, 0.0647, 0.0237,
        0.0244], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,183][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3097, 0.0794, 0.0808, 0.0584, 0.0869, 0.0719, 0.0856, 0.0834, 0.0651,
        0.0789], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,183][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0496, 0.1039, 0.0973, 0.1187, 0.0898, 0.1306, 0.1017, 0.1165, 0.1116,
        0.0804], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,184][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0041, 0.1096, 0.1030, 0.1262, 0.1017, 0.0951, 0.1273, 0.0988, 0.1071,
        0.1270], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,184][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.2798, 0.0102, 0.0579, 0.0837, 0.0601, 0.0833, 0.1163, 0.0566, 0.1623,
        0.0898], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,185][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0238, 0.2659, 0.1000, 0.1000, 0.0589, 0.0760, 0.0594, 0.1436, 0.1020,
        0.0704], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,186][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.4882, 0.0293, 0.0284, 0.0235, 0.0649, 0.0453, 0.0665, 0.0622, 0.0719,
        0.0562, 0.0637], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,188][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0673, 0.0112, 0.0249, 0.0893, 0.0437, 0.1209, 0.1527, 0.1597, 0.1194,
        0.0927, 0.1183], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,190][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2272, 0.1057, 0.0805, 0.0789, 0.0659, 0.0758, 0.0758, 0.0780, 0.0725,
        0.0725, 0.0672], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,191][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.4581, 0.1702, 0.0220, 0.2023, 0.0078, 0.0132, 0.0159, 0.0092, 0.0216,
        0.0270, 0.0528], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,192][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0026, 0.0901, 0.0875, 0.1048, 0.1009, 0.0901, 0.1010, 0.0914, 0.0941,
        0.1197, 0.1179], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,192][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0261, 0.1003, 0.0866, 0.0920, 0.0865, 0.1066, 0.0974, 0.1090, 0.0989,
        0.1021, 0.0944], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,192][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.4487, 0.0964, 0.0355, 0.0210, 0.0650, 0.0929, 0.0967, 0.0684, 0.0242,
        0.0249, 0.0263], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,193][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.3103, 0.0721, 0.0731, 0.0523, 0.0775, 0.0636, 0.0759, 0.0755, 0.0576,
        0.0732, 0.0690], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,193][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0346, 0.0953, 0.0888, 0.1046, 0.0839, 0.1202, 0.0916, 0.1096, 0.1068,
        0.0806, 0.0840], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,193][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0041, 0.0938, 0.0890, 0.1087, 0.0906, 0.0853, 0.1133, 0.0882, 0.0955,
        0.1099, 0.1216], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,194][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1931, 0.0133, 0.0560, 0.0821, 0.0607, 0.0782, 0.1038, 0.0581, 0.1363,
        0.0864, 0.1319], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,194][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0280, 0.2612, 0.0867, 0.0917, 0.0471, 0.0694, 0.0553, 0.1240, 0.0865,
        0.0631, 0.0871], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,196][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.2678, 0.0297, 0.0296, 0.0327, 0.0602, 0.0583, 0.0834, 0.0669, 0.0800,
        0.0686, 0.0821, 0.1406], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,198][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0585, 0.0090, 0.0200, 0.0737, 0.0410, 0.0984, 0.1310, 0.1168, 0.1058,
        0.0833, 0.1239, 0.1384], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,199][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.2054, 0.0992, 0.0765, 0.0748, 0.0628, 0.0706, 0.0713, 0.0716, 0.0666,
        0.0670, 0.0624, 0.0718], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,201][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.4857, 0.1930, 0.0167, 0.1865, 0.0051, 0.0102, 0.0136, 0.0073, 0.0176,
        0.0189, 0.0382, 0.0071], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,202][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0016, 0.0808, 0.0823, 0.0947, 0.0917, 0.0826, 0.0983, 0.0823, 0.0844,
        0.1088, 0.1073, 0.0851], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,204][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0207, 0.0911, 0.0741, 0.0867, 0.0738, 0.0943, 0.0871, 0.0981, 0.0871,
        0.0950, 0.0901, 0.1019], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,206][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.4539, 0.0843, 0.0333, 0.0189, 0.0620, 0.0879, 0.0925, 0.0663, 0.0231,
        0.0242, 0.0253, 0.0283], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,207][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.2891, 0.0678, 0.0662, 0.0496, 0.0690, 0.0604, 0.0716, 0.0721, 0.0557,
        0.0697, 0.0658, 0.0630], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,208][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0233, 0.0898, 0.0764, 0.1085, 0.0727, 0.1063, 0.0849, 0.1032, 0.0926,
        0.0844, 0.0923, 0.0658], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,208][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0052, 0.0804, 0.0782, 0.0918, 0.0806, 0.0761, 0.0984, 0.0795, 0.0882,
        0.0957, 0.1035, 0.1224], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,208][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1061, 0.0246, 0.0674, 0.0801, 0.0850, 0.0747, 0.0817, 0.0616, 0.0869,
        0.0773, 0.1065, 0.1481], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,209][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0183, 0.2497, 0.0832, 0.0860, 0.0436, 0.0636, 0.0511, 0.1216, 0.0804,
        0.0563, 0.0813, 0.0650], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,209][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.1885, 0.0239, 0.0290, 0.0356, 0.0598, 0.0528, 0.0705, 0.0674, 0.0800,
        0.0634, 0.0745, 0.1317, 0.1230], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,210][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0544, 0.0063, 0.0164, 0.0675, 0.0427, 0.0829, 0.1129, 0.1085, 0.0963,
        0.0680, 0.1081, 0.1535, 0.0825], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,210][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.1917, 0.0960, 0.0732, 0.0706, 0.0578, 0.0663, 0.0677, 0.0684, 0.0621,
        0.0633, 0.0586, 0.0669, 0.0575], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,210][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.4408, 0.2369, 0.0198, 0.1673, 0.0040, 0.0115, 0.0140, 0.0079, 0.0216,
        0.0233, 0.0424, 0.0070, 0.0036], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,211][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0014, 0.0733, 0.0718, 0.0858, 0.0840, 0.0770, 0.0845, 0.0760, 0.0819,
        0.1001, 0.0964, 0.0764, 0.0914], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,212][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0193, 0.0841, 0.0716, 0.0803, 0.0687, 0.0902, 0.0799, 0.0907, 0.0829,
        0.0862, 0.0820, 0.0958, 0.0680], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,213][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.5770, 0.0770, 0.0255, 0.0145, 0.0463, 0.0594, 0.0622, 0.0437, 0.0154,
        0.0166, 0.0177, 0.0181, 0.0266], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,215][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.2531, 0.0657, 0.0654, 0.0499, 0.0683, 0.0576, 0.0678, 0.0670, 0.0548,
        0.0661, 0.0630, 0.0627, 0.0586], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,217][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0227, 0.0848, 0.0664, 0.1020, 0.0559, 0.1048, 0.0683, 0.1041, 0.0967,
        0.0873, 0.0866, 0.0670, 0.0533], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,218][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0037, 0.0723, 0.0698, 0.0843, 0.0708, 0.0679, 0.0901, 0.0712, 0.0787,
        0.0857, 0.0932, 0.1119, 0.1006], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,219][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.1322, 0.0173, 0.0557, 0.0658, 0.0669, 0.0614, 0.0715, 0.0494, 0.0789,
        0.0614, 0.0909, 0.1454, 0.1031], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,219][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0156, 0.2359, 0.0847, 0.0841, 0.0359, 0.0594, 0.0472, 0.1203, 0.0764,
        0.0491, 0.0782, 0.0653, 0.0480], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,219][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.2255, 0.0200, 0.0227, 0.0251, 0.0433, 0.0466, 0.0631, 0.0532, 0.0642,
        0.0534, 0.0637, 0.1131, 0.0886, 0.1177], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,220][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0589, 0.0053, 0.0133, 0.0493, 0.0291, 0.0716, 0.0981, 0.0955, 0.0876,
        0.0624, 0.0906, 0.1265, 0.0531, 0.1587], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,220][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.1813, 0.0865, 0.0660, 0.0648, 0.0538, 0.0617, 0.0626, 0.0638, 0.0596,
        0.0599, 0.0556, 0.0638, 0.0542, 0.0664], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,221][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.4067, 0.1938, 0.0190, 0.2146, 0.0048, 0.0089, 0.0134, 0.0076, 0.0204,
        0.0334, 0.0586, 0.0113, 0.0042, 0.0033], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,221][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0014, 0.0670, 0.0681, 0.0782, 0.0731, 0.0721, 0.0797, 0.0689, 0.0763,
        0.0921, 0.0897, 0.0770, 0.0798, 0.0767], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,223][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0232, 0.0768, 0.0652, 0.0723, 0.0666, 0.0814, 0.0737, 0.0809, 0.0739,
        0.0781, 0.0759, 0.0884, 0.0667, 0.0769], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,225][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.3313, 0.0896, 0.0365, 0.0225, 0.0625, 0.0853, 0.0832, 0.0648, 0.0266,
        0.0281, 0.0280, 0.0307, 0.0399, 0.0710], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,226][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.2340, 0.0574, 0.0579, 0.0440, 0.0633, 0.0529, 0.0630, 0.0636, 0.0523,
        0.0629, 0.0616, 0.0611, 0.0583, 0.0679], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,228][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0258, 0.0788, 0.0680, 0.0909, 0.0655, 0.0917, 0.0694, 0.0862, 0.0787,
        0.0684, 0.0758, 0.0613, 0.0615, 0.0781], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,228][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0038, 0.0677, 0.0654, 0.0760, 0.0649, 0.0619, 0.0807, 0.0642, 0.0711,
        0.0794, 0.0851, 0.1008, 0.0910, 0.0879], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,229][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0759, 0.0299, 0.0631, 0.0661, 0.0807, 0.0654, 0.0673, 0.0550, 0.0687,
        0.0670, 0.0854, 0.1042, 0.0791, 0.0921], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,229][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0194, 0.2675, 0.0723, 0.0829, 0.0291, 0.0504, 0.0408, 0.0965, 0.0672,
        0.0499, 0.0715, 0.0596, 0.0391, 0.0537], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,230][circuit_model.py][line:2294][INFO] ##6-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2985, 0.0210, 0.0216, 0.0195, 0.0413, 0.0337, 0.0488, 0.0419, 0.0481,
        0.0402, 0.0466, 0.0916, 0.0818, 0.0961, 0.0691], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,230][circuit_model.py][line:2297][INFO] ##6-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0505, 0.0065, 0.0162, 0.0574, 0.0299, 0.0787, 0.0958, 0.0878, 0.0687,
        0.0556, 0.0748, 0.0953, 0.0436, 0.1327, 0.1066], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,230][circuit_model.py][line:2300][INFO] ##6-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1690, 0.0818, 0.0630, 0.0617, 0.0512, 0.0582, 0.0587, 0.0600, 0.0557,
        0.0563, 0.0524, 0.0602, 0.0511, 0.0623, 0.0584], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,231][circuit_model.py][line:2303][INFO] ##6-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.5953, 0.1354, 0.0128, 0.1589, 0.0038, 0.0063, 0.0072, 0.0040, 0.0102,
        0.0162, 0.0330, 0.0083, 0.0044, 0.0018, 0.0022], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,232][circuit_model.py][line:2306][INFO] ##6-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0018, 0.0634, 0.0638, 0.0745, 0.0703, 0.0661, 0.0737, 0.0627, 0.0682,
        0.0847, 0.0842, 0.0667, 0.0761, 0.0692, 0.0746], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,233][circuit_model.py][line:2309][INFO] ##6-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0201, 0.0718, 0.0614, 0.0663, 0.0634, 0.0751, 0.0705, 0.0766, 0.0676,
        0.0728, 0.0695, 0.0803, 0.0624, 0.0729, 0.0694], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,235][circuit_model.py][line:2312][INFO] ##6-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.2935, 0.0838, 0.0365, 0.0224, 0.0594, 0.0844, 0.0868, 0.0616, 0.0250,
        0.0274, 0.0283, 0.0293, 0.0361, 0.0654, 0.0602], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,237][circuit_model.py][line:2315][INFO] ##6-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.2407, 0.0580, 0.0595, 0.0428, 0.0617, 0.0488, 0.0580, 0.0581, 0.0457,
        0.0569, 0.0535, 0.0528, 0.0517, 0.0599, 0.0519], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,238][circuit_model.py][line:2318][INFO] ##6-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0198, 0.0705, 0.0643, 0.0831, 0.0631, 0.0885, 0.0704, 0.0784, 0.0767,
        0.0605, 0.0656, 0.0541, 0.0562, 0.0826, 0.0664], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,239][circuit_model.py][line:2321][INFO] ##6-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0037, 0.0616, 0.0589, 0.0695, 0.0594, 0.0566, 0.0737, 0.0592, 0.0642,
        0.0718, 0.0775, 0.0916, 0.0836, 0.0815, 0.0870], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,239][circuit_model.py][line:2324][INFO] ##6-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0868, 0.0163, 0.0447, 0.0519, 0.0553, 0.0532, 0.0622, 0.0446, 0.0705,
        0.0576, 0.0746, 0.1093, 0.0783, 0.1037, 0.0909], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,239][circuit_model.py][line:2327][INFO] ##6-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0232, 0.1956, 0.0858, 0.0718, 0.0356, 0.0499, 0.0389, 0.0888, 0.0598,
        0.0445, 0.0630, 0.0520, 0.0424, 0.0483, 0.1004], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,275][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:18,275][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,276][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,276][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,276][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,277][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,278][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,280][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,281][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,282][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,283][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,284][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,284][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,285][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.9351, 0.0649], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,285][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.3675, 0.6325], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,285][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4828, 0.5172], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,286][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.5854, 0.4146], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,286][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.8656, 0.1344], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,286][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3814, 0.6186], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,286][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2869, 0.7131], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,287][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.5606, 0.4394], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,287][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.9431, 0.0569], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,289][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0450, 0.9550], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,291][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1656, 0.8344], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,292][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8487, 0.1513], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,293][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.7014, 0.1102, 0.1884], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,294][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([0.3915, 0.3535, 0.2550], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,295][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.2786, 0.3999, 0.3215], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,295][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.5162, 0.3122, 0.1716], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,295][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.7098, 0.1502, 0.1400], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,296][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.4698, 0.5044, 0.0257], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,296][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.1860, 0.1944, 0.6196], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,296][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.4627, 0.2450, 0.2923], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,297][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.7155, 0.0758, 0.2087], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,297][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.0240, 0.5797, 0.3963], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,297][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.1461, 0.5234, 0.3305], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,298][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.5127, 0.1782, 0.3091], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,299][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.8328, 0.0348, 0.0802, 0.0522], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,301][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2924, 0.2341, 0.1583, 0.3152], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,303][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.2868, 0.2394, 0.2145, 0.2593], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,304][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5744, 0.1302, 0.0830, 0.2125], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,305][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.7558, 0.0912, 0.0925, 0.0605], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,305][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4821, 0.4178, 0.0295, 0.0705], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,305][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1612, 0.2657, 0.1756, 0.3975], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,306][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.4862, 0.1336, 0.2059, 0.1744], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,306][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.7191, 0.0336, 0.1180, 0.1293], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,306][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0177, 0.3796, 0.2675, 0.3351], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,307][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0755, 0.2712, 0.1781, 0.4752], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,307][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.5775, 0.0745, 0.1642, 0.1838], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,307][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.3996, 0.0893, 0.1440, 0.1784, 0.1887], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,308][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.1686, 0.1441, 0.1132, 0.3619, 0.2121], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,308][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.2104, 0.2239, 0.1605, 0.2625, 0.1426], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,310][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.3957, 0.1651, 0.0795, 0.2778, 0.0820], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,311][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.5350, 0.1330, 0.1257, 0.0978, 0.1085], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,313][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.4585, 0.4283, 0.0260, 0.0658, 0.0214], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,314][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.1640, 0.1349, 0.2352, 0.1388, 0.3272], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,315][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.2585, 0.1318, 0.1946, 0.1909, 0.2242], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,315][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.4064, 0.0440, 0.1276, 0.2137, 0.2083], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,316][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0122, 0.3157, 0.2151, 0.2916, 0.1654], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,316][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0593, 0.2230, 0.1145, 0.4369, 0.1662], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,316][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.2615, 0.0921, 0.1376, 0.2652, 0.2436], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,317][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.4206, 0.0680, 0.1173, 0.1156, 0.1392, 0.1393], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,317][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1007, 0.1325, 0.0859, 0.2333, 0.1150, 0.3326], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,317][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1590, 0.2008, 0.1362, 0.2235, 0.1426, 0.1379], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,318][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.4384, 0.1179, 0.0686, 0.2370, 0.0550, 0.0830], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,318][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.5088, 0.1064, 0.1011, 0.0737, 0.0916, 0.1183], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,320][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3358, 0.4349, 0.0385, 0.0766, 0.0325, 0.0817], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,322][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0775, 0.2329, 0.1487, 0.1513, 0.1671, 0.2225], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,323][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1892, 0.1124, 0.1547, 0.1564, 0.1510, 0.2364], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,325][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3737, 0.0365, 0.1004, 0.1740, 0.1709, 0.1445], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,325][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0114, 0.2625, 0.1804, 0.2280, 0.1375, 0.1802], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,326][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0482, 0.1713, 0.0839, 0.3633, 0.1314, 0.2019], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,326][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.2336, 0.0604, 0.1148, 0.1882, 0.1955, 0.2074], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,326][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.4309, 0.0561, 0.0965, 0.0873, 0.1099, 0.0991, 0.1202],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,327][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.1320, 0.0865, 0.0664, 0.1534, 0.0911, 0.2240, 0.2465],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,327][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1461, 0.1588, 0.1117, 0.1583, 0.1179, 0.1278, 0.1795],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,327][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4259, 0.1036, 0.0629, 0.1848, 0.0504, 0.0723, 0.1000],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,328][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.4793, 0.0853, 0.0842, 0.0591, 0.0788, 0.0971, 0.1161],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,328][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3882, 0.3520, 0.0297, 0.0591, 0.0251, 0.0657, 0.0802],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,329][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0959, 0.1561, 0.1612, 0.1411, 0.1071, 0.1227, 0.2159],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,330][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1840, 0.0907, 0.1245, 0.1204, 0.1237, 0.1804, 0.1764],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,332][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.3883, 0.0245, 0.0786, 0.1045, 0.1262, 0.1078, 0.1701],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,333][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0106, 0.2187, 0.1525, 0.1951, 0.1181, 0.1542, 0.1508],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,335][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0291, 0.1294, 0.1001, 0.2780, 0.1381, 0.2150, 0.1102],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,336][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.2394, 0.0500, 0.0924, 0.1317, 0.1385, 0.1584, 0.1897],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,336][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.3648, 0.0417, 0.0806, 0.0822, 0.1104, 0.0919, 0.1184, 0.1099],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,336][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0642, 0.0512, 0.0497, 0.1302, 0.0650, 0.2061, 0.2382, 0.1955],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,337][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0969, 0.1321, 0.0915, 0.1638, 0.1027, 0.1220, 0.1528, 0.1381],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,337][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.4651, 0.0939, 0.0471, 0.1446, 0.0422, 0.0533, 0.0746, 0.0791],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,337][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.4396, 0.0820, 0.0761, 0.0519, 0.0701, 0.0894, 0.1089, 0.0820],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,338][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2782, 0.3085, 0.0320, 0.0655, 0.0317, 0.0795, 0.0936, 0.1110],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,338][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1055, 0.1443, 0.0847, 0.1431, 0.1099, 0.1080, 0.1267, 0.1778],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,338][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1367, 0.0723, 0.0991, 0.1049, 0.1020, 0.1607, 0.1605, 0.1639],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,339][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.2940, 0.0189, 0.0598, 0.0930, 0.1031, 0.0986, 0.1699, 0.1625],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,341][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0088, 0.1874, 0.1303, 0.1675, 0.0996, 0.1308, 0.1301, 0.1455],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,342][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0279, 0.1183, 0.0810, 0.2507, 0.1038, 0.1512, 0.1062, 0.1609],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,344][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.1992, 0.0346, 0.0623, 0.1004, 0.1126, 0.1351, 0.1643, 0.1915],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,345][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.2896, 0.0389, 0.0736, 0.0672, 0.0887, 0.0891, 0.1129, 0.1202, 0.1196],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,346][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0644, 0.0487, 0.0419, 0.1075, 0.0689, 0.1544, 0.1854, 0.1894, 0.1393],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,346][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0940, 0.1021, 0.0732, 0.1402, 0.0787, 0.1276, 0.1416, 0.1167, 0.1259],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,347][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.4801, 0.0861, 0.0386, 0.1221, 0.0382, 0.0460, 0.0641, 0.0735, 0.0513],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,347][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.4386, 0.0658, 0.0596, 0.0417, 0.0637, 0.0783, 0.0981, 0.0745, 0.0797],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,347][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.3233, 0.2436, 0.0272, 0.0533, 0.0250, 0.0634, 0.0718, 0.0853, 0.1072],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,348][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0865, 0.1323, 0.1471, 0.1262, 0.1291, 0.0868, 0.0866, 0.0580, 0.1472],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,348][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1225, 0.0635, 0.0904, 0.0863, 0.0990, 0.1359, 0.1416, 0.1445, 0.1163],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,348][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.2382, 0.0177, 0.0541, 0.0795, 0.0971, 0.0791, 0.1410, 0.1528, 0.1406],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,349][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0076, 0.1697, 0.1137, 0.1492, 0.0874, 0.1156, 0.1126, 0.1271, 0.1171],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,350][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0217, 0.0937, 0.0672, 0.1860, 0.0891, 0.1337, 0.0781, 0.1279, 0.2027],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,352][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.1412, 0.0314, 0.0563, 0.0824, 0.0972, 0.1151, 0.1370, 0.1946, 0.1449],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,353][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3263, 0.0370, 0.0749, 0.0537, 0.0945, 0.0667, 0.0826, 0.0965, 0.0999,
        0.0679], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,355][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0527, 0.0469, 0.0410, 0.0879, 0.0606, 0.1449, 0.1624, 0.1730, 0.1160,
        0.1145], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,356][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0955, 0.1004, 0.0802, 0.1229, 0.0686, 0.0876, 0.1226, 0.0934, 0.1101,
        0.1187], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,356][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1979, 0.0866, 0.0506, 0.1508, 0.0436, 0.0677, 0.0933, 0.0911, 0.0796,
        0.1387], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,357][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.3688, 0.0676, 0.0648, 0.0448, 0.0607, 0.0745, 0.0916, 0.0678, 0.0772,
        0.0822], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,357][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.2043, 0.2557, 0.0267, 0.0562, 0.0254, 0.0681, 0.0808, 0.0947, 0.1250,
        0.0631], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,357][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0547, 0.1563, 0.0853, 0.1629, 0.1016, 0.0618, 0.0746, 0.0389, 0.0575,
        0.2064], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,358][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1116, 0.0654, 0.0872, 0.0773, 0.0905, 0.1192, 0.1176, 0.1332, 0.1024,
        0.0956], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,358][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.2334, 0.0160, 0.0547, 0.0649, 0.0843, 0.0712, 0.1127, 0.1368, 0.1293,
        0.0966], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,358][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0069, 0.1446, 0.1007, 0.1291, 0.0773, 0.0998, 0.0974, 0.1100, 0.1018,
        0.1323], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,359][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0200, 0.0735, 0.0554, 0.1691, 0.0881, 0.1120, 0.0703, 0.1163, 0.1682,
        0.1272], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,361][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1527, 0.0263, 0.0658, 0.0628, 0.1003, 0.0866, 0.1078, 0.1614, 0.1276,
        0.1086], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,362][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3560, 0.0321, 0.0641, 0.0424, 0.0825, 0.0563, 0.0735, 0.0835, 0.0844,
        0.0602, 0.0650], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,364][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0468, 0.0412, 0.0342, 0.0751, 0.0488, 0.1224, 0.1397, 0.1491, 0.0993,
        0.1034, 0.1401], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,365][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1218, 0.0899, 0.0811, 0.0991, 0.0692, 0.0746, 0.1098, 0.0836, 0.0955,
        0.0948, 0.0805], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,366][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2034, 0.0697, 0.0433, 0.1188, 0.0402, 0.0522, 0.0733, 0.0753, 0.0656,
        0.1111, 0.1470], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,367][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3715, 0.0586, 0.0568, 0.0389, 0.0566, 0.0640, 0.0794, 0.0586, 0.0658,
        0.0732, 0.0767], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,367][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.2214, 0.2252, 0.0255, 0.0501, 0.0230, 0.0606, 0.0704, 0.0824, 0.1085,
        0.0581, 0.0748], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,367][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0643, 0.1212, 0.0648, 0.1882, 0.0672, 0.0604, 0.0635, 0.0386, 0.0467,
        0.1444, 0.1407], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,368][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1301, 0.0545, 0.0796, 0.0670, 0.0864, 0.1024, 0.1061, 0.1156, 0.0909,
        0.0868, 0.0807], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,368][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.2373, 0.0142, 0.0477, 0.0520, 0.0724, 0.0576, 0.0964, 0.1145, 0.1098,
        0.0826, 0.1156], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,368][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0062, 0.1280, 0.0888, 0.1136, 0.0687, 0.0897, 0.0871, 0.0979, 0.0904,
        0.1169, 0.1126], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,369][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0129, 0.0671, 0.0513, 0.1265, 0.0805, 0.0980, 0.0560, 0.1038, 0.1553,
        0.1378, 0.1109], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,370][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1448, 0.0263, 0.0541, 0.0536, 0.0834, 0.0773, 0.0949, 0.1350, 0.1103,
        0.0998, 0.1206], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,371][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1735, 0.0354, 0.0560, 0.0588, 0.0664, 0.0682, 0.0839, 0.0801, 0.0857,
        0.0695, 0.0842, 0.1384], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,373][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0399, 0.0322, 0.0286, 0.0695, 0.0450, 0.1025, 0.1304, 0.1125, 0.0878,
        0.0894, 0.1328, 0.1293], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,374][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0805, 0.0824, 0.0572, 0.1141, 0.0406, 0.0896, 0.0925, 0.0833, 0.1009,
        0.1090, 0.1044, 0.0456], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,376][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.2824, 0.0629, 0.0312, 0.0940, 0.0288, 0.0398, 0.0527, 0.0583, 0.0448,
        0.0952, 0.1292, 0.0809], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,377][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.3002, 0.0523, 0.0459, 0.0332, 0.0550, 0.0638, 0.0771, 0.0595, 0.0619,
        0.0718, 0.0728, 0.1065], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,377][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.3608, 0.1622, 0.0184, 0.0364, 0.0149, 0.0444, 0.0465, 0.0590, 0.0750,
        0.0452, 0.0571, 0.0802], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,377][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0969, 0.1075, 0.0761, 0.1141, 0.0800, 0.0482, 0.0489, 0.0649, 0.0714,
        0.1143, 0.0833, 0.0944], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,378][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0839, 0.0472, 0.0718, 0.0727, 0.0756, 0.0984, 0.1040, 0.1075, 0.0886,
        0.0837, 0.0826, 0.0841], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,378][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.1619, 0.0126, 0.0356, 0.0561, 0.0577, 0.0563, 0.0936, 0.1003, 0.0915,
        0.0752, 0.1201, 0.1390], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,379][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0054, 0.1165, 0.0791, 0.1045, 0.0622, 0.0820, 0.0811, 0.0912, 0.0845,
        0.1083, 0.1045, 0.0808], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,379][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0110, 0.0760, 0.0388, 0.1546, 0.0541, 0.1017, 0.0586, 0.0850, 0.1397,
        0.1258, 0.1171, 0.0376], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,379][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0900, 0.0207, 0.0342, 0.0540, 0.0594, 0.0787, 0.0915, 0.1099, 0.0883,
        0.0896, 0.1160, 0.1676], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,380][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.1256, 0.0254, 0.0476, 0.0585, 0.0646, 0.0608, 0.0712, 0.0864, 0.0881,
        0.0633, 0.0789, 0.1339, 0.0956], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,382][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0368, 0.0238, 0.0220, 0.0637, 0.0438, 0.0883, 0.1128, 0.1056, 0.0832,
        0.0760, 0.1182, 0.1450, 0.0807], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,383][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0826, 0.0823, 0.0621, 0.0949, 0.0513, 0.0723, 0.0881, 0.0707, 0.0997,
        0.1191, 0.0818, 0.0472, 0.0480], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,385][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1579, 0.0560, 0.0275, 0.1030, 0.0268, 0.0476, 0.0643, 0.0742, 0.0551,
        0.1104, 0.1513, 0.0966, 0.0293], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,386][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.2423, 0.0557, 0.0489, 0.0377, 0.0525, 0.0602, 0.0680, 0.0552, 0.0628,
        0.0673, 0.0699, 0.0969, 0.0828], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,387][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.3197, 0.1614, 0.0150, 0.0313, 0.0114, 0.0370, 0.0413, 0.0539, 0.0743,
        0.0396, 0.0511, 0.0805, 0.0833], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,387][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0683, 0.0634, 0.0942, 0.0668, 0.1354, 0.0757, 0.0508, 0.0381, 0.0711,
        0.0962, 0.0567, 0.0476, 0.1355], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,388][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0810, 0.0503, 0.0700, 0.0701, 0.0804, 0.0836, 0.0860, 0.0933, 0.0771,
        0.0704, 0.0727, 0.0863, 0.0788], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,388][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.1142, 0.0092, 0.0310, 0.0518, 0.0504, 0.0497, 0.0814, 0.0924, 0.0914,
        0.0644, 0.1020, 0.1538, 0.1083], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,388][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0047, 0.1040, 0.0726, 0.0988, 0.0581, 0.0780, 0.0765, 0.0863, 0.0804,
        0.1038, 0.1000, 0.0777, 0.0591], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,389][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0190, 0.0683, 0.0374, 0.1375, 0.0560, 0.0847, 0.0425, 0.0840, 0.1507,
        0.1222, 0.0963, 0.0291, 0.0724], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,389][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0639, 0.0183, 0.0303, 0.0524, 0.0513, 0.0670, 0.0805, 0.1104, 0.0803,
        0.0747, 0.1035, 0.1630, 0.1043], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,390][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1638, 0.0226, 0.0442, 0.0437, 0.0494, 0.0551, 0.0648, 0.0677, 0.0740,
        0.0566, 0.0699, 0.1236, 0.0726, 0.0920], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,391][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0403, 0.0234, 0.0206, 0.0530, 0.0325, 0.0807, 0.1036, 0.0917, 0.0711,
        0.0721, 0.1075, 0.1185, 0.0546, 0.1305], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,392][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0744, 0.0665, 0.0509, 0.0862, 0.0498, 0.0880, 0.1043, 0.0684, 0.0748,
        0.0906, 0.0837, 0.0416, 0.0490, 0.0718], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,394][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.2856, 0.0512, 0.0271, 0.0924, 0.0242, 0.0289, 0.0439, 0.0497, 0.0389,
        0.0855, 0.1230, 0.0776, 0.0227, 0.0493], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,395][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.2775, 0.0469, 0.0427, 0.0317, 0.0439, 0.0515, 0.0647, 0.0483, 0.0513,
        0.0589, 0.0612, 0.0846, 0.0689, 0.0682], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,397][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.2395, 0.1536, 0.0176, 0.0327, 0.0140, 0.0384, 0.0443, 0.0513, 0.0663,
        0.0379, 0.0494, 0.0734, 0.0855, 0.0961], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,397][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0412, 0.0511, 0.0645, 0.0511, 0.0767, 0.0390, 0.0444, 0.0227, 0.0508,
        0.0863, 0.0406, 0.0391, 0.0709, 0.3216], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,398][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0790, 0.0425, 0.0555, 0.0580, 0.0583, 0.0900, 0.0896, 0.0946, 0.0758,
        0.0729, 0.0694, 0.0759, 0.0581, 0.0803], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,398][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.1411, 0.0098, 0.0247, 0.0399, 0.0408, 0.0388, 0.0692, 0.0698, 0.0681,
        0.0604, 0.0982, 0.1225, 0.0890, 0.1275], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,399][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0050, 0.1030, 0.0715, 0.0906, 0.0552, 0.0720, 0.0704, 0.0791, 0.0735,
        0.0947, 0.0907, 0.0715, 0.0543, 0.0684], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,399][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0209, 0.0561, 0.0427, 0.1330, 0.0610, 0.0916, 0.0409, 0.0764, 0.1223,
        0.0927, 0.0963, 0.0352, 0.0775, 0.0534], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,399][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0888, 0.0155, 0.0242, 0.0399, 0.0356, 0.0552, 0.0634, 0.0851, 0.0687,
        0.0687, 0.0926, 0.1474, 0.0730, 0.1420], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,400][circuit_model.py][line:2332][INFO] ##6-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2380, 0.0231, 0.0458, 0.0356, 0.0508, 0.0406, 0.0526, 0.0558, 0.0571,
        0.0432, 0.0500, 0.1007, 0.0692, 0.0764, 0.0611], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,401][circuit_model.py][line:2335][INFO] ##6-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0422, 0.0250, 0.0235, 0.0480, 0.0342, 0.0794, 0.0881, 0.0846, 0.0594,
        0.0600, 0.0843, 0.0971, 0.0502, 0.1084, 0.1156], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,402][circuit_model.py][line:2338][INFO] ##6-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0851, 0.0681, 0.0547, 0.0807, 0.0531, 0.0593, 0.0801, 0.0665, 0.0707,
        0.0798, 0.0665, 0.0503, 0.0505, 0.0742, 0.0604], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,404][circuit_model.py][line:2341][INFO] ##6-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1979, 0.0494, 0.0290, 0.0894, 0.0262, 0.0327, 0.0460, 0.0480, 0.0403,
        0.0773, 0.1061, 0.0656, 0.0251, 0.0494, 0.1176], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,406][circuit_model.py][line:2344][INFO] ##6-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.2772, 0.0422, 0.0395, 0.0267, 0.0404, 0.0461, 0.0580, 0.0424, 0.0477,
        0.0530, 0.0551, 0.0823, 0.0672, 0.0688, 0.0534], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,407][circuit_model.py][line:2347][INFO] ##6-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2355, 0.1399, 0.0157, 0.0287, 0.0127, 0.0363, 0.0407, 0.0507, 0.0673,
        0.0372, 0.0473, 0.0679, 0.0779, 0.0903, 0.0518], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,408][circuit_model.py][line:2350][INFO] ##6-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0589, 0.0768, 0.0716, 0.0911, 0.0855, 0.0424, 0.0470, 0.0153, 0.0402,
        0.1011, 0.0707, 0.0379, 0.0762, 0.0935, 0.0920], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,408][circuit_model.py][line:2353][INFO] ##6-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0903, 0.0486, 0.0617, 0.0527, 0.0650, 0.0816, 0.0789, 0.0853, 0.0659,
        0.0623, 0.0572, 0.0659, 0.0576, 0.0687, 0.0583], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,408][circuit_model.py][line:2356][INFO] ##6-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.1717, 0.0074, 0.0256, 0.0302, 0.0410, 0.0334, 0.0567, 0.0642, 0.0590,
        0.0449, 0.0681, 0.1042, 0.0832, 0.1059, 0.1045], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,409][circuit_model.py][line:2359][INFO] ##6-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0048, 0.0955, 0.0673, 0.0841, 0.0518, 0.0668, 0.0652, 0.0730, 0.0678,
        0.0868, 0.0835, 0.0656, 0.0501, 0.0631, 0.0745], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,409][circuit_model.py][line:2362][INFO] ##6-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0100, 0.0489, 0.0390, 0.1135, 0.0601, 0.0872, 0.0404, 0.0806, 0.1379,
        0.0877, 0.0870, 0.0386, 0.0759, 0.0497, 0.0436], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,409][circuit_model.py][line:2365][INFO] ##6-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.1105, 0.0124, 0.0324, 0.0303, 0.0449, 0.0420, 0.0549, 0.0743, 0.0602,
        0.0535, 0.0658, 0.1189, 0.0860, 0.1195, 0.0944], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,410][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:18,412][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[12914],
        [ 5115],
        [ 5969],
        [ 1108],
        [  274],
        [  437],
        [  268],
        [  333],
        [  585],
        [  486],
        [  910],
        [  114],
        [  180],
        [  166],
        [  210]], device='cuda:0')
[2024-07-24 10:20:18,413][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[13964],
        [20125],
        [24036],
        [ 4562],
        [ 4157],
        [ 5561],
        [ 3479],
        [ 6021],
        [ 7265],
        [ 6615],
        [ 7178],
        [ 3540],
        [ 5925],
        [ 5052],
        [ 3393]], device='cuda:0')
[2024-07-24 10:20:18,415][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38394],
        [35025],
        [36983],
        [37501],
        [33549],
        [31948],
        [32162],
        [30486],
        [26687],
        [28469],
        [27262],
        [23312],
        [24726],
        [25466],
        [27597]], device='cuda:0')
[2024-07-24 10:20:18,416][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[39377],
        [33514],
        [35984],
        [27659],
        [23078],
        [20202],
        [21897],
        [26912],
        [28624],
        [28039],
        [28428],
        [29222],
        [28922],
        [25939],
        [25869]], device='cuda:0')
[2024-07-24 10:20:18,418][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[40463],
        [39723],
        [40177],
        [40619],
        [40717],
        [40818],
        [41043],
        [41330],
        [41552],
        [41761],
        [41937],
        [42025],
        [41865],
        [41910],
        [42083]], device='cuda:0')
[2024-07-24 10:20:18,419][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[14700],
        [12091],
        [12627],
        [13183],
        [13116],
        [13747],
        [14109],
        [14012],
        [14194],
        [13953],
        [13075],
        [13076],
        [12842],
        [12821],
        [13208]], device='cuda:0')
[2024-07-24 10:20:18,420][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[14766],
        [16079],
        [ 5261],
        [ 7269],
        [ 5821],
        [ 5949],
        [ 6099],
        [ 6888],
        [ 7118],
        [ 7451],
        [ 7649],
        [ 7371],
        [ 6570],
        [ 6885],
        [ 6971]], device='cuda:0')
[2024-07-24 10:20:18,421][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[ 47],
        [235],
        [327],
        [208],
        [241],
        [313],
        [296],
        [311],
        [312],
        [318],
        [292],
        [296],
        [321],
        [358],
        [363]], device='cuda:0')
[2024-07-24 10:20:18,422][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[11731],
        [ 7117],
        [ 6322],
        [ 7639],
        [ 5412],
        [ 3088],
        [ 1948],
        [ 2802],
        [ 3841],
        [ 3460],
        [ 2775],
        [ 2829],
        [ 4554],
        [ 1504],
        [ 1252]], device='cuda:0')
[2024-07-24 10:20:18,424][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[11437],
        [13150],
        [19288],
        [19487],
        [22673],
        [25461],
        [26770],
        [26999],
        [27037],
        [27950],
        [27749],
        [27767],
        [28448],
        [29250],
        [28625]], device='cuda:0')
[2024-07-24 10:20:18,425][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[23495],
        [24145],
        [23888],
        [26972],
        [27958],
        [26730],
        [27172],
        [27025],
        [26434],
        [26418],
        [26982],
        [27164],
        [27077],
        [26623],
        [26582]], device='cuda:0')
[2024-07-24 10:20:18,427][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[35957],
        [19713],
        [25313],
        [21216],
        [21326],
        [20900],
        [20317],
        [20107],
        [19567],
        [19720],
        [19521],
        [19423],
        [19893],
        [19652],
        [19310]], device='cuda:0')
[2024-07-24 10:20:18,428][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[15452],
        [13512],
        [10864],
        [ 4022],
        [ 4626],
        [ 4076],
        [ 3904],
        [ 4266],
        [ 3768],
        [ 3544],
        [ 3162],
        [ 2810],
        [ 3152],
        [ 3073],
        [ 2866]], device='cuda:0')
[2024-07-24 10:20:18,429][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[35687],
        [22474],
        [22824],
        [22343],
        [22216],
        [21929],
        [21778],
        [22493],
        [22308],
        [22214],
        [22001],
        [21894],
        [22192],
        [22117],
        [21927]], device='cuda:0')
[2024-07-24 10:20:18,430][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[ 9482],
        [24611],
        [24181],
        [35700],
        [29006],
        [31535],
        [33768],
        [28408],
        [31147],
        [32904],
        [37080],
        [27335],
        [27343],
        [29730],
        [34352]], device='cuda:0')
[2024-07-24 10:20:18,431][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[25370],
        [26025],
        [21691],
        [24027],
        [16302],
        [16857],
        [15887],
        [14048],
        [12371],
        [13148],
        [14000],
        [ 9708],
        [ 9424],
        [ 9060],
        [10097]], device='cuda:0')
[2024-07-24 10:20:18,432][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[37702],
        [ 7888],
        [ 6867],
        [ 8236],
        [11019],
        [12990],
        [12962],
        [10598],
        [10543],
        [10054],
        [10684],
        [10572],
        [11762],
        [10633],
        [10935]], device='cuda:0')
[2024-07-24 10:20:18,433][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[31919],
        [35010],
        [35356],
        [38093],
        [39078],
        [38760],
        [39815],
        [40781],
        [40319],
        [40042],
        [40211],
        [40202],
        [40299],
        [40030],
        [40114]], device='cuda:0')
[2024-07-24 10:20:18,435][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[11166],
        [ 3698],
        [ 3143],
        [ 2110],
        [ 2113],
        [ 2124],
        [ 2271],
        [ 2385],
        [ 2370],
        [ 2497],
        [ 2480],
        [ 2413],
        [ 2469],
        [ 2263],
        [ 2223]], device='cuda:0')
[2024-07-24 10:20:18,436][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[7801],
        [5675],
        [3860],
        [3597],
        [6184],
        [5852],
        [4588],
        [4980],
        [4917],
        [6038],
        [5748],
        [7222],
        [8445],
        [7701],
        [7573]], device='cuda:0')
[2024-07-24 10:20:18,438][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[3253],
        [2052],
        [2198],
        [2320],
        [2298],
        [2341],
        [2452],
        [2442],
        [2411],
        [2303],
        [2346],
        [2431],
        [2271],
        [2176],
        [2133]], device='cuda:0')
[2024-07-24 10:20:18,439][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[38105],
        [ 8842],
        [ 7950],
        [12505],
        [ 6816],
        [ 9098],
        [12777],
        [ 9656],
        [ 9992],
        [11085],
        [10438],
        [11529],
        [ 9226],
        [18057],
        [13200]], device='cuda:0')
[2024-07-24 10:20:18,440][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[21841],
        [16257],
        [10769],
        [ 9324],
        [ 8766],
        [17836],
        [21410],
        [22636],
        [23572],
        [23580],
        [23452],
        [25037],
        [23224],
        [25519],
        [24877]], device='cuda:0')
[2024-07-24 10:20:18,441][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[33564],
        [35076],
        [32704],
        [30498],
        [26940],
        [24251],
        [22545],
        [19690],
        [18984],
        [19176],
        [19785],
        [17624],
        [16678],
        [14936],
        [15986]], device='cuda:0')
[2024-07-24 10:20:18,442][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[25925],
        [18308],
        [16846],
        [16725],
        [16276],
        [16228],
        [16102],
        [15897],
        [15655],
        [15589],
        [15655],
        [15632],
        [15550],
        [15456],
        [15473]], device='cuda:0')
[2024-07-24 10:20:18,443][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[ 429],
        [1604],
        [2251],
        [3167],
        [3145],
        [3537],
        [3846],
        [3829],
        [4016],
        [4087],
        [4181],
        [4172],
        [4076],
        [4091],
        [4116]], device='cuda:0')
[2024-07-24 10:20:18,445][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[23447],
        [28593],
        [33320],
        [34521],
        [36836],
        [31259],
        [27270],
        [21816],
        [21250],
        [21316],
        [19878],
        [19607],
        [20789],
        [20864],
        [20166]], device='cuda:0')
[2024-07-24 10:20:18,446][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[30977],
        [44238],
        [46074],
        [45713],
        [44575],
        [43237],
        [43350],
        [44248],
        [44501],
        [43770],
        [43789],
        [44089],
        [44056],
        [43796],
        [44262]], device='cuda:0')
[2024-07-24 10:20:18,448][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[49239],
        [44796],
        [42087],
        [33118],
        [36496],
        [36000],
        [30307],
        [35919],
        [32387],
        [29304],
        [25216],
        [33418],
        [33540],
        [31171],
        [28323]], device='cuda:0')
[2024-07-24 10:20:18,449][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644],
        [12644]], device='cuda:0')
[2024-07-24 10:20:18,498][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:18,499][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,500][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,500][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,501][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,501][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,501][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,501][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,502][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,502][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,502][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,503][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,504][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,506][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.8060, 0.1940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,508][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.6061, 0.3939], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,509][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0016, 0.9984], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,511][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9011, 0.0989], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,513][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.7624, 0.2376], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,514][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9800, 0.0200], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,515][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.6574, 0.3426], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,516][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.1979, 0.8021], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,516][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.7994, 0.2006], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,516][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0839, 0.9161], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,517][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0344, 0.9656], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,517][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1533, 0.8467], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,517][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.5177, 0.2740, 0.2083], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,517][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.8479, 0.1276, 0.0245], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,518][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.0016, 0.6185, 0.3799], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,518][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.7776, 0.1094, 0.1130], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,518][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.4328, 0.2572, 0.3100], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,519][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.9778, 0.0096, 0.0126], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,519][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.3442, 0.3233, 0.3325], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,519][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.0911, 0.4104, 0.4985], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,520][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.4933, 0.1924, 0.3143], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,521][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.0396, 0.4633, 0.4971], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,523][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.0770, 0.3604, 0.5627], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,524][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.1835, 0.7690, 0.0475], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,526][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.7474, 0.0773, 0.0779, 0.0974], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,527][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.2848, 0.1040, 0.0199, 0.5914], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,527][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([6.6634e-04, 1.3028e-01, 1.3298e-01, 7.3607e-01], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,527][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.9267, 0.0172, 0.0241, 0.0319], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,528][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.4862, 0.0752, 0.1317, 0.3069], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,528][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9759, 0.0048, 0.0167, 0.0025], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,528][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.3302, 0.2244, 0.2383, 0.2071], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,528][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1158, 0.1804, 0.3474, 0.3564], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,529][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6209, 0.0619, 0.1392, 0.1780], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,529][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0360, 0.2715, 0.2882, 0.4044], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,529][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0251, 0.2377, 0.2817, 0.4554], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,530][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1895, 0.4413, 0.0471, 0.3221], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,532][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.2743, 0.1049, 0.1093, 0.2963, 0.2152], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,533][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.3703, 0.0663, 0.0097, 0.5334, 0.0203], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,534][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([2.4953e-04, 8.1745e-02, 4.3365e-02, 8.5068e-01, 2.3962e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,536][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.5944, 0.0517, 0.0559, 0.1306, 0.1673], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,537][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.1978, 0.1051, 0.1084, 0.3882, 0.2005], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,537][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.9501, 0.0143, 0.0152, 0.0092, 0.0112], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,537][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.1983, 0.2130, 0.2114, 0.2028, 0.1744], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,538][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0439, 0.1881, 0.2000, 0.3625, 0.2055], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,538][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.2373, 0.0838, 0.1199, 0.3029, 0.2561], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,538][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0257, 0.2057, 0.2038, 0.3146, 0.2502], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,539][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0251, 0.1489, 0.2219, 0.4379, 0.1662], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,539][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.1040, 0.5393, 0.0233, 0.3259, 0.0075], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,539][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.3274, 0.0884, 0.0732, 0.1671, 0.1372, 0.2067], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,540][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.2341, 0.0985, 0.0104, 0.5081, 0.0240, 0.1249], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,540][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ had] are: tensor([2.5382e-04, 1.1959e-01, 6.8726e-02, 6.0937e-01, 1.8158e-02, 1.8390e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,542][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.6568, 0.0209, 0.0323, 0.0665, 0.0790, 0.1446], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,543][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.2142, 0.0617, 0.0847, 0.2857, 0.1404, 0.2133], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,545][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.9545, 0.0048, 0.0155, 0.0088, 0.0116, 0.0048], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,546][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.2020, 0.1706, 0.1753, 0.1618, 0.1457, 0.1445], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,547][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0458, 0.1367, 0.1989, 0.2453, 0.1673, 0.2059], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,548][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.2010, 0.0520, 0.0980, 0.2020, 0.1726, 0.2745], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,548][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0213, 0.1663, 0.1679, 0.2550, 0.2014, 0.1881], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,548][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.0103, 0.1293, 0.1881, 0.3708, 0.1344, 0.1670], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,548][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.1238, 0.4490, 0.0338, 0.3027, 0.0119, 0.0788], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,549][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.3399, 0.0615, 0.0616, 0.1010, 0.1050, 0.1443, 0.1867],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,549][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.3845, 0.0822, 0.0074, 0.3683, 0.0147, 0.0772, 0.0657],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,549][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ a] are: tensor([2.4691e-04, 9.0538e-02, 5.5335e-02, 5.0478e-01, 1.5054e-02, 1.3251e-01,
        2.0154e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,550][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.6942, 0.0170, 0.0249, 0.0366, 0.0517, 0.0787, 0.0968],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,550][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.2661, 0.0436, 0.0691, 0.1479, 0.1087, 0.1390, 0.2256],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,551][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.9790, 0.0024, 0.0067, 0.0021, 0.0055, 0.0025, 0.0018],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,553][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.2005, 0.1481, 0.1546, 0.1397, 0.1275, 0.1238, 0.1059],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,554][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0559, 0.1306, 0.1641, 0.1804, 0.1300, 0.1618, 0.1772],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,556][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2412, 0.0376, 0.0711, 0.1225, 0.1275, 0.1817, 0.2184],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,557][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0236, 0.1325, 0.1307, 0.1930, 0.1513, 0.1476, 0.2213],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,558][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.0121, 0.1259, 0.1650, 0.3162, 0.1135, 0.1550, 0.1124],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,558][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.1417, 0.3837, 0.0351, 0.2760, 0.0133, 0.0776, 0.0727],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,558][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1958, 0.0403, 0.0474, 0.0965, 0.0892, 0.1442, 0.2166, 0.1699],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,559][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.1352, 0.0400, 0.0050, 0.2212, 0.0138, 0.0531, 0.0557, 0.4759],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,559][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ long] are: tensor([1.2927e-04, 7.2625e-02, 3.9955e-02, 4.5751e-01, 1.0244e-02, 1.1055e-01,
        2.3010e-01, 7.8876e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,559][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.5831, 0.0157, 0.0218, 0.0425, 0.0599, 0.1011, 0.1239, 0.0520],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,559][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.1241, 0.0379, 0.0484, 0.1472, 0.0894, 0.1291, 0.2234, 0.2004],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,560][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.9725, 0.0027, 0.0059, 0.0028, 0.0035, 0.0031, 0.0024, 0.0070],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,561][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.1922, 0.1376, 0.1416, 0.1245, 0.1114, 0.1080, 0.0915, 0.0933],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,562][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0320, 0.0979, 0.1227, 0.1627, 0.1110, 0.1423, 0.1708, 0.1605],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,564][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1138, 0.0271, 0.0536, 0.1206, 0.0972, 0.1674, 0.2129, 0.2074],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,565][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0141, 0.1069, 0.1033, 0.1627, 0.1265, 0.1285, 0.2033, 0.1548],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,567][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.0041, 0.0905, 0.1456, 0.3445, 0.1041, 0.1405, 0.1040, 0.0666],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,568][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.1148, 0.4218, 0.0234, 0.2843, 0.0075, 0.0614, 0.0615, 0.0253],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,568][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1791, 0.0369, 0.0437, 0.0741, 0.0796, 0.1103, 0.1571, 0.1552, 0.1640],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,568][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.2354, 0.0227, 0.0040, 0.1230, 0.0095, 0.0410, 0.0431, 0.2246, 0.2967],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,569][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([2.2292e-04, 6.4968e-02, 3.3046e-02, 3.8157e-01, 1.3686e-02, 1.3533e-01,
        2.2511e-01, 8.4540e-02, 6.1530e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,569][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.5004, 0.0208, 0.0222, 0.0457, 0.0586, 0.1041, 0.1252, 0.0665, 0.0566],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,569][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.1119, 0.0244, 0.0405, 0.1170, 0.0681, 0.0962, 0.1648, 0.1636, 0.2134],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,570][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.9440, 0.0054, 0.0094, 0.0047, 0.0058, 0.0039, 0.0050, 0.0126, 0.0091],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,570][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.1705, 0.1267, 0.1302, 0.1160, 0.1019, 0.1009, 0.0853, 0.0855, 0.0831],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,570][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0256, 0.0833, 0.0994, 0.1343, 0.0989, 0.1357, 0.1522, 0.1472, 0.1234],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,571][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.1049, 0.0205, 0.0458, 0.0814, 0.0847, 0.1265, 0.1510, 0.1845, 0.2007],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,572][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0127, 0.0888, 0.0905, 0.1408, 0.1100, 0.1108, 0.1766, 0.1335, 0.1364],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,574][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.0038, 0.0798, 0.1299, 0.2970, 0.0914, 0.1279, 0.0957, 0.0613, 0.1132],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,576][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.1591, 0.3704, 0.0210, 0.2804, 0.0071, 0.0626, 0.0600, 0.0247, 0.0147],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,577][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2338, 0.0361, 0.0503, 0.0543, 0.0845, 0.0770, 0.1058, 0.1271, 0.1562,
        0.0749], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,578][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1291, 0.0256, 0.0016, 0.0999, 0.0037, 0.0283, 0.0197, 0.2904, 0.3706,
        0.0310], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,578][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [,] are: tensor([1.7730e-04, 4.9017e-02, 3.2070e-02, 2.7297e-01, 9.1812e-03, 6.4772e-02,
        1.1999e-01, 4.6721e-02, 3.7505e-02, 3.6759e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,578][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.5550, 0.0153, 0.0247, 0.0333, 0.0530, 0.0791, 0.0926, 0.0455, 0.0478,
        0.0536], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,579][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1205, 0.0181, 0.0419, 0.0780, 0.0643, 0.0809, 0.1352, 0.1499, 0.2076,
        0.1035], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,579][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.9560, 0.0028, 0.0093, 0.0015, 0.0040, 0.0037, 0.0037, 0.0079, 0.0095,
        0.0015], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,580][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1649, 0.1114, 0.1207, 0.1043, 0.0958, 0.0915, 0.0775, 0.0775, 0.0768,
        0.0796], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,580][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0328, 0.0666, 0.0999, 0.1015, 0.0887, 0.1104, 0.1316, 0.1241, 0.1095,
        0.1348], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,580][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.1231, 0.0169, 0.0450, 0.0641, 0.0837, 0.0986, 0.1172, 0.1647, 0.1912,
        0.0953], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,580][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0104, 0.0807, 0.0839, 0.1208, 0.0973, 0.0950, 0.1459, 0.1129, 0.1161,
        0.1371], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,582][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.0065, 0.0828, 0.1199, 0.2397, 0.0853, 0.1138, 0.0858, 0.0599, 0.0993,
        0.1070], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,583][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.1360, 0.3759, 0.0202, 0.2800, 0.0066, 0.0590, 0.0580, 0.0229, 0.0135,
        0.0278], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,585][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2346, 0.0306, 0.0382, 0.0412, 0.0683, 0.0665, 0.0974, 0.1122, 0.1375,
        0.0691, 0.1044], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,586][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.1249, 0.0342, 0.0015, 0.0891, 0.0041, 0.0239, 0.0148, 0.2690, 0.3989,
        0.0278, 0.0118], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,587][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ and] are: tensor([1.2922e-04, 3.7659e-02, 2.6164e-02, 2.1024e-01, 8.1057e-03, 6.0302e-02,
        9.3752e-02, 4.2211e-02, 3.1431e-02, 2.7773e-01, 2.1228e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,588][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5477, 0.0149, 0.0209, 0.0276, 0.0391, 0.0611, 0.0758, 0.0374, 0.0400,
        0.0470, 0.0884], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,588][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1163, 0.0153, 0.0346, 0.0580, 0.0516, 0.0639, 0.1174, 0.1285, 0.1791,
        0.0927, 0.1425], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,589][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.9250, 0.0051, 0.0161, 0.0028, 0.0059, 0.0059, 0.0057, 0.0132, 0.0156,
        0.0027, 0.0020], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,589][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.1522, 0.1033, 0.1118, 0.0955, 0.0902, 0.0849, 0.0724, 0.0722, 0.0717,
        0.0748, 0.0710], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,589][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0354, 0.0578, 0.0899, 0.0924, 0.0841, 0.0984, 0.1187, 0.1038, 0.0985,
        0.1127, 0.1082], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,590][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.1305, 0.0157, 0.0401, 0.0505, 0.0724, 0.0763, 0.0993, 0.1344, 0.1609,
        0.0872, 0.1328], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,590][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0115, 0.0708, 0.0710, 0.1037, 0.0826, 0.0811, 0.1242, 0.0966, 0.0979,
        0.1188, 0.1417], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,590][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.0061, 0.0760, 0.0984, 0.1950, 0.0745, 0.1024, 0.0763, 0.0565, 0.0883,
        0.0924, 0.1342], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,591][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.1459, 0.3281, 0.0226, 0.2702, 0.0079, 0.0582, 0.0585, 0.0242, 0.0150,
        0.0280, 0.0414], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,593][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.1289, 0.0239, 0.0299, 0.0460, 0.0536, 0.0675, 0.0928, 0.0877, 0.1028,
        0.0661, 0.1069, 0.1938], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,595][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0855, 0.0176, 0.0012, 0.0837, 0.0034, 0.0267, 0.0216, 0.2772, 0.4147,
        0.0362, 0.0195, 0.0126], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,596][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([7.8018e-05, 3.4248e-02, 1.8923e-02, 2.3964e-01, 6.9311e-03, 5.9568e-02,
        9.4747e-02, 3.9840e-02, 2.6885e-02, 2.6192e-01, 1.9572e-01, 2.1504e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,597][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.3442, 0.0133, 0.0176, 0.0296, 0.0380, 0.0800, 0.0980, 0.0442, 0.0407,
        0.0533, 0.0966, 0.1445], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,598][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0521, 0.0194, 0.0261, 0.0925, 0.0406, 0.0583, 0.0972, 0.0952, 0.1147,
        0.0861, 0.1432, 0.1745], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,599][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.8426, 0.0076, 0.0158, 0.0100, 0.0112, 0.0093, 0.0125, 0.0297, 0.0164,
        0.0073, 0.0112, 0.0264], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,599][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.1072, 0.1009, 0.1015, 0.0929, 0.0798, 0.0829, 0.0711, 0.0719, 0.0716,
        0.0741, 0.0713, 0.0748], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,599][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0188, 0.0568, 0.0723, 0.0965, 0.0731, 0.0909, 0.1076, 0.0954, 0.0837,
        0.1163, 0.1176, 0.0713], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,600][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0579, 0.0134, 0.0318, 0.0553, 0.0524, 0.0797, 0.1046, 0.1167, 0.1330,
        0.0840, 0.1203, 0.1508], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,600][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0114, 0.0606, 0.0594, 0.0918, 0.0695, 0.0708, 0.1097, 0.0852, 0.0859,
        0.1076, 0.1286, 0.1196], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,600][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0028, 0.0589, 0.0943, 0.2124, 0.0652, 0.0923, 0.0672, 0.0450, 0.0829,
        0.0869, 0.1373, 0.0548], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,601][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.1096, 0.4097, 0.0166, 0.2736, 0.0050, 0.0526, 0.0523, 0.0191, 0.0098,
        0.0182, 0.0296, 0.0039], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,601][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0681, 0.0176, 0.0248, 0.0471, 0.0506, 0.0580, 0.0841, 0.0982, 0.1048,
        0.0550, 0.0940, 0.1977, 0.1001], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,603][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.1732, 0.0144, 0.0009, 0.0978, 0.0028, 0.0216, 0.0108, 0.1823, 0.4443,
        0.0279, 0.0117, 0.0118, 0.0005], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,604][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([4.6884e-05, 2.2176e-02, 9.8266e-03, 2.1533e-01, 5.4838e-03, 5.3261e-02,
        1.0358e-01, 3.6185e-02, 2.2886e-02, 2.7429e-01, 2.3226e-01, 1.8160e-02,
        6.5095e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,606][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.1613, 0.0180, 0.0174, 0.0423, 0.0467, 0.0938, 0.0996, 0.0588, 0.0539,
        0.0623, 0.1055, 0.1505, 0.0899], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,607][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0474, 0.0182, 0.0239, 0.0747, 0.0416, 0.0566, 0.0896, 0.0969, 0.1101,
        0.0775, 0.1232, 0.1651, 0.0751], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,608][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.7995, 0.0138, 0.0131, 0.0093, 0.0102, 0.0122, 0.0123, 0.0332, 0.0189,
        0.0097, 0.0123, 0.0417, 0.0138], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,609][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0900, 0.0929, 0.0928, 0.0875, 0.0735, 0.0790, 0.0691, 0.0706, 0.0701,
        0.0732, 0.0698, 0.0715, 0.0601], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,609][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0135, 0.0592, 0.0555, 0.0962, 0.0597, 0.0871, 0.0974, 0.0954, 0.0777,
        0.1116, 0.1207, 0.0634, 0.0626], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,609][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0521, 0.0152, 0.0268, 0.0551, 0.0565, 0.0672, 0.0821, 0.1197, 0.1106,
        0.0617, 0.0938, 0.1560, 0.1032], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,610][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0100, 0.0541, 0.0519, 0.0825, 0.0635, 0.0644, 0.1017, 0.0786, 0.0795,
        0.0993, 0.1191, 0.1118, 0.0835], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,610][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0058, 0.0491, 0.0786, 0.1888, 0.0598, 0.0857, 0.0654, 0.0473, 0.0866,
        0.0878, 0.1326, 0.0551, 0.0575], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,610][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.1012, 0.3829, 0.0161, 0.2822, 0.0057, 0.0558, 0.0564, 0.0217, 0.0112,
        0.0224, 0.0354, 0.0050, 0.0038], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,611][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.1482, 0.0165, 0.0169, 0.0256, 0.0308, 0.0390, 0.0583, 0.0547, 0.0745,
        0.0455, 0.0806, 0.1769, 0.0759, 0.1565], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,612][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.1186, 0.0169, 0.0011, 0.0721, 0.0042, 0.0233, 0.0126, 0.2494, 0.4237,
        0.0278, 0.0110, 0.0118, 0.0005, 0.0270], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,613][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ said] are: tensor([9.6387e-05, 3.0236e-02, 1.6268e-02, 1.6720e-01, 6.3160e-03, 6.2975e-02,
        9.7518e-02, 4.0096e-02, 2.8161e-02, 2.7315e-01, 1.9886e-01, 2.4313e-02,
        7.6386e-03, 4.7164e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,615][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.3572, 0.0081, 0.0105, 0.0186, 0.0244, 0.0443, 0.0612, 0.0251, 0.0250,
        0.0349, 0.0750, 0.1068, 0.0582, 0.1508], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,616][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0638, 0.0113, 0.0154, 0.0442, 0.0251, 0.0388, 0.0709, 0.0641, 0.0905,
        0.0594, 0.1051, 0.1613, 0.0547, 0.1954], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,618][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.8653, 0.0038, 0.0181, 0.0042, 0.0076, 0.0044, 0.0056, 0.0133, 0.0117,
        0.0038, 0.0059, 0.0163, 0.0123, 0.0276], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,618][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.1119, 0.0854, 0.0891, 0.0807, 0.0712, 0.0706, 0.0608, 0.0610, 0.0611,
        0.0643, 0.0617, 0.0652, 0.0578, 0.0592], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,619][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0187, 0.0428, 0.0560, 0.0681, 0.0617, 0.0812, 0.0934, 0.0871, 0.0736,
        0.1020, 0.0999, 0.0651, 0.0638, 0.0867], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,619][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0575, 0.0098, 0.0196, 0.0341, 0.0346, 0.0531, 0.0680, 0.0754, 0.0939,
        0.0597, 0.0930, 0.1358, 0.0761, 0.1893], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,619][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0093, 0.0509, 0.0489, 0.0772, 0.0588, 0.0590, 0.0922, 0.0710, 0.0723,
        0.0909, 0.1098, 0.1032, 0.0766, 0.0797], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,620][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0026, 0.0509, 0.0837, 0.1945, 0.0591, 0.0828, 0.0588, 0.0393, 0.0720,
        0.0768, 0.1233, 0.0475, 0.0500, 0.0588], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,620][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.1115, 0.3365, 0.0210, 0.2587, 0.0076, 0.0628, 0.0596, 0.0251, 0.0145,
        0.0273, 0.0402, 0.0067, 0.0060, 0.0224], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,620][circuit_model.py][line:2294][INFO] ##7-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.1742, 0.0161, 0.0232, 0.0219, 0.0387, 0.0357, 0.0506, 0.0547, 0.0684,
        0.0332, 0.0523, 0.1479, 0.0803, 0.1203, 0.0825], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,621][circuit_model.py][line:2297][INFO] ##7-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0972, 0.0244, 0.0011, 0.0832, 0.0033, 0.0216, 0.0125, 0.2535, 0.3901,
        0.0288, 0.0106, 0.0120, 0.0004, 0.0298, 0.0313], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,621][circuit_model.py][line:2300][INFO] ##7-th layer ##Weight##: The head3 weight for token [ to] are: tensor([9.9863e-05, 3.2899e-02, 1.9487e-02, 1.7480e-01, 6.1474e-03, 4.8040e-02,
        7.9527e-02, 3.1639e-02, 2.4495e-02, 2.3927e-01, 1.7496e-01, 1.8981e-02,
        6.7162e-03, 3.8839e-02, 1.0410e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,623][circuit_model.py][line:2303][INFO] ##7-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.4130, 0.0089, 0.0129, 0.0150, 0.0255, 0.0367, 0.0473, 0.0199, 0.0216,
        0.0260, 0.0492, 0.0809, 0.0517, 0.1106, 0.0808], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,625][circuit_model.py][line:2306][INFO] ##7-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0755, 0.0096, 0.0181, 0.0351, 0.0276, 0.0393, 0.0652, 0.0640, 0.0842,
        0.0502, 0.0800, 0.1262, 0.0523, 0.1638, 0.1090], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,626][circuit_model.py][line:2309][INFO] ##7-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.9173, 0.0032, 0.0098, 0.0025, 0.0045, 0.0034, 0.0039, 0.0098, 0.0078,
        0.0018, 0.0020, 0.0116, 0.0053, 0.0147, 0.0024], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,628][circuit_model.py][line:2312][INFO] ##7-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.1220, 0.0802, 0.0848, 0.0736, 0.0691, 0.0662, 0.0564, 0.0558, 0.0563,
        0.0585, 0.0556, 0.0612, 0.0553, 0.0547, 0.0502], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,628][circuit_model.py][line:2315][INFO] ##7-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0269, 0.0426, 0.0651, 0.0675, 0.0684, 0.0745, 0.0852, 0.0703, 0.0670,
        0.0796, 0.0814, 0.0628, 0.0630, 0.0718, 0.0739], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,629][circuit_model.py][line:2318][INFO] ##7-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0837, 0.0098, 0.0235, 0.0298, 0.0433, 0.0473, 0.0577, 0.0729, 0.0851,
        0.0485, 0.0712, 0.1128, 0.0815, 0.1453, 0.0878], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,629][circuit_model.py][line:2321][INFO] ##7-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0093, 0.0479, 0.0482, 0.0704, 0.0548, 0.0550, 0.0831, 0.0648, 0.0658,
        0.0809, 0.0955, 0.0907, 0.0692, 0.0722, 0.0923], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,629][circuit_model.py][line:2324][INFO] ##7-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0025, 0.0529, 0.0770, 0.1668, 0.0578, 0.0765, 0.0581, 0.0390, 0.0672,
        0.0724, 0.1131, 0.0474, 0.0497, 0.0580, 0.0617], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,630][circuit_model.py][line:2327][INFO] ##7-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.1383, 0.3140, 0.0199, 0.2583, 0.0068, 0.0575, 0.0536, 0.0213, 0.0125,
        0.0235, 0.0356, 0.0058, 0.0053, 0.0193, 0.0284], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,669][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:18,671][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,672][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,673][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,674][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,674][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,674][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,675][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,675][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,675][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,676][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,676][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,676][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,677][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.8060, 0.1940], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,679][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.6114, 0.3886], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,680][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0020, 0.9980], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,682][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6311, 0.3689], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,683][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.7269, 0.2731], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,684][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.6195, 0.3805], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,684][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.5485, 0.4515], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,684][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.1995, 0.8005], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,685][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.7994, 0.2006], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,685][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.7750, 0.2250], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,685][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0328, 0.9672], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,686][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.1795, 0.8205], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,686][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.5177, 0.2740, 0.2083], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,686][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([0.3730, 0.2192, 0.4078], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,687][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.0017, 0.6081, 0.3902], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,689][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.4916, 0.2636, 0.2448], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,690][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.4313, 0.2652, 0.3036], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,692][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.3552, 0.3114, 0.3334], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,693][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.3235, 0.3680, 0.3084], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,694][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.0883, 0.4206, 0.4911], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,695][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.4933, 0.1924, 0.3143], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,695][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.4704, 0.2835, 0.2461], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,695][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.0248, 0.4531, 0.5221], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,696][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.1139, 0.5441, 0.3421], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,696][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.7474, 0.0773, 0.0779, 0.0974], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,696][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5624, 0.1128, 0.2321, 0.0927], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,697][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0011, 0.1620, 0.1687, 0.6681], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,697][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5627, 0.1211, 0.1203, 0.1960], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,698][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.4675, 0.0933, 0.1435, 0.2957], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,699][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5927, 0.1184, 0.1598, 0.1291], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,701][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.4634, 0.2125, 0.1846, 0.1396], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,703][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1323, 0.1831, 0.3476, 0.3370], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,704][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6209, 0.0619, 0.1392, 0.1780], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,705][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.6165, 0.0808, 0.1214, 0.1813], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,705][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0195, 0.2149, 0.2303, 0.5352], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,705][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.1973, 0.2382, 0.2746, 0.2899], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,706][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.2743, 0.1049, 0.1093, 0.2963, 0.2152], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,706][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.1625, 0.1470, 0.2264, 0.2587, 0.2053], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,706][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([3.3855e-04, 1.1159e-01, 6.1754e-02, 7.9256e-01, 3.3754e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,707][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.2877, 0.1228, 0.1176, 0.2282, 0.2437], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,707][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.2033, 0.1204, 0.1182, 0.3604, 0.1977], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,709][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.2362, 0.1875, 0.1919, 0.2638, 0.1205], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,710][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.2091, 0.2211, 0.2035, 0.2098, 0.1564], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,712][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0423, 0.1967, 0.1983, 0.3602, 0.2025], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,713][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.2373, 0.0838, 0.1199, 0.3029, 0.2561], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,714][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.2739, 0.1118, 0.1013, 0.2445, 0.2685], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,715][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0067, 0.1117, 0.1376, 0.5959, 0.1481], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,715][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0506, 0.2576, 0.1444, 0.3994, 0.1480], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,715][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.3274, 0.0884, 0.0732, 0.1671, 0.1372, 0.2067], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,716][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.1791, 0.1199, 0.2009, 0.1258, 0.1599, 0.2144], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,716][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([4.3899e-04, 1.4288e-01, 9.1033e-02, 5.4357e-01, 2.6809e-02, 1.9527e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,717][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.2351, 0.0882, 0.0949, 0.1861, 0.1624, 0.2334], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,717][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.2094, 0.0747, 0.0926, 0.2618, 0.1376, 0.2239], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,718][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3245, 0.1368, 0.1498, 0.1603, 0.0937, 0.1348], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,719][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2335, 0.1947, 0.1704, 0.1586, 0.1241, 0.1187], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,721][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0490, 0.1416, 0.2009, 0.2429, 0.1732, 0.1925], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,722][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.2010, 0.0520, 0.0980, 0.2020, 0.1726, 0.2745], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,724][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2543, 0.0675, 0.0978, 0.1827, 0.2232, 0.1745], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,725][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.0037, 0.0901, 0.1086, 0.4198, 0.0777, 0.3001], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,725][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0450, 0.2096, 0.1446, 0.2492, 0.1200, 0.2317], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,725][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.3399, 0.0615, 0.0616, 0.1010, 0.1050, 0.1443, 0.1867],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,726][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.2273, 0.0997, 0.1694, 0.0897, 0.1390, 0.1526, 0.1222],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,726][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([4.2521e-04, 1.0969e-01, 7.3677e-02, 4.5634e-01, 2.2288e-02, 1.4511e-01,
        1.9247e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,727][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.2719, 0.0694, 0.0734, 0.1230, 0.1143, 0.1618, 0.1862],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,727][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.2398, 0.0548, 0.0747, 0.1456, 0.1062, 0.1498, 0.2292],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,727][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.3616, 0.1162, 0.1386, 0.1142, 0.0850, 0.1028, 0.0816],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,728][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2655, 0.1673, 0.1465, 0.1216, 0.1066, 0.1051, 0.0874],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,730][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0599, 0.1351, 0.1653, 0.1787, 0.1316, 0.1556, 0.1737],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,731][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2412, 0.0376, 0.0711, 0.1225, 0.1275, 0.1817, 0.2184],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,733][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2533, 0.0565, 0.0751, 0.1194, 0.1680, 0.1324, 0.1953],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,734][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.0042, 0.0834, 0.0847, 0.2823, 0.0670, 0.2036, 0.2747],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,735][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0822, 0.1560, 0.1425, 0.1819, 0.1211, 0.1792, 0.1370],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,735][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1958, 0.0403, 0.0474, 0.0965, 0.0892, 0.1442, 0.2166, 0.1699],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,736][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.1461, 0.0936, 0.1404, 0.0950, 0.1239, 0.1550, 0.1288, 0.1173],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,736][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([2.1824e-04, 9.0678e-02, 5.4765e-02, 4.1556e-01, 1.5617e-02, 1.2285e-01,
        2.1071e-01, 8.9607e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,736][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.1685, 0.0587, 0.0607, 0.1168, 0.1037, 0.1553, 0.1847, 0.1517],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,737][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.1127, 0.0474, 0.0535, 0.1431, 0.0875, 0.1388, 0.2226, 0.1944],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,737][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.2599, 0.1109, 0.1093, 0.1271, 0.0715, 0.1319, 0.0987, 0.0906],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,738][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.2176, 0.1510, 0.1309, 0.1126, 0.0973, 0.1007, 0.0882, 0.1016],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,739][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0350, 0.1022, 0.1232, 0.1608, 0.1125, 0.1343, 0.1703, 0.1617],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,741][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1138, 0.0271, 0.0536, 0.1206, 0.0972, 0.1674, 0.2129, 0.2074],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,742][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.1610, 0.0437, 0.0521, 0.0999, 0.1373, 0.1338, 0.1985, 0.1736],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,744][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.0021, 0.0438, 0.0632, 0.2330, 0.0507, 0.1828, 0.3216, 0.1026],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,745][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0335, 0.1263, 0.1019, 0.1820, 0.0828, 0.1869, 0.1495, 0.1371],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,745][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1791, 0.0369, 0.0437, 0.0741, 0.0796, 0.1103, 0.1571, 0.1552, 0.1640],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,746][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.1399, 0.0740, 0.1168, 0.0821, 0.1081, 0.1354, 0.1169, 0.1066, 0.1202],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,746][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([3.1340e-04, 8.1022e-02, 4.4421e-02, 3.4964e-01, 1.9022e-02, 1.4205e-01,
        2.0111e-01, 9.2012e-02, 7.0403e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,747][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.1447, 0.0554, 0.0500, 0.0946, 0.0825, 0.1280, 0.1544, 0.1374, 0.1530],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,747][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.1047, 0.0318, 0.0448, 0.1149, 0.0681, 0.1053, 0.1683, 0.1602, 0.2019],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,747][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.2784, 0.0943, 0.1015, 0.1018, 0.0669, 0.1050, 0.0882, 0.0836, 0.0803],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,748][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.1977, 0.1369, 0.1142, 0.1040, 0.0864, 0.0982, 0.0848, 0.0941, 0.0837],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,750][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0261, 0.0856, 0.0998, 0.1364, 0.0999, 0.1287, 0.1510, 0.1512, 0.1212],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,751][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.1049, 0.0205, 0.0458, 0.0814, 0.0847, 0.1265, 0.1510, 0.1845, 0.2007],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,753][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1255, 0.0345, 0.0466, 0.0881, 0.1123, 0.1027, 0.1556, 0.1535, 0.1811],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,754][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.0033, 0.0438, 0.0543, 0.1910, 0.0540, 0.1744, 0.2858, 0.1028, 0.0905],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,755][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0351, 0.1069, 0.0899, 0.1638, 0.0873, 0.1640, 0.1241, 0.1253, 0.1035],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,756][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2338, 0.0361, 0.0503, 0.0543, 0.0845, 0.0770, 0.1058, 0.1271, 0.1562,
        0.0749], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,756][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2375, 0.0739, 0.1105, 0.0526, 0.0921, 0.1126, 0.0840, 0.0826, 0.0873,
        0.0670], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,757][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([2.9930e-04, 6.2616e-02, 4.4054e-02, 2.5544e-01, 1.3885e-02, 7.4998e-02,
        1.1552e-01, 5.5195e-02, 4.6274e-02, 3.3172e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,757][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.1505, 0.0449, 0.0530, 0.0788, 0.0796, 0.1093, 0.1213, 0.1103, 0.1329,
        0.1194], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,757][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1166, 0.0237, 0.0448, 0.0776, 0.0630, 0.0884, 0.1393, 0.1443, 0.1922,
        0.1101], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,758][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3074, 0.0918, 0.0984, 0.0842, 0.0651, 0.0872, 0.0707, 0.0695, 0.0727,
        0.0530], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,759][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2237, 0.1244, 0.1076, 0.0877, 0.0778, 0.0824, 0.0724, 0.0805, 0.0746,
        0.0689], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,760][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0354, 0.0676, 0.1001, 0.0998, 0.0888, 0.1079, 0.1309, 0.1287, 0.1092,
        0.1317], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,762][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.1231, 0.0169, 0.0450, 0.0641, 0.0837, 0.0986, 0.1172, 0.1647, 0.1912,
        0.0953], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,764][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1460, 0.0273, 0.0533, 0.0623, 0.1178, 0.0761, 0.1162, 0.1217, 0.1628,
        0.1165], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,765][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.0025, 0.0383, 0.0483, 0.1501, 0.0460, 0.1233, 0.1947, 0.0762, 0.0668,
        0.2540], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,766][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0578, 0.0946, 0.1121, 0.1133, 0.0908, 0.1257, 0.0981, 0.0940, 0.0877,
        0.1259], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,766][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2346, 0.0306, 0.0382, 0.0412, 0.0683, 0.0665, 0.0974, 0.1122, 0.1375,
        0.0691, 0.1044], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,766][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.2805, 0.0721, 0.0996, 0.0425, 0.0954, 0.0824, 0.0657, 0.0666, 0.0755,
        0.0560, 0.0638], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,767][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([2.3305e-04, 4.8021e-02, 3.6070e-02, 1.9907e-01, 1.2220e-02, 6.8398e-02,
        9.2210e-02, 4.9394e-02, 3.8911e-02, 2.5505e-01, 2.0042e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,767][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1637, 0.0401, 0.0437, 0.0635, 0.0629, 0.0893, 0.1014, 0.0924, 0.1128,
        0.1021, 0.1281], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,768][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.1062, 0.0203, 0.0373, 0.0601, 0.0512, 0.0714, 0.1211, 0.1246, 0.1666,
        0.0988, 0.1424], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,768][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3588, 0.0826, 0.0944, 0.0699, 0.0678, 0.0678, 0.0600, 0.0559, 0.0600,
        0.0442, 0.0386], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,769][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2459, 0.1126, 0.1016, 0.0745, 0.0761, 0.0719, 0.0622, 0.0694, 0.0659,
        0.0600, 0.0600], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,771][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0388, 0.0586, 0.0895, 0.0899, 0.0838, 0.0962, 0.1188, 0.1071, 0.0992,
        0.1110, 0.1071], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,773][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.1305, 0.0157, 0.0401, 0.0505, 0.0724, 0.0763, 0.0993, 0.1344, 0.1609,
        0.0872, 0.1328], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,774][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1535, 0.0233, 0.0418, 0.0484, 0.0959, 0.0632, 0.0983, 0.1029, 0.1332,
        0.0982, 0.1413], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,776][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.0023, 0.0339, 0.0392, 0.1219, 0.0383, 0.1027, 0.1463, 0.0624, 0.0545,
        0.2036, 0.1950], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,776][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0638, 0.0780, 0.1006, 0.1003, 0.0876, 0.1132, 0.0894, 0.0819, 0.0792,
        0.1031, 0.1027], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:18,776][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1289, 0.0239, 0.0299, 0.0460, 0.0536, 0.0675, 0.0928, 0.0877, 0.1028,
        0.0661, 0.1069, 0.1938], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,777][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0887, 0.0507, 0.0748, 0.0604, 0.0743, 0.1020, 0.0994, 0.0873, 0.0946,
        0.0836, 0.0970, 0.0873], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,777][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([1.2234e-04, 4.4070e-02, 2.6151e-02, 2.2381e-01, 1.0144e-02, 6.7114e-02,
        9.2601e-02, 4.6241e-02, 3.3133e-02, 2.4306e-01, 1.8606e-01, 2.7496e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,778][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0833, 0.0309, 0.0321, 0.0563, 0.0492, 0.0825, 0.0999, 0.0837, 0.0980,
        0.0927, 0.1143, 0.1771], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,778][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0487, 0.0246, 0.0289, 0.0898, 0.0410, 0.0645, 0.1007, 0.0952, 0.1121,
        0.0910, 0.1404, 0.1631], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,779][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.2009, 0.0752, 0.0879, 0.0908, 0.0536, 0.0840, 0.0689, 0.0662, 0.0665,
        0.0573, 0.0521, 0.0966], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,781][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1373, 0.1152, 0.0855, 0.0826, 0.0660, 0.0759, 0.0684, 0.0747, 0.0693,
        0.0673, 0.0726, 0.0851], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,783][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0188, 0.0592, 0.0729, 0.0976, 0.0744, 0.0882, 0.1061, 0.0981, 0.0831,
        0.1144, 0.1152, 0.0718], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,784][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0579, 0.0134, 0.0318, 0.0553, 0.0524, 0.0797, 0.1046, 0.1167, 0.1330,
        0.0840, 0.1203, 0.1508], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,786][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0654, 0.0233, 0.0281, 0.0537, 0.0614, 0.0649, 0.0954, 0.0924, 0.1010,
        0.0988, 0.1393, 0.1762], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,786][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0013, 0.0288, 0.0317, 0.1316, 0.0308, 0.0942, 0.1470, 0.0565, 0.0510,
        0.1754, 0.1887, 0.0630], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,786][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0244, 0.0680, 0.0699, 0.1299, 0.0627, 0.1167, 0.0932, 0.0846, 0.0701,
        0.1094, 0.1098, 0.0615], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:18,787][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0681, 0.0176, 0.0248, 0.0471, 0.0506, 0.0580, 0.0841, 0.0982, 0.1048,
        0.0550, 0.0940, 0.1977, 0.1001], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,787][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0517, 0.0423, 0.0621, 0.0811, 0.0680, 0.1004, 0.0905, 0.0747, 0.0869,
        0.0879, 0.1013, 0.0805, 0.0727], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,788][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([7.1958e-05, 3.0557e-02, 1.4748e-02, 2.0710e-01, 8.1765e-03, 6.1325e-02,
        1.0077e-01, 4.2660e-02, 2.8780e-02, 2.5578e-01, 2.1724e-01, 2.3573e-02,
        9.2206e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,788][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0692, 0.0300, 0.0288, 0.0543, 0.0558, 0.0759, 0.0890, 0.0794, 0.0878,
        0.0756, 0.0995, 0.1489, 0.1057], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,789][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0474, 0.0230, 0.0267, 0.0737, 0.0420, 0.0614, 0.0923, 0.0948, 0.1067,
        0.0812, 0.1215, 0.1548, 0.0745], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,791][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.1146, 0.0809, 0.0747, 0.0883, 0.0517, 0.0922, 0.0726, 0.0771, 0.0775,
        0.0642, 0.0572, 0.0957, 0.0533], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,793][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0963, 0.0929, 0.0832, 0.0832, 0.0677, 0.0757, 0.0686, 0.0779, 0.0670,
        0.0670, 0.0697, 0.0871, 0.0638], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,794][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0130, 0.0612, 0.0550, 0.0953, 0.0587, 0.0842, 0.0958, 0.1005, 0.0780,
        0.1105, 0.1203, 0.0648, 0.0627], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,796][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0521, 0.0152, 0.0268, 0.0551, 0.0565, 0.0672, 0.0821, 0.1197, 0.1106,
        0.0617, 0.0938, 0.1560, 0.1032], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,796][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0588, 0.0204, 0.0226, 0.0470, 0.0573, 0.0593, 0.0804, 0.0809, 0.0955,
        0.0776, 0.1106, 0.1667, 0.1229], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,797][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0012, 0.0218, 0.0258, 0.1257, 0.0312, 0.0840, 0.1395, 0.0542, 0.0592,
        0.1677, 0.1858, 0.0653, 0.0386], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,797][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0210, 0.0838, 0.0502, 0.1236, 0.0540, 0.0942, 0.0797, 0.0841, 0.0658,
        0.1060, 0.1150, 0.0620, 0.0608], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:18,797][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.1482, 0.0165, 0.0169, 0.0256, 0.0308, 0.0390, 0.0583, 0.0547, 0.0745,
        0.0455, 0.0806, 0.1769, 0.0759, 0.1565], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,798][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.1044, 0.0450, 0.0744, 0.0435, 0.0760, 0.0900, 0.0702, 0.0647, 0.0722,
        0.0614, 0.0669, 0.0738, 0.0770, 0.0806], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,798][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([1.5921e-04, 3.9494e-02, 2.3224e-02, 1.6068e-01, 9.4696e-03, 6.9192e-02,
        9.2024e-02, 4.5827e-02, 3.4233e-02, 2.4506e-01, 1.8374e-01, 3.0550e-02,
        1.0794e-02, 5.5554e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,799][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0843, 0.0244, 0.0240, 0.0406, 0.0376, 0.0552, 0.0713, 0.0582, 0.0724,
        0.0696, 0.0936, 0.1397, 0.0792, 0.1500], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,801][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0588, 0.0161, 0.0185, 0.0470, 0.0267, 0.0454, 0.0763, 0.0668, 0.0899,
        0.0656, 0.1061, 0.1492, 0.0558, 0.1778], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,803][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.2152, 0.0611, 0.0718, 0.0685, 0.0450, 0.0672, 0.0591, 0.0521, 0.0586,
        0.0475, 0.0433, 0.0886, 0.0489, 0.0731], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,804][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1303, 0.0968, 0.0750, 0.0701, 0.0587, 0.0649, 0.0565, 0.0654, 0.0573,
        0.0569, 0.0574, 0.0760, 0.0547, 0.0799], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,806][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0203, 0.0442, 0.0568, 0.0659, 0.0625, 0.0781, 0.0923, 0.0910, 0.0729,
        0.1003, 0.0967, 0.0673, 0.0650, 0.0867], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,806][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0575, 0.0098, 0.0196, 0.0341, 0.0346, 0.0531, 0.0680, 0.0754, 0.0939,
        0.0597, 0.0930, 0.1358, 0.0761, 0.1893], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,807][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0669, 0.0153, 0.0200, 0.0356, 0.0453, 0.0393, 0.0634, 0.0588, 0.0700,
        0.0667, 0.1046, 0.1529, 0.1046, 0.1566], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,807][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0015, 0.0256, 0.0283, 0.0943, 0.0274, 0.0860, 0.1226, 0.0527, 0.0443,
        0.1547, 0.1609, 0.0671, 0.0323, 0.1023], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,808][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0332, 0.0632, 0.0649, 0.0938, 0.0618, 0.0964, 0.0798, 0.0748, 0.0623,
        0.0919, 0.0893, 0.0618, 0.0631, 0.0635], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:18,808][circuit_model.py][line:2332][INFO] ##7-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.1742, 0.0161, 0.0232, 0.0219, 0.0387, 0.0357, 0.0506, 0.0547, 0.0684,
        0.0332, 0.0523, 0.1479, 0.0803, 0.1203, 0.0825], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,808][circuit_model.py][line:2335][INFO] ##7-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.1620, 0.0499, 0.0687, 0.0371, 0.0700, 0.0710, 0.0547, 0.0543, 0.0616,
        0.0493, 0.0535, 0.0701, 0.0772, 0.0713, 0.0492], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,809][circuit_model.py][line:2338][INFO] ##7-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([1.7242e-04, 4.1670e-02, 2.7009e-02, 1.6426e-01, 9.2675e-03, 5.4473e-02,
        7.6719e-02, 3.7212e-02, 3.0246e-02, 2.1624e-01, 1.6317e-01, 2.4707e-02,
        9.6957e-03, 4.6709e-02, 9.8445e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,811][circuit_model.py][line:2341][INFO] ##7-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1059, 0.0234, 0.0261, 0.0347, 0.0390, 0.0524, 0.0611, 0.0508, 0.0631,
        0.0572, 0.0710, 0.1185, 0.0722, 0.1301, 0.0944], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,813][circuit_model.py][line:2344][INFO] ##7-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0741, 0.0130, 0.0205, 0.0367, 0.0285, 0.0440, 0.0688, 0.0646, 0.0824,
        0.0548, 0.0817, 0.1191, 0.0531, 0.1482, 0.1105], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,815][circuit_model.py][line:2347][INFO] ##7-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2531, 0.0603, 0.0703, 0.0581, 0.0493, 0.0601, 0.0506, 0.0442, 0.0507,
        0.0382, 0.0345, 0.0823, 0.0491, 0.0601, 0.0390], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,816][circuit_model.py][line:2350][INFO] ##7-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1589, 0.0937, 0.0773, 0.0603, 0.0593, 0.0578, 0.0490, 0.0553, 0.0508,
        0.0474, 0.0468, 0.0700, 0.0534, 0.0687, 0.0513], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,818][circuit_model.py][line:2353][INFO] ##7-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0297, 0.0441, 0.0655, 0.0661, 0.0692, 0.0728, 0.0846, 0.0714, 0.0662,
        0.0778, 0.0795, 0.0634, 0.0641, 0.0720, 0.0735], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,820][circuit_model.py][line:2356][INFO] ##7-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0837, 0.0098, 0.0235, 0.0298, 0.0433, 0.0473, 0.0577, 0.0729, 0.0851,
        0.0485, 0.0712, 0.1128, 0.0815, 0.1453, 0.0878], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,821][circuit_model.py][line:2359][INFO] ##7-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0902, 0.0133, 0.0229, 0.0281, 0.0493, 0.0363, 0.0557, 0.0538, 0.0667,
        0.0520, 0.0738, 0.1331, 0.1024, 0.1320, 0.0904], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,822][circuit_model.py][line:2362][INFO] ##7-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0016, 0.0239, 0.0292, 0.0827, 0.0296, 0.0757, 0.1135, 0.0421, 0.0405,
        0.1374, 0.1289, 0.0581, 0.0320, 0.0917, 0.1129], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,822][circuit_model.py][line:2365][INFO] ##7-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0426, 0.0580, 0.0714, 0.0770, 0.0642, 0.0868, 0.0677, 0.0653, 0.0616,
        0.0767, 0.0762, 0.0666, 0.0639, 0.0632, 0.0587], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:18,823][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:18,824][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[8731],
        [ 592],
        [5001],
        [ 555],
        [ 411],
        [ 363],
        [ 189],
        [ 262],
        [ 341],
        [ 193],
        [ 228],
        [  95],
        [ 155],
        [ 101],
        [  97]], device='cuda:0')
[2024-07-24 10:20:18,825][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[10323],
        [ 2531],
        [ 7790],
        [  909],
        [  622],
        [  571],
        [  266],
        [  414],
        [  478],
        [  277],
        [  318],
        [  114],
        [  213],
        [  142],
        [  171]], device='cuda:0')
[2024-07-24 10:20:18,827][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[47887],
        [46879],
        [43968],
        [46604],
        [39539],
        [40711],
        [42197],
        [39138],
        [39744],
        [41220],
        [40825],
        [39807],
        [38774],
        [41378],
        [41229]], device='cuda:0')
[2024-07-24 10:20:18,829][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[23421],
        [ 5998],
        [12172],
        [ 6237],
        [ 6669],
        [ 7022],
        [ 7695],
        [ 9301],
        [ 8118],
        [ 7817],
        [ 7632],
        [ 7741],
        [ 7370],
        [ 7669],
        [ 7663]], device='cuda:0')
[2024-07-24 10:20:18,830][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 7436],
        [21345],
        [49025],
        [47073],
        [44301],
        [45664],
        [46997],
        [46745],
        [46371],
        [47562],
        [47946],
        [47623],
        [47720],
        [47765],
        [47503]], device='cuda:0')
[2024-07-24 10:20:18,832][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[4399],
        [5551],
        [2249],
        [3124],
        [2001],
        [2772],
        [2468],
        [3104],
        [4136],
        [3628],
        [4116],
        [5822],
        [6690],
        [6338],
        [5424]], device='cuda:0')
[2024-07-24 10:20:18,833][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[32473],
        [26140],
        [30879],
        [38331],
        [38381],
        [36418],
        [34323],
        [33632],
        [33767],
        [33076],
        [33310],
        [34212],
        [34033],
        [36147],
        [36699]], device='cuda:0')
[2024-07-24 10:20:18,834][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[42474],
        [42720],
        [41317],
        [40848],
        [41077],
        [41055],
        [41841],
        [42291],
        [41834],
        [41658],
        [40719],
        [39103],
        [37722],
        [38325],
        [40685]], device='cuda:0')
[2024-07-24 10:20:18,835][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[ 9947],
        [15326],
        [14420],
        [14442],
        [13705],
        [14075],
        [14336],
        [14824],
        [16014],
        [16495],
        [17144],
        [17631],
        [16839],
        [16787],
        [16931]], device='cuda:0')
[2024-07-24 10:20:18,836][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[48131],
        [ 8143],
        [23171],
        [28006],
        [22203],
        [19225],
        [17681],
        [17351],
        [16412],
        [16747],
        [16495],
        [15904],
        [15041],
        [15725],
        [15397]], device='cuda:0')
[2024-07-24 10:20:18,838][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[11985],
        [ 3878],
        [18046],
        [ 8516],
        [16554],
        [16604],
        [16504],
        [16284],
        [15732],
        [15590],
        [12275],
        [15223],
        [21453],
        [17683],
        [18769]], device='cuda:0')
[2024-07-24 10:20:18,839][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[18619],
        [12268],
        [ 3432],
        [ 5305],
        [ 6296],
        [ 6524],
        [ 6891],
        [ 6358],
        [ 7423],
        [ 7228],
        [ 7030],
        [ 6811],
        [ 7067],
        [ 7357],
        [ 7361]], device='cuda:0')
[2024-07-24 10:20:18,841][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[22925],
        [ 7343],
        [17713],
        [11499],
        [11038],
        [11415],
        [11961],
        [11965],
        [12398],
        [12834],
        [13129],
        [13174],
        [13433],
        [13218],
        [13246]], device='cuda:0')
[2024-07-24 10:20:18,842][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[28261],
        [17757],
        [18360],
        [20086],
        [19463],
        [19516],
        [19957],
        [19550],
        [19772],
        [19892],
        [20410],
        [19847],
        [20080],
        [20427],
        [20701]], device='cuda:0')
[2024-07-24 10:20:18,844][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[4757],
        [4048],
        [4184],
        [3643],
        [3660],
        [3961],
        [4384],
        [4420],
        [4398],
        [4547],
        [4437],
        [4651],
        [4004],
        [3981],
        [3803]], device='cuda:0')
[2024-07-24 10:20:18,845][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[29401],
        [19330],
        [12717],
        [19269],
        [ 9369],
        [12413],
        [14870],
        [18373],
        [20545],
        [19530],
        [18427],
        [18165],
        [18786],
        [19048],
        [20196]], device='cuda:0')
[2024-07-24 10:20:18,846][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[21699],
        [34502],
        [20447],
        [17384],
        [18799],
        [27589],
        [29421],
        [33939],
        [34783],
        [34710],
        [33487],
        [35148],
        [33613],
        [33532],
        [33524]], device='cuda:0')
[2024-07-24 10:20:18,847][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[14670],
        [41827],
        [39975],
        [46344],
        [46703],
        [43760],
        [43574],
        [43219],
        [41966],
        [40881],
        [40761],
        [40196],
        [39980],
        [39494],
        [40359]], device='cuda:0')
[2024-07-24 10:20:18,848][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[13342],
        [ 4948],
        [ 6619],
        [12413],
        [15821],
        [13263],
        [12381],
        [12721],
        [11676],
        [11894],
        [12799],
        [11416],
        [12605],
        [10993],
        [10460]], device='cuda:0')
[2024-07-24 10:20:18,850][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[33464],
        [ 7222],
        [ 6251],
        [ 6719],
        [ 6118],
        [ 4834],
        [ 4886],
        [ 3851],
        [ 4166],
        [ 4109],
        [ 4525],
        [ 3870],
        [ 4015],
        [ 3793],
        [ 4105]], device='cuda:0')
[2024-07-24 10:20:18,851][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[17549],
        [ 9282],
        [ 2758],
        [ 5847],
        [ 1490],
        [ 2171],
        [ 2363],
        [ 2855],
        [ 3527],
        [ 3651],
        [ 3976],
        [ 3800],
        [ 3461],
        [ 3748],
        [ 3842]], device='cuda:0')
[2024-07-24 10:20:18,853][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[10162],
        [ 8048],
        [ 9461],
        [10528],
        [12362],
        [12471],
        [14910],
        [17494],
        [17761],
        [17519],
        [17858],
        [18949],
        [19381],
        [19058],
        [19223]], device='cuda:0')
[2024-07-24 10:20:18,854][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[46748],
        [29901],
        [22568],
        [19282],
        [19483],
        [20616],
        [19290],
        [16327],
        [13332],
        [13123],
        [12269],
        [11865],
        [11565],
        [11913],
        [11860]], device='cuda:0')
[2024-07-24 10:20:18,855][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[39569],
        [47752],
        [47696],
        [46531],
        [46288],
        [46020],
        [43293],
        [43563],
        [41796],
        [40809],
        [39935],
        [38852],
        [35948],
        [35247],
        [35469]], device='cuda:0')
[2024-07-24 10:20:18,856][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[29070],
        [22064],
        [14848],
        [16502],
        [10935],
        [10247],
        [ 9586],
        [10400],
        [11220],
        [11414],
        [12755],
        [11438],
        [ 9820],
        [11466],
        [11628]], device='cuda:0')
[2024-07-24 10:20:18,857][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[29640],
        [49033],
        [49082],
        [49178],
        [48257],
        [48825],
        [48537],
        [48021],
        [47759],
        [47934],
        [47567],
        [47902],
        [47583],
        [47794],
        [48016]], device='cuda:0')
[2024-07-24 10:20:18,859][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[26953],
        [18978],
        [16844],
        [14338],
        [15669],
        [13679],
        [12544],
        [11671],
        [11950],
        [12211],
        [12410],
        [12448],
        [13395],
        [13975],
        [14460]], device='cuda:0')
[2024-07-24 10:20:18,861][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[ 7860],
        [23832],
        [36425],
        [30238],
        [35722],
        [34196],
        [34691],
        [32396],
        [32569],
        [33447],
        [33495],
        [34038],
        [34931],
        [35056],
        [34319]], device='cuda:0')
[2024-07-24 10:20:18,862][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[46083],
        [44032],
        [45165],
        [45302],
        [45650],
        [45316],
        [45003],
        [45253],
        [45398],
        [45425],
        [45676],
        [45339],
        [45832],
        [45856],
        [46053]], device='cuda:0')
[2024-07-24 10:20:18,863][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548],
        [19548]], device='cuda:0')
[2024-07-24 10:20:18,915][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:18,915][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,915][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,916][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,916][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,916][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,917][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,919][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,920][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,921][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,922][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,923][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,924][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:18,925][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2204, 0.7796], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,925][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0013, 0.9987], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,925][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.6495, 0.3505], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,926][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.2655, 0.7345], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,926][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.4441, 0.5559], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,926][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.8301, 0.1699], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,927][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.2599, 0.7401], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,927][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.6422, 0.3578], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,927][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4471, 0.5529], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,929][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.3601, 0.6399], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,931][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6566, 0.3434], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,932][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2063, 0.7937], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:18,934][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.1597, 0.3963, 0.4439], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,935][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.0011, 0.5627, 0.4362], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,935][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.6831, 0.2472, 0.0697], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,935][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.3543, 0.3134, 0.3323], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,936][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.2135, 0.5103, 0.2762], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,936][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.6041, 0.2493, 0.1466], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,936][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.1823, 0.3459, 0.4718], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,937][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.3963, 0.4663, 0.1374], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,937][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.4651, 0.2969, 0.2380], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,937][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.2918, 0.4025, 0.3057], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,938][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.6051, 0.2615, 0.1334], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,940][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.1695, 0.5137, 0.3169], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:18,942][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0981, 0.2065, 0.1942, 0.5012], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,943][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0011, 0.2230, 0.1811, 0.5948], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,945][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5902, 0.2043, 0.0501, 0.1554], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,945][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5243, 0.1719, 0.1701, 0.1336], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,945][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.3330, 0.1935, 0.1227, 0.3508], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,946][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.7717, 0.0895, 0.0555, 0.0833], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,946][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.2214, 0.1605, 0.3215, 0.2967], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,946][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.6338, 0.1530, 0.0437, 0.1695], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,947][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.6279, 0.1892, 0.1057, 0.0772], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,947][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.4165, 0.2657, 0.1560, 0.1619], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,947][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.7980, 0.1080, 0.0401, 0.0539], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,949][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.2328, 0.3079, 0.1419, 0.3174], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:18,951][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0793, 0.1671, 0.1713, 0.4719, 0.1104], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,951][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([2.9676e-04, 1.4524e-01, 1.2121e-01, 6.1934e-01, 1.1391e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,953][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.3763, 0.1724, 0.0760, 0.2565, 0.1188], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,954][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.1577, 0.1797, 0.1812, 0.2483, 0.2331], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,955][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.1009, 0.1592, 0.0751, 0.5069, 0.1579], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,955][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.3837, 0.1425, 0.0871, 0.2267, 0.1601], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,956][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0815, 0.1519, 0.2165, 0.3255, 0.2245], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,956][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.1970, 0.1909, 0.0652, 0.4024, 0.1445], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,956][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.3815, 0.1815, 0.1360, 0.1373, 0.1637], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,957][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.2106, 0.2157, 0.1528, 0.2290, 0.1919], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,957][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.4784, 0.1575, 0.0715, 0.1373, 0.1552], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,957][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0839, 0.2313, 0.1099, 0.4114, 0.1636], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:18,958][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0276, 0.1550, 0.1810, 0.5248, 0.0732, 0.0385], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,960][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ had] are: tensor([1.0740e-04, 1.4580e-01, 1.3664e-01, 5.0269e-01, 9.1497e-02, 1.2326e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,961][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.6562, 0.0780, 0.0365, 0.1046, 0.0837, 0.0411], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,963][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.1717, 0.1974, 0.1446, 0.2111, 0.1504, 0.1247], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,964][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.1222, 0.1226, 0.0563, 0.3139, 0.1040, 0.2809], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,965][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.4827, 0.1007, 0.0561, 0.1236, 0.0966, 0.1404], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,965][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0614, 0.1067, 0.2076, 0.2501, 0.1700, 0.2043], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,966][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.3063, 0.1323, 0.0375, 0.2164, 0.0699, 0.2376], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,966][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.3636, 0.1534, 0.1331, 0.1058, 0.1328, 0.1114], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,966][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.2026, 0.1940, 0.1228, 0.1663, 0.1419, 0.1725], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,967][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.5768, 0.0998, 0.0462, 0.0705, 0.0829, 0.1239], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,967][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0737, 0.1710, 0.0796, 0.2673, 0.1113, 0.2971], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:18,968][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0013, 0.0052, 0.0061, 0.0201, 0.0015, 0.0011, 0.9646],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,968][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0006, 0.1377, 0.1137, 0.3773, 0.0765, 0.1061, 0.1882],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,970][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.5820, 0.1357, 0.0400, 0.0587, 0.0866, 0.0324, 0.0647],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,972][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2384, 0.1634, 0.1064, 0.1470, 0.1080, 0.1062, 0.1305],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,973][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.1382, 0.0855, 0.0445, 0.1679, 0.0777, 0.2009, 0.2854],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,975][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.5291, 0.0787, 0.0505, 0.0763, 0.0783, 0.0995, 0.0875],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,975][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.1205, 0.1113, 0.1833, 0.1631, 0.1358, 0.1404, 0.1456],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,976][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.3265, 0.0904, 0.0337, 0.1172, 0.0564, 0.1512, 0.2246],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,976][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.4654, 0.1296, 0.0997, 0.0636, 0.0948, 0.0747, 0.0722],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,976][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2492, 0.1492, 0.0960, 0.1004, 0.1125, 0.1383, 0.1543],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,977][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.6537, 0.0747, 0.0333, 0.0383, 0.0546, 0.0743, 0.0711],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,977][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0768, 0.1449, 0.0657, 0.1755, 0.0795, 0.1970, 0.2607],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:18,978][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0011, 0.0051, 0.0057, 0.0156, 0.0020, 0.0011, 0.9371, 0.0323],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,978][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ long] are: tensor([1.1058e-04, 1.0440e-01, 9.4043e-02, 4.0657e-01, 5.6554e-02, 8.2920e-02,
        2.0015e-01, 5.5241e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,980][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.3910, 0.0987, 0.0502, 0.1038, 0.0709, 0.0715, 0.1079, 0.1060],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,982][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.2272, 0.1463, 0.0936, 0.1177, 0.1077, 0.0859, 0.1078, 0.1137],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,983][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0749, 0.0627, 0.0295, 0.1581, 0.0566, 0.1570, 0.2527, 0.2085],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,985][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.3580, 0.0755, 0.0430, 0.0874, 0.0757, 0.1199, 0.1108, 0.1297],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,985][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0735, 0.0896, 0.1432, 0.1565, 0.1204, 0.1358, 0.1437, 0.1373],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,986][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1735, 0.0673, 0.0230, 0.1099, 0.0475, 0.1483, 0.2364, 0.1942],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,986][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.3077, 0.1263, 0.0940, 0.0901, 0.0853, 0.0956, 0.0921, 0.1089],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,987][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.1507, 0.1200, 0.0750, 0.1056, 0.0966, 0.1383, 0.1640, 0.1498],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,987][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.5736, 0.0750, 0.0279, 0.0396, 0.0547, 0.0868, 0.0762, 0.0661],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,987][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0440, 0.1021, 0.0458, 0.1399, 0.0656, 0.1818, 0.2471, 0.1736],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:18,988][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0107, 0.0242, 0.0200, 0.0505, 0.0089, 0.0069, 0.7556, 0.0941, 0.0291],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,988][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([4.2439e-05, 1.0787e-01, 8.3464e-02, 4.3188e-01, 4.6173e-02, 7.5034e-02,
        1.8555e-01, 4.6800e-02, 2.3175e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,990][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.2855, 0.0773, 0.0685, 0.1240, 0.1183, 0.0577, 0.1016, 0.0905, 0.0765],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,991][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.2157, 0.1143, 0.0787, 0.1185, 0.0943, 0.0886, 0.1141, 0.0911, 0.0846],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,993][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0501, 0.0449, 0.0257, 0.1246, 0.0507, 0.1271, 0.2073, 0.1873, 0.1822],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,994][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.3074, 0.0607, 0.0403, 0.0802, 0.0706, 0.0958, 0.0984, 0.1193, 0.1273],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,996][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0636, 0.0752, 0.1134, 0.1310, 0.0974, 0.1162, 0.1311, 0.1276, 0.1445],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,996][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1618, 0.0513, 0.0229, 0.0818, 0.0438, 0.1095, 0.1692, 0.1771, 0.1825],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,996][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.3263, 0.1157, 0.0812, 0.0656, 0.0773, 0.0774, 0.0761, 0.0886, 0.0917],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,997][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.1400, 0.1123, 0.0658, 0.0968, 0.0825, 0.1190, 0.1299, 0.1205, 0.1334],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,997][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.5334, 0.0676, 0.0226, 0.0373, 0.0451, 0.0829, 0.0771, 0.0590, 0.0750],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,998][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0421, 0.0974, 0.0402, 0.1347, 0.0557, 0.1520, 0.2077, 0.1428, 0.1274],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:18,998][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [,] are: tensor([3.8683e-03, 5.0575e-03, 4.8895e-03, 1.8398e-02, 1.8863e-03, 8.0962e-04,
        9.1294e-01, 3.7528e-02, 8.1793e-03, 6.4448e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:18,998][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [,] are: tensor([1.4536e-04, 1.0480e-01, 8.6361e-02, 3.1892e-01, 5.4739e-02, 7.6234e-02,
        1.6433e-01, 5.3600e-02, 3.1176e-02, 1.0968e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,000][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4488, 0.0791, 0.0405, 0.1214, 0.0558, 0.0557, 0.0481, 0.0731, 0.0576,
        0.0200], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,002][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1190, 0.1119, 0.0763, 0.1258, 0.0785, 0.0875, 0.1159, 0.1018, 0.0985,
        0.0848], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,003][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0658, 0.0398, 0.0308, 0.0914, 0.0548, 0.0893, 0.1444, 0.1596, 0.1817,
        0.1425], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,005][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.3697, 0.0479, 0.0405, 0.0505, 0.0698, 0.0679, 0.0637, 0.0999, 0.1157,
        0.0745], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,006][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0704, 0.0646, 0.1241, 0.0974, 0.0966, 0.1027, 0.1166, 0.1082, 0.1252,
        0.0940], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,006][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.2045, 0.0418, 0.0223, 0.0496, 0.0422, 0.0693, 0.1073, 0.1573, 0.1845,
        0.1210], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,007][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.3320, 0.1006, 0.0853, 0.0568, 0.0822, 0.0644, 0.0643, 0.0782, 0.0853,
        0.0509], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,007][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1523, 0.1036, 0.0673, 0.0711, 0.0741, 0.0963, 0.1102, 0.1044, 0.1163,
        0.1045], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,007][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.4744, 0.0666, 0.0299, 0.0364, 0.0532, 0.0725, 0.0673, 0.0581, 0.0773,
        0.0644], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,008][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0477, 0.0934, 0.0419, 0.1053, 0.0495, 0.1220, 0.1635, 0.1206, 0.1185,
        0.1375], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,008][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0051, 0.0108, 0.0111, 0.0276, 0.0038, 0.0023, 0.8345, 0.0467, 0.0160,
        0.0153, 0.0267], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,009][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ and] are: tensor([1.4201e-04, 9.3505e-02, 7.4033e-02, 2.8423e-01, 4.6585e-02, 6.7524e-02,
        1.3943e-01, 4.4064e-02, 2.6884e-02, 9.2926e-02, 1.3067e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,011][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.3604, 0.1086, 0.0465, 0.0619, 0.0709, 0.0572, 0.0632, 0.0730, 0.0679,
        0.0342, 0.0561], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,013][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1172, 0.0871, 0.0623, 0.1076, 0.0684, 0.0795, 0.1076, 0.0874, 0.0903,
        0.0821, 0.1105], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,014][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0661, 0.0271, 0.0239, 0.0626, 0.0436, 0.0710, 0.1175, 0.1297, 0.1478,
        0.1131, 0.1975], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,016][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.3880, 0.0397, 0.0341, 0.0396, 0.0587, 0.0533, 0.0562, 0.0835, 0.0946,
        0.0657, 0.0866], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,016][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0789, 0.0591, 0.1109, 0.0886, 0.0929, 0.0887, 0.1029, 0.0944, 0.1095,
        0.0827, 0.0914], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,017][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1906, 0.0278, 0.0165, 0.0377, 0.0326, 0.0549, 0.0932, 0.1227, 0.1437,
        0.0997, 0.1806], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,017][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.3650, 0.0938, 0.0690, 0.0479, 0.0713, 0.0540, 0.0561, 0.0669, 0.0750,
        0.0460, 0.0550], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,017][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1876, 0.0948, 0.0585, 0.0604, 0.0630, 0.0775, 0.0885, 0.0831, 0.0991,
        0.0863, 0.1012], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,018][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.4605, 0.0537, 0.0251, 0.0343, 0.0393, 0.0599, 0.0601, 0.0459, 0.0628,
        0.0566, 0.1019], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,018][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0509, 0.0801, 0.0360, 0.0826, 0.0409, 0.0987, 0.1394, 0.1005, 0.1047,
        0.1229, 0.1433], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,019][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0246, 0.0250, 0.0204, 0.0516, 0.0123, 0.0097, 0.5432, 0.1273, 0.0347,
        0.0421, 0.0511, 0.0579], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,019][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([7.3492e-05, 8.5631e-02, 7.6390e-02, 2.9672e-01, 4.2059e-02, 6.1007e-02,
        1.3691e-01, 3.7218e-02, 2.0863e-02, 8.7130e-02, 1.2428e-01, 3.1721e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,021][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.1793, 0.0762, 0.0519, 0.1316, 0.0524, 0.0538, 0.0713, 0.0717, 0.0633,
        0.0553, 0.1267, 0.0664], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,023][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0915, 0.0693, 0.0578, 0.1127, 0.0601, 0.0856, 0.1044, 0.0850, 0.0810,
        0.0739, 0.0981, 0.0807], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,024][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0299, 0.0266, 0.0166, 0.0756, 0.0301, 0.0821, 0.1154, 0.1109, 0.1031,
        0.0980, 0.1549, 0.1568], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,026][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.2103, 0.0392, 0.0318, 0.0572, 0.0492, 0.0627, 0.0714, 0.0782, 0.0835,
        0.0689, 0.0922, 0.1553], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,026][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0334, 0.0525, 0.0920, 0.0975, 0.0757, 0.0816, 0.1018, 0.0900, 0.0984,
        0.0924, 0.0982, 0.0866], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,027][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.1043, 0.0265, 0.0156, 0.0442, 0.0275, 0.0593, 0.0898, 0.0957, 0.0990,
        0.0829, 0.1476, 0.2076], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,027][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.2176, 0.0873, 0.0651, 0.0604, 0.0574, 0.0659, 0.0657, 0.0735, 0.0813,
        0.0535, 0.0643, 0.1079], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,028][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0974, 0.0746, 0.0486, 0.0624, 0.0566, 0.0831, 0.0950, 0.0855, 0.0924,
        0.0898, 0.0993, 0.1154], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,028][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.3514, 0.0460, 0.0202, 0.0298, 0.0358, 0.0603, 0.0644, 0.0458, 0.0610,
        0.0508, 0.0872, 0.1472], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,028][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0321, 0.0625, 0.0289, 0.0867, 0.0307, 0.0994, 0.1358, 0.0945, 0.0887,
        0.1080, 0.1296, 0.1031], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,029][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0188, 0.0299, 0.0299, 0.0591, 0.0214, 0.0123, 0.4463, 0.0796, 0.0646,
        0.0592, 0.0745, 0.0813, 0.0231], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,029][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([3.8110e-05, 6.5318e-02, 5.2841e-02, 2.8655e-01, 4.0929e-02, 5.9919e-02,
        1.4745e-01, 4.1427e-02, 2.3523e-02, 9.1204e-02, 1.3719e-01, 3.4704e-02,
        1.8918e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,031][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.1556, 0.0613, 0.0412, 0.0955, 0.0535, 0.0772, 0.0628, 0.0626, 0.0734,
        0.0373, 0.1096, 0.0948, 0.0751], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,033][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0382, 0.0534, 0.0508, 0.0863, 0.0661, 0.0794, 0.1015, 0.1057, 0.0984,
        0.0780, 0.0778, 0.0917, 0.0727], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,035][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0240, 0.0224, 0.0153, 0.0733, 0.0326, 0.0745, 0.1046, 0.1175, 0.0960,
        0.0814, 0.1310, 0.1627, 0.0646], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,036][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.1307, 0.0351, 0.0308, 0.0639, 0.0555, 0.0639, 0.0676, 0.0853, 0.0892,
        0.0587, 0.0794, 0.1460, 0.0938], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,037][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0282, 0.0500, 0.0770, 0.0968, 0.0767, 0.0833, 0.0921, 0.0891, 0.0857,
        0.0768, 0.0844, 0.0790, 0.0809], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,037][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0476, 0.0222, 0.0132, 0.0500, 0.0316, 0.0591, 0.0860, 0.1102, 0.1032,
        0.0643, 0.1193, 0.2143, 0.0789], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,037][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.1628, 0.0766, 0.0568, 0.0597, 0.0646, 0.0665, 0.0630, 0.0723, 0.0781,
        0.0498, 0.0598, 0.1124, 0.0776], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,038][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0660, 0.0599, 0.0425, 0.0632, 0.0558, 0.0789, 0.0930, 0.0868, 0.0914,
        0.0856, 0.0950, 0.1093, 0.0725], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,038][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.1568, 0.0437, 0.0229, 0.0447, 0.0474, 0.0753, 0.0752, 0.0694, 0.0857,
        0.0626, 0.0922, 0.1501, 0.0740], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,039][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0207, 0.0595, 0.0252, 0.0931, 0.0332, 0.0935, 0.1185, 0.1066, 0.0825,
        0.1039, 0.1232, 0.1013, 0.0388], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,039][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0202, 0.0355, 0.0277, 0.0727, 0.0130, 0.0231, 0.4390, 0.0578, 0.0556,
        0.0572, 0.0692, 0.0639, 0.0141, 0.0510], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,040][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ said] are: tensor([3.4846e-05, 6.9189e-02, 6.2363e-02, 2.9544e-01, 4.0016e-02, 5.7760e-02,
        1.2932e-01, 3.9861e-02, 2.0895e-02, 8.2101e-02, 1.2362e-01, 3.0262e-02,
        1.7304e-02, 3.1829e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,042][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.2833, 0.0541, 0.0298, 0.0658, 0.0535, 0.0314, 0.0598, 0.0604, 0.0382,
        0.0329, 0.0812, 0.0544, 0.0875, 0.0678], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,043][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1040, 0.0574, 0.0460, 0.0849, 0.0569, 0.0538, 0.0818, 0.0674, 0.0609,
        0.0609, 0.0894, 0.0837, 0.0804, 0.0726], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,045][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0317, 0.0167, 0.0091, 0.0372, 0.0180, 0.0452, 0.0786, 0.0698, 0.0763,
        0.0817, 0.1422, 0.1567, 0.0540, 0.1829], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,046][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.2233, 0.0275, 0.0173, 0.0325, 0.0286, 0.0403, 0.0448, 0.0520, 0.0639,
        0.0549, 0.0797, 0.1381, 0.0707, 0.1265], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,047][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0421, 0.0418, 0.0688, 0.0692, 0.0669, 0.0708, 0.0834, 0.0756, 0.0882,
        0.0719, 0.0743, 0.0810, 0.0738, 0.0923], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,047][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0987, 0.0165, 0.0067, 0.0226, 0.0127, 0.0314, 0.0554, 0.0557, 0.0662,
        0.0642, 0.1348, 0.2070, 0.0563, 0.1719], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,048][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.2295, 0.0653, 0.0460, 0.0422, 0.0478, 0.0465, 0.0509, 0.0608, 0.0654,
        0.0435, 0.0553, 0.1005, 0.0657, 0.0806], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,048][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.1017, 0.0677, 0.0389, 0.0478, 0.0451, 0.0546, 0.0698, 0.0607, 0.0709,
        0.0689, 0.0832, 0.1031, 0.0665, 0.1211], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,049][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.3360, 0.0284, 0.0127, 0.0184, 0.0235, 0.0375, 0.0425, 0.0323, 0.0423,
        0.0401, 0.0745, 0.1153, 0.0487, 0.1477], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,049][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0366, 0.0562, 0.0237, 0.0662, 0.0282, 0.0775, 0.1078, 0.0802, 0.0753,
        0.0927, 0.1173, 0.1036, 0.0384, 0.0963], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,050][circuit_model.py][line:2294][INFO] ##8-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0075, 0.0137, 0.0130, 0.0290, 0.0042, 0.0033, 0.7272, 0.0489, 0.0205,
        0.0236, 0.0293, 0.0294, 0.0036, 0.0177, 0.0292], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,052][circuit_model.py][line:2297][INFO] ##8-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0003, 0.0778, 0.0649, 0.2109, 0.0425, 0.0576, 0.1064, 0.0376, 0.0241,
        0.0761, 0.1056, 0.0343, 0.0219, 0.0383, 0.1018], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,054][circuit_model.py][line:2300][INFO] ##8-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.2378, 0.0788, 0.0382, 0.0512, 0.0566, 0.0334, 0.0625, 0.0457, 0.0396,
        0.0233, 0.0576, 0.0496, 0.0827, 0.0704, 0.0727], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,055][circuit_model.py][line:2303][INFO] ##8-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1181, 0.0614, 0.0510, 0.0703, 0.0610, 0.0495, 0.0708, 0.0578, 0.0634,
        0.0457, 0.0610, 0.0731, 0.0742, 0.0605, 0.0821], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,057][circuit_model.py][line:2306][INFO] ##8-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0425, 0.0160, 0.0147, 0.0340, 0.0268, 0.0393, 0.0672, 0.0699, 0.0762,
        0.0578, 0.0980, 0.1402, 0.0664, 0.1404, 0.1106], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,057][circuit_model.py][line:2309][INFO] ##8-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2455, 0.0267, 0.0228, 0.0280, 0.0354, 0.0371, 0.0393, 0.0507, 0.0585,
        0.0414, 0.0572, 0.1150, 0.0757, 0.0999, 0.0668], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,057][circuit_model.py][line:2312][INFO] ##8-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0630, 0.0495, 0.0839, 0.0621, 0.0690, 0.0648, 0.0704, 0.0614, 0.0734,
        0.0557, 0.0604, 0.0742, 0.0701, 0.0816, 0.0605], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,058][circuit_model.py][line:2315][INFO] ##8-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.1406, 0.0172, 0.0110, 0.0186, 0.0210, 0.0279, 0.0454, 0.0561, 0.0663,
        0.0459, 0.0820, 0.1696, 0.0738, 0.1213, 0.1032], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,058][circuit_model.py][line:2318][INFO] ##8-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.2801, 0.0695, 0.0514, 0.0338, 0.0514, 0.0402, 0.0417, 0.0472, 0.0553,
        0.0340, 0.0411, 0.0822, 0.0615, 0.0629, 0.0478], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,059][circuit_model.py][line:2321][INFO] ##8-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.1235, 0.0663, 0.0405, 0.0403, 0.0444, 0.0511, 0.0599, 0.0548, 0.0674,
        0.0589, 0.0681, 0.0908, 0.0609, 0.0979, 0.0751], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,059][circuit_model.py][line:2324][INFO] ##8-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.3960, 0.0330, 0.0145, 0.0169, 0.0236, 0.0320, 0.0332, 0.0238, 0.0350,
        0.0302, 0.0542, 0.0909, 0.0438, 0.1110, 0.0621], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,061][circuit_model.py][line:2327][INFO] ##8-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0365, 0.0612, 0.0251, 0.0597, 0.0286, 0.0732, 0.0986, 0.0715, 0.0695,
        0.0831, 0.0953, 0.0885, 0.0355, 0.0824, 0.0912], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,114][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:19,116][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,117][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,119][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,120][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,121][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,122][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,122][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,122][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,123][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,123][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,123][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,123][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,124][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4359, 0.5641], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,124][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0251, 0.9749], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,124][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.4546, 0.5454], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,125][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3110, 0.6890], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,125][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.4441, 0.5559], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,126][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.8301, 0.1699], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,127][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.2599, 0.7401], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,127][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.6422, 0.3578], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,128][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4471, 0.5529], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,128][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.3601, 0.6399], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,128][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.4790, 0.5210], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,128][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2063, 0.7937], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,129][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.3461, 0.3512, 0.3027], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,129][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([0.0250, 0.4417, 0.5334], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,130][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.2964, 0.3178, 0.3858], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,130][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.2148, 0.3827, 0.4025], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,130][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.2135, 0.5103, 0.2762], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,131][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.6041, 0.2493, 0.1466], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,131][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.1823, 0.3459, 0.4718], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,131][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.3963, 0.4663, 0.1374], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,131][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.4651, 0.2969, 0.2380], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,132][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.2918, 0.4025, 0.3057], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,132][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.3813, 0.3347, 0.2840], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,133][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.1695, 0.5137, 0.3169], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,133][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.3018, 0.2446, 0.1872, 0.2664], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,133][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0173, 0.1894, 0.2174, 0.5759], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,134][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3084, 0.2503, 0.2652, 0.1762], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,134][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.2500, 0.2540, 0.2198, 0.2762], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,134][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.3330, 0.1935, 0.1227, 0.3508], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,135][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.7717, 0.0895, 0.0555, 0.0833], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,135][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.2214, 0.1605, 0.3215, 0.2967], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,136][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.6338, 0.1530, 0.0437, 0.1695], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,137][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.6279, 0.1892, 0.1057, 0.0772], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,139][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.4165, 0.2657, 0.1560, 0.1619], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,140][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.4182, 0.2198, 0.1486, 0.2134], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,141][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.2328, 0.3079, 0.1419, 0.3174], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,142][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.2662, 0.1991, 0.1647, 0.2727, 0.0973], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,142][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0059, 0.0963, 0.1288, 0.5851, 0.1839], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,142][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.1798, 0.2295, 0.2187, 0.2026, 0.1694], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,143][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1007, 0.1800, 0.1827, 0.3163, 0.2203], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,143][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.1009, 0.1592, 0.0751, 0.5069, 0.1579], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,143][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.3837, 0.1425, 0.0871, 0.2267, 0.1601], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,144][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0815, 0.1519, 0.2165, 0.3255, 0.2245], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,145][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.1970, 0.1909, 0.0652, 0.4024, 0.1445], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,146][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.3815, 0.1815, 0.1360, 0.1373, 0.1637], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,148][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.2106, 0.2157, 0.1528, 0.2290, 0.1919], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,149][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.2212, 0.1694, 0.1411, 0.2449, 0.2233], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,151][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0839, 0.2313, 0.1099, 0.4114, 0.1636], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,152][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1815, 0.1532, 0.1386, 0.2491, 0.0902, 0.1874], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,152][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0077, 0.1095, 0.1541, 0.3875, 0.1310, 0.2101], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,152][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1344, 0.1865, 0.1882, 0.1614, 0.1691, 0.1604], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,153][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0947, 0.1655, 0.1455, 0.2388, 0.1471, 0.2084], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,153][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.1222, 0.1226, 0.0563, 0.3139, 0.1040, 0.2809], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,153][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.4827, 0.1007, 0.0561, 0.1236, 0.0966, 0.1404], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,154][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0614, 0.1067, 0.2076, 0.2501, 0.1700, 0.2043], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,154][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.3063, 0.1323, 0.0375, 0.2164, 0.0699, 0.2376], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,155][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.3636, 0.1534, 0.1331, 0.1058, 0.1328, 0.1114], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,157][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.2026, 0.1940, 0.1228, 0.1663, 0.1419, 0.1725], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,158][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1977, 0.1561, 0.1113, 0.1889, 0.1608, 0.1852], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,160][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0737, 0.1710, 0.0796, 0.2673, 0.1113, 0.2971], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,161][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1423, 0.0972, 0.0847, 0.1256, 0.0495, 0.0963, 0.4044],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,162][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0093, 0.1004, 0.1261, 0.3120, 0.0981, 0.1558, 0.1983],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,162][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1551, 0.1688, 0.1500, 0.1322, 0.1371, 0.1294, 0.1274],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,163][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.1154, 0.1426, 0.1172, 0.1738, 0.1087, 0.1648, 0.1776],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,163][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.1382, 0.0855, 0.0445, 0.1679, 0.0777, 0.2009, 0.2854],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,163][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.5291, 0.0787, 0.0505, 0.0763, 0.0783, 0.0995, 0.0875],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,164][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.1205, 0.1113, 0.1833, 0.1631, 0.1358, 0.1404, 0.1456],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,164][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.3265, 0.0904, 0.0337, 0.1172, 0.0564, 0.1512, 0.2246],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,165][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.4654, 0.1296, 0.0997, 0.0636, 0.0948, 0.0747, 0.0722],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,165][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2492, 0.1492, 0.0960, 0.1004, 0.1125, 0.1383, 0.1543],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,167][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.2360, 0.1294, 0.0914, 0.1281, 0.1226, 0.1410, 0.1514],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,169][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0768, 0.1449, 0.0657, 0.1755, 0.0795, 0.1970, 0.2607],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,170][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0812, 0.0635, 0.0679, 0.1075, 0.0417, 0.0856, 0.3413, 0.2113],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,172][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0049, 0.0673, 0.1049, 0.2720, 0.0866, 0.1422, 0.2171, 0.1049],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,172][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1173, 0.1366, 0.1243, 0.1124, 0.1237, 0.1117, 0.1163, 0.1577],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,173][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0868, 0.1172, 0.1023, 0.1515, 0.1047, 0.1467, 0.1578, 0.1330],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,173][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0749, 0.0627, 0.0295, 0.1581, 0.0566, 0.1570, 0.2527, 0.2085],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,173][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.3580, 0.0755, 0.0430, 0.0874, 0.0757, 0.1199, 0.1108, 0.1297],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,174][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0735, 0.0896, 0.1432, 0.1565, 0.1204, 0.1358, 0.1437, 0.1373],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,174][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1735, 0.0673, 0.0230, 0.1099, 0.0475, 0.1483, 0.2364, 0.1942],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,175][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.3077, 0.1263, 0.0940, 0.0901, 0.0853, 0.0956, 0.0921, 0.1089],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,175][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.1507, 0.1200, 0.0750, 0.1056, 0.0966, 0.1383, 0.1640, 0.1498],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,177][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.1468, 0.1062, 0.0759, 0.1301, 0.1098, 0.1395, 0.1510, 0.1407],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,179][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0440, 0.1021, 0.0458, 0.1399, 0.0656, 0.1818, 0.2471, 0.1736],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,180][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0710, 0.0627, 0.0550, 0.0967, 0.0323, 0.0765, 0.3073, 0.1872, 0.1113],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,182][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0047, 0.0591, 0.0869, 0.2348, 0.0818, 0.1361, 0.1962, 0.1021, 0.0984],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,182][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.1023, 0.1136, 0.1092, 0.0978, 0.1022, 0.1058, 0.1023, 0.1332, 0.1336],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,183][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0655, 0.0977, 0.0857, 0.1542, 0.0891, 0.1307, 0.1493, 0.1064, 0.1214],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,183][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0501, 0.0449, 0.0257, 0.1246, 0.0507, 0.1271, 0.2073, 0.1873, 0.1822],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,184][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.3074, 0.0607, 0.0403, 0.0802, 0.0706, 0.0958, 0.0984, 0.1193, 0.1273],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,184][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0636, 0.0752, 0.1134, 0.1310, 0.0974, 0.1162, 0.1311, 0.1276, 0.1445],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,184][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1618, 0.0513, 0.0229, 0.0818, 0.0438, 0.1095, 0.1692, 0.1771, 0.1825],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,185][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.3263, 0.1157, 0.0812, 0.0656, 0.0773, 0.0774, 0.0761, 0.0886, 0.0917],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,186][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.1400, 0.1123, 0.0658, 0.0968, 0.0825, 0.1190, 0.1299, 0.1205, 0.1334],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,188][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.1216, 0.0859, 0.0601, 0.1144, 0.0885, 0.1197, 0.1373, 0.1219, 0.1508],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,190][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0421, 0.0974, 0.0402, 0.1347, 0.0557, 0.1520, 0.2077, 0.1428, 0.1274],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,191][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0801, 0.0593, 0.0544, 0.0819, 0.0346, 0.0644, 0.2545, 0.1694, 0.0949,
        0.1067], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,192][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0049, 0.0591, 0.0794, 0.1896, 0.0623, 0.0972, 0.1446, 0.0745, 0.0733,
        0.2149], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,193][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0996, 0.1061, 0.0953, 0.0800, 0.0916, 0.0933, 0.0979, 0.1269, 0.1256,
        0.0837], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,193][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0645, 0.0923, 0.0788, 0.1235, 0.0729, 0.1178, 0.1337, 0.0992, 0.1091,
        0.1082], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,194][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0658, 0.0398, 0.0308, 0.0914, 0.0548, 0.0893, 0.1444, 0.1596, 0.1817,
        0.1425], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,194][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.3697, 0.0479, 0.0405, 0.0505, 0.0698, 0.0679, 0.0637, 0.0999, 0.1157,
        0.0745], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,194][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0704, 0.0646, 0.1241, 0.0974, 0.0966, 0.1027, 0.1166, 0.1082, 0.1252,
        0.0940], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,195][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.2045, 0.0418, 0.0223, 0.0496, 0.0422, 0.0693, 0.1073, 0.1573, 0.1845,
        0.1210], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,196][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.3320, 0.1006, 0.0853, 0.0568, 0.0822, 0.0644, 0.0643, 0.0782, 0.0853,
        0.0509], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,197][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1523, 0.1036, 0.0673, 0.0711, 0.0741, 0.0963, 0.1102, 0.1044, 0.1163,
        0.1045], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,199][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1436, 0.0815, 0.0643, 0.0867, 0.0865, 0.0969, 0.1016, 0.0962, 0.1276,
        0.1152], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,201][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0477, 0.0934, 0.0419, 0.1053, 0.0495, 0.1220, 0.1635, 0.1206, 0.1185,
        0.1375], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,202][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0847, 0.0554, 0.0498, 0.0692, 0.0299, 0.0546, 0.2338, 0.1488, 0.0844,
        0.0910, 0.0985], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,203][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0033, 0.0438, 0.0591, 0.1469, 0.0482, 0.0791, 0.1170, 0.0607, 0.0591,
        0.1819, 0.2009], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,203][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1049, 0.1025, 0.0910, 0.0734, 0.0868, 0.0823, 0.0841, 0.1080, 0.1142,
        0.0736, 0.0792], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,203][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0678, 0.0840, 0.0661, 0.1051, 0.0658, 0.1017, 0.1194, 0.0878, 0.0976,
        0.0991, 0.1056], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,204][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0661, 0.0271, 0.0239, 0.0626, 0.0436, 0.0710, 0.1175, 0.1297, 0.1478,
        0.1131, 0.1975], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,204][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3880, 0.0397, 0.0341, 0.0396, 0.0587, 0.0533, 0.0562, 0.0835, 0.0946,
        0.0657, 0.0866], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,205][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0789, 0.0591, 0.1109, 0.0886, 0.0929, 0.0887, 0.1029, 0.0944, 0.1095,
        0.0827, 0.0914], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,205][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1906, 0.0278, 0.0165, 0.0377, 0.0326, 0.0549, 0.0932, 0.1227, 0.1437,
        0.0997, 0.1806], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,206][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3650, 0.0938, 0.0690, 0.0479, 0.0713, 0.0540, 0.0561, 0.0669, 0.0750,
        0.0460, 0.0550], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,208][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1876, 0.0948, 0.0585, 0.0604, 0.0630, 0.0775, 0.0885, 0.0831, 0.0991,
        0.0863, 0.1012], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,210][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1491, 0.0698, 0.0523, 0.0732, 0.0685, 0.0797, 0.0871, 0.0804, 0.1089,
        0.0992, 0.1319], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,211][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0509, 0.0801, 0.0360, 0.0826, 0.0409, 0.0987, 0.1394, 0.1005, 0.1047,
        0.1229, 0.1433], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,213][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0580, 0.0462, 0.0376, 0.0645, 0.0239, 0.0544, 0.2206, 0.1255, 0.0832,
        0.0810, 0.0921, 0.1129], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,213][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0020, 0.0345, 0.0524, 0.1501, 0.0480, 0.0839, 0.1250, 0.0553, 0.0523,
        0.1665, 0.1790, 0.0509], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,213][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0772, 0.0814, 0.0693, 0.0690, 0.0749, 0.0800, 0.0873, 0.1057, 0.1048,
        0.0753, 0.0818, 0.0931], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,214][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0411, 0.0604, 0.0553, 0.1112, 0.0526, 0.1074, 0.1207, 0.0821, 0.0912,
        0.0942, 0.1048, 0.0791], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,214][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0299, 0.0266, 0.0166, 0.0756, 0.0301, 0.0821, 0.1154, 0.1109, 0.1031,
        0.0980, 0.1549, 0.1568], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,215][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.2103, 0.0392, 0.0318, 0.0572, 0.0492, 0.0627, 0.0714, 0.0782, 0.0835,
        0.0689, 0.0922, 0.1553], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,215][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0334, 0.0525, 0.0920, 0.0975, 0.0757, 0.0816, 0.1018, 0.0900, 0.0984,
        0.0924, 0.0982, 0.0866], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,216][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.1043, 0.0265, 0.0156, 0.0442, 0.0275, 0.0593, 0.0898, 0.0957, 0.0990,
        0.0829, 0.1476, 0.2076], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,218][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.2176, 0.0873, 0.0651, 0.0604, 0.0574, 0.0659, 0.0657, 0.0735, 0.0813,
        0.0535, 0.0643, 0.1079], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,219][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0974, 0.0746, 0.0486, 0.0624, 0.0566, 0.0831, 0.0950, 0.0855, 0.0924,
        0.0898, 0.0993, 0.1154], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,221][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0835, 0.0529, 0.0408, 0.0687, 0.0564, 0.0732, 0.0902, 0.0757, 0.0982,
        0.0887, 0.1154, 0.1563], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,222][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0321, 0.0625, 0.0289, 0.0867, 0.0307, 0.0994, 0.1358, 0.0945, 0.0887,
        0.1080, 0.1296, 0.1031], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,223][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0602, 0.0426, 0.0376, 0.0589, 0.0240, 0.0507, 0.2204, 0.1231, 0.0804,
        0.0743, 0.0916, 0.1084, 0.0280], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,223][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0010, 0.0219, 0.0306, 0.1291, 0.0409, 0.0809, 0.1291, 0.0634, 0.0528,
        0.1669, 0.1908, 0.0489, 0.0437], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,224][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0657, 0.0841, 0.0784, 0.0742, 0.0669, 0.0767, 0.0710, 0.0957, 0.0927,
        0.0612, 0.0700, 0.0840, 0.0796], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,224][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0254, 0.0499, 0.0485, 0.0922, 0.0569, 0.0922, 0.1142, 0.0911, 0.0983,
        0.0913, 0.0943, 0.0889, 0.0568], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,225][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0240, 0.0224, 0.0153, 0.0733, 0.0326, 0.0745, 0.1046, 0.1175, 0.0960,
        0.0814, 0.1310, 0.1627, 0.0646], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,225][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.1307, 0.0351, 0.0308, 0.0639, 0.0555, 0.0639, 0.0676, 0.0853, 0.0892,
        0.0587, 0.0794, 0.1460, 0.0938], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,225][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0282, 0.0500, 0.0770, 0.0968, 0.0767, 0.0833, 0.0921, 0.0891, 0.0857,
        0.0768, 0.0844, 0.0790, 0.0809], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,227][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0476, 0.0222, 0.0132, 0.0500, 0.0316, 0.0591, 0.0860, 0.1102, 0.1032,
        0.0643, 0.1193, 0.2143, 0.0789], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,229][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.1628, 0.0766, 0.0568, 0.0597, 0.0646, 0.0665, 0.0630, 0.0723, 0.0781,
        0.0498, 0.0598, 0.1124, 0.0776], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,230][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0660, 0.0599, 0.0425, 0.0632, 0.0558, 0.0789, 0.0930, 0.0868, 0.0914,
        0.0856, 0.0950, 0.1093, 0.0725], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,232][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0632, 0.0428, 0.0399, 0.0669, 0.0620, 0.0687, 0.0846, 0.0775, 0.0940,
        0.0777, 0.1001, 0.1332, 0.0894], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,233][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0207, 0.0595, 0.0252, 0.0931, 0.0332, 0.0935, 0.1185, 0.1066, 0.0825,
        0.1039, 0.1232, 0.1013, 0.0388], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,233][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0547, 0.0376, 0.0316, 0.0549, 0.0193, 0.0461, 0.1998, 0.1167, 0.0688,
        0.0738, 0.0832, 0.1017, 0.0228, 0.0889], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,234][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0019, 0.0276, 0.0409, 0.1169, 0.0424, 0.0752, 0.1020, 0.0571, 0.0474,
        0.1473, 0.1566, 0.0504, 0.0434, 0.0908], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,234][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0613, 0.0769, 0.0677, 0.0598, 0.0624, 0.0674, 0.0686, 0.0873, 0.0841,
        0.0628, 0.0647, 0.0759, 0.0720, 0.0893], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,235][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0459, 0.0560, 0.0511, 0.0895, 0.0544, 0.0784, 0.0960, 0.0682, 0.0772,
        0.0793, 0.0887, 0.0737, 0.0559, 0.0859], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,235][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0317, 0.0167, 0.0091, 0.0372, 0.0180, 0.0452, 0.0786, 0.0698, 0.0763,
        0.0817, 0.1422, 0.1567, 0.0540, 0.1829], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,236][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.2233, 0.0275, 0.0173, 0.0325, 0.0286, 0.0403, 0.0448, 0.0520, 0.0639,
        0.0549, 0.0797, 0.1381, 0.0707, 0.1265], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,237][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0421, 0.0418, 0.0688, 0.0692, 0.0669, 0.0708, 0.0834, 0.0756, 0.0882,
        0.0719, 0.0743, 0.0810, 0.0738, 0.0923], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,238][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0987, 0.0165, 0.0067, 0.0226, 0.0127, 0.0314, 0.0554, 0.0557, 0.0662,
        0.0642, 0.1348, 0.2070, 0.0563, 0.1719], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,240][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.2295, 0.0653, 0.0460, 0.0422, 0.0478, 0.0465, 0.0509, 0.0608, 0.0654,
        0.0435, 0.0553, 0.1005, 0.0657, 0.0806], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,241][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.1017, 0.0677, 0.0389, 0.0478, 0.0451, 0.0546, 0.0698, 0.0607, 0.0709,
        0.0689, 0.0832, 0.1031, 0.0665, 0.1211], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,243][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0807, 0.0406, 0.0311, 0.0480, 0.0448, 0.0507, 0.0624, 0.0573, 0.0743,
        0.0711, 0.0972, 0.1250, 0.0756, 0.1413], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,243][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0366, 0.0562, 0.0237, 0.0662, 0.0282, 0.0775, 0.1078, 0.0802, 0.0753,
        0.0927, 0.1173, 0.1036, 0.0384, 0.0963], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,244][circuit_model.py][line:2332][INFO] ##8-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0657, 0.0404, 0.0353, 0.0494, 0.0217, 0.0410, 0.1764, 0.1138, 0.0622,
        0.0673, 0.0731, 0.0933, 0.0239, 0.0806, 0.0559], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,244][circuit_model.py][line:2335][INFO] ##8-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0031, 0.0377, 0.0477, 0.1140, 0.0390, 0.0623, 0.0857, 0.0455, 0.0437,
        0.1244, 0.1406, 0.0439, 0.0383, 0.0818, 0.0922], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,245][circuit_model.py][line:2338][INFO] ##8-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0748, 0.0725, 0.0585, 0.0511, 0.0596, 0.0577, 0.0593, 0.0743, 0.0801,
        0.0550, 0.0582, 0.0747, 0.0724, 0.0849, 0.0668], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,245][circuit_model.py][line:2341][INFO] ##8-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0526, 0.0612, 0.0515, 0.0781, 0.0529, 0.0741, 0.0889, 0.0644, 0.0732,
        0.0674, 0.0703, 0.0672, 0.0498, 0.0773, 0.0710], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,246][circuit_model.py][line:2344][INFO] ##8-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0425, 0.0160, 0.0147, 0.0340, 0.0268, 0.0393, 0.0672, 0.0699, 0.0762,
        0.0578, 0.0980, 0.1402, 0.0664, 0.1404, 0.1106], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,247][circuit_model.py][line:2347][INFO] ##8-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2455, 0.0267, 0.0228, 0.0280, 0.0354, 0.0371, 0.0393, 0.0507, 0.0585,
        0.0414, 0.0572, 0.1150, 0.0757, 0.0999, 0.0668], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,249][circuit_model.py][line:2350][INFO] ##8-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0630, 0.0495, 0.0839, 0.0621, 0.0690, 0.0648, 0.0704, 0.0614, 0.0734,
        0.0557, 0.0604, 0.0742, 0.0701, 0.0816, 0.0605], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,251][circuit_model.py][line:2353][INFO] ##8-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.1406, 0.0172, 0.0110, 0.0186, 0.0210, 0.0279, 0.0454, 0.0561, 0.0663,
        0.0459, 0.0820, 0.1696, 0.0738, 0.1213, 0.1032], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,252][circuit_model.py][line:2356][INFO] ##8-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.2801, 0.0695, 0.0514, 0.0338, 0.0514, 0.0402, 0.0417, 0.0472, 0.0553,
        0.0340, 0.0411, 0.0822, 0.0615, 0.0629, 0.0478], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,253][circuit_model.py][line:2359][INFO] ##8-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.1235, 0.0663, 0.0405, 0.0403, 0.0444, 0.0511, 0.0599, 0.0548, 0.0674,
        0.0589, 0.0681, 0.0908, 0.0609, 0.0979, 0.0751], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,254][circuit_model.py][line:2362][INFO] ##8-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0944, 0.0446, 0.0331, 0.0447, 0.0441, 0.0492, 0.0556, 0.0490, 0.0674,
        0.0606, 0.0775, 0.1096, 0.0667, 0.1187, 0.0849], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,254][circuit_model.py][line:2365][INFO] ##8-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0365, 0.0612, 0.0251, 0.0597, 0.0286, 0.0732, 0.0986, 0.0715, 0.0695,
        0.0831, 0.0953, 0.0885, 0.0355, 0.0824, 0.0912], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,256][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:19,257][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[7878],
        [ 277],
        [4896],
        [ 239],
        [ 245],
        [ 279],
        [ 144],
        [ 275],
        [ 347],
        [ 139],
        [ 127],
        [  85],
        [  91],
        [ 110],
        [  97]], device='cuda:0')
[2024-07-24 10:20:19,258][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[9319],
        [ 573],
        [5970],
        [ 374],
        [ 453],
        [ 514],
        [ 292],
        [ 591],
        [ 784],
        [ 338],
        [ 305],
        [ 257],
        [ 280],
        [ 376],
        [ 320]], device='cuda:0')
[2024-07-24 10:20:19,260][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[16244],
        [18867],
        [11288],
        [16725],
        [16875],
        [17599],
        [11990],
        [12393],
        [13651],
        [12459],
        [12476],
        [13242],
        [11668],
        [11863],
        [12007]], device='cuda:0')
[2024-07-24 10:20:19,261][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[16346],
        [14430],
        [31174],
        [27247],
        [27259],
        [27950],
        [28563],
        [28432],
        [27900],
        [28489],
        [27912],
        [27900],
        [27710],
        [27942],
        [27803]], device='cuda:0')
[2024-07-24 10:20:19,263][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 6417],
        [14839],
        [ 8146],
        [11836],
        [ 9989],
        [ 7415],
        [ 8773],
        [11853],
        [11031],
        [11835],
        [11643],
        [11679],
        [ 9325],
        [ 9254],
        [ 8757]], device='cuda:0')
[2024-07-24 10:20:19,264][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[29056],
        [37227],
        [45191],
        [44107],
        [42696],
        [40860],
        [39036],
        [37574],
        [37504],
        [36911],
        [35481],
        [34855],
        [33576],
        [32828],
        [32736]], device='cuda:0')
[2024-07-24 10:20:19,265][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[45943],
        [34925],
        [30512],
        [24640],
        [20718],
        [26492],
        [24993],
        [22106],
        [20245],
        [20002],
        [19450],
        [19718],
        [20408],
        [18919],
        [18677]], device='cuda:0')
[2024-07-24 10:20:19,266][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[15102],
        [ 8055],
        [ 6774],
        [10069],
        [ 6540],
        [ 6733],
        [ 6791],
        [ 6330],
        [ 6066],
        [ 5928],
        [ 6006],
        [ 5971],
        [ 5583],
        [ 5986],
        [ 6050]], device='cuda:0')
[2024-07-24 10:20:19,267][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[21826],
        [10776],
        [23243],
        [10973],
        [10053],
        [ 9590],
        [10078],
        [ 9560],
        [ 8061],
        [ 7831],
        [ 6879],
        [ 6160],
        [ 6341],
        [ 6388],
        [ 6480]], device='cuda:0')
[2024-07-24 10:20:19,269][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[20459],
        [21202],
        [24191],
        [26656],
        [34676],
        [32741],
        [33149],
        [35386],
        [34572],
        [34093],
        [33178],
        [33019],
        [33578],
        [33225],
        [33143]], device='cuda:0')
[2024-07-24 10:20:19,271][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[39691],
        [27075],
        [43335],
        [40715],
        [42662],
        [42903],
        [42700],
        [41544],
        [41720],
        [42153],
        [41597],
        [41378],
        [41751],
        [41580],
        [41649]], device='cuda:0')
[2024-07-24 10:20:19,272][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 6335],
        [26377],
        [29051],
        [26549],
        [27502],
        [24985],
        [23758],
        [23601],
        [23119],
        [22417],
        [21741],
        [21104],
        [20815],
        [20386],
        [20347]], device='cuda:0')
[2024-07-24 10:20:19,273][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[24770],
        [10926],
        [ 2613],
        [ 6172],
        [ 1571],
        [ 2547],
        [ 3258],
        [ 2577],
        [ 2880],
        [ 2573],
        [ 3415],
        [ 3248],
        [ 2722],
        [ 3868],
        [ 3988]], device='cuda:0')
[2024-07-24 10:20:19,275][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[16198],
        [ 8168],
        [49572],
        [43170],
        [45699],
        [40624],
        [38859],
        [35222],
        [34166],
        [33591],
        [33856],
        [30772],
        [32552],
        [32502],
        [33142]], device='cuda:0')
[2024-07-24 10:20:19,276][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[16663],
        [12852],
        [13081],
        [12544],
        [13025],
        [10712],
        [12318],
        [13185],
        [13474],
        [13756],
        [13243],
        [13324],
        [14063],
        [11079],
        [11788]], device='cuda:0')
[2024-07-24 10:20:19,277][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[13274],
        [ 4616],
        [ 1206],
        [ 1191],
        [ 1277],
        [ 1486],
        [  965],
        [  456],
        [  363],
        [  400],
        [  487],
        [  487],
        [  484],
        [  475],
        [  502]], device='cuda:0')
[2024-07-24 10:20:19,278][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 8059],
        [32845],
        [15763],
        [11937],
        [ 9530],
        [ 9763],
        [ 7297],
        [ 5549],
        [ 5100],
        [ 3463],
        [ 3355],
        [ 3414],
        [ 3093],
        [ 3179],
        [ 3455]], device='cuda:0')
[2024-07-24 10:20:19,279][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[41908],
        [13285],
        [15150],
        [15043],
        [15527],
        [16814],
        [18908],
        [17991],
        [17655],
        [17391],
        [16970],
        [17357],
        [17761],
        [18616],
        [18830]], device='cuda:0')
[2024-07-24 10:20:19,281][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[19500],
        [27726],
        [26994],
        [24555],
        [24154],
        [23563],
        [23669],
        [26257],
        [26276],
        [27426],
        [28426],
        [27717],
        [27191],
        [26178],
        [26525]], device='cuda:0')
[2024-07-24 10:20:19,283][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[ 4419],
        [29591],
        [27154],
        [26648],
        [23867],
        [24589],
        [24788],
        [21506],
        [19109],
        [17627],
        [17598],
        [19738],
        [20028],
        [18928],
        [19325]], device='cuda:0')
[2024-07-24 10:20:19,284][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[38057],
        [35134],
        [29558],
        [32980],
        [22161],
        [24350],
        [26352],
        [20672],
        [20949],
        [23318],
        [23937],
        [18617],
        [16637],
        [19655],
        [20247]], device='cuda:0')
[2024-07-24 10:20:19,285][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[18898],
        [ 5478],
        [ 3136],
        [ 4049],
        [ 5848],
        [ 8665],
        [ 9875],
        [10250],
        [12241],
        [12209],
        [13055],
        [12943],
        [13388],
        [13643],
        [12756]], device='cuda:0')
[2024-07-24 10:20:19,286][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 5966],
        [10674],
        [17203],
        [14671],
        [27833],
        [23789],
        [23667],
        [27692],
        [27515],
        [26317],
        [26780],
        [24575],
        [26078],
        [24162],
        [23005]], device='cuda:0')
[2024-07-24 10:20:19,287][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 7008],
        [14618],
        [14734],
        [15161],
        [16786],
        [17582],
        [17267],
        [15765],
        [14556],
        [14692],
        [14618],
        [12696],
        [12294],
        [12081],
        [12226]], device='cuda:0')
[2024-07-24 10:20:19,288][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[38736],
        [10109],
        [ 7256],
        [ 7267],
        [ 6508],
        [ 5612],
        [ 5612],
        [ 5268],
        [ 5908],
        [ 6041],
        [ 6413],
        [ 6813],
        [ 7241],
        [ 7596],
        [ 8053]], device='cuda:0')
[2024-07-24 10:20:19,290][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[10149],
        [ 4346],
        [16914],
        [17125],
        [19677],
        [17952],
        [18835],
        [20481],
        [17375],
        [16887],
        [15777],
        [16651],
        [16519],
        [15097],
        [15216]], device='cuda:0')
[2024-07-24 10:20:19,292][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[28677],
        [41185],
        [34397],
        [37077],
        [34309],
        [27424],
        [27838],
        [26979],
        [27724],
        [27613],
        [30303],
        [30260],
        [28216],
        [28145],
        [30239]], device='cuda:0')
[2024-07-24 10:20:19,293][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[30691],
        [40559],
        [42161],
        [41654],
        [41211],
        [41086],
        [39765],
        [41130],
        [42271],
        [42447],
        [42128],
        [42470],
        [42667],
        [42799],
        [42756]], device='cuda:0')
[2024-07-24 10:20:19,295][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[30194],
        [34443],
        [36271],
        [36636],
        [35532],
        [39051],
        [37329],
        [37359],
        [36686],
        [36986],
        [36969],
        [37143],
        [36369],
        [39326],
        [38347]], device='cuda:0')
[2024-07-24 10:20:19,296][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361],
        [22361]], device='cuda:0')
[2024-07-24 10:20:19,352][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:19,352][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,353][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,353][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,354][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,355][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,356][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,358][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,359][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,360][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,361][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,361][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,361][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,362][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1799, 0.8201], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,362][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2081, 0.7919], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,362][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.4653, 0.5347], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,362][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9943, 0.0057], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,363][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1679, 0.8321], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,363][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0942, 0.9058], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,364][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0717, 0.9283], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,366][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3810, 0.6190], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,367][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.5650, 0.4350], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,369][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0239, 0.9761], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,370][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.6024, 0.3976], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,371][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.3036, 0.6964], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,371][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.0223, 0.1135, 0.8641], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,372][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.0616, 0.2408, 0.6976], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,372][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.3096, 0.3703, 0.3201], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,372][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([9.6918e-01, 2.9941e-02, 8.7617e-04], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,373][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.0565, 0.3306, 0.6129], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,373][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.0527, 0.5126, 0.4347], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,373][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.0137, 0.1435, 0.8427], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,374][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.1679, 0.5217, 0.3105], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,374][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.3553, 0.4570, 0.1876], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,376][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.0064, 0.1764, 0.8172], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,378][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.2574, 0.6652, 0.0774], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,379][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.0939, 0.2282, 0.6779], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,381][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0169, 0.0620, 0.3802, 0.5409], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,381][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0448, 0.1523, 0.1545, 0.6484], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,382][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.5240, 0.2106, 0.1733, 0.0920], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,382][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.9443e-01, 3.9159e-03, 8.8122e-05, 1.5700e-03], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,382][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0385, 0.2277, 0.3366, 0.3973], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,383][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0882, 0.2952, 0.2303, 0.3863], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,383][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0071, 0.0524, 0.3371, 0.6033], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,383][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.2939, 0.3116, 0.1656, 0.2289], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,384][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.4102, 0.2608, 0.1417, 0.1873], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,384][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0015, 0.0298, 0.1583, 0.8104], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,386][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.5564, 0.1890, 0.0206, 0.2341], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,388][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0436, 0.1543, 0.2331, 0.5691], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,389][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0048, 0.0249, 0.2144, 0.4297, 0.3262], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,391][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0204, 0.0459, 0.1154, 0.5921, 0.2261], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,391][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.1998, 0.2475, 0.1882, 0.2093, 0.1553], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,392][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.8171, 0.0806, 0.0016, 0.0986, 0.0021], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,392][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0251, 0.1235, 0.2289, 0.3033, 0.3193], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,392][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0214, 0.1584, 0.1468, 0.2633, 0.4101], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,393][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0029, 0.0283, 0.2328, 0.5256, 0.2104], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,393][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0836, 0.2878, 0.1517, 0.3281, 0.1489], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,393][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.1979, 0.2436, 0.1238, 0.2307, 0.2039], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,394][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0009, 0.0217, 0.0917, 0.7398, 0.1459], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,396][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.1316, 0.2040, 0.0339, 0.5534, 0.0771], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,398][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0357, 0.0892, 0.2776, 0.3914, 0.2061], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,399][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0074, 0.0257, 0.1850, 0.3368, 0.2797, 0.1654], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,400][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0142, 0.0620, 0.0905, 0.4935, 0.1264, 0.2133], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,401][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.1586, 0.2082, 0.1842, 0.1599, 0.1399, 0.1492], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,402][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ had] are: tensor([9.8918e-01, 6.0796e-03, 1.5655e-04, 3.2365e-03, 3.1267e-04, 1.0353e-03],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,402][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0136, 0.0913, 0.1627, 0.2843, 0.2298, 0.2183], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,402][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0153, 0.1436, 0.1212, 0.2065, 0.2584, 0.2550], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,403][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0016, 0.0216, 0.2059, 0.4004, 0.1466, 0.2240], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,403][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1642, 0.1975, 0.1172, 0.2069, 0.1055, 0.2088], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,403][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.1843, 0.1909, 0.1194, 0.1514, 0.1756, 0.1783], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,404][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ had] are: tensor([2.6483e-04, 1.3238e-02, 8.3442e-02, 5.2738e-01, 6.3598e-02, 3.1208e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,404][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.2867, 0.1817, 0.0188, 0.2420, 0.0495, 0.2214], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,406][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0346, 0.0516, 0.0680, 0.2063, 0.1019, 0.5377], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,408][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0072, 0.0208, 0.1419, 0.2923, 0.2538, 0.1438, 0.1402],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,409][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0200, 0.0628, 0.0873, 0.3181, 0.1167, 0.1521, 0.2431],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,411][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.2002, 0.1714, 0.1583, 0.1159, 0.1045, 0.1238, 0.1259],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,412][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ a] are: tensor([9.9090e-01, 4.5051e-03, 8.6665e-05, 2.1454e-03, 2.2722e-04, 7.4470e-04,
        1.3934e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,412][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0249, 0.1101, 0.1506, 0.2041, 0.2009, 0.1653, 0.1442],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,412][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0326, 0.1166, 0.0921, 0.1433, 0.1942, 0.1907, 0.2304],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,413][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0025, 0.0251, 0.1799, 0.2675, 0.1118, 0.1610, 0.2522],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,413][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1937, 0.1796, 0.1019, 0.1459, 0.0789, 0.1446, 0.1554],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,413][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.2361, 0.1507, 0.1048, 0.1012, 0.1326, 0.1345, 0.1400],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,414][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ a] are: tensor([2.7926e-04, 9.4575e-03, 5.2254e-02, 2.9267e-01, 3.8644e-02, 1.9685e-01,
        4.0984e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,414][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.3062, 0.1197, 0.0172, 0.1411, 0.0400, 0.1296, 0.2462],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,415][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0111, 0.0946, 0.0826, 0.2181, 0.1258, 0.3771, 0.0907],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,417][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0039, 0.0164, 0.1434, 0.3029, 0.2272, 0.1242, 0.1266, 0.0554],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,419][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0173, 0.0416, 0.0535, 0.3123, 0.0812, 0.1375, 0.2386, 0.1180],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,420][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.1377, 0.1413, 0.1254, 0.1156, 0.1009, 0.1281, 0.1383, 0.1128],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,421][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ long] are: tensor([9.6687e-01, 1.0967e-02, 9.2965e-05, 6.9652e-03, 1.9741e-04, 3.5215e-03,
        9.9612e-03, 1.4278e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,422][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0119, 0.0676, 0.1215, 0.2151, 0.1551, 0.1624, 0.1673, 0.0991],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,422][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0123, 0.0958, 0.0636, 0.1090, 0.1653, 0.1359, 0.1751, 0.2431],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,422][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0017, 0.0178, 0.1082, 0.2376, 0.0891, 0.1465, 0.2896, 0.1094],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,423][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0814, 0.1251, 0.0793, 0.1535, 0.0755, 0.1525, 0.1848, 0.1479],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,423][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.1057, 0.1018, 0.0662, 0.0825, 0.1193, 0.1202, 0.1608, 0.2435],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,424][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ long] are: tensor([2.2578e-04, 6.7773e-03, 3.9256e-02, 2.4624e-01, 3.4642e-02, 1.6640e-01,
        4.0728e-01, 9.9174e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,424][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1438, 0.0796, 0.0135, 0.1574, 0.0370, 0.1426, 0.2796, 0.1466],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,424][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0109, 0.0692, 0.0602, 0.2406, 0.0458, 0.2544, 0.1465, 0.1725],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,425][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0015, 0.0108, 0.1217, 0.3201, 0.2075, 0.1102, 0.1370, 0.0466, 0.0446],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,427][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0097, 0.0287, 0.0469, 0.2905, 0.0654, 0.1272, 0.2285, 0.0921, 0.1110],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,429][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.1243, 0.1350, 0.1203, 0.1190, 0.0891, 0.1113, 0.1220, 0.0953, 0.0837],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,430][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([9.1735e-01, 1.8959e-02, 2.5317e-04, 1.5326e-02, 5.7890e-04, 5.3958e-03,
        2.7296e-02, 1.3682e-02, 1.1568e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,431][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0127, 0.0728, 0.1078, 0.1805, 0.1555, 0.1434, 0.1438, 0.0788, 0.1047],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,433][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0094, 0.0758, 0.0433, 0.0933, 0.1158, 0.1224, 0.1531, 0.1812, 0.2058],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,435][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0015, 0.0145, 0.0874, 0.2224, 0.0764, 0.1398, 0.2585, 0.0992, 0.1003],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,436][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0878, 0.1202, 0.0686, 0.1206, 0.0595, 0.1264, 0.1434, 0.1097, 0.1638],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,437][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0994, 0.1089, 0.0524, 0.0804, 0.0793, 0.1024, 0.1355, 0.1680, 0.1737],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,438][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([2.0847e-04, 6.7676e-03, 3.5132e-02, 2.1244e-01, 3.1929e-02, 1.6481e-01,
        3.7684e-01, 9.8604e-02, 7.3267e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,438][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.1066, 0.0491, 0.0125, 0.1136, 0.0320, 0.1016, 0.2087, 0.1347, 0.2412],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,438][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0194, 0.0349, 0.0828, 0.1063, 0.0965, 0.2103, 0.1886, 0.1288, 0.1324],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,439][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0024, 0.0139, 0.1354, 0.2752, 0.2084, 0.1001, 0.1213, 0.0470, 0.0450,
        0.0513], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,439][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0170, 0.0389, 0.0639, 0.2164, 0.0747, 0.0873, 0.1750, 0.0776, 0.1047,
        0.1444], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,440][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.1757, 0.1344, 0.1150, 0.0857, 0.0783, 0.0856, 0.0970, 0.0744, 0.0664,
        0.0876], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,440][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [,] are: tensor([8.6963e-01, 2.1298e-02, 1.0569e-03, 2.1230e-02, 2.7502e-03, 5.7248e-03,
        4.7942e-02, 2.4849e-02, 4.6507e-03, 8.6830e-04], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,440][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0149, 0.0680, 0.0973, 0.1435, 0.1372, 0.1377, 0.1425, 0.0732, 0.0920,
        0.0936], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,441][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0136, 0.0556, 0.0533, 0.1004, 0.0997, 0.1063, 0.1505, 0.1538, 0.1447,
        0.1221], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,442][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0018, 0.0174, 0.1157, 0.1734, 0.0757, 0.1079, 0.1831, 0.0726, 0.0867,
        0.1657], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,444][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0930, 0.1019, 0.0687, 0.0976, 0.0605, 0.1078, 0.1215, 0.0994, 0.1560,
        0.0938], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,446][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0850, 0.0752, 0.0555, 0.0588, 0.0745, 0.0810, 0.1033, 0.1466, 0.1755,
        0.1447], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,446][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [,] are: tensor([2.0997e-04, 5.3850e-03, 3.1772e-02, 1.6320e-01, 2.4818e-02, 1.1967e-01,
        2.7084e-01, 7.0843e-02, 5.7011e-02, 2.5625e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,448][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1441, 0.0334, 0.0117, 0.0639, 0.0361, 0.0609, 0.1315, 0.1151, 0.2546,
        0.1489], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,448][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0069, 0.0072, 0.0372, 0.0398, 0.0405, 0.2560, 0.1440, 0.2257, 0.2146,
        0.0282], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,449][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0021, 0.0135, 0.1217, 0.2181, 0.1879, 0.1023, 0.1166, 0.0460, 0.0531,
        0.0519, 0.0869], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,449][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0213, 0.0393, 0.0531, 0.1885, 0.0652, 0.0750, 0.1452, 0.0652, 0.0814,
        0.1199, 0.1459], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,450][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.2100, 0.1270, 0.1084, 0.0752, 0.0726, 0.0676, 0.0779, 0.0602, 0.0566,
        0.0721, 0.0724], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,450][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ and] are: tensor([9.4720e-01, 1.3415e-02, 5.0541e-04, 5.0007e-03, 1.1341e-03, 2.7954e-03,
        1.5267e-02, 1.0465e-02, 1.4338e-03, 3.9800e-04, 2.3882e-03],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,450][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0156, 0.0642, 0.0887, 0.1346, 0.1280, 0.1233, 0.1255, 0.0683, 0.0904,
        0.0858, 0.0756], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,451][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0133, 0.0484, 0.0480, 0.0904, 0.0863, 0.0917, 0.1370, 0.1352, 0.1256,
        0.1094, 0.1148], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,452][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0022, 0.0163, 0.0897, 0.1460, 0.0652, 0.0923, 0.1576, 0.0672, 0.0820,
        0.1486, 0.1330], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,454][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1081, 0.1056, 0.0545, 0.0862, 0.0503, 0.0861, 0.1046, 0.0837, 0.1386,
        0.0843, 0.0980], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,455][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0903, 0.0674, 0.0557, 0.0576, 0.0668, 0.0669, 0.0868, 0.1183, 0.1478,
        0.1225, 0.1198], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,456][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ and] are: tensor([1.9558e-04, 4.5815e-03, 2.4506e-02, 1.3324e-01, 2.0241e-02, 9.6777e-02,
        2.0586e-01, 5.5848e-02, 4.4442e-02, 2.0168e-01, 2.1263e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,458][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1577, 0.0187, 0.0080, 0.0361, 0.0251, 0.0350, 0.0897, 0.0782, 0.1800,
        0.0977, 0.2739], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,458][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0036, 0.0159, 0.0258, 0.0707, 0.0363, 0.1947, 0.1545, 0.1651, 0.1634,
        0.0714, 0.0987], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,459][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0011, 0.0104, 0.1049, 0.2949, 0.1562, 0.0764, 0.1051, 0.0404, 0.0332,
        0.0502, 0.0981, 0.0292], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,459][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0081, 0.0204, 0.0351, 0.1901, 0.0481, 0.0834, 0.1656, 0.0682, 0.0710,
        0.1212, 0.1396, 0.0493], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,460][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.1048, 0.1059, 0.0734, 0.0794, 0.0571, 0.0874, 0.0936, 0.0764, 0.0678,
        0.0850, 0.0839, 0.0854], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,460][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.7321, 0.0499, 0.0013, 0.0380, 0.0025, 0.0144, 0.0762, 0.0467, 0.0066,
        0.0036, 0.0176, 0.0111], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,460][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0096, 0.0400, 0.0832, 0.1319, 0.0997, 0.1096, 0.1457, 0.0712, 0.0878,
        0.0887, 0.0810, 0.0517], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,461][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0111, 0.0415, 0.0335, 0.0714, 0.0817, 0.0845, 0.1221, 0.1160, 0.1034,
        0.0887, 0.0930, 0.1531], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,462][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0008, 0.0093, 0.0600, 0.1608, 0.0510, 0.0909, 0.1821, 0.0643, 0.0671,
        0.1439, 0.1317, 0.0382], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,463][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0647, 0.0703, 0.0518, 0.0842, 0.0433, 0.0864, 0.1061, 0.0750, 0.1183,
        0.0779, 0.0877, 0.1342], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,465][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0594, 0.0523, 0.0385, 0.0506, 0.0534, 0.0675, 0.0994, 0.1136, 0.1002,
        0.1172, 0.1165, 0.1315], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,466][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([1.1534e-04, 3.6270e-03, 1.7273e-02, 1.2917e-01, 1.7010e-02, 8.9106e-02,
        2.1578e-01, 5.4495e-02, 4.3298e-02, 1.9143e-01, 2.0509e-01, 3.3609e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,468][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.0803, 0.0199, 0.0078, 0.0456, 0.0197, 0.0408, 0.0905, 0.0548, 0.1029,
        0.0695, 0.1850, 0.2832], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,468][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0077, 0.0269, 0.0962, 0.0844, 0.0858, 0.1043, 0.0785, 0.0733, 0.0775,
        0.2005, 0.1209, 0.0439], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,469][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0014, 0.0090, 0.1023, 0.2642, 0.1563, 0.0794, 0.1147, 0.0381, 0.0289,
        0.0419, 0.0831, 0.0249, 0.0558], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,469][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0075, 0.0116, 0.0317, 0.1672, 0.0614, 0.0761, 0.1453, 0.0648, 0.0811,
        0.1081, 0.1258, 0.0569, 0.0625], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,470][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0724, 0.0910, 0.0698, 0.0816, 0.0569, 0.0820, 0.0891, 0.0782, 0.0702,
        0.0871, 0.0796, 0.0877, 0.0545], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,470][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.3479, 0.0902, 0.0018, 0.1312, 0.0026, 0.0448, 0.1454, 0.1456, 0.0105,
        0.0080, 0.0351, 0.0343, 0.0028], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,470][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0092, 0.0393, 0.0799, 0.1170, 0.1147, 0.1004, 0.1253, 0.0683, 0.0840,
        0.0739, 0.0720, 0.0497, 0.0664], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,471][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0037, 0.0290, 0.0343, 0.0750, 0.0914, 0.0932, 0.1196, 0.0930, 0.1038,
        0.0728, 0.0795, 0.1135, 0.0912], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,473][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0007, 0.0075, 0.0528, 0.1289, 0.0508, 0.0991, 0.1929, 0.0670, 0.0687,
        0.1331, 0.1222, 0.0325, 0.0437], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,474][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0288, 0.0736, 0.0447, 0.0883, 0.0472, 0.0977, 0.1028, 0.0855, 0.1053,
        0.0665, 0.0693, 0.1281, 0.0623], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,476][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0390, 0.0492, 0.0314, 0.0544, 0.0488, 0.0748, 0.0995, 0.0996, 0.1004,
        0.1118, 0.1139, 0.1223, 0.0548], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,477][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([1.5390e-04, 3.5748e-03, 1.4752e-02, 1.1773e-01, 2.5421e-02, 9.0805e-02,
        2.0472e-01, 5.6177e-02, 4.2308e-02, 1.8108e-01, 1.9558e-01, 3.5824e-02,
        3.1870e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,478][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.0323, 0.0170, 0.0070, 0.0597, 0.0189, 0.0569, 0.1051, 0.0853, 0.1180,
        0.0622, 0.1392, 0.2447, 0.0538], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,479][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0072, 0.0186, 0.0505, 0.0939, 0.0435, 0.1145, 0.1081, 0.0533, 0.1078,
        0.1421, 0.1684, 0.0453, 0.0467], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,479][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0020, 0.0093, 0.0970, 0.2186, 0.1673, 0.0813, 0.0847, 0.0342, 0.0328,
        0.0466, 0.0812, 0.0252, 0.0703, 0.0496], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,480][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0084, 0.0177, 0.0293, 0.1524, 0.0519, 0.0772, 0.1305, 0.0609, 0.0694,
        0.1066, 0.1106, 0.0485, 0.0498, 0.0869], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,480][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0982, 0.0897, 0.0825, 0.0735, 0.0570, 0.0682, 0.0763, 0.0614, 0.0552,
        0.0716, 0.0708, 0.0701, 0.0500, 0.0755], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,480][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ said] are: tensor([9.0741e-01, 1.3462e-02, 5.2803e-04, 8.9966e-03, 9.1425e-04, 2.2611e-03,
        2.7880e-02, 1.0213e-02, 2.2043e-03, 1.6849e-03, 1.1431e-02, 7.5538e-03,
        2.0766e-03, 3.3852e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,481][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0079, 0.0456, 0.0716, 0.1251, 0.1117, 0.1014, 0.1096, 0.0562, 0.0683,
        0.0679, 0.0613, 0.0374, 0.0605, 0.0755], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,482][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0045, 0.0339, 0.0316, 0.0580, 0.0688, 0.0560, 0.0933, 0.0980, 0.1122,
        0.0664, 0.0686, 0.1270, 0.0753, 0.1064], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,484][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0008, 0.0096, 0.0695, 0.1372, 0.0549, 0.0876, 0.1499, 0.0522, 0.0563,
        0.1168, 0.1016, 0.0340, 0.0436, 0.0859], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,485][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0565, 0.0550, 0.0294, 0.0520, 0.0263, 0.0573, 0.0749, 0.0539, 0.0922,
        0.0649, 0.0782, 0.1297, 0.0534, 0.1761], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,487][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0548, 0.0421, 0.0359, 0.0525, 0.0491, 0.0503, 0.0730, 0.0786, 0.0965,
        0.0906, 0.0868, 0.1027, 0.0541, 0.1331], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,488][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ said] are: tensor([1.1217e-04, 3.4181e-03, 1.8579e-02, 1.2462e-01, 1.8867e-02, 8.6461e-02,
        1.9413e-01, 4.9519e-02, 3.5613e-02, 1.7782e-01, 1.8680e-01, 3.0549e-02,
        2.1330e-02, 5.2186e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,488][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.0498, 0.0095, 0.0019, 0.0165, 0.0047, 0.0154, 0.0432, 0.0260, 0.0555,
        0.0510, 0.1624, 0.2282, 0.0307, 0.3052], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,489][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0025, 0.0092, 0.0259, 0.0793, 0.0439, 0.1328, 0.1059, 0.0695, 0.0339,
        0.1241, 0.1514, 0.0264, 0.0362, 0.1591], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,489][circuit_model.py][line:2294][INFO] ##9-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0015, 0.0078, 0.0981, 0.2245, 0.1569, 0.0848, 0.0927, 0.0356, 0.0356,
        0.0379, 0.0762, 0.0256, 0.0590, 0.0411, 0.0225], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,490][circuit_model.py][line:2297][INFO] ##9-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0165, 0.0324, 0.0329, 0.1316, 0.0480, 0.0567, 0.1087, 0.0447, 0.0582,
        0.0848, 0.0915, 0.0562, 0.0509, 0.0907, 0.0962], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,490][circuit_model.py][line:2300][INFO] ##9-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.1471, 0.1004, 0.0807, 0.0610, 0.0552, 0.0565, 0.0628, 0.0512, 0.0461,
        0.0576, 0.0557, 0.0659, 0.0474, 0.0639, 0.0485], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,491][circuit_model.py][line:2303][INFO] ##9-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.8359, 0.0250, 0.0010, 0.0259, 0.0017, 0.0071, 0.0380, 0.0237, 0.0035,
        0.0012, 0.0116, 0.0114, 0.0023, 0.0049, 0.0068], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,491][circuit_model.py][line:2306][INFO] ##9-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0113, 0.0442, 0.0712, 0.1006, 0.1073, 0.0874, 0.0972, 0.0480, 0.0634,
        0.0610, 0.0547, 0.0418, 0.0614, 0.0777, 0.0729], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,493][circuit_model.py][line:2309][INFO] ##9-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0088, 0.0328, 0.0354, 0.0563, 0.0632, 0.0542, 0.0864, 0.0839, 0.0817,
        0.0672, 0.0690, 0.1062, 0.0692, 0.0913, 0.0945], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,495][circuit_model.py][line:2312][INFO] ##9-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0012, 0.0125, 0.0787, 0.1178, 0.0477, 0.0704, 0.1231, 0.0469, 0.0575,
        0.1081, 0.0912, 0.0362, 0.0399, 0.0821, 0.0869], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,496][circuit_model.py][line:2315][INFO] ##9-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0619, 0.0639, 0.0376, 0.0517, 0.0325, 0.0572, 0.0696, 0.0507, 0.0830,
        0.0539, 0.0624, 0.1057, 0.0559, 0.1384, 0.0756], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,498][circuit_model.py][line:2318][INFO] ##9-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0554, 0.0426, 0.0305, 0.0414, 0.0389, 0.0414, 0.0567, 0.0797, 0.0909,
        0.0787, 0.0752, 0.1006, 0.0433, 0.1201, 0.1047], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,498][circuit_model.py][line:2321][INFO] ##9-th layer ##Weight##: The head10 weight for token [ to] are: tensor([1.6428e-04, 4.0267e-03, 1.9352e-02, 1.0904e-01, 1.6894e-02, 8.1210e-02,
        1.7289e-01, 4.5015e-02, 3.4697e-02, 1.5783e-01, 1.5964e-01, 2.8672e-02,
        1.9347e-02, 4.9501e-02, 1.0173e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,499][circuit_model.py][line:2324][INFO] ##9-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.0676, 0.0102, 0.0038, 0.0170, 0.0095, 0.0168, 0.0388, 0.0312, 0.0651,
        0.0365, 0.0983, 0.2012, 0.0474, 0.2539, 0.1027], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,499][circuit_model.py][line:2327][INFO] ##9-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0025, 0.0133, 0.0139, 0.0928, 0.0417, 0.1245, 0.0860, 0.0929, 0.0445,
        0.0763, 0.0968, 0.0250, 0.0343, 0.2013, 0.0542], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,556][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:19,558][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,558][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,558][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,559][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,559][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,559][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,560][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,560][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,560][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,561][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,562][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,564][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,565][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.3827, 0.6173], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,567][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1449, 0.8551], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,568][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.3756, 0.6244], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,568][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.6523, 0.3477], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,569][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0919, 0.9081], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,569][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4345, 0.5655], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,569][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0717, 0.9283], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,570][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3810, 0.6190], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,570][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.5296, 0.4704], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,570][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0484, 0.9516], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,571][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.6024, 0.3976], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,571][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0775, 0.9225], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,573][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.2115, 0.4435, 0.3450], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,575][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([0.0611, 0.2288, 0.7101], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,576][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.2343, 0.4386, 0.3271], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,577][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.2405, 0.6621, 0.0973], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,578][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.0511, 0.4716, 0.4773], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,579][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.1860, 0.3441, 0.4699], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,579][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.0137, 0.1435, 0.8427], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,579][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.1679, 0.5217, 0.3105], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,580][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.3237, 0.4516, 0.2247], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,580][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.0088, 0.0791, 0.9121], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,580][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.2574, 0.6652, 0.0774], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,581][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.0521, 0.5732, 0.3747], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,581][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2859, 0.3452, 0.2029, 0.1660], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,582][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0454, 0.1734, 0.2849, 0.4963], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,584][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.3292, 0.3091, 0.2253, 0.1364], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,585][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.5055, 0.2572, 0.0274, 0.2098], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,587][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0396, 0.3315, 0.2556, 0.3733], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,588][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.3364, 0.2280, 0.2952, 0.1404], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,589][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0071, 0.0524, 0.3371, 0.6033], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,589][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.2939, 0.3116, 0.1656, 0.2289], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,589][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.3751, 0.2611, 0.1618, 0.2021], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,590][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0021, 0.0204, 0.2453, 0.7322], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,590][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5564, 0.1890, 0.0206, 0.2341], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,590][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0322, 0.1860, 0.1379, 0.6439], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,591][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.1331, 0.2629, 0.1954, 0.2061, 0.2025], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,591][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0222, 0.0724, 0.2017, 0.4442, 0.2596], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,593][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.1271, 0.2973, 0.1705, 0.2584, 0.1467], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,594][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1650, 0.2710, 0.0440, 0.4558, 0.0642], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,596][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0237, 0.2071, 0.1951, 0.3278, 0.2463], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,597][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.1479, 0.1729, 0.2592, 0.1443, 0.2756], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,598][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0029, 0.0283, 0.2328, 0.5256, 0.2104], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,599][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0836, 0.2878, 0.1517, 0.3281, 0.1489], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,599][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.1845, 0.2470, 0.1363, 0.2334, 0.1988], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,600][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0014, 0.0108, 0.1105, 0.5837, 0.2936], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,600][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.1316, 0.2040, 0.0339, 0.5534, 0.0771], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,600][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0087, 0.1276, 0.0932, 0.5984, 0.1721], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,601][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1226, 0.1836, 0.1580, 0.1719, 0.1309, 0.2330], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,601][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0166, 0.0843, 0.1752, 0.3643, 0.1652, 0.1944], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,602][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.1144, 0.2376, 0.1895, 0.1672, 0.1427, 0.1485], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,603][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3184, 0.2389, 0.0191, 0.2312, 0.0300, 0.1623], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,605][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0145, 0.1617, 0.1325, 0.2849, 0.1673, 0.2391], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,607][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.1594, 0.1796, 0.2027, 0.1060, 0.1874, 0.1649], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,608][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0016, 0.0216, 0.2059, 0.4004, 0.1466, 0.2240], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,609][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1642, 0.1975, 0.1172, 0.2069, 0.1055, 0.2088], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,609][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.1650, 0.1948, 0.1328, 0.1609, 0.1624, 0.1841], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,610][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([3.2356e-04, 5.5453e-03, 9.9455e-02, 3.5120e-01, 1.0092e-01, 4.4256e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,610][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.2867, 0.1817, 0.0188, 0.2420, 0.0495, 0.2214], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,610][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0132, 0.1130, 0.0874, 0.4079, 0.1374, 0.2410], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,611][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1713, 0.1645, 0.1382, 0.1004, 0.0992, 0.1736, 0.1527],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,611][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0213, 0.0783, 0.1562, 0.2518, 0.1465, 0.1472, 0.1987],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,611][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.1409, 0.2008, 0.1690, 0.1216, 0.1052, 0.1257, 0.1368],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,612][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4385, 0.1667, 0.0216, 0.1094, 0.0299, 0.1065, 0.1274],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,614][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0302, 0.1793, 0.1298, 0.2086, 0.1553, 0.1729, 0.1238],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,616][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.1860, 0.1498, 0.1789, 0.0818, 0.1649, 0.1302, 0.1084],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,617][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0025, 0.0251, 0.1799, 0.2675, 0.1118, 0.1610, 0.2522],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,619][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1937, 0.1796, 0.1019, 0.1459, 0.0789, 0.1446, 0.1554],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,619][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.2079, 0.1579, 0.1156, 0.1146, 0.1269, 0.1426, 0.1345],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,620][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([3.7581e-04, 4.6408e-03, 6.0915e-02, 1.8630e-01, 5.0529e-02, 2.3973e-01,
        4.5750e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,620][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3062, 0.1197, 0.0172, 0.1411, 0.0400, 0.1296, 0.2462],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,620][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0124, 0.0896, 0.0638, 0.2796, 0.0771, 0.1644, 0.3131],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,621][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0832, 0.1112, 0.1005, 0.1065, 0.1015, 0.1812, 0.1677, 0.1481],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,621][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0170, 0.0566, 0.1060, 0.2483, 0.1103, 0.1360, 0.1956, 0.1303],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,621][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.1091, 0.1489, 0.1183, 0.1297, 0.1059, 0.1370, 0.1627, 0.0884],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,622][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.2354, 0.1260, 0.0175, 0.1368, 0.0281, 0.1361, 0.1855, 0.1344],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,624][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0115, 0.1123, 0.1039, 0.2267, 0.1151, 0.1755, 0.1471, 0.1079],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,626][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.1095, 0.1309, 0.1446, 0.0885, 0.1568, 0.1312, 0.1140, 0.1244],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,627][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0017, 0.0178, 0.1082, 0.2376, 0.0891, 0.1465, 0.2896, 0.1094],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,629][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0814, 0.1251, 0.0793, 0.1535, 0.0755, 0.1525, 0.1848, 0.1479],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,629][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.1134, 0.1181, 0.0771, 0.0951, 0.1079, 0.1318, 0.1497, 0.2069],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,630][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([2.5956e-04, 2.7294e-03, 3.8996e-02, 1.4348e-01, 3.7379e-02, 1.9809e-01,
        4.7204e-01, 1.0702e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,630][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.1438, 0.0796, 0.0135, 0.1574, 0.0370, 0.1426, 0.2796, 0.1466],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,630][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0073, 0.0514, 0.0491, 0.2565, 0.0642, 0.1311, 0.2940, 0.1463],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,631][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0806, 0.1136, 0.0886, 0.0875, 0.0828, 0.1348, 0.1318, 0.1107, 0.1696],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,631][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0100, 0.0415, 0.0930, 0.2328, 0.0925, 0.1282, 0.1868, 0.1050, 0.1102],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,632][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0910, 0.1479, 0.1091, 0.1249, 0.0908, 0.1142, 0.1410, 0.0800, 0.1011],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,633][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.2729, 0.0842, 0.0173, 0.0911, 0.0304, 0.0960, 0.1345, 0.1323, 0.1414],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,635][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0145, 0.1176, 0.0924, 0.1863, 0.1164, 0.1540, 0.1270, 0.0847, 0.1071],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,636][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.1037, 0.1101, 0.1203, 0.0786, 0.1279, 0.1161, 0.0982, 0.1063, 0.1387],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,638][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0015, 0.0145, 0.0874, 0.2224, 0.0764, 0.1398, 0.2585, 0.0992, 0.1003],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,639][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0878, 0.1202, 0.0686, 0.1206, 0.0595, 0.1264, 0.1434, 0.1097, 0.1638],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,640][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.1027, 0.1139, 0.0613, 0.0826, 0.0770, 0.1150, 0.1299, 0.1574, 0.1602],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,640][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([3.0529e-04, 2.9820e-03, 3.7209e-02, 1.2504e-01, 3.7235e-02, 1.9670e-01,
        4.2797e-01, 9.6071e-02, 7.6484e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,640][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.1066, 0.0491, 0.0125, 0.1136, 0.0320, 0.1016, 0.2087, 0.1347, 0.2412],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,641][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0054, 0.0411, 0.0329, 0.1942, 0.0535, 0.1375, 0.2822, 0.1411, 0.1120],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,641][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0680, 0.0984, 0.0902, 0.0781, 0.0560, 0.1219, 0.1267, 0.0928, 0.1370,
        0.1309], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,642][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0130, 0.0498, 0.1145, 0.1763, 0.0942, 0.0906, 0.1394, 0.0871, 0.0980,
        0.1371], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,642][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0931, 0.1448, 0.1180, 0.0980, 0.0767, 0.0965, 0.1211, 0.0629, 0.0819,
        0.1071], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,644][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.2771, 0.0590, 0.0193, 0.0660, 0.0340, 0.0600, 0.0792, 0.1271, 0.1549,
        0.1234], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,646][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0171, 0.1144, 0.0831, 0.1407, 0.0991, 0.1493, 0.1207, 0.0813, 0.0956,
        0.0988], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,647][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.1209, 0.0907, 0.1381, 0.0664, 0.1243, 0.0962, 0.0809, 0.0902, 0.1156,
        0.0767], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,649][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0018, 0.0174, 0.1157, 0.1734, 0.0757, 0.1079, 0.1831, 0.0726, 0.0867,
        0.1657], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,649][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0930, 0.1019, 0.0687, 0.0976, 0.0605, 0.1078, 0.1215, 0.0994, 0.1560,
        0.0938], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,650][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0916, 0.0877, 0.0665, 0.0699, 0.0740, 0.0926, 0.1024, 0.1327, 0.1514,
        0.1312], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,650][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([2.2739e-04, 2.2841e-03, 3.7194e-02, 1.0972e-01, 2.9455e-02, 1.3732e-01,
        3.2158e-01, 6.9243e-02, 5.9213e-02, 2.3375e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,650][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1441, 0.0334, 0.0117, 0.0639, 0.0361, 0.0609, 0.1315, 0.1151, 0.2546,
        0.1489], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,651][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0066, 0.0482, 0.0430, 0.1568, 0.0522, 0.0991, 0.1914, 0.0996, 0.0737,
        0.2294], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,651][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0809, 0.0924, 0.0760, 0.0687, 0.0499, 0.0999, 0.1029, 0.0791, 0.1244,
        0.1145, 0.1113], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,652][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0143, 0.0475, 0.0946, 0.1598, 0.0811, 0.0818, 0.1226, 0.0749, 0.0796,
        0.1187, 0.1251], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,653][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.1154, 0.1413, 0.1102, 0.0862, 0.0699, 0.0737, 0.0931, 0.0536, 0.0756,
        0.0888, 0.0921], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,654][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.3271, 0.0387, 0.0150, 0.0383, 0.0295, 0.0406, 0.0602, 0.0902, 0.1148,
        0.0843, 0.1612], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,656][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0175, 0.1040, 0.0754, 0.1342, 0.0924, 0.1320, 0.1064, 0.0735, 0.0928,
        0.0904, 0.0813], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,658][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.1404, 0.0855, 0.1259, 0.0570, 0.1093, 0.0843, 0.0743, 0.0801, 0.1081,
        0.0701, 0.0651], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,659][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0022, 0.0163, 0.0897, 0.1460, 0.0652, 0.0923, 0.1576, 0.0672, 0.0820,
        0.1486, 0.1330], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,660][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1081, 0.1056, 0.0545, 0.0862, 0.0503, 0.0861, 0.1046, 0.0837, 0.1386,
        0.0843, 0.0980], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,660][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0925, 0.0776, 0.0643, 0.0668, 0.0666, 0.0769, 0.0871, 0.1099, 0.1305,
        0.1134, 0.1144], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,660][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([2.2459e-04, 2.1327e-03, 2.8774e-02, 9.3855e-02, 2.6052e-02, 1.1741e-01,
        2.5743e-01, 5.7772e-02, 4.8782e-02, 1.9695e-01, 1.7062e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,661][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1577, 0.0187, 0.0080, 0.0361, 0.0251, 0.0350, 0.0897, 0.0782, 0.1800,
        0.0977, 0.2739], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,661][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0050, 0.0328, 0.0328, 0.1259, 0.0402, 0.0779, 0.1576, 0.0781, 0.0612,
        0.1825, 0.2060], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,662][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0528, 0.0667, 0.0593, 0.0527, 0.0522, 0.0883, 0.0992, 0.0882, 0.1234,
        0.1028, 0.0978, 0.1164], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,663][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0074, 0.0297, 0.0666, 0.1619, 0.0653, 0.0872, 0.1374, 0.0762, 0.0710,
        0.1173, 0.1230, 0.0570], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,664][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0697, 0.1097, 0.0644, 0.0844, 0.0525, 0.0963, 0.1104, 0.0674, 0.0776,
        0.0909, 0.0911, 0.0856], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,666][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.2637, 0.0433, 0.0143, 0.0429, 0.0235, 0.0462, 0.0687, 0.0721, 0.0838,
        0.0625, 0.1093, 0.1698], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,668][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0088, 0.0602, 0.0648, 0.1246, 0.0680, 0.1203, 0.1282, 0.0774, 0.0953,
        0.1011, 0.0938, 0.0575], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,669][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0717, 0.0688, 0.0841, 0.0564, 0.0964, 0.0895, 0.0837, 0.0846, 0.0989,
        0.0715, 0.0642, 0.1303], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,670][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0008, 0.0093, 0.0600, 0.1608, 0.0510, 0.0909, 0.1821, 0.0643, 0.0671,
        0.1439, 0.1317, 0.0382], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,670][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0647, 0.0703, 0.0518, 0.0842, 0.0433, 0.0864, 0.1061, 0.0750, 0.1183,
        0.0779, 0.0877, 0.1342], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,670][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0629, 0.0631, 0.0449, 0.0569, 0.0530, 0.0768, 0.0921, 0.1087, 0.1000,
        0.1093, 0.1113, 0.1211], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,671][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([1.6082e-04, 1.6925e-03, 2.0054e-02, 9.0046e-02, 2.3372e-02, 1.2015e-01,
        2.9117e-01, 5.6191e-02, 4.5252e-02, 1.7919e-01, 1.5432e-01, 1.8402e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,671][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.0803, 0.0199, 0.0078, 0.0456, 0.0197, 0.0408, 0.0905, 0.0548, 0.1029,
        0.0695, 0.1850, 0.2832], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,672][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0030, 0.0246, 0.0201, 0.1123, 0.0370, 0.0708, 0.1521, 0.0774, 0.0589,
        0.1825, 0.2045, 0.0568], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,672][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0340, 0.0597, 0.0552, 0.0532, 0.0550, 0.0946, 0.1016, 0.0807, 0.1096,
        0.0963, 0.0909, 0.1087, 0.0603], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,673][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0067, 0.0201, 0.0576, 0.1400, 0.0744, 0.0803, 0.1211, 0.0722, 0.0777,
        0.1046, 0.1098, 0.0648, 0.0707], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,675][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0339, 0.0836, 0.0486, 0.0830, 0.0438, 0.0968, 0.1149, 0.0771, 0.0863,
        0.1065, 0.0925, 0.0866, 0.0463], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,676][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0881, 0.0376, 0.0170, 0.0713, 0.0304, 0.0659, 0.0870, 0.1105, 0.1060,
        0.0519, 0.0983, 0.1727, 0.0633], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,678][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0078, 0.0615, 0.0606, 0.1129, 0.0792, 0.1108, 0.1138, 0.0778, 0.0948,
        0.0846, 0.0816, 0.0539, 0.0608], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,680][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0548, 0.0554, 0.0963, 0.0553, 0.1015, 0.0847, 0.0709, 0.0696, 0.0921,
        0.0584, 0.0528, 0.1010, 0.1072], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,680][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0007, 0.0075, 0.0528, 0.1289, 0.0508, 0.0991, 0.1929, 0.0670, 0.0687,
        0.1331, 0.1222, 0.0325, 0.0437], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,680][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0288, 0.0736, 0.0447, 0.0883, 0.0472, 0.0977, 0.1028, 0.0855, 0.1053,
        0.0665, 0.0693, 0.1281, 0.0623], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,681][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0425, 0.0567, 0.0370, 0.0592, 0.0512, 0.0797, 0.0903, 0.1004, 0.0986,
        0.1051, 0.1097, 0.1127, 0.0570], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,681][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([2.0660e-04, 1.5217e-03, 1.5900e-02, 8.1812e-02, 4.0244e-02, 1.4138e-01,
        2.7636e-01, 5.3438e-02, 4.1874e-02, 1.4929e-01, 1.4197e-01, 1.8125e-02,
        3.7875e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,682][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0323, 0.0170, 0.0070, 0.0597, 0.0189, 0.0569, 0.1051, 0.0853, 0.1180,
        0.0622, 0.1392, 0.2447, 0.0538], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,682][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0016, 0.0238, 0.0186, 0.1114, 0.0359, 0.0949, 0.1566, 0.0819, 0.0526,
        0.1609, 0.1840, 0.0425, 0.0352], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,683][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0520, 0.0566, 0.0562, 0.0519, 0.0464, 0.0664, 0.0719, 0.0546, 0.0994,
        0.0883, 0.0955, 0.0999, 0.0568, 0.1040], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,685][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0067, 0.0271, 0.0599, 0.1328, 0.0661, 0.0798, 0.1083, 0.0698, 0.0673,
        0.1028, 0.0972, 0.0552, 0.0587, 0.0681], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,687][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0632, 0.0875, 0.0729, 0.0672, 0.0522, 0.0683, 0.0833, 0.0511, 0.0686,
        0.0796, 0.0821, 0.0756, 0.0560, 0.0923], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,688][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.1829, 0.0244, 0.0047, 0.0223, 0.0081, 0.0248, 0.0433, 0.0383, 0.0570,
        0.0627, 0.1373, 0.1811, 0.0425, 0.1705], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,690][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0089, 0.0775, 0.0567, 0.1203, 0.0774, 0.1129, 0.0924, 0.0608, 0.0698,
        0.0716, 0.0659, 0.0405, 0.0548, 0.0904], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,690][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0722, 0.0590, 0.0780, 0.0393, 0.0817, 0.0608, 0.0531, 0.0593, 0.0828,
        0.0532, 0.0478, 0.1034, 0.0974, 0.1120], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,691][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0008, 0.0096, 0.0695, 0.1372, 0.0549, 0.0876, 0.1499, 0.0522, 0.0563,
        0.1168, 0.1016, 0.0340, 0.0436, 0.0859], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,691][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0565, 0.0550, 0.0294, 0.0520, 0.0263, 0.0573, 0.0749, 0.0539, 0.0922,
        0.0649, 0.0782, 0.1297, 0.0534, 0.1761], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,691][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0611, 0.0533, 0.0445, 0.0605, 0.0506, 0.0614, 0.0744, 0.0773, 0.0912,
        0.0860, 0.0858, 0.0947, 0.0534, 0.1058], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,692][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([1.5663e-04, 1.5817e-03, 2.3197e-02, 8.4721e-02, 2.8031e-02, 1.1807e-01,
        2.4878e-01, 5.1002e-02, 3.8747e-02, 1.6643e-01, 1.4527e-01, 1.7574e-02,
        2.7502e-02, 4.8938e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,692][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.0498, 0.0095, 0.0019, 0.0165, 0.0047, 0.0154, 0.0432, 0.0260, 0.0555,
        0.0510, 0.1624, 0.2282, 0.0307, 0.3052], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,693][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0025, 0.0244, 0.0211, 0.1008, 0.0352, 0.0748, 0.1399, 0.0745, 0.0525,
        0.1598, 0.1679, 0.0480, 0.0354, 0.0633], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,695][circuit_model.py][line:2332][INFO] ##9-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0535, 0.0656, 0.0626, 0.0489, 0.0415, 0.0674, 0.0695, 0.0519, 0.0850,
        0.0771, 0.0732, 0.0897, 0.0461, 0.0903, 0.0778], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,697][circuit_model.py][line:2335][INFO] ##9-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0126, 0.0395, 0.0661, 0.1133, 0.0619, 0.0627, 0.0928, 0.0551, 0.0601,
        0.0858, 0.0836, 0.0609, 0.0592, 0.0685, 0.0780], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,698][circuit_model.py][line:2338][INFO] ##9-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0727, 0.1085, 0.0759, 0.0613, 0.0516, 0.0596, 0.0708, 0.0420, 0.0581,
        0.0667, 0.0671, 0.0716, 0.0513, 0.0802, 0.0626], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,700][circuit_model.py][line:2341][INFO] ##9-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.1784, 0.0265, 0.0095, 0.0235, 0.0162, 0.0286, 0.0399, 0.0466, 0.0612,
        0.0446, 0.0845, 0.1577, 0.0611, 0.1330, 0.0889], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,700][circuit_model.py][line:2344][INFO] ##9-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0132, 0.0715, 0.0584, 0.0981, 0.0734, 0.0946, 0.0823, 0.0507, 0.0656,
        0.0645, 0.0601, 0.0466, 0.0558, 0.0931, 0.0721], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,701][circuit_model.py][line:2347][INFO] ##9-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0822, 0.0562, 0.0902, 0.0382, 0.0778, 0.0569, 0.0487, 0.0527, 0.0727,
        0.0463, 0.0418, 0.0881, 0.0863, 0.0917, 0.0702], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,701][circuit_model.py][line:2350][INFO] ##9-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0012, 0.0125, 0.0787, 0.1178, 0.0477, 0.0704, 0.1231, 0.0469, 0.0575,
        0.1081, 0.0912, 0.0362, 0.0399, 0.0821, 0.0869], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,702][circuit_model.py][line:2353][INFO] ##9-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0619, 0.0639, 0.0376, 0.0517, 0.0325, 0.0572, 0.0696, 0.0507, 0.0830,
        0.0539, 0.0624, 0.1057, 0.0559, 0.1384, 0.0756], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,702][circuit_model.py][line:2356][INFO] ##9-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0634, 0.0545, 0.0389, 0.0512, 0.0419, 0.0518, 0.0603, 0.0783, 0.0869,
        0.0770, 0.0770, 0.0929, 0.0452, 0.0967, 0.0842], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,702][circuit_model.py][line:2359][INFO] ##9-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0002, 0.0022, 0.0259, 0.0793, 0.0239, 0.1061, 0.2167, 0.0446, 0.0380,
        0.1553, 0.1311, 0.0165, 0.0239, 0.0456, 0.0908], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,704][circuit_model.py][line:2362][INFO] ##9-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.0676, 0.0102, 0.0038, 0.0170, 0.0095, 0.0168, 0.0388, 0.0312, 0.0651,
        0.0365, 0.0983, 0.2012, 0.0474, 0.2539, 0.1027], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,706][circuit_model.py][line:2365][INFO] ##9-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0034, 0.0307, 0.0230, 0.0962, 0.0296, 0.0597, 0.1158, 0.0586, 0.0472,
        0.1465, 0.1515, 0.0468, 0.0283, 0.0536, 0.1091], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,707][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:19,709][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[6359],
        [ 155],
        [6287],
        [  32],
        [ 105],
        [ 104],
        [  24],
        [  29],
        [  77],
        [  60],
        [  33],
        [  18],
        [  31],
        [  53],
        [  32]], device='cuda:0')
[2024-07-24 10:20:19,710][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2265],
        [ 395],
        [6375],
        [ 122],
        [ 288],
        [ 322],
        [ 142],
        [ 309],
        [ 458],
        [ 222],
        [ 151],
        [  93],
        [ 121],
        [ 254],
        [ 172]], device='cuda:0')
[2024-07-24 10:20:19,711][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[13830],
        [14393],
        [  108],
        [  532],
        [  512],
        [  486],
        [  461],
        [  429],
        [  436],
        [  381],
        [  363],
        [  457],
        [  401],
        [  343],
        [  361]], device='cuda:0')
[2024-07-24 10:20:19,712][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[27181],
        [22726],
        [ 6774],
        [ 5133],
        [ 4637],
        [ 3966],
        [ 3831],
        [ 3466],
        [ 3654],
        [ 3740],
        [ 4037],
        [ 4043],
        [ 4036],
        [ 4181],
        [ 4863]], device='cuda:0')
[2024-07-24 10:20:19,714][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[26328],
        [19726],
        [43450],
        [38784],
        [40492],
        [41446],
        [41210],
        [39348],
        [38665],
        [39312],
        [39592],
        [37284],
        [38211],
        [38729],
        [38484]], device='cuda:0')
[2024-07-24 10:20:19,715][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[34159],
        [33983],
        [33146],
        [33997],
        [28075],
        [33845],
        [33897],
        [33356],
        [32170],
        [30995],
        [32902],
        [26252],
        [15611],
        [31690],
        [29538]], device='cuda:0')
[2024-07-24 10:20:19,717][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[ 6867],
        [39759],
        [33671],
        [35387],
        [31876],
        [31191],
        [31108],
        [30097],
        [30836],
        [30123],
        [30274],
        [30040],
        [29721],
        [30157],
        [30901]], device='cuda:0')
[2024-07-24 10:20:19,718][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[42430],
        [ 2041],
        [ 1253],
        [ 2353],
        [ 2379],
        [ 2494],
        [ 2237],
        [ 2479],
        [ 2518],
        [ 2737],
        [ 3203],
        [ 2702],
        [ 2752],
        [ 3034],
        [ 3099]], device='cuda:0')
[2024-07-24 10:20:19,720][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[29176],
        [17868],
        [50257],
        [43214],
        [36510],
        [34012],
        [33705],
        [24243],
        [22158],
        [26323],
        [24870],
        [21006],
        [20667],
        [23355],
        [25435]], device='cuda:0')
[2024-07-24 10:20:19,721][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[5415],
        [ 174],
        [ 115],
        [ 103],
        [ 148],
        [ 171],
        [ 150],
        [ 193],
        [ 226],
        [ 182],
        [ 111],
        [ 141],
        [ 147],
        [ 101],
        [ 106]], device='cuda:0')
[2024-07-24 10:20:19,722][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[25770],
        [ 4711],
        [26774],
        [30066],
        [34055],
        [32379],
        [31986],
        [22217],
        [20872],
        [20477],
        [22197],
        [18405],
        [18940],
        [20512],
        [20563]], device='cuda:0')
[2024-07-24 10:20:19,723][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[ 4735],
        [38546],
        [50257],
        [49626],
        [49138],
        [48828],
        [47290],
        [46638],
        [46516],
        [46815],
        [46794],
        [46515],
        [46558],
        [46989],
        [47301]], device='cuda:0')
[2024-07-24 10:20:19,725][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[19429],
        [21656],
        [23807],
        [26288],
        [30170],
        [27994],
        [27815],
        [28207],
        [30286],
        [30087],
        [27920],
        [28077],
        [29013],
        [29801],
        [30982]], device='cuda:0')
[2024-07-24 10:20:19,726][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[24335],
        [ 4544],
        [  106],
        [  987],
        [  520],
        [ 2045],
        [ 1521],
        [ 1708],
        [ 1408],
        [ 2164],
        [ 2021],
        [ 1202],
        [ 1374],
        [ 1853],
        [ 1997]], device='cuda:0')
[2024-07-24 10:20:19,728][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[36266],
        [ 8962],
        [17685],
        [ 4440],
        [ 5537],
        [ 6185],
        [ 2819],
        [ 1433],
        [ 3619],
        [ 7612],
        [ 5675],
        [ 5696],
        [ 9825],
        [ 9376],
        [ 4692]], device='cuda:0')
[2024-07-24 10:20:19,729][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[25986],
        [  990],
        [ 2081],
        [ 3640],
        [ 6364],
        [ 3507],
        [ 2714],
        [ 3366],
        [ 3282],
        [ 3988],
        [ 4306],
        [ 4051],
        [ 4432],
        [ 4723],
        [ 4896]], device='cuda:0')
[2024-07-24 10:20:19,731][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[12479],
        [43989],
        [49168],
        [49155],
        [49029],
        [48721],
        [48943],
        [48347],
        [48443],
        [48551],
        [48246],
        [47572],
        [47630],
        [47275],
        [47281]], device='cuda:0')
[2024-07-24 10:20:19,733][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[ 7333],
        [19945],
        [ 9285],
        [12390],
        [11222],
        [10548],
        [11855],
        [14673],
        [15119],
        [16223],
        [17539],
        [19764],
        [19661],
        [16579],
        [16628]], device='cuda:0')
[2024-07-24 10:20:19,734][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[1029],
        [1667],
        [3987],
        [3305],
        [6980],
        [4106],
        [2836],
        [3498],
        [3232],
        [3259],
        [3219],
        [3368],
        [3929],
        [3736],
        [3970]], device='cuda:0')
[2024-07-24 10:20:19,735][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[1048],
        [3565],
        [3103],
        [5468],
        [4146],
        [3227],
        [3001],
        [3659],
        [3460],
        [3870],
        [4168],
        [4528],
        [4029],
        [4129],
        [4043]], device='cuda:0')
[2024-07-24 10:20:19,737][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 5399],
        [23053],
        [24949],
        [21066],
        [19946],
        [18467],
        [17976],
        [14108],
        [12562],
        [12979],
        [12725],
        [10404],
        [11496],
        [11634],
        [11309]], device='cuda:0')
[2024-07-24 10:20:19,738][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[31375],
        [14516],
        [17411],
        [ 2923],
        [ 3862],
        [ 2427],
        [ 2897],
        [ 2576],
        [ 2609],
        [ 3533],
        [ 3609],
        [ 3354],
        [ 3595],
        [ 3332],
        [ 3616]], device='cuda:0')
[2024-07-24 10:20:19,739][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[ 1203],
        [14938],
        [ 9395],
        [10933],
        [ 8808],
        [10307],
        [12144],
        [14834],
        [16427],
        [17238],
        [18791],
        [20258],
        [19053],
        [17257],
        [16922]], device='cuda:0')
[2024-07-24 10:20:19,740][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[ 9532],
        [ 4425],
        [ 8718],
        [10653],
        [11946],
        [10620],
        [ 9088],
        [ 9462],
        [ 9217],
        [ 8905],
        [ 9232],
        [ 9069],
        [ 9026],
        [ 9552],
        [10303]], device='cuda:0')
[2024-07-24 10:20:19,741][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[ 2214],
        [23913],
        [20177],
        [12612],
        [13199],
        [21091],
        [20863],
        [20583],
        [20346],
        [17875],
        [16092],
        [15590],
        [16460],
        [16192],
        [15250]], device='cuda:0')
[2024-07-24 10:20:19,742][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[11960],
        [13062],
        [13671],
        [ 7329],
        [10708],
        [ 8941],
        [ 9679],
        [12293],
        [12925],
        [13009],
        [13936],
        [11692],
        [12102],
        [10353],
        [10336]], device='cuda:0')
[2024-07-24 10:20:19,744][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[1767],
        [ 582],
        [ 345],
        [ 254],
        [ 306],
        [ 301],
        [ 398],
        [ 487],
        [ 594],
        [ 628],
        [ 728],
        [ 773],
        [ 722],
        [ 741],
        [ 742]], device='cuda:0')
[2024-07-24 10:20:19,746][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[50050],
        [48381],
        [48103],
        [48454],
        [47380],
        [48874],
        [48995],
        [48826],
        [48864],
        [48515],
        [48275],
        [48808],
        [48511],
        [48823],
        [48744]], device='cuda:0')
[2024-07-24 10:20:19,747][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[23342],
        [49257],
        [43856],
        [49429],
        [49330],
        [49133],
        [49535],
        [49722],
        [49231],
        [49506],
        [49240],
        [48052],
        [48133],
        [47079],
        [49019]], device='cuda:0')
[2024-07-24 10:20:19,748][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442],
        [8442]], device='cuda:0')
[2024-07-24 10:20:19,798][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:19,798][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,799][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,799][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,799][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,800][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,800][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,800][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,801][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,803][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,804][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,805][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,806][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:19,808][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.2680, 0.7320], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,808][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.1159, 0.8841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,808][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.2510, 0.7490], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,809][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.4100, 0.5900], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,809][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.1430, 0.8570], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,809][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.5032, 0.4968], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,810][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.1494, 0.8506], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,810][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.3560, 0.6440], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,810][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.4035, 0.5965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,811][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.5196, 0.4804], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,820][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.8940, 0.1060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,820][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.2640, 0.7360], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:19,821][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.1633, 0.4736, 0.3631], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,823][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.0289, 0.0947, 0.8764], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,824][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.0753, 0.2947, 0.6301], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,826][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.1504, 0.2888, 0.5607], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,827][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.1153, 0.6955, 0.1891], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,828][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.0647, 0.9264, 0.0089], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,828][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.0780, 0.3797, 0.5423], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,829][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.1349, 0.2104, 0.6547], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,829][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.1739, 0.2538, 0.5722], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,829][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.0487, 0.9397, 0.0116], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,830][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.1726, 0.0341, 0.7933], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,830][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.0691, 0.4105, 0.5204], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:19,830][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.1150, 0.2783, 0.1471, 0.4596], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,831][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0063, 0.0268, 0.2254, 0.7416], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,832][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0308, 0.0721, 0.2473, 0.6498], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,833][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1241, 0.1857, 0.4153, 0.2749], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,835][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0848, 0.3868, 0.0668, 0.4615], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,836][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.4777, 0.4128, 0.0025, 0.1070], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,838][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0447, 0.1599, 0.1706, 0.6248], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,838][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.1223, 0.1424, 0.5624, 0.1729], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,839][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0878, 0.1973, 0.3467, 0.3682], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,839][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.2753, 0.3651, 0.0027, 0.3569], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,839][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1659, 0.0257, 0.8017, 0.0067], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,840][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0413, 0.1316, 0.2206, 0.6066], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:19,840][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0544, 0.1763, 0.1233, 0.3664, 0.2796], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,840][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0042, 0.0163, 0.1884, 0.3611, 0.4300], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,841][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0142, 0.0515, 0.1567, 0.5000, 0.2776], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,842][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0657, 0.1141, 0.2515, 0.2627, 0.3060], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,843][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0414, 0.2358, 0.0487, 0.6049, 0.0692], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,845][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0787, 0.5087, 0.0060, 0.3977, 0.0088], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,847][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0170, 0.0736, 0.1251, 0.4465, 0.3379], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,848][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0575, 0.0847, 0.2780, 0.1138, 0.4660], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,848][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0803, 0.1390, 0.2562, 0.2327, 0.2918], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,849][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0238, 0.3246, 0.0051, 0.6350, 0.0115], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,849][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.2005, 0.0196, 0.6799, 0.0053, 0.0946], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,849][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0145, 0.0713, 0.0705, 0.7535, 0.0902], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:19,850][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.0362, 0.1222, 0.1344, 0.2167, 0.2217, 0.2688], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,850][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.0026, 0.0144, 0.1593, 0.3126, 0.1897, 0.3214], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,851][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0096, 0.0364, 0.1403, 0.3715, 0.2402, 0.2021], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,851][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.0562, 0.0977, 0.2242, 0.1594, 0.2277, 0.2347], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,853][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0582, 0.2547, 0.0607, 0.3786, 0.0690, 0.1788], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,855][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.3838, 0.3745, 0.0021, 0.0953, 0.0034, 0.1408], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,856][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0180, 0.0707, 0.1248, 0.3074, 0.1882, 0.2909], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,858][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.0504, 0.0834, 0.3324, 0.1173, 0.3121, 0.1043], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,858][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0823, 0.1480, 0.2533, 0.2119, 0.2142, 0.0902], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,859][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.1475, 0.2884, 0.0020, 0.3507, 0.0038, 0.2076], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,859][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ had] are: tensor([0.1342, 0.0208, 0.7636, 0.0072, 0.0692, 0.0050], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,859][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0159, 0.0740, 0.0933, 0.4014, 0.0610, 0.3544], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:19,860][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.0370, 0.0886, 0.0801, 0.1174, 0.1196, 0.1430, 0.4143],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,860][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.0025, 0.0095, 0.1004, 0.1674, 0.0810, 0.1213, 0.5178],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,861][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0120, 0.0360, 0.1237, 0.2051, 0.1532, 0.1088, 0.3612],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,861][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.0748, 0.0925, 0.2147, 0.0984, 0.1762, 0.1515, 0.1920],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,862][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0644, 0.2569, 0.0495, 0.3127, 0.0473, 0.1410, 0.1282],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,864][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.5017, 0.2344, 0.0029, 0.0531, 0.0041, 0.1003, 0.1036],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,865][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0220, 0.0712, 0.0945, 0.1714, 0.1309, 0.1773, 0.3328],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,867][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.0707, 0.1073, 0.3366, 0.1045, 0.2202, 0.0771, 0.0837],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,868][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0848, 0.1385, 0.2376, 0.1825, 0.1409, 0.0573, 0.1584],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,869][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.2057, 0.1768, 0.0031, 0.1704, 0.0056, 0.1320, 0.3064],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,869][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ a] are: tensor([0.1530, 0.0182, 0.7693, 0.0035, 0.0458, 0.0026, 0.0076],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,869][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0236, 0.0629, 0.0651, 0.2252, 0.0382, 0.1984, 0.3867],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:19,870][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.0228, 0.0508, 0.0525, 0.0923, 0.1053, 0.1159, 0.3533, 0.2071],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,870][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.0026, 0.0068, 0.0763, 0.1227, 0.0742, 0.1116, 0.5676, 0.0381],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,871][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0066, 0.0213, 0.0676, 0.1784, 0.1085, 0.0955, 0.3839, 0.1382],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,871][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.0727, 0.0583, 0.1248, 0.0792, 0.1364, 0.1431, 0.2442, 0.1413],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,872][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0405, 0.2123, 0.0431, 0.2553, 0.0447, 0.1453, 0.1378, 0.1210],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,874][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.3043, 0.2275, 0.0026, 0.0829, 0.0056, 0.1460, 0.1520, 0.0791],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,875][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0116, 0.0366, 0.0559, 0.1088, 0.1008, 0.1670, 0.4078, 0.1115],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,877][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.0661, 0.0864, 0.2661, 0.1136, 0.2114, 0.0936, 0.1073, 0.0553],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,878][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0661, 0.0960, 0.1695, 0.1598, 0.1427, 0.0551, 0.1968, 0.1139],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,879][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0619, 0.1016, 0.0018, 0.1990, 0.0054, 0.1399, 0.3881, 0.1023],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,879][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ long] are: tensor([0.1209, 0.0171, 0.7534, 0.0059, 0.0689, 0.0054, 0.0168, 0.0116],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,880][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0093, 0.0294, 0.0307, 0.1487, 0.0204, 0.1996, 0.4685, 0.0934],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:19,880][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.0244, 0.0491, 0.0459, 0.0654, 0.0834, 0.0960, 0.2845, 0.1650, 0.1863],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,880][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.0021, 0.0050, 0.0583, 0.1283, 0.0686, 0.1149, 0.5081, 0.0303, 0.0844],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,881][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0078, 0.0216, 0.0608, 0.1480, 0.0951, 0.0887, 0.3382, 0.1162, 0.1235],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,881][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.0536, 0.0478, 0.0934, 0.0692, 0.1225, 0.1255, 0.2033, 0.1177, 0.1670],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,882][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0478, 0.1563, 0.0336, 0.2259, 0.0362, 0.1313, 0.1551, 0.1098, 0.1040],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,883][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.3437, 0.1339, 0.0026, 0.0566, 0.0057, 0.0974, 0.1319, 0.0637, 0.1644],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,885][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0162, 0.0443, 0.0598, 0.1063, 0.1068, 0.1520, 0.3498, 0.0910, 0.0738],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,887][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.0616, 0.0864, 0.2081, 0.0926, 0.2351, 0.0863, 0.0887, 0.0459, 0.0952],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,888][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0456, 0.0689, 0.1279, 0.1312, 0.1170, 0.0546, 0.1799, 0.0863, 0.1886],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,889][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0751, 0.0593, 0.0022, 0.1257, 0.0059, 0.0916, 0.2833, 0.1008, 0.2563],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,889][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([0.1625, 0.0158, 0.7077, 0.0049, 0.0604, 0.0048, 0.0158, 0.0087, 0.0194],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,890][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0102, 0.0299, 0.0402, 0.1289, 0.0305, 0.1749, 0.3848, 0.0907, 0.1100],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:19,890][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.0134, 0.0319, 0.0415, 0.0598, 0.0550, 0.0708, 0.2162, 0.1113, 0.1208,
        0.2793], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,890][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.0012, 0.0037, 0.0619, 0.1034, 0.0463, 0.0796, 0.4143, 0.0250, 0.0613,
        0.2034], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,891][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0051, 0.0132, 0.0587, 0.1235, 0.0746, 0.0644, 0.2669, 0.0806, 0.0880,
        0.2249], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,891][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.0425, 0.0376, 0.1213, 0.0569, 0.1207, 0.1040, 0.1544, 0.0873, 0.1400,
        0.1353], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,892][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0336, 0.1346, 0.0365, 0.1992, 0.0393, 0.1093, 0.1362, 0.0931, 0.0892,
        0.1291], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,894][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.4587, 0.0812, 0.0026, 0.0315, 0.0068, 0.0441, 0.0568, 0.0517, 0.1716,
        0.0949], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,895][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0104, 0.0349, 0.0564, 0.1219, 0.0716, 0.1206, 0.2829, 0.0611, 0.0506,
        0.1896], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,897][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0374, 0.0638, 0.2620, 0.0884, 0.1724, 0.0641, 0.0797, 0.0362, 0.0728,
        0.1233], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,898][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0292, 0.0508, 0.0914, 0.0918, 0.0630, 0.0264, 0.0984, 0.0412, 0.0936,
        0.4142], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,899][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1259, 0.0419, 0.0026, 0.0748, 0.0089, 0.0424, 0.1213, 0.0934, 0.2804,
        0.2084], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,900][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.1069, 0.0124, 0.7956, 0.0031, 0.0473, 0.0029, 0.0098, 0.0056, 0.0129,
        0.0037], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,900][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0057, 0.0239, 0.0441, 0.1453, 0.0245, 0.1156, 0.2563, 0.0534, 0.0846,
        0.2466], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:19,900][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.0135, 0.0256, 0.0260, 0.0461, 0.0403, 0.0519, 0.1564, 0.0848, 0.0999,
        0.2258, 0.2298], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,901][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.0014, 0.0041, 0.0465, 0.0962, 0.0397, 0.0642, 0.3086, 0.0233, 0.0561,
        0.1861, 0.1738], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,901][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0061, 0.0135, 0.0492, 0.0986, 0.0676, 0.0559, 0.2145, 0.0694, 0.0764,
        0.1718, 0.1772], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,902][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.0508, 0.0446, 0.1065, 0.0548, 0.0990, 0.0852, 0.1220, 0.0785, 0.1262,
        0.1159, 0.1165], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,902][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0375, 0.1419, 0.0349, 0.1636, 0.0392, 0.0916, 0.1085, 0.0768, 0.0840,
        0.1139, 0.1081], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,904][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.5147, 0.0368, 0.0017, 0.0139, 0.0049, 0.0202, 0.0310, 0.0293, 0.0977,
        0.0473, 0.2024], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,906][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0114, 0.0347, 0.0435, 0.1059, 0.0595, 0.0933, 0.2067, 0.0532, 0.0455,
        0.1651, 0.1812], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,907][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0420, 0.0655, 0.2348, 0.0860, 0.1521, 0.0549, 0.0659, 0.0357, 0.0700,
        0.1102, 0.0830], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,909][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0224, 0.0365, 0.0637, 0.0827, 0.0431, 0.0230, 0.0766, 0.0320, 0.0799,
        0.2962, 0.2438], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,909][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.1550, 0.0152, 0.0012, 0.0233, 0.0048, 0.0134, 0.0477, 0.0363, 0.1252,
        0.0741, 0.5039], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,910][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.1407, 0.0163, 0.7436, 0.0038, 0.0500, 0.0033, 0.0103, 0.0062, 0.0148,
        0.0043, 0.0066], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,910][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0057, 0.0213, 0.0371, 0.1125, 0.0232, 0.0882, 0.2007, 0.0452, 0.0704,
        0.1968, 0.1990], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:19,911][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.0107, 0.0269, 0.0269, 0.0394, 0.0437, 0.0680, 0.1792, 0.1037, 0.1002,
        0.1744, 0.1516, 0.0751], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,911][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.0012, 0.0037, 0.0500, 0.1020, 0.0532, 0.0929, 0.3354, 0.0260, 0.0555,
        0.1378, 0.1256, 0.0167], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,911][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([0.0036, 0.0112, 0.0379, 0.0848, 0.0605, 0.0560, 0.2510, 0.0691, 0.0640,
        0.1470, 0.1679, 0.0470], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,912][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0328, 0.0321, 0.0953, 0.0673, 0.0813, 0.0835, 0.1104, 0.0835, 0.1057,
        0.1152, 0.1104, 0.0825], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,913][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0419, 0.1201, 0.0291, 0.1521, 0.0332, 0.0858, 0.1064, 0.0742, 0.0735,
        0.1032, 0.1000, 0.0805], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,915][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.2932, 0.0629, 0.0032, 0.0263, 0.0061, 0.0437, 0.0593, 0.0307, 0.0789,
        0.0456, 0.1494, 0.2007], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,916][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0075, 0.0218, 0.0456, 0.0716, 0.0708, 0.1048, 0.2373, 0.0645, 0.0433,
        0.1296, 0.1364, 0.0667], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,918][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0492, 0.0636, 0.1724, 0.0747, 0.1695, 0.0611, 0.0738, 0.0329, 0.0755,
        0.1065, 0.0802, 0.0405], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,919][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0270, 0.0310, 0.0534, 0.0680, 0.0567, 0.0314, 0.0970, 0.0470, 0.0805,
        0.2188, 0.2065, 0.0828], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,920][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0751, 0.0167, 0.0020, 0.0306, 0.0053, 0.0225, 0.0726, 0.0250, 0.0764,
        0.0522, 0.2814, 0.3403], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,920][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([0.1320, 0.0166, 0.7294, 0.0044, 0.0528, 0.0043, 0.0140, 0.0087, 0.0175,
        0.0042, 0.0065, 0.0096], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,921][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0043, 0.0201, 0.0327, 0.0951, 0.0243, 0.0915, 0.2140, 0.0472, 0.0527,
        0.1792, 0.1679, 0.0709], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:19,921][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0055, 0.0152, 0.0152, 0.0290, 0.0320, 0.0526, 0.1663, 0.0957, 0.0999,
        0.1685, 0.1746, 0.0787, 0.0667], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,921][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.0005, 0.0019, 0.0282, 0.0528, 0.0536, 0.0955, 0.4241, 0.0244, 0.0518,
        0.1187, 0.1029, 0.0115, 0.0341], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,922][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0032, 0.0103, 0.0312, 0.0773, 0.0601, 0.0560, 0.2613, 0.0692, 0.0641,
        0.1216, 0.1558, 0.0355, 0.0545], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,923][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0168, 0.0231, 0.0548, 0.0496, 0.0721, 0.0736, 0.1468, 0.0868, 0.1050,
        0.1079, 0.1113, 0.0811, 0.0713], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,924][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0199, 0.0821, 0.0187, 0.1727, 0.0277, 0.0960, 0.1210, 0.0783, 0.0847,
        0.0989, 0.0901, 0.0745, 0.0355], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,926][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0937, 0.0785, 0.0035, 0.0773, 0.0088, 0.0880, 0.0913, 0.0740, 0.1190,
        0.0408, 0.1316, 0.1753, 0.0182], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,928][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0029, 0.0118, 0.0231, 0.0667, 0.0539, 0.0971, 0.2854, 0.0600, 0.0427,
        0.1264, 0.1385, 0.0480, 0.0433], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,929][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0291, 0.0414, 0.1317, 0.0559, 0.2336, 0.0497, 0.0703, 0.0307, 0.0632,
        0.0869, 0.0617, 0.0257, 0.1200], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,930][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([0.0191, 0.0293, 0.0461, 0.0567, 0.0613, 0.0364, 0.1012, 0.0395, 0.0722,
        0.1960, 0.1780, 0.0703, 0.0939], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,930][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0204, 0.0276, 0.0027, 0.0712, 0.0087, 0.0581, 0.0925, 0.0705, 0.1360,
        0.0317, 0.1417, 0.3117, 0.0272], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,930][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.1761, 0.0150, 0.6014, 0.0036, 0.0785, 0.0053, 0.0188, 0.0108, 0.0208,
        0.0045, 0.0080, 0.0116, 0.0457], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,931][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0019, 0.0081, 0.0112, 0.0979, 0.0158, 0.0868, 0.2669, 0.0650, 0.0587,
        0.1560, 0.1630, 0.0494, 0.0194], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:19,931][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.0097, 0.0191, 0.0260, 0.0381, 0.0404, 0.0444, 0.1301, 0.0660, 0.0766,
        0.1574, 0.1500, 0.0711, 0.0771, 0.0941], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,932][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.0010, 0.0032, 0.0382, 0.0701, 0.0529, 0.0782, 0.3179, 0.0217, 0.0490,
        0.1333, 0.1173, 0.0158, 0.0355, 0.0659], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,932][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ said] are: tensor([0.0045, 0.0105, 0.0373, 0.0812, 0.0644, 0.0495, 0.2075, 0.0602, 0.0583,
        0.1301, 0.1457, 0.0389, 0.0572, 0.0548], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,934][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.0197, 0.0222, 0.0694, 0.0470, 0.0668, 0.0654, 0.1015, 0.0701, 0.0906,
        0.1035, 0.0985, 0.0892, 0.0648, 0.0913], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,936][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0407, 0.0875, 0.0198, 0.1169, 0.0256, 0.0696, 0.0944, 0.0735, 0.0764,
        0.0956, 0.0997, 0.0789, 0.0444, 0.0769], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,937][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.2379, 0.0233, 0.0004, 0.0065, 0.0008, 0.0128, 0.0244, 0.0105, 0.0348,
        0.0370, 0.1856, 0.1673, 0.0082, 0.2505], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,939][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0057, 0.0159, 0.0309, 0.0647, 0.0566, 0.0839, 0.2099, 0.0409, 0.0362,
        0.1226, 0.1352, 0.0607, 0.0548, 0.0820], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,940][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0300, 0.0361, 0.1495, 0.0544, 0.1622, 0.0451, 0.0583, 0.0284, 0.0665,
        0.1066, 0.0757, 0.0252, 0.0941, 0.0680], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,940][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0224, 0.0336, 0.0563, 0.0716, 0.0562, 0.0263, 0.0761, 0.0300, 0.0637,
        0.2032, 0.1635, 0.0688, 0.0804, 0.0478], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,940][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ said] are: tensor([3.8452e-02, 4.5336e-03, 1.2855e-04, 5.3680e-03, 3.3371e-04, 3.6538e-03,
        1.8355e-02, 5.3904e-03, 2.5166e-02, 3.2769e-02, 2.8038e-01, 2.1506e-01,
        7.3822e-03, 3.6302e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,941][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ said] are: tensor([0.1328, 0.0126, 0.6723, 0.0036, 0.0670, 0.0037, 0.0136, 0.0068, 0.0156,
        0.0044, 0.0065, 0.0095, 0.0362, 0.0154], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,941][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0036, 0.0154, 0.0192, 0.0810, 0.0218, 0.0854, 0.1811, 0.0475, 0.0607,
        0.1761, 0.1663, 0.0532, 0.0266, 0.0620], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:19,942][circuit_model.py][line:2294][INFO] ##10-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.0078, 0.0191, 0.0214, 0.0312, 0.0281, 0.0327, 0.1004, 0.0542, 0.0673,
        0.1450, 0.1322, 0.0581, 0.0572, 0.0760, 0.1693], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,942][circuit_model.py][line:2297][INFO] ##10-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.0009, 0.0039, 0.0451, 0.0724, 0.0348, 0.0578, 0.2571, 0.0166, 0.0437,
        0.1475, 0.1229, 0.0136, 0.0235, 0.0496, 0.1105], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,944][circuit_model.py][line:2300][INFO] ##10-th layer ##Weight##: The head3 weight for token [ to] are: tensor([0.0044, 0.0115, 0.0420, 0.0669, 0.0535, 0.0373, 0.1633, 0.0495, 0.0592,
        0.1244, 0.1233, 0.0433, 0.0531, 0.0501, 0.1182], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,946][circuit_model.py][line:2303][INFO] ##10-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.0337, 0.0323, 0.0892, 0.0381, 0.0664, 0.0532, 0.0779, 0.0500, 0.0788,
        0.0842, 0.0785, 0.0904, 0.0616, 0.0822, 0.0833], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,947][circuit_model.py][line:2306][INFO] ##10-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0280, 0.1097, 0.0212, 0.1333, 0.0223, 0.0653, 0.0792, 0.0513, 0.0586,
        0.0878, 0.0862, 0.0673, 0.0324, 0.0637, 0.0937], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,949][circuit_model.py][line:2309][INFO] ##10-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.2319, 0.0239, 0.0012, 0.0085, 0.0026, 0.0141, 0.0205, 0.0168, 0.0512,
        0.0284, 0.1166, 0.1817, 0.0186, 0.1943, 0.0896], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,950][circuit_model.py][line:2312][INFO] ##10-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0073, 0.0224, 0.0316, 0.0618, 0.0434, 0.0653, 0.1626, 0.0362, 0.0340,
        0.1201, 0.1286, 0.0573, 0.0432, 0.0665, 0.1195], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,950][circuit_model.py][line:2315][INFO] ##10-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0321, 0.0502, 0.1843, 0.0535, 0.1386, 0.0384, 0.0472, 0.0234, 0.0566,
        0.0917, 0.0642, 0.0252, 0.0786, 0.0512, 0.0650], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,951][circuit_model.py][line:2318][INFO] ##10-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0258, 0.0449, 0.0592, 0.0629, 0.0419, 0.0205, 0.0568, 0.0247, 0.0548,
        0.1893, 0.1449, 0.0659, 0.0627, 0.0376, 0.1083], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,951][circuit_model.py][line:2321][INFO] ##10-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0505, 0.0062, 0.0005, 0.0093, 0.0016, 0.0062, 0.0197, 0.0105, 0.0377,
        0.0280, 0.1805, 0.2225, 0.0224, 0.2783, 0.1261], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,952][circuit_model.py][line:2324][INFO] ##10-th layer ##Weight##: The head11 weight for token [ to] are: tensor([0.1288, 0.0172, 0.7210, 0.0029, 0.0456, 0.0027, 0.0086, 0.0049, 0.0118,
        0.0033, 0.0051, 0.0080, 0.0239, 0.0111, 0.0050], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:19,952][circuit_model.py][line:2327][INFO] ##10-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0054, 0.0220, 0.0274, 0.0837, 0.0215, 0.0747, 0.1498, 0.0375, 0.0577,
        0.1453, 0.1309, 0.0569, 0.0228, 0.0512, 0.1133], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,013][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:20,014][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,016][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,017][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,017][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,017][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,018][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,018][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,018][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,019][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,019][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,019][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,020][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,020][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.2680, 0.7320], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,022][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.1159, 0.8841], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,024][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.2510, 0.7490], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,025][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.4100, 0.5900], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,026][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1430, 0.8570], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,027][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.5032, 0.4968], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,028][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1494, 0.8506], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,028][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.3560, 0.6440], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,028][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.4035, 0.5965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,029][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.5196, 0.4804], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,029][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.8940, 0.1060], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,029][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.2640, 0.7360], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,030][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.1633, 0.4736, 0.3631], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,030][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([0.0289, 0.0947, 0.8764], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,031][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.0753, 0.2947, 0.6301], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,033][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.1504, 0.2888, 0.5607], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,034][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.1153, 0.6955, 0.1891], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,036][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.0647, 0.9264, 0.0089], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,037][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.0780, 0.3797, 0.5423], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,039][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.1349, 0.2104, 0.6547], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,041][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.1739, 0.2538, 0.5722], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,042][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.0487, 0.9397, 0.0116], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,043][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.1726, 0.0341, 0.7933], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,043][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.0691, 0.4105, 0.5204], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,044][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.1150, 0.2783, 0.1471, 0.4596], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,044][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0063, 0.0268, 0.2254, 0.7416], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,044][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0308, 0.0721, 0.2473, 0.6498], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,045][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.1241, 0.1857, 0.4153, 0.2749], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,045][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0848, 0.3868, 0.0668, 0.4615], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,045][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.4777, 0.4128, 0.0025, 0.1070], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,046][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0447, 0.1599, 0.1706, 0.6248], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,046][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.1223, 0.1424, 0.5624, 0.1729], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,046][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0878, 0.1973, 0.3467, 0.3682], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,047][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.2753, 0.3651, 0.0027, 0.3569], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,049][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1659, 0.0257, 0.8017, 0.0067], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,051][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0413, 0.1316, 0.2206, 0.6066], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,052][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0544, 0.1763, 0.1233, 0.3664, 0.2796], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,054][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0042, 0.0163, 0.1884, 0.3611, 0.4300], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,054][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0142, 0.0515, 0.1567, 0.5000, 0.2776], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,055][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0657, 0.1141, 0.2515, 0.2627, 0.3060], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,055][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0414, 0.2358, 0.0487, 0.6049, 0.0692], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,055][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0787, 0.5087, 0.0060, 0.3977, 0.0088], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,056][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0170, 0.0736, 0.1251, 0.4465, 0.3379], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,056][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0575, 0.0847, 0.2780, 0.1138, 0.4660], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,056][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0803, 0.1390, 0.2562, 0.2327, 0.2918], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,057][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0238, 0.3246, 0.0051, 0.6350, 0.0115], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,059][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.2005, 0.0196, 0.6799, 0.0053, 0.0946], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,060][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0145, 0.0713, 0.0705, 0.7535, 0.0902], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,062][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.0362, 0.1222, 0.1344, 0.2167, 0.2217, 0.2688], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,063][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.0026, 0.0144, 0.1593, 0.3126, 0.1897, 0.3214], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,064][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0096, 0.0364, 0.1403, 0.3715, 0.2402, 0.2021], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,065][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.0562, 0.0977, 0.2242, 0.1594, 0.2277, 0.2347], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,065][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0582, 0.2547, 0.0607, 0.3786, 0.0690, 0.1788], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,065][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.3838, 0.3745, 0.0021, 0.0953, 0.0034, 0.1408], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,066][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.0180, 0.0707, 0.1248, 0.3074, 0.1882, 0.2909], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,066][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.0504, 0.0834, 0.3324, 0.1173, 0.3121, 0.1043], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,066][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0823, 0.1480, 0.2533, 0.2119, 0.2142, 0.0902], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,067][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.1475, 0.2884, 0.0020, 0.3507, 0.0038, 0.2076], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,068][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.1342, 0.0208, 0.7636, 0.0072, 0.0692, 0.0050], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,069][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.0159, 0.0740, 0.0933, 0.4014, 0.0610, 0.3544], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,071][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.0370, 0.0886, 0.0801, 0.1174, 0.1196, 0.1430, 0.4143],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,073][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.0025, 0.0095, 0.1004, 0.1674, 0.0810, 0.1213, 0.5178],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,074][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0120, 0.0360, 0.1237, 0.2051, 0.1532, 0.1088, 0.3612],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,074][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.0748, 0.0925, 0.2147, 0.0984, 0.1762, 0.1515, 0.1920],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,075][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0644, 0.2569, 0.0495, 0.3127, 0.0473, 0.1410, 0.1282],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,075][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.5017, 0.2344, 0.0029, 0.0531, 0.0041, 0.1003, 0.1036],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,076][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.0220, 0.0712, 0.0945, 0.1714, 0.1309, 0.1773, 0.3328],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,076][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.0707, 0.1073, 0.3366, 0.1045, 0.2202, 0.0771, 0.0837],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,076][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0848, 0.1385, 0.2376, 0.1825, 0.1409, 0.0573, 0.1584],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,077][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.2057, 0.1768, 0.0031, 0.1704, 0.0056, 0.1320, 0.3064],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,078][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.1530, 0.0182, 0.7693, 0.0035, 0.0458, 0.0026, 0.0076],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,079][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.0236, 0.0629, 0.0651, 0.2252, 0.0382, 0.1984, 0.3867],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,081][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.0228, 0.0508, 0.0525, 0.0923, 0.1053, 0.1159, 0.3533, 0.2071],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,083][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.0026, 0.0068, 0.0763, 0.1227, 0.0742, 0.1116, 0.5676, 0.0381],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,084][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0066, 0.0213, 0.0676, 0.1784, 0.1085, 0.0955, 0.3839, 0.1382],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,085][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.0727, 0.0583, 0.1248, 0.0792, 0.1364, 0.1431, 0.2442, 0.1413],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,085][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0405, 0.2123, 0.0431, 0.2553, 0.0447, 0.1453, 0.1378, 0.1210],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,085][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.3043, 0.2275, 0.0026, 0.0829, 0.0056, 0.1460, 0.1520, 0.0791],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,086][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.0116, 0.0366, 0.0559, 0.1088, 0.1008, 0.1670, 0.4078, 0.1115],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,086][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.0661, 0.0864, 0.2661, 0.1136, 0.2114, 0.0936, 0.1073, 0.0553],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,086][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0661, 0.0960, 0.1695, 0.1598, 0.1427, 0.0551, 0.1968, 0.1139],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,087][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0619, 0.1016, 0.0018, 0.1990, 0.0054, 0.1399, 0.3881, 0.1023],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,088][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.1209, 0.0171, 0.7534, 0.0059, 0.0689, 0.0054, 0.0168, 0.0116],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,089][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.0093, 0.0294, 0.0307, 0.1487, 0.0204, 0.1996, 0.4685, 0.0934],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,091][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.0244, 0.0491, 0.0459, 0.0654, 0.0834, 0.0960, 0.2845, 0.1650, 0.1863],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,093][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.0021, 0.0050, 0.0583, 0.1283, 0.0686, 0.1149, 0.5081, 0.0303, 0.0844],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,094][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0078, 0.0216, 0.0608, 0.1480, 0.0951, 0.0887, 0.3382, 0.1162, 0.1235],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,095][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.0536, 0.0478, 0.0934, 0.0692, 0.1225, 0.1255, 0.2033, 0.1177, 0.1670],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,095][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0478, 0.1563, 0.0336, 0.2259, 0.0362, 0.1313, 0.1551, 0.1098, 0.1040],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,095][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.3437, 0.1339, 0.0026, 0.0566, 0.0057, 0.0974, 0.1319, 0.0637, 0.1644],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,096][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.0162, 0.0443, 0.0598, 0.1063, 0.1068, 0.1520, 0.3498, 0.0910, 0.0738],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,096][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.0616, 0.0864, 0.2081, 0.0926, 0.2351, 0.0863, 0.0887, 0.0459, 0.0952],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,097][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0456, 0.0689, 0.1279, 0.1312, 0.1170, 0.0546, 0.1799, 0.0863, 0.1886],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,097][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0751, 0.0593, 0.0022, 0.1257, 0.0059, 0.0916, 0.2833, 0.1008, 0.2563],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,099][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.1625, 0.0158, 0.7077, 0.0049, 0.0604, 0.0048, 0.0158, 0.0087, 0.0194],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,100][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.0102, 0.0299, 0.0402, 0.1289, 0.0305, 0.1749, 0.3848, 0.0907, 0.1100],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,102][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.0134, 0.0319, 0.0415, 0.0598, 0.0550, 0.0708, 0.2162, 0.1113, 0.1208,
        0.2793], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,103][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.0012, 0.0037, 0.0619, 0.1034, 0.0463, 0.0796, 0.4143, 0.0250, 0.0613,
        0.2034], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,104][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0051, 0.0132, 0.0587, 0.1235, 0.0746, 0.0644, 0.2669, 0.0806, 0.0880,
        0.2249], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,105][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.0425, 0.0376, 0.1213, 0.0569, 0.1207, 0.1040, 0.1544, 0.0873, 0.1400,
        0.1353], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,105][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0336, 0.1346, 0.0365, 0.1992, 0.0393, 0.1093, 0.1362, 0.0931, 0.0892,
        0.1291], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,106][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.4587, 0.0812, 0.0026, 0.0315, 0.0068, 0.0441, 0.0568, 0.0517, 0.1716,
        0.0949], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,106][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.0104, 0.0349, 0.0564, 0.1219, 0.0716, 0.1206, 0.2829, 0.0611, 0.0506,
        0.1896], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,106][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0374, 0.0638, 0.2620, 0.0884, 0.1724, 0.0641, 0.0797, 0.0362, 0.0728,
        0.1233], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,107][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0292, 0.0508, 0.0914, 0.0918, 0.0630, 0.0264, 0.0984, 0.0412, 0.0936,
        0.4142], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,108][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1259, 0.0419, 0.0026, 0.0748, 0.0089, 0.0424, 0.1213, 0.0934, 0.2804,
        0.2084], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,109][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1069, 0.0124, 0.7956, 0.0031, 0.0473, 0.0029, 0.0098, 0.0056, 0.0129,
        0.0037], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,111][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.0057, 0.0239, 0.0441, 0.1453, 0.0245, 0.1156, 0.2563, 0.0534, 0.0846,
        0.2466], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,113][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.0135, 0.0256, 0.0260, 0.0461, 0.0403, 0.0519, 0.1564, 0.0848, 0.0999,
        0.2258, 0.2298], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,114][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.0014, 0.0041, 0.0465, 0.0962, 0.0397, 0.0642, 0.3086, 0.0233, 0.0561,
        0.1861, 0.1738], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,115][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0061, 0.0135, 0.0492, 0.0986, 0.0676, 0.0559, 0.2145, 0.0694, 0.0764,
        0.1718, 0.1772], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,115][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.0508, 0.0446, 0.1065, 0.0548, 0.0990, 0.0852, 0.1220, 0.0785, 0.1262,
        0.1159, 0.1165], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,115][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0375, 0.1419, 0.0349, 0.1636, 0.0392, 0.0916, 0.1085, 0.0768, 0.0840,
        0.1139, 0.1081], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,116][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.5147, 0.0368, 0.0017, 0.0139, 0.0049, 0.0202, 0.0310, 0.0293, 0.0977,
        0.0473, 0.2024], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,116][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.0114, 0.0347, 0.0435, 0.1059, 0.0595, 0.0933, 0.2067, 0.0532, 0.0455,
        0.1651, 0.1812], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,117][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0420, 0.0655, 0.2348, 0.0860, 0.1521, 0.0549, 0.0659, 0.0357, 0.0700,
        0.1102, 0.0830], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,117][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0224, 0.0365, 0.0637, 0.0827, 0.0431, 0.0230, 0.0766, 0.0320, 0.0799,
        0.2962, 0.2438], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,118][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.1550, 0.0152, 0.0012, 0.0233, 0.0048, 0.0134, 0.0477, 0.0363, 0.1252,
        0.0741, 0.5039], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,120][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.1407, 0.0163, 0.7436, 0.0038, 0.0500, 0.0033, 0.0103, 0.0062, 0.0148,
        0.0043, 0.0066], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,122][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.0057, 0.0213, 0.0371, 0.1125, 0.0232, 0.0882, 0.2007, 0.0452, 0.0704,
        0.1968, 0.1990], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,123][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.0107, 0.0269, 0.0269, 0.0394, 0.0437, 0.0680, 0.1792, 0.1037, 0.1002,
        0.1744, 0.1516, 0.0751], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,125][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.0012, 0.0037, 0.0500, 0.1020, 0.0532, 0.0929, 0.3354, 0.0260, 0.0555,
        0.1378, 0.1256, 0.0167], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,125][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0036, 0.0112, 0.0379, 0.0848, 0.0605, 0.0560, 0.2510, 0.0691, 0.0640,
        0.1470, 0.1679, 0.0470], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,125][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.0328, 0.0321, 0.0953, 0.0673, 0.0813, 0.0835, 0.1104, 0.0835, 0.1057,
        0.1152, 0.1104, 0.0825], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,126][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0419, 0.1201, 0.0291, 0.1521, 0.0332, 0.0858, 0.1064, 0.0742, 0.0735,
        0.1032, 0.1000, 0.0805], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,126][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.2932, 0.0629, 0.0032, 0.0263, 0.0061, 0.0437, 0.0593, 0.0307, 0.0789,
        0.0456, 0.1494, 0.2007], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,127][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.0075, 0.0218, 0.0456, 0.0716, 0.0708, 0.1048, 0.2373, 0.0645, 0.0433,
        0.1296, 0.1364, 0.0667], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,127][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0492, 0.0636, 0.1724, 0.0747, 0.1695, 0.0611, 0.0738, 0.0329, 0.0755,
        0.1065, 0.0802, 0.0405], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,128][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0270, 0.0310, 0.0534, 0.0680, 0.0567, 0.0314, 0.0970, 0.0470, 0.0805,
        0.2188, 0.2065, 0.0828], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,130][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0751, 0.0167, 0.0020, 0.0306, 0.0053, 0.0225, 0.0726, 0.0250, 0.0764,
        0.0522, 0.2814, 0.3403], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,131][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1320, 0.0166, 0.7294, 0.0044, 0.0528, 0.0043, 0.0140, 0.0087, 0.0175,
        0.0042, 0.0065, 0.0096], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,133][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.0043, 0.0201, 0.0327, 0.0951, 0.0243, 0.0915, 0.2140, 0.0472, 0.0527,
        0.1792, 0.1679, 0.0709], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,134][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0055, 0.0152, 0.0152, 0.0290, 0.0320, 0.0526, 0.1663, 0.0957, 0.0999,
        0.1685, 0.1746, 0.0787, 0.0667], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,135][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.0005, 0.0019, 0.0282, 0.0528, 0.0536, 0.0955, 0.4241, 0.0244, 0.0518,
        0.1187, 0.1029, 0.0115, 0.0341], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,135][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0032, 0.0103, 0.0312, 0.0773, 0.0601, 0.0560, 0.2613, 0.0692, 0.0641,
        0.1216, 0.1558, 0.0355, 0.0545], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,136][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0168, 0.0231, 0.0548, 0.0496, 0.0721, 0.0736, 0.1468, 0.0868, 0.1050,
        0.1079, 0.1113, 0.0811, 0.0713], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,136][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0199, 0.0821, 0.0187, 0.1727, 0.0277, 0.0960, 0.1210, 0.0783, 0.0847,
        0.0989, 0.0901, 0.0745, 0.0355], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,137][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0937, 0.0785, 0.0035, 0.0773, 0.0088, 0.0880, 0.0913, 0.0740, 0.1190,
        0.0408, 0.1316, 0.1753, 0.0182], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,137][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0029, 0.0118, 0.0231, 0.0667, 0.0539, 0.0971, 0.2854, 0.0600, 0.0427,
        0.1264, 0.1385, 0.0480, 0.0433], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,137][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0291, 0.0414, 0.1317, 0.0559, 0.2336, 0.0497, 0.0703, 0.0307, 0.0632,
        0.0869, 0.0617, 0.0257, 0.1200], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,138][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([0.0191, 0.0293, 0.0461, 0.0567, 0.0613, 0.0364, 0.1012, 0.0395, 0.0722,
        0.1960, 0.1780, 0.0703, 0.0939], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,140][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0204, 0.0276, 0.0027, 0.0712, 0.0087, 0.0581, 0.0925, 0.0705, 0.1360,
        0.0317, 0.1417, 0.3117, 0.0272], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,142][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.1761, 0.0150, 0.6014, 0.0036, 0.0785, 0.0053, 0.0188, 0.0108, 0.0208,
        0.0045, 0.0080, 0.0116, 0.0457], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,143][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.0019, 0.0081, 0.0112, 0.0979, 0.0158, 0.0868, 0.2669, 0.0650, 0.0587,
        0.1560, 0.1630, 0.0494, 0.0194], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,145][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.0097, 0.0191, 0.0260, 0.0381, 0.0404, 0.0444, 0.1301, 0.0660, 0.0766,
        0.1574, 0.1500, 0.0711, 0.0771, 0.0941], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,145][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.0010, 0.0032, 0.0382, 0.0701, 0.0529, 0.0782, 0.3179, 0.0217, 0.0490,
        0.1333, 0.1173, 0.0158, 0.0355, 0.0659], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,146][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0045, 0.0105, 0.0373, 0.0812, 0.0644, 0.0495, 0.2075, 0.0602, 0.0583,
        0.1301, 0.1457, 0.0389, 0.0572, 0.0548], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,146][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([0.0197, 0.0222, 0.0694, 0.0470, 0.0668, 0.0654, 0.1015, 0.0701, 0.0906,
        0.1035, 0.0985, 0.0892, 0.0648, 0.0913], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,147][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0407, 0.0875, 0.0198, 0.1169, 0.0256, 0.0696, 0.0944, 0.0735, 0.0764,
        0.0956, 0.0997, 0.0789, 0.0444, 0.0769], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,147][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.2379, 0.0233, 0.0004, 0.0065, 0.0008, 0.0128, 0.0244, 0.0105, 0.0348,
        0.0370, 0.1856, 0.1673, 0.0082, 0.2505], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,147][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.0057, 0.0159, 0.0309, 0.0647, 0.0566, 0.0839, 0.2099, 0.0409, 0.0362,
        0.1226, 0.1352, 0.0607, 0.0548, 0.0820], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,148][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0300, 0.0361, 0.1495, 0.0544, 0.1622, 0.0451, 0.0583, 0.0284, 0.0665,
        0.1066, 0.0757, 0.0252, 0.0941, 0.0680], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,150][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0224, 0.0336, 0.0563, 0.0716, 0.0562, 0.0263, 0.0761, 0.0300, 0.0637,
        0.2032, 0.1635, 0.0688, 0.0804, 0.0478], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,151][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([3.8452e-02, 4.5336e-03, 1.2855e-04, 5.3680e-03, 3.3371e-04, 3.6538e-03,
        1.8355e-02, 5.3904e-03, 2.5166e-02, 3.2769e-02, 2.8038e-01, 2.1506e-01,
        7.3822e-03, 3.6302e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,153][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.1328, 0.0126, 0.6723, 0.0036, 0.0670, 0.0037, 0.0136, 0.0068, 0.0156,
        0.0044, 0.0065, 0.0095, 0.0362, 0.0154], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,154][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.0036, 0.0154, 0.0192, 0.0810, 0.0218, 0.0854, 0.1811, 0.0475, 0.0607,
        0.1761, 0.1663, 0.0532, 0.0266, 0.0620], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,155][circuit_model.py][line:2332][INFO] ##10-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.0078, 0.0191, 0.0214, 0.0312, 0.0281, 0.0327, 0.1004, 0.0542, 0.0673,
        0.1450, 0.1322, 0.0581, 0.0572, 0.0760, 0.1693], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,155][circuit_model.py][line:2335][INFO] ##10-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.0009, 0.0039, 0.0451, 0.0724, 0.0348, 0.0578, 0.2571, 0.0166, 0.0437,
        0.1475, 0.1229, 0.0136, 0.0235, 0.0496, 0.1105], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,156][circuit_model.py][line:2338][INFO] ##10-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0044, 0.0115, 0.0420, 0.0669, 0.0535, 0.0373, 0.1633, 0.0495, 0.0592,
        0.1244, 0.1233, 0.0433, 0.0531, 0.0501, 0.1182], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,156][circuit_model.py][line:2341][INFO] ##10-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.0337, 0.0323, 0.0892, 0.0381, 0.0664, 0.0532, 0.0779, 0.0500, 0.0788,
        0.0842, 0.0785, 0.0904, 0.0616, 0.0822, 0.0833], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,157][circuit_model.py][line:2344][INFO] ##10-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0280, 0.1097, 0.0212, 0.1333, 0.0223, 0.0653, 0.0792, 0.0513, 0.0586,
        0.0878, 0.0862, 0.0673, 0.0324, 0.0637, 0.0937], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,157][circuit_model.py][line:2347][INFO] ##10-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.2319, 0.0239, 0.0012, 0.0085, 0.0026, 0.0141, 0.0205, 0.0168, 0.0512,
        0.0284, 0.1166, 0.1817, 0.0186, 0.1943, 0.0896], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,158][circuit_model.py][line:2350][INFO] ##10-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.0073, 0.0224, 0.0316, 0.0618, 0.0434, 0.0653, 0.1626, 0.0362, 0.0340,
        0.1201, 0.1286, 0.0573, 0.0432, 0.0665, 0.1195], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,159][circuit_model.py][line:2353][INFO] ##10-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0321, 0.0502, 0.1843, 0.0535, 0.1386, 0.0384, 0.0472, 0.0234, 0.0566,
        0.0917, 0.0642, 0.0252, 0.0786, 0.0512, 0.0650], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,161][circuit_model.py][line:2356][INFO] ##10-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0258, 0.0449, 0.0592, 0.0629, 0.0419, 0.0205, 0.0568, 0.0247, 0.0548,
        0.1893, 0.1449, 0.0659, 0.0627, 0.0376, 0.1083], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,163][circuit_model.py][line:2359][INFO] ##10-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0505, 0.0062, 0.0005, 0.0093, 0.0016, 0.0062, 0.0197, 0.0105, 0.0377,
        0.0280, 0.1805, 0.2225, 0.0224, 0.2783, 0.1261], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,164][circuit_model.py][line:2362][INFO] ##10-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.1288, 0.0172, 0.7210, 0.0029, 0.0456, 0.0027, 0.0086, 0.0049, 0.0118,
        0.0033, 0.0051, 0.0080, 0.0239, 0.0111, 0.0050], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,165][circuit_model.py][line:2365][INFO] ##10-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.0054, 0.0220, 0.0274, 0.0837, 0.0215, 0.0747, 0.1498, 0.0375, 0.0577,
        0.1453, 0.1309, 0.0569, 0.0228, 0.0512, 0.1133], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,166][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:20,167][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2968],
        [   9],
        [ 108],
        [   8],
        [   4],
        [   4],
        [   3],
        [   4],
        [   9],
        [   6],
        [   6],
        [   5],
        [   5],
        [   9],
        [   5]], device='cuda:0')
[2024-07-24 10:20:20,168][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[2211],
        [   8],
        [  36],
        [   3],
        [   2],
        [   4],
        [   2],
        [   3],
        [   9],
        [   5],
        [   4],
        [   4],
        [   3],
        [   6],
        [   4]], device='cuda:0')
[2024-07-24 10:20:20,170][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[38277],
        [30227],
        [50015],
        [34493],
        [37222],
        [38859],
        [28093],
        [20055],
        [15120],
        [16974],
        [20480],
        [16595],
        [16184],
        [20581],
        [23524]], device='cuda:0')
[2024-07-24 10:20:20,172][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[37506],
        [47451],
        [50247],
        [48717],
        [46601],
        [46497],
        [44186],
        [42600],
        [41311],
        [41594],
        [41450],
        [41461],
        [39460],
        [40800],
        [41537]], device='cuda:0')
[2024-07-24 10:20:20,173][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[25131],
        [30443],
        [50233],
        [45125],
        [45575],
        [44608],
        [42514],
        [38711],
        [37557],
        [36480],
        [35883],
        [34928],
        [35804],
        [36853],
        [37879]], device='cuda:0')
[2024-07-24 10:20:20,175][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[ 8513],
        [ 3854],
        [22033],
        [14638],
        [15634],
        [15676],
        [17570],
        [16958],
        [16485],
        [16486],
        [15454],
        [15122],
        [15810],
        [15544],
        [15733]], device='cuda:0')
[2024-07-24 10:20:20,176][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[17860],
        [10940],
        [11408],
        [18165],
        [21958],
        [20675],
        [20531],
        [20656],
        [20547],
        [19667],
        [18953],
        [18448],
        [19349],
        [18601],
        [18823]], device='cuda:0')
[2024-07-24 10:20:20,177][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[16348],
        [21561],
        [22907],
        [20991],
        [21271],
        [21493],
        [21657],
        [23408],
        [26235],
        [25548],
        [21906],
        [23126],
        [24658],
        [24752],
        [25694]], device='cuda:0')
[2024-07-24 10:20:20,178][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[22628],
        [27131],
        [48522],
        [41454],
        [41769],
        [42259],
        [42201],
        [41882],
        [42229],
        [41189],
        [39428],
        [40355],
        [39434],
        [39524],
        [39161]], device='cuda:0')
[2024-07-24 10:20:20,179][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[47716],
        [28667],
        [   11],
        [   51],
        [ 1016],
        [  590],
        [  512],
        [ 1257],
        [ 2419],
        [ 1410],
        [ 2012],
        [ 4296],
        [ 5481],
        [ 4739],
        [ 3178]], device='cuda:0')
[2024-07-24 10:20:20,180][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15305],
        [19779],
        [14864],
        [ 8232],
        [ 6512],
        [ 6612],
        [ 7468],
        [ 6272],
        [ 6234],
        [ 6383],
        [ 5207],
        [ 5886],
        [ 5455],
        [ 5456],
        [ 5410]], device='cuda:0')
[2024-07-24 10:20:20,182][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[39710],
        [44617],
        [44656],
        [46789],
        [47208],
        [46328],
        [45675],
        [45556],
        [45521],
        [45979],
        [46295],
        [46427],
        [46378],
        [46159],
        [46239]], device='cuda:0')
[2024-07-24 10:20:20,184][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[31752],
        [34088],
        [49872],
        [49874],
        [49836],
        [49857],
        [49864],
        [49829],
        [49813],
        [49850],
        [49832],
        [49802],
        [49717],
        [49778],
        [49807]], device='cuda:0')
[2024-07-24 10:20:20,185][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[25938],
        [18478],
        [19993],
        [16780],
        [15809],
        [15514],
        [15125],
        [14464],
        [14711],
        [14974],
        [14461],
        [14394],
        [14209],
        [14186],
        [14061]], device='cuda:0')
[2024-07-24 10:20:20,187][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[17178],
        [24426],
        [ 4631],
        [ 5090],
        [ 2510],
        [ 5468],
        [15582],
        [ 1554],
        [ 1155],
        [15192],
        [11599],
        [ 7825],
        [ 2028],
        [ 5365],
        [ 5315]], device='cuda:0')
[2024-07-24 10:20:20,187][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[39619],
        [37492],
        [42831],
        [37846],
        [40535],
        [39249],
        [38229],
        [37997],
        [37535],
        [38951],
        [40295],
        [40094],
        [40195],
        [40925],
        [40568]], device='cuda:0')
[2024-07-24 10:20:20,188][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[35364],
        [33922],
        [14340],
        [16893],
        [26952],
        [25275],
        [34499],
        [35936],
        [37344],
        [38130],
        [38972],
        [38321],
        [39676],
        [39539],
        [39496]], device='cuda:0')
[2024-07-24 10:20:20,189][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[36592],
        [26356],
        [14722],
        [25846],
        [21707],
        [22278],
        [24165],
        [24191],
        [22309],
        [20325],
        [18628],
        [18560],
        [18396],
        [17697],
        [16064]], device='cuda:0')
[2024-07-24 10:20:20,191][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[22487],
        [39092],
        [40433],
        [42560],
        [44755],
        [45392],
        [45682],
        [45944],
        [46103],
        [46016],
        [45634],
        [45405],
        [45589],
        [45281],
        [45207]], device='cuda:0')
[2024-07-24 10:20:20,193][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[15622],
        [13366],
        [ 8738],
        [ 4670],
        [ 3367],
        [ 3680],
        [ 4042],
        [ 4263],
        [ 4365],
        [ 5114],
        [ 5992],
        [ 6701],
        [ 6252],
        [ 7506],
        [ 7622]], device='cuda:0')
[2024-07-24 10:20:20,194][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[23336],
        [31864],
        [31389],
        [34697],
        [36974],
        [35865],
        [38541],
        [39240],
        [40453],
        [41485],
        [42819],
        [41107],
        [40530],
        [39702],
        [39820]], device='cuda:0')
[2024-07-24 10:20:20,196][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[14705],
        [ 5714],
        [ 6733],
        [ 9629],
        [10005],
        [11798],
        [13213],
        [14456],
        [14482],
        [14885],
        [15338],
        [15574],
        [15259],
        [14761],
        [14890]], device='cuda:0')
[2024-07-24 10:20:20,197][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[22921],
        [ 9653],
        [ 7039],
        [ 8250],
        [ 7060],
        [ 7183],
        [ 7800],
        [ 8232],
        [ 7877],
        [ 8082],
        [ 8413],
        [ 8230],
        [ 7555],
        [ 7763],
        [ 7884]], device='cuda:0')
[2024-07-24 10:20:20,198][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[16677],
        [20454],
        [15566],
        [20309],
        [22249],
        [21709],
        [22151],
        [22905],
        [23008],
        [23968],
        [24249],
        [23308],
        [23513],
        [23119],
        [22537]], device='cuda:0')
[2024-07-24 10:20:20,199][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[26509],
        [ 8120],
        [ 3539],
        [ 6712],
        [ 5812],
        [ 8447],
        [11245],
        [12869],
        [14788],
        [14443],
        [13655],
        [16666],
        [16843],
        [16060],
        [16621]], device='cuda:0')
[2024-07-24 10:20:20,200][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[30449],
        [32255],
        [33343],
        [33403],
        [35548],
        [34960],
        [34465],
        [35664],
        [35829],
        [34870],
        [35501],
        [35940],
        [37937],
        [37104],
        [36146]], device='cuda:0')
[2024-07-24 10:20:20,202][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[10970],
        [17256],
        [19554],
        [28495],
        [28693],
        [22116],
        [16714],
        [14893],
        [15194],
        [17406],
        [18166],
        [18175],
        [17488],
        [18415],
        [19227]], device='cuda:0')
[2024-07-24 10:20:20,203][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[12241],
        [20337],
        [29619],
        [20490],
        [18832],
        [18881],
        [15227],
        [13543],
        [12760],
        [11185],
        [10170],
        [10587],
        [10847],
        [10858],
        [11075]], device='cuda:0')
[2024-07-24 10:20:20,205][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[29519],
        [ 8674],
        [40678],
        [42583],
        [42474],
        [38419],
        [33056],
        [46432],
        [46314],
        [28501],
        [37937],
        [38280],
        [37643],
        [35011],
        [34530]], device='cuda:0')
[2024-07-24 10:20:20,206][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276],
        [17276]], device='cuda:0')
[2024-07-24 10:20:20,270][circuit_model.py][line:1774][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:20,271][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,271][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,271][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,272][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,272][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,272][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,273][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,273][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,274][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,275][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,276][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,277][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,279][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.4015, 0.5985], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,280][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.2365, 0.7635], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,281][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.3441, 0.6559], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,281][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.9780, 0.0220], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,281][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.2244, 0.7756], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,282][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0441, 0.9559], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,282][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.3226, 0.6774], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,282][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0641, 0.9359], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,283][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0151, 0.9849], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,283][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.1346, 0.8654], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,284][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([0.5399, 0.4601], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,285][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0317, 0.9683], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,287][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Angela] are: tensor([0.0475, 0.3715, 0.5810], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,288][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Angela] are: tensor([0.3160, 0.5955, 0.0885], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,290][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Angela] are: tensor([0.0722, 0.5867, 0.3411], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,291][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Angela] are: tensor([0.4819, 0.3671, 0.1510], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,291][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Angela] are: tensor([0.4135, 0.4491, 0.1374], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,291][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Angela] are: tensor([0.1725, 0.5619, 0.2656], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,292][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Angela] are: tensor([0.0812, 0.4720, 0.4468], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,292][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Angela] are: tensor([0.1118, 0.6756, 0.2127], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,292][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Angela] are: tensor([0.0022, 0.6089, 0.3889], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,293][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Angela] are: tensor([0.1297, 0.2998, 0.5705], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,293][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Angela] are: tensor([0.7575, 0.2288, 0.0137], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,293][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Angela] are: tensor([0.0041, 0.5622, 0.4336], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,294][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2623, 0.4171, 0.2405, 0.0801], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,296][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.5535, 0.2376, 0.0745, 0.1344], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,298][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0525, 0.3794, 0.2382, 0.3299], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,299][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.5738, 0.2871, 0.0724, 0.0667], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,301][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.1495, 0.1023, 0.0394, 0.7088], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,301][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0093, 0.0506, 0.0337, 0.9064], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,301][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0483, 0.3552, 0.2529, 0.3436], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,302][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0752, 0.5854, 0.0859, 0.2535], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,302][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0265, 0.6115, 0.0777, 0.2844], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,302][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0771, 0.2005, 0.6804, 0.0420], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,303][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([0.9373, 0.0341, 0.0017, 0.0269], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,303][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0028, 0.3249, 0.2300, 0.4423], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,304][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0328, 0.1650, 0.4022, 0.1988, 0.2011], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,304][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.4270, 0.3032, 0.1593, 0.0688, 0.0416], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,306][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0221, 0.3200, 0.2220, 0.3000, 0.1360], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,308][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.2338, 0.4038, 0.0975, 0.1713, 0.0935], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,309][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0607, 0.0639, 0.0259, 0.5606, 0.2889], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,311][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0337, 0.1181, 0.0675, 0.7686, 0.0121], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,311][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0374, 0.1515, 0.2051, 0.3752, 0.2309], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,312][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0752, 0.5105, 0.0728, 0.3071, 0.0343], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,312][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([1.6833e-04, 4.8615e-02, 4.7589e-02, 8.9422e-01, 9.4108e-03],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,312][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0496, 0.1206, 0.4519, 0.0635, 0.3144], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,313][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([0.6215, 0.0977, 0.0117, 0.2649, 0.0041], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,313][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0020, 0.2376, 0.1922, 0.3347, 0.2335], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,313][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ had] are: tensor([0.1856, 0.3062, 0.3157, 0.0870, 0.0485, 0.0569], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,314][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ had] are: tensor([0.5020, 0.2129, 0.1386, 0.0653, 0.0486, 0.0326], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,316][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ had] are: tensor([0.0095, 0.2615, 0.2043, 0.3445, 0.0816, 0.0986], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,317][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ had] are: tensor([0.2710, 0.3711, 0.0645, 0.1056, 0.0514, 0.1365], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,319][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ had] are: tensor([0.0476, 0.0604, 0.0187, 0.4908, 0.1900, 0.1925], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,320][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ had] are: tensor([0.0044, 0.0351, 0.0514, 0.7396, 0.0114, 0.1580], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,321][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ had] are: tensor([0.0790, 0.2440, 0.2263, 0.2549, 0.1246, 0.0711], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,321][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ had] are: tensor([0.1661, 0.4823, 0.0654, 0.1960, 0.0209, 0.0692], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,322][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ had] are: tensor([0.0132, 0.3868, 0.1023, 0.3247, 0.0115, 0.1615], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,322][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ had] are: tensor([0.0214, 0.1255, 0.5799, 0.0443, 0.1979, 0.0310], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,322][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ had] are: tensor([8.0877e-01, 2.7258e-02, 1.5936e-03, 3.7016e-02, 5.2865e-04, 1.2484e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,323][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ had] are: tensor([0.0025, 0.1839, 0.1425, 0.2472, 0.1712, 0.2529], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,323][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ a] are: tensor([0.1268, 0.3036, 0.3103, 0.1127, 0.0415, 0.0676, 0.0374],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,323][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ a] are: tensor([0.5197, 0.1444, 0.1584, 0.0859, 0.0323, 0.0195, 0.0399],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,324][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ a] are: tensor([0.0065, 0.1875, 0.1135, 0.2665, 0.0573, 0.0892, 0.2795],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,326][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ a] are: tensor([0.2757, 0.2845, 0.0524, 0.0811, 0.0371, 0.1244, 0.1447],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,328][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ a] are: tensor([0.0502, 0.0443, 0.0150, 0.3227, 0.1293, 0.1091, 0.3294],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,329][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ a] are: tensor([0.0089, 0.0466, 0.0503, 0.5396, 0.0098, 0.0965, 0.2482],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,330][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ a] are: tensor([0.0765, 0.2950, 0.2665, 0.1992, 0.0536, 0.0312, 0.0779],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,331][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ a] are: tensor([0.1274, 0.3841, 0.0631, 0.2391, 0.0213, 0.0539, 0.1111],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,332][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ a] are: tensor([0.0284, 0.6274, 0.1523, 0.1067, 0.0173, 0.0407, 0.0271],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,332][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ a] are: tensor([0.0686, 0.1509, 0.5961, 0.0279, 0.1227, 0.0157, 0.0182],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,332][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ a] are: tensor([8.4677e-01, 2.2205e-02, 5.6825e-04, 2.4323e-02, 8.8645e-05, 2.7699e-02,
        7.8346e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,333][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ a] are: tensor([0.0009, 0.1209, 0.0910, 0.1725, 0.1115, 0.1701, 0.3330],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,333][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ long] are: tensor([0.1636, 0.2851, 0.1974, 0.1012, 0.0416, 0.0721, 0.0458, 0.0933],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,334][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ long] are: tensor([0.3526, 0.1703, 0.0868, 0.1205, 0.0668, 0.0451, 0.1278, 0.0302],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,334][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ long] are: tensor([0.0061, 0.1505, 0.1129, 0.2408, 0.0616, 0.0704, 0.2736, 0.0842],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,335][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ long] are: tensor([0.1817, 0.2476, 0.0437, 0.0695, 0.0381, 0.1290, 0.1955, 0.0949],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,337][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ long] are: tensor([0.0332, 0.0325, 0.0092, 0.3409, 0.0884, 0.0976, 0.3347, 0.0634],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,338][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ long] are: tensor([0.0057, 0.0195, 0.0225, 0.5195, 0.0048, 0.0911, 0.3070, 0.0298],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,340][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ long] are: tensor([0.0516, 0.1439, 0.0679, 0.2511, 0.0523, 0.0649, 0.1593, 0.2089],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,340][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ long] are: tensor([0.1483, 0.2819, 0.0595, 0.2582, 0.0245, 0.0515, 0.1424, 0.0338],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,342][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ long] are: tensor([0.0054, 0.2179, 0.0845, 0.3845, 0.0106, 0.1053, 0.0644, 0.1275],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,344][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ long] are: tensor([0.0245, 0.1118, 0.4527, 0.0601, 0.1558, 0.0421, 0.1014, 0.0515],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,345][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ long] are: tensor([6.8176e-01, 2.0696e-02, 1.0470e-03, 3.5307e-02, 1.7156e-04, 6.7361e-02,
        1.9105e-01, 2.6124e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,347][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ long] are: tensor([0.0011, 0.1037, 0.0771, 0.1514, 0.0957, 0.1467, 0.2836, 0.1407],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,347][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ argument] are: tensor([0.1734, 0.2178, 0.1671, 0.0935, 0.0471, 0.0879, 0.0532, 0.0732, 0.0869],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,347][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ argument] are: tensor([0.4911, 0.1173, 0.0826, 0.0643, 0.0439, 0.0306, 0.0747, 0.0181, 0.0774],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,348][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ argument] are: tensor([0.0009, 0.0543, 0.0324, 0.1990, 0.0228, 0.0611, 0.4086, 0.0860, 0.1349],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,348][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ argument] are: tensor([0.2096, 0.1989, 0.0374, 0.0503, 0.0350, 0.1013, 0.1524, 0.1054, 0.1098],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,349][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ argument] are: tensor([0.0315, 0.0258, 0.0135, 0.2958, 0.1078, 0.0893, 0.3101, 0.0700, 0.0562],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,349][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ argument] are: tensor([0.0073, 0.0154, 0.0374, 0.2932, 0.0086, 0.1229, 0.3504, 0.0399, 0.1250],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,349][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ argument] are: tensor([0.0559, 0.0902, 0.0818, 0.1186, 0.0431, 0.0414, 0.0902, 0.1726, 0.3061],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,350][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ argument] are: tensor([0.1314, 0.2393, 0.0720, 0.2051, 0.0231, 0.0641, 0.1439, 0.0396, 0.0816],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,350][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ argument] are: tensor([0.0034, 0.1292, 0.1012, 0.3758, 0.0127, 0.0989, 0.0719, 0.1385, 0.0684],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,351][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ argument] are: tensor([0.0534, 0.1165, 0.3920, 0.0559, 0.1332, 0.0432, 0.0811, 0.0411, 0.0835],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,352][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ argument] are: tensor([8.0654e-01, 7.3654e-03, 7.6780e-05, 1.0519e-02, 3.8136e-05, 2.3338e-02,
        9.8198e-02, 6.7709e-04, 5.3243e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,354][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ argument] are: tensor([0.0016, 0.0934, 0.0752, 0.1312, 0.0938, 0.1295, 0.2450, 0.1314, 0.0990],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,355][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [,] are: tensor([0.1176, 0.2164, 0.2807, 0.1006, 0.0359, 0.0425, 0.0291, 0.0551, 0.0404,
        0.0817], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,357][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [,] are: tensor([0.4580, 0.0974, 0.1434, 0.0760, 0.0370, 0.0188, 0.0507, 0.0095, 0.0356,
        0.0737], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,358][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [,] are: tensor([0.0034, 0.0958, 0.0611, 0.1469, 0.0310, 0.0470, 0.1692, 0.0500, 0.0959,
        0.2997], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,358][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [,] are: tensor([0.1690, 0.2095, 0.0404, 0.0559, 0.0303, 0.0939, 0.1235, 0.0759, 0.0924,
        0.1092], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,359][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [,] are: tensor([0.0336, 0.0249, 0.0103, 0.2284, 0.0740, 0.0563, 0.1832, 0.0450, 0.0343,
        0.3099], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,359][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [,] are: tensor([0.0032, 0.0147, 0.0327, 0.4147, 0.0061, 0.0869, 0.2034, 0.0213, 0.0541,
        0.1629], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,359][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [,] are: tensor([0.0353, 0.1093, 0.1069, 0.1205, 0.0358, 0.0279, 0.0774, 0.1286, 0.1606,
        0.1977], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,360][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [,] are: tensor([0.0732, 0.1994, 0.0530, 0.2346, 0.0188, 0.0640, 0.1345, 0.0230, 0.0403,
        0.1593], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,360][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [,] are: tensor([0.0120, 0.3169, 0.1332, 0.1787, 0.0118, 0.0357, 0.0221, 0.0867, 0.0339,
        0.1688], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,361][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [,] are: tensor([0.0305, 0.1085, 0.5716, 0.0396, 0.0976, 0.0187, 0.0314, 0.0210, 0.0450,
        0.0360], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,362][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [,] are: tensor([5.6303e-01, 2.4993e-02, 1.3802e-03, 4.8671e-02, 1.6957e-04, 5.1858e-02,
        1.5188e-01, 1.4839e-03, 7.9490e-02, 7.7038e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,364][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [,] are: tensor([0.0007, 0.0807, 0.0634, 0.1149, 0.0778, 0.1070, 0.2088, 0.1072, 0.0724,
        0.1671], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,365][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ and] are: tensor([0.2563, 0.2307, 0.2160, 0.0679, 0.0174, 0.0279, 0.0168, 0.0352, 0.0287,
        0.0537, 0.0495], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,367][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ and] are: tensor([0.4912, 0.1013, 0.1201, 0.0637, 0.0306, 0.0141, 0.0300, 0.0081, 0.0339,
        0.0534, 0.0536], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,368][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ and] are: tensor([0.0021, 0.0607, 0.0343, 0.1168, 0.0199, 0.0339, 0.1398, 0.0377, 0.0694,
        0.2588, 0.2265], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,368][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ and] are: tensor([0.1767, 0.1789, 0.0359, 0.0487, 0.0297, 0.0727, 0.1042, 0.0624, 0.0835,
        0.0949, 0.1125], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,369][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ and] are: tensor([0.0270, 0.0150, 0.0072, 0.1369, 0.0444, 0.0297, 0.0912, 0.0246, 0.0198,
        0.1671, 0.4372], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,369][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ and] are: tensor([0.0050, 0.0184, 0.0261, 0.3592, 0.0057, 0.0623, 0.1425, 0.0229, 0.0567,
        0.1508, 0.1501], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,370][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ and] are: tensor([0.0298, 0.1084, 0.0707, 0.1082, 0.0208, 0.0194, 0.0521, 0.1138, 0.1405,
        0.1907, 0.1456], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,370][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ and] are: tensor([0.0790, 0.2753, 0.0442, 0.1785, 0.0114, 0.0457, 0.0787, 0.0188, 0.0345,
        0.1327, 0.1013], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,370][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ and] are: tensor([0.0227, 0.2571, 0.1060, 0.1270, 0.0150, 0.0251, 0.0198, 0.0698, 0.0354,
        0.1411, 0.1809], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,371][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ and] are: tensor([0.0410, 0.1263, 0.5102, 0.0380, 0.1103, 0.0163, 0.0258, 0.0224, 0.0489,
        0.0366, 0.0241], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,372][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ and] are: tensor([6.2672e-01, 1.6108e-02, 4.3094e-04, 2.4114e-02, 6.9118e-05, 2.0548e-02,
        6.8749e-02, 7.0764e-04, 3.7818e-02, 4.2002e-02, 1.6273e-01],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,374][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ and] are: tensor([0.0005, 0.0655, 0.0497, 0.0934, 0.0613, 0.0884, 0.1793, 0.0889, 0.0606,
        0.1436, 0.1688], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,376][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ afterwards] are: tensor([0.1224, 0.1992, 0.1551, 0.0580, 0.0542, 0.0537, 0.0376, 0.0660, 0.0515,
        0.0708, 0.0753, 0.0563], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,377][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ afterwards] are: tensor([0.3711, 0.1236, 0.0739, 0.0747, 0.0321, 0.0265, 0.0716, 0.0189, 0.0523,
        0.0641, 0.0591, 0.0321], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,378][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ afterwards] are: tensor([1.1989e-04, 1.0842e-02, 6.0088e-03, 7.6250e-02, 5.1010e-03, 2.3062e-02,
        1.7665e-01, 2.9370e-02, 4.6977e-02, 2.8087e-01, 2.9230e-01, 5.2446e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,379][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ afterwards] are: tensor([0.0993, 0.0904, 0.0243, 0.0285, 0.0196, 0.0610, 0.1121, 0.0638, 0.0684,
        0.0826, 0.1069, 0.2430], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,379][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ afterwards] are: tensor([0.0120, 0.0101, 0.0047, 0.1074, 0.0294, 0.0294, 0.1171, 0.0232, 0.0160,
        0.1376, 0.4004, 0.1127], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,379][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ afterwards] are: tensor([0.0052, 0.0214, 0.0305, 0.2752, 0.0067, 0.0775, 0.2196, 0.0301, 0.0554,
        0.1252, 0.1057, 0.0475], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,380][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ afterwards] are: tensor([0.0216, 0.0744, 0.0705, 0.0920, 0.0217, 0.0247, 0.0454, 0.1101, 0.1211,
        0.0972, 0.0656, 0.2557], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,380][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ afterwards] are: tensor([0.0553, 0.1888, 0.0676, 0.2362, 0.0159, 0.0408, 0.1215, 0.0254, 0.0364,
        0.1135, 0.0675, 0.0310], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,381][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ afterwards] are: tensor([0.0059, 0.1214, 0.0789, 0.2291, 0.0127, 0.0572, 0.0454, 0.0785, 0.0444,
        0.1406, 0.1375, 0.0484], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,381][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ afterwards] are: tensor([0.0298, 0.1194, 0.3111, 0.0699, 0.1005, 0.0366, 0.0648, 0.0313, 0.0656,
        0.0577, 0.0428, 0.0704], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,382][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ afterwards] are: tensor([6.0650e-01, 7.2001e-03, 6.9498e-05, 1.1451e-02, 3.2291e-05, 1.5035e-02,
        7.7092e-02, 3.0918e-04, 3.3514e-02, 2.8597e-02, 1.3240e-01, 8.7803e-02],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,384][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ afterwards] are: tensor([0.0004, 0.0623, 0.0474, 0.0871, 0.0568, 0.0823, 0.1660, 0.0860, 0.0549,
        0.1298, 0.1555, 0.0714], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,385][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ Tiffany] are: tensor([0.0199, 0.0630, 0.1902, 0.0780, 0.0890, 0.0978, 0.0473, 0.0799, 0.0814,
        0.0751, 0.0717, 0.0382, 0.0684], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,387][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ Tiffany] are: tensor([0.3024, 0.1394, 0.0841, 0.0478, 0.0243, 0.0303, 0.0967, 0.0152, 0.0630,
        0.0656, 0.0694, 0.0429, 0.0190], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,388][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ Tiffany] are: tensor([0.0003, 0.0211, 0.0091, 0.0550, 0.0090, 0.0249, 0.1606, 0.0377, 0.0598,
        0.2575, 0.2455, 0.0986, 0.0207], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,389][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ Tiffany] are: tensor([0.0490, 0.0791, 0.0205, 0.0342, 0.0219, 0.0741, 0.1245, 0.0816, 0.0728,
        0.0932, 0.1174, 0.2045, 0.0273], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,389][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ Tiffany] are: tensor([0.0085, 0.0054, 0.0032, 0.0666, 0.0331, 0.0279, 0.1123, 0.0212, 0.0175,
        0.1247, 0.3767, 0.1166, 0.0862], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,390][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ Tiffany] are: tensor([0.0086, 0.0250, 0.0169, 0.1972, 0.0024, 0.0632, 0.2844, 0.0293, 0.0568,
        0.1329, 0.1350, 0.0456, 0.0027], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,390][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ Tiffany] are: tensor([0.0059, 0.0223, 0.0281, 0.0806, 0.0350, 0.0263, 0.0654, 0.1453, 0.1362,
        0.1143, 0.0950, 0.2090, 0.0365], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,391][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ Tiffany] are: tensor([0.0273, 0.1526, 0.0312, 0.1720, 0.0117, 0.0613, 0.2420, 0.0313, 0.0501,
        0.1162, 0.0736, 0.0266, 0.0044], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,391][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ Tiffany] are: tensor([8.9285e-05, 1.5920e-02, 2.8037e-02, 5.0642e-01, 6.5233e-03, 3.9172e-02,
        3.4139e-02, 8.3212e-02, 3.0026e-02, 1.1882e-01, 1.0912e-01, 2.3734e-02,
        4.7882e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,392][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ Tiffany] are: tensor([0.0335, 0.0640, 0.2103, 0.0376, 0.1213, 0.0390, 0.0925, 0.0418, 0.0794,
        0.0575, 0.0516, 0.0690, 0.1024], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,393][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ Tiffany] are: tensor([3.2233e-01, 5.9005e-03, 6.0547e-05, 2.4957e-02, 5.9199e-05, 3.4056e-02,
        1.3544e-01, 9.9774e-04, 1.0654e-01, 4.5761e-02, 2.1791e-01, 1.0358e-01,
        2.4100e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,395][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ Tiffany] are: tensor([0.0005, 0.0567, 0.0470, 0.0832, 0.0569, 0.0775, 0.1529, 0.0834, 0.0570,
        0.1177, 0.1411, 0.0718, 0.0542], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,396][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ said] are: tensor([0.3169, 0.1803, 0.1931, 0.0473, 0.0163, 0.0221, 0.0163, 0.0263, 0.0287,
        0.0437, 0.0459, 0.0228, 0.0121, 0.0284], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,398][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ said] are: tensor([0.3712, 0.0938, 0.0779, 0.0447, 0.0264, 0.0227, 0.0551, 0.0102, 0.0548,
        0.0600, 0.0586, 0.0404, 0.0196, 0.0647], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,399][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ said] are: tensor([3.5699e-05, 6.4612e-03, 2.5421e-03, 5.6586e-02, 2.5864e-03, 1.0639e-02,
        1.5585e-01, 1.7193e-02, 2.5311e-02, 3.1839e-01, 3.1822e-01, 3.9046e-02,
        7.3457e-03, 3.9798e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,399][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ said] are: tensor([0.1049, 0.0764, 0.0156, 0.0223, 0.0126, 0.0363, 0.0779, 0.0401, 0.0496,
        0.0799, 0.1068, 0.2240, 0.0253, 0.1285], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,400][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ said] are: tensor([0.0131, 0.0060, 0.0038, 0.0872, 0.0359, 0.0272, 0.1022, 0.0213, 0.0146,
        0.1249, 0.3664, 0.0925, 0.0616, 0.0432], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,400][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ said] are: tensor([0.0057, 0.0134, 0.0165, 0.2073, 0.0033, 0.0629, 0.1965, 0.0223, 0.0825,
        0.1490, 0.1351, 0.0574, 0.0038, 0.0443], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,400][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ said] are: tensor([0.0248, 0.0456, 0.0309, 0.0581, 0.0201, 0.0160, 0.0363, 0.0673, 0.1168,
        0.0985, 0.0804, 0.2885, 0.0184, 0.0983], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,401][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ said] are: tensor([0.0697, 0.1525, 0.0265, 0.1549, 0.0094, 0.0559, 0.1132, 0.0205, 0.0457,
        0.1221, 0.0880, 0.0342, 0.0053, 0.1020], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,401][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ said] are: tensor([0.0043, 0.0962, 0.0431, 0.0919, 0.0039, 0.0313, 0.0251, 0.0829, 0.0329,
        0.2033, 0.2276, 0.0857, 0.0101, 0.0618], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,402][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ said] are: tensor([0.0337, 0.0912, 0.2907, 0.0333, 0.1100, 0.0228, 0.0492, 0.0210, 0.0493,
        0.0438, 0.0303, 0.0672, 0.1104, 0.0471], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,403][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ said] are: tensor([5.9281e-01, 1.6854e-03, 8.2534e-06, 3.2909e-03, 6.3957e-06, 5.8943e-03,
        4.8966e-02, 1.2782e-04, 3.0033e-02, 2.8709e-02, 1.7642e-01, 6.8615e-02,
        6.5137e-04, 4.2790e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,405][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ said] are: tensor([0.0008, 0.0493, 0.0419, 0.0663, 0.0508, 0.0670, 0.1396, 0.0723, 0.0555,
        0.1114, 0.1395, 0.0704, 0.0537, 0.0816], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,407][circuit_model.py][line:2294][INFO] ##11-th layer ##Weight##: The head1 weight for token [ to] are: tensor([0.2274, 0.2001, 0.2075, 0.0589, 0.0128, 0.0251, 0.0153, 0.0278, 0.0271,
        0.0532, 0.0454, 0.0303, 0.0101, 0.0258, 0.0333], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,408][circuit_model.py][line:2297][INFO] ##11-th layer ##Weight##: The head2 weight for token [ to] are: tensor([0.4098, 0.0742, 0.1267, 0.0621, 0.0164, 0.0139, 0.0313, 0.0072, 0.0315,
        0.0625, 0.0555, 0.0240, 0.0101, 0.0343, 0.0405], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,409][circuit_model.py][line:2300][INFO] ##11-th layer ##Weight##: The head3 weight for token [ to] are: tensor([2.1436e-04, 1.7896e-02, 7.5808e-03, 6.2572e-02, 5.0581e-03, 1.5704e-02,
        1.1922e-01, 1.9610e-02, 3.2237e-02, 2.4903e-01, 2.2654e-01, 4.9395e-02,
        9.6218e-03, 3.9221e-02, 1.4610e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,409][circuit_model.py][line:2303][INFO] ##11-th layer ##Weight##: The head4 weight for token [ to] are: tensor([0.1284, 0.0971, 0.0189, 0.0208, 0.0153, 0.0467, 0.0687, 0.0389, 0.0491,
        0.0630, 0.0734, 0.1779, 0.0235, 0.1044, 0.0738], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,410][circuit_model.py][line:2306][INFO] ##11-th layer ##Weight##: The head5 weight for token [ to] are: tensor([0.0153, 0.0084, 0.0031, 0.0805, 0.0227, 0.0205, 0.0708, 0.0172, 0.0124,
        0.1063, 0.3037, 0.0778, 0.0382, 0.0302, 0.1930], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,410][circuit_model.py][line:2309][INFO] ##11-th layer ##Weight##: The head6 weight for token [ to] are: tensor([0.0036, 0.0166, 0.0226, 0.2975, 0.0034, 0.0482, 0.1076, 0.0156, 0.0445,
        0.1263, 0.1197, 0.0458, 0.0039, 0.0272, 0.1174], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,411][circuit_model.py][line:2312][INFO] ##11-th layer ##Weight##: The head7 weight for token [ to] are: tensor([0.0132, 0.0675, 0.0600, 0.0616, 0.0115, 0.0095, 0.0231, 0.0613, 0.0868,
        0.1021, 0.0662, 0.2306, 0.0087, 0.0508, 0.1471], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,411][circuit_model.py][line:2315][INFO] ##11-th layer ##Weight##: The head8 weight for token [ to] are: tensor([0.0559, 0.2647, 0.0453, 0.1526, 0.0097, 0.0389, 0.0643, 0.0112, 0.0225,
        0.1064, 0.0744, 0.0249, 0.0039, 0.0568, 0.0685], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,411][circuit_model.py][line:2318][INFO] ##11-th layer ##Weight##: The head9 weight for token [ to] are: tensor([0.0188, 0.2559, 0.0935, 0.0697, 0.0097, 0.0160, 0.0129, 0.0453, 0.0214,
        0.1036, 0.1288, 0.0617, 0.0167, 0.0168, 0.1292], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,413][circuit_model.py][line:2321][INFO] ##11-th layer ##Weight##: The head10 weight for token [ to] are: tensor([0.0509, 0.1135, 0.4229, 0.0258, 0.0809, 0.0117, 0.0180, 0.0154, 0.0341,
        0.0260, 0.0165, 0.0625, 0.0750, 0.0270, 0.0199], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,414][circuit_model.py][line:2324][INFO] ##11-th layer ##Weight##: The head11 weight for token [ to] are: tensor([6.5737e-01, 2.9113e-03, 2.8668e-05, 6.0021e-03, 9.5333e-06, 5.4927e-03,
        2.9130e-02, 9.8106e-05, 1.7798e-02, 1.7801e-02, 1.0444e-01, 5.1295e-02,
        4.8023e-04, 2.0402e-02, 8.6740e-02], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,416][circuit_model.py][line:2327][INFO] ##11-th layer ##Weight##: The head12 weight for token [ to] are: tensor([0.0004, 0.0467, 0.0380, 0.0676, 0.0452, 0.0639, 0.1312, 0.0639, 0.0425,
        0.1032, 0.1229, 0.0577, 0.0448, 0.0566, 0.1154], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,481][circuit_model.py][line:1879][INFO] ############showing the attention weight of each circuit
[2024-07-24 10:20:20,482][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,483][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,484][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,484][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,485][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,486][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,486][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,488][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,489][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,491][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,492][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,493][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [Then] are: tensor([1.], device='cuda:0') for source tokens [Then]
[2024-07-24 10:20:20,494][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.4015, 0.5985], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,495][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.2365, 0.7635], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,495][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0627, 0.9373], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,496][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.8903, 0.1097], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,497][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.1233, 0.8767], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,499][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0399, 0.9601], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,501][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.3317, 0.6683], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,502][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0641, 0.9359], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,504][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0151, 0.9849], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,504][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.1035, 0.8965], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,505][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.1477, 0.8523], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,506][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.8659, 0.1341], device='cuda:0') for source tokens [Then,]
[2024-07-24 10:20:20,506][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Angela] are: tensor([0.0475, 0.3715, 0.5810], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,508][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Angela] are: tensor([0.3160, 0.5955, 0.0885], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,510][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Angela] are: tensor([0.1711, 0.7051, 0.1239], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,512][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Angela] are: tensor([0.1580, 0.6506, 0.1914], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,513][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Angela] are: tensor([0.2310, 0.4714, 0.2977], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,514][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Angela] are: tensor([0.1493, 0.5516, 0.2991], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,515][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Angela] are: tensor([0.1381, 0.3912, 0.4707], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,515][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Angela] are: tensor([0.1118, 0.6756, 0.2127], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,516][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Angela] are: tensor([0.0022, 0.6089, 0.3889], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,517][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Angela] are: tensor([0.1314, 0.5536, 0.3150], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,519][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Angela] are: tensor([0.1425, 0.6863, 0.1712], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,521][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Angela] are: tensor([0.1267, 0.0741, 0.7992], device='cuda:0') for source tokens [Then, Angela]
[2024-07-24 10:20:20,522][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2623, 0.4171, 0.2405, 0.0801], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,524][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.5535, 0.2376, 0.0745, 0.1344], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,525][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0237, 0.1316, 0.0333, 0.8114], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,525][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6269, 0.1376, 0.0068, 0.2287], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,526][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0148, 0.0455, 0.0293, 0.9105], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,527][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0100, 0.0572, 0.0404, 0.8924], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,529][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1449, 0.3796, 0.3214, 0.1541], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,531][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0752, 0.5854, 0.0859, 0.2535], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,532][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0265, 0.6115, 0.0777, 0.2844], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,534][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0945, 0.3448, 0.4164, 0.1443], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,535][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.5302, 0.3415, 0.0730, 0.0553], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,535][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8802, 0.0378, 0.0730, 0.0091], device='cuda:0') for source tokens [Then, Angela and]
[2024-07-24 10:20:20,536][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0328, 0.1650, 0.4022, 0.1988, 0.2011], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,537][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.4270, 0.3032, 0.1593, 0.0688, 0.0416], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,539][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0295, 0.1118, 0.0274, 0.6694, 0.1619], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,541][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.0512, 0.2182, 0.0188, 0.7027, 0.0091], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,542][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0314, 0.0545, 0.0370, 0.7261, 0.1510], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,544][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0370, 0.1373, 0.0771, 0.7364, 0.0122], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,545][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.1353, 0.2005, 0.3565, 0.1480, 0.1598], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,545][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0752, 0.5105, 0.0728, 0.3071, 0.0343], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,546][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([1.6833e-04, 4.8615e-02, 4.7589e-02, 8.9422e-01, 9.4108e-03],
       device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,547][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0829, 0.1799, 0.3216, 0.1651, 0.2505], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,549][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.1554, 0.4143, 0.1748, 0.2324, 0.0231], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,551][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.3207, 0.0534, 0.5397, 0.0184, 0.0679], device='cuda:0') for source tokens [Then, Angela and Tiffany]
[2024-07-24 10:20:20,552][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ had] are: tensor([0.1856, 0.3062, 0.3157, 0.0870, 0.0485, 0.0569], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,554][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ had] are: tensor([0.5020, 0.2129, 0.1386, 0.0653, 0.0486, 0.0326], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,555][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ had] are: tensor([0.0224, 0.1191, 0.0364, 0.6167, 0.1274, 0.0779], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,555][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ had] are: tensor([0.3191, 0.1009, 0.0057, 0.3851, 0.0020, 0.1873], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,556][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ had] are: tensor([0.0105, 0.0294, 0.0221, 0.5904, 0.0879, 0.2596], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,557][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ had] are: tensor([0.0051, 0.0431, 0.0607, 0.7177, 0.0129, 0.1604], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,559][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ had] are: tensor([0.2383, 0.2813, 0.2444, 0.1181, 0.0781, 0.0398], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,561][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ had] are: tensor([0.1661, 0.4823, 0.0654, 0.1960, 0.0209, 0.0692], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,562][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ had] are: tensor([0.0132, 0.3868, 0.1023, 0.3247, 0.0115, 0.1615], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,564][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ had] are: tensor([0.0376, 0.1458, 0.4095, 0.1013, 0.1743, 0.1315], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,565][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ had] are: tensor([0.3383, 0.2549, 0.0774, 0.0604, 0.0079, 0.2612], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,565][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ had] are: tensor([0.8655, 0.0349, 0.0695, 0.0057, 0.0114, 0.0131], device='cuda:0') for source tokens [Then, Angela and Tiffany had]
[2024-07-24 10:20:20,566][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ a] are: tensor([0.1268, 0.3036, 0.3103, 0.1127, 0.0415, 0.0676, 0.0374],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,567][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ a] are: tensor([0.5197, 0.1444, 0.1584, 0.0859, 0.0323, 0.0195, 0.0399],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,569][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ a] are: tensor([0.0271, 0.1063, 0.0248, 0.4709, 0.0776, 0.0386, 0.2547],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,571][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ a] are: tensor([0.4104, 0.0580, 0.0097, 0.2177, 0.0028, 0.0989, 0.2024],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,573][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ a] are: tensor([0.0146, 0.0239, 0.0211, 0.4614, 0.0431, 0.0910, 0.3448],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,574][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ a] are: tensor([0.0112, 0.0587, 0.0601, 0.5310, 0.0113, 0.0975, 0.2303],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,575][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ a] are: tensor([0.2341, 0.3254, 0.2717, 0.0932, 0.0326, 0.0172, 0.0258],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,576][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ a] are: tensor([0.1274, 0.3841, 0.0631, 0.2391, 0.0213, 0.0539, 0.1111],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,576][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ a] are: tensor([0.0284, 0.6274, 0.1523, 0.1067, 0.0173, 0.0407, 0.0271],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,577][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ a] are: tensor([0.0535, 0.2238, 0.4107, 0.0846, 0.0892, 0.0498, 0.0884],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,579][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ a] are: tensor([0.3738, 0.3259, 0.1007, 0.0543, 0.0032, 0.0837, 0.0584],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,581][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ a] are: tensor([0.8378, 0.0256, 0.0778, 0.0040, 0.0131, 0.0087, 0.0329],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a]
[2024-07-24 10:20:20,583][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ long] are: tensor([0.1636, 0.2851, 0.1974, 0.1012, 0.0416, 0.0721, 0.0458, 0.0933],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,584][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ long] are: tensor([0.3526, 0.1703, 0.0868, 0.1205, 0.0668, 0.0451, 0.1278, 0.0302],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,585][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ long] are: tensor([0.0262, 0.0718, 0.0140, 0.4442, 0.0711, 0.0437, 0.2981, 0.0308],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,586][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ long] are: tensor([0.5157, 0.0508, 0.0035, 0.1319, 0.0019, 0.0714, 0.1865, 0.0384],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,586][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ long] are: tensor([0.0126, 0.0191, 0.0078, 0.4018, 0.0255, 0.0936, 0.4186, 0.0211],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,588][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ long] are: tensor([0.0070, 0.0251, 0.0264, 0.5048, 0.0056, 0.0953, 0.2978, 0.0379],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,589][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ long] are: tensor([0.1339, 0.2251, 0.1474, 0.2107, 0.0760, 0.0580, 0.0985, 0.0504],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,591][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ long] are: tensor([0.1483, 0.2819, 0.0595, 0.2582, 0.0245, 0.0515, 0.1424, 0.0338],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,593][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ long] are: tensor([0.0054, 0.2179, 0.0845, 0.3845, 0.0106, 0.1053, 0.0644, 0.1275],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,594][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ long] are: tensor([0.0483, 0.0937, 0.1142, 0.0853, 0.0778, 0.1197, 0.3971, 0.0638],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,595][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ long] are: tensor([0.2325, 0.2331, 0.0860, 0.0758, 0.0038, 0.1966, 0.1385, 0.0335],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,596][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ long] are: tensor([0.8194, 0.0392, 0.0585, 0.0073, 0.0098, 0.0127, 0.0435, 0.0097],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long]
[2024-07-24 10:20:20,596][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ argument] are: tensor([0.1734, 0.2178, 0.1671, 0.0935, 0.0471, 0.0879, 0.0532, 0.0732, 0.0869],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,599][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ argument] are: tensor([0.4911, 0.1173, 0.0826, 0.0643, 0.0439, 0.0306, 0.0747, 0.0181, 0.0774],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,601][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ argument] are: tensor([0.0351, 0.0534, 0.0201, 0.3180, 0.0819, 0.0451, 0.3145, 0.0386, 0.0933],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,602][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ argument] are: tensor([0.6547, 0.0486, 0.0021, 0.0570, 0.0012, 0.0305, 0.0772, 0.0277, 0.1011],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,604][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ argument] are: tensor([0.0164, 0.0211, 0.0157, 0.3087, 0.0407, 0.0944, 0.4389, 0.0322, 0.0319],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,605][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ argument] are: tensor([0.0091, 0.0195, 0.0435, 0.2822, 0.0097, 0.1221, 0.3223, 0.0472, 0.1444],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,606][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ argument] are: tensor([0.2295, 0.1829, 0.1966, 0.0988, 0.0631, 0.0400, 0.0591, 0.0446, 0.0853],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,606][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ argument] are: tensor([0.1314, 0.2393, 0.0720, 0.2051, 0.0231, 0.0641, 0.1439, 0.0396, 0.0816],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,607][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ argument] are: tensor([0.0034, 0.1292, 0.1012, 0.3758, 0.0127, 0.0989, 0.0719, 0.1385, 0.0684],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,609][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ argument] are: tensor([0.0690, 0.0979, 0.1442, 0.0642, 0.0585, 0.1100, 0.2827, 0.0554, 0.1180],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,611][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ argument] are: tensor([0.2748, 0.1880, 0.0644, 0.0460, 0.0052, 0.1518, 0.1420, 0.0392, 0.0887],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,613][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ argument] are: tensor([0.6507, 0.0327, 0.0881, 0.0065, 0.0187, 0.0159, 0.0702, 0.0235, 0.0937],
       device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument]
[2024-07-24 10:20:20,614][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [,] are: tensor([0.1176, 0.2164, 0.2807, 0.1006, 0.0359, 0.0425, 0.0291, 0.0551, 0.0404,
        0.0817], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,615][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [,] are: tensor([0.4580, 0.0974, 0.1434, 0.0760, 0.0370, 0.0188, 0.0507, 0.0095, 0.0356,
        0.0737], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,616][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [,] are: tensor([0.0223, 0.0459, 0.0128, 0.3198, 0.0399, 0.0246, 0.2112, 0.0161, 0.0351,
        0.2724], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,617][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [,] are: tensor([0.3626, 0.0321, 0.0062, 0.1570, 0.0036, 0.0589, 0.1338, 0.0361, 0.1299,
        0.0798], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,619][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [,] are: tensor([0.0102, 0.0139, 0.0115, 0.3047, 0.0255, 0.0665, 0.2946, 0.0172, 0.0129,
        0.2431], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,621][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [,] are: tensor([0.0038, 0.0186, 0.0384, 0.3959, 0.0069, 0.0859, 0.1859, 0.0253, 0.0629,
        0.1764], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,623][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [,] are: tensor([0.1920, 0.2273, 0.2149, 0.1007, 0.0446, 0.0283, 0.0471, 0.0233, 0.0357,
        0.0861], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,624][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [,] are: tensor([0.0732, 0.1994, 0.0530, 0.2346, 0.0188, 0.0640, 0.1345, 0.0230, 0.0403,
        0.1593], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,625][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [,] are: tensor([0.0120, 0.3169, 0.1332, 0.1787, 0.0118, 0.0357, 0.0221, 0.0867, 0.0339,
        0.1688], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,626][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [,] are: tensor([0.0195, 0.0771, 0.3090, 0.0915, 0.0654, 0.0608, 0.1924, 0.0234, 0.0390,
        0.1220], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,627][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [,] are: tensor([0.2020, 0.2286, 0.1047, 0.0776, 0.0033, 0.1128, 0.0834, 0.0148, 0.0432,
        0.1295], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,628][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [,] are: tensor([0.7022, 0.0271, 0.1226, 0.0067, 0.0245, 0.0101, 0.0446, 0.0121, 0.0402,
        0.0100], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument,]
[2024-07-24 10:20:20,630][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ and] are: tensor([0.2563, 0.2307, 0.2160, 0.0679, 0.0174, 0.0279, 0.0168, 0.0352, 0.0287,
        0.0537, 0.0495], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,632][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ and] are: tensor([0.4912, 0.1013, 0.1201, 0.0637, 0.0306, 0.0141, 0.0300, 0.0081, 0.0339,
        0.0534, 0.0536], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,633][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ and] are: tensor([0.0214, 0.0556, 0.0111, 0.2449, 0.0256, 0.0202, 0.1380, 0.0145, 0.0328,
        0.1973, 0.2386], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,635][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ and] are: tensor([0.6010, 0.0216, 0.0032, 0.0712, 0.0022, 0.0222, 0.0483, 0.0132, 0.0702,
        0.0367, 0.1102], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,635][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ and] are: tensor([0.0080, 0.0102, 0.0081, 0.2227, 0.0158, 0.0462, 0.1715, 0.0153, 0.0116,
        0.1740, 0.3166], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,636][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ and] are: tensor([0.0060, 0.0222, 0.0294, 0.3379, 0.0064, 0.0617, 0.1314, 0.0266, 0.0649,
        0.1610, 0.1524], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,637][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ and] are: tensor([0.1950, 0.2422, 0.1436, 0.0937, 0.0266, 0.0218, 0.0339, 0.0225, 0.0370,
        0.0873, 0.0964], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,639][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ and] are: tensor([0.0790, 0.2753, 0.0442, 0.1785, 0.0114, 0.0457, 0.0787, 0.0188, 0.0345,
        0.1327, 0.1013], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,641][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ and] are: tensor([0.0227, 0.2571, 0.1060, 0.1270, 0.0150, 0.0251, 0.0198, 0.0698, 0.0354,
        0.1411, 0.1809], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,643][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ and] are: tensor([0.0193, 0.1091, 0.2738, 0.0802, 0.0631, 0.0422, 0.1166, 0.0280, 0.0466,
        0.1272, 0.0938], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,644][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ and] are: tensor([0.2802, 0.2043, 0.0633, 0.0564, 0.0025, 0.0665, 0.0602, 0.0122, 0.0363,
        0.1092, 0.1089], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,646][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ and] are: tensor([0.8212, 0.0174, 0.0396, 0.0033, 0.0108, 0.0054, 0.0272, 0.0091, 0.0285,
        0.0088, 0.0287], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and]
[2024-07-24 10:20:20,648][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ afterwards] are: tensor([0.1224, 0.1992, 0.1551, 0.0580, 0.0542, 0.0537, 0.0376, 0.0660, 0.0515,
        0.0708, 0.0753, 0.0563], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,650][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ afterwards] are: tensor([0.3711, 0.1236, 0.0739, 0.0747, 0.0321, 0.0265, 0.0716, 0.0189, 0.0523,
        0.0641, 0.0591, 0.0321], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,651][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ afterwards] are: tensor([0.0293, 0.0504, 0.0164, 0.2606, 0.0394, 0.0358, 0.1448, 0.0208, 0.0451,
        0.1502, 0.1774, 0.0298], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,652][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ afterwards] are: tensor([0.6219, 0.0242, 0.0026, 0.0271, 0.0016, 0.0135, 0.0454, 0.0167, 0.0479,
        0.0267, 0.0743, 0.0981], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,652][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ afterwards] are: tensor([0.0074, 0.0107, 0.0072, 0.1991, 0.0113, 0.0450, 0.2506, 0.0192, 0.0110,
        0.1504, 0.2494, 0.0386], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,653][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ afterwards] are: tensor([0.0061, 0.0255, 0.0346, 0.2586, 0.0073, 0.0753, 0.1997, 0.0346, 0.0630,
        0.1327, 0.1067, 0.0560], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,654][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ afterwards] are: tensor([0.1531, 0.1908, 0.1946, 0.0852, 0.0343, 0.0290, 0.0333, 0.0336, 0.0407,
        0.0569, 0.0511, 0.0976], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,656][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ afterwards] are: tensor([0.0553, 0.1888, 0.0676, 0.2362, 0.0159, 0.0408, 0.1215, 0.0254, 0.0364,
        0.1135, 0.0675, 0.0310], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,658][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ afterwards] are: tensor([0.0059, 0.1214, 0.0789, 0.2291, 0.0127, 0.0572, 0.0454, 0.0785, 0.0444,
        0.1406, 0.1375, 0.0484], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,660][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ afterwards] are: tensor([0.0191, 0.0760, 0.1574, 0.0867, 0.0498, 0.0755, 0.1949, 0.0304, 0.0540,
        0.1157, 0.0858, 0.0548], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,661][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ afterwards] are: tensor([0.1593, 0.1753, 0.1199, 0.0420, 0.0068, 0.0802, 0.0828, 0.0216, 0.0409,
        0.1298, 0.0828, 0.0587], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,662][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ afterwards] are: tensor([0.6973, 0.0257, 0.0798, 0.0037, 0.0168, 0.0077, 0.0334, 0.0218, 0.0426,
        0.0081, 0.0257, 0.0374], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards]
[2024-07-24 10:20:20,663][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ Tiffany] are: tensor([0.0199, 0.0630, 0.1902, 0.0780, 0.0890, 0.0978, 0.0473, 0.0799, 0.0814,
        0.0751, 0.0717, 0.0382, 0.0684], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,664][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ Tiffany] are: tensor([0.3024, 0.1394, 0.0841, 0.0478, 0.0243, 0.0303, 0.0967, 0.0152, 0.0630,
        0.0656, 0.0694, 0.0429, 0.0190], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,666][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ Tiffany] are: tensor([0.0170, 0.0282, 0.0055, 0.1443, 0.0359, 0.0231, 0.1843, 0.0244, 0.0515,
        0.1739, 0.2197, 0.0428, 0.0493], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,668][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ Tiffany] are: tensor([0.1210, 0.0612, 0.0062, 0.1194, 0.0058, 0.0746, 0.1470, 0.0702, 0.1384,
        0.0401, 0.0908, 0.1168, 0.0085], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,669][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ Tiffany] are: tensor([0.0057, 0.0085, 0.0040, 0.1164, 0.0172, 0.0388, 0.3042, 0.0185, 0.0149,
        0.1494, 0.2658, 0.0368, 0.0199], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,671][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ Tiffany] are: tensor([0.0099, 0.0299, 0.0190, 0.1824, 0.0025, 0.0607, 0.2568, 0.0340, 0.0658,
        0.1433, 0.1377, 0.0548, 0.0031], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,672][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ Tiffany] are: tensor([0.0656, 0.0925, 0.1502, 0.0886, 0.0784, 0.0317, 0.0508, 0.0561, 0.0599,
        0.0752, 0.0790, 0.1110, 0.0610], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,673][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ Tiffany] are: tensor([0.0273, 0.1526, 0.0312, 0.1720, 0.0117, 0.0613, 0.2420, 0.0313, 0.0501,
        0.1162, 0.0736, 0.0266, 0.0044], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,674][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ Tiffany] are: tensor([8.9285e-05, 1.5920e-02, 2.8037e-02, 5.0642e-01, 6.5233e-03, 3.9172e-02,
        3.4139e-02, 8.3212e-02, 3.0026e-02, 1.1882e-01, 1.0912e-01, 2.3734e-02,
        4.7882e-03], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,676][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ Tiffany] are: tensor([0.0119, 0.0300, 0.0728, 0.0386, 0.0384, 0.0778, 0.3359, 0.0376, 0.0586,
        0.1105, 0.1203, 0.0477, 0.0199], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,678][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ Tiffany] are: tensor([0.0570, 0.1019, 0.0610, 0.0736, 0.0077, 0.1548, 0.1114, 0.0463, 0.0948,
        0.1481, 0.0975, 0.0428, 0.0031], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,679][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ Tiffany] are: tensor([0.4260, 0.0321, 0.2220, 0.0092, 0.0336, 0.0130, 0.0501, 0.0350, 0.0794,
        0.0066, 0.0208, 0.0474, 0.0250], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany]
[2024-07-24 10:20:20,681][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ said] are: tensor([0.3169, 0.1803, 0.1931, 0.0473, 0.0163, 0.0221, 0.0163, 0.0263, 0.0287,
        0.0437, 0.0459, 0.0228, 0.0121, 0.0284], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,682][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ said] are: tensor([0.3712, 0.0938, 0.0779, 0.0447, 0.0264, 0.0227, 0.0551, 0.0102, 0.0548,
        0.0600, 0.0586, 0.0404, 0.0196, 0.0647], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,683][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ said] are: tensor([0.0161, 0.0298, 0.0067, 0.1926, 0.0455, 0.0225, 0.1670, 0.0185, 0.0397,
        0.1715, 0.1833, 0.0367, 0.0341, 0.0359], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,684][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ said] are: tensor([4.4672e-01, 8.2987e-03, 5.3497e-04, 1.1997e-02, 3.3134e-04, 5.1492e-03,
        2.2900e-02, 5.0112e-03, 2.6426e-02, 2.0705e-02, 8.7148e-02, 1.1694e-01,
        4.1213e-03, 2.4372e-01], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,686][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ said] are: tensor([0.0053, 0.0081, 0.0077, 0.2044, 0.0204, 0.0545, 0.2120, 0.0165, 0.0130,
        0.1435, 0.2325, 0.0297, 0.0129, 0.0395], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,688][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ said] are: tensor([0.0068, 0.0153, 0.0183, 0.1905, 0.0036, 0.0598, 0.1724, 0.0254, 0.0932,
        0.1566, 0.1356, 0.0679, 0.0044, 0.0501], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,690][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ said] are: tensor([0.1894, 0.1408, 0.0996, 0.0734, 0.0397, 0.0232, 0.0321, 0.0198, 0.0447,
        0.0658, 0.0751, 0.1179, 0.0316, 0.0471], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,692][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ said] are: tensor([0.0697, 0.1525, 0.0265, 0.1549, 0.0094, 0.0559, 0.1132, 0.0205, 0.0457,
        0.1221, 0.0880, 0.0342, 0.0053, 0.1020], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,692][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ said] are: tensor([0.0043, 0.0962, 0.0431, 0.0919, 0.0039, 0.0313, 0.0251, 0.0829, 0.0329,
        0.2033, 0.2276, 0.0857, 0.0101, 0.0618], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,693][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ said] are: tensor([0.0267, 0.0729, 0.1403, 0.0368, 0.0486, 0.0490, 0.1688, 0.0222, 0.0664,
        0.0976, 0.0800, 0.0624, 0.0261, 0.1023], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,694][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ said] are: tensor([0.2827, 0.0750, 0.0300, 0.0148, 0.0023, 0.0434, 0.0620, 0.0136, 0.0430,
        0.1822, 0.1364, 0.0507, 0.0016, 0.0623], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,696][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ said] are: tensor([0.5493, 0.0066, 0.0214, 0.0007, 0.0035, 0.0016, 0.0136, 0.0053, 0.0255,
        0.0040, 0.0199, 0.0310, 0.0119, 0.3058], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said]
[2024-07-24 10:20:20,698][circuit_model.py][line:2332][INFO] ##11-th layer ##Weight##: The head1 weight before mlp for token [ to] are: tensor([0.2274, 0.2001, 0.2075, 0.0589, 0.0128, 0.0251, 0.0153, 0.0278, 0.0271,
        0.0532, 0.0454, 0.0303, 0.0101, 0.0258, 0.0333], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,700][circuit_model.py][line:2335][INFO] ##11-th layer ##Weight##: The head2 weight before mlp for token [ to] are: tensor([0.4098, 0.0742, 0.1267, 0.0621, 0.0164, 0.0139, 0.0313, 0.0072, 0.0315,
        0.0625, 0.0555, 0.0240, 0.0101, 0.0343, 0.0405], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,702][circuit_model.py][line:2338][INFO] ##11-th layer ##Weight##: The head3 weight before mlp for token [ to] are: tensor([0.0103, 0.0302, 0.0070, 0.2063, 0.0193, 0.0141, 0.1172, 0.0087, 0.0241,
        0.1583, 0.1903, 0.0315, 0.0196, 0.0218, 0.1413], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,703][circuit_model.py][line:2341][INFO] ##11-th layer ##Weight##: The head4 weight before mlp for token [ to] are: tensor([0.3587, 0.0133, 0.0024, 0.0374, 0.0015, 0.0145, 0.0362, 0.0072, 0.0381,
        0.0215, 0.0653, 0.0907, 0.0064, 0.2288, 0.0781], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,703][circuit_model.py][line:2344][INFO] ##11-th layer ##Weight##: The head5 weight before mlp for token [ to] are: tensor([0.0054, 0.0072, 0.0056, 0.2082, 0.0102, 0.0374, 0.1400, 0.0105, 0.0088,
        0.1230, 0.2326, 0.0232, 0.0074, 0.0195, 0.1610], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,704][circuit_model.py][line:2347][INFO] ##11-th layer ##Weight##: The head6 weight before mlp for token [ to] are: tensor([0.0044, 0.0191, 0.0248, 0.2725, 0.0038, 0.0463, 0.0953, 0.0179, 0.0505,
        0.1325, 0.1202, 0.0547, 0.0046, 0.0311, 0.1224], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,706][circuit_model.py][line:2350][INFO] ##11-th layer ##Weight##: The head7 weight before mlp for token [ to] are: tensor([0.1406, 0.2117, 0.1626, 0.0744, 0.0201, 0.0149, 0.0203, 0.0152, 0.0279,
        0.0625, 0.0613, 0.0803, 0.0139, 0.0244, 0.0697], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,708][circuit_model.py][line:2353][INFO] ##11-th layer ##Weight##: The head8 weight before mlp for token [ to] are: tensor([0.0559, 0.2647, 0.0453, 0.1526, 0.0097, 0.0389, 0.0643, 0.0112, 0.0225,
        0.1064, 0.0744, 0.0249, 0.0039, 0.0568, 0.0685], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,710][circuit_model.py][line:2356][INFO] ##11-th layer ##Weight##: The head9 weight before mlp for token [ to] are: tensor([0.0188, 0.2559, 0.0935, 0.0697, 0.0097, 0.0160, 0.0129, 0.0453, 0.0214,
        0.1036, 0.1288, 0.0617, 0.0167, 0.0168, 0.1292], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,712][circuit_model.py][line:2359][INFO] ##11-th layer ##Weight##: The head10 weight before mlp for token [ to] are: tensor([0.0212, 0.1111, 0.2812, 0.0503, 0.0386, 0.0279, 0.0693, 0.0137, 0.0307,
        0.0777, 0.0569, 0.0632, 0.0170, 0.0436, 0.0978], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,713][circuit_model.py][line:2362][INFO] ##11-th layer ##Weight##: The head11 weight before mlp for token [ to] are: tensor([0.3395, 0.1107, 0.0460, 0.0316, 0.0020, 0.0431, 0.0433, 0.0073, 0.0308,
        0.1063, 0.0995, 0.0491, 0.0012, 0.0348, 0.0550], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,714][circuit_model.py][line:2365][INFO] ##11-th layer ##Weight##: The head12 weight before mlp for token [ to] are: tensor([0.7473, 0.0077, 0.0319, 0.0012, 0.0052, 0.0018, 0.0109, 0.0031, 0.0142,
        0.0029, 0.0132, 0.0206, 0.0095, 0.1202, 0.0104], device='cuda:0') for source tokens [Then, Angela and Tiffany had a long argument, and afterwards Tiffany said to]
[2024-07-24 10:20:20,717][circuit_model.py][line:2041][INFO] ############showing the lable-rank of each circuit
[2024-07-24 10:20:20,719][circuit_model.py][line:2228][INFO] The CircuitSUM has label_rank 
 tensor([[2580],
        [  23],
        [  83],
        [   9],
        [  10],
        [  17],
        [   1],
        [   1],
        [   1],
        [   1],
        [   1],
        [   4],
        [   4],
        [   4],
        [   1]], device='cuda:0')
[2024-07-24 10:20:20,721][circuit_model.py][line:2230][INFO] The Circuit0 has label_rank 
 tensor([[3053],
        [  61],
        [ 205],
        [  28],
        [  42],
        [  53],
        [  21],
        [   9],
        [  11],
        [  25],
        [   9],
        [  20],
        [  11],
        [  21],
        [   7]], device='cuda:0')
[2024-07-24 10:20:20,723][circuit_model.py][line:2232][INFO] The Circuit1 has label_rank 
 tensor([[9169],
        [3355],
        [1375],
        [2660],
        [2330],
        [2486],
        [2844],
        [3726],
        [4169],
        [3610],
        [3877],
        [4593],
        [4508],
        [3994],
        [4080]], device='cuda:0')
[2024-07-24 10:20:20,724][circuit_model.py][line:2234][INFO] The Circuit2 has label_rank 
 tensor([[ 1568],
        [18558],
        [30729],
        [25522],
        [43750],
        [43680],
        [44334],
        [41996],
        [39834],
        [44420],
        [42015],
        [39712],
        [42046],
        [42854],
        [44477]], device='cuda:0')
[2024-07-24 10:20:20,725][circuit_model.py][line:2236][INFO] The Circuit3 has label_rank 
 tensor([[ 8889],
        [10401],
        [46216],
        [26248],
        [26544],
        [19758],
        [ 8550],
        [ 8913],
        [ 4301],
        [ 5683],
        [ 5293],
        [ 4731],
        [ 5204],
        [ 4948],
        [ 6366]], device='cuda:0')
[2024-07-24 10:20:20,727][circuit_model.py][line:2238][INFO] The Circuit4 has label_rank 
 tensor([[38463],
        [39108],
        [35205],
        [34901],
        [32572],
        [33064],
        [31598],
        [28794],
        [27060],
        [26920],
        [26177],
        [22705],
        [22583],
        [22568],
        [22662]], device='cuda:0')
[2024-07-24 10:20:20,729][circuit_model.py][line:2240][INFO] The Circuit5 has label_rank 
 tensor([[30960],
        [36250],
        [34667],
        [33346],
        [34213],
        [32287],
        [28882],
        [28341],
        [28258],
        [28395],
        [28741],
        [28275],
        [27765],
        [27819],
        [27090]], device='cuda:0')
[2024-07-24 10:20:20,731][circuit_model.py][line:2242][INFO] The Circuit6 has label_rank 
 tensor([[50003],
        [44032],
        [35699],
        [29353],
        [30048],
        [28450],
        [29909],
        [30359],
        [30953],
        [29845],
        [29318],
        [29267],
        [29742],
        [29010],
        [27221]], device='cuda:0')
[2024-07-24 10:20:20,733][circuit_model.py][line:2244][INFO] The Circuit7 has label_rank 
 tensor([[11574],
        [ 6944],
        [28160],
        [19994],
        [18936],
        [19565],
        [21006],
        [12293],
        [12438],
        [12186],
        [10704],
        [11739],
        [10573],
        [11424],
        [11733]], device='cuda:0')
[2024-07-24 10:20:20,734][circuit_model.py][line:2246][INFO] The Circuit8 has label_rank 
 tensor([[41354],
        [35979],
        [32175],
        [40039],
        [41203],
        [40480],
        [41908],
        [42973],
        [42596],
        [43164],
        [42791],
        [43220],
        [43598],
        [43696],
        [43182]], device='cuda:0')
[2024-07-24 10:20:20,735][circuit_model.py][line:2248][INFO] The Circuit9 has label_rank 
 tensor([[15835],
        [18201],
        [19636],
        [19817],
        [44215],
        [23246],
        [19647],
        [30503],
        [36607],
        [25237],
        [27733],
        [40606],
        [42320],
        [44877],
        [28895]], device='cuda:0')
[2024-07-24 10:20:20,737][circuit_model.py][line:2250][INFO] The Circuit10 has label_rank 
 tensor([[26447],
        [23061],
        [39585],
        [41325],
        [39007],
        [40381],
        [40644],
        [38528],
        [37143],
        [39780],
        [38875],
        [35722],
        [33642],
        [35698],
        [37958]], device='cuda:0')
[2024-07-24 10:20:20,739][circuit_model.py][line:2252][INFO] The Circuit11 has label_rank 
 tensor([[24797],
        [43969],
        [39210],
        [31519],
        [38593],
        [33071],
        [33102],
        [34642],
        [31645],
        [34807],
        [34295],
        [34065],
        [34502],
        [33164],
        [32851]], device='cuda:0')
[2024-07-24 10:20:20,740][circuit_model.py][line:2254][INFO] The Circuit12 has label_rank 
 tensor([[10463],
        [11568],
        [15999],
        [12290],
        [12012],
        [10019],
        [ 9119],
        [ 9254],
        [ 9417],
        [ 9434],
        [ 9378],
        [ 8951],
        [ 8982],
        [ 9285],
        [ 8931]], device='cuda:0')
[2024-07-24 10:20:20,742][circuit_model.py][line:2256][INFO] The Circuit13 has label_rank 
 tensor([[11493],
        [ 4623],
        [11803],
        [ 5656],
        [11049],
        [ 8270],
        [ 6789],
        [ 7765],
        [ 8238],
        [ 8056],
        [ 7574],
        [10709],
        [11972],
        [10807],
        [ 6793]], device='cuda:0')
[2024-07-24 10:20:20,744][circuit_model.py][line:2258][INFO] The Circuit14 has label_rank 
 tensor([[17763],
        [20785],
        [18008],
        [19794],
        [17839],
        [18384],
        [18341],
        [18577],
        [17437],
        [18083],
        [18246],
        [17204],
        [16685],
        [17740],
        [17799]], device='cuda:0')
[2024-07-24 10:20:20,745][circuit_model.py][line:2260][INFO] The Circuit15 has label_rank 
 tensor([[ 5770],
        [ 8687],
        [ 9367],
        [11150],
        [12601],
        [12880],
        [13403],
        [13710],
        [13263],
        [14058],
        [13745],
        [13743],
        [13893],
        [13946],
        [14118]], device='cuda:0')
[2024-07-24 10:20:20,746][circuit_model.py][line:2262][INFO] The Circuit16 has label_rank 
 tensor([[33218],
        [25232],
        [21469],
        [25320],
        [21313],
        [21278],
        [21886],
        [21665],
        [20847],
        [23196],
        [24290],
        [23393],
        [23062],
        [22958],
        [24477]], device='cuda:0')
[2024-07-24 10:20:20,748][circuit_model.py][line:2264][INFO] The Circuit17 has label_rank 
 tensor([[14040],
        [16823],
        [16632],
        [13980],
        [13639],
        [13878],
        [13832],
        [13926],
        [14281],
        [14116],
        [13610],
        [14784],
        [14770],
        [15889],
        [15911]], device='cuda:0')
[2024-07-24 10:20:20,750][circuit_model.py][line:2266][INFO] The Circuit18 has label_rank 
 tensor([[18589],
        [12809],
        [13183],
        [14673],
        [16359],
        [13611],
        [13784],
        [13557],
        [13899],
        [12753],
        [11532],
        [11597],
        [11529],
        [11338],
        [10702]], device='cuda:0')
[2024-07-24 10:20:20,752][circuit_model.py][line:2268][INFO] The Circuit19 has label_rank 
 tensor([[ 8731],
        [11725],
        [13238],
        [16121],
        [15614],
        [14675],
        [13476],
        [13092],
        [12076],
        [13010],
        [13344],
        [12691],
        [12414],
        [12705],
        [13842]], device='cuda:0')
[2024-07-24 10:20:20,754][circuit_model.py][line:2270][INFO] The Circuit20 has label_rank 
 tensor([[11917],
        [28860],
        [20847],
        [20790],
        [15673],
        [18964],
        [20562],
        [19862],
        [20853],
        [22147],
        [25486],
        [23864],
        [23593],
        [25778],
        [25609]], device='cuda:0')
[2024-07-24 10:20:20,755][circuit_model.py][line:2272][INFO] The Circuit21 has label_rank 
 tensor([[13296],
        [17388],
        [18569],
        [19344],
        [19516],
        [19528],
        [20066],
        [20580],
        [20789],
        [21017],
        [20198],
        [20765],
        [20590],
        [20229],
        [19856]], device='cuda:0')
[2024-07-24 10:20:20,756][circuit_model.py][line:2274][INFO] The Circuit22 has label_rank 
 tensor([[15409],
        [14363],
        [13733],
        [13536],
        [ 5430],
        [11971],
        [13699],
        [ 7837],
        [ 4480],
        [10839],
        [ 9316],
        [ 2716],
        [ 6245],
        [ 1866],
        [ 8746]], device='cuda:0')
[2024-07-24 10:20:20,758][circuit_model.py][line:2276][INFO] The Circuit23 has label_rank 
 tensor([[23374],
        [ 5881],
        [ 4982],
        [ 4667],
        [ 3611],
        [ 4061],
        [ 4321],
        [ 4940],
        [ 5072],
        [ 4605],
        [ 4563],
        [ 4461],
        [ 4776],
        [ 4362],
        [ 4211]], device='cuda:0')
[2024-07-24 10:20:20,760][circuit_model.py][line:2278][INFO] The Circuit24 has label_rank 
 tensor([[10335],
        [13329],
        [12869],
        [11539],
        [10838],
        [10248],
        [10556],
        [ 9695],
        [ 9220],
        [10258],
        [10723],
        [10589],
        [10291],
        [11256],
        [10948]], device='cuda:0')
[2024-07-24 10:20:20,762][circuit_model.py][line:2280][INFO] The Circuit25 has label_rank 
 tensor([[ 8831],
        [ 8618],
        [12265],
        [ 8341],
        [11576],
        [ 8663],
        [ 9465],
        [ 9873],
        [10639],
        [10418],
        [ 9153],
        [10018],
        [10613],
        [ 9508],
        [ 8786]], device='cuda:0')
[2024-07-24 10:20:20,763][circuit_model.py][line:2282][INFO] The Circuit26 has label_rank 
 tensor([[37053],
        [36950],
        [37079],
        [37179],
        [39423],
        [38488],
        [37941],
        [38340],
        [38772],
        [37546],
        [37725],
        [38448],
        [38630],
        [38482],
        [37013]], device='cuda:0')
[2024-07-24 10:20:20,765][circuit_model.py][line:2284][INFO] The Circuit27 has label_rank 
 tensor([[37437],
        [44038],
        [38671],
        [42754],
        [40548],
        [42683],
        [42023],
        [42084],
        [43065],
        [42297],
        [42428],
        [41213],
        [38207],
        [42047],
        [42719]], device='cuda:0')
[2024-07-24 10:20:20,766][circuit_model.py][line:2286][INFO] The Circuit28 has label_rank 
 tensor([[17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496],
        [17496]], device='cuda:0')
